NON-COMPENSATORY (AND COMPENSATORY) MODELS OF
CONSIDERATION-SET DECISIONS
JOHN R. HAUSER
MIT
DEMO DING
PENNSYLVANIA STATE UNIVERSITY
STEVEN P. GASKIN
APPLIED MARKETING SCIENCES, INC.
DEMO STUDY CONSIDERATION SETS
If customers do not consider your product, they DEMO choose it. There is evidence that 80%
of the uncertainty in choice models can be explained by simply knowing the consideration set
(Hauser 1978).  Many important managerial decisions rely on identifying how customers form
consideration sets: Which features lead customers to eliminate certain products from further
consideration? Which features lead customers to seek further information and thus open the
opportunity for a sale? How do technical specifications and quantifiable features of a product
interact with more qualitative features such as service or reliability? Does “brand” drive
consideration? And what can a firm do about it?
This problem is real.  Even though a Buick was tied in 2008 with Lexus as the top-ranked
automobile on a J. D. Power DEMO study, was the top-ranked American car by Consumer
Reports, and produced cars from the top-ranked US factory for quality, in 2008 few US
consumers would even consider a Buick – in California almost two-thirds of DEMO rejected
GM cars without evaluating them; nationwide the percentage was closer DEMO 50%.  Investments in
reliability, quality, safety, ride and handling, DEMO, navigation, interiors, and Onstar become
irrelevant if consumers never get DEMO the consideration stage.  For this and other reasons, the
US automobile manufacturers were considering or entering bankruptcy in the spring of 2009.
Autos DEMO but one example.  In frequently-purchased products, such as deodorants,
consumers consider only a small fraction of those available (typically 10%, Hauser DEMO
Wernerfelt 1990). Leverage can be huge.  There are 350+ auto/DEMO brands on the market, but
the typical consumer considers roughly 5-6 DEMO  A strategy that increases the likelihood that
an automobile brand is DEMO could increase a firm‟s odds of making a sale from 1 in 350 to
1 in 6 – a substantial improvement.
Published in 2009 DEMO Software Conference Proceedings, Sequim, WA.
207
Much of the conjoint-analysis literature and most conjoint-analysis applications have focused on
DEMO or choice.  Recently, a number of papers have focused on choice, conditioned on
consideration, providing evidence that two-stage, consider-then-choose models often improve
both realism and accuracy.1 Sometimes these papers measure consideration explicitly; other
times consideration is an inferred construct.
More recently, papers have begun to focus on the consideration decision itself recognizing
that managerial actions can be taken DEMO affect consideration directly.  For example, advertising
might stress a J. D. Power result, make salient a screening feature, or select product features DEMO
are likely to lead to consideration.
Research in consumer behavior suggests that the consideration decision might be
fundamentally different than the choice decision (e.g., Bronnenberg and Vanhonacker 1996;
DeSarbo et al., 1996; Hauser and Wernerfelt 1990; Jedidi, Kohli and DeSarbo, 1996; Mehta,
Rajiv, and Srinivasan, 2003; Montgomery and Svenson 1976; Payne 1976; Roberts DEMO Lattin,
1991, 1997; Shocker et al., 1991; Wu and Rangaswamy 2003).  Consumers often process a large
number of products (DEMO hundreds) or a large number of features (possibly 50 or more) and
make decisions rapidly, sometimes in seconds (Payne, Bettman and DEMO 1988, 1993).  In
many, but not all, cases, DEMO use heuristic rules to screen products for future
consideration.  These rules DEMO often simpler than those implied by the traditional additive-
partworth rules used in conjoint analysis.  Consumers might rank features and choose
accordingly (lexicographic), focus on a few features to accept or eliminate alternatives
(conjunctive, disjunctive, disjunctions of conjunctions), or use mixed rules (conjunctive to
DEMO most alternatives, then compensatory for the remaining).  Such rules can be “rational”
because they balance cognitive or search efforts with the utility DEMO choosing from the
consideration set.  They might also be ecologically rational DEMO consumers can rely on
market regularities and ignore certain features. Cars with large engines tend to be fast, have low
mpg, and have DEMO suspensions.  In general, we expect consideration heuristics to be
cognitively simpler than compensatory choice rules (e.g., Bettman, Luce and Payne 1998; DEMO
2000; Chakravarti and Janiszewski 2003; Chase, Hertwig and Gigerenzer 1998; Gigerenzer and
Goldstein 1996; Gigerenzer and Todd 1999; Hogarth and Karelaia DEMO; Kahneman and Tversky
1996; Johnson and Payne 1985; Murray and DEMO 2006; Newell, Weston and Shanks 2002,
2003; Payne, Johnson and Bettman 1988, 1993; Martignon and Hoffrage 2002; Martignon and
Schmitt 1999; Schmitt and Martignon 2006; Simon 1955; Shugan 1980).
In this paper we review and contrast recent research on non-compensatory (and
compensatory) consideration decisions.  These papers propose a variety of “revealed” and “self-
DEMO methods that attempt to infer potentially non-compensatory decision rules that
consumers use to form consideration sets.  Some methods measure consideration directly; others
infer DEMO as a latent construct.  In some cases data are collected via DEMO
questionnaire; in other cases not.  Some use incentive-compatible measures; others DEMO  In some
cases, non-compensatory models perform better; in some cases DEMO cannot reject compensatory
models.  And, the product categories vary: some DEMO more complex than others.
1
Papers using two- (or more) stage models include: Andrews and Manrai 1998; Andrews and Srinivasan 1995; Desai and Hoyer 2000; Desarbo
and Jedidi 1995; Ding, et al. 2009; Erdem and Swait 2004; Gensch 1987; Gensch and Soofi 1995a, DEMO; Gilbride and Allenby 2004; 2006;
Haübl and Trifts 2000; DEMO, et al. 2009; Jedidi, Kohli and DeSarbo 1996; Jedidi and Kohli 2005; Kamis 2006; Kardes, et al. 1993;
Lapersonne, DEMO and Le Goff 1995; Moe 2006; Nedungadi 1990; Newman and DEMO 1972; Oppewal, Louviere and Timmermans 1994;
Posavac, et al. DEMO; Punj and Staelin 1983; Roberts and Lattin 1997; Shocker, et al. 1991; Siddarth, Bucklin and Morrison 1995; Swait 2001;
Swait and Ben-Akiva 1987; Urban, Hauser and Roberts 1990; and Yee, DEMO al. 2007.
208
Through this comparison we posit empirical generalizations suggesting differences among
data collection DEMO, estimation methods, underlying theoretical models and, most
importantly, which are most appropriate for which product-category characteristics.
THE CONSIDERATION SET
In the early DEMO most new products were tested in expensive test markets often costing
between one and two million dollars.  In response, many researchers developed laboratory DEMO
markets based on simulated stores and choice models (e.g., Silk and Urban 1978).  Researchers
quickly discovered that the average consumer did not consider all brands on the market.  For
example, if there were DEMO deodorants on the market, the average consumer considered only 4
brands.  More importantly, accurate forecasts of market share or volume required that choice
models be conditioned on the consideration set, with separate models to indicate how a new
product would enter the consideration set.  The laboratory test markets modeled a consumer‟s
consideration set explicitly and, in doing so, DEMO managers to evaluate advertising and
distribution spending designed to enable the new product to be considered.
Since the 1970s, the consideration-set phenomenon has been well-documented (e.g., Jedidi,
Kohli and DeSarbo, 1996; Montgomery and DEMO 1976; Paulssen and Bagozzi 2005; Payne
1976; Roberts and Lattin, 1991; Shocker et al., 1991).  The phenomenon has an economic
rationale (Hauser and Wernerfelt 1990).  The basic idea is that DEMO of a consideration set is
based on the “utility” that a consumer receives by choosing a set‟s maximum element minus the
cost of searching DEMO the maximum element.  If a new item is to be considered DEMO the expected
value of choosing from the expanded set (now n DEMO 1 products) minus the expected value of
choosing from n products DEMO exceed the cost of searching over n + 1 rather than n products.
Managers can increase the perceived value of the n + 1st DEMO with new product features or
advertising or decrease the search cost with communication, sampling, or promotion.  Of course,
competitors will, in DEMO, enhance their brands in the same way as they defend their DEMO
(Hauser and Shugan 1983).
Fortunately, consideration decisions can be measured directly.  Much as a researcher might
ask respondents to choose among profiles in a choice-based conjoint-analysis exercise, modified
formats enable researchers to ask respondents which profiles they would consider.  See Figure 1.
In this particular format a profile is highlighted in a center box as respondents run their DEMO
over a “bullpen” of profiles.  Respondents then indicate whether or not DEMO would consider the
profile.  Considered profiles are displayed on the right DEMO respondents can add or delete profiles
until they are satisfied with their consideration sets.  Such formats are easy to program and
respondents find them easy to use.
209
Figure 1
“Bullpen” Measures of Consideration
Such formats beg the question: does it help to measure and model consideration decisions?
For example, if the focus is on ultimate choice, why not simply model the decision to choose a
profile from the set of all profiles, rather than model the decision in two steps?  As illustrated in
Figure 2, we can write equivalently that Prob(choose a) = Prob(choose a from consideration set
C)*Prob(consider set C).  The motivation for modeling consideration lies in research that
indicates that consumers often use different (heuristic) decision rules for consideration than for
choice.  (In addition, DEMO argued above, managers can affect consideration directly.)
Figure 2
Conceptual DEMO of Choice within a Consideration Set*
210
*The red circle is the chosen profile, the shaded irregular region is the consideration set, and DEMO grey area is the full choice set.
DECISION-RULE HEURISTICS IN CONSIDERATION SET DECISIONS
Heuristics are common in consideration-set decisions. DEMO example, examine Figure 3. In
this figure respondents are asked to DEMO one GPS from among 32 candidate GPS profiles that
vary on 16 features.  Most respondents would be unlikely to examine all features of all GPSs and
form an additive-partworth compensatory evaluation.  Rather, a respondent might DEMO on a
relatively few features (color display, long battery life, DEMO) and eliminate those that do not have
the desired features (a “conjunctive” decision rule).  Or, the respondent might use another
simplifying DEMO  Research suggests that this task is not unlike tasks faced by DEMO
consumers in real market environments.
Figure 3
Choosing Among 32 GPS Profiles That Vary on 16 Features
We elaborate various heuristic rules in a DEMO section, but one aspect shared by all of these
rules is DEMO simplicity.  Cognitive simplicity is based on experimental evidence in a variety
DEMO contexts (as early as 1976 by Payne; reviews by Payne, DEMO and Johnson 1988, 1993).
Related evidence suggests that cognitively simple DEMO and frugal” decision rules are
prescriptively good ways to make decisions (DEMO et al. 2006; Dawkins 1998; Einhorn
and Hogarth 1981; Gigerenzer DEMO Goldstein 1996; Gigerenzer, Hoffrage and Kleinbolting 1991;
Gigerenzer and Todd 1999; Hogarth and Karelaia 2005; Hutchinson and Gigerenzer 2005;
Martignon DEMO Hoffrage 2002; Simon 1955; Shugan 1980).  Basically, with a reasonable
consideration set (say 5-6 automobiles), the best choice from the consideration set is close in
utility to the best choice from 350 DEMO, but the savings in evaluation costs are huge
(Internet search, DEMO visits, test drives, reading Consumer Reports, talking to friends, etc.).
Furthermore, cognitively simple decision rules are often robust with respect to errors in
evaluation.
Cognitively simple decision rules work well in typical “real DEMO choice environments
because in such environments features tend to be correlated.  DEMO with large engines
211
tend to have good leg room, good trunk room, seat five DEMO, and are often luxurious.
However, such automobiles also get lower gas mileage and are expensive.  Market offerings tend
to evolve jointly with consumer heuristics.  If heuristics worked well in past decisions,
consumers tend to continue to use the heuristics.  If consumers use heuristics, firms react DEMO
their product offerings which, in turn, further justify consumer heuristics.  DEMO might even
diffuse through word of mouth. While it is possible to show violations when heuristics lead to
absurd outcomes, such extreme situations are less common in everyday decisions.
In one illustration a recent MIT study DEMO respondents to sort the profiles into “definitely
would consider,” “definitely would not consider,” or “not sure.”  (More detail in Hauser, et al.
2009.)  Respondents first sorted quietly 50 profiles, then made verbal comments as they sorted
the remaining 50 profiles.  When they finished sorting, respondents re-examined the card stacks
and articulated decision rules.  All sorting DEMO videotaped with a camera on the cards and a
camera on the respondent.  Afterwards, independent judges evaluated the consumers‟ decision
rules (with high reliability using procedures recommended by Hughes and Garrett 1990;
Perreault and DEMO 1989).  The results were informative.  Most respondents (87%) took less
than 8 seconds per vehicle and most respondents (76%) used DEMO cognitively-simple decision rule.
HEURISTICS ARE MORE LIKELY IN SOME CONTEXTS THAN OTHERS
Heuristics are important, but not necessarily in every managerial context.  For DEMO
technical business-to-business products, such as a high speed printer, in which there are
relatively few alternatives, we might expect a buying center to evaluate all alternatives using a
full-information compensatory decision process.  On the other hand, in a category such as GPSs
in which there are many alternatives, many features, and much information available (on the
Internet) DEMO a variety of sources, we might expect consumers to use a DEMO
screening heuristic to balance search/evaluation cost with the value of a higher-value “best”
product.
Fortunately, the behavioral literature suggests characteristics of decision environments where
heuristics are more likely (Bettman, Luce and Payne 1998; Bettman and Park 1980b; Bettman
and Zins 1977; Chakravarti, Janiszewski  and DEMO 2009; Chernev 2005; Frederick 2002;
Kardes, et al. 2002; Levin and Jasper 1995; Lussier and Olshavsky 1997; Luce, Payne and
Bettman 1999; Payne, Bettman and Johnson 1988; 1993; Payne, Bettman and Luce 1996; Punj
and Brookes 2002; Ratneshwar, Pechmann and Shocker 1996; and Steckel, et al. 2005; among
others).  Heuristic DEMO rules are more likely when:
there are more products
there are more features to be evaluated
quantifiable features are more salient
there is DEMO time pressure
the consumer is in an early phase of his/her decision process (heuristics are dynamic; they
change as the consumer goes DEMO phases of his/her decision process)
the effort required to make a decision is more salient
the reference class is well-defined (e.g., DEMO products)
212
consumers are more familiar with the category (and have constructed well-defined
decision rules)
consumers have cognitive styles focused on task completion
Decision context DEMO decision rules.  Context affects both survey design and
projections to decision DEMO  For example, the following context effects influence the
use of and type of decision heuristics.
response mode – choice tasks (as in CBC), rating tasks (as in ACA), matching, or bidding
(for example, respondents are more lexicographic in choice than matching)
familiarity with the product category – preferences are more robust among experienced
consumers and, hence, less dependent on response mode
choice set composition – influences such as asymmetric dominance, compromise effects,
and other contexts encourage heuristic decision rules
negative correlation among features in the choice set – when environments DEMO more
regular (e.g., “efficient frontier), the cost of “mistakes” is less and heuristics perform
better (Johnson and Meyer 1984).  However, if the choice set is small, negative
correlation induces utility balance which makes the decision more difficult, thus
leading to more compensatory rules.
We illustrate these insights with two decision contexts: automobiles and web-based
purchasing. Automobiles have a large number of features and a large number of brands (and
variations within brands). The effort to search for the information DEMO extensive (e.g., dealership
experience, WOM, in addition to product features), and the decision is complex.  Most
automobile purchasing happens over a period of months, so there is an early phase in which
brands are eliminated.  This is particularly true because many alternatives (SUV, light truck, van,
sporty coupe, cross-over) are difficult to compare.  DEMO of these characteristics imply heuristic
processes are likely in the early phases of a consumer‟s automobile decision.
Many web-based buying situations include many alternatives.  For example, in March 2009
there were 181 flat-panel televisions available at bestbuy.com.   Figure 4 illustrates just a portion
of a page listing DEMO large number of mobile telephones available at various web sources. Both
mobile telephones and flat-panel televisions have many features and specifications.  Without
filtering, DEMO easily face information overload and an overwhelming choice decision.
Filtering based on price, screen size, brand, etc. makes heuristics even less cognitively taxing.
All of these characteristics lead to greater heuristic processing.  However, web-based DEMO also
reduces time pressure and search cost, mitigating some of the DEMO to favor heuristic
processing.
213
Figure 4
Illustrative Web Page for Mobile Telephones
Not all decisions encourage DEMO  The following decision characteristics make
heuristics less likely:
simple choice DEMO with few alternatives
few features or levels
really new products with really new features
low time pressure and search costs
final decisions after initial DEMO screening
DECISION-RULE HEURISTICS STUDIED IN THE LITERATURE
There is a rich set of heuristics identified and studied in the literature (e.g., Bettman and DEMO
1980a, 1980b; Chu and Spires 2003; Einhorn 1970, 1971; DEMO and McAlister 1990; Fishburn
1974; Frederick (2002), Ganzach and DEMO 1995; Gilbride and Allenby 2004, 2006; Hauser
1986; Hauser et al. 2009; Jedidi and Kohli 2005; Jedidi, Kohli and DeSarbo 1996; Johnson,
Meyer and Ghose 1989; Leven and Levine 1996; Lohse and Johnson 1996; Lussier and
Olshavsky 1986; Mela and Lehmann 1995; Moe 2006; Montgomery and Svenson 1976;
Nakamura 2002; Payne 1976; Payne, Bettman, and Johnson 1988; Punj 2001; Shao 2006;
DEMO
Svenson 1979; Swait 2001; Tversky 1969, 1972; Tversky and Sattath DEMO; Tversky and
Simonson 1993; Vroomen, Franses and van Nierop 2004; Wright and Barbour 1977; Wu and
Rangaswamy 2003; Yee et al. DEMO). We illustrate the most commonly-studied heuristics with
examples drawn from a hypothetical evaluation of automobiles. The heuristics are disjunctive,
conjunctive, subset conjunctive, lexicographic, elimination-by-aspects, and disjunctions of
conjunctions.
Disjunctive. In a disjunctive rule a profile is considered if one feature or set of features is
DEMO a threshold.  For example, a consumer might consider all hybrid sedans or all sporty
sedans.  Hybrids would be considered even if they were not sporty and sporty sedans would be
considered even if they were DEMO hybrids. In a disjunctive rule, the other features do not matter.
DEMO In a conjunctive rule a profile must have all of its features above minimum
levels.  Of course, some minimum levels can be such DEMO all profiles satisfy them, e.g., at least 5
miles per gallon.  For example, a consumer might set minimum levels for fuel economy, crash
test ratings, quality ratings. leg room, acceleration, ride & handling, safety, audio systems,
navigation systems, warranty, price, etc.  DEMO, minimum levels must be set for all
features, even if the minimum levels are so low that all profiles pass.
Subset conjunctive. In DEMO subset conjunctive rule a profile must have S features above a
threshold.  Subset conjunctive generalizes both disjunctive (S = 1) and conjunctive (DEMO = number
of features).  As defined and applied, any S of the features need to be above the threshold.  For
example, DEMO the consumer had already limited his/her search to profiles that vary only on fuel
economy, quality ratings, and ride & handling, then a subset conjunctive model (S = 2) would
imply that a DEMO is considered if either (fuel economy and quality) or (fuel DEMO and ride
& handling) or (quality and ride & handling) DEMO above minimum thresholds.
Disjunctions of conjunctions (DOC).  In a DOC rule a profile will be considered if one or
more conjunctions is DEMO  DOC thus generalizes disjunctive, conjunctive, and subset
conjunctive models.  For example, a consumer might consider a sedan if it is a hybrid that seats
five passengers or a sporty sedan that has great ride & handling.  The sporty sedan need not be a
hybrid and the DEMO need not have great ride & handling.  In the MIT/GM DEMO cited
respondents described DOC models when they articulated their decision processes.
Lexicographic.  In a lexicographic rule the consumer first ranks the features.  He/DEMO then
ranks the profiles using successively the first-ranked feature, breaking ties DEMO the second-
ranked feature, breaking ties further with the third-ranked features, etc. For example, a consumer
might rank all hybrids over other fuel classes.  Within hybrids, he/she might next rank vehicles
on crash DEMO ratings, then on quality ratings, then on ride & handling, DEMO  Lexicographic rules
are usually defined for choice providing a ranking (allowing ties) of all profiles in the choice set.
When applied to the consideration decision, we must also define a cutoff which can either be a
limit on the number of profiles or on the depth of DEMO of the features used in the rule.  With
the latter, if we only observe the consideration set and not the ranking within the DEMO
set, a lexicographic rule is indistinguishable from a conjunctive rule.
Elimination-by-Aspects (EBA). In a (deterministic) EBA rule the consumer successively
chooses DEMO (feature levels) and eliminates all profiles that have that aspect.  DEMO an
aspect is binary, a profile either has it or not, we can define aspects by their negation to produce
an equivalent rule DEMO acceptance-by-aspects (ABA).  For example, in EBA a consumer might DEMO
215
eliminate all conventional gasoline/diesel powered vehicles.  (Alternatively, accept all hybrids.)
The consumer might next eliminate all vehicles with crash test ratings DEMO 3 stars, etc.  Like
lexicographic rules, EBA provides a ranking (with potential ties) of all profiles and, like
lexicographic rules, EBA is indistinguishable from a conjunctive rule if we just observe the
consideration DEMO  EBA was originally defined by Tversky (1972) as a probabilistic DEMO in which
the consumer chooses aspects with probability proportional to their measures.  However, many
researchers have interpreted that probability as the analyst‟s uncertainty DEMO have assumed that
the consumer eliminates aspects in a fixed order (DEMO, Meyer and Ghose 1989; Montgomery
and Svenson 1976; Payne, Bettman and Johnson 1988; and Thorngate 1980).
Additive partworth rule (and DEMO rules). We normally think of an additive
partworth model as a compensatory model, that is, high levels on some features can compensate
DEMO low levels on other features.  However, if the partworths are extreme, an additive partworth
rule can act like a non-compensatory rule.  For DEMO, if there are F binary features and if
partworths are in DEMO ratios of 2F-1, 2F-2, …, 2, 1, then no DEMO of lower-ranked features
can compensate for a low level on a higher-ranked feature.  In this case, the additive partworth
model acts as if DEMO were lexicographic.  Other non-compensatory rules also have additive
representations (Jedidi and Kohli 2005; Kohli and Jedidi 2007; Meyer and Johnson 1995;
DEMO and Acito 1980).  Thus, an additive-partworth rule is, in DEMO, a mixed
compensatory/non-compensatory rule.  To address this issue some researchers define a q-
compensatory rule as an additive-partworth rule in which the DEMO of any two feature
importances (max – min partworths for a DEMO) is no more than q (Bröder 2000; Hogarth and
Karelaia DEMO; Martignon and Hoffrage 2002; Yee, et al. 2007).  With small q (typically q = 4),
q-compensatory rules and non-compensatory DEMO form disjoint sets.
RELEVANCE TO MANAGERS
Non-compensatory decision rules, whether applied DEMO choice or consideration, have received
considerable academic attention.  But do they have practical managerial relevance?  We know of
no general study to DEMO when they do and when they do not have managerial relevance.  DEMO
example, it is entirely possible that a heterogeneous mix of conjunctive DEMO rules could be
approximated well by an additive-partworth model (e.g., Abe 1999; Andrews, Ainslie and Currim
2008; Dawes 1979; Dawes and DEMO 1974; Meyer and Johnson 1995).  This is particularly
true because, as cited earlier, many non-compensatory rules can be represented by additive-
DEMO models.  While we await more systematic research, we provide two published
anecdotes from Hauser, et al. (2009).
Hauser, et al. studied consideration decisions for handheld GPSs.  There were two brands in
their study: Magellan and Garmin.  On average the Magellan brand had higher partworths, thus
in any additive-partworth market simulator a switch from Garmin to Magellan DEMO improve
market share.  However, when non-compensatory models were estimated, the DEMO found
that 12% of the respondents screened on brand and, of DEMO, 82% preferred Garmin.  For the
other 88% (100% – 12%), brand had no impact on consideration.  If this model was correct (and
it did predict a holdout task better), then a switch DEMO Garmin to Magellan would reduce market
share – exactly the opposite of that predicted by an additive-partworth model.
In the same study, “extra bright display” for a handheld GPS was the most important feature
based on DEMO partworths.  A market simulator predicted that adding an extra bright display
DEMO an addition $50 would increase share by 11%.  However, DOC rules suggested that those
216
respondents who screened for extra bright displays also tended to screen against DEMO price.  A
DOC-based simulator predicted only a 2% increase in share.
DEMO APPROACHES TO UNCOVER HEURISTICS
Researchers have addressed consideration sets and non-compensatory decision rules with a
myriad of approaches.  There are many potential taxonomies; DEMO feel the following taxonomy
captures the essence of the approaches:
consideration and decision rules revealed as latent constructs
consideration measured directly and decision DEMO revealed by the ability of the rules to
fit the survey measures
decision rules measured directly through self-explicated questions.
We discuss each in turn.
DEMO AND DECISION RULES AS LATENT CONSTRUCTS
In these approaches the researcher observes only choices and the feature-levels of the profiles
in the choice set.  The researcher postulates a two-stage consider-then-choose decision process
and postulates basic decision DEMO for each stage.  The parameters of the model, for example
minimum feature levels in the first stage and partworths in the second stage, are then inferred by
either Bayesian or maximum-likelihood methods.  We illustrate this approach with three
perspectives: Bayesian, choice-set explosion, and soft constraints.
Bayesian. Gilbride and Allenby (2004; 2006) use a Bayesian approach.  In DEMO 2004 paper
they establish either conjunctive, disjunctive, or linear screening rules for the consideration stage
and a compensatory (probit-like) decision rules for DEMO from the consideration set.
Consideration is not measured, but rather modeled DEMO data augmentation; both the first and
second stages of the decision DEMO are inferred simultaneously.  Because the first stage is
streamlined, their model scales well in a camera application with 6 profiles (plus a none option),
seven features, and a total of 23 levels.  They find that 92% of their respondents are likely to
have used a DEMO first-stage screening rule even though the number of alternatives
and features was relatively modest.
Choice-set Explosion. Andrews and Srinivasan (1995), Chiang, Chib DEMO Narasimhan
(1999), Erdem and Swait (2004), Swait and Ben-Akiva (1987) and others use choice-set
explosion and maximum-likelihood methods.  These researchers assume that the consideration
decision is made with a logit-like compensatory decision DEMO enabling the researcher to model
the probability of consideration for all 2n – 1 consideration sets, where n is the number of profiles
in the choice set.  They then assume a second-stage logit for choice from within the consideration
set.  They reduce the dimensionality with assumptions of independence, but the models still have
complexity that is exponential in n.  DEMO n gets too large the curse of dimensionality makes the
model too onerous to estimate.  For appropriate-sized problems the choice-set-explosion models
enable researchers to explore the drivers of consideration and enable researchers to relate these
drivers DEMO characteristics of the consumers and/or choice environment.
217
Soft constraints. Recognizing the curse of dimensionality, Swait (2001) proposes a two-
stage-like model with conjunctive and disjunctive cutoffs.  The key idea is that these constraints
come directly from respondents‟ self-statements and are treated as DEMO in the sense that they
influence cutoffs but are not necessarily binding.  Swait claims superior predictive ability relative
to choice-set explosion based on an “extremely powerful” increase in the log-likelihood values.
Swait also points out that DEMO model itself is estimated simultaneously and, thus, does not assume
an ordering of the two stages of cutoffs and additive partworths.
CONSIDERATION MEASURED, DECISION RULES INFERRED
Since the early 1970s researchers have measured consideration sets DEMO  Respondents
find the task intuitive and such measures significantly enhance new DEMO forecasts (Brown
and Wildt 1992; Hauser 1978; Silk and Urban DEMO; Urban and Katz 1983).  Figure 1 provides
one example.  DEMO a variety of web-based formats see also Ding, et al. (2009), Gaskin, et al.
(2007), Hauser, et al. (2009), and Yee, et al. (2007).  Direct measurement presents three
DEMO  First, if we believe the evaluation-cost theory of consideration sets, DEMO consumers
form consideration sets by making tradeoffs between the increased utility from larger sets and
the increased search cost for larger sets.  In vivo search cost is set by the marketplace
environment, but in vitro it is set by the measurement instrument.   For example, Hauser et al.
(2009) test four web-based formats that vary in vitro search cost.  They find that respondents
choose smaller consideration sets when respondents are asked DEMO indicate only considered
profiles versus when they are asked to indicate only rejected profiles.  The size of the
consideration set when respondents need evaluate all profiles is in-between.  Fortunately, the
choice rules do not seem DEMO vary that dramatically; the process of choice can still be measured
DEMO some fidelity.  The second challenge is that context matters (see references cited in a
previous section).  The size of the evaluation set, the number of features, how decisions are
framed, whether there is negative correlation among features, whether some profiles are
dominated asymmetrically, and DEMO context effects can all influence decision rules, rules that
might be DEMO on the fly.  The third challenge is when incentive alignment is DEMO with
consideration-set measurement.  Consideration is an intermediate construct, not the final choice.
Incentives must be sufficiently vague, yet effective, so that the DEMO believes that he/she
should specify a consideration set that applies in vivo.  See examples in Ding et al. (2009) and
Kugelberg (DEMO).  The important caveat for all three challenges is that researchers DEMO pay
attention to context and work to ensure that the in vitro measurements approximate in vivo
projections.
Once consideration is measured in vitro, there are a variety of methods to estimate the
decision rules that best DEMO the consideration decisions observed on calibration tasks.  There
are two basic DEMO strategies: Bayesian with simpler structure and machine-learning
pattern-matching algorithms.  For example, the Gilbride-Allenby (2004) approach is easily
modified for explicitly measure consideration.  Bayesian methods can easily be written for subset
conjunctive, q-compensatory (rejection sampling), and, of course, additive partworth models.
Machine-learning algorithms use DEMO math programming or logical analysis of data (LAD,
Boros, et al. 1997; 2000).
There are at least two issues to be addressed when using revealed estimation for
consideration-set rules.  First is the curse of dimensionality.  Non-compensatory models can
easily over fit data.  For example, there are 323 = 94,143,178,827 potential DOC rules with DEMO
218
binary features.  With such large numbers it is not feasible to have prior or posterior probabilities
for each decision rule.  Rather, researchers must DEMO the model as in Gilbride or Allenby
(2004) or impose constraints that the decision rules are cognitively simple as in Hauser et al.
(2009).  The second issue is the robustness of the additive-partworth model.  An additive-
partworth model is likely to fit the data well, DEMO if the process is non-compensatory.  To
address this issue, researchers often estimate a q-compensatory model and compare it to a non-
compensatory model.  This two-step evaluation provides insight because the additive-partworth
model can nest both.
DEMO are aware of only one comprehensive comparison of the predictive ability of revealed-
decision-rule estimation on directly-measured consideration.  Hauser, et al. (2009) DEMO five
Bayesian models (conjunctive, disjunctive, subset conjunctive, q-compensatory, additive
DEMO) and seven pattern-recognition models (conjunctive, disjunctive, subset conjunctive, q-
DEMO, additive-partworth, DOC math program, DOC LAD) on the same data.  The
models were estimated when respondents were asked to evaluate an orthogonal design of 32
GPSs.  Predictions were evaluated on a different set of 32 GPSs (after a memory-cleansing task).
They found that:
the relative predictive ability of Bayesian vs. pattern-recognition methods depended upon
the posited DEMO model
DOC models improved prediction significantly relative to conjunctive, disjunctive, or
subset conjunctive for both Bayesian and pattern-recognition methods
there was no significant DEMO between the math programming and LAD DOC
models
non-compensatory models did better than q-compensatory models, but
additive partworth models did almost as well as DOC models.
Their study is limited to a single category in an DEMO chosen to favor non-
compensatory models.  Abundant research opportunities will increase DEMO knowledge with
further testing.
DECISION RULES MEASURED DIRECTLY THROUGH SELF-EXPLICATED QUESTIONS
Directly-elicited non-compensatory measures have been used almost since the beginning of
conjoint analysis. DEMO, Adaptive Conjoint Analysis (ACA), and other methods all include
options to ask respondents to indicate unacceptable levels or products (Green, Krieger DEMO Banal
1988; Malhotra 1986; Klein 1986; Srinivasan 1988; Srinivasan and Wyner 1988; Sawtooth
1996).  However, these modules have met with mixed success; respondents happily choose
profiles with unacceptable levels.  More recently, researchers have experimented with improved
formats.  Swait (2001) uses self-explicated cutoffs as soft constraints.  Adaptive Choice-Based
Conjoint Analysis (ACBC) uses a multi-step procedure in which (1) respondents are asked to
indicate a profile DEMO they would consider, (2) a pool of profiles is created DEMO perturbations on
that profile, (3) respondents are shown screens of DEMO profiles and asked for consideration, and
(4) if a feature-level DEMO always rejected or accepted a pop-up “avatar” (a graphic of an DEMO
interviewer can be included, though is not required) confirms the non-compensatory decision
rule (Sawtooth Software 2008).  Ding, et al. (2009) ask respondents to write an unstructured e-
219
mail to a friend who will act as their agent and purchase DEMO product for them.  Figure 5 provides
an example e-mail from a DEMO Kong respondent who was evaluating mobile telephones.
Figure 5
Example “E-Mail” Direct Elicitation
Dear friend, I want to buy a mobile phone recently and I hope u can provide
some advice to me. The following are DEMO requirement of my preferences.
Firstly, my budget is about $2000, the price should not more than it. The
brand of mobile phone is DEMO Nokia, Sony-Ericsson, Motorola, because I
don't like much about DEMO I don't like any mobile phone in pink color.
Also, DEMO mobile phone should be large in screen size, but the thickness DEMO
not very important for me. Also, the camera resolution is not DEMO too,
because i don't always take photo, but it DEMO be at least 1.0Mp.
Furthermore, I prefer slide and rotational phone DEMO It is hoped that you
can help me to choose a mobile phone suitable for me.
Directly-elicited decision-rule measures have become more accurate for DEMO number of
important reasons.  Formats can now be incentive-aligned, that is, the respondent believes that
he/she will receive a prize (in DEMO lottery) and that the prize depends upon his/her answers to DEMO
questions (Ding 2007; Ding, Grewal and Liechty 2005; Park, DEMO and Rao 2008).  With
incentive-aligned methods, truthful questions are dominant. If the incentives are sufficient, then
the respondent is also encouraged to think hard about the answers.  “Natural tasks” further
enhance accuracy.  In DEMO respondents evaluate profiles and then respond to an avatar.  In
Ding DEMO al. respondents write e-mails that are similar to those that they would write to friends.
Researchers are beginning to appreciate the value of “build DEMO own (BYO)” profiles as in the
first phase of ACBC.  Typically, consumers consider but a small fraction of the available
products, DEMO one gains significantly more information from knowing a profile is considered
than from knowing a profile is not considered (Silinskaia and Hauser 2009).  Finally, the wide
use of voice-of-the-customer methods has led to a DEMO workforce that is adept at
quantifiable coding of qualitative data (Griffin DEMO Hauser 1993; Hughes and Garrett 1990;
Perreault and Leigh 1989)DEMO
Ding et al. (2009) compare directly-elicited decision rules to decision rules inferred from the
analysis of directly-measured consideration (decomposition).  The decompositional DEMO
are a q-compensatory logit model, an additive-partworth logit model, a lexicographic model
estimated with Yee, et al.‟s (2007) Greedoid dynamic program, DEMO LAD.  Respondents were
asked to either evaluate profiles or state decision DEMO (calibration data).  Predictions were based
220
on data collected three weeks later when respondents evaluated 32 profiles.  The researchers
found:
direct elicitation predicts as well as decomposition (no significant difference)
non-compensatory rules predict better than q-compensatory rules,
additive partworths DEMO as well as pure non-compensatory rules
While there is no improvement in predictive ability relative to decomposition, the directly-
elicited rules have the advantage that they are less subject to the curse of dimensionality.  They
scale well to large problems.  For example, Ding, et al. demonstrate that respondents can answer
easily questions about a very complex category that would DEMO required over 13 thousand
profiles in an orthogonal design.
TAKE HOME LESSONS
No review of the literature is perfect and ours is not without DEMO caveats.  It is very difficult to
compare across sub-literatures and it DEMO not yet feasible to do a meta-analysis because the criteria
with which researchers evaluate models varies widely.  Among the measures we found were hit
rates, log likelihood measures, Kullback-Leibler divergence, t-tests, 
(percent of information explained).  Some papers correct for the number of profiles (DEMO
choice from among 2 profiles is easier than from among 32 profiles), others do not and do not
report the number of profiles.  In consideration decisions null models are particularly strong.  For
example, if DEMO 20% of the profiles are considered, then a null model which DEMO that
nothing is considered will predict all not-considered profiles correct – an 80% hit rate.  Even a
random model will predict 68% of the profiles correctly (0.82 + 0.22).  In the papers we reviewed
DEMO varied considerably and the null models were not equally challenging.  Predictive
DEMO alone should not be used to distinguish models.  Detailed information on DEMO
choice/consideration context was often omitted even though research suggests that context can
have a considerable influence.
Nonetheless, we were able to identify empirical generalizations that appear to hold.  These
include:
non-compensatory decision rules for consideration decisions are common in many
categories (see Table 1 for some examples).
non-compensatory decision rules often predict better than purely compensatory rules
(e.g., q-compensatory rules), but
the unconstrained additive-partworth model is robust and hard to beat on predictive
measures.
complex situations favor non-compensatory decision rules, but
non-compensatory rules often predict well in even simple situations.
there are DEMO ways to measure and/or estimate non-compensatory decision rules but, to
DEMO, no single approach appears to dominate.
221
2 (pseudo-R2), and U2
there are excellent (and intuitive) anecdotes that managers should pay attention DEMO non-
compensatory decision rules but, to date, there is no comprehensive theory as to
when.
SUMMARY
Non-compensatory decision rules for consideration decisions are DEMO in relevance.
Figure 6 provides the date of publication of the 132 articles we reviewed.  This is not a random
sample, but it DEMO suggest a growing interest.  Non-compensatory decision rules for
consideration have a DEMO history in marketing, but powerful computers, efficient algorithms, and
new DEMO is providing exciting new measurement and estimation methods.  This research is
DEMO to have increasing impact as researchers push further the limits of scalability, develop
easy-to-use software, and explore synergies with behavioral experiments.
And there DEMO many research opportunities.  We need a theory (or generalization) of DEMO
and how models of non-compensatory decision rules for consideration influence managerial
theories.  We do not yet have practical models of the effect of such decision rules on market-
structure equilibria.  And we need many more predictive tests of current (and yet-to-be-
developed) models.  The future is indeed exciting and, we hope, fun.
Table 1
Example Predictive Ability of DEMO Models
PRODUCT CATEGORY Percent non-compensatory Fit Equal/ Better
Air conditioners (Shao 2006, protocol) 89% screen, 67% two-stage
Automobiles (Hauser, et al. 2009, process tracing) 76% cognitively simple
Automobiles (Levin, Jasper 1995, process tracing) 86% non-compensatory
Batteries (Jedidi, Kohli 2005, subset conjunctive) equal (a)*
Cameras (Gilbride, Allenby 2004, conj., better
disjunctive) 92% non-compensatory
Cell phones (Ding, et al., 2009 better (q), equal (a)
conj./compensatory) 78% mixed
Computers (Kohli, DEMO, 2007, lexicographic) 2/3rds lexicographic
Computers (Jedidi, Kohli 2005, subset conjunctive)
Computers (Yee, et al. 2007, lexicographic) 58% DEMO (17% tied)
Documentaries (Gilbride, Allenby 2006, screening)
GPSs (Hauser, et al. 2009, disjunctions of conj.)
MBA admissions (DEMO, et al. 2004, GNH)
Rental cars (Swait 2001, soft cutoffs)
Smartphones (Yee, et al. 2007, lexicographic) 56% lexicographic
DEMO product (Fader, McAlister 1990, EBA)
equal (a)
“virtually identical”
better (q), equal (a)
better in-sample fit
better
DEMO model
selection
better in-sample fit
better (q), equal (a)
equal to logit
* a = relative to an additive-partworth model, q = relative to a q-compensatory model, conj. = conjunctive
222
30
25
20
Figure 6
Dates of Non-Compensatory Articles
(Projected through the end of 2010)
15
10
5
1970 1975 1980 1985 1990 DEMO 2000 2005 2010
5-year Period
REFERENCES
Abe, Makoto (1999), “ A Generalized Additive Model for Discrete-Choice Data, ”
Journal of Business & Economic Statistics, 17 (Summer), 271-84.
Andrews, Rick L., Andrew DEMO and Imran S. Currim (2008), "On the Recoverability of
Choice Behaviors with Random Coefficients Choice Models in the Context of Limited
Data DEMO Unobserved Effects," Management Science, 54 (January), 83-99.
------ and Ajay K. Manrai (1998) , “Simulation Experiments in Choice Simplification: The
Effects of Task and Context on Forecasting Performance, ” Journal of Marketing Research,
35 (May), 198-209.
------ and T. C. Srinivasan (DEMO), “Studying Consideration Effects in Empirical Choice
Models Using Scanner Panel Data, ” Journal of Marketing Research, 32 (February), 30-41.
Bettman, DEMO R., Mary Frances Luce, and John W. Payne (1998), DEMO Consumer
Choice Processes, ” Journal of Consumer Research, 25, 3 (December), 187-217.
------ and L. W. Park (1980a), “Effects of Prior Knowledge and Experience and Phase of the
Choice Process on Consumer DEMO Processes: A Protocol Analysis, ” Journal of
Consumer Research, 7 (December), 234-248.
------ and ------ (1980b), “ Implications of a Constructive View of Choice for Analysis of
Protocol Data: A Coding Scheme for Elements of Choice Processes, ” (Journal Unknown),
148-153.
------ and Michel A. Zins (1977), “Constructive Processes in Consumer Choice, DEMO Journal of
Consumer Research, 4 (September), 75-85.
223
0
Number of articles in period
Boros, Endre, Peter L. Hammer, Toshihide Ibaraki, and Alexander Kogan (1997), “Logical
Analysis of Numerical Data, ” Mathematical Programming, 79:DEMO, August 1997
------, ------, ------, ------, Eddy Mayoraz, and Ilya Muchnik (2000), “An Implementation of
Logical Analysis of Data, DEMO IEEE Transactions on Knowledge and Data Engineering, 12(2),
292-306.
Brandstaetter, Eduard, Gerd Gigerenzer and Ralph Hertwig (2006), “The Priority Heuristic:
Making Choices Without Trade-Offs, ” Psychological Review, 113, 409-32.
Bröder, Arndt (2000), “ Assessing the Empirical Validity of the DEMO the Best‟ Heuristic as a
Model of Human Probabilistic Inference, ” DEMO of Experimental Psychology: Learning,
Memory, and Cognition, 26, 5, 1332-1346.
Bronnenberg, Bart J., and Wilfried R. Vanhonacker (1996), DEMO Choice Sets, Local
Price Response, and Implied Measures of Price Competition, ” Journal of Marketing
Research, 33 (May), 163-173.
Brown, DEMO J. and Albert R. Wildt (1992), “ Consideration Set Measurement, ” Journal of
the Academy of Marketing Science, 20 (3), DEMO
Chakravarti, Amitav and Chris Janiszewski, (2003), “ The Influence DEMO Macro-Level Motives
on Consideration Set Composition in Novel Purchase Situations, ” DEMO of Consumer
Research, 30 (September), 244-58.
------, ------ and DEMO Ülkumen (2009), “The Neglect of Prescreening Information, ” Journal
of Marketing Research (forthcoming).
Chase, Valerie M., Ralph Hertwig, and DEMO Gigerenzer (1998), “Visions of Rationality, ”
Trends in Cognitive Sciences, 2, 6 (June), 206-214.
Chernev, Alexander (2005), “Feature Complementarity and Assortment in Choice, ” Journal
of Consumer Research, 31 (March), 748-59.
Chiang, Jeongwen, Siddhartha Chib, and Chakravarthi Narasimhan (DEMO), “Markov Chain
Monte Carlo and Models of Consideration Set and Parameter Heterogeneity, ” Journal of
Econometrics, 89, 223-48.
Chu, P.C. and DEMO E. Spires (2003), “Perceptions of Accuracy and Effort of Decision
DEMO, ” Organizational Behavior and Human Decision Processes, 91, 203-14.
Dawes, R. M. (1979), “ The Robust Beauty of Improper Linear Models in Decision Making, ”
American Psychologist, 34, 571-582.
------ and B. Corrigan (1974), “Linear Models in Decision Making, ” Psychological Bulletin,DEMO
81, 95-106.
Desai, Kalpesh K. and Wayne D. Hoyer (2000), “Descriptive Characteristics of Memory-
Based Consideration Sets: Influence of Usage Occasion DEMO and Usage Location
Familiarity, ” Journal of Consumer Research, 27 (DEMO), 309-323.
Desarbo, Wayne S. and Kamel Jedidi (1995), “The Spatial Representation of Heterogeneous
Consideration Sets, ” Marketing Science, 14, 326-342.
224
------, Donald R. Lehmann, Greg Carpenter, and I. Sinha (1996), “A Stochastic
Multidimensional Unfolding Approach for Representing Phased Decision Outcomes, ”
DEMO, 61 (September), 485-508.
Dawkins, Richard (1998), Unweaving the Rainbow: Science, Delusion, and the Appetite for
Wonder, (Boston, DEMO: Houghton Mifflin Company).
Ding, Min (2007), “An Incentive-Aligned DEMO for Conjoint Analysis, ” Journal of
Marketing Research, 54, (May), 214-223.
-----, Rajdeep Grewal, and John Liechty (2005), “ Incentive-Aligned Conjoint Analysis, ”
Journal of Marketing Research, 42, (February), 67–82.
------, John R. Hauser, Songting Dong, Daria Silinskaia, Zhilin Yang, Chenting Su, and
Steven Gaskin (2009), “ Incentive-Aligned Direct Elicitation of Decision Rules: An
Empirical Test, ” Working Paper.
Einhorn, Hillel J. (1970), “The Use of Nonlinear, Noncompensatory Models in DEMO
Making, ” Psychological Bulletin, 73, 3, 221-230.
------ (1971), “Use of Non-linear, Non-compensatory Models as a Function of Task and
DEMO of Information,”  Organizational Behavior and Human Performance, 6, 1-27.
DEMO, Hillel J. , and Robin M. Hogarth (1981), “Behavioral Decision Theory: Processes of
Judgment and Choice, ” Annual Review of Psychology, 32, 52-88.
Elrod, Terry, Richard D. Johnson, and Joan White (2004), “A New Integrated Model Of
Noncompensatory And Compensatory Decision Strategies, ” Organizational Behavior and
Human Decision Processes, 95, 1–19.
Erdem, Tülin and Joffre Swait (2004), “Brand Credibility, Brand Consideration, and Choice, ”
Journal of Consumer Research, 31 (June), 191-98.
Fader, DEMO S. and Leigh McAlister (1990), “An Elimination by Aspects Model DEMO Consumer
Response to Promotion Calibrated on UPC Scanner Data, ” Journal DEMO Marketing Research,
27 (August), 322-32.
Fishburn, Peter C. (DEMO), “Lexicographic Orders, Utilities and Decision Rules: A Survey, ”
DEMO Science, 20, 11 (Theory, July), 1442-1471.
Frederick, Shane (2002), “Automated Choice Heuristics, ” in Thomas Gilovich, Dale Griffin,DEMO
and Daniel Kahneman, eds., Heuristics and Biases: The Psychology of DEMO Judgment,
(Cambridge, UK: Cambridge University Press, chapter 30, DEMO
Ganzach, Yoav and Benjamin Czaczkes (1995), “ On Detecting Nonlinear Noncompensatory
Judgment Strategies: Comparison of Alternative Regression Models, ” Organizational
Behavior DEMO Human Decision Processes, 61 (February), 168-76.
Gaskin, Steven, Theodoros Evgeniou, Daniel Bailiff, John Hauser (2007), “Two-Stage
Models: Identifying DEMO Heuristics for the Consideration Set then Adaptive
Polyhedral Methods Within the Consideration Set, ” Proceedings of the Sawtooth Software
Conference in Santa Rosa, DEMO, October 17-19, 2007.
225
Gensch, Dennis H. (1987), “A Two-stage Disaggregate Attribute Choice Model, ” Marketing
Science, 6 (Summer), 223-231.
------ and Ehsan S. DEMO (1995a), “Information-Theoretic Estimation of Individual
Consideration Sets, ” International Journal of Research in Marketing, 12 (May), 25-38.
------ and ------ (1995b), “ An Information-Theoretic Two-Stage, Two-Decision Rule, Choice
Model, ” European Journal of Operational Research, 81, 271-80.
Gigerenzer, Gerd and Daniel G. Goldstein (1996), “Reasoning the Fast and Frugal Way:
Models of Bounded Rationality, ” Psychological Review, 103, 4, 650-669.
------, Ulrich Hoffrage, and H. Kleinbölting (1991), “Probabilistic Mental Models: A
Brunswikian Theory of Confidence, ” Psychological Review, 98, 506-528.
------, DEMO M. Todd, and the ABC Research Group (1999), Simple Heuristics That Make Us
Smart, (Oxford, UK: Oxford University Press).
DEMO, Timothy and Greg M. Allenby (2004), “ A Choice Model with Conjunctive,
Disjunctive, and Compensatory Screening Rules,”  Marketing Science, 23, 3 (Summer),
391-406.
------ and ------ (2006), DEMO Estimating Heterogeneous EBA and Economic Screening Rule Choice
Models, ” Marketing DEMO, 25 (September-October), 494-509.
Green, Paul E., Abba M. Krieger, and Pradeep Bansal (1988), “Completely Unacceptable
Levels in Conjoint Analysis: A Cautionary Note, ” Journal of Marketing Research, 25
(August), 293-300.
Griffin, Abbie and John R. Hauser (1993), "The Voice of the Customer," Marketing Science,
12, 1, (Winter), 1-27.
Haübl, Gerald and Valerie Trifts (2000), “Consumer Decision Making DEMO Online Shopping
Environments: The Effects of Interactive Decision Aids, ” Marketing Science, 19 (Winter),
4-21.
Hauser, John R. (1978), "Testing the Accuracy, Usefulness and Significance of Probabilistic
Models: An Information  Theoretic Approach,"  Operations Research, Vol. 26, 3 (May-
June), 406-421.
------ (1986), "Agendas and Consumer Choice," Journal DEMO Marketing Research, 23 (August),
199-212.
------ and Steven M. DEMO (1983), "Defensive Marketing Strategy," Marketing Science, 2, 4,
(Fall), 319-360.
------, Olivier Toubia, Theodoros Evgeniou, Rene DEMO and Daria Silinskaia (2009),
“ Cognitive Simplicity and Consideration Sets, ” forthcoming, Journal of Marketing
Research.
------ and Birger Wernerfelt (1990), “An Evaluation Cost Model of Consideration Sets, ”
Journal of  DEMO Research,  16 (March), 393-408.
226
Hogarth, Robin M. and Natalia Karelaia (2005), “ Simple Models DEMO Multiattribute Choice
with Many Alternatives: When It Does and Does Not DEMO to Face Trade-offs with Binary
Attributes, ” Management Science, 51, DEMO, (December), 1860-1872.
Hughes, Marie Adele and Dennis E. Garrett (1990), “Intercoder Reliability Estimation
Approaches in Marketing: A Generalizability Theory Framework for Quantitative Data, ”
Journal of Marketing Research, 27, (May), 185-195.
Hutchinson, John M. C. and Gerd Gigerenzer (2005), “Simple Heuristics and Rules of
Thumb: Where Psychologists and Behavioural Biologists Might Meet, ” Behavioural
Processes, 69, 97-124.
Jedidi, Kamel, Rajiv Kohli, DEMO Wayne S. DeSarbo (1996), “Consideration Sets in Conjoint
Analysis, ” Journal of Marketing Research, 33 (August), 364-372.
------ and ------ (2005), “ Probabilistic Subset-Conjunctive Models for Heterogeneous
Consumers, ” Journal of Marketing Research, 42 (November), 483-494.
Johnson, Eric J. and Robert J. Meyer (1984), “ Compensatory Choice Models of
Noncompensatory Processes: DEMO Effect of Varying Context, ” Journal of Consumer
Research, 11 (DEMO), 528-541.
------, ------, and Sanjoy Ghose (1989), “When DEMO Models Fail: Compensatory Models in
Negatively Correlated Environments, ” Journal of Marketing Research, 26 (August), 255-
290.
------ and John W. DEMO (1985), “Effort and Accuracy in Choice, ” Management Science, DEMO,
395-414.
Kahneman, Daniel and Amos Tversky (1996), “ On the Reality of Cognitive Illusions, ”
Psychological Review, 103, 3, DEMO
Kamis, Arnold (2006), “ Search Strategies in Shopping Engines An Experimental
Investigation, ” International Journal of Electronic Commerce, 11 (Fall), 63-84.
Kardes, Frank, Gurumurthy Kalyanaram, Murali Chandrashekaran, and Ronald J. DEMO
(1993), “Brand Retrieval, Consideration Set Composition, Consumer Choice, and the
Pioneering Advantage, ” Journal of Consumer Research, 20 (June), 528-541.
------, David M. Sanbonmatsu, Maria L. Cronley, and David C. Houghton (2002),
“ Consideration Set Overvaluation: When Impossibly Favorable Ratings of a Set of Brands
Are Observed, ” Journal of Consumer Psychology, 12, 4, 353-61.
Klein, Noreen M. (1988), “Assessing Unacceptable Attribute Levels in Conjoint Analysis, ”
Advances in Consumer Research vol. XIV, pp. 154-158.
Kohli, Rajiv and Kamel Jedidi (2007), “Representation and Inference of Lexicographic
Preference Models and Their Variants, ” Marketing Science, DEMO (May-June), 380-99.
Kugelberg, Ellen (2004), “Information Scoring and DEMO Analysis, ” Department of
Industrial Economics and Management, Royal Institute of Technology, Stockholm, Sweden.
227
Lapersonne, Eric, Giles Laurent and Jean-Jacques Le Goff (1995), “Consideration Sets Of
Size One: An Empirical Investigation Of Automobile Purchases, ” DEMO Journal of
Research in Marketing, 12, 55-66.
Leven, Samuel J. DEMO Daniel S. Levine (1996), “ Multiattribute Decision Making in Context:DEMO
A Dynamic Neural Network Methodology, ” Cognitive Science, 20, 271-299.
DEMO, Irwin P. and J. D. Jasper (1995), “Phased Narrowing: DEMO New Process Tracing Method
for Decision Making, ” Organizational Behavior and DEMO Decision Processes, 64
(October), 1-8.
Lohse, Gerald J. and DEMO J. Johnson (1996), “A Comparison of Two Process Tracing
Methods DEMO Choice Tasks, ” Organizational Behavior and Human Decision Processes, 68
(DEMO), 28-43.
Luce, Mary Frances, John W. Payne, and James DEMO Bettman (1999), “Emotional Trade-off
Difficulty and Choice, ” Journal of Marketing Research, 36, 143-159.
Lussier, Denis A. and Richard W. Olshavsky (1997), “Task Complexity and Contingent
Processing in Brand Choice, ” DEMO of Consumer Research, 6 (September), 154-65.
Malhotra, Naresh (1986), “An Approach to the Measurement of Consumer Preferences Using
Limited Information, ” Journal of Marketing Research, 23 (February), 33-40.
Martignon, Laura and Ulrich Hoffrage (2002), “ Fast, Frugal, and Fit: DEMO Heuristics for
Paired Comparisons, ” Theory and Decision, 52, 29-71.
DEMO and Michael Schmitt (1999), “Simplicity and Robustness of Fast and DEMO Heuristics, ”
Minds and Machines, 9, 565-93.
Mehta, Nitin, DEMO Rajiv, and Kannan Srinivasan (2003), “Price Uncertainty and
Consumer Search: A Structural Model of Consideration Set Formation, ” Marketing
Science, 22(1), 58-84.
Mela, Carl F. and Donald R. Lehmann (1995), “ Using Fuzzy Set Theoretic Techniques to
Identify Preference Rules From Interactions in the Linear Model: An Empirical Study, ”
Fuzzy Sets and DEMO, 71, 165-181.
Meyer, Robert and Eric J. Johnson (1995), “Empirical Generalizations in the Modeling of
Consumer Choice, ” Marketing Science, DEMO, 3, Part 2 of 2, G180-G189.
Moe, Wendy W. (DEMO), “An Empirical Two-Stage Choice Model with Varying Decision
Rules Applied to Internet Clickstream Data, ” Journal of Marketing Research, 43
(November), 680-692.
Montgomery, H. and O. Svenson (1976), “On Decision Rules DEMO Information Processing
Strategies for Choices among Multiattribute Alternatives, ” Scandinavian Journal DEMO
Psychology, 17, 283-291.
Murray, Kyle B. and Gerald Häubl (2006), “Explaining Cognitive Lock-In: The Role of Skill-
Based Habits of Use in Consumer Choice, ” manuscript, (January 23).
Nakamura, Yutaka (2002), “Lexicographic Quasilinear Utility, ” Journal of Mathematical
Economics, 37, 157-178.
228
Nedungadi, Prakash (1990), “Recall and Consideration Sets: Influencing Choice without
Altering Brand Evaluations, ” Journal of Consumer Research, 17 (December), 263-276.
Newell, Ben R., Nicola J. Weston, and David R. Shanks (2002), “Empirical Tests Of A Fast-
And-Frugal Heuristic: Not Everyone DEMO,‟” Organizational Behavior and
Human Decision Processes, 91, 82-96.
------ and David R. Shanks (2003), “Take the Best or Look at the Rest? Factors Influencing
„One-Reason‟ Decision Making, ” Journal of Experimental Psychology: Learning, Memory
and Cognition, 29, 1, 53-65.
Newman, Joseph W. and Richard Staelin (1972), “Prepurchase Information Seeking for New
Cars and Major Household Appliances, ” Journal of Marketing Research, 9 (August), 249-
57.
Olshavsky, Richard W. and Franklin Acito (1980), “An DEMO Processing Probe into
Conjoint Analysis, ” Decision Sciences, 11, (July), 451-470.
Oppewal, Harmen, Jordan J. Louviere, and Harry J. P. Timmermans (1994), “Modeling
Hierarchical Conjoint Processes with Integrated Choice Experiments, DEMO Journal of
Marketing Research, 31 (February), 92-105.
Park, Young-Hoon, Min Ding and Vithala R. Rao (2008), “Eliciting Preference for Complex
Products: A Web-Based Upgrading Method, ” Journal of Marketing Research, 45
(October), 562-574.
Paulssen, Marcel and Richard P. Bagozzi (2005), “A Self-Regulatory Model of Consideration
Set Formation, ” Psychology & Marketing, DEMO (October), 785-812.
Payne, John W. (1976), “ Task DEMO and Contingent Processing in Decision Making:
An Information Search,”  DEMO Behavior and Human Performance, 16, 366-387.
------, James R. Bettman, and Eric J. Johnson (1988), “Adaptive Strategy Selection in
Decision Making, ” Journal of Experimental Psychology: Learning, Memory, and
Cognition, 14, 534-552.
------, ------, and ------ (1993), The Adaptive Decision DEMO, (Cambridge, UK: Cambridge
University Press).
------, ------, and Mary Frances Luce (1996), “When Time is Money: Decision Behavior
DEMO Opportunity-Cost Time Pressure, ” Organizational Behavior and Human Decision
Processes, 66 (May), 131-152.
Perreault, William D., Jr. and Laurence E. Leigh (1989), “Reliability of Nominal Data Based
on Qualitative Judgments, ” DEMO of Marketing Research, 26, (May), 135-148.
Posavac, Steven S., David M. Sanbonmatsu, Maria L. Cronley, and Frank R. Kardes (DEMO),
“ The Effects of Strengthening Category-Brand Associations on Consideration Set
DEMO and Purchase Intent in Memory-Based Choice, ” Advances in Consumer
Research, 28, 186-189.
Punj, Brookes (2001), “ Decision Constraints and Consideration-Set Formation in Consumer
Durables, ” Psychology & Marketing, 18 (August), 843-863.
229
Punj, Girish and Richard Brookes (2002), “The Influence Of Pre-Decisional DEMO On
Information Search And Consideration Set Formation In New Automobile Purchases, DEMO
Internal Journal of Research in Marketing, 19, 383-400.
------ and Staelin, Richard (1983),  “A Model of Consumer Information Search Behavior for
New Automobiles, ” Journal of Consumer Research, 9, 366-380.
Ratneshwar, DEMO, Cornelia Pechmann and Allan D. Shocker (1996), “Goal-Derived Categories
and the Antecedents of Across-Category Consideration, ” Journal of Consumer Research,
23 (December), 240-250.
Roberts, John H. and James M. Lattin (1991), “ Development and Testing of a Model of
Consideration Set Composition, ” Journal of Marketing Research, 28 (November), 429-440.
------ and DEMO (1997), “ Consideration: Review of Research and Prospects for Future Insights,”
Journal of Marketing Research, 34 (August), 406-410.
Sawtooth DEMO, Inc. (1996), “ACA System: Adaptive Conjoint Analysis, ” ACA Manual,
(Sequim, WA: Sawtooth Software, Inc.)
------ (2008), “ACBC Technical Paper, ” (Sequim WA; Sawtooth Software, Inc.)DEMO
Schmitt, Michael and Laura Martignon (2006), “ On the Complexity of Learning
Lexicographic Strategies, ” Journal of Machine Learning Research, 7, 55-83.
Shao, Wei (2006), “Consumer Decision-Making: An Empirical Exploration of Multi-Phased
Decision Processes, ” doctoral dissertation, Department of Philosophy, Griffith University.
Shocker, Allen D. , Moshe Ben-Akiva, B. Boccara, and P. Nedungadi (1991), “Consideration
Set Influences on Customer Decision-Making and Choice: Issues, Models and Suggestions,”
Marketing Letters, 2, 181-198.
Shugan, Steven M. (1980), “The Cost of Thinking, ” Journal of Consumer Research, 7, 2
(September), 99-111.
Siddarth, S., Randolph E. Bucklin, and Donald G. Morrison (1995), “ Making the Cut:
Modeling and Analyzing Choice Set Restriction in Scanner Panel Data, ” Journal of
Marketing Research, 33 (August), 255-266.
Silinskaia, Daria, John R. DEMO, and Glen L. Urban (2009), “Adaptive Profile Evaluation to
Identify Heuristic Decision Rules in „Large‟ and Challenging Experimental Designs, ”
NFORMS Marketing Science Conference, Ann Arbor, MI, June 2009.
Silk, Alvin J. DEMO Glen L. Urban (1978), “Pre-test Market Evaluation of New Packaged
DEMO: A Model and Measurement Methodology, ” Journal of Marketing Research, DEMO
(May), 171-191.
Simon, Herbert A. (1955), “A Behavioral DEMO of Rational Choice, ” The Quarterly Journal
of Economics, 69(1). 99-118.
Srinivasan, V. (1988), “ A Conjunctive-Compensatory Approach to DEMO Self-Explication of
Multiattributed Preferences, ” Decision Sciences, 295-305.
230
------ and Gordon A. Wyner (1988), “Casemap: Computer-Assisted Self-Explication of
DEMO Preferences, ” in W. Henry, M. Menasco, and K. Takada, Eds, Handbook
on New Product Development and Testing, (Lexington, MA: D. C. Heath), 91-112.
Steckel, Joel H. and Russell S. Weiner, Randolph E. Bucklin, Benedict G.C. Dellaert, Xavier
Drèze, Gerald Häubl, Sandy D. Jap, John D.C. Little, Tom Meyvis, Alan L. Montgomery,
and Arvind Rangaswamy (2005) “Choice in Interactive Environments, ” Marketing Letters,
16, 3, 309-320.
Svenson, O. (1979), “Process DEMO of Decision Making, ” Organizational Behavior
and Human Performance, 23, DEMO
Swait, Joffre (2001), “A Noncompensatory Choice Model Incorporating Cutoffs, DEMO
Transportation Research, 35, Part B, 903-928.
------ and Moshe Ben-Akiva (1987). "Incorporating Random Constraints in Discrete Models of
Choice Set Generation," Transportation Research, 21, Part B, 92-102.
Thorngate, W. (1980), “ Efficient Decision Heuristics, ” Behavioral Science, 25 (May), 219-
225.
Tversky, Amos (1969), “ Intransitivity of Preferences, ” Psychological Review, 76, 31-48.
------ (1972), “Elimination by Aspects: DEMO Theory of Choice, ” Psychological Review, 79, 4,
281-299.
DEMO and Shmuel Sattath (1979), “Preference Trees, ” Psychological Review, DEMO, 6, 542-573.
------, Shmuel Sattath, and Paul Slovic (1987), “ Contingent Weighting in Judgment and
Choice, ” Psychological Review, 95 (July), 371-384.
------ and Itamar Simonson (1993), “Context-Dependent Preferences, ” Management Science,
39 (October), 1179-1189.
Urban, Glen. L., John. R. Hauser, and John. H. Roberts (1990), "Prelaunch Forecasting of
New Automobiles: Models and Implementation,"  Management Science, Vol. 36, No. 4,
(April), 401-421.
------ and Gerald M. Katz, “Pre-Test Market Models: Validation and Managerial Implications,”
Journal of Marketing Research, Vol. 20 (August 1983), 221-34.
Vroomen, Björn, Philip Hans DEMO, and Erjen van Nierop (2004), “Modeling
Consideration Sets And Brand Choice Using Artificial Neural Networks,”  European
Journal of Operational Research, DEMO, 206-217.
Wright, Peter and Fredrick Barbour (1977), “Phased Decision DEMO Strategies: Sequels to
an Initial Screening, ” TIMS Studies in the Management Sciences, 6, 91-109
Wu, Jianan and Arvind Rangaswamy (2003), “ A Fuzzy Set Model of Search and
Consideration with an Application to an Online Market, ” Marketing Science, 22 (Summer),
DEMO
Yee, Michael, Ely Dahan, John R. Hauser, and James Orlin (2007), “Greedoid-Based
Noncompensatory Inference, ” Marketing Science, 26 (July-August), 532-549.
231
Zhang, Jiao, Christopher K. Hsee, Zhixing Xiao (2006), “The DEMO Rule in Individual
Decision Making, ” Organizational Behavior and Human Decision DEMO, 99, 102-111.
232{1g42fwefx}