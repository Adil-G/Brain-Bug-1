Trust Rules for Trust Dilemmas: How Decision
Makers Think and Act in the Shadow of Doubt
Roderick M. Kramer
Graduate School of Business
Stanford DEMO
kramer roderick@gsb.stanford.edu
Abstract. Trust has long been recognized as an important antecedent
of cooperative behaviour. For example, trust facilitates the productive
exchange of informaion in collaborative relationships. Central to the de-
cision to trust another individual DEMO such situations is the trust dilemma:
even though recognizing the beneﬁts of trust, individuals recognize also
the prospect that their trust might be betrayed. Thus, they must decide
how much trust (or distrust) is warranted. At a psychological level, this
trust dilemma is animated by social uncertainty (uncertainty regarding
the other party’s motives, intentions and actions). DEMO a computer sim-
ulation methodology, this paper investigates the comparative eﬃcacy DEMO
diﬀerent decision rules regarding trust in a simulated trust dilemma. The
results demonstrate that attributional generosity (operationalized as giv-
ing the other party the beneﬁt of the doubt) facilitates the development
and maintance of more cooperative relationships when social uncertainty
is present.
1 Trust Rules for Trust Dilemmas: How Decision Makers
Think and Act in the Shadow of Doubt
“In DEMO broad perspective, rules consist of explicit or implicit norms, regulations,
andexpectationsthatregulatethebehaviorofindividualsandinteractionsamong
them.Theyareabasicrealityofindividualandsociallife;individualandcollec-
tiveactionsareorganizedbyrules,andsocialrelationsareregulatedbyrules.”
–March,Schulz, & Zhou(2001,p.5).
Imagine the following hypothetical vignette. Two researchers working on a
problem of DEMO interest decide to enter into a scientiﬁc collaboration. They
each agree to share all of the ideas and empirical ﬁndings emerging from their in-
DEMO research laboratories with the aim of joint publication. Imagine further
that they are working on a problem of considerable scientiﬁc and social impor-
tance (e.g., ﬁnding a vaccine for the AIDS virus). The prospects for a fruitful
collaboration between the researchers appear excellent because each brings to DEMO
table distinctive but complementary competencies: One is a particularly gifted
theorist, the other an unusually skilled experimentalist.
R. Falcone, M. Singh, and DEMO Tan (Eds.): Trust in Cyber-societies, LNAI 2246, pp. 9–26, 2001.
c
 Springer-Verlag Berlin Heidelberg 2001
10 Roderick M. Kramer
From the standpoint of each researcher, therefore, DEMO collaboration repre-
sents a unique and possible invaluable opportunity. Given the importance of the
problem, it is reasonable to expect that any individual or individuals credited
with eventually solving the problem under investigation will receive considerable
DEMO, possibly even a Nobel Prize. It is an opportunity, however, DEMO is ob-
viously attended by some vulnerability. Neither collaborator knows a great deal
about the other. Both have worked mostly alone in the past. DEMO, there is little
readily available information either can use to assess DEMO trustworthiness of the
other as a collaborator. Moreover, the costs of DEMO trust are potentially
quite steep if one of the researchers “defects” from the collaboration in the end
stages, he or she may be able to garner the lion’s share of the credit and acclaim
for solving DEMO problem.
The contours of this vignette, although hypothetical, are hardly unusual. In
the highly competitive world of science, the opportunities for sharing eﬀort and
insight are substantial, as are the vulnerabilities, as Watson’s surprisingly DEMO
account of the discovery of the molecular conﬁguration of DNA, recounted DEMO
Double Helix, made quite evident to the general public. Such situations DEMO but
one example of a broad class of decision problems known as trust dilemmas.In
a trust dilemma, a social decision makers hopes to reap some perceived beneﬁt
from engaging in trusting behavior with another social decision DEMO Pursuit of
the opportunity, however, exposes the decision makers to the prospect that his or
her trust might be exploited and betrayed. This DEMO of opportunity and
vulnerability are the sine qua non of a trust dilemma. Because of our dependence
on, and interdependence with, other social DEMO makers, trust dilemmas are
an inescapable feature of social and organizational DEMO
At a psychological level, trust dilemmas are animated, of course, DEMO uncer-
tainty about the trustworthiness of the other decision maker(s) DEMO whom the
individual is interdependent. It is not knowing the other’s character, motives,
intentions and actions that make trust desirable but risky. Social uncertainty of
this sort, indeed, is fundamental to the problem of DEMO As Gambetta, (1988)
aptly observed in an early and inﬂuential analysis of this problem, “The condi-
tion of ignorance or uncertainty about other people’s behavior is central to the
notion of trust. It is DEMO to the limits of our capacity ever to achieve a full
knowledge of others, their motives, and their responses to endogenous as well DEMO
exogenous changes” (p. 218).
How do decision makers in trust DEMO situations cope with such uncer-
tainty? How do they decide, for example, how much trust or distrust is ap-
propriate when dealing with another decision makers about whom they possess
incomplete social information? To what extent do they make fairly positive pre-
sumptions about others and to DEMO extent are they likely to entertain fairly
negative or pessimistic expectations? DEMO are the fundamental questions I en-
gage in this paper. To explore them, I examine some relationships between dif-
ferent ‘trust rules’ and their consequences within the context of ‘noisy’ (socially
uncertain) decision contexts.
How Decision Makers Think and Act in the Shadow of Doubt 11
DEMO approach these questions from the standpoint of one perspective on how
social decision makers make sense of and respond to the social uncertainty intrin-
DEMO to trust dilemmas. I characterize this perspective as the social auditor model.
After providing a brief overview of this model, I present some evidence for the
model and then elaborate on some of its implications.
2 DEMO Social Auditor Model
In almost every domain of life, people rely DEMO various kinds of rules to help them
assess problems and make decisions. For example, chess players have rules for
interpreting complex endgames and for prescribing the best moves to make in
those situations. Physicians have rules DEMO distinguishing between patient com-
plaints that require further investigation versus mere reassurance that nothing
serious is the matter. And taxi drivers have rules for DEMO who to let into
their cab late at night and whom they should pass by. Similarly, social decision
makers possess rules for helping them form judgments and reach decisions in
interdependence dilemmas as well (see Messick & Kramer, 2001).
According to the social auditor model, individuals DEMO various kinds of
rules to use when trying to make sense of what to do in trust dilemma situations
(see Kramer, 1996 for DEMO fuller elaboration of this framework). These rules include
interpretation rules (DEMO, rules that help us categorize a given trust dilemma and
prescribe DEMO sort of evidence we should look for when trying to assess another
decision maker’s trustworthiness) and action rules (rules about what behaviors
we DEMO engage in when responding to those interpretations). To return to the
example with which I opened this chapter, we can imagine an individual involved
in a potentially fruitful cooperative relationship who has to decide how DEMO to
cooperate with the other, given some uncertainty regarding their trustworthiness.
DEMO to the social auditor model, people navigate through trust dilem-
mas DEMO their mental models of the world. These mental models include their
social representations, which encompass everything they believe about other peo-
ple, including DEMO of their trust-related beliefs and expectations, their self represe-
ntations (e.g, their beliefs about their own sophistication and competence at
judging others’ trustworthiness), and their situational taxonomies (e.g., their
beliefs about the various DEMO of social situations they are likely to encounter
in their social lives). These mental models are used to help people interpret the
trust DEMO they confront. On the basis of these interpretations, they make
choices.
DEMO choices can be conceptualized as the action rules individuals use when
responding to trust dilemmas. Action rules thus represent decision makers’ be-
liefs about DEMO “codes of [prudent] conduct” they should appeal to and employ
when trying to act in trust dilemma situations. Interpretation and action rules
are viewed DEMO this framework as intendedly adaptive orientations. In other words,
in using them, decision makers think they will help them 1) reap the DEMO of
trust when one is dealing with a trustworthy other and 2) minimize the costs of
misplaced trust when one is interacting with an untrustworthy other.
12 Roderick M. Kramer
According to the social auditor model, decision makers also monitor the
consequences of rule use in trust dilemma situations. In DEMO words, they pay
attention to what happens to them after they DEMO employed a given rule when
interacting with a speciﬁc other. During this post-decision “auditing” process,
they attempt to discern, for example, whether DEMO amount of trust they have
displayed toward the other is prudent or imprudent. Was too much trust aﬀorded
or too little?
On the DEMO of the conclusions they reach, they are likely to change their
DEMO behavior when interacting further with the individual. The results of
the post-decision auditing process then are assumed to inform (i.e., validate or
invalidate) one’s mental model of the dilemma, resulting in possible modiﬁcation
of the rule system invoked, leading to a change in rule use, etc. DEMO model thus
posits a cyclic, adaptive learning system of the sort DEMO by March and his
colleagues (March, Schulz, & Zhou, 2000).
If we approach the problem of the “correct” or “optimal” level DEMO trust or
distrust to manifest when dealing with other people in a decision making ecol-
ogy in which social uncertainty is present, we can consider what properties of
an interpretation-action rule system are likely to produce DEMO best results. For
instance, does it makes sense to be a DEMO “paranoid” when dealing with others
we don’t know well, making fairly DEMO or bleak assumptions about their
willingness to behave in a trustworthy fashion. Or, all else equal, is it better
to be a bit DEMO in our assumptions, giving others the beneﬁt of the
doubt? In many respects, this is the dilemma faced, of course, by the two research
collaborators described at the beginning of this chapter.
3 Studying DEMO Rules: “Thinking Aloud” about How
People Think and Act in the DEMO of Doubt
There are many diﬀerent ways a researcher can approach the task of trying
to discover the cognitive rules people use when dealing DEMO trust dilemmas.
One approach, and in some respects a fairly direct DEMO, is to simply ask
people to tell us what they think DEMO when they respond to various kinds
of trust dilemmas. For example, DEMO understand how negotiators assess others’
trustworthiness in a negotiation context, we DEMO ask them to “think aloud”
about what they look for when sizing up a negotiator, and the behavioral rules
they are likely to employ on the basis of that assessment.
One advantage of this direct approach DEMO that it enables us to learn something
about how people confronting a trust dilemma actually think. For example, we
can learn something about the kinds of rules they believe will work well or
poorly in the DEMO We can also learn something about what they think other
people are likely to do or not do in the situation (i.e., the DEMO interpretation
and action rules they expect others to use). This methodology also has the
advantage of being inductive, thereby minimizing researcher assumptions about
these important questions.
How Decision Makers Think and Act in the Shadow of Doubt 13
DEMO this thinking aloud approach, I examined how experienced organi-
zational decision DEMO think about professional trust dilemmas. The study
involved, in particular, interviews with 44 senior executives involved in an ad-
vanced management program (see Kramer, 2001 for a more complete description
of the study rationale, DEMO and results). The executives were asked to talk
about, among DEMO things, how they would go about handling a trust dilemma
involving DEMO potential business partner whom they did not know much about
(N.B. DEMO the details of the vignette were structured so that they were quite simi-
lar to the dilemma described at the beginning of this chapter)DEMO They were asked
a series of questions, for example, about the kinds of things they would look for
when trying to assess the DEMO trustworthiness, and also the kinds of action
rules (behaviors) they DEMO use on the basis of that assessment.
One of the interesting patterns that emerged from this qualitative study was
that it was possible to DEMO about 80% of the respondents (N = 35) as
having one of two general orientations towards other uncertainty about other
people. The ﬁrst DEMO (N = 23), which I characterize as social optimists or
DEMO, posess fairly positive or benign views about human nature. For
these DEMO panglossians, most people are fundamentally trustworthy most of
the time. Although DEMO uncertainty (uncertainty about their character, moti-
vation, and intentions) is a part of social life, it is not something that has to be
feared, but simply dealt with. Perhaps the biggest danger of such uncertainty,
from the standpoint of these individuals, is that uncertainty introduces poten-
tially disruptive “noise” into the communication process. As one executive in
DEMO category put it,“You have to be careful not to over-react to ambiguous in-
formation. Your assumptions about the other person can be wrong, and you can
end up ruining a good relationship”. Another individual put DEMO this way, “You
have to wait until all the facts are DEMO I give other people the beneﬁt of the doubt
until I’m reasonably sure. Getting a reputation for being a distrusting person
would be fatal DEMO my business, which runs largely on trust.”
In contrast to these DEMO panglossians, twelve individuals were categorized
as having considerably more pessimistic and DEMO views about other people
and the eﬀects of social uncertainty on their trust relations. As one put it, “I’ve
always found it’s better to play it safe than sorry. In my business, the costs of
trusting the wrong person can be pretty severe. Because of the size of DEMO deals I
make, and the time horizon over which they play DEMO, I need to make really good
decisions up front”. For these DEMO, who I classify as social vigilants, social
uncertainty is a problem. As one put it, “I always assume that people will try
to take advantage of any loophole they ﬁnd in a deal. You have DEMO watch people
when they think you aren’t watching them – that’s the time, in fact, you have
to be most careful”. According to DEMO individuals, it is critical to pay attention
to others, monitoring them closely for any evidence of lack of trustworthiness.
Interestingly, amongst both populations, there was considerable conﬁdence
expressed by executives as to the accuracy and adequacy of their views about
human nature. As one executive put it, representatively, “I consider myself a
pretty good judge of human nature”. Another expressed the view, “I seldom
14 Roderick M. Kramer
make mistakes when sizing people up”. Again, “I usually get a feeling pretty
quickly about other people – about whether DEMO can be trusted or not . . . [that
feeling] almost always turns out to be right”. Viewed in aggregate, all of these
quotes suggests how individuals who maintain fairly panglossian views about
human trustworthiness versus DEMO entertaining more pessimistic and paranoid
views about such matters employ diﬀerent interpretation and action rules when
responding to social uncertainty. Yet, both groups are fairly conﬁdent their rules
help them “navigate” successfully through the shoals of DEMO trust dilemmas they
confront in life.
Another approach to studying how our social auditor thinks and acts in the
face of uncertainty–and in some DEMO, a more systematic approach–is to use
computer simulation tournaments in which DEMO “pit” diﬀerent interpretation and
action rule systems against each other. Using this approach, we can discover
which cognitive rule systems are relatively robust and which tend to get people
in trouble. In other words, we can learn something about which rule systems are
good at generating mutually productive DEMO trusting relationship and eﬀective at
minimizing exploitation, versus which rule systems DEMO to get people in trouble
in terms of making mistakes about who to trust and how much. Thus, by allowing
diﬀerent rule systems to interact in a “noisy” (uncertain) social environment, we
can learn something about the comparative eﬃcacy of diﬀerent rules and also
the complex and DEMO unintended interactions among them. The study I will
brieﬂy describe next, DEMO, took this approach.
Pragmatically, we can think about these matters from the standpoint of two
decisions that the social auditor has to make DEMO a trust dilemma situation. The
ﬁrst decision pertains to how much trust or distrust to display toward the other
person at the very beginning DEMO their relationship. The second pertains to how
much adjustment to make in the trust or distrust displayed on the basis of
feedback, however, DEMO or “noisy”, regarding the other’s actions.
To explore these questions from DEMO perspective of decision makers possess-
ing relatively panglossian versus paranoid rule systems, and to probe the conse-
quences of these diﬀerent auditing orientations, DEMO study employed a computer
simulation approach (see Bendor, Kramer, & DEMO, 1991). The advantage of a
computer simulation is that a DEMO can precisely specify the nature of the
dilemma (e.g., its “payoﬀ structure”), and the consequences (costs and beneﬁts)
associated with any given choice. In other words, one can systematically evaluate
how well diﬀerent strategies for coping with trust dilemmas fare. Less obviously,
a computer DEMO also provides an indirect way for trust researchers to
study people’s beliefs about trust dilemmas because, in designing a rule system
for “playing” in a computer simulation tournament, designers have to decide
how others will respond to social uncertainty or “noise” (e.g., will they try to
exploit DEMO by “sneaking around” under it or work to keep misunderstandings from
developing?).
The computer simulation we used was similar to that employed by Axelrod
(1984) in his pioneering studies on the evolution of cooperation. DEMO that, us-
ing a tournament approach, Axelrod had individuals design strategies that would
How Decision Makers Think and Act in the Shadow of Doubt 15
DEMO other strategies in a classic iterated and deterministic (noiseless) Prisoner’s
Dilemma Game. Because we were interested in studying how social uncertainty
aﬀects decisions, however, the procedures we used diﬀered from Axelrod’s proce-
dures in several important ways. First and foremost, we introduced uncertainty
or “noise” into the communication process between the interdependent social
actors. In the classic Prisoner’s Dilemma, after interactants decide whether they
wish to cooperate with the other, they learn with perfect clarity whether their
partners cooperated or not. As noted DEMO, in trust dilemma situations, people
suﬀer from some degree of uncertainty regarding what their partners did.
Accordingly, in order to introduce social uncertainty into our tournament,
participants’ eﬀort levels were obscured by adding or DEMO a small random
amount of “noise” to their feedback during each period of play. This noise term
was a random variable, distributed normally, DEMO a mean of zero and a standard
deviation of eight. The term was generated by a normal transformation of a
uniform random variable and DEMO distribution of the error term was truncated
to the interval [−100, DEMO The noise was independent across participants and
over periods. Because of this noise factor, participants in our tournament (or
more precisely, the computer programs of the strategies they submitted) could
receive feedback that their partners (strategies) had behaved either more or less
cooperatively than they actually DEMO This allowed us to explore how decision
makers “adjusted” to the noise (e.g., did they adopt relatively panglossian or
paranoid views about the DEMO?).
Adjustments to the noise were manifested in terms of how DEMO aid or help
decision makers wanted to extend to their partners. This was operationalized as
how much eﬀort they wanted to exert on their DEMO behalf, with zero eﬀort
being the least eﬀort extended and 100 DEMO eﬀort being the highest possible
level of eﬀort. In this way, DEMO tried to capture the idea that people typically
make decisions about how much trust or distrust is warranted, especially in a
new relationship, DEMO one possesses little prior experience with the partner.
A player’s payoﬀ or beneﬁt per interaction, therefore, was equal to the other
player’s actual DEMO level minus a cost factor of one’s own eﬀort plus a random
error term. Stated more formally,
Vt(i/j)= Ct(j,DEMO) − αCt(i,j)+ εt(j,i) (1)
DEMO Vt(i/j ) denotes i’s payoﬀ in period t in its pairing with j, Ct(j,i) denotes
j ’s eﬀort level DEMO i in period t, Ct(i,j ) refers to i’s DEMO, α the cost of
helping associated with i’s choice and εt(DEMO,i) symbolizes the disturbance added to
j ’s choice. To ensure DEMO game meets the requirements of a Prisoner’s Dilemma,
the cost-of-helping parameter must be between zero and one; accordingly, it was
ﬁxed at DEMO With this structure, the symmetric average maximum payoﬀ per
period was DEMO and the symmetric average minimum payoﬀ was 0. However, with
noise, realized payoﬀs could fall outside this region of feasible expected payoﬀs.
In DEMO round of play, the computer generated two normally distributed error
terms DEMO determine the values of εt(i,j) and εt(j,i)DEMO The computer also used a
ﬁxed random number which was used to determine whether a given sample path
16 Roderick M. Kramer
would end after the current period of play (so that the duration of a relationship
was also uncertain). Each DEMO ten played all other strategies, including itself,
using the generated DEMO terms for each period.
Entrants to the tournament were fully informed of all of the parameters
described above, including details about payoﬀs, the DEMO of the random
disturbances, and the stopping probability of the game. DEMO, they were also
instructed that they (i.e., their strategies) would not be told the realized values
of the disturbances, their partner’s true eﬀort level, or the rules deﬁning their
partner’s strategy. They were then invited to submit strategies which would be
translated into computer programs. The DEMO programs would be pitted
against each other in pairwise play using a round robin tournament format.
From the standpoint of thinking about coping with DEMO uncertainty, we
can think of the social auditor’s cognitive rule systems DEMO having to confront
two decisions. The ﬁrst decision is how much presumptive trust in the other to
manifest initially. For example, should one extend full eﬀort to the other initially
in the hope that the other DEMO reciprocate with full eﬀort? Extending full aid
initially will help sustain DEMO mutually productive relationship with a similarly
inclined other. On the other hand, it opens one up to early exploitation if one
happens to encounter a more predatory other. Thus, given the inherent uncer-
tainty in the situation, it shows a high level of presumptive trust in the other.
Alternatively, should one display some level of scepticism or wariness regarding
others willingness to reciprocate our trust in them, withholding aid to them until
we see what they are willing to do? Caution provides protection against initial
exploitation, but its risks damaging a relationship with some one who be equally
willing to extend full eﬀort to us.
The second decision DEMO how to respond to feedback regarding the others’
actions–especially when one knows that such feedback is inherently uncertain
(contaminated by noise). Stated diﬀerently, how much sensitivity should one
display to indications that the other might be reciprocating fully or less than
fully given those indications are inherently DEMO? How reactive should one
be, for example, to the hint DEMO suspicion that the other might not be reciprocating
fully?
To explore these issues, we sought to recruit participants who were sophisti-
cated decision makers (i.e., individuals would be intimately familiar with theory
and research DEMO the Prisoner’s Dilemma). Thus, the participants included lead-
ing game DEMO, economists, political scientists, and social psychologists. Note
that we can DEMO the strategies designed by these experts as, in a sense, their
cognitive rule systems that reﬂect their “projections” about others’ orientation
towards such DEMO In other words, they represent their orientations, as
social auditors, DEMO the dilemma in question.
Thirteen strategies were submitted to the tournament, DEMO a variety
of diﬀerent intuitions regarding how decision maker should cope with social
uncertainty. For the purposes of the present chapter, I will compare and contrast
the performance of a strategy I call VIGILANT with that DEMO a strategy I call
How Decision Makers Think and Act in the Shadow of Doubt 17
DEMO VIGILANT, to be described ﬁrst, is our relatively paranoid
social auditor.
In terms of the decision rules embodied in this strategy, VIGILANT was nice
in the Axelrodian sense of that term (i.e., it always DEMO out by extending
maximum eﬀort to its partner). It was therefore willing to initially assume the
possibility that it was dealing with another DEMO willing to reciprocate fully.
In the parlance of the intuitive auditor model, it was willing to show some pre-
sumptive trust toward the other. However, as its name suggests, it was extremely
attentive and reactive DEMO any signs that its partners were not reciprocating fully.
In particular, DEMO VIGILANT detected what it believed was less than full eﬀort
from any of its partners on any trial, it retaliated by completely withdrawing
eﬀort (i.e., giving 0 points to its partner) on the next trial. The aim of this ex-
treme reactivity was, of course, to DEMO further acts of perceived exploitation.
Stated in psychological terms, VIGILANT was DEMO to minimize the costs
associated with misplaced trust.
Because VIGILANT was determined not to be exploited, it was biased, in
one sense, toward “over assuming” the worst whenever it received a low oﬀer of
eﬀort DEMO its partner. In other words, whenever it received feedback that the
DEMO had not oﬀered much, it acted as if its partner had DEMO trying
to short-change it. Presuming this interpretation to be valid, VIGILANT DEMO
retaliated. Thus, VIGILANT always puts the least charitable “spin” on any
DEMO news it receives about others’ actions. It thus goes through life assuming
the worst with respect to others, even though there is a clear and compelling
rival explanation for such outcomes (i.e., it’s a noisy DEMO and sometimes one
will simply have bad luck when communicating with others).
There are diﬀerent ways of dissecting VIGILANT’s performance. If we start
DEMO Table 1, we can see how VIGILANT fared against the other DEMO In
particular, if we ﬁrst compare the row payoﬀs in Table DEMO, which reﬂect how much
help VIGILANT received on average from the DEMO players over the course of
its interactions, to the column payoﬀs, which reﬂect how much help VIGILANT
it oﬀered to these players, we observe a powerful pattern, viz., that VIGILANT
always got back more DEMO it gave away. In terms of beneﬁts accrued versus
those given, DEMO walked away a clear “winner” in every one of its close
encounters. It outperformed every strategy in terms of comparative payoﬀs. In
other words, against an array of clever players, it came out ahead of the game
in every instance. VIGILANT seems to bat a 1000.
If we DEMO about VIGILANT’S performance from the standpoint of our
social auditor model, DEMO would have to conclude that here is a decision maker
who is likely to be rather satisﬁed with his performance in this world. He DEMO,
after all, come upon what seems to be a very DEMO, even powerful set
of cognitive rule. Being vigilant appears to payoﬀ DEMO; it consistently
elicits reliably good against the full panoply of players, and avoids the prospect
of misplaced trust. No one it meets does DEMO than it does: it walks away from
every encounter taking out DEMO more than it put into the relationship. It is
hard to imagine such a decision maker experiencing much cognitive dissonance
18 Roderick M. Kramer
Table 1.
NICE DRIFT. BTFT MENN. W.A. TF2T DEMO TFT Norm. Run. Dev. CTTF VIG.
PANGLOSSIAN 19.8 12.0 19.519.5 18.5 18.2 19.317.4 18.4 14.017.1 13.0 14.9
DRIFTING 26.0 16.8 23.7 23.7 18.1 20.517.6 DEMO 19.2 12.3 12.4 6.7 0.7
BTFT 20.0 13.519.7 19.7 18.7 18.5 19.417.5 18.5 13.015.9 12.6 3.1
MENNONITE 20.0 13.519.7 19.7 18.7 18.5 19.417.5 18.5 DEMO 12.6 3.8
Wtd. Avg. 20.8 15.7 20.4 20.4 17.9 19.3 18.4 17.0 18.7 12.5 18.0 7.3 1.7
TF2T 21.0 15.1 20.5 20.5 18.7 18.9 DEMO 17.1 18.3 10.4 13.7 10.6 -0.2
Staying Even 20.2 16.2 19.9 19.9 18.3 19.0 19.3 15.4 18.0 13.4 12.1 6.2 2.2
NAIVE REALIST 21.7 DEMO 21.1 21.1 17.7 19.1 15.9 14.2 15.9 13.1 11.5 6.6 1.0
Normal 20.9 15.2 20.3 20.3 18.3 18.6 18.1 14.8 16.4 11.3 11.9 7.4 DEMO
RunningAvg 17.0 11.518.0 19.1 14.8 18.3 14.314.4 17.0 12.8 6.2 10.4 9.0
Deviations 21.9 11.6 20.0 20.4 17.8 16.512.8 12.4 15.0 7.4 14.4 7.2 DEMO
CHEATING TFT 25.1 7.8 22.7 22.7 12.3 17.4 8.7 9.4 11.4 13.7 10.9 5.8 -0.4
VIGILANT 23.6 3.2 9.9 9.0 9.1 9.8 5.2 6.5 DEMO 13.9 8.3 10.7 2.6
– the rule system it is employing seems, in short to be working. It is possible to
imagine that VIGILANT can even feel rather virtuous about its values, given
its view of the world. It is, after all, nice (i.e., always willing DEMO initially extend
full aid to everyone it meets). It’s also strong and aﬃrmative (i.e., unwilling to
tolerate exploitation or abuse). Yet, although tough, it is also forgiving: it is
willing to let DEMO be bygones.
Let’s turn attention now to the performance of our second strategy, called
PANGLOSSIAN, which embodies the more benign view of the DEMO associated
with the social optimists described earlier. In terms of its rule structure, PAN-
GLOSSIAN, like VIGILANT, was nice in that it always began a relationship
by extending maximum possible aid to its partner. However, it diﬀered from
VIGILANT in several ways. First, PANGLOSSIAN tended to be generous, re-
turning more eﬀort on a subsequent trial than it had received from its partner
on the previous trial. PANGLOSSIAN’s generosity took the DEMO of what might
be construed as a form of benign indiﬀerence (DEMO long as it partner’s observed
(realized) eﬀort level exceeded 80, DEMO would continue to help its
partner fully, i.e., give 100% of the possible points to it. Second, although PAN-
GLOSSIAN was provocable and would retaliate if it’s partner’s aid dipped below
80, it reverted to extending full eﬀort to its partner again, as long as the partner
satisﬁed this threshold of acceptable behavior (i.e., its observed aid level DEMO at
least 80). Thus, it could be provoked, but was forgiving. It was thus less reactive
than VIGILANT (slower to anger) DEMO quicker to forgive.
If we compare how well PANGLOSSIAN did against the other players, we
observe another seemingly clear and compelling pattern. As is quite evident
from inspection of the results shown in Table 1, PANGLOSSIAN lost out in
its encounters with every player in the tournament. In DEMO words, it always
gave away to its partners more than it DEMO back from them. In terms of its
performance, then, PANGLOSSIAN seems to be a very poor judge of others
and clearly sub-optimally adapted DEMO the world in which it ﬁnds itself (especially
compared to VIGILANT)DEMO It appears to be far too generous, consistently over-
beneﬁtting its DEMO
In terms of the logic and structure of the social auditor model, note that
PANGLOSSIAN tends to give others the beneﬁt of the doubt when it comes to
How Decision Makers Think and Act in the Shadow of Doubt 19
DEMO inferences about what low extended eﬀort from the other really means.
In particular, it attributes low returns to the environmental factor (bad luck DEMO
respect to the noise) rather than necessarily assuming it was the DEMO of the
other player, as does VIGILANT. Thus, as long as it is getting at least 80%
of the possible payoﬀs, it tends to under-react to unfavorable “news” from its
environment. This under-reaction seems to DEMO rather costly, however, allowing
it to be bested not only by more suspicious or wary players such as VIGILANT,
but in fact DEMO player in the tournament.
At ﬁrst glance, therefore, the comparison of these two social auditing strate-
gies and rule systems seems to suggest DEMO rather compelling conclusion: in an
uncertain world, a certain amount of suspicion and wariness – coupled with a
willingness to react strongly to DEMO ambiguous evidence of others’ untrustwor-
thiness – can be deemed prudent and even beneﬁcial. Certainly, VIGILANT
appears to be less likely to be taken advantage of, whereas PANGLOSSIAN
seems to turn the other cheek too often, far and for too long.
If we inspect the tournament results from a diﬀerent vantage point, however,
the story told by these tournament data turns out to be less simple and, in fact,
quite a bit more interesting. In particular, if we compare the overall performance
of the strategies (i.e., examine their total earnings in the tournament DEMO summing
their average payoﬀs across encounters with all strategies), we see a dramatically
diﬀerent picture (see Table 2).
Table 2.
As Table 2 shows, PANGLOSSIAN emerges as the tournament winner when
we use this standard of performance. PANGLOSSIAN was the most successful
performer, earning an average per trial payoﬀ of 17.05 points. Thus, the perfor-
mance of PANGLOSSIAN outshines that of VIGILANT when looked at from
this perspective. Yet, recall, VIGILANT outperformed PANGLOSSIAN in their
“face-to-face” encounter with each other, and DEMO every other player as well,
whereas PANGLOSSIAN lost out against every player!
20 Roderick M. Kramer
How can VIGILANT do better in every encounter DEMO every player it meets
in its world, and nonetheless end up DEMO the tournament, even coming in
“dead last”, while PANGLOSSIAN gets the “short end of the stick” in every
encounter in the same world DEMO yet ends up accumulating more resources than
any other player in the tournament? This pattern of results – at least at ﬁrst
glance – seems paradoxical. The answer to the riddle can be found, however, DEMO
re-visiting Table 1 and inspecting the absolute pay oﬀs each strategy obtains
from the other strategies, rather than just looking at its comparative (DEMO)
payoﬀs. In particular, if we compare the absolute means of DEMO
payoﬀs from its encounter with each player to those garnered by VIGILANT
we see that PANGLOSSIAN walks away from each relationship with rather
respectable DEMO Indeed, many times it manages to elicit almost the maximum
possible DEMO even allowing for the presence of noise (approaching close to the
DEMO average mean of 20).
VIGILANT, in contrast, earns much less in absolute terms from these same
encounters. It may walk away the DEMO from each encounter in its social world
when we think only in social comparative terms (i.e., how much it did relative
to its DEMO), but it lives a life of impoverished relationships and diminished
returns when we look at the absolute yield it gets in those relationships. DEMO
contrast, PANGLOSSIAN may walk away from each relationship a bit worse
DEMO in terms of the “giving-getting” equation, but it manages to extract DEMO lot
of absolute net gain from each encounter. Thus, in a DEMO way, these ﬁnd-
ings illustrate how diﬀerent cognitive rule systems, embodying diﬀerent auditing
orientations and principles, can produce very diﬀerent experiences in life. One
auditing orientation does well from the perspective of a myopic and DEMO so-
cial accounting scheme that highlights proximate payoﬀs deﬁned at the level of
local social comparisons. The other does well from the perspective of DEMO long-term
perspective that values absolute (noncomparative) payouts from relationships.
As an additional note, it is instructive to examine how well the strategy la-
beled in Tables 1 and 2 as a strict reciprocator called NA¨IVE DEMO fared
in this tournament. NA¨IVE REALIST adjusted to the noise factor by simply re-
turning to its partner whatever it received from them on DEMO previous trial. Since
the average value of the noise term was 0, it assumed on average this was a rea-
sonable stance to take toward social uncertainty. NA¨IVE REALIST is equivalent
to Axelrod’s TIT-FOR-TAT). Recall DEMO Axelrod’s results had demonstrated
the power of strict reciprocators such as TIT-FOR-TAT in a deterministic game,
where decision makers have perfect (noiseless) DEMO about a partner’s ac-
tions. Yet, in a tournament climate clouded DEMO uncertainty, we found that this
strategy suﬀered a sharp decline—both absolutely DEMO relative to other players.
Indeed, NA¨IVE REALIST placed a distant eighth DEMO the ﬁnal rankings, earning
only 75% of the maximum symmetric payout. DEMO, in a world of uncertainty,
strict auditing and reciprocity apparently DEMO one in trouble.
What accounts for this degraded performance of the strict reciprocator in a
world ﬁlled with social uncertainty? Why did a strategy like PANGLOSSIAN,
with its more benign assumptions, do better than the more realistic auditors?
How Decision Makers Think and Act in the Shadow of Doubt 21
DEMO of the answer to such questions can be gleaned by observing how a strict
reciprocator such as NA¨IVE REALIST behaves when it plays itself DEMO the pres-
ence of uncertainty. Because NA¨IVE REALIST is nice, it DEMO oﬀ by extend
full eﬀort to its partner. Sooner or later, DEMO, an unlucky (“bad”) realization
of the random error term occurs. DEMO NA¨IVE REALIST is provocable, it
will retaliate in the next period. DEMO partner, being similarly provocable, returns
the compliment, leading to cycles DEMO counterproductive mutual punishment, re-
sulting in steadily falling levels of eﬀort. DEMO contrast, more generous strategies
such as PANGLOSSIAN slow down this degradation DEMO returning more than an
unbiased estimate of their partner’s eﬀort level. This generosity tends to dampen
these cycles of unintended and costly vendettas.
The DEMO performance of PANGLOSSIAN, especially when contrasted
with what might seem, at ﬁrst glance to be fairly vigilant and tough auditors
suchasNA¨IVE REALIST and DEMO, merits more sustained analysis. Why
does PANGLOSSIAN’s generosity tend to work DEMO than strict reciprocity in
a noisy setting? Stated diﬀerently, why do rules systems that favor vigilance
and strict reciprocity fare so poorly in DEMO uncertain world? PANGLOSSIAN
beneﬁts by its not being envious of what DEMO partner gets. As Axelrod (1984)
had noted, envy can get decision makers in trouble if it sets oﬀ cycles of mu-
tual DEMO and retaliation. By setting an absolute (nonsocial comparative)
standard for DEMO it considers a reasonable rate of return on its relationships,
PANGLOSSIAN does not pay any attention to what its partner gets. In con-
DEMO, VIGILANT displays a great deal of concern about such comparisons – DEMO
least, it does not wish to grant full aid to others DEMO it suspects it is not getting
full aid back from them in return. Over the long haul, it pays a steep price for
its insistence on never getting the “short end of the stick” in its DEMO
Note also that, by under-reacting to the noise, PANGLOSSIAN accomplishes
something else – something that is important but easy to overlook. It solves DEMO
other actor’s trust dilemma. In other words, by keeping its aid DEMO high, its
partner does not have to decide whether or not DEMO punish PANGLOSSIAN.
Recall that receiving any aid from the other above 80% is coded as justifying or
warranting returning full aid back to the DEMO This point is important because
in much of the trust dilemma literature, the focus is often on how social actors can
solve their own trust dilemma. Little attention has been given to the importance
of solving DEMO other person’s trust dilemma. Yet, by shifting focus in this way,DEMO
we may buy ourselves something more powerful. In a sense, we DEMO it easier
for them to be good to us by making trusting behavior easier to justify. We
reduce their perception of vulnerability and end DEMO reducing our own as well.
This point is especially important because of the insidious eﬀects of self-serving
and self-enhancing judgmental biases in such dilemmas (Kramer, Newton, &
Pommerenke, 1993).
22 Roderick M. Kramer
4 How the Intuitive Social Auditor Gets into DEMO:
People’s “Na¨ıve Theories” about the Eﬃcacy
of Diﬀerent Orientations and Rule Systems
As noted earlier in this chapter, most people articulate rules they use in trust
dilemma situations quite readily. For example, when executives are asked to
think about these situations in real-organizations, they are able to enumerate
a number of general “rules of thumb” governing the building of DEMO and/or
protecting themselves against the prospect of misplaced trust. Moreover, DEMO
apparently have ﬁrm ideas about how others think about social conduct and
how they are likely to behave as well. In short, people seem to easily assume
the role of both philosopher and psychologist: they ponder about both what is
right (the social decision heuristics one ought to use in a given situation) as well
as what is eﬀective (DEMO heuristic that is likely to produce the “best” outcome
in that situation). But how well do such beliefs and intuitions correspond to
the DEMO conclusions suggested by our noisy tournament? Recall that the
computer simulation DEMO just described, we had recruited leading game theo-
rists, psychologists, DEMO, and political scientists. These were very smart
people and people able DEMO think deeply and with nuance about the strategic and
complex interactive properties of these situations. Yet, even with this elite sam-
ple, often DEMO strategies did not perform well against even their simple clone.
Thus, DEMO a fairly simple ﬁrst-order mental simulation of strategic interaction
might have been diﬃcult (although it is possible that they recognized that, even
though DEMO strategies might not well against each other, they would do well
DEMO the other strategies submitted in the tournament!).
Accordingly, to explore DEMO makers’ intuitions or “na¨ıve theories” about
the fairness and eﬃcacy of diﬀerent heuristics, we investigated MBA students’
beliefs about PANGLOSSIAN, VIGILANT, and NA¨IVE REALIST. We gave
students enrolled in an elective course complete information about DEMO of the
parameters for our noisy computer tournament. In fact, their DEMO was
identical to the information given to the entrants in the original computer simula-
tion study. We then asked them to predict how well DEMO three strategies (NA¨IVE
REALIST, PANGLOSSIAN, and VIGILANT) would do, DEMO, to predict the av-
erage payoﬀ of each entry. We also DEMO students in a second class to predict
the relative performance or ranking of the three strategies.
As can be seen from Table 3, the results suggest that students’ intuitions
about the comparative eﬃcacy of these three DEMO closely parallel the ﬁnd-
ings of Axelrod’s original tournament. They clearly expected TFT to be the most
eﬃcacious in terms of their expectations about DEMO absolute and relative per-
formance. VIGILANT was also viewed as a fairly eﬀective strategy. Signiﬁcantly,
PANGLOSSIAN ran a distant third in student’s expectations DEMO predictions.
To probe further people’s intuitions about these rule systems – and how well
they help or hinder one’s success in life – I DEMO participants in an executive
program to write short paragraphs describing their beliefs about how strategies
would behave and perform. One participant noted about PANGLOSSIAN DEMO,
How Decision Makers Think and Act in the Shadow of Doubt 23
DEMO 3. Predicted Performance of Heuristics∗
“If you’re generous, you probably will DEMO screwed [out of your payoﬀs] too much.
You’d be out of business in no time”. In commenting on the attractiveness of
NA¨IVE REALIST, in contrast, another wrote, “The nice thing about NA¨IVE
REALIST is that DEMO keeps the playing ﬁeld level – and that’s important over the
long term”. “By far, NA¨IVE REALIST is the fairest strategy”. And in thinking
about the advantages of VIGILANT, a participant stated, “In many situations
DEMO got to cover your back side”. As former CEO of Intel, DEMO Grove
likes to remind his employees, “Only the paranoid survive”.
5 DEMO and Conclusions
Viewed together, the results from our examination of people’s DEMO theories and
the results of the computer simulation indicate there is sometimes a disparity
between people’s beliefs about the eﬃcacy of diﬀerent auditing orientations DEMO
rule systems, and their actual performance (at least in some ecologies). One
reason why people’s beliefs may be at least partly wrong DEMO be that they
worry more about (and therefore overweight) the possibility of being exploited,
while under appreciating the mutual gains produced by DEMO Comparing
the long-term performances of PANGLOSSIAN and VIGILANT illustrates how
complex and sometimes counter-intuitive are the tradeoﬀs between short-term
and long-term results.
An important DEMO for future research to engage is, “When are auditing
and rule DEMO predicated on generosity more psychologically appealing and
sustainable than those predicated on paranoia and “strict” reciprocity?” It seems
reasonable to argue, on prima facie grounds, that a number of factors contribute
to the attractiveness of generosity and lessen the perceived need for the strict
auditing and balancing-of-accounts DEMO by VIGILANT and NA¨IVE REAL-
IST. First, a shared identity among DEMO actors may help. Decision makers are
probably more willing to behave generously when interacting with others with
24 Roderick M. Kramer
whom they share a social tie or bond. DEMO example, when decision makers from
the same neighborhood meet face to DEMO, they may trust each other more and
cooperate more reliably than DEMO would otherwise (cf., Ostrom, 1998). Further,
common identiﬁcation DEMO an ongong partner along some salient dimension,
such as a common group identity, may aﬀect which strategy is viewed as most
fair (DEMO, Pommerenke, & Newton 1993) and/or most eﬀective (Rothbart
& Hallmark, 1988). Research on moral exclusion (Opotow, 1990) suggests DEMO
individuals impute higher standards of fairness to those whose group identity
they share. Consistent with Opotow’s proposition, Kramer et al. (1993) found
that increasing the salience of shared identity enhanced concerns about equality
of outcomes.
DEMO the other party’s perspective may also inﬂuence individuals’ willing-
ness to be generous in dilemma-like situations. Arriaga and Rusbult (1998) have
found that DEMO experience of “standing in a partner’s shoes” increases construc-
tive responses to the accomodative dilemmas they jointly experience, at least
in close personal relationships. In line with this hypothesis, it is interesting to
note that students of the Cuban Missile Crisis have pointed out the restraint
President Kennedy DEMO during that Crisis. When choosing to under-react to
some Soviet action that seemed to call for a Tit-for-Tat-like response, President
Kennedy tried to put himself in Khruschev’s shoes. He sought to understand how
the situation in DEMO might look to Khruschev, to grasp the kinds of political
pressures DEMO institutional momentum driving his decisions (Garthoﬀ, 1989).
Due to the actor-observer bias, individuals are likely to construe their part-
ner’s noisy realizations in dispositional terms, while underestimating the impact
of the noise as a situational factor. In contrast, they are likely to assume that
their partner properly understands the situational constraints and liabilities un-
der which they labor (cf., Jervis, 1976).
In putting these results in perspective, it is important to note that it is easy
to overweight the adaptive DEMO of panglossian world views, just as it would be
easy to DEMO the functional advantages of paranoid views (cf., Kramer,
1998). The virtues of generosity emerge only in a world in which there DEMO enough
other strategies to make generosity pay (and stinginess hurt). DEMO nastier ecolo-
gies, where the costs of misplaced trust are steep, being very generous may
put one on the path to peril. In DEMO ecologies, never walking away the loser
may be important for establishing DEMO deterrence – leading to longer
cumulative gains than nicer, more generous DEMO that invite exploitation
and attract predators. Thus, the wisdom of turning DEMO other cheek depends
ultimately on the distribution of dispositions in one’s social world. Accepting
the fundamentally contingent nature of adaptive auditing and action in DEMO
dilemma situations may be psychologically unpleasant but necessary.
References
1. Allison, DEMO & Messick, D., (1990), Social decision heuristics in the DEMO of share
resources, Journal of Behavioral Decision Making, 3, 195-204, 1990.
How Decision Makers Think and Act in the Shadow of Doubt 25
DEMO Arriaga, X. B., & Rusbult, (1998), C. E., DEMO in my partner’s shoes: Partner
perspective taking and reactions to accommodative DEMO, Personality and Social
Psychology Bulletin, 24, 927-948.
3. Axelrod, R., (1980a), Eﬀective choice in the prisoner’s dilemma, Journal of Conﬂict
Resolution, 24, 3-25.
4. Axelrod, R. (1980b), More eﬀective DEMO in the prisoner’s dilemma, Journal of
Conﬂict Resolution, 24, 379-403.
DEMO Axelrod, R. (1984), The evolution of cooperation, New York: Basic Books.
6. Axelrod, R. & Dion, D. (1988), The further evolution of cooperation, Science, 242.
1385-1390.
7. Baron, J. (DEMO), Do no harm, In D. M. Messick & A. E. DEMO (Eds.), Codes
of conduct: Behavioral research into business ethics, DEMO 197-214. New York: Russell
Sage Foundation.
8. Bazerman, M. (1986), Judgment in managerial decision making. New York: Wiley.
9. Bazerman, M. H. (1994), Judgment in managerial decision making. New York:
John Wiley.
10. Bendor, J. (1987), In good times and bad: Reciprocity in an uncertain world, Amer-
ican Journal of Political Science, DEMO, 531-558.
11. Bendor, J., Kramer, R. M., & Stout, S. (1991), When in doubt: Cooperation in the
noisy prisoner’s DEMO Journal of Conﬂict Resolution, 35, 691-719.
12. Bendor, J., Kramer, R. M., & Swistak, P. (1996), Cooperation under uncertainty
(Comment on Kollock), American Sociological Review, 61, 333-338.
13. Cialdini, R. (1993), Inﬂuence: Science and Practice, New York: Harper-Collins.
DEMO Garthoﬀ, R. (1989), Reﬂections on the Cuban Missle Crisis, DEMO, D.C.:
The Brookings Institution.
15. Gigerenzer, G., & Too, P. M. (1999), Simple heuristics that make us smart, Oxford,DEMO
England: Oxford University Press.
16. Jervis, R. (1976), Perception DEMO misperception in international politics, Princeton,
NJ: Princeton University Press.
17. Kramer, R. M. (1996), Divergent realities and convergent disappointments in DEMO
hierarchic relation: The intuitive auditor at work, In R. M. Kramer and T. R. Tyler
(Eds.), Trust in organizations: Frontiers of DEMO and Research. Thousand Oaks:
Sage Publications.
18. Kramer, R. M. (1998), Paranoid cognition in social systems, Personality and Social
Psychology Review, 2, 251-275.
19. Kramer, R. M. (2001), Trust and DEMO as adaptive orientations in trust dilem-
mas, Unpublished manuscript.
20. Kramer, R. M. (1999), Trust and distrust in organizations: Emerging perspectives,DEMO
enduring questions, Annual Review of Psychology, 50, 569-598.
21. Kramer, R., Meyerson, D. & Davis, G. (1990), How much DEMO enough? Psychological
components of ‘guns versus butter’ decisions in a security DEMO, Journal of
Personality and Social Psychology, 58, 984-993.
22. Kramer, R., Newton, E., & Pommerenke, P. (1993), Self-enhancement biases and
negotiator judgment: Eﬀects of self-esteem and mood, Organizational Behavior and
DEMO Decision Processes, 56, 110-133.
23. Kramer, R., Pommerenke, P., & Newton, E. (1993), The social context of nego-
tiation: Eﬀects of social identity and accountability on negotiator judgment and
decision making, Journal of Conﬂict Resolution, 37, 633-654.
24. March, J. G., DEMO, M, & Zhou, X. (2000), The dynamics of rules: Change in
written organizational codes, Stanford, CA: Stanford University Press.
26 Roderick M. Kramer
25. Molander, P. (1985), The optimal DEMO of generosity in a selﬁsh, uncertain envi-
ronment, Journal of Conﬂict Resolution, 29, 611-618.
26. Novak, M. & Sigmund, K. (1992), Tit-for-Tat in heterogeneous populations Nature,
355, 250-253.
27. Novak, DEMO & Sigmund, K. (1993), A strategy of win-stay, lose-shift DEMO outperforms
tit-for-tat in the prisoner’s dilemma game, Nature, 364, 56-58.
DEMO Opotow, S. (1990), Deterring moral exclusion, Journal of Social DEMO 46, 173-182.
29. Ostrom, E. (1998), A behavioral approach DEMO the rational choice theory of collective
action, Presidential address, American Political Science Association, 1997. Ameri-
can Political Science Review, 92, 1-22.
30. Ross, L. (1977), The intuitive psychologist and his shortcomings, In L. Berkowitz
(Ed.). Advances in experimental social psychology, 10. New DEMO: Academic Press.
31. Thompson, L. (1998), The mind and DEMO of the negotiator, Upper Saddle River,
NJ: Prentice Hall.
32. Watson, J. (1980), The double helix: A personal account of the discovery of the
structure of DNA, (Norton Critical Edition). DEMO York: W. W. Norton.
33. Wilson, J. Q. (1993), DEMO moral sense, New York: Free Press.
34. Wu, J., & Axelrod, R. (1997), Coping with noise: How to cope with noise in the
iterated prisoner’s dilemma, In R. Axelrod (Ed.), DEMO complexities of cooperation.{1g42fwefx}