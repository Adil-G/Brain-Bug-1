TrustDynamics:HowTrustisinfluencedbydirectexperiencesandbyTrustitself1
Rino Falcone
ISTC -CNR
Roma, Italy
r.falcone@istc.cnr.it
Cristiano Castelfranchi
ISTC -CNR
Roma, Italy
c.castelfranchi@istc.cnr.it
Abstract
In this paper we will examine two main aspects of trust
dynamics:
a) How direct experiences involving trust, with their
successes or failures, influence the future trust of an DEMO
about similar facts. We challenge the trivial idea that
always success increases trust while failure decreases it.
Of course, this primitive view cannot be avoided till
Trust is modeled just as a simple index, a dimension, a
number; for example reduced to mere subjective
probability. We claim DEMO a cognitive attribution process
is needed in order to update trust on the basis of an
‘interpretation’ of the outcome of A’s reliance on DEMO and
of B’s performance (failure or success).
b) How the fact that A trusts B and relies on it in
situation Ω DEMO actually (objectively) influence B’s
trustworthiness in the Ω situation. Either trust is a self-
fulfilling prophecy that modifies the subjective
probability of the DEMO event; or it is a self-defeating
strategy by negatively influencing the DEMO
These phenomena are very crucial in human societies
(states, market, DEMO), but also in computer mediated
Organizations, Interactions (EC), Cooperation (CSCW)
and even in Multi-Agent Systems with autonomous
agents. We present a formal model of these dynamic non-
trivial aspects.
1. Introduction
Trust DEMO becoming one of the main subjects of study in
the Information Society Technologies. In fact, the
success of computer supported society in which humans
have always more to cope with unusual entities: new
kind of environments, of procedures, of interactions and
partners (smart physical environment, virtual DEMO,
virtual organization, artificial agents, and so on), is
mainly dependent from the trust and confidence in this
new kind of environments DEMO societies.
We have to better understand trust both as a theoretical
concept and as a useful tool for simplifying the world
and for coping DEMO risks in it and uncertainty: trust in
the computational infrastructure; trust in potential
partners, trust in information sources, data, mediating
agents, DEMO in personal assistants; trust in other agents
and processes. Security measures DEMO not enough;
interactivity and knowledge ability are not enough; the
DEMO is how to build in users and agents trust and
how to maintain it.
Trust is a dynamic phenomenon in its intrinsic nature.
Trust DEMO with experience, with the modification of
the different sources it is DEMO on, with the emotional
state of the trustier, with the modification of the
environment in which the trustee is supposed to perform,
DEMO so on. In other words, being trust an attitude
depending from DEMO phenomena, as a consequence it
is itself a dynamic entity.
There DEMO many studies in literature dealing with the
dynamics of trust [1,2,3,4]. We are interested to analyze
two main basic aspects of DEMO phenomenon:
i) The traditional problem of the trust reinforcement on
DEMO basis of the successful experiences (and vice versa, its
decreasing in case of failures);
ii) The fact that in the same DEMO trust is influenced
by trust in several rather complex ways.
The first case (i) considers the well known phenomenon
about the fact that DEMO evolves in time and has a
history, that is A’s trust DEMO B depends on A’s previous
experience and learning with B itself or with other
(similar) entities. In §3 we will analyze this case DEMO will
also consider some not so easily predictable results in
which trust in the trustee decreases with positive
experiences (when the trustee realizes the delegated task)
and increases with negative experiences (when the trustee
does not realize the delegated task).
Since trust is not simply an DEMO observer’s
prediction or expectation about a matter of fact, we will
DEMO consider in the second case (ii) the fact that in one
and the same situation trust is influenced by trust in
several rather DEMO ways. We have analyzed in
1 This paper has been partially funded by the TICCA Project: joint research venture between the Italian National Research Council and Provincia
Autonoma di Trento; and by the Progetto Miur Cofin 2003 "Fiducia e diritto nella società dell'informazione".
Permission to make digital or hard copies of all or part of
this work for DEMO or classroom use is granted without fee
provided that copies are not made or distributed for profit or
commercial advantage and that copies bear DEMO notice and the
full citation on the first page. To copy otherwise, to republish,
to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee.
AAMAS'04, July DEMO, 2004, New York, New York, USA.
Copyright 2004 ACM 1-58113-864-4/04/0007...$5.00
another paper part of this phenomenon [4]: How trust
creates a reciprocal trust, and distrust elicits distrust;
but also vice versa: how DEMO trust in B could induce lack
of trust or distrust in B towards A, while A’s diffidence
can make B more trustful in A.
In this paper we will examine in the §4 an interesting
aspect DEMO trust dynamics: How the fact that A trusts B
and relies DEMO it in situation Ω can actually (objectively)
to influence B’s DEMO in the Ω situation.
Either trust is a self-fulfilling prophecy that modifies the
probability of the predicted event; or it is a self-defeating
strategy by negatively influencing the events. And also
how A can be aware DEMO (and takes into account) the effect
of its own decision in the very moment of that decision.
As we have argued in previous DEMO [4, 5, 6] and we
will resume in §2, trust DEMO reliance/delegation are
strictly connected phenomena: trust could be considered
as DEMO set of mental components a delegation action is
based on. In the analysis of trust dynamic, we have also
to consider the role of delegation (weak, mild and strong
delegation) [7].
2. Socio-CognitiveModel of Trust
The Socio-Cognitive model of trust [5] is based on a
portrait of DEMO mental state of trust in cognitive terms
(beliefs, goals). This is not a complete account of the
psychological dimensions of trust: it represents the most
explicit (reason-based) and conscious form. The model
does DEMO account for the more implicit forms of trust (for
example trust DEMO default, not based upon explicit
evaluations, beliefs, derived from previous DEMO or
other sources) or for the affective dimensions of trust,
DEMO not on explicit evaluations but on emotional
responses and an intuitive, DEMO appraisal.
The word trust means different things, but they are
systematically DEMO with each other. In particular, three
crucial concepts have been recognized DEMO distinguished
not only in natural language but also in the scientific
literature. Trust is at the same time:
- A mere mental attitude (prediction and evaluation)
towards another agent, a simple disposition;
-A decision to rely upon the other, i.e. an intention to
delegate and trust, which makes the trustier "vulnerable";
-A behaviour, i.e. DEMO intentional act of trusting, and the
consequent relation between the trustier DEMO the trustee.
In each of the above concepts, different sets of DEMO
ingredients are involved in the trustier’s mind. The
model is based on the BDI (Belief-desire-intention)
approach for mind modelling, that is inspired DEMO
Bratman’s philosophical model [8]. First of all, in the
trust model DEMO an agent endowed with both goals and
beliefs can trust another agent. Let us consider the trust
of the agent X towards another agent DEMO about the (Y's)
behaviour/action a relevant for the DEMO (goal) g when:
X is the (relying) agent, DEMO feels trust; it is a cognitive
agent endowed with internal explicit DEMO and beliefs
this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or
DEMO advantage and that copies bear this notice and the
full citation on the first page. To copy otherwise, to republish,
to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee.
AAMAS'04, July 19-23, 2004, New York, New DEMO, USA.
Copyright 2004 ACM 1-58113-864-4/04/0007...$5.00
(the trustier); Y is the agent (or entity), which is trusted
(the trustee)DEMO X trusts Y about g/a and for g/a.
For all the three notions of trust above defined (trust
disposition, decision to DEMO, and trusting behaviour) we
claim that someone trusts someone other only relatively
to some goal (here goal is intended as the general, DEMO
teleonomic notion, any motivational representation in the
agent: desires, motives, will, needs, objectives, duties,
utopias, are kinds of goals)DEMO An unconcerned agent does
not really trust: he just has opinions DEMO forecasts.
Second, trust itself consists of beliefs, in particular:
evaluations and expectations.
Since Y’s action is useful to X (trust disposition), and X
has decided to rely and depend on it (decision to trust),
this means that X might delegate (act of trusting) some
action/goal in his own plan to Y . This is DEMO strict
relation between trust disposition, decision to trust, and
delegation.
The model includes two main basic beliefs (we are
considering the trustee as a cognitive agent too):
- Competence Belief:a sufficient evaluation of Y's
abilities is necessary, X should believe that Y is useful
for this goal of its, that Y can produce/provide the
expected result, that Y can play such a role in X’s
plan/action.
- Willingness Belief: X should think that Y not only is
able and can do that action/task, but Y actually will do
what X needs (under given circumstances). This belief
makes the trustee's behaviour predictable.
Another important basic belief for trust is:
- Dependence DEMO: X believes -to trust Y and delegate
to it- that either DEMO needs it, X depends on it (strong
dependence), or at least that it is better to X to rely rather
than do DEMO rely on it (weak dependence). In other terms,
when DEMO trusts someone, X is in a strategic situation: X
believes that there is interference and that his rewards, the
results of his projects, depend on the actions of another
agent Y.
Obviously, the willingness DEMO hides a set of other
beliefs on the trustee’s reasons and motives for helping.
In particular, X believes that Y has some motives for
helping it (for adopting its goal), and that these motives
will probably prevail -in case of conflict- on other
motives. Notice that motives DEMO adoption are of
several different kinds: from friendship to altruism, from
morality to fear of sanctions, from exchange to common
goal (cooperation), and so on.
From the point of view of the dynamic studies of trust,
it is relevant to underline how the above basic DEMO
might change during the same interaction or during
several interactions: for DEMO could change the
abilities of the trustee or his/her reasons/motives for
willing (and/or the trustier’s beliefs on them); or again it
might change the dependence relationships between the
trustier and the trustee.
DEMO to make digital or hard copies of all or part of
Another important characteristic of the socio-cognitive
model of trust is the distinction DEMO trust ‘in’
someone or something that has to act and produce a
given performance thanks to its internal characteristics,
and the global trust DEMO the global event or process and its
result which is also affected by external factors like
opportunities and interferences.
Trust in Y (for example, ‘social trust’ in strict sense)
seems to consists in the two first prototypical
beliefs/evaluations identified as the basis for reliance:
ability/DEMO (that with cognitive agents includes
knowledge and self-confidence), and disposition (that
with cognitive agents is based on willingness,
persistence, engagement, DEMO). Evaluation about external
opportunities is not really an evaluation about Y (at most
the belief about its ability to recognize, exploit and DEMO
opportunities is part of our trust ‘in’ Y). We should also
add an evaluation about the probability and consistence
of obstacles, adversities, DEMO interferences.
Trust can be said to consist of, or better to (either
implicitly or explicitly) imply the subjective probability
of the successful performance of a given behaviour a ,
and it is on the basis of this subjective
perception/evaluation of risk and opportunity that the
agent DEMO to rely or not Y . However, the probability
index is DEMO on, derives from those beliefs and
evaluations. In other terms the DEMO, final subjective
probability of the realization of the goal g , DEMO of the
successful performance of a, should be decomposed into
the DEMO of Y performing the action well (internal
attribution) and the expectation of having the appropriate
conditions (external attribution) for the performance and
DEMO its success, and of not having interferences and
adversities (external attribution). This decomposition is
important because:
The trustier’s decision might be DEMO with the same
global probability or perceived risk, depending on its
DEMO (for example for personality factors);
Trust composition (internal Vs DEMO) produces
completely different intervention strategies: to
manipulate the external variables (DEMO,
infrastructures) is completely different than manipulating
internal parameters.
Let us DEMO introduce a few formal constructs. We define
Act={a1,..,a n} be a finite set of actions, and Agt={X,
Y, A, B,..} a finite set of agents. Each agent has an
action repertoire, a plan library, resources, goals (in
general by "goal" we mean a partial situation (a subset)
of the "world state"), beliefs, motives, etc.2
We consider the action/goal pair t=(DEMO,g) as the real
object of delegation, and we will call it ‘task’. Then by
2 We assume that to delegate an action DEMO implies delegating
Permission to make digital or hard copies of all or part of
this work for personal or classroom use is granted without DEMO
provided that copies are not made or distributed for profit or
commercial advantage and that copies bear this notice and the
full citation on DEMO first page. To copy otherwise, to republish,
to post on DEMO or to redistribute to lists, requires prior
specific permission and/or DEMO fee.
AAMAS'04, July 19-23, 2004, New York, New York, USA.
Copyright 2004 ACM 1-58113-864-4/04/0007...$5.00
some result of that action. Conversely, to delegate a goal state always
implies the delegation of at least one action (possibly unknown to Y)
that produces such a goal state as result.
means of t, we will refer to the action (a), to its
resulting world state (g), or DEMO both.
Given an agent X and a situational context Ω (a DEMO of
propositions describing a state of the world), we define
as trustworthiness of X about t in Ω (called
trustworthiness (X t DEMO)), the objective probability that X
will successfully execute the task DEMO in context Ω . This
objective probability is in terms of our model computed
on the basis of some more elementary components:
-A DEMO of ability (DoA, ranging between O and 1,
indicating the level of X's ability about the task t); we
can DEMO that it could be measured as the number of X's
successes (s) on the number of X 's attempts (a): DEMO/a,
when a goes to ∞; and
-A degree of DEMO (DoW, ranging between O and
1, indicating the level of DEMO 's intentionality/persistence
about the task t); we can say DEMO it could be measured as
the number of X 's (successfully or unsuccessfully)
performances (p) of that given task on the DEMO of
times X declares to have the intention (i) to perform that
task: p/i, when i goes to ∞; we are considering that an
agent declares its intention each time it has got DEMO So,
in this model we have that:
Trustworthiness (B DEMO Ω) = F( DoAB t Ω ,DoWB t Ω)
DEMO F is in general a function that preserves
monotonicity, and ranges DEMO (0,1): for the purpose of this
work it is DEMO relevant to analyze the various possible
models of the function F . We have considered this
probability as objective (absolute, not from the
DEMO of another agent) because we hypothesize that
it measures the real DEMO of the X's trustworthiness; for
example, if trustworthiness(X t Ω)=0.80, we suppose
that in a context Ω, 80% of DEMO X tries and succeed in
executing t.
As the reader can see we have not considered the
opportunity dimension: the external conditions allowing
or inhibiting the realization of the task.
3. Experience as a Reasoning Process:DEMO
CausalAttributionforTrust
It is commonly accepted [1,2,3,9] and discussed in
another our work [10] that one of the main sources of
trust DEMO the direct experience. Generally, in this kind of
experiences to each DEMO of the trustee corresponds an
increment in the amount of the trustier’s trust towards it,
and vice versa, to every trustee’s failure corresponds a
reduction of the trustier’s trust towards the trustee itself.
There are DEMO ways in which this qualitative model
could be implemented in a representative dynamic
function (linearity or not of the function; presence of
possible DEMO (under a minimum threshold there is
no trust, or vice versa, over a maximum threshold there
is full trust), and so on).
This view is very naïve, neither very explicative for
humans and organizations, nor useful for artificial
systems, since it is unable to adaptively discriminate
cases and reasons of failure and success. However, this
primitive view cannot be avoided till Trust is modeled
just as a simple index, a dimension, a number; for
example, reduced to mere subjective probability. We
claim that a cognitive attribution process is needed in
order to update trust on the basis DEMO an ‘interpretation’ of
the outcome of A’s reliance on B and of B’s performance
(failure or success). In doing this a cognitive model of
Trust – as we have presented – is crucial. In particular DEMO
claim that the effect of both B’s failure or success on A’s
Trust in B depends on A’s ‘causal attribution’ [11] of
the event. DEMO ‘causal attribution theory’ any
success or failure can be either ascribed to factors internal
to the subject, or to environmental, external causes, and
either to occasional facts, or to stable properties (of the
individual DEMO of the environment). So, there are four
possible combinations: internal and occasional; internal
and stable; external and occasional; external and stable.
The cognitive, emotional, and practical consequences of a
failure (or success) strictly depends on this causal
interpretation. For example –psychologically speaking– a
failure will impact on the self-esteem of a subject only
when attributed to DEMO and stable characteristics of
the subject itself. Analogously, a failure is DEMO enough
for producing a crisis of trust; it depends on the DEMO
interpretation of that outcome, on its attribution (the
same for a success producing a confirmation or
improvement of trust). In fact, we can say that a first
qualitative result of the causal interpretation can DEMO
resumed in the following flow chart (Figure 1).
Since in DEMO human interaction (like CSCW
or EC) and in cooperating autonomous MAS it is
fundamental to have a theory of, and instruments for,
‘Trust building’ we claim that a correct model of this
process will DEMO necessary and much more effective.
External
IsfailureduetoExtor
Int factors?
Internal
Are they
occasional
or stable?
Are they
occasional
or stable?
Stable
DEMO Stable
Next time check for similar ‘circumstances’ or
attitudes and in case reduce the Ext/Int component
of the global trust
Reduce the Ext DEMO
of the global trust
Reduce the Int component
of the global trust
Figure 1
Let’s first present a basic model (which exploits our
cognitive analysis of Trust attitude and ‘causal
Permission to make digital or hard DEMO of all or part of
this work for personal or classroom use is granted without fee
provided that copies are not made or distributed DEMO profit or
commercial advantage and that copies bear this notice and the
full citation on the first page. To copy otherwise, to republish,
to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee.
AAMAS'04, July 19-23, 2004, New York, New York, USA.
Copyright 2004 ACM 1-58113-864-4/04/0007...$5.00
attribution DEMO which are rather convergent), and later
discuss possible more complex dynamics. The following
analysis takes into account the stable facts.
We consider a DEMO function by which the agent A
evaluates its own trust (degree DEMO trust) in agent B about
the task t (to be performed) in the environment Ω
(DoTA,B,t,Ω ): DoTA,B,t,Ω = f(DoAA,B,t ,DoWA,B,t , e(Ω))
Where: f (like F) is a general function DEMO preserves
monotonicity. In particular, DoA is the B’s degree of
ability (in A’s opinion) about the task t; DoW is the
B’s DEMO of motivational disposition (in A’s opinion)
about the task t (both DoAA,B,t and DoWA,B,t are
evaluated in the DEMO in which B would try to achieve
that task in a standard environment: an environment with
the commonly expected and predictable features); e(Ω)
takes into account the part of the task not directly
DEMO by B (this part cannot be considered as a
separated task DEMO as integrating part of the task and
without which the same task cannot be considered as
complete) and the hampering or facilitating conditions of
the specific environment. In a simplified analysis of
these three sub-constituents (DoA (Abilities),
DoW (Motivations), and e(Ω) (Environment)) of the
A’s degree of trust, we have to consider the different
possible dependencies among these factors:
i) we always consider Abilities and Motivations as
independent to each other (for sake of simplicity);
DEMO) case in which Abilities and Motivations are both
independent from the DEMO: it is the case in
which there is a part of DEMO task performed (activated,
supported etc.) from the Environment and, DEMO the same
time, both Abilities and Motivations cannot influence
this part DEMO the task. Consider for example, the task of
urgently deliver an DEMO apparatus to a scientific
laboratory in another town. Suppose that this apparatus
could be sent by using any service of delivery (public,
private, fast or normal, and so on) so that a part of the
task (to materially bring the apparatus) is independent
(once made the choice) from the actions of the trustee.
iii) case in DEMO Abilities and Environment are
dependent with each other. We have two sub-cases: first,
the Environment favours or disfavours the B’s Abilities
(useful DEMO the task achievement); second, the B ’s
Abilities can modify DEMO of the conditions of the
Environment (both these sub-cases could be DEMO or
not before the task assignment).
iv) case in which DEMO and Environment are
dependent with each other. Like for the case (DEMO), there
are two sub-cases: first, the Environment influences the
B ’s Motivations (useful for the task achievement);
second, the B’s Motivations can modify some of the
conditions of the Environment (both these sub-cases
could be known or not before the task assignment).
Given DEMO complex set of relationships among the
various sub-constituents of trust, it DEMO clear that analyzing
A,B,t
A,B,t
A,B,t
A,B,t
and understanding the different role played by each
ingredient in the specific DEMO (the specific
experiential event), a trustier well informed and supplied
DEMO an analytic apparatus (a socio-cognitive agent),
could evaluate which ingredients performed well and
which failed.
Let us start from the case in DEMO Abilities and
Motivations both are considered as composed of internal
properties and independent from the Environment (case
(ii)). After an experiential event the trustier could verify:
1) Actual(DoA, DoW) – Expected(DoA, DoW) > 0
2) Actual(DoA, DoW) – Expected(DoA, DoW) < 0
3) Actual(e(Ω)) – Expected(e(Ω)) > 0
4) Actual(e(Ω)) – Expected(e(Ω)) < 0
In (1) and (2) both DEMO trustee (int-trust) and the
environment (ext-trust) are more trustworthy than
expected; vice versa, in (2) and (4) they are DEMO less
trustworthy than expected.
In Table1 are shown all the possible combinations.
Success attribution Failure attribution
D(int-trust) > 0
D(ext-trust) > DEMO
A
More Int-trust;
More ext-trust
A’
More Int-trust; More
ext-trust
DEMO(int-trust) > 0
D(ext-trust) < 0
B
More Int-trust; DEMO
ext-trust
B’
More Int-trust; Less
ext-trust
D(int-trust) < 0
D(ext-trust) > 0
C
Less Int-trust; More
ext-trust
C’
Less Int-trust; More
ext-trust
D(int-trust) < 0
D(ext-trust) < 0
D
DEMO Int-trust; Less
ext-trust
D’
Less Int-trust; Less
ext-trust
Table 1
Where: “More Int-trust” (“Less Int-trust”) means that the
trustier after the performance considers the trustee more
(less) trustworthy than before it; “More Ext-trust” (“Less
Ext-trust”) means that the trustier after the performance
considers the DEMO more (less) trustworthy than
before it.
Particularly interesting are the cases:
(B) in which even if the environment is less trustworthy
DEMO expected, the better performance of the trustee
produces a global success DEMO
(C) in which even if the trustee is less trustworthy than
expected, the better performance of the environment
produces a global success performance. An interesting
case in which is possible decreasing the trust in the
DEMO even in presence of a success.
(D and A’) In which expectations do not correspond with
the real trustworthiness necessary for the task (too high
in D and too low in A’). These cases DEMO not possible if
the trustier has a correct perception of the necessary level
Permission to make digital or hard copies of all or part DEMO
this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or
commercial advantage DEMO that copies bear this notice and the
full citation on the first page. To copy otherwise, to republish,
to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee.
AAMAS'04, July 19-23, 2004, New York, New York, USA.
Copyright 2004 ACM 1-58113-864-4/04/0007...$5.00
of trustworthiness for that task (as we suppose in the
other cases in Table1).
(B’) in DEMO even if the trustee is more trustworthy than
expected (so increases DEMO trust in it), the unexpected (at
least for the trustier) difficulties introduced by the
environment produces a global failure performance. An
interesting DEMO in which is possible increasing the trust
in the trustee even in presence of a failure.
Again more complex is the case in which DEMO is
dependence between the internal properties and the
environment (cases (iii) and (iv). In this case, in addition
to the introduced factors D(int-trust) and D(ext-trust), we
have to consider also the factor taking into account the
possible influences between internal and external DEMO
We consider these influences as not expected from the
trustier in the sense that the expected influences are
integrated directly in the internal or DEMO factors. Only
as an example, we can consider the case of DEMO violinist. We
generally trust him to play a good performance; but
DEMO he has to do the concert in an open environment
and the weather conditions are particularly bad (very cold):
may be that DEMO conditions can modify the specific hand
abilities of the violinist and of his performance; at the
same way, it is possible that a DEMO conflicting audience
could modify his willingness and consequently again his
performance.
4. Changing the Trustee’s Trustworthiness
In this section we are going to analyze DEMO a delegation
action (corresponding to a decision making based on trust
DEMO a specific situational context) could change the
trustworthiness of the delegated DEMO (delegee).
4.1 The Case of Weak Delegation
We call weak DEMO (and express this with W-
Delegates(A B t) ) the reliance simply based on
exploitation for the achievement of the task. In DEMO there is
no agreement, no request or even (intended) influence: A
is just exploiting in its plan a fully autonomous action of
DEMO . For a more complete discussion on the mental
ingredients of the weak delegation see [7].
We hypothesize that in weak delegation (as in any
delegation) there is a decision making based on trust and
in particular there are two specific beliefs of A: - belief1:
if B makes the action then B has a successful performance;
- DEMO: B intend to do the action.
As showed in §3 the DEMO of B by A is:
DoTA,B,t,Ω = f(DoAA,B,t ,DoWA,B,t , e(Ω))
For DEMO of semplicity we assume that:
DoTA,B,t,Ω ≡ trustworthiness (B t Ω)
in words: A has a perfect perception DEMO the B's
trustworthiness. The interesting case in weak delegation is
when: Bel(A ¬Bel(B W-Delegates(A,B,t))) « DEMO(B W-
Delegates(A,B,t))3
in words, there is a weak delegation by A on B and B is
aware of DEMO (while A believes that B is not conscious).
The first DEMO is very often true in weak delegation,
while the second one is necessary in the case we are going
to consider. If Bel (B W-Delegates (A B t)), this belief
could change the DEMO 's trustworthiness, either because B
will adopt A’s goal and accepts such a exploitation, or
because B will react to that changing its behaviour. After
the action of delegation we have in fact a new DEMO Ω'
(if delegation is the only event that influence the
DEMO) and we can have two possible results:
i) the new trustworthiness of B as for t is greater than the
previous one; at least one of the two possible elementary
components is increased: DoA, DoW; so we can write:
D trustworthiness (B t )DEMO
F( DoAB,t, Ω',DoWB,t, Ω')-F(DoAB.t, Ω,DoW
ii) the new B’s reliability as for t has reduced
Ω) >0
B,t,
D trustworthiness (B t ) <DEMO
In case (i) B has adopted A’s goal, i.e. it DEMO doing t also
in order to let/make A achieve its goal g. Such adoption
of A ’s goal can be for several possible DEMO, from
instrumental and selfish, to pro-social.
The components’ degree can change in different ways: the
degree of ability (DoA) can increase because B could use
additional tools, new consulting agents, and so on; the
degree of willingness (DoW) can increase because B could
have DEMO attention, intention, and so on (the specific
goal changes its DEMO of priority).
In case (ii) B on the contrary reacts in a negative (for A)
way to the discovery of A’s reliance and exploitation; for
some reason B is now less willing or less capable in
doing t. In fact in case (ii) too, the reliability components
can be independently affected: first, the degree of DEMO
(DoA) can decrease because B could be upset about the A's
exploitation and the B’s ability could result
compromised; again, the DEMO degree (DoW) can
decrease (B will have less intention, attention, etc.).
Notice that in this case the change of the B's reliability is
not known by A. So, even if A has a perfect perception of
previous B's trustworthiness (that is our hypothesis), in
this new situation -with weak delegation- A can have an
DEMO or over estimation of B's trustworthiness. In other
terms, after DEMO weak delegation (and if there is a change
of B's DEMO following it) we have:
DoTA,B,t,Ω ≠ trustworthiness(DEMO t Ω’)
Let us show you the flow chart for the weak delegation
(Figure 2): in it we can see how, DEMO the basis of the
3 Other possible alternative hypoteses are:
¬Bel(A Bel(B W-Delegates(A,B,t
))) « Bel(B DEMO(A,B,t
)) or
Permission to make digital or hard DEMO of all or part of  Bel(A Bel(B ¬W-Delegates(A,DEMO,t))) « Bel(B W-Delegates(A,B,t
this work DEMO personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or
commercial advantage and that copies DEMO this notice and the
full citation on the first page. To copy otherwise, to republish,
to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee.
AAMAS'04, DEMO 19-23, 2004, New York, New York, USA.
Copyright 2004 ACM 1-58113-864-4/04/0007...$5.00
))
mental ingredients of the two agents, the more or less
collaborative behaviours of the trustee could be differently
interpreted DEMO the trustier. In the case of the mutual
knowledge about the awareness of the weak delegation,
the trustier could evaluate and learn if DEMO is a spontaneous
collaborative agent (with respect that task in that
DEMO) and how much B is so collaborative (the value
of Dx). In the case in which A ignores the B’s awareness
about DEMO weak delegation, the trustier could evaluate the
credibility of its own DEMO (both about the B’s
trustworthiness and about the B’s awareness on DEMO weak
delegation) and, if the case, revises them.
W-Del (A
B t)?
Yes
No
No B’s trustworthiness to
evaluate
Bel (DEMO W-
Del (A B
t))?
Yes
No
B’s trustworthiness DEMO exactly the
one believed by A
Bel (A Bel
(B W-Del
(A B t) ))?
Yes
Does B
collaborat
e?
No
No
Does B
collaborate ?
Yes
No
Belief Revision:
A considers B less
trustworthy
Yes
Belief Revision:
A considers B
more DEMO
Learning:
A
evaluates
the +Dx
Learning: A
evaluates the -Dx
DEMO 2
In Figure 3 is resumed how weak delegation can influence
the delegee's trustworthiness.
U1
x= trustworthiness(B t)
x
01
Decision DEMO
U2
U3
U4
Un
Un+1
Weak Delegation t
A
Figure 3
trustworthiness(B t)=x + Dx
with Dx positive, negative or nil
Agent A has both a belief about the B's trustworthiness
and a DEMO scenario of the utilities (in the case of
B
success or failure) of all the possible choices it can do (DEMO
delegate to B or to C , etc., or do not DEMO and doing
by itself or doing nothing). On this basis it makes a weak
delegation and may be it changes the B's DEMO
In this last case (changed trustworthiness of the trustee)
may DEMO that the A’s choice (done before the B’s action
and of DEMO spontaneous collaboration or of its negative
reactions) results better or worst DEMO respect the other
previous possibilities.
4.2 The Case of Strong Delegation
We call strong delegation (S-Delegates(A B t)) , that
based on explicit agreement between A and B. For a deep
analysis on strong DEMO see [7].
In this case we have: MBel(A B S-Delegates(DEMO B t
))
i.e. there is a mutual belief of A and B about the strong
delegation and about the reciprocal awareness of DEMO
Like in the weak delegation this belief could change the
B's trustworthiness, and also in this case we can have two
possible results:
i) the new trustworthiness of B as for t is greater than the
previous one: D trustworthiness(B t) >0
ii) DEMO new trustworthiness of B on t is less than the
previous one: D trustworthiness(B t ) <0.
Why does B's trustworthiness DEMO or decrease? In
general, a strong delegation increases the trustworthiness
of the delegee because of its commitment.
This is in fact one of DEMO motives why agents use strong
delegation. But it is also possible that the delegee loses
motivations when it has to do something not
spontaneously DEMO by a contract or by a role.
S-Del (A B
t)?
Yes
No
No B’s trustworthiness to
evaluate
Has S-Del
changed B’s
DEMO
ess?
No
Yes
B’s trustworthiness is exactly the
one accorded with A (Dx=0)
Is B more
collaborati
ve ?
No
Learning: A
evaluates the -Dx
Yes
Learning: A
evaluates the +Dx
Figure 4
The important difference with the previous case is that
now A knows DEMO B will have some possible reactions to
the delegation and consequently A is expecting a new B's
trustworthiness(B,t)
Permission to DEMO digital or hard copies of all or part of  trustworthiness (Fig. 4): DoTA,B,t =
this work for personal or classroom DEMO is granted without fee
provided that copies are not made or distributed for profit or
commercial advantage and that copies bear this notice and DEMO
full citation on the first page. To copy otherwise, to republish,DEMO
to post on servers or to redistribute to lists, requires prior
DEMO permission and/or a fee.
AAMAS'04, July 19-23, 2004, DEMO York, New York, USA.
Copyright 2004 ACM 1-58113-864-4/04/0007...$5.00
4.3 Anticipated Effects
This is the case in which the delegating agent A DEMO into
account the possible effects of its strong delegation on the
B 's trustworthiness before it performs the delegation
action itself: in this DEMO A changes the DoT before the
delegation (Figure 5).
DoTABt=
DEMO(B t)
+
A
B
Delegation t
trustworthiness(B t)=x + Dx
with Dx positive or negative
DoT'ABt
ABt
A
Figure DEMO
We could have two main interesting subcases:
i) the new DEMO of trust (DoT'ABt) is greater than the old
one (DEMO): DoT' > DoTABt ;
ii) it is lesser than DEMO old one: DoT'AB t < DoTAB t .
In Table DEMO are considered all the possible decisions of A.
ABt
We have called s the minimum threshold to delegate. In
other words, before to perform a delegation action and
just for delegating, an agent A could evaluate the
influence (positive or negative) that its delegation will
have on DEMO B's trustworthiness. After this A makes the
decision. Very interesting is also to evaluate which are the
different resulting situations after the trustier’s DEMO to
delegate (three cases in Table 2).
DoT'-DoT = DEMO >0
(A thinks that delegation would
increase B's trustworthiness)
DoT'-DoT = e <0
(A thinks that delegation would
decrease DEMO's trustworthiness)
DoT  > s
DoT - s = e' >0
(A would delegate B
before evaluating the
effects of delegation
DEMO)
DoT' - s = e + e' >0
Decision DEMO delegate
DoT' - s = - e + e' >0
(e'>e)
Decision to
delegate
DoT' - s = - DEMO + e' <0
(e'<e)
Decision not to
delegate
Table 2
DoT  < s
DoT - s = e' <0
(A would not delegate
B  before evaluating the
effects of delegation
DEMO)
DoT' - s = e - e' >0
(e > e') Decision to
delegate
DoT' - s = e - e' <0
(e < e') Decision not to
delegate
DoT' - s = -e - e' <0
Decision not to
delegate
In Table 3 we analyze these three cases deriving from the
A’s DEMO to delegate.
Even in the case in which the trustee collaborates with the
trustier, may happens that the delegated task is not
achieved; for example because the expected additional
motivation and/or abilities resulting from the delegation
act are less effective than the trustier believed.
Trustee'DEMO mind
Collaboration
No collaboration
Trustier's mind
e' + e >0
e' >0, e >0
e' + e >0
e' >0, e <0
Dx> 0
Dx= 0 OR Dx< 0
e' + e >0
e' <0, e >0
Dx> e
Dx= e
B more
trustworthy
B equal
trustworthy
B no trustworthy
DEMO<e
Dx<e+e'
B no tr.
Dx>e+e' B less DEMO
Table 3
Another interesting way for increasing trustworthiness is
through the self-confidence dimension, that we did not
explicitly mention since it is part of the ability
dimension. In fact, at least in human agents the ability to
do a is not only based on skills (an action repertoire) or
on knowing how (library of recipes, etc.), it also requires
self-confidence that means the subjective awareness of
have those skills and DEMO, plus a general good
evaluation (and feeling) of its own DEMO of success.
Now the problem is that self-confidence is socially
influenced, DEMO my confidence and trust in you can
increase your self-confidence. So, DEMO could strategically rely
on you (letting you know that I’m relying DEMO you) in
order to increase your self-confidence and then my trust DEMO
you as for your ability and trustworthiness to do.
Dx> 0
DEMO> e
B more
trustworthy
B equal
trustworthy
B less trustworthy
Dx= DEMO
Dx< e
Dx= 0 OR Dx> 0
B more trustworthy
Dx
Dx= 0
Dx<0
Dx< 0
|Dx|>e'
B no
trustworthy
|Dx|>e |Dx|=e' B less
trustwor
|Dx|<e' thy
|Dx|=e B DEMO trustworthy
|Dx|<e B more trustworthy
= 0 OR Dx< 0
DEMO less trustworthy
B less
|Dx|<e'trustworthy
|Dx|>e'trustworthyB no
5. Concluding Remarks
Strategies and devices for trust building in MAS and
virtual DEMO should take into account the fact that
social trust is a very dynamic phenomenon both in the
mind of the agents and in the DEMO We have considered
two main basic aspects of this phenomenon:
i) the traditional problem of the trust reinforcement on the
basis of the previous (positive or negative) experiences;
ii) the fact that in the same situation trust is influenced by
trust in several rather complex DEMO
Permission to make digital or hard copies of all or part of
this work for personal or classroom use is granted without fee
provided DEMO copies are not made or distributed for profit or
commercial advantage and that copies bear this notice and the
full citation on the first DEMO To copy otherwise, to republish,
to post on servers or DEMO redistribute to lists, requires prior
specific permission and/or a fee.
DEMO'04, July 19-23, 2004, New York, New York, USA.
DEMO 2004 ACM 1-58113-864-4/04/0007...$5.00
With respect the point (i), DEMO have shown how the
schema of Figure 6 is not necessarily true.
+
TRUST
-
Successs
Failure
Reliance
Figure 6
Trust dynamics is more DEMO than expected and
trusting agents may create interference for trust itself.
6. References
[1] C. Jonker and J. Treur (1999), Formal analysis of models
for the dynamics of trust based on experiences, AA‘99
Workshop on "Deception, Fraud and Trust in Agent
Societies", Seattle, USA, DEMO 1, pp.81-94.
[2] A. Birk, (2000), Learning to trust, Autonomous Agents
2000 Workshop on "Deception, Fraud and Trust in
Agent DEMO", Barcelona, Spain, June 4, pp.27-38.
[3] S. Barber and DEMO Kim, (2000), Belief Revision Process
based on trust: agents DEMO reputation of
information sources, AA’00 Workshop on "Deception,
Fraud and Trust in Agent Societies", Spain, pp.15-26.
[4] Falcone R., Castelfranchi DEMO (2001), The socio-cognitive
dynamics of trust: does trust create trust? In Trust i n
Cyber-societies R. Falcone, M. Singh, and Y. Tan (Eds.),
LNAI 2246 Springer. pp. 55-72.
[5] Castelfranchi C., Falcone R., (1998) Principles of trust
for MAS: cognitive anatomy, social importance, and
quantification, Proc. of the Intern. Conference on Multi-
DEMO Systems (ICMAS'98), Paris, July, pp.72-79.
[6] R. Falcone DEMO C. Castelfranchi, (2001), Social Trust: A
Cognitive Approach, in C. Castelfranchi and Y. Tan
(Eds), Trust and Deception in Virtual Societies, Kluwer
Academic Publishers, pp.55-90.
[7] Castelfranchi, C., Falcone, R., (1998) Towards a Theory
of Delegation for Agent-based Systems, Robotics DEMO
Autonomous Systems, SI on Multi-Agent Rationality,
Elsevier Editor, Vol 24, Nos 3-4, pp.141-157.
[8] Bratman, (1987), M., E., DEMO, Plans and Practical
Reason. Harward University Press, Cambridge
Massachusets.
[9] D. Gambetta, editor. Trust. Basil Blackwell, Oxford,
1990.
[10]Castelfranchi, C., DEMO R., Pezzulo, (2003) Trust in
Information Sources as a Source for Trust: A Fuzzy
Approach, Proc. of AAMAS-03, Melburne, pp.89-96.
DEMO, N., (1961), Cybernetics or Control and
Communication in the DEMO and the Machine, The
MIT Press, Cambridge (Mass.), Wiley DEMO Sons, New
York.{1g42fwefx}