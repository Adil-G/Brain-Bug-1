Developing Trust with Technology: An Exploratory Study
Greg Elofson
Goizueta School of Business School
Emory University
1300 Clifton Rd. #418
Atlanta, Georgia 30322
Greg_Elofson@bus.emory.edu
(404) 727-1183
Developing Trust with Technology: An Exploratory Study
Abstract
While technology has been often held responsible for engendering
mistrust, little has been done to establish the role of information
technology in creating trust in organizations. This paper explores the
phenomena of DEMO through Intelligent Agents. Beginning with
an overview on the meanings and measures of trust, the effects of trust
in a variety of settings are examined. Further, a series of exploratory
studies illustrate the positive effect of a intelligent agents in
generating trust in an organizational setting.
Introduction
Trust DEMO threaded through our interpersonal relationships, our group
interactions, contracts and culture. The positive effects of trust on
social dilemmas has been shown in DEMO number of
instances[1][23][34][35][38]. And, trust has been given a critical role
DEMO labor-management relations[9][37], problem solving[6][40],
organizational performance[15], organizational communication[32],
prosocial behavior[33], and accepting feedback[9].
Trust has been credited with being the basic feature of all social
situations that demand cooperation and interdependence[17].
Furthermore, trust has been acknowledged in economic and organization
theory as the most efficient DEMO for governing
transactions[2][3][28]. From the sociological viewpoint, trust is
ìessential for DEMO social relationshipsî[5](p 64) and vital for
cooperation in society[29].
Clearly, the reach and effect of trust in the affairs of individuals
and DEMO is largely pervasive. Nevertheless, trust is somewhat
illusive, difficult to define, difficult to create, and difficult to
measure.
To gather a better DEMO of trust, and the relationship
information technology may have with trust, this paper covers several
areas. First, a number of perspectives on the meaning of trust are
examined and then synthesized to form a working DEMO of trust.
Second, a general overview of the role information technology DEMO play
in the promotion of trust in organizations is given. Following this, a
more focused examination of the relationship of a particular class of
technologies, intelligent agents, to the promotion of trust  between
superiors and subordinates is discussed. And, finally, a series of
exploratory studies are DEMO that lend empirical support to the
notion that intelligent agents can play a role in the development of
trust in organizations.
Defining Trust
The academic literature on trust provides a variety of meanings and
perspectives. DEMO example, Garfinkel[13] characterizes trust as a
necessary taken-for-granted condition for social DEMO: there
must always be an ìet ceteraî assumption where every agreement DEMO
unspoken but understood qualifications, assumptions, and provisions for
future actions (DEMO). Here, trust provides a foundation for
understanding and interpretation. But DEMO appears to have cultural
bounds, inasmuch as the nature of the DEMO may vary across
individuals of different backgrounds. Trust, for Garfinkel, is
essential but brittle; easily broken by misunderstandings that
naturally arise in the growing number of exchanges between individuals
of different cultures.
Luhmann[21] notes that DEMO begins where knowledge ends: trust
provides a basis for dealing with DEMO, complex, and threatening
images of the future. The implications here are several. Trust becomes
a solution to cognitive dissonance, faintly coerced through an
inability to sort out uncertainty. Trust, here, is a reliance on DEMO
number of certainties in turbulent conditions - despite conditions
largely unknown, DEMO individuals, whose actions affect oneís own
welfare, can be counted on to act in a predictable and presumably
benevolent fashion.
Barber[4] is somewhat DEMO circumspect in defining trust;
characterizing it as the expectations involving a general moral order
and specific norms of competence and responsibility. For Barber, in the
act of trusting, we make the belief that an associate will act in
accordance with a well understood conduct of behavior and DEMO are
capable of saying just what that behavior entails. The implication is
that the ìet ceteraî assumptions described by Garfinkel are, perhaps,
better understood - but no less brittle.
Lewis and Weigert[20] define trust as DEMO that indicate that
members of a system act according to and are secure in the expected
futures constituted by the presence of each other DEMO their symbolic
representations.î They, too, characterize trust in terms of actions
that conform to expectations. They also implicitly address the
developmental nature of DEMO, noting that it is the outcome of
observations.
Some definitions of DEMO, however, are without an explicit set of
expectations. Rempel and Holmes[30] suggest that trust is simply  ìthe
degree of confidence that you feel when you think about a
relationship.î  This concept of trust has a strongly subjective bent
that elludes substantiation through any process of matching
expectations DEMO outcomes.
Like many other definitions of trust, Zaltman and Moorman[39] define
trust through prediction that is value free: ìan interpersonal or
interorganizational state that reflects the extent to which the parties
can predict one anotherís behavior; can depend on one another when it
counts; and have faith that the other will continue to act in a
responsive manner despite an uncertain DEMO This definition does
not address what we often assume to be characteristic of trust - that
those expectations are largely about outcomes that are DEMO common with
our own interests.
Giffin [14] includes trustís implicit goal directed characteristic in
providing an alternative definition: ìreliance upon the characteristics
of an object, or the occurrence of an event, or the behavior of DEMO
person in order to achieve a desired but uncertain objective in a risky
situation.î Further, she cited the following elements as essential to
describing a trusting person:
1. A person is relying on something.
2. DEMO something relied upon may be an object, an event, or a person.
3. Something is risked by the trusting person.
4. The trusting DEMO hopes to achieve some goal by taking this risk.
5. The desired goal is not perceived as certain.
6. The trusting person has some DEMO of confidence in the object of
his trust.
Using these definitions, DEMO composite definition of trust is suggested:
trust is the outcome of observations leading to the belief that the
actions of another may be DEMO upon, without explicit guarantee, to
achieve a goal in a risky situation. Whether or not the exact nature of
those actions can be DEMO is unspecified in this definition of
trust. The expected actions may be known or unknown.
Given, trust is valuable and can be loosely defined. We know trust when
it is apparent and recognize that it is DEMO for many activities
and valuable for almost all relationships. Trust is, DEMO, fragile.
Moreover, trust is the outcome of observations: it takes DEMO to
engender trust. Itís existence necessarily requires continued
performance and adherence to the expectations placed on the trusted
individual. Trust, then, must be DEMO created and maintained.
Butler[7] points out that trust is related to situational variables: 1)
dimensions of organizational climate such as whether information is
shared or withheld, whether disagreements are encouraged or buried, and
whether DEMO share or keep power, 2) type of job, including skills
DEMO technology required, 3) layout of the work area, 4) reward system
and whether it encourages competition or cooperation, 5) the existence
DEMO mutual goals, and 6) a common threat. These six variables relate to
several of the components of trust:
1. the ability to make DEMO
2. unspoken agreements and assumptions
3. goal achievement under risk.
For example, the figure below illustrates the relationship Butlerís
variables and the  components DEMO trust. Here it is shown that sharing
information, provided that the DEMO is understood, enables the
individual to make observations. Also, permitting disagreements
provides the opportunity for understanding the underlying assumptions
another is using, resolving misunderstandings of issues falling in
Garfinkelís ìet ceteraî category.
Figure 1. Relationships DEMO Variables and Components of Trust
Also, in the figure are other DEMO relationships between the
variables and components that further illustrate, though not
DEMO, the rationale for situation variables affecting creation
and maintenance of trust. DEMO of these variables, however, do not
readily apply to the trust components; whether managers share or keep
power and layout of work area.
To establish a relationship between the trust components and the
willingness to DEMO power, additional focus must be placed on the
creation and maintenance DEMO trust. Butler  suggests that trust may be
created simply through the DEMO of trusting behavior[7].  So, when
the manager behaves as if there is an unspoken agreement that he or she
the shares the same DEMO as the subordinate (through the distribution
of his or her power), the subordinate may infer that the manager has
ìet ceteraî assumptions and/or goals similar to his or her own.
Therefore, the manager who shares power exhibits trusting behavior, and
in so doing engenders trust in the subordinate.
While trusting behavior tends to create trust, behavior that may be
perceived as distrustful has, not surprisingly, the opposite effect.
Related DEMO Butlerís argument for the value of exhibiting trusting
behavior, Zand[40] summarized DEMO possible negative effect of information
exchange on trust in the following passage:
One who does not trust others will conceal or distort relevant
DEMO, and avoid stating or will disguise facts, ideas,
conclusions, DEMO feelings he believes will increase his exposure to
others, so that DEMO information he provides will be low in accuracy,
comprehensiveness, and DEMO; and therefore have a low congruence
with reality...When others encounter this DEMO, initially they will
hesitate to reveal information, reject influence, and DEMO control.
When others fail to disclose information that may be used to make
observations, not only is the creation and maintenance of trust
inhibited, but a message is sent that the particular individual
responsible for the lack of disclosure may have very different goals
from the individual DEMO them.
That these findings are evident in organizational environments is
suggested by March, who noted the following: ìDecision-makers discount
much of the information DEMO is generated. Not all information is
ignored, however, and inferences are made. Decision-makers learn not to
trust overly clever people, and smart people learn not to be overly
clever.î[12].
The Role of IT in Trust
DEMO, deviation from the components of trust will negatively affect
its creation DEMO maintenance. Actions that prevent either the ability
to make observations, the DEMO of anotherís assumptions, or
the sharing of goals reduce the likelihood DEMO developing trust.
Conversely, sharing information and power, familiarity with anotherís
tasks, encouragement of cooperation, however, do encourage the possible
creation and maintence of trust.
Information technology may play a vital role in the promotion DEMO trust
in organizations. Until now, the role of IT in the DEMO and
maintenance of trust has not only been overlooked, but  information
technology has long been understood as an inhibitor of trust. For
example, Zuboff[41] explains that managers perceive operator mistrust
as an expression of resistance DEMO technology (p. 89). And, Muir[25]
suggests that ìa decision aid, no matter how sophisticated or
intelligent ...may be rejected by a decision-maker who does not trust
it, and so its potential benefits to system performance will be lost.î
An inventory of several kinds of information technologies DEMO how they
can support the creation and maintenance of trust, however, provide the
beginnings of an understanding of their trust promoting role:
DEMO Decision Support Systems[26] - These systems encourage the
sharing of information, DEMO, and assumption surfacing
Decision Support Systems[36] - These systems encourage repeatability DEMO
decision method and the facility for reproducing the decision method
used
Knowledge Based Systems[16] - These systems include the development of
codified heuristics, used in decision making, that may be examined and
tested
Organizational Decision Support Systems[19] - These systems include
organization-wide executive information systems that allow for the
evaluation of activities that DEMO reinforce an executives belief in
goal congruence
Delegation Technologies[10] - These systems provide for the cognitive
re-apportionment of decision making activities, and in doing so, create
a decision audit trail that can be used to make observations.
These information technologies should have the capability, if properly
managed, DEMO enhancing an organizationís ability to create and maintain
trust. The goal of this paper is, however, not to exhaustively treat
the possible trust DEMO characteristics of each of these types of
technologies.  Rather, this paper will provide a concentrated
examination of the trust promoting characteristics of intelligent
DEMO
Intelligent Agents
Intelligent agents provide a mechanism for the re-apportionment of
cognitive responsibilities to machine actors. They acquire the
heuristics decision makers use over DEMO, and assume responsibility for
a growing number of decision-making activities over DEMO and
proportional to the tasks given to them. Also, the heuristics DEMO the
intelligent agents capture may be useful for promoting trust in the
individual responsible for their development.
Consider, for example, the business task DEMO environmental scanning,
where a senior manager may rely on the assessments of scanning unit
personnel for making decisions. The process is severely hampered DEMO a
lack of trust in the scanning unit personnel[11]. And interleaving
intelligent agents between the senior manager and the scanner may
provide the necessary DEMO information, the ability to make
observations, to enhance the senior managerís trust in the scanner.
Under these circumstances, intelliigent agents would be used by the
subordinate manager responsible for interpreting information about the
organizationís external DEMO With the passage of time, the
decision heuristics that this manager DEMO to evaluate threats and
opportunities in the business environment are re-apportioned to the
intelligent agents, making the knowedge available to the rest of the
organization as well as allowing the initelligent agents to have a
greater DEMO in the scanning process.
These intelligent agents might also serve as a promoter of trust,
because the additional information provided by them, information that
supplements the scannerís reports to senior management, includes the
intelligent agent generated cognitive rules that a scanner uses in
interpreting the environment. The rules, the additional cognitive
information generated by the intelligent agents, may be added to
scanning reports. And, judging from DEMO set of experimental evaluations
that follow, the rules significantly increase trust DEMO the individuals
providing those reports.
A more detailed discussion of a intelligent agents and their role in
the process of scanning the business environment, and whether or not
they have the capability of creating and maintaining DEMO, is the
subject of the rest of this paper.
Intelligent Agent DEMO Used to Test Trust
In the empirical study that follows, I DEMO the an existing intelligent
agent system developed in 1990, that was DEMO for supporting the
applied task of environmental scanning [10]. During environmental
scanning activities, managers and analysts combine their efforts in
monitoring and searching the environment. For example, given the most
current goals of the organization, DEMO managers (experts in some aspect
of the external environment such as DEMO events, regulatory
measures, competitor financial status, etc.) decide upon monitoring
sets of qualitative indicators that might provide insight into various
threats and DEMO to the organization. Once the indicators are
chosen, the managers request DEMO from the analysts of the
indicators' values. The analyst has the DEMO of locating and
interpreting information that will shed light on the disposition of the
indicators in question.  So, in a typical information request, the
manager generates a list of information requirements and sends them via
DEMO to the analyst . The analyst finds the answer, and
sends DEMO back. After this, the manager classifies the information.
The figure below DEMO the information exchanged in this
relationship:
Figure 2. Flow of Information in Environmental Scanning
These intelligent agents provide an active channel of communication
DEMO analysts and managers, where their tasks are structured as
separate sequential DEMO processes. For example, when an
organization monitors the political climate of DEMO foreign country, the
attributes a manager may considers the following: pro-regime and
anti-regime sense of relative deprivation; pro-regime and anti-regime
belief in violence; coercive force available to both pro-regime and
anti-regime actors; and institutional DEMO for both pro-regime and
anti-regime actors. In seeking attributes for these values, the manager
initiates a request for information by passing a structured message to
a particular intelligent agent. The initial message would state the
following:
DEMO) attributes for which the manager requires values and the name of DEMO
intelligent agent - which corresponds to the threat or opportunity
being monitored
b) an explanation or elucidation of the attributes to better clarify
the nature of each being requested
c) scaling information specifying the values which are acceptable as
answers to the attribute request.
This structured message is DEMO by the intelligent agent to the
analyst, and the questions about DEMO attribute values, together with
the explanations and scaling information, are given by the intelligent
agent to the analyst. To each of the attribute DEMO the analyst
responds with a value corresponding to one of the scaled values
provided by the intelligent agent. Additionally, the analyst may
provide a written explanation of why he chose a particular scaled value.
Once this DEMO done, the intelligent agent carries its new information
back to the DEMO And, upon returning to the manager, the
intelligent agent displays the answers to the specified questions and
asks (in effect), ìWhat does it mean?î  To this, the manager may ask
for an DEMO of one of the analyst's answers, or give the
intelligent DEMO an assessment, a classification, of the information
provided. With the answer, the intelligent agent forms an initial
concept - a concept that is represented as a collection of
attribute-value pairs and a classification.
The figure DEMO shows the rules induced by this system in a series of
eight separate political analyses performed on archival data that
described the Polish conflict DEMO the early 80ís[10].
Figure 3. Rules Generated by Intelligent Agent
These concepts, corresponding to somewhat likely, highly likely, and
likely chances of political turmoil, represent the cognitive heuristics
a managerís has used in diagnosing problems.  But whether making these
heuristics available to a senior manager will help in the either the
creation or maintenance of trust remains to be DEMO, and is the subject
of the next section.
Empirical Evaluation of Trust
In evaluating the effect of decision heuristics on DEMO trust,
several exploratory evaluations were conducted. Specifically, four
tests were DEMO to evaluate the effects of intelligent-agent generated
decision heuristics on trust, DEMO consequently, whether there would be
an increased propensity for trusting a DEMO who provided
those decision heuristics to the intelligent agents. The first of these
evaluations was conducted to establish whether the computer generated
information provided DEMO an intelligent agent would positively impact
trust. Following these positive results, DEMO second test was run to
determine whether the presence of only decision heuristics (without the
subjects knowing they were computer generated and without the guarantee
of additional information) would have a positive effect on trust, DEMO
the subjects were professional managers. The third test was run to
examine what kinds of order effects in the paired t-test were present.
And DEMO fourth test was conducted to determine whether arguably
irrelevant (placebo) information affected trust.
Within these experiments, a collection of constraints guided the design
of each. These considerations required that: 1) like the principals,
DEMO subjects in the experiment should not have high familiarity with
the scanning activity of interest, 2) also, to avoid confounding the
value of the decision heuristics with subject opinion, an area of
unfamiliarity be chosen, 3) to avoid the possibility of
semantic/presentation effects, the evaluations presented by the two
experts under scrutiny be randomized, and 4) DEMO heuristics presented
to the subjects be generated from the above mentioned intelligent agent
sytem. Given these guiding considerations, the design of each
experiment is described.
Test 1
Fifteen students from a graduate level evening course in DEMO systems
were instructed to read a brief statement informing them of their need
to have relevant environmental scanning information as part of their
business DEMO:
You have the responsibility of developing Eagle Corpís overseas
business, DEMO one of its concerns is in negotiating and winning a
contract with the Buhmar Company, Poland's largest manufacturer of
tractors. The negotiation is over a contract of several million dollars
to supply parts for Buhmar'DEMO new line of tractors. You have the
responsibility for closing contract negotiations with Buhmar. Moreover,
you improve your companyís position the longer the negotiations take.
But, if political violence breaks out in Poland, you stand to lose
income.
You have two political analysts working for you (A and B). They are
located in different divisions within Eagle Corp., and have recently
sent this week's update to you about political tensions in Poland.
Please DEMO them and fill out the accompanying questionnaire.
The students were told that two environmental scanning professionals
would be providing them with the needed information. DEMO, they were
then given an environmental assessment by the first professional:DEMO
Analyst Aís conclusion:
Given the current political tensions in Poland and the growing division
between the government and the citizens, I believe that political
turmoil is highly likely - and that further destablizing activities
could DEMO in an outbreak of violence. The fact that economic
conditions have lately deteriorated for the workers, who ar faced with
the military power controlled by the Central Committee, makes the
problem worse.
They were then asked to answer a series of Likert-type questions (the
McCroskey Trust Scale [22]) about their trust in that individualís work
(figure 3) (A DEMO 5 = Strongly Agree, B = 4 = Agree, C = 3 = Neutral, D =
2 = Disagree, E = 1 DEMO Strongly Disagree). Next, the students were given
a very similar DEMO by the second professional and the rules
generated by the machine induction algorithm (figure 4) about the topic
in question:
Analyst Bís DEMO:
Political Turmoil is highly likely at this time. The increase in
tensions between the workers and government could quickly lead to an
outbreak DEMO violence unless the workerís current grievances are quickly
heard and acted on by the government. This problem is being exacerbated
by the Polish army DEMO police remaining very loyal to the Central
Committee.
Additionally, they were DEMO that the rules that accompanied the second
opinion were generated by a machine learning algorithm that monitored
the activities of the second professional, and that supportive
information for each of the variables in the rules was available to
DEMO They were read an example of the kind of information about a
particular variable that could be expected, and were then asked to fill
out a duplicate, Likert-type questionnaire regarding their trust in the
competence of the second professional.
Finally, they were given five final questions regarding their trust and
willingness to hire either one or the other professional: (DEMO it turned
out, questions 4 and 5 might have been unclear DEMO read as though the
subjects were being asked if they could choose A or B over any analyst
in the world.)
1. I DEMO the results given by analyst A more than analyst B:    A
B    C    D    E
2. I trust the results given by analyst B more than analyst A:    DEMO
B    C    D    E
3. If you DEMO the results of one analyst over another, please state
as specifically DEMO possible why:
4. If I could have only one analyst working for me, I would choose
analyst A:    A    DEMO    C    D    E
5. If I could DEMO only one analyst working for me, I would choose
analyst B:    A    B    C    D    E
Analyst B: Rationales used for Political Evaluation
Condition 1: Highly Likely DEMO Turmoil
IF the Pro-Regime Actors' Belief in Violence is Strong
and DEMO Anti-Regime Actors' Belief in Violence is Somewhat Strong
and the Institutional DEMO for Pro-Regime Actors is Moderate
and the Institutional Support for Anti-Regime Actors is Strong
Then a condition of political turmoil being highly likely is DEMO
To support this conclusion, the following must be verified:
Pro-Regime DEMO's Relative Deprivation is Low
Anti-Regime Actor's Relative Deprivation is High
Coercive Force Available to Pro-Regime Actors is Strong
Coercive Force Available to DEMO Actors is Not Strong
Condition 2: Likely Political Turmoil
IF Pro-Regime Actors' Belief in Violence DEMO Moderate
and Institutional Support for Pro-Regime Actors is Low
and Institutional Support for Anti-Regime Actors is Strong
then a condition of political turmoil being DEMO is indicated.
to support this conclusion, the following must be verified:DEMO
Pro-Regime Actors' Relative Deprivation is Low
Anti-Regime Actors' Relative Deprivation is High
Anti-Regime Actors' Belief in Violence is Moderate
Coercive Force Available to Pro-Regime Actors is Strong
Coercive Force Available to Anti-Regime Actors is Not DEMO
Condition 3: Political Turmoil only Somewhat Likely
IF Pro-Regime Actors' Belief in Violence is Moderate
and Pro-Regime Actors' Institutional Support is Low
then a condition of political turmoil being somewhat likely is
indicated.
to support DEMO conclusion, the following must be verified:
Coercive Force Available to DEMO Actors is Not Strong
Pro-Regime Actors' Relative Deprivation is Low
Anti-Regime DEMO' Relative Deprivation is High
Anti-Regime Actors' Belief in Violence is High
Coercive Force Available to Pro-Regime Actors is Strong
Figure 4.  Intelligent Agent Generated Rules Provided for Test Subjects
Test 2
The second test was DEMO to determine several effects. First, while the
results of the initial DEMO were very positive, we wanted to determine
whether professional executives would DEMO the political analysis of
the expert providing the decision heuristics more than the other
expert. Additionally, we wanted to determine whether trust was still
increased when the cognitive information was presented as is, without
attributing its origin to an AI based program, and without the promise
of additional supporting data - as in the first test.
Twenty-three professional DEMO participated in this test. Their
average age was 37 years and they had an average of 15 years of work
experience. They were given DEMO same description of responsibilities as
were the students in the first test. First, they reviewed the analysis
by the expert without additional heuristics. Second, they reviewed the
second expert's analysis with the heuristics.
As a precaution, the written opinions of the two experts were
randomized, so DEMO the written opinion of A on one subjects's report
appeared as the written opinion of B on another's. Moreover, no mention
of any AI-based support system was made in regard to the decision
heuristics. DEMO heuristics were presented simply as the way in which an
opinion was formed. Also, no mention of the availability of any
supporting information was made in reference to the heuristics.
Test 3
A third test was DEMO to determine the presence of any order
effects in the presentation of the experts' findings. Fourteen students
from a graduate level evening course in systems analysis participated
in the experiment. The conditions of the experiment were DEMO to
test 2, except that the expert's opinion that was DEMO by
decision heuristics was presented first.
Test 4
A fourth test was run to determine whether an information ìplaceboî
effect could be found. Because DEMO effects of the decision heuristics
were positively related to trust in the previous experiments, the
possibility of this effect being related to just ìmore informationî was
investigated.
Seventeen students from a graduate evening course in expert DEMO
served as subjects for this test. Also, the test was conducted DEMO the
same order and with the same information as test 3, DEMO that the
heuristics were replaced by the following information:
A recent newspaper article summarized Poland's past changes by
reporting that, originally, DEMO rule was opposed by most Poles.
But the Communists used police power and other methods to crush
resistance. Communist controlled elections in 1947 gave DEMO a large
majority in the new legislature. By 1948, Communist rule DEMO firmly
established.
During the late 1940ís, the USSR gained increasing influence over the
Polish government. In 1949, a USSR military officer, Konstantin
Rokossovsky, was made Polandís defense minister. And, Polish Communists
suspected of disloyalty to the USSR were removed from power.
In 1970, strikes and riots broke out in Gdansk and other cities.
Thousands of Poles demanded better living conditions and DEMO and
political reforms. After several days of riots, Gomulka resigned and
DEMO Gierek became the Communist Party leader.
The answers to the two sets of 22 McCroskey trust scale questions were
analyzed as a paired t-test. DEMO for each of the responses regarding
A and B, together with DEMO for the two-tailed test, are reported.
Also, the five remaining questions were evaluated. The first two
regarding relative trust in A and B, as well as the fourth and fifth
questions regarding hiring A or DEMO, were evaluated as unpaired t-tests.
The means for these values, as well as the p-values for the two-tailed
tests, are also reported here. The written answers for the third
questions were completed only occasionally and DEMO be discussed below.
Discussion
Test 1
Figure 5 presents the data of the initial test. The evidence suggests
that the effects of the data DEMO by the delegation technology
approach had a significant impact on the trust the subjects had in B
over A. The questions being least affected DEMO the intervention of the
AI-based data were questions 13, 15, and 16.These questions focused on
the professionalís status in society, as well as on general authority
and experience. In discussing these questions with the subjects DEMO
the experiment was administered, they expressed their belief that the
person DEMO not have had the job unless they were qualified. So it
appears that they answered those particular questions from an a priori
perspective that DEMO not significantly influenced by the available
information.
Concerning the final set of questions, the results of which are shown
in figure 6, the DEMO intervention appears to have had a positive
significant impact on both trust and hiring preferences. The answers of
thirteen subjects were used in this DEMO, instead of fifteen, as
two of the subjects did not respond to the final five questions. Also,
while many of the respondents DEMO not provide the written answer
requested by the third of these questions, some did respond. For
example, the reasons they gave for trusting DEMO analysis accompanied by
intelligent-agent generated information included the following:
1) ì A conclusion on a matter should be based on an established,
consistent, procedural or methodological evaluation process,î
2) ìAnalyst B not only states his conclusions, but also gives reasons
for his statements. You can see and feel the flow in thoughts in
analyst B,î
3) ìAnalyst B had reasons for his result. Also, of equal importance,
he/she could give facts to backup the rankings of attributes,î
4) ìIn analyst B's report he was able to back his information with a
DEMO set of rules. I, as a manager, like to be able to look at the
analyst's reasoning and critique it for possible DEMO,î
5) ìI would show A the work done by B DEMO tell him to make his work
look like that,î
6) DEMO facts and rules leading to analyst B's conclusions are covered
in more detail and they appear to indicate more thorough research.
However, A's line of reasoning is more clearly presented.î
Not all of the DEMO, however, preferred the work of the
intelligent-agent supported analyst B. Of the written explanations,
there was one who trusted A over B DEMO had the following to say:
ìI prefer short reports. I hate to read through extra material just to
get the answers to my DEMO I trust analyst A to do the job. I
trust my judgement. I don't need a bunch of explanations, just the
answer to my question.î
Figure 5 - Results from Test 1
Figure 6 - DEMO 1 Comparisons for Trust and Hiring Preferences
Test 2
Figure 7 represents the data of the test run with professional managers
as subjects. While DEMO evidence suggests that the effects of the
AI-based data had a significant impact on trust, it had a less positive
impact, as measured DEMO the 22 questions of the trust scale, than it had
on DEMO initial group. Factors that may have contributed to this
difference include issues of presentation and the promise of extra
information. Concerning presentation, OíKeefe [27] showed that
improvements in style increase perceived prestige. Thus, a terse set of
rules would correspond to lower perceived prestige in the case of the
professional managers, as opposed to the initial group, because they
were not told the information was computer generated and could
conceivably be expecting more eloquence in the presentation. The
initial DEMO would possibly expect a terse style of presentation as
they were informed of this prior to the onset of the experiment.
The absence of DEMO promise of additional backup information may also
have contributed to the smaller impact of the intelligent-agent
generated data. In the initial group, they were read an example of some
of the explanatory information that supported Bís DEMO, and told that
additional information was available. In the case of DEMO professional
managers, the availability of additional information was neither
suggested nor DEMO They received only the heuristics that
accompanied Bís analysis - nothing else. There was no information
available about Poland. There was only data about DEMO decision-makerís
method of analysis. And looking back to the written answers of the
initial group in test 1, to the remarks numbered ì3î and ì6,î the
combination of rules and facts were given as reasons DEMO the greater
trust in B.
Like the first test, greater statistical DEMO was found when
measuring attitudes about the analystís intelligence and ability to
provide an analysis of the current problem. Less significance was
detected concerning DEMO a priori characteristics of the analyst (ie.
questions 13, 14, DEMO, 18-22).
Figure 7 - Results from Test 2
Figure 8 DEMO Trust and Hiring Preferences from Test 2
Overall, the results of DEMO final set of questions regarding trust and
hiring preferences showed the effects of AI-based intervention to be
strongly significant (figure 8). The number of respondents for the
trust preference was 19, and the hiring preference was 20, as not all
of the subjects filled out this part of the questionnaire. Very few
filled out the written answer to question DEMO, but consistent with the
presented data, most of the answers affirmed the positive effects of
the cognitive data:
ìAnalyst B demonstrated more systematic thinkingî
ìAnalyst B conveyed messages with depth DEMO knowledge of subjectî
ìI prefer B. Identification of logical factors gives credibilityî
One of the professional managers, however, preferred Aís analysis and
explained DEMO the following:
ìA gives the impression that he has an understanding of the situation.
Analyst B gives the impression that he just understands DEMO mechanisms
involved but not necessarily the actual conditions.î
Finally, one professional DEMO strongly disagreed with trusting
either analyst, writing: ìI donít like either of them.î
Figure 9 - Results from Test 3
Figure 10 - DEMO and Hiring Preferences for Test 3
Test 3
The third test was run to detect the possible effects of the order in
which the DEMO were presented. Thus, the analysis accompanied by
the intelligent-agent based cognitive DEMO was presented before the
analysis without the cognitive data. Other than this difference, the
test was run just as test 2. The 14 respondents were graduate and
undergraduate students in an evening systems analysis class. The
DEMO of their responses are shown in figure 9. The evidence suggests
that, when the order of presentation was reversed, the effects of the
DEMO generated by the knowledge processor still had a significant
impact on the trust the subjects had in A over B, to roughly the same
degree (and slightly weaker) as for the subjects in test 2.
DEMO, the summary questions at the end of the experiment provided
strong DEMO that the subjects trusted and preferred to hire the
analyst whose information was accompanied by the decision heuristics
(figure 10). Finally, the DEMO remarks that were made to clarify why the
analysis of one was preferred to another were consistent with the
remarks DEMO the other previous test.
Test 4
The fourth test was conducted to determine whether the presence of a
greater quantity of information was responsible DEMO increased trust in
analysts. The accompanying information detailed above was presented
with the findings of the first analyst, A. The results of the test are
shown in figure 11. These results show that the arguably irrelevant
DEMO not only had no positive impact on trust, but rather on
DEMO dimensions (questions 5, 11, 15, 16, 21) detracted from trust.
Overall, based on the responses to the final five summary questions
(figure 12), we conclude that the ìplaceboî information had no impact
on either trust preferences or hiring preferences. The few remarks made
concerning DEMO one analyst should be trusted over another include
the following:
ìB was more explicit and clear about the reason for the turmoilî
ìB DEMO more specific in terms of pointing out the population involved
(working DEMO)î
Figure 11 - Test Results from Test 4
Figure 12 - Trust and Hiring Preferences for Test 4
Conclusion
Trust has many facets DEMO many influences. In sociological and economic
realms, the influence of trust DEMO rather pervasive and typically
positive. The breadth of our notions of trust, however, combined with
its elusiveness and resistance to value measurements, may have
contributed to the tentativeness with which researchers have regarded
it.
Given DEMO outcomes of the empirical studies discussed in this paper, it
is DEMO to separate them from being a simple re-validation of the
widely held information economics viewpoint on information. That is,
from the information economics DEMO, decision-makers generally
prefer more information until its marginal cost exceeds its DEMO
value. If the experimental results were viewed as being a simple
re-iteration of this premise, a salient point would be overlooked.
These experiments examined how information pertaining to the
problem-solver, and not the problem, affects trust. In studiess two and
three, the subjects in DEMO experiment were not responding to direct
information about Poland and its potential for political violence. They
were responding to cognitive data that explained how DEMO scanner
thought about the problem. There was no information about Poland in
those heuristics. The evidence suggesting that this cognitive data
engendered trust in DEMO scanners was derived from the availability of
how the scanners thought. Simply giving additional information about
Poland, as in experiment 4, did not DEMO trust in the scanner.
Still, an alternative scenario for creating this DEMO trust, other
than the intelligent agents, should be addressed. That is, why not
simply have the scanners report their cognitive information without the
intervention of intelligent-agent based knowledge acquisition methods?
There is a straightforward DEMO for this. First, the literature
explaining the extreme difficulty experts have DEMO specifying their
heuristics is voluminous. Simply put, experts are generally very
DEMO at stating cognitive information. The examples used in the
experiment, where DEMO analysts gave a written evaluation of the
political situation in Poland, DEMO a genuine sense of reasoning
without appearing to be deliberately ìcognitive.î Any attempt to
present the written findings of the analysts as a set DEMO heuristics
would have gone directly against research in knowledge acquisition.
Finally, DEMO promoting trust, information technology may have a
role for promoting trust DEMO such factors as reliability, dynamism,
an communicator intentions. The solutions DEMO reach to problems
dominated by control, such as the agency problem. DEMO may also
contribute to solutions of the ìcommons problem,î [24] as well as
information sharing.
References
[1] Alcock, J. E., and Mansell, D. ìPredisposition and behavior in a
collective dilemma,î Journal of Conflict DEMO, 21, 1977, 443-457.
[2] Arrow, K., ìPolitical and Economic DEMO of Social Effects and
Externalities.î In J.Margolis (Ed.), The Analysis DEMO Public Output. New
York, National Bureau of Economic Research, Columbia University Press,
1970.
[3] Arrow, K., The Limits of Organization. New DEMO, Norton. 1974.
[4] Barber, B., The Logic and Limits of Trust, New-Jersey, DEMO
University Press, 1983.
[5] Blau, P.M., Exchange and Power in DEMO Life, New York, Wiley,
1964.
[6] Boss, R.W., ìTrust and Managerial Problem Solving Revisited,î Group
and Organizational Studies, 3(3), 1978, 331-342
[7] Butler, J.K., Jr., ìReciprocity of Trust DEMO Professionals and
Their Secretaries,î Psychological Reports, 53, 1983, 411-416.
DEMO Deutsch, M.A., ìTrust and Suspicion,î Journal of Conflict
Resolution, DEMO, 2, 265-279.
[9] Earley, P.C. ìTrust, Perceived Importance of Praise and Criticism,
and Work Performance: An Examination of Feedback in the United States
and England,î Journal of Management, 12, 4, 1986. 457-473.
[10] Elofson, G. S., and Konsynski, B. R., ìDelegation DEMO:
Environmental Scanning with Intelligent Agents,î Journal of Management
Information Systems, Vol 4, No 2, Summer 1991.
[11] Elofson. G.S., ìAn DEMO Monitoring Technology for Management
Control,î Proceeding of the 26rd Hawaii International Conference on
Systems Sciences, January 1993.
[12] Feldman, M.S., and March, J.G., ìInformation as Signal and
Symbol,î Administrative Science Quarterly, 26, 1981, 171-186.
[13] Garfinkel, H., ìStudies in the Routine Grounds DEMO Everyday
Activities,î Social Problems, 1964. 225-250.
[14] Giffin, K., DEMO contribution of studies of source credibility to
a theory of interpersonal trust in the communication process,î
Psychological Bulletin, vol 68, no 2. DEMO 104 -120.
[15] Hart, K.M., Capps, H.R., Cangemi, J.P., Caillouet, L.M.,
ìExploring Organizational Trust and its Multiple Dimensions: A DEMO
Study of General Motors,î Organization Development Journal, Summer,
1986. DEMO
[16] Hays-Roth, F., D.A. Waterman, and D. Lenat, eds., DEMO Expert
Systems, Addison-Wesley, Reading, Mass., 1983.
[17] Johnson-George, C. DEMO Swap, W.C., ìMeasurement of Specific
Interpersonal Trust: Construction and Validation DEMO a Scale to Assess
Trust in a Specific Other,î Journal of Personality and Social
Psychology, Vol. 43, No.6, 1982, 1306-1317.
[18] Lebowitz, M., ìExperiments with Incremental Concept Formation:
UNIMEMî  Machine Learning, Vol 2, No 2, September 1987.
[19] Lee, R.M., A.M. McCosh, and P. Migliarese, eds. Organizational
Decision SUpport Systems, North-Holland, Amsterdam, The Netherlands,
1988.
[20] Lewis, D. and Weigert, A., ìSocial Atomism, Holism, and Trust,î
Sociological Quarterly, 1985, 455-471.
[21] Luhmann, N., Trust DEMO Power, New York, John Wiley, 1979.
[22] McCroskey, J.C., DEMO for the Measurement of Ethos,î Speech
Monographs, 33, 1966, DEMO
[23] Messick, D.M., Wilke, H., Brewer, M.B., Kramer, DEMO, Zemke, P.E.,
Lui, L., ìIndividual Adaptations and structural change as a solution to
social dilemmas,î Journal of Personality and Social DEMO, 44,
1983, 294-309.
[24] Moore, S.F., Shaffer, L.S., Pollak, E.L., and Taylor-Lemcke, P.,
ìThe effects of interpersonal Trust on Prior Commons Problem Experience
on Commons Management,î The Journal of DEMO Psychology, 127(1), 1987,
19-29.
[25] Muir, B.M., DEMO between Humans and Machines, and the Design of
Decision Aids,î DEMO Journal of Man-Machine Studies, 27, 1987,
527-539.
[26] Nunamaker, DEMO, L. Applegate, and B.R.Konsynski, ìComputer Aided
Deliberation: Model Management and Group Deliberation Support,
Operations Research, Nov.-Dec, 1988.
[27] OíKeefe, B.J. and S. A. McCornack, ìMessage Design Logic and
Message Goal Structure: DEMO on Perception of Message Quality in
Regulative Communication Situations,î Human Communication Research,
Vol.. 14, No. 1, Fall 1987.
[28] Ouchi, W.G., ìMarkets, Bureaucracies, and Clans,î Administrative
Science Quarterly, 25, 1980, 129-141.
[29] Parsons, T., The Social System, Glencoe, IL, DEMO Press, 1951.
[30] Rempel, J.K., Holmes, J.G., and Zanna, M.P., ìTrust DEMO Close
Relationships,î Journal of Personality and Social Psychology, 49, 1985,
95-112.
[31] Rempel, J.K., and Holmes, J.G., ìHow do DEMO Trust Thee?î Psychology
Today, February, 1986, 28-34.
[32] Roberts, K.H. and OíReilly, C.A., III. ìFailures in Upward
Communication in Organizations: Three Possible Culprits,î Academy of
Management Journal, 17, 1974, 205-215.
[33] Rotter, J.B., Interpersonal Trust, Trustworthiness, and
Gullibility,î American DEMO, Vol. 35, No 1, January 1980, 1-7.
[34] Samuelson, DEMO, Messick, D.M., Rutte, C.G., Wilke, H.,
ìIndividual and Structural Solutions to resource dilemmas in two
cultures.î Journal of Personality and DEMO Psychology, 47, 1984,
94-104.
[35] Sato, Kaori, ìTrust and Group Size in a Social Dilemma,î Japanese
Psychological Research, 30, DEMO, 1988, 88-93.
[36] Sprague, R.H., ìA Framework for Research on Decision Support
Systems,î MIS Quarterly, Vol. 4, No. 4, Dec 1980, pp1-26.
[37] Taylor, R.G., Jr., ìThe Role of Trust DEMO Labor-Management
Relations,î Organization Development Journal, Summer 1989. 85-89.
[38] Yamagishi, T., ìThe Provision of a Sanctioning System as a Public
Good,î Journal of Personality and Social Psychology,î 51, 1986, 110-116.
[39] DEMO, G. and Moorman, C., ìThe Importance of Personal Trust in
DEMO Use of Research,î Journal of Advertising Research,
October-November, 1988. DEMO
[40] Zand, D.E., ìTrust and Managerial Problem Solving,î Administration
Science Quarterly, 17, 1972, 229-239.
[41] Zuboff, S., ìIn the Age of the Smart Machine: The Future of Work
and Power,î Basic Books, New York, 1984.
[42] Zucker, Lynne G., ìProduction of DEMO: Institutional Sources of
Economic Structure, 1840-1920,î Research in Organizational Behavior,
Vol. 8, p 53-111. 1986{1g42fwefx}