FIRST IMPRESSIONS MATTER:
A MODEL OF CONFIRMATORY BIAS*
MATTHEW RABIN AND DEMO L. SCHRAG
Psychological research indicates that people have a cognitive bias that leads
them to misinterpret new information as supporting previously held hypotheses.
We DEMO in a simple model that such conﬁrmatory bias induces overconﬁdence:
given any probabilistic assessment by an agent that one of two hypotheses is DEMO,
the appropriate beliefs would deem it less likely to be true. Indeed, the hypothesis
that the agent believes in may be more likely to be wrong than right. We also show
that the agent may DEMO to believe with near certainty in a false hypothesis
despite receiving an inﬁnite amount of information.
The human understanding when it has once adopted DEMO
opinion draws all things else to support and agree with it. And
though there be a greater number and weight of instances to
be DEMO on the other side, yet these it either neglects and
despises, or else by some distinction sets aside and rejects, in
order that by this great and pernicious predetermination the
authority of its former conclusion DEMO remain inviolate.
Francis Bacon1
I. INTRODUCTION
How do people form beliefs in situations of uncertainty?
Economists have traditionally assumed that people begin with
DEMO beliefs over the different possible states of the world
and use Bayes’ Rule to update those beliefs. This elegant and
powerful model of economic DEMO as Bayesian statisticians is the
foundation of modern information economics.
Yet a large and growing body of psychological research
* We thank Jimmy Chan, Erik Eyster, Bruce Hsu, Clara Wang, and especially
Steven Blatt for research assistance. We thank Linda Babcock, Steven Blatt, Jon
Elster, J effrey Ely, Roger Lagunoff, George Loewenstein, and seminar participants
at the University of California at Berkeley, Carnegie-Mellon University, Cornell
University, Emory University, the University of Michigan, Northwestern Univer-
sity, the 1997 meetings of the Econometrics Society, and the 1997 meetings of the
European Economic Association, as well as three referees, for helpful comments.
For ﬁnancial support, Rabin thanks the Alfred P. Sloan and Russell Sage
Foundations, and Schrag thanks the University Research Committee of Emory
University. This draft was completed DEMO Rabin was a Fellow at the Center for
Advanced Studies in the Behavioral Sciences, supported by NSF Grant #SBR-
960123.
1. From The New Organon and Related Writings [1960; 1620], quoted in
Nisbett and Ross DEMO, p. 167].
r 1999 by the President and Fellows of Harvard DEMO and the Massachusetts Institute of
Technology.
The Quarterly Journal of Economics, DEMO 1999
37
Page 37
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
38
QUARTERLY JOURNAL OF ECONOMICS
suggests that the way people process information DEMO departs
systematically from Bayesian updating. In this paper we formally
model and explore the consequences of one particular departure
from Bayesian rationality: conﬁrmatory bias. A person suffers
from conﬁrmatory bias if he tends to misinterpret ambiguous
DEMO as conﬁrming his current hypotheses about the world.
Teachers misread performance of pupils as supporting their
initial impressions of those pupils; many people misread their
observations of individual behavior as supporting their prior
stereotypes about groups DEMO which these individuals belong;
scientists biasedly interpret data as supporting their hypotheses.
Our simple model by and large conﬁrms an intuition common
in DEMO psychology literature: conﬁrmatory bias leads to overconﬁ-
dence, in the sense that people on average believe more strongly
than they should in their DEMO hypotheses. The model also
yields surprising further results. An agent who suffers from
conﬁrmatory bias may come to believe in a hypothesis that is
DEMO wrong, meaning that a Bayesian observer who was
aware of the DEMO conﬁrmatory bias would, after observing the
agent’s beliefs, favor a different hypothesis than the agent. We
also show that even an inﬁnite amount DEMO information does not
necessarily overcome the effects of conﬁrmatory bias: over DEMO an
agent may with positive probability come to believe with near
certainty in the wrong hypothesis.
In Section II—which readers impatient for math may DEMO to
skip—we review some of the psychological evidence that humans
are prone to conﬁrmatory bias. In Section III we present our
formal model and DEMO examples and general propositions
illustrating the implications of conﬁrmatory bias. In our model, an
agent initially believes that each of two possible states of the
world is equally likely. The agent then receives a series of
DEMO and identically distributed signals that are corre-
lated with the true state. To model conﬁrmatory bias, we assume
that when the agent gets a signal that is counter to the hypothesis
he currently believes is more DEMO, there is a positive probability
that he misreads that signal as DEMO his current hypothesis.
The agent is unaware that he is misreading evidence in this way
and engages in Bayesian updating that would be fully DEMO
given his environment if he were not misreading evidence.2
2. Researchers have, of course, documented many other biases in information
processing. We develop DEMO model ignoring these other biases, assuming complete
rationality except for this DEMO bias, so as to keep our model tractable and because
we DEMO that incorporating documented biases into the Bayesian model one at a
time is useful for carefully identifying the effects of each particular bias.
Page DEMO
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
39
Because we assume that the agent always correctly DEMO
evidence that conﬁrms his current beliefs, relative to proper
Bayesian updating DEMO is biased toward conﬁrming his current
hypothesis.
So, for example, a teacher may believe either that Marta is
smarter than Bart or that DEMO is smarter than Marta; he initially
believes each is equally likely, and over time he collects a series of
signals that help him DEMO identify who is smarter. If, after receiving
one or more signals, the teacher believes that Marta is probably
smarter than Bart, conﬁrmatory bias may lead him to erroneously
interpret his next signal as supporting this DEMO Therefore,
the teacher ’s updated belief that Marta is smarter than Bart may
be stronger than is warranted.
The notion that the teacher DEMO likely to believe ‘‘too strongly’’
that Marta is smarter corresponds to the commonly held intuition
that conﬁrmatory bias leads to overconﬁdence. While qualifying
this DEMO with several caveats, our model by and large
conﬁrms it: given any probabilistic assessment by an agent that
one of the hypotheses is DEMO true, the appropriate beliefs
should on average deem it less likely DEMO be true. Intuitively, a
person who believes strongly in a hypothesis DEMO likely to have
misinterpreted some signals that conﬂict with what he believes,
and hence is likely to have received more evidence against his
DEMO hypothesis than he realizes.
Our analysis shows that a more surprising result arises when
conﬁrmatory bias is severe: a Bayesian observer with no direct
information of her own, but who can observe the agent’s belief in
favor of one hypothesis, may herself believe that the other
hypothesis is more likely. We show that such ‘‘wrongness’’ can
arise when the agent’s DEMO is sufficiently mixed. Intuitively, if
the agent has perceived almost as DEMO evidence against his
hypothesis as supporting it, then, since some of the evidence he
perceives as supportive is actually not supportive, it is likely that
a majority of the real signals oppose his hypothesis. Because DEMO
wrongness only arises when the agent has relatively weak evi-
dence supporting his favored hypothesis, however, the agent on
average correctly judges which DEMO the two hypotheses is more
likely, in the sense that his DEMO guess is right most of the time.
While seemingly straightforward, the DEMO for our over-
conﬁdence and wrongness results conceals some subtle implica-
tions of the agent’s conﬁrmatory bias. For example, an agent who
currently believes in Hypothesis A (say) may once have believed in
Hypothesis B, at which time he had a propensity to misread as
Page 39
DEMO/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
40
QUARTERLY JOURNAL OF ECONOMICS
supporting Hypothesis B evidence actually in favor DEMO Hypothesis
A. But then the agent may underestimate how many signals
supporting Hypothesis A he has received, and thus he may be
underconﬁdent in his belief in favor of Hypothesis A. Indeed, we
show that an agent who has only recently come to believe in a
hypothesis is DEMO to be underconﬁdent in that hypothesis,
because until recently he has been biased against his current
hypothesis. If a teacher used to think DEMO was smarter than
Marta and only recently concluded that Marta is smarter, then
probably he has been ignoring evidence all along that Marta is
smarter. The simple overconﬁdence and wrongness results hold
because an agent has DEMO believed in his currently held
hypothesis during most of the time he has been receiving informa-
tion and so, on average, has been DEMO toward this hypothesis.
In Section IV we investigate the implications of conﬁrmatory
bias after the agent receives an inﬁnite sequence of signals. In the
DEMO of conﬁrmatory bias, an agent will always come to believe
with DEMO certainty in the correct hypothesis if he receives an
inﬁnite sequence of signals. If the conﬁrmatory bias is sufficiently
severe or the strength of DEMO signals is weak, however, then
with positive probability the agent may come to believe with near
certainty that the incorrect hypothesis is true. DEMO, once
the agent comes to believe in an incorrect hypothesis, the conﬁrma-
tory bias inhibits his ability to overturn his erroneous beliefs. If
DEMO bias is strong enough, the expected drift once the agent comes
DEMO believe in the false hypothesis is toward believing more strongly
in that hypothesis, guaranteeing a positive probability that the
agent ends up forever believing very strongly in the false hy-
pothesis. The results of Section IV DEMO the common intuition that
learning will eventually correct cognitive biases. While this is true
for sufficiently mild conﬁrmatory bias, when the bias is suffi-
ciently severe ‘‘learning’’can exacerbate the bias.
The premise of this paper is DEMO explicit formalizations of
departures from Bayesian information processing are crucial to
incorporating psychological biases into economic analysis. For the
most part, we do not in this paper take the important next step of
developing extended economic DEMO of the bias we model.
In Section V, however, we illustrate one implication of conﬁrma-
tory bias by sketching a simple principal-agent model. DEMO illus-
trate how a principal may wish to mute the incentives that she
offers an agent who suffers from conﬁrmatory bias. Indeed, we
Page 40
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
41
show that even if it is very easy DEMO an agent to gather information,
so that a principal can at negligible costs provide incentives for an
agent to search for proﬁtable investment DEMO, the
principal may choose not to provide these incentives to a DEMO
tory agent. This arises when the expected costs in terms of an
overconﬁdent agent investing too much in risky projects outweigh
the expected beneﬁt DEMO the agent being better informed. We
conclude in Section VI by discussing some other potential eco-
nomic implications of conﬁrmatory bias, as well as highlighting
some likely obstacles to applying our model.
II.AREVIEW OF THE PSYCHOLOGY DEMO
Many different strands of psychological research yield evi-
dence on phenomena that we are modeling under the rubric of
conﬁrmatory bias. Before reviewing this DEMO, we ﬁrst wish
to distinguish a form of ‘‘quasi-Bayesian’’ information processing
DEMO the bias we are examining. Although the two phenomena are
related—and not always distinguished clearly in the psychology
literature—they differ importantly in their implications DEMO deci-
sion theory. Suppose that, once they form a strong hypothesis,DEMO
people simply stop being attentive to relevant new information
that contradicts or supports their hypotheses. Intuitively, when
you become convinced that one investment strategy is more
lucrative than another, you may simply stop paying attention to
even freely available additional information.3
Bruner and Potter [1964] elegantly demonstrate such DEMO
ing. About 90 subjects were shown blurred pictures that were
gradually brought into sharper focus. Different subjects began
viewing the pictures at different points DEMO the focusing process,
but the pace of the focusing process and ﬁnal degree of focus were
identical for all subjects. Strikingly, of those subjects who began
their viewing at a severe-blur stage, less than a quarter eventu-
ally identiﬁed the pictures correctly, whereas over half of those
who began viewing at a light-blur stage were able to correctly
identify DEMO pictures. Bruner and Potter [p. 424] conclude that
‘‘Interference may be accounted for partly by the difficulty of
rejecting incorrect hypotheses based on substandard DEMO That
3. Such behavior corresponds to a natural economic ‘‘cognitive-search’’model:
if we posit a cost to information processing, in many settings the natural stopping
rule would be to process information until beliefs are sufficiently strong DEMO one
direction or another, and then stop.
Page 41
@xyserv1/disk4/DEMO/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
42
QUARTERLY JOURNAL OF ECONOMICS
is, people who use weak evidence to form initial hypotheses have
difficulty correctly interpreting subsequent, better information
that contradicts those initial hypotheses.4
This form of anchoring does not necessarily imply that DEMO
misinterpret additional evidence to either disconﬁrm or conﬁrm
initial hypotheses, only DEMO they ignore additional evidence. Such
a tendency to anchor on initial hypotheses can therefore be
reconciled with Bayesian information processing. While such
anchoring is DEMO quite important, psychological evidence
reveals a stronger and more provocative phenomenon: people tend
to misread evidence as additional support for initial hypotheses. If
DEMO teacher initially believes that one student is smarter than
another, she DEMO the propensity to conﬁrm that hypothesis when
interpreting later performance.5 Lord, DEMO, and Lepper [1979, p.
2099] posited some of the underlying cognitive mechanisms
involved in such propensities:
. . . there is considerable DEMO that people tend to interpret subse-
quent evidence so as to maintain their initial beliefs. The biased assimilation
processes underlying this effect may include DEMO propensity to remember the
strengths of conﬁrming evidence but the weaknesses of disconﬁrming
evidence, to judge conﬁrming evidence as relevant and reliable but disconﬁrm-
ing evidence as irrelevant and unreliable, and to accept conﬁrming evidence
at face value while scrutinizing disconﬁrming evidence hypercritically. With
conﬁrming evidence, we suspect that both lay and professional scientists
rapidly reduce the complexity of the DEMO and remember only a few
well-chosen supportive impressions. With disconﬁrming evidence, DEMO con-
tinue to reﬂect upon any information that suggests less damaging ‘‘alterna-
tive interpretations.’’ Indeed, they may even come to regard the ambiguities
and conceptual ﬂaws in the data opposing their hypotheses as somehow
suggestive of DEMO fundamental correctness of those hypotheses. Thus, com-
4. A similar experiment DEMO and Campbell 1951] was cited by Perkins
[1981] as one interpretation of the perspective that ‘‘fresh’’thinkers may be better
at seeing solutions to problems DEMO people who have meditated at length on the
problems, because the DEMO thinkers are not overwhelmed by the ‘‘interference’’of
old hypotheses.
5. A related arena where the conﬁrmation bias has been studied widely is in
counselor DEMO: counselors in clinical settings tend to conﬁrm original
suppositions in their DEMO judgments. If you are told ahead of time that an
interviewee is combative, then both your conduct and your interpretation of his
conduct during an interview may reinforce that supposition, even if he is in fact no
more combative than the average person. See, e.g., Haverkamp [1993]. DEMO has
also been extensive research on conﬁrmatory bias in the interviewing process more
generally; see, e.g., Dougherty, Turban, and Callender [1994] and Macan and
Dipboye [1994]. Research applying variants of conﬁrmatory bias to other DEMO
includes Arkes [1989] and Borum, Otto, and Golding [1993] to the law; Baumann,
Deber, and Thompson [1991] to medicine; and Souter [1993] discusses the
implications of overconﬁdence to business insurance.
Page 42
@xyserv1/DEMO/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER 43
pletely inconsistent or even random data—when ‘‘processed’’ in DEMO suitably
biased fashion—can maintain or even reinforce one’s preconceptions.
The most striking evidence for the conﬁrmatory bias is a
series of experiments demonstrating how DEMO the same
ambiguous information to people who differ in their initial beliefs
on some topic can move their beliefs farther apart. To illustrate
such DEMO, Lord, Ross, and Lepper [1979] asked 151
undergraduates to complete DEMO questionnaire that included three
questions on capital punishment. Later, 48 of DEMO students were
recruited to participate in another experiment. Twenty-four of
them were selected because their answers to the earlier question-
naire indicated that they DEMO ‘‘ ‘proponents’ who favored capital
punishment, believed it to have a DEMO effect, and thought
most of the relevant research supported their own DEMO Twenty-
four were opponents who opposed capital punishment, doubted its
deterrent DEMO and thought that the relevant research supported
their views.’’These subjects were then asked to judge the merits of
randomly selected studies on the deterrent DEMO of the death
penalty, and to state whether a given study (along with criticisms
of that study) provided evidence for or against the deterrence
hypothesis. Subjects were then asked to rate, on 16 point scales
ranging from 28to 18, how the studies they had read moved their
attitudes toward the death penalty, and how they had changed
their beliefs regarding its deterrent efficacy. Lord, Ross, and
Lepper [pp. 2102–2104] summarize DEMO basic results (all of which
hold with conﬁdence p , .01) as follows:
The relevant data provide strong support for the polarization DEMO
sis. Asked for their ﬁnal attitudes relative to the experiment’s start,
proponents reported that they were more in favor of capital punishment,
DEMO opponents reported that they were less in favor of capital punish-
ment.... Similar results characterized subjects’ beliefs about deterrent
efficacy. Proponents reported greater belief DEMO the deterrent effect of capital
punishment, whereas opponents reported less belief DEMO this deterrent effect.
Plous [1991] replicates the Lord-Ross-Lepper results in the
context of judgments about the safety of nuclear technology. Pro-
and antinuclear subjects DEMO given identical information and
arguments regarding the Three Mile Island nuclear disaster and
a case of false military alert that could have led to DEMO launching of
U. S. nuclear missiles. Plous [p. 1068] found that 54 percent of
pronuclear subjects became more pronuclear from the informa-
tion, while only 7 percent became less pronuclear. By contrast,
Page 43
@xyserv1/DEMO/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
44
QUARTERLY JOURNAL OF ECONOMICS
only 7 percent of the antinuclear subjects DEMO less antinuclear
from the information while 45 percent became more antinuclear.6
Darley and Gross [1983] demonstrate a related and similarly
striking form of polarization DEMO to conﬁrmatory bias. Seventy
undergraduates were asked to assess a nine-year-old girl’s aca-
demic skills in several different academic areas. Before complet-
ing this DEMO, the students received information about the girl and
her family and DEMO a video tape of the girl playing in a
playground. One group of subjects was given a fact sheet that
described the girl’s parents DEMO college graduates who held white-
collar jobs; these students viewed a DEMO of the girl playing in
what appeared to be a well-to-do, DEMO class neighborhood. The
other group of subjects was given a fact sheet that described the
girl’s parents as high school graduates who held blue-collar DEMO;
these students viewed a video of the same girl playing in what
appeared to be an impoverished inner-city neighborhood. Half of
each group DEMO subjects were then asked to evaluate the girl’s
reading level, measured DEMO terms of equivalent grade level.7 There
was a small difference in the two groups’ estimates—those
subjects who had viewed the ‘‘inner-city’’video rated the girl’s DEMO
level at an average of 3.90 (i.e., 9⁄10 through third grade) while
those who had viewed the ‘‘suburban video’’ rated the girl’s skill
level at an average of 4.29. The remaining subjects in each group
DEMO shown a second video of the girl answering (with mixed
success) a series of questions. Afterwards, they were asked to
6. These percentages were derived from Table 2 of Plous [1991, p. 1068],
aggregating across two studies; the remaining subjects in each case reported no
change in beliefs. For other papers following on Lord, Ross, and Lepper DEMO, see
Fleming and Arrowood [1979]; Jennings, Lepper, and Ross [1981]; Hubbard [1984];
Lepper, Ross, and Lau [1986]. See also Miller, McHoskey, Bane, and Dowd [1993]
for more mixed evidence regarding the Lord-Ross-Lepper experiment. In the
passage above, Lord, Ross, and Lepper posit that even professional scientists are
susceptible to such same-evidence polarization. Indeed, many economists and
other academics have probably observed how differing schools of thought DEMO
ambiguous evidence differently. An example was once told to one of us by a
colleague. He saw the same model—calibrating the elasticity of demand DEMO a
Cournot oligopolist as a function of the number of ﬁrms in an industry—described
at the University of Chicago and at the Massachusetts Institute DEMO Technology. A
Chicago economist derived the formula and said, ‘‘Look at DEMO few ﬁrms you need
to get close to inﬁnite elasticities and perfect competition.’’ An M.I.T. economist
derived the same formula and said, ‘‘Look at how large n [the number of ﬁrms] has
to be before you DEMO anywhere close to an inﬁnite elasticity and perfect competi-
tion.’’These different schools each interpreted the same mathematical formula as
evidence reinforcing their respective views. DEMO related analysis in the scientiﬁc
domain, see also Mahoney [1977].
7. DEMO subjects were also asked to evaluate the girl’s mathematics and liberal
arts skill levels; we report the results that are least supportive of the existence of
conﬁrmatory bias.
Page 44
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 DEMO
FIRST IMPRESSIONS MATTER
45
evaluate the girl’s reading level. The inner-city video DEMO rated
the girl’s skill level at an average of 3.71, signiﬁcantly DEMO the
3.90 estimate of the inner-city subjects who did not view the
question-answer video. Meanwhile, the suburban video group
rated the girl’s skill level at an average of 4.67, signiﬁcantly above
the 4.29 estimate of the suburban subjects who did not view the
second video. Even though the DEMO groups viewed the identical
question-and-answer video, the additional information further
polarized DEMO assessments of the girl’s skill level. Darley and
Gross interpret this result as evidence of conﬁrmatory bias—
subjects were inﬂuenced by the girl’s background DEMO their initial
judgments, but their beliefs were evidently inﬂuenced even more
DEMO by the effect their initial hypotheses had on their
interpretation of further evidence.8
Our reading of the psychology literature leads us to conclude
that DEMO of three different information-processing problems con-
tribute to conﬁrmatory bias. First, DEMO widely recognize
that conﬁrmatory bias and overconﬁdence arise when people must
interpret ambiguous evidence (see, e.g., Keren [1987] and Griffin
and Tversky [1992]). Lord, Ross, and Lepper ’s [1979] study,
discussed above, clearly illustrates the point. Keren [1988] notes
the lack of conﬁrmatory bias DEMO visual perceptions and concludes
that conﬁrmatory tendency depends on some degree of abstraction
and ‘‘discrimination’’(i.e., the need for interpretation) not present
in DEMO visual tasks. A primary mechanism of stereotype-
maintenance is our tendency to interpret ambiguous behavior
according to previous stereotype.9 Similarly, a teacher may inter-
pret an ambiguous answer by a student as either creative or just
DEMO stupid, according to his earlier impressions of the student,
8. DEMO should be noted that polarization of the form identiﬁed by Darley and
Gross [1983] provides more direct evidence of conﬁrmatory bias than does
polarization DEMO by Lord, Ross, and Lepper [1979] and related papers. As Jeff
Ely pointed out to us, Lord, Ross, and Lepper permit an alternative interpretation:
that some people are predisposed to interpret ambiguous evidence DEMO way and
some the other. Hence, observing further polarization by groups DEMO already differ
may not reﬂect conﬁrmatory bias per se, but underlying DEMO in interpreta-
tion of evidence that would appear irrespective of subjects’ current beliefs. While
this interpretation also departs from common-priors Bayesian information process-
ing DEMO will often yield similar implications as conﬁrmatory bias, it is conceptually
DEMO and would sometimes yield different predictions. By demonstrating
polarization based on differing beliefs induced in two ex ante identical groups of
subjects, Darley and Gross are not subject to this alternative interpretation.
9. A vast literature DEMO the mechanisms by which people retain ethnic,
gender, and other DEMO stereotypes. See, e.g., Hamilton and Rose [1980];
Bodenhausen and Wyer [1985]; Bodenhausen and Lichtenstein [1987]; Stangor
[1988]; Stangor and Ruble [1989]; and Hamilton, Sherman, and Ruvolo [1990].
Page 45
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
46
QUARTERLY JOURNAL OF ECONOMICS
but will be less likely to biasedly DEMO more objective feedback
such as answers to multiple-choice questions.
Second, conﬁrmatory DEMO can arise when people must inter-
pret statistical evidence to assess the correlation between phenom-
ena that are separated by time. Nisbett and Ross DEMO argue
that the inability to accurately identify such correlation (e.g.,
DEMO hyperactivity and sugar intake, or between performance
on exams and the DEMO of day the exams are held) is one of the
most DEMO shortcomings in human reasoning.10 People often
imagine a correlation between events when no such correlation
exists.11 Jennings, Amadibile, and Ross [1982] argue that DEMO
correlation can play an important role in the conﬁrmation of false
hypotheses, ﬁnding that people underestimate correlation when
they have no theory of the correlation, but exaggerate correlation
and see it where it is not when they have a preconceived theory of
it.12
Third, conﬁrmatory bias occurs when people selectively col-
lect or scrutinize evidence. One form of ‘‘scrutiny-based’’conﬁrma-
tory DEMO is what we shall call hypothesis-based ﬁltering.13 While it
is sensible to interpret ambiguous data according to current
hypotheses, people tend to use the consequent ‘‘ﬁltered’’ evidence
10. As Jennings, Amabile, and Ross [1982, p. 212] put it, ‘‘even the staunchest
defenders of the layperson’s capacities as an intuitive scientist . . . have had little
that was ﬂattering DEMO say about the layperson’s handling of bivariate observation.’’
11. Chapman and Chapman [1967, 1969, 1971] demonstrate that clinicians
and laypeople often perceive entirely DEMO correlation among (for instance)
pictures and the personality traits of DEMO people who drew the pictures. Stangor
[1988] and Hamilton and Rose [1980] also discuss the role of illusory correlation in
the context of conﬁrmatory-like DEMO
12. Similarly, Redelmeier and Tversky [1996] argue illusory correlation may
help DEMO the persistent belief that arthritis pain is related to the weather.
13. Another mechanism can be deﬁned as ‘‘positive test strategy’’: People tend
to ask questions (of others, of themselves, or of data) that DEMO likely to be true if
their hypothesis is true—without due regard to the fact that they are likely to be
true even if the DEMO is false. See Einhorn and Hogarth [1978]; Klayman and
Ha [1987]; Beattie and Baron [1988]; Devine, Hirt, and Gehrke [1990]; Hodgins
DEMO Zuckerman [1993]; Friedrich [1993]; and Zuckerman, Knee, Hodgins, and
DEMO [1995]. We are using this term a bit differently than we suspect
psychologists would use it. As far as we know, the term was coined by Klayman and
Ha to point out that much of what DEMO put under the rubric of conﬁrmatory bias
could indeed be a rational form of hypothesis testing. Fischhoff and Beyth-Marom
[1983, pp. 255–256] and Friedrich also point out that if people are fully aware that
asking ‘‘soft’’ DEMO teaches them little about the truth of hypotheses, then no
bias DEMO occurred. While we feel research on the positive test strategy needs more
careful calibration versus Bayesian updating, we believe that the evidence
suggests that people do not fully appreciate how little they have learned about the
DEMO of their hypotheses when asking soft questions. (Mehle, Gettys, Manning,DEMO
Baca, and Fisher [1981], for instance, show that people with DEMO hypotheses
for observed data tend to overuse such hypotheses to explain the data because they
do not have ‘‘available’’the many unspeciﬁed hypothesis that could DEMO explain the
data.)
Page 46
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER 47
inappropriately as further evidence for these hypotheses. If DEMO
student gives an unclear answer to an exam question, it is
DEMO for a teacher to be inﬂuenced in his evaluation of the
answer by his prior perceptions of that student’s mastery of the
material. However, after assigning differential grades to students
according to differential interpretation of comparable DEMO, it
is a mistake to then use differential grades on the DEMO as further
evidence of the differences in the students’abilities.14 This sort of
error is especially likely when the complexity and ambiguity of
evidence requires DEMO use of prior theories when interpreting data
and deciding what data to examine.15
Finally, one of the main results in our model is conﬁrmation of
the conjecture common in the psychological literature that conﬁr-
matory bias DEMO to overconﬁdence. A vast body of psychological
research, separate from research DEMO conﬁrmatory bias, ﬁnds that
people are prone toward overconﬁdence in their DEMO
14. Lord, Ross, and Lepper [1979, pp. 2106–2107] note a DEMO distinction in
reﬂecting on the bias in their experiment discussed above. They note that it is
proper for people to differentially assess probative value DEMO different studies
according to their current beliefs about the merits of the death penalty. The ‘‘sin’’is
in using their hypothesis-based interpretations of the strength DEMO different studies
as further support for their beliefs.
15. We suspect that hypothesis-based ﬁltering is especially important in
understanding persistence and strengthening of beliefs DEMO tenuous ‘‘scientiﬁc’’
theories. Indeed, Jon Elster drew our attention to an DEMO by philosopher of
science Karl Popper [1963, pp. 34–35] of conﬁrmatory DEMO in intellectual pursuits.
Popper observed that followers of Marx, Freud, and Adler found ‘‘conﬁrmation’’
everywhere, and described the process by which they strengthened their convic-
tion over time in terms remarkably similar to the process DEMO we’ve described it
based on psychological research:
Once your eyes were thus opened you saw conﬁrming instances every-
where: the world was full of veriﬁcations of the theory. Whatever happened
always conﬁrmed it . . DEMO The most characteristic element in this situation
seemed to me the incessant stream of conﬁrmations . . . As for Adler, I was
much impressed by a personal experience. Once, in 1919, I reported to DEMO a
case which to me did not seem particularly Adlerian, but DEMO he found no
difficulty in analysing in terms of his theory of inferiority feelings, although
he had not even seen the child. Slightly shocked, I asked him how he could be
so sure. ‘‘Because of my thousandfold experience,’’ he replied; whereupon I
could not help saying: DEMO with this new case, I suppose, your experience
has become thousand-and-one-fold.’’
What I had in mind was that his previous observations may not DEMO
been much sounder than this new one; that each in its DEMO had been
interpreted in the light of ‘‘previous experience,’’ and at the same time
counted as additional conﬁrmation.
16. See, e.g., Oskamp DEMO, Mahajan [1992], and Paese and Kinnaly [1993].
An early paper that makes this point is Fischhoff, Slovic, and Lichtenstein [1977],
who DEMO tested the robustness of overconﬁdence with monetary stakes rather than
reported judgments. No decrease in overconﬁdence was found relative to the
no-money-stakes condition. (As Camerer [1995] notes, there exist very few
conclusions reached by researchers on judgment that have been overturned when
Page 47
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/DEMO/DIV_044a09 tres
48
QUARTERLY JOURNAL OF ECONOMICS
III. CONFIRMATORY BIAS AND BELIEF FORMATION
Consider DEMO states of the world, x [ 5A,B6, where A and B are
two exhaustive and mutually exclusive hypotheses regarding
some issue. We DEMO an agent whose prior belief about x is
given by prob (DEMO 5 A) 5 prob (x 5 B) 5 0.5, so the agent initially
views the two alternative hypotheses as equally likely to DEMO true.
In every period t [ 51,2,3,...6 the agent receives a signal, st [ 5a,b6,
that is correlated with the true state of the world. Signals received
at different times t DEMO independently and identically distributed,
with prob (st 5 a 0 DEMO) 5 prob (st 5 b 0 B) 5u, for some u [ (.5,1).
After receiving each signal, the agent DEMO his belief about the
relative likelihood of x 5 A and x 5 B.
To model conﬁrmatory bias, we suppose that the agent may
misinterpret signals that conﬂict with his current belief about
which hypothesis is DEMO likely. Suppose that, given the signals
the agent thinks he has DEMO in the ﬁrst t 2 1 periods, he
believes that state DEMO is more likely than state B. Because of his
conﬁrmatory bias, DEMO agent may misread a conﬂicting signal st 5
b in the next period, believing instead that he observes st 5 a.
Formally, in DEMO period t [ 51,2,3,...6 the agent perceives a
signal st [ 5a,b6. When the agent perceives a signal st 5a,DEMO
believes that he actually received a signal st 5 a, and DEMO he
perceives st 5b, he believes that he actually received a DEMO st 5
b. He updates his beliefs using Bayes’ Rule given his (possibly
erroneous) perceptions of the signals he is receiving. We assume
DEMO with probability q . 0 the agent misreads a signal st that
conﬂicts with his belief about which hypothesis is more likely, and
that the agent always correctly interprets signals that conﬁrm his
belief. If he DEMO believes that Hypothesis A is more likely,
then for sure he interprets a signal st 5 a as st 5a, but with
probability q he misreads st 5 b as st 5a.
This model of DEMO bias incorporates several unrealis-
tic simplifying assumptions. For instance, we assume DEMO the
severity of the bias summarized by q does not depend on the
strength of the agent’s beliefs about which of the two states DEMO
more likely. It would be reasonable to expect that q is greater if the
monetary stakes are added.) There have, however, been criticisms of the evidence
in support of overconﬁdence. See Bjorkman [1994]; Pfeifer [1994]; Tomassini,
Solomon, Romney, and Krogstad [1982]; Va n Lenthe DEMO; and Winman and
Juslin [1993]. We feel, nevertheless, that the DEMO makes a strong case for
overconﬁdence. Indeed, see Soll [1996] for DEMO that overconﬁdence does
extend to ecologically valid domains.
Page 48
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
49
agent’s beliefs are more extreme. We conjecture that DEMO qualita-
tive results would continue to hold if we were to relax this
assumption. Also, we assume that the agent misreads conﬂicting
evidence as conﬁrming evidence. While we feel that this is often
the case, a reasonable alternative model would be to assume
instead that the agent merely DEMO a tendency to overlook evidence
that conﬂicts with his beliefs. This model, too, would yield the
same qualitative results as our model; intuitively, ignoring the
counterhypothesis evidence in a cluster of mixed, but mostly
DEMO evidence, is equivalent to misreading the whole
cluster as hypothesis-supportive.
The DEMO of conﬁrmatory bias means that the agent’s
perceived signals st are neither independently nor identically
distributed. Suppose that, after receiving signals st21 5 (DEMO,..., st21)
the agent has perceived a sequence of signals DEMO 5 (s1,..., st21)
and holds beliefs prob (x DEMO A 0 st21 ). Deﬁne
u* ; prob (st 5a 0 prob (x 5 A 0 st21) . 0.5, x 5 B )
5 prob (st 5b 0 prob (x 5 B 0 st21) . 0.5, x 5 A ).
u** ; prob (DEMO 5a 0 prob (x 5 A 0 st21) . 0.5, DEMO 5 A )
5 prob (st 5b 0 prob (x DEMO B 0 st21) . 0.5, x5 B ).
u* and DEMO summarize the distribution of the agent’s per-
ceived signal st when the agent believes that one hypothesis is
more likely than the other; i.e., when prob (x 5 A 0 st21) Þ 0.5. u*is
the probability that the agent perceives a signal conﬁrming his
belief that one DEMO is more likely when in fact the other
hypothesis is true. u** is the probability that the agent perceives a
signal conﬁrming his belief DEMO a hypothesis is more likely when
in fact it is true. Because with probability q the agent misreads a
signal that conﬂicts with his DEMO, u* 5 (1 2u) 1 qu and u** 5
u1 DEMO(1 2u). When prob (x 5 A 0 st21) 5 0.5, i.e., when the agent
believes that the two possible hypotheses DEMO equally likely, the
agent does not suffer from conﬁrmatory bias. In DEMO case, he
correctly perceives the signal that he receives, and he updates
accurately, so u ; prob (st 5a 0 prob (x 5 A 0 st21) 5 0.5, x 5 A) 5
prob (st 5b 0 prob (x 5 B 0 st21) 5 0.5, x 5 B).
If q 5 0, then the agent DEMO an unbiased Bayesian statistician;
while if q 5 1, the DEMO ﬁrst piece of information completely
determines his ﬁnal belief, since he DEMO misreads signals that
Page 49
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
50
QUARTERLY JOURNAL OF ECONOMICS
conﬂict with the ﬁrst signal he receives. DEMO generally, the
higher is q, the more extreme is the conﬁrmatory bias.
Suppose that the agent has perceived na a signals and nb DEMO
signals, where na . nb. Because the agent believes he has DEMO
na a signals and nb b signals, his updated posterior beliefs DEMO
given by
Deﬁne
prob (x 5 A 0 na, nb)
una2nb
.
una2nb 1 (1 2u)na2nb
5
5 prob (x DEMO A 0 na, nb)
L(na,nb) prob (x DEMO B 0 na, nb) .
L(na, nb) represents the agent’s beliefs in terms of a relative
likelihood ratio. Using Bayes’Rule, L(na,nb) 5 (una2nb)/(1 2u)na 2nb.If
L(na,DEMO) . 1, the agent believes that A is more likely than B to be
the true state; while if L(na ,nb ) , 1, the agent believes that B is
more likely than DEMO L(na,nb) 5 1, the agent believes that the two
states are equally likely. The agent’s interpretation of an addi-
tional signal DEMO biased whenever L(na, nb) Þ 1.
In order to identify the effects of conﬁrmatory bias, it is
helpful to compare the agent’s beliefs with the beliefs of a
hypothetical unbiased, Bayesian observer who learns how many a
and b signals the agent has perceived, and who knows that the
agent suffers from conﬁrmatory bias. Like the agent, the Bayesian
observer initially believes that prob (x 5 A) 5 prob (x 5 B) 5 0.5,
and she has no independent information about whether x 5 A or
x 5 B. This hypothetical observer DEMO beliefs, therefore, reﬂect the
true probability that x 5 A and x 5 B, given the signals that the
agent has perceived.
Deﬁne L*(na,nb) a s the Bayesian observer ’s likelihood ratio of
A versus B when she knows that an agent who suffers from
DEMO bias has perceived na a signals and nb b signals,
where na . nb. In general, when q . 0, the biased DEMO
likelihood ratio L(na,nb) and the unbiased observer ’s likelihood
DEMO L*(na,nb) are not equal. If L(na,nb) when na . nb, the agent is
overconﬁdent; his belief in favor DEMO the hypothesis that x 5 A is
stronger than is justiﬁed by the available evidence. Similarly, if
L(na,nb) ,L*(na,nb), the agent is underconﬁdent in his belief that
x 5 A.
DEMO 50
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
51
In the formal results that we develop below, we assume that,
while the unbiased observer knows how many a DEMO b signals the
agent has perceived, she does not know the DEMO in which the
agent perceived his signals. But when q . 0, the order of the
agent’s perceived signals, if known, would inﬂuence a Bayesian
observer ’s beliefs, since the agent’s conﬁrmatory bias implies that
his perceived signals are not distributed independently. Suppose
that the agent has DEMO three a signals and two b signals, in
which case his DEMO are L(na 5 3, nb 5 2) 5u/(1 DEMO). If the
Bayesian observer knew the order of the agent’s signals, her
posterior belief L*(na 5 3, nb 5 2) could be less than, greater than,
or equal to u/(1 DEMO), depending on the order of the signals. Thus,
from the perspective of an outside observer, the agent could be
overconﬁdent, underconﬁdent, or perfectly calibrated in his beliefs.
Suppose, for example, that the DEMO observer knew that
the agent’s sequence of perceived signals was (a,DEMO,a,b,b). In this
case the observer ’s posterior likelihood ratio is
L* 5
u(u1 q(1 2u))2 (1 DEMO)2
(1 2u)(1 2u1 qu)2 u2
5
(u1 DEMO(1 2u)) 2 (1 2u)
,
(1 2u1 DEMO)2 u
u
, ;q [ (0,1].
2u
1
Intuitively, the Bayesian observer recognizes the possibility
that the agent may have misread his second and third signals,
perceiving that they supported the hypothesis DEMO x 5 A when in
fact one or both may have supported the hypothesis that x 5 B.
Therefore, the Bayesian observer is less convinced that x 5 A than
the agent, who is overconﬁdent in his belief. More generally, a n
observer who knows that a biased agent has always believed in his
current hypothesis should judge the agent DEMO be overconﬁdent in
his belief, since there is a positive probability DEMO the agent has
misread signals that are counter to his favored hypothesis. An
observer who knows that a teacher has always believed that Bart
DEMO smarter than Marta should recognize that the teacher ’s conﬁr-
matory bias may have led him to misread evidence that Marta is
in fact DEMO
Alternatively, suppose that the Bayesian observer knew that
the agent’s sequence DEMO perceived signals was (b,b,a,a,a). Now the
DEMO 51
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
52
QUARTERLY JOURNAL OF ECONOMICS
observer ’s posterior likelihood ratio is
L* DEMO
(1 2u)(1 2u1 qu)u3
u(u1 q(1 2u))(12u)3
5
(1 2u1 qu)u2
.
(u1 q(DEMO 2u))(1 2u)2
u
, ; q [ (0,DEMO
2u
1
In this case, the Bayesian observer believes that the DEMO
may have misread his second signal, perceiving that it supported
the DEMO that x 5 B when in fact it may have supported the
hypothesis that x 5 A. Thus, the Bayesian observer believes that
there is a greater likelihood that x 5 A than the agent, who is
underconﬁdent in his belief. More generally, a n observer who
knows that a biased agent only recently came to believe in his
current DEMO after long believing in the opposite hypothesis
should judge the agent to be underconﬁdent in his belief, since the
agent may have misread one or more signals that support his
current hypothesis when he believed the DEMO An observer
who knows that a teacher initially thought that Bart was smarter
than Marta, but eventually started to believe that it was slightly
more likely that Marta was smarter than Bart, should conjecture
that the teacher is underconﬁdent about his new hypothesis.
When the teacher believed that DEMO was smarter than Marta, he
may have misinterpreted signals that Marta DEMO smarter. The
fact that the teacher came to believe that Marta was smarter
despite his initial bias toward believing that Bart was smarter
indicates DEMO the evidence is very strong that Marta is smarter.17
The preceding examples illustrate how information about the
order of the agent’s signals would signiﬁcantly DEMO an
17. As a discussant for this paper, Roger Lagunoff made DEMO interesting
suggestion that is especially relevant for the examples we are discussing here. In
our model, once the agent interprets a signal, he DEMO goes back and reinterprets
it—even if he later changes his hypothesis about the world. Hence we are not
capturing a form of belief updating DEMO sometimes observe: when somebody (ﬁnally)
comes around to change his world-view that he held for quite a while, he
sometimes experiences an epiphany whereby he goes back and reinterprets
previous evidence in light of DEMO new hypothesis, realizing that ‘‘the signs were
there all along.’’This suggests DEMO model in which an agent is biased in interpreting
not just the next signal, but all past signals, as supporting his current hypothesis
DEMO the world. While we suspect there is some truth to this, DEMO don’t believe that
people fully retroactively rebias themselves in this way. (DEMO have found no
psychological evidence about this one way or another.) DEMO such an alternative
model would rule out the possibility of ‘‘underconﬁdence’’ for recent converts, it
would leave all the predictions regarding overconﬁdence discussed in the remain-
der of the paper qualitatively the same, and magnify the magnitude of our results
(and simplify the proofs).
Page 52
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
53
outside observer ’s judgment about whether, and in what direction,
the agent’s beliefs were biased. Nevertheless, for the remainder of
the paper we assume that an outside observer only knows the
DEMO of a and b signals that the agent has received, and DEMO the
order in which he received them. This assumption enables us to
identify whether, on average, the agent is over- or underconﬁdent.
This DEMO to be the question that the psychological literature
addresses; presumably, it is also of interest to economists.
Clearly, if q 5 0, DEMO L*(na,nb) 5L(na,nb). When q . 0,DEMO
however, Proposition 1 establishes that L*(na,nb) ,L(na,DEMO). That
is, when the agent perceives that a majority of DEMO signals support
(say) Hypothesis A, he believes in A with DEMO probability than
is warranted.18
PROPOSITION 1. Suppose that na . nb and na 1 nb . 1. Then
L*(na,nb) ,L(na,DEMO).
Proposition 1 establishes that an agent who suffers from
conﬁrmatory bias will be overconﬁdent in his belief about which
state is most likely.
DEMO observer who knows the agent’s beliefs cannot usually
observe the exact sequence of the agent’s perceived signals.
Therefore, the observer ’s judgment about whether the agent is
under- or overconﬁdent depends on her belief regarding the
DEMO of the different possible sequences of signals. Proposi-
tion 1 establishes that overconﬁdence is the dominant force. The
intuition for this result is fairly DEMO: if you cannot
directly observe the agent’s past beliefs, but you know that he now
believes in Hypothesis A, you should surmise that, on average, he
spent more time in the past believing Hypothesis DEMO than Hy-
pothesis B. Consequently, you should surmise that, on average,
the agent misread more signals while believing in Hypothesis
A—contributing to DEMO he misread while believ-
ing in Hypothesis B—contributing to underconﬁdence. Proposi-
tion 1 hinges to some extent on our assumption that the agent
receives DEMO that are the same strength in every period. We
believe that (DEMO more complicated) versions of Proposition 1 hold
in more general models, but we show in Appendix 1 that undercon-
ﬁdence is sometimes possible DEMO the agent’s signals are of
different strengths in different periods.
18. All proofs are in Appendix 2. Because our model is entirely symmetric, we
shall for convenience present all results and much of our discussion solely DEMO the
case where A is perceived as more likely.
Page 53
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
54
QUARTERLY JOURNAL OF ECONOMICS
Proposition 1 shows that when the agent DEMO that the
state is x 5 A with probability µ . 0.5, the true probability that
the state is x 5 A is less than µ. Interestingly, the true probability
that A is the true state may be less than 0.5, meaning that B is
more likely than A. The possibility that the agent may suffer not
merely from overconﬁdence, but also from ‘‘wrongness,’’ arises
when the agent’s conﬁrmatory bias is DEMO and he has perceived
at least two signals in favor of each hypothesis.
To see the intuition for this result, suppose that the agent has
since his ﬁrst signal s1 5 a believed that Hypothesis A DEMO more
likely than B, but that he nevertheless has perceived two DEMO
st 5st 5b at two times t, t8 . 1. If DEMO agent’s conﬁrmatory bias is
severe (i.e., q < 1), only his ﬁrst perceived signal in favor of A
provides true evidence that DEMO 5 A. Once the agent believes that A
is true, his DEMO bias predisposes him to perceive that
subsequent signals support this belief, DEMO, therefore, additional
signals in favor of A are not very informative. But, because the
agent’s two perceived signals in favor of B conﬂict with what he
believes—that x 5 A is more likely—they reﬂect actual DEMO in
favor of B. Thus, although the agent has always believed DEMO x 5
A is more likely, he has effectively received only DEMO signal in favor
of A and two signals in favor of B. In this case the agent’s belief
that x 5 A represents extreme DEMO; if he had correctly
interpreted evidence, he would believe that x 5 B is more likely.
It is, of course, possible that DEMO A is more likely than
the agent realizes if he ﬁrst perceives a signal s1 5 b, falsely reads
a’s a s b’s for a while, and only later perceives enough a’s to come to
believe in A. And it is true that getting more true a’s than DEMO b’s
implies that Hypothesis A is more likely. Yet, it can DEMO shown that
these possibilities may be far less likely than the cases leading to
extreme overconﬁdence, so that the net effect that is more likely
that B is true than that A is true if the DEMO believes in A with
mixed evidence.
For example, suppose that the DEMO has perceived seven
signals, four a’s and three b’s. Given these DEMO, the agent’s
posterior beliefs are L(na 5 4,nb 5 DEMO) 5u/(1 2u) . 1; the agent
believes that the state x 5 A is more likely. Meanwhile, the true
likelihood ratio is L*(na 5 4,nb 5 3) 5
(1 2u)DEMO 1 8u3u** 1 7u2u**2 1 5uu**3]
1 (1 2u)2[u3u**u* 1 DEMO 1 2u4(1 2u)u*2
.
u3[8(1 2u)4 1 8(1 2u)3u* 1 7(1 2u)2u*2 1 5(1 2u)DEMO
1u2[(1 2u)3u**u* 1 4(1 2u)4u**] 1 2u(1 2u)4u**2
Page 54
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
55
Suppose that u5 .75. Then the agent’s posterior DEMO ratio is
L(4,3) 5 3. Suppose further that q DEMO .95, and therefore the agent
suffers from severe conﬁrmatory bias. Then, the true likelihood
ratio is L*(4,3) 5 .63, and DEMO x 5 B is more likely to be the
true state, DEMO the agent having perceived more a signals than
b signals.
Indeed, DEMO turns out to be the case that when conﬁrmatory
bias is very severe and the signals are very informative, then
whenever you observe the agent believing in Hypothesis A and
having perceived two or more b DEMO, then you should assume
that it is more likely that B DEMO true than A. We formalize this in
Proposition 2. Let L*(na,nb 0 q,u) be the appropriate beliefs as a
function of q and u. Then
PROPOSITION 2. For na . nb and nb DEMO 1, lime=0 L*(na,nb 0 1 2e,
1 2e) . 1. For all na . nb $ 2, lime=0 L*(na,nb 01 2e,1 2e) , 1.
That is, for u DEMO q both very close to 1, when the agent has
perceived DEMO or fewer b signals and believes in Hypothesis A, she
is DEMO correct (though overconﬁdent) in her beliefs; when the
agent has DEMO two or more b signals and believes in
Hypothesis A, she DEMO probably incorrect in her beliefs—Hypothesis
B is more likely to be true.
We emphasize that the very premise of the proposition means
that the DEMO to which it applies are uncommon; when both q
and u DEMO close to 1, the probability of perceiving anything besides
a sequence DEMO signals favoring the correct hypothesis is small.
Therefore, Proposition 2 tells DEMO about a very low-probability
event. In our example with seven signals, DEMO 5 .95, and u5 .75, the
probability that the signals are sufficiently mixed that the agent is
probably wrong is a little more DEMO one-half percent.
While we do not know more generally the highest probability
with which the agent can be wrong, some calibrations illustrate
that it can be relatively likely that the agent ends up with beliefs
that DEMO Bayesian observer would deem probably wrong. Tables
I–IV display, for various DEMO of n, u, and q, the probability that
L* ,h and L. 1or L* . 1/h and L, 1, where DEMO represents
different thresholds for how wrong the agent is. Table entries are
in percentage terms (rounded to the nearest percent), with rows
corresponding to different values of q and columns to different
values of u. (Dashes indicate an entry exactly equal to zero.)19
For instance, with u5 .6 and q 5 .5, the probability that the
19. The entries in Tables I–IV reﬂect direct calculations (performed by
computer) of DEMO probabilities in question.
Page 55
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
56
QUARTERLY JOURNAL OF ECONOMICS
TABLE I
PROBABILITY OF ‘‘WRONGNESS,’’ n DEMO 50, h5 1
u
q
0.6 0.7 0.7 0.9
.1 ————
DEMO 12 2 0 —
.3 21 9 1 0
.4 29 15 5 1
.5 27 18 10 3
.6 33 22 12 5
DEMO 27 21 15 7
.8 33 24 15 8
.9 21 17 12 9
TABLE II
PROBABILITY OF ‘‘WRONGNESS,’’ n 5 50, h5 1⁄2
u
q
0.6 0.7 0.7 0.9
.1 ————
.2 ————
.3 DEMO 5 1 —
.4 15 13 5 1
.5 19 18 9 3
.6 16 18 12 5
.7 18 21 13 7
.8 DEMO 16 15 7
.9 4 8 12 6
TABLE III
PROBABILITY OF ‘‘WRONGNESS,’’ n 5 50, h5 1⁄9
u
q
0.6 0.7 0.7 0.9
.1 ————
.2 ————
.3 ————
.4 — 5 — —
DEMO 3 12 7 1
.6 3 14 11 4
.7 2 11 12 6
.8 1 6 12 7
.9 0 4 7 6
DEMO 56
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
57
TABLE IV
PROBABILITY OF ‘‘WRONGNESS,’’ n 5 DEMO, h5 1
u
q
0.6 0.7 0.7 0.9
.1 ————
.2 DEMO
.3 ————
.4 ————
.5 ——— 2
.6 — 531
.7 3 325
.8 10 8 6 3
.9 3 221
agent has beliefs DEMO 50 signals that the observer would deem
probably wrong is about 27 percent. The probability in this same
case that his beliefs will lead DEMO observer to believe in the other
hypothesis with at least probability 2⁄3 is 19 percent, and the
probability that the observer would believe in the hypothesis
opposite to the agent’s with at least 9/10 probability DEMO about 3
percent.20
In the example above and in Proposition 2, DEMO agent can be
wrong in her beliefs. Even more surprising, perhaps, the true
probability that A is the correct hypothesis need not be DEMO
cally increasing in the proportion of a signals the agent perceives.
Continue to assume that the agent has received seven signals, but
now suppose that ﬁve support x 5 A and two support x 5 B. DEMO,
because u5 .75, the agent’s posterior likelihood ratio is L(DEMO,2) 5
27 .L(4,3). Meanwhile, the true likelihood ratio is
L*(na 5 5,nb 5 2)
5
(1 2u)2[7u2u**3 1 9uu**4 1 4u3u**2] 1 (1 2u)u3u**2u*
.
u2[7(1 2u)2u*3 1 9(1 2u)u*4 1 4(1 2u)DEMO 1u(1 2u)3u*2u**
20. Readers may note that these probabilities generally increase in q and
then decrease, with probability about 0 for q 5 0 and q 5 1. But they are not
single-peaked in DEMO This is because there are two factors at work in determining the
inﬂuence of q on the probability. As q increases, the probability that the agent will
end up with close-to-even mixes of a and b DEMO decreases continuously. But
because an increase in q increases the likelihood that any given combination of a’s
and b’s involves the agent being probabilistically DEMO, there will be at certain
points discrete jumps upward in the DEMO of wrongness for some values of q.
The result is an extremely poorly behaved function.
Page 57
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
58
QUARTERLY JOURNAL OF ECONOMICS
Maintaining the assumption that q 5 .95, L*(5,2) 5 .62 ,
L*(4,3) 5 .63. Therefore, the relative likelihood that the true state
is x 5 A versus x 5 B is smaller if the agent perceives that ﬁve DEMO
of seven signals support x 5 A than if he perceives that only four
out of seven signals support x 5 A.
While seemingly DEMO, this result reﬂects the fact
that the agent is more likely DEMO have perceived (truly informative)
signals sj 5b that conﬂict with DEMO belief that x 5 A when he has
perceived only two signals in favor of B than when he has
perceived three signals in DEMO of B. Intuitively, the agent is more
likely to have believed DEMO many periods that x 5 A in the former
case than in the latter case. Put differently, the agent is less likely
to have perceived (truly informative) signals sj 5a that conﬂict
with a belief DEMO x 5 B when he has perceived only two signals in
favor of B than when he has perceived three signals in favor of DEMO
The preceding examples illustrate that an agent who suffers
from conﬁrmatory bias may believe that one of the two possible
states is more likely DEMO the other when in fact the reverse is
true. Nevertheless, Proposition DEMO shows that a Bayesian observer
who knows only that a biased agent believes that x 5 A is more
likely than x 5 B DEMO herself believe that x 5 A is more likely.
Therefore, an DEMO who suffers from conﬁrmatory bias will ‘‘on
average’’ correctly judge which of the two possible states is more
likely, though, as Proposition 1 DEMO, he will always be
overconﬁdent in his belief.
Deﬁne L*(n) a s the likelihood ratio of a Bayesian observer
who knows that DEMO conﬁrmatory agent has perceived a total of n
signals, and knows DEMO na . nb, but does not know the exact
values of DEMO and nb. That is, the observer knows only that the
agent DEMO A is more likely than B, but observes nothing about
the DEMO of his beliefs. Then
PROPOSITION 3. For all n, L*(n) . 1.
In light of the above examples where the agent may DEMO wrong,
the simple generality of Proposition 3 may seem surprising. It is
reconciled with the examples by observing that the agent suffers
from DEMO only when his conﬁrmatory bias is very severe,
meaning that q is close to 1, and yet he has perceived mixed
signals about which state is more likely. But the agent is unlikely
to receive DEMO signals when his conﬁrmatory bias is strong,
because each signal st will tend to mirror s1.
Page 58
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DEMO tres
FIRST IMPRESSIONS MATTER
59
IV. BELIEFS AFTER AN INFINITE NUMBER OF SIGNALS
DEMO fully Bayesian agent—for whom q 5 0—will after an
inﬁnite number of signals come to believe with near certainty in
the correct hypothesis. We DEMO investigate the implications of
conﬁrmatory bias in the limit as an agent receives an inﬁnite
number of signals.
We begin with deﬁnitions and a DEMO that will help to
analyze this question. Suppose that the agent has thus far
received m 5 na 2 nb . 0 more perceived DEMO in support of
Hypothesis A than in support of Hypothesis B. Suppose further
that, as long as na . nb, prob (st 5a) 5g. Note that g5u*if B is
true, and g5u** if A DEMO true. We wish to consider some
preliminary results that hold in either case. We deﬁne p(m,g)as
the probability that there exists DEMO time in the future when the
agent will have received an equal number of a and b signals. (At
that time the agent’s posterior belief is the same as his prior belief,
prob (x 5 A) 5 0.5.) We have the following lemma, which is a
restatement of a well-known result from Feller [1968, pp. 344–
347).
LEMMA 1. For all m . 0, g$ 0.5, p(m,DEMO) 5 [(1 2g)/g]m. For g# 0.5,
p(m,g) 5 1.
We deﬁne PW as the probability that the agent, beginning
with the prior belief prob (x 5 A) 5 0.5, comes to believe with
certainty in the wrong hypothesis after receiving an inﬁnite
number of signals.21 That is, PW is the probability that, DEMO
the true state is x 5 A, the agent instead comes DEMO believe
irreversibly, with near certainty, that x 5 B. Proposition 4
characterizes PW as a function of q and u.
PROPOSITION 4. If DEMO . 1 2 1/(2u), then
PW 5
(1 2u)·(1 2 (1 2u*)/u*)
. 0.
(1 2 (1 2u) · ((1 2u*)/u*) 2u((1 2u**)/u**))
If q # 1 2 1/(2u), then PW 5 0.
When q . 1 2 1/(2u), u* 5 (1 2u) 1 qu. 0.5. When u* . 0.5,
DEMO once the agent comes to believe that the wrong hypothesis
about x is more likely, he is consequently more likely to receive a
21. Formally, PW ; prob (; k . 0 and ;e . 0, ' n* such that prob (na 2 nb . k
DEMO all n . n*) . 1 2e).
Page 59
@xyserv1/DEMO/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
60
QUARTERLY JOURNAL OF ECONOMICS
TABLE V
PROBABILITY OF BELIEVING IN WRONG DEMO AFTER OBSERVING AN INFINITE
NUMBER OF SIGNALS
q
u5 .6
u5 .667
u5 .75
u5 .9
.25 18 — — —
.333 26 12 DEMO —
.5 34 24 13 2
.75 38 31 22 8
signal st that conﬁrms this incorrect belief than he is to receive a
DEMO that conﬂicts with this incorrect belief. This guarantees
that there is a positive probability that the agent will never
overturn his incorrect hypothesis, and in fact come to believe more
and more strongly in that wrong DEMO Conversely, if q , 1 2
1/(2u), then u* , .5, which guarantees that the agent will, every
time he DEMO to believe the wrong hypothesis is more likely,
eventually come to abandon that belief. This in turn implies that
the agent will repeatedly DEMO to believe the correct hypothesis is
more likely; and since u** DEMO q(1 2u) .u. .5, he will
eventually come to believe in it with near certainty.
The proposition shows that, despite receiving an inﬁnite
number of signals, the agent may become certain that the
incorrect hypothesis is in fact true.22 This occurs when the agent’s
conﬁrmatory bias DEMO sufficiently severe. To illustrate the magni-
tude of PW, Table V DEMO PW for various values of u and q. Table
entries are in percentage terms (rounded to the nearest percent),
with rows corresponding DEMO different values of q and columns to
different values of u. (DEMO indicate an entry exactly equal to
zero.)
For example, suppose DEMO q 5 0.5 and u5 .75. Then PW 5 7⁄52,
meaning that approximately 13 percent of the time the agent will
eventually come DEMO believe with certainty in the wrong hypothesis.
As the quality of the agent’s true signal worsens he is more likely
to believe with certainty DEMO the wrong hypothesis. Indeed, a
corollary to Proposition 4 is that, ﬁxing any q . 0, limu=1/2 PW 5 1⁄2.
We now investigate the related question of when the agent
will maintain an incorrect DEMO belief. To do so, we relax our
22. It is straightforward DEMO show that the agent becomes certain that the
correct hypothesis about the state of the world is true with complementary
probability. Therefore, after an inﬁnite number of signals the agent will believe
that one of the DEMO is certainly true.
Page 60
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER 61
assumption that the agent initially believes that each DEMO x is
equally likely and suppose instead that the agent initially believes
that the wrong hypothesis is more likely to be true. For example, if
x 5 B is the true state of the world, then the agent initially
believes prob (x 5 A) 5 µ . DEMO Crucially, we assume that this
belief arose from signals that are DEMO of the new signals
that the agent receives, which are distributed DEMO outlined above.
Given the assumption that the signals are independently
distributed and ignoring integer problems, these prior beliefs can
be interpreted as if the agent has already received D more signals
supporting the incorrect hypothesis, where
µ 5uD/[uD 1 (1 2u)D].
This formula implicitly deﬁnes a function D(µ). The agent
must receive D(µ) more conﬂicting signals st than conﬁrming
signals in order to reach a posterior belief DEMO the two possible
states of the world, A and B, are equally likely.
We deﬁne PW (µ) as the probability that the DEMO, beginning
with the prior belief µ . 0.5 that the wrong DEMO about the
state of the world is true, comes to believe DEMO certainty in the
wrong hypothesis after receiving an inﬁnite number of signals.23
PROPOSITION 5. Choose any e. 0 and any µ . 0.5. Then
(i) For all u [ (0.5,1), there exists q DEMO 0 such that PW (µ) .
1 2e.
(ii) For all q . 0, there exists u. 0.5 such that PW (DEMO) . 1 2e.
Proposition 5 says that an agent who begins DEMO an arbi-
trarily small bias in the direction of the incorrect hypothesis will
almost surely maintain his belief in this hypothesis when either of
DEMO conditions is satisﬁed. First, and not very surprisingly, this
will occur when the agent is subject to severe conﬁrmatory bias.
When q is DEMO close to 1, then the agent almost never receives
signals that DEMO with his initial belief, and therefore it is not
surprising that DEMO belief is rarely overturned. Second, and
somewhat more surprisingly, the agent almost surely maintains
his incorrect belief provided that his true signals are DEMO weak,
meaning that u is very close to 0.5. This result does not depend on
the level of conﬁrmatory bias, so long as q . 0. This result means
that if the agent receives only DEMO weak feedback from his
environment and is subject to any conﬁrmatory bias, he almost
23. PW (0.5) 5 PW.
Page 61
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
62
QUARTERLY JOURNAL OF ECONOMICS
never overcomes any initial beliefs that are DEMO incorrect,
and in fact comes to believe that the incorrect hypothesis is
certainly true. While one should not overinterpret the second
result in DEMO 5—we can question whether agents really
pay attention to such weak feedback—the conclusion is neverthe-
less very striking. Propositions 4 and 5 show that DEMO inﬁnite
sequence of signals will not necessarily lead people to overcome
erroneous beliefs; rather, people may simply become more and
more conﬁdent in DEMO erroneous beliefs.
Table VI displays PW (µ) for various values of u, q, and µ. If u
and µ are chosen in DEMO a way that D(µ) is an integer, and q . 1 2
1/2u, it follows from Lemma 1 that
PW (DEMO) 5 11 2 31 2u*4D(µ) 2 1 1PW (0.5) 31 2u*4D(µ) 2 . 0.
u*
u*
Table entries are in percentage terms (rounded to the nearest
percent), with rows corresponding to different values of q and
columns to different values of u and DEMO prior belief µ. (Dashes
indicate an entry exactly equal to zero.)DEMO
For example, suppose that u5 .551 and µ 5 .6. In DEMO case
D(µ) 5 2, meaning that the agent must receive two more signals
that conﬂict with rather than conﬁrm his prior belief DEMO order to
believe that the states A and B are equally likely. But if q 5 .333,
there is nearly an 80 percent DEMO that the agent will never
overturn his incorrect prior belief. Clearly, DEMO does not
necessarily lead the agent to correctly identify the true state.
V. CONFIRMATORY BIAS IN A PRINCIPAL-AGENT MODEL
Conﬁrmatory bias is likely to DEMO economic behavior in
many different arenas. In this section we develop a simple
TABLE VI
PROBABILITY OF MAINTAINING AN INCORRECT PRIOR BELIEF AFTER RECEIVING DEMO
INFINITE NUMBER OF SIGNALS
q
u5 .6, µ 5 .6,
DEMO(µ) 5 1
u5 .551, µ 5 .6,
D(µ) 5 2
u5 .75, µ 5 .75,
D(µ) 5 1
u5 .634, µ 5 .75,
D(µ) 5 2
DEMO 32 67 — 24
.33 51 79 — 56
.5 72 92 48 85
.75 89 99 82 98
Page 62
@xyserv1/disk4/CLS_jrnlkz/DEMO/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
63
illustrative model of a principal-agent relationship, a context
where we think conﬁrmatory bias is likely to be important. The
premise DEMO the model is that an agent may take inappropriate
actions not solely because of intentional misbehavior—moral
hazard—but also because of unintentional errors arising from
DEMO bias. Speciﬁcally, because an agent who suffers from
conﬁrmatory bias will DEMO overconﬁdent in his judgment about how
likely various actions are to pay off, he may be prone to taking
actions that are riskier and more ‘‘extreme’’than is optimal for the
principal. Such overconﬁdence seems to reﬂect DEMO intuition
among some researchers: at a conference one of the authors
DEMO, a leading economist conjectured that bad investment
decisions by businesses in DEMO Europe receiving bank loans
were more often the result of overconﬁdence by borrowers than of
intentions to mislead banks. Even more directly along the DEMO of
our model, Wood [1989] asserts that money managers become
more DEMO in their investment decisions as they gather more
information—even when the quality of their investment decisions
is not improved.
A principal who is aware DEMO an agent’s conﬁrmatory bias will
wish to design incentives that both cause the agent to internalize
the negative consequences of bad choices and prevent DEMO
based on good-faith overconﬁdence. In particular, incentives that
lead the agent DEMO collect a lot of information may not be optimal if
the agent suffers from severe conﬁrmatory bias and, hence,
becomes more overconﬁdent as he collects more information. The
principal may therefore wish to mute the DEMO incentives
relative to what would be optimal in the absence of conﬁrmatory
bias.
While an exhaustive analysis of the effect of conﬁrmatory bias
on DEMO relationships is beyond the scope of this paper, we now
develop DEMO simple illustrative model along these lines. Suppose
that a principal hires an agent to allocate initial wealth W 5 1
between the different investments DEMO the set I 5 5IA, IB, I C6. The
investment IC is risk-free; it always yields a gross return r(IC) 5 DEMO
Investments IA and IB, on the other hand, are risky; DEMO returns
depend on the state of nature x [ 5A,B6. Conditional on the state x,
the gross returns from IA and IB DEMO r(IA 0 A) 5 r(IB 0 B) 5 R [ (1,2)
and r(IA 0 B) 5 r(DEMO 0 A) 5 0. Let u(·) be the principal’s Von Neumann-
Morgenstern utility function for money. Because the principal
may be risk-averse, we assume that u8 . 0 and u9 # 0. Consistent
with DEMO model that we developed in the previous sections, the
Page 63
DEMO/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
64
QUARTERLY JOURNAL OF ECONOMICS
principal and the agent cannot observe the DEMO x, and they hold a
common prior belief that prob (x 5 A) 5 prob (x 5 B) 5 0.5.
Hence, DEMO the agent learns nothing more about the true state, the
optimal DEMO is in the riskless investment IC; if he learns
sufficiently more—generating DEMO sufficiently different from
.5—he will perceive it as optimal to invest some money in one of
the two risky investments.24
Before choosing how to DEMO the principal’s wealth, the
agent has the opportunity to observe informative DEMO about
the true state, although the agent’s conﬁrmatory bias may lead
DEMO to misinterpret these signals. We assume that the signals
that the agent receives, and the way he perceives these signals,
accord with the model in the previous sections.
For both analytic ease and to highlight DEMO role of conﬁrma-
tory bias, we abstract away from the usual DEMO con-
cerns: we assume that the agent costlessly observes signals about
DEMO state x and expends no effort when making decisions on the
principal’s behalf. Under this assumption, an arbitrarily small
incentive to identify the true state would lead the agent to observe
an inﬁnite number of signals, after which he would believe that he
could identify the true state DEMO near certainty. Furthermore, to
abstract away from issues of optimal risk-sharing DEMO the
agent and the principal, we assume that the agent is (nearly)
inﬁnitely risk-averse. Therefore, the principal must offer the
agent a nearly constant wage.25 Under these assumptions, the
24. While the language and notation suggest that we are referring to
well-deﬁned investment portfolios (e.g., DEMO different bonds), we mean for the
model to apply as well to internal organizational incentives to pursue ambiguously
deﬁned projects. Indeed, this alternative interpretation may better ﬁt the formal
model in some respects. Note that DEMO is crucial to our analysis that the agent cannot
or does not merely report his beliefs to the principal, but rather implements a
strategy himself based on his beliefs. If the principal knew the agent’s beliefs DEMO
the extent of his conﬁrmatory bias, she could form her own DEMO about the true
state of the world and then directly choose the action that would maximize her
expected payoff.
25. These assumptions raise a DEMO point. If the agent anticipated gathering
an inﬁnite number of signals, DEMO would be willing to accept a contract that yielded
a payoff that depended on the outcome of a risky investment, even if he were
inﬁnitely risk-averse. This is because the agent would anticipate being able to
DEMO the true state with virtual certainty. But, if the hypothesis of DEMO ﬁrst part
of Proposition 4 is satisﬁed, the agent will be DEMO in his judgment after
observing an inﬁnite number of signals. Therefore, DEMO a contract would impose
more risk on the agent—and yield a lower expected utility—than he anticipated.
We assume here that the principal cannot exploit DEMO agent’s conﬁrmatory bias by
convincing him to sign a contract that yields an expected payoff that is less than
the agent’s reservation payoff. This DEMO means that the principal cannot
use the agent as a ‘‘money pump,’’and its empirical validity deserves investigation.
The issue of whether to focus DEMO on ‘‘efficiency contracts’’ rather than
‘‘money-pumping contracts’’ is a more general one that is likely to arise in
Page 64
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/DEMO/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
65
incentives that the principal offers to the agent DEMO the princi-
pal’s payoff only through their effect on the investment decision
that the agent makes. The principal does not need to compensate
the DEMO for gathering information, and she cannot transfer risk
to the agent.
DEMO assumptions permit us to focus on two polar cases. In
the ﬁrst case, the principal gives the agent no incentive to collect
information, DEMO the agent allocates the principal’s wealth with
no information beyond his prior belief. In the second case, the
principal gives the agent an arbitrarily small incentive to collect
information, and the agent allocates the principal’s wealth after
observing an inﬁnite number of signals and coming to believe with
DEMO certainty that he has identiﬁed the true state.
Suppose ﬁrst that the principal offers the agent no incentive
to gather information. Because R , DEMO and the principal’s prior
belief is prob (x 5 A) 5 0.5, it is optimal for the principal to direct
the agent to invest all of the principal’s wealth in the risk-free
asset IC. Now DEMO that the principal offers the agent a small
incentive to identify the true state. For instance, suppose that the
principal offers to pay the agent an arbitrarily small fraction of
the principal’s gross return. Because it DEMO free for the agent to
collect information, he would observe an DEMO number of
signals and come to believe that he could identify the true state
with certainty. These extreme beliefs would lead the agent to
DEMO all of the principal’s wealth to one of the risky assets. If,
for example, the agent thought that A was surely the true state, he
would allocate all of the principal’s wealth to asset IA.26
If q # 1 2 1/(2u) (i.e., if conﬁrmatory DEMO is sufficiently weak),
Proposition 4 establishes that the agent will DEMO identify
the true state with near certainty if he collects enough signals.
Hence, under our assumption that it is costless for the agent to
gather information and that in every state of the world one or DEMO
other of the ‘‘risky’’ investments is optimal, it would then be
DEMO for the principal to offer a contract that would lead the
agent to collect an inﬁnite number of signals, and the principal
would receive a payoff u(R) . u(1).
If q . 1 2 1/(2u), on the other hand, Proposition 4 establishes
DEMO formal models of incentives for boundedly rational agents. See, for
instance, O’Donoghue and Rabin [1997], who study incentive design for agents
who irrationally procrastinate, and who discuss various rationales for focusing on
efficiency contracts.
26. We assume that short-selling is impossible, so the agent could not allocate
more than $1 to asset a by, for instance, selling investment DEMO short.
Page 65
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
66
QUARTERLY JOURNAL OF ECONOMICS
that the agent’s (completely conﬁdent) belief DEMO the true state
is wrong with positive probability. It can be shown that he
correctly identiﬁes the true state with probability
µ*(u,q) 5
u[2(u1 q(1 2u)) 2 1](1 2u1 qu)DEMO
q[1 2 2(1 2 q) u(1 2u)]
.
DEMO the agent is fully conﬁdent that he has identiﬁed the true
state, he invests all of the principal’s wealth in the risky asset he
believes is most proﬁtable, so the principal’s payoff is µ*(u,q)u(R) 1
(1 2 µ*(u,q)) u(0)DEMO Note that µ*(u,q) is increasing in u and decreas-
DEMO in q, meaning that the agent identiﬁes the true state with
DEMO probability when he receives more informative signals and
lower probability when his conﬁrmatory bias is more severe.
The principal does not want the agent DEMO become ‘‘informed’’
when u(1) $ µ*(u,q)u(R) 1 (1 2 µ*(u,q)) u(0). Deﬁne µ a s satisfy-
ing u(1) 5 µ u(R) 1 (1 2 µ) u(0); if the agent correctly identiﬁes the
true state with probability µ after observing an inﬁnite number of
signals, the principal is just willing for the agent to become
informed about DEMO state x. Because µ*(u,q) $u, the principal
always offers the agent an incentive to become informed if u$ µ.
That is, if the principal prefers all her money invested in a risky
investment DEMO on just one signal to having all her money
invested in the risk-free investment, she will provide incentives to
the agent. When u, DEMO, on the other hand, we have Proposition 6.
PROPOSITION 6. Suppose that u, µ.
(i) There exists q* [ (1 2 DEMO/2u,1] such that the principal
does not offer the agent an incentive to become informed
about the state x if and only if DEMO $ q*.
(ii) For any q [ [0,1], there DEMO u* [ (0.5,µ] such that the
principal does not offer DEMO agent an incentive to become
informed about the state x if and only if u#u*.
When u, µ, the principal does not want DEMO agent to observe
signals about the state x either if conﬁrmatory bias is very severe
or if the agent receives very weak signals. In DEMO case, there is a
strong possibility that an ‘‘informed’’ agent would DEMO
identify the true state, although the agent himself would overcon-
ﬁdently DEMO that he could identify the true state with near
certainty. If the agent’s overconﬁdence is sufficiently severe, the
principal prefers not to offer the agent any incentive to become
informed, in which case the agent will invest the principal’s
wealth in the riskless asset.
Page 66
@xyserv1/disk4/DEMO/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
67
The principal’s degree of risk aversion also inﬂuences DEMO
or not he wants the agent to observe signals about the state x.
While Proposition 6 shows that there are conditions where even a
DEMO principal eschews incentives for the agent, the princi-
pal is more DEMO by the overconﬁdence when she is more
risk-averse, in the usual DEMO deﬁned by Pratt [1964]. Indeed,
whenever conﬁrmatory bias is severe enough that the agent might
be wrong even after gathering an inﬁnite number DEMO signals, a
principal who is sufficiently risk-averse will prefer not to DEMO her
agent any incentive to become informed. We formalize this idea in
Proposition 7.
PROPOSITION 7. Suppose that u [ (0.5,1), q [ (1 2 1/2u,1], and u(·)
is DEMO Von Neumann-Morgenstern utility function u(·) satisfy-
ing u8 . 0, u9 # 0.
(i) Suppose that u(1) # µ*(u,q)u(R) 1 (1 2 µ*(u,q))u(0).
Then there exists a function g(·) such that g8 . 0, g9 # 0,
and g(u(1)) $ µ*(u,q) g(u(R)) 1 (1 2 µ*(u,DEMO)) g(u(0)).
(ii) Suppose that u(1) $ µ*(u,q)u(R) 1 (1 2 µ*(u,DEMO))u(0).
Then for any function g(·) such that g8 . 0, g9 # 0,
g(u(1)) $ µ*(u,q) g(u(R)) 1 (1 2 µ*(DEMO,q)) g(u(0)).
(iii) In both (i) and (ii), v(·) 5 g(u(·)) is a Von Neumann-
Morgenstern utility function that represents preferences
that are globally DEMO risk-averse than those repre-
sented by u(·).
Suppose that Marta, whose preferences are represented by
u(·), wishes to give her agent the incentive to become informed
about x. The proposition establishes that DEMO exist preferences
that are globally more risk-averse than Marta’s under which a
principal would prefer not to give her agent the incentive to
become DEMO Furthermore, if Marta does not wish to give her
agent an DEMO to become informed about the state x, then any
principal who DEMO globally more risk-averse than Marta would also
choose not to offer incentives to an identically biased agent facing
the same investment decision.
The preceding DEMO reﬂects an assumption that a biased
agent who feels he is fully informed will invest all of the principal’s
wealth in a single risky DEMO The agent will pursue such a
strategy if, for example, the principal offers the agent a ﬁxed share
of the principal’s gross investment DEMO Our analysis assumes,
of course, that the principal cannot directly DEMO on decisions,
Page 67
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
68
QUARTERLY JOURNAL OF ECONOMICS
only on returns. But it also implicitly DEMO that the principal
cannot punish the agent for having too high an expected return. If
she could, then she might wish for the agent to gather some
information—and then provide incentives such that the (overcon-
ﬁdent) agent will be afraid of making too much money for the
principal.27 There might be a variety of reasons, of course, why
such DEMO are infeasible or undesirable. If, for example, the
principal is uncertain about either the true value of R or the
extent of the DEMO conﬁrmatory bias q, she may not have enough
information to propose DEMO contract that always leads the agent to
invest optimally.
Nevertheless, even DEMO the presence of uncertainty the princi-
pal would generally be better off if she could restrain the agent’s
ability to take an extreme action. DEMO feasible to restrain the agent,
the principal could propose a contract that stipulates that the
agent cannot invest more than a fraction of DEMO wealth in any
single asset. Even more simply, the principal could DEMO give the
agent only a portion of her wealth to invest. All of these strategies
serve the same purpose, namely preventing an overconﬁdent
agent from investing too much of the principal’s money in a single
asset DEMO still taking advantage of the information that the
agent actually does possess.
VI. DISCUSSION AND CONCLUSION
We believe that conﬁrmatory bias is important in DEMO social
and economic situations, and that variants of the formulation
developed DEMO this paper can be usefully applied in formal economic
models. For instance, conﬁrmatory bias is likely to matter when a
27. From the principal’s point of view, the optimal proportional allocation to a
risky investment, DEMO, maximizes the objective function V(a) ; µ*(u,q)
u(1 1 (R 2 1)a) 1 (1 2 µ*(u,q))·(1 2 a). The optimal allocation a* then satisﬁes
the following necessary and sufficient condition:
$ 0,
a* DEMO 1
µ*(u,q) u8(1 1 (R 2 1) DEMO)(R 2 1) 2 (1 2 µ*(u,q))u8(1 2 a*) 5 0,
a* [ [0,1]
# 0,
a* 5 0.
The principal would like to propose a contract DEMO that the agent
receives an arbitrarily small reward when the principal’s gross return is 1 1
(R 2 1)a*, no payoff when DEMO principal’s gross return is 1 2 a*, and a large penalty
DEMO any other gross return. Such a contract would punish the agent if he chooses an
allocation that is more extreme than the principal desires.
DEMO 68
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
69
decision-maker must aggregate information from many sources.
In DEMO setting where several individuals (nonstrategically) transmit
their beliefs to a principal, how should she combine these reports
to form her own beliefs? DEMO the principal thought that the agents
were Bayesians, then she would DEMO very sensitive to the strength
of the agents’ beliefs. Suppose, for DEMO, that the principal
knows that all agents receive signals of strength DEMO .6. Then if
two agents report believing Hypothesis A with probability .6 and
one agent reports believing Hypothesis B with probability .77
(meaning he has gotten three more b signals than a signals), the
principal DEMO believe in Hypothesis B with probability .6.
What if the principal were aware that agents were subject to
conﬁrmatory bias? If conﬁrmatory bias is so severe that only an
agent’s ﬁrst signal is very informative, then the principal may
wish to discount the strength of agents’ beliefs and DEMO
aggregate according to a ‘‘majority rules’’criterion. In the example
above, for DEMO, the principal should perhaps think Hypothe-
sis A is more likely, because two of three agents believe in it. We
think this intuition DEMO merit, but it is complicated by the fact that
agents who DEMO relatively weakly in a hypothesis may be more
likely to be wrong than right. So, if the principal thought
conﬁrmatory bias were severe and were very sure that all agents
had received lots of information, then in our example she should
believe that all three agents have provided DEMO in favor of
Hypothesis B. Hence, she should believe more in DEMO B
than she would if the agents were Bayesian.
We suspect nonetheless that the ‘‘majority-rules intuition’’ is
more valid, especially when considering realistic uncertainty by
the principal about how many signals each agent has received. If
DEMO were highly uncertain about how much information each
agent received, she DEMO assume weak beliefs merely reﬂected
that an agent got few signals. Similarly, if the principal thinks
susceptibility to conﬁrmatory bias is heterogeneous, she DEMO
infer that an agent’s weak beliefs indicate merely that he is not
susceptible to overconﬁdence, and count weak beliefs as much as
strong beliefs. Indeed, she may then count them more heavily,
since conﬁrmation-free agents are not only less likely to be
overconﬁdent, they are also less likely to be wrong.
This intuition that, when aggregating information from a
group, it may be wise to count the number of people with given
Page 69
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
70
QUARTERLY JOURNAL OF ECONOMICS
beliefs rather than the strength of their DEMO suggests a
related prescription for organizational design: relative to what
she DEMO do with Bayesian agents, a principal may prefer to hire
more DEMO to collect a given amount of information. That is,
while the lower value of information processing by conﬁrmatory
agents may mean that either DEMO or fewer should be hired than if
they were Bayesian, ﬁxing DEMO total amount of information
processing a principal wants done, with conﬁrmatory DEMO she
should prefer more people thinking than if they were fully
rational agents.
Imagine, for instance, that a principal allocated 1000 ‘‘sig-
nals’’ DEMO different agents, whose reports she would aggregate
to form her own DEMO There are various costs that might
inﬂuence how many agents to have, or (equivalently) how many
signals to allocate per agent, e.g., the ﬁxed cost of hiring new
agents and decreasing returns from each DEMO due to fatigue
or the increasing opportunity cost of time. But the optimal
number of conﬁrmatory agents is likely to be greater than the
DEMO number of Bayesian agents. Intuitively, the value of
allocating a signal DEMO a conﬁrmatory agent is less than the value of
allocating it to a Bayesian agent, unless the conﬁrmatory agent is
unbiased by previous signals. For example, if the principal hires
1000 conﬁrmatory agents, each to DEMO his observation of a
single signal, then she receives all of DEMO information contained in
the signals. If the principal instead hires one conﬁrmatory agent
to report his beliefs after interpreting 1000 signals, she may get
far less information. Both signal allocations would yield the same
amount of DEMO if the agents were Bayesian.
We suspect that a similar issue plays out less abstractly in
different aspects of the legal system. While other DEMO are
probably more important, conﬁrmatory bias may help to explain
some DEMO of the American jury system, such as the bias
toward more DEMO than fewer jurors and the use of a majority-
rules criterion with no mechanism (other than jury deliberations)
to extract the strength of all participants’ convictions. Conﬁrma-
tory bias may also help to justify the DEMO of multiple judges to
reach a decision when using a single judge seems to be more
cost-effective. Appeals, for example, are usually heard DEMO a panel
of judges that does not include the trial judge, DEMO some legal
scholars (e.g., Resnik [1982]) argue that the judge DEMO adjudicates
at trial should not also supervise settlement bargaining and
Page 70
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
71
pretrial discovery, which is the process by which litigants request
information from each other. These observers fear that the trial
DEMO might learn things during pretrial activities that would
‘‘bias’’ her during the trial. The notion that the quality of the
judge’s decisions during the DEMO suffers if she has more informa-
tion relevant to the case is somewhat puzzling; worries that she
can be ‘‘biased’’ by more information certainly ﬂies in the face of
the Bayesian model. While there are various DEMO of bias that one
could imagine (e.g., that the judge will use her rulings during the
trial to punish perceived misbehavior during the DEMO pro-
cess), the evidence on conﬁrmatory bias raises the possibility that
the judge will form preconceptions during the discovery phase of
litigation that DEMO cause her to misread additional evidence
presented at trial.
Finally, the DEMO process itself nicely illustrates how the
polarization associated with conﬁrmatory bias may have impor-
tant implications. Discovery takes place when potential litigants
think that DEMO trial is relatively likely, and hence wish to engage in
the DEMO effort of preparing for that trial. Nonetheless, litigants
often settle their DEMO out of court during or after the discovery
process. Discovery encourages this settlement by promoting the
exchange of information between the litigants and, hence, helping
to align their perceptions of the likely outcome at trial. But while
the evidence garnered during the discovery process sometimes
does lead to DEMO before trial, conﬁrmatory bias suggests
that the discovery process may be DEMO efficient at achieving such
settlement than would be hoped: if a DEMO of evidence is ambigu-
ous, it may move the parties’ beliefs DEMO apart. Each litigant
will interpret the evidence through the prism of his or her own
beliefs, and each may conclude that the evidence supports his or
her case. More generally, efforts to reduce disagreements by
providing evidence to the parties involved in a conﬂict may not be
as DEMO to achieve as one would hope.
Much of our discussion above implicitly makes an assumption
about judgment whose psychological validity has not (to our
knowledge) been determined by research: that somebody design-
ing an institution DEMO aware of the bias of others. We suspect that
usefully incorporating conﬁrmatory bias into economic analysis
will depend upon the extent to which people DEMO that others
suffer from conﬁrmatory bias. It could be that people are well
aware of biases in others’judgment, or that people are unaware of
Page 71
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
72
QUARTERLY JOURNAL OF ECONOMICS
the general tendency toward conﬁrmatory bias.28 Investors DEMO
hire a money manager might or might not believe that the money
manager suffers from a conﬁrmatory bias (and is therefore prone
toward overconﬁdence). A principal hiring an employee to make
decisions might or might DEMO know that the employee will be prone
to making such errors. By the logic of economic models that
involve multiple agents, these distinctions are likely to matter:
Just as assuming that rationality is common knowledge DEMO often
very different than merely assuming that people are rational,
assuming that agents are aware of others’ irrationality may be
very different than DEMO assuming that people are irrational.
How might economic implications depend on people’s aware-
ness of others’ conﬁrmatory bias? One possibility is that people
might exploit the bias of others. A principal may, for instance,
design an incentive contract for an agent that yields the agent
lower wages DEMO average than the agent anticipates, because the
agent will be overconﬁdent DEMO her judgments in ways that may
lead her to exaggerate her yield from a contract. Conversely,
others may wish to mitigate bias rather DEMO exploit it. A principal
may be more concerned with overcoming costly bias of an agent
than with exploiting it, and design contracts that avoid errors.
APPENDIX 1: DIFFERENTIAL-STRENGTH SIGNALS AND
UNDERCONFIDENCE
If the agent receives signals of different strengths in different
periods, it is possible that the agent will be underconﬁdent in his
belief about which of the two states DEMO most likely. Suppose, for
example, that the agent receives three signals st [ 5a,b6, t [ 51,2,36.
Suppose that the ﬁrst two signals are distributed according to
prob (st 5 a 0 A) 5 prob (st 5 b 0 B) 5u. 0.5, DEMO [ 51,26, but that the
agent’s third signal is distributed DEMO to prob (s3 5 a 0 A) 5
prob (s3 DEMO b 0 B) 5u3/[u3 1 (1 2u)3]. That is, the agent’s third
signal is three times as strong as ﬁrst- or second-period signals. As
before, with probability q . 0 the agent misreads signals that
conﬂict with his belief about which state is more likely. (This
28. Unfortunately, while this issue may turn out to be central to economic
applications of conﬁrmatory bias (and to applications of other psychological
biases), we have not found psychological research that convincingly resolves this
DEMO There is a small literature in ‘‘construal’’ that concerns third-party aware-
ness of biases. See, e.g., Ross [1987], and tangentially Paese and Kinnaly [1993].
We have not found investigation of this issue in the context DEMO conﬁrmatory bias or
overconﬁdence.
Page 72
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
73
means that the probability of misreading is independent DEMO the
strength of the signal.)
Suppose that the agent perceives that his ﬁrst two signals
support Hypothesis B, while his third signal supports Hypothesis
A. Formally, the agent perceives (s1 5b,s2 5b,s3 DEMO). Given
these perceived signals, the agent’s posterior likelihood ratio is
DEMO(s1 5 b,s2 5 b,s3 5 a) 5u/(1 2u) . 1. Now, suppose that a
Bayesian observer knows both DEMO the agent’s posterior likeli-
hood ratio is L5u/(1 2u) and that the agent suffers from
conﬁrmatory bias. Given the distributions of the DEMO, the
observer is able to infer that the agent has perceived (s1 5b,
s2 5b,s3 5a). Then, the observer ’s belief regarding the relative
likelihood that the state is x 5 A DEMO x 5 B is given by
L*(b,b,a) 5
(1 2u)(1 2u1 qu)(1 2 q)u3
u(u1 DEMO(1 2u))(1 2 q)(1 2u)3
5
(1 2u1 qu)u2
.
(u1 q(1 2u))(1 2u)2
u
,
2u
;q [ (0,1].
1
Therefore, given DEMO she infers about the agent’s sequence of
perceived signals, a Bayesian DEMO believes that the biased
agent is underconﬁdent in his belief that the true state is A.
This underconﬁdence result arises here because the observer
DEMO the exact sequence of the agent’s perceived signals from his
likelihood ratio. In this light, the results here are the same as the
path-dependent underconﬁdence example in the text—if the
agent is known to have only DEMO come to believe in a
hypothesis, then he will be underconﬁdent. DEMO our main model, in
which the agent receives signals of equal DEMO, an observer
who knows the agent’s beliefs cannot infer the exact DEMO of
the agent’s perceived signals.
While there may be some domains in which this differential-
signal model is applicable, constructing examples of underconﬁ-
dence seem to require clever contrivance. It is ﬁrst of all clear that
DEMO ‘‘overconﬁdence’’ result will be stronger than the underconﬁ-
dence result in one sense: in the model of this paper, the
overconﬁdence result holds DEMO all ﬁnal beliefs by the agent. Any
underconﬁdence example will clearly hold for only some ﬁnal
beliefs—because it will always be the case that DEMO conﬁrmatory
agent is overconﬁdent when all his perceived signals favor one
hypothesis.
Page 73
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
74
QUARTERLY JOURNAL OF ECONOMICS
We suspect, moreover, that more complicated DEMO weaker
versions of Proposition 1 will hold in more general models. The
underconﬁdence result seems to rely on the agent having received
a small DEMO of signals, where certain ﬁnal beliefs can only be
generated by DEMO unique path of updating. Consequently, it is very
likely that a DEMO overconﬁdence’’ result would hold—once an
agent is likely to have received large numbers of signals of all
strengths, we can assure that L* ,DEMO when L. 1.
APPENDIX 2: PROOFS
Proof of Proposition 1. We DEMO notice that
and
prob (na,nb 0 B ) 5
nb
DEMO (i,i 0 B)c(na 2 nb,na 1 nb DEMO 2i)
i 5 0
o
·(1 2u)[(1 2u) 1 qu]na212i[(1 2 q)u]nb2i,
where c(na 2 nb,n a 1 nb 2 2i) is the number of ways to choose
na 2 nb more a signals than b signals in na DEMO nb 2 2i draws
without ever having chosen an equal number of a and b signals,
and prob (i,i 0 x) DEMO the probability of observing i perceived a and i
perceived b signals in 2i draws when the true state is x [ 5A,B6.
DEMO the symmetric distribution of the signals, prob (i,i 0 A) 5
prob (i,i 0 B).29 Therefore, prob (na,DEMO 0 A) and prob (na,nb 0 B) differ
prob (na,nb 0 A ) 5
nb
prob (i,i 0 A )c(na 2 nb,na 1 nb 2 2i)
i 5 0
o
· u[u1 q(1 2u)]na212i[(1 2 q)(1 2u)]nb2i
29. Formally,
i
i2j max5i2j2k21,0)6
prob (i,i 0 A ) 5 prob (i,i 0 B ) 5 o k50
o
i50
j50 o
· djklu ju**k((1 2 q)(1 2u)) j1k(1 2u)i2 j2k2lu*l((1 2 q)DEMO)i2 j2k.
The coefficient djkl is the number of ways to choose j signals in favor of the correct
hypothesis when the agent believes DEMO two hypotheses are equally likely, k biased
signals favoring the correct DEMO, i 2 j 2 k 2 l signals in favor of DEMO incorrect
hypothesis when the agent believes the two hypotheses are equally likely, l biased
signals in favor of the incorrect hypothesis, j 1 DEMO unbiased signals opposing a
belief in favor of the correct hypothesis, DEMO i 2 j 2 k unbiased signals opposing a
belief in favor of the incorrect hypothesis.
Page 74
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 DEMO
FIRST IMPRESSIONS MATTER
75
only by the effect of the signals that DEMO agent perceives after the
last time that he believes the two hypotheses are equally likely.
Using Bayes’Rule,
(1.1)
L*(na,nb)
5 prob (na,nb 0 A )
prob (na,nb 0 B )
Snb0 prob (i,i 0 A )c(na 2 nb,na 1 nb 2 2i)
i5
5
· u[u1 q(DEMO 2u)]na212i[(1 2 q)(1 2u)]nb2i
.
Snb0 prob (i,i 0 B )c(na 2 nb,na 1 nb 2 2i)(1 2u)
i5
? [(1 2u) 1 qu]na212i[(DEMO 2 q)u]nb2i
Because [u1 q(1 2u)]/[(1 2u) 1 qu] ,u/(1 2u), ;q [ (0,1],
it follows that
(1.2) [u1 q(1 2u)]na212i (1 2u)na212i # [(1 2u) 1 qu]na212iuna212i
with a strict inequality for i 5 0 since the hypotheses imply that
na $ 2. DEMO and multiplying (1.2) by (1 2u)(1 2 q)nb2i and
rearranging, we have
(1.3)
u[u1 q(1 2u)]na212i(DEMO 2 q)nb2i(1 2u)nb2i
# (1 2u)[(1 DEMO) 1 qu]na212i(1 2 q)nb2iunb2i 11 u
2u2na2nb
;i, DEMO a strict inequality for at least i 5 0 since na $ 2. Using
(1.1), (1.3), and prob (i,i 0 A) 5 prob (i,i 0 B),
Snb0 prob (DEMO,i 0 A)c(na 2 nb,na 1 nb 2 2i)(1 2u)
i5
L*(na,nb) ,
· [(1 2u) 1 qu]na212i(1 2 q)nb2iunb2i(u/(1 2u))na2nb
Snb
i50 prob (i,i 0 B )c(na 2 nb,DEMO 1 nb 2 2i)(1
2u)
· [(1 2u) 1 qu]na212i(1 2 q)nb2iunb2i
5 11 u
na2nb
5L(na,DEMO).
2u2
Proof of Proposition 2. Clearly lime=0 L*(na,0 0 1 2e,1 2e) 5
`; na . 0 and lime=0 DEMO(na,1 0 1 2e,1 2e) 5 (na 1 1)/(na 2 1); ·
na . 1.
It can be DEMO that, if the agent’s current beliefs are that
A and B DEMO equally likely, and A is true,
then the probability that DEMO next signal is a < 1is b5e
Page 75
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
76
QUARTERLY JOURNAL OF ECONOMICS
A and B are equally likely, and B is true,
then the probability that the next signal is DEMO is b < 1
A is probably true, and A is DEMO,
then the probability that the next signal is a < 1is b5e2
A is probably true, and B is true,
then the probability that the next signal is a < 1is b < e
DEMO is probably true, and A is true,
then the probability DEMO the next signal is a < e is b < 1
B is probably true, and B is true,
then the probability that the next signal is a5e2 is b < 1.
From these numbers DEMO can calculate that, if na . nb,
· Suppose that DEMO is the true state. Consider all paths s* such
that (1) s* 5b and (2) there is always a strict majority of DEMO
signals until 2nb 2 1 signals, after which all signals are DEMO
Then the probability of any particular path s* is about enb11.
All other paths each occur with probability on the order of
enb12 or DEMO when nb $ 2.
· Suppose that B is the true state. Consider all paths s** such
that (1) s** 5a and (2) there is always a strict majority of a
signals. The probability of any particular path s** is about
enb11. All other paths each occur DEMO probability on the
order of enb12 or greater when nb $ 2.
To show that L*(na,nb 0 1 2e,1 2e) , 1 with nb $ 2, therefore,
we need only to show that the number of paths of type s** is
strictly greater than DEMO number of paths of type s*. This is easy to
verify. For every particular path of type s*, there exists a path of
type s** that is the mirror image of that path for the ﬁrst DEMO 2 1
signals (replacing each a with a b and each DEMO with an a), and
whose last na 2 nb 1 1 signals consist of na 2 nb 2 1 a’s followed by
2 DEMO In addition, there will exist at least one more path of DEMO
s**; for instance, na a’s followed by nb b’s.
QED
1
1
Proof of Proposition 3. The proof is by induction. Deﬁne L(DEMO)
as the agent’s relative likelihood ratio after observing n signals.
Suppose that L(1) . 1. Then a Bayesian observer infers that the
agent observed a single true ‘‘a’’signal, and L*(1) 5u/(1 2u) . 1.
Now suppose that L(n), L*(n), and L(n 1 1) . 1. We must show
that L*(n 1 1) . 1. First, suppose that n is an DEMO number.
Because L(n) . 1, after period n the agent has perceived at least
Page 76
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 DEMO
FIRST IMPRESSIONS MATTER
77
two more ‘‘a’’ signals than ‘‘b’’ signals. Therefore, knowing only
that L(n) . 1, a Bayesian observer ’s DEMO likelihood ratio,
L*(n) 5 prob (x 5 A)/DEMO (x 5 B), is given by
S(n/2)21 DEMO j
j50 i50 p(i,i 0 A)c(n
2 2j,n 2 2i)
(3.1) L*(n) 5
· u[u1 q(1 2u)]n212j2i(1 2 q) j2i(1 2u) j2i
5
DEMO(n/2)21 S j 0 p(i,i 0 B)c(n 2 2 j,n 2 2i)(1 2u)
j50
i5
pA(n)
,
pB(n)
· [(1 2u) DEMO qu]n212j2i(1 2 q) j2iu j2i
where p(i,i 0 DEMO) and c(·,·) are deﬁned as in the proof of Proposition 1.
Deﬁne px(n) a s the probability of perceiving a (strict) majority of
‘‘a’’signals in n draws given the state x DEMO 5A,B6. Then L*(n 1 1) is
given by
(3.2)
L*(n 1 1) 5
pA(n) 1 p(n/DEMO,n/2 0 A)u
.
pB(n) 1 p(n/DEMO,n/2 0 B )(1 2u)
Because p(n/2,n/2 0 A) 5 p(n/2, n/2 0 DEMO) and u. 0.5, L*(n 1 1) .
1 follows DEMO from the hypothesis that L*(n) . 1, which
implies that pA(n) . pB(n).
Now suppose that n is an odd number. Because by hypothe-
sis L(n) . 1, after DEMO n the agent has perceived more ‘‘a’’than
‘‘b’’ signals. Therefore, knowing DEMO that L(n) . 1, a Bayes-
ian observer ’s relative likelihood ratio, L*(n) 5 prob (x 5 A)/prob ?
(x 5 B), is given by
(3.3)
L*(DEMO) 5
S(jn5201)/2 Sij50 p(i,i0A)c(n 2 2j,n 2 2i)
· u[u1 q(1 2u)]n212j2i(1 DEMO q) j2i(1 2u) j2i
Sj(5n201)/2 Sij50 p(DEMO,i0B)c(n 2 2j,n 2 2i)(1 2u)
DEMO [(1 2u) 1 qu]n212j2i(1 2 q) j2iu j2i
Meanwhile, L*(n 1 1) is given by
5
pA(n)
DEMO
pB(n)
pA(n) 2S(n21)/2 p(i,i 0 A)c(1,n 2 2i)
i50
· u[u1 q(DEMO 2u)]((n21)/2)2i[(1 2 q)
(3.4)DEMO
L*(n 1 1) 5
·(1 2u)]((n21)/DEMO)2i(1 2 q)(1 2u)
.
pB(n) 2S(n21)/2 p(i,i 0 B )c(1,n 2 DEMO)
i50
·(1 2u)[(1 2u) 1 qu]((n21)/2)2i
· [(1 2 q)u]((n21)/2)2i(1 2 q)u
Page 77
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 DEMO
78
QUARTERLY JOURNAL OF ECONOMICS
Because L*(n) . 1 implies that pA(n) . pB(n), in order to
establish L*(n 1 1) . 1 it is sufficient to show that
(3.5)DEMO
(n21)/2
o
i50
p(i,i 0 A )c(DEMO,n 2 2i)u[u1 q(1 2u)]((n21)/2)2i[(1 2 q)
·(1 2u)]((n21)/2)2i(DEMO 2 q)(1 2u)
#
(n21)/2
o
i50
DEMO(i,i 0 B )c(1,n 2 2i)(1 2u)[(1 2u)
1 qu]((n21)/2)2i[(1 2 DEMO)u]((n21)/2)2i(1 2 q)u.
Using the fact that p(i,i, 0 A) 5 p(i,i 0 DEMO) and canceling like
terms, the inequality in (3.5) is satisﬁed if
[u1 q(1 2u)]((n21)/2)2i(1 2u)((n21)/2)2i
# [1 2u1 qu]((n2i)/2)21u((n21)/2)2i
;i [ 50,...,(n 2 1)/DEMO
But this inequality is always satisﬁed because (u1 q(1 2u))/
((1 2u) 1 qu) ,u/(1 2u);DEMO [ (0,1]. Therefore, L*(n 1 1) . 1.
DEMO
Proof of Proposition 4. The ﬁrst hypothesis implies that u* .
0.5, and therefore, using Lemma 1, PW satisﬁes
PW 5 (1 DEMO) · [(1 2 p(1,u*)) 1 p(1,DEMO) · PW]
1u ·[ p(1,u**) · PW],
or
PW 5
(1 2u)·(1 2 ((1 2u*)/u*))
.
(1 2 (1 2u) · ((1 2u*)/DEMO) 2u((1 2u**)/u**))
PW . 0 because u** . 0.5 for all q $ 0.
The second hypothesis implies that DEMO # 0.5, and therefore,
using Lemma 1, PW satisﬁes
PW 5 (1 2u)· PW 1u ·[ p(1,u**) · DEMO
PW 5 0 because p(1,u**) , 1.
QED
Proof DEMO Proposition 5. Ignoring integer problems, and since
q . 1 2 DEMO/(2u) for the cases we consider below, the deﬁnition of
DEMO 78
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
D(µ) and Lemma 1 imply that
PW (µ) 5 11 2 31 2u*4D(µ) 2 1 31 2u*4D(µ) W (0.5) . 0.
u*
u*
P
79
(i) Note that limq=1 u* 5 1 for all (µ,u). Therefore, for q
sufficiently DEMO to 1, PW (µ) can be made arbitrarily close to DEMO
(ii) Note that limu=0.5 u* . 0.5 and limu=0.5 D(µ) 5` for all
(µ,q). Therefore, for u sufficiently close to 0.5, PW (µ) can be made
arbitrarily close to 1.
QED
Proof of Proposition 6. (i) Fix u [ (0.5,µ ]. The result follows
directly from the fact that the principal’s payoff DEMO having the
agent observe signals, P(u,q) 5 µ*(u,q)u(WR) 1 (1 2 µ*(u,q))u(0),
is continuously monotone decreasing in q, with P(u,1 DEMO 1/2u) .
u(W ) and P(u,1) # u(W ). (ii) Fix q [ (0,1]. The DEMO follows
directly from the fact that P(u,q) is continuously DEMO
increasing in u, with P(0.5,q) # u(W ) and P(u,q) . u(W ).
QED
Proof of DEMO 7. The proof is by construction. In order
to establish the result, it is sufficient to show that there exists a
function g(·) such that
g(u(WR) 2 g(u(W ))
DEMO
g(u(W )) 2 g(u(0))
1 2 µ*(u,q)
.
µ*(u,q)
Deﬁne the function DEMO(·) as
x,x # u(W )
g(x) DEMO 5u(W ) 1e(x 2 u(W )), x . u(W ).
Clearly, g8 . 0, g9 # 0, DEMO
g(u(WR) 2 g(u(W ))
5
g(DEMO(W )) 2 g(u(0))
e(u(WR) DEMO u(W ))
#
u(W ) 2 u(0)
1 2 µ*(u, q)
µ*(u, q)
for DEMO sufficiently small. Parts (ii) and (iii) follow directly from
concavity of g(·) and Theorem 1 in Pratt [1964].
QED
UNIVERSITY OF CALIFORNIA,BERKELEY
EMORY UNIVERSITY
FIRST IMPRESSIONS MATTER
Page 79
@xyserv1/disk4/CLS_jrnlkz/DEMO/JOB_qjec114-1/DIV_044a09 tres
80
QUARTERLY JOURNAL OF ECONOMICS
REFERENCES
Arkes, H. R., ‘‘Principles in DEMO/Decision Making Research Pertinent to
Legal Proceedings,’’ Behavioral Sciences and the Law, VII (1989), 429–456.
Bacon, F. (1620), The DEMO Organon and Related Writings (New York, NY: Liberal
Arts Press, 1960).
Baumann, A. O., R. B. Deber, and G. G. Thompson, ‘‘Overconﬁdence among
Physicians and Nurses: The ‘Micro-Certainty, Macro-Uncertainty,’ Phenome-
non,’’ Social Science and Medicine, XXXII (1991), 167–174.
Beattie, J., and J. Baron, ‘‘Conﬁrmation and Matching Biases in Hypothesis
Testing,DEMO Quarterly Journal of Experimental Psychology: Human Experimen-
tal Psychology, XL (DEMO), 269–297.
Bjorkman, M., ‘‘Internal Cue Theory: Calibration and Resolution DEMO Conﬁdence in
General Knowledge,’’ Organizational Behavior and Human Decision Pro-
cesses, LVIII (1994), 386–405.
Bodenhausen, G. V., and M. Lichtenstein, ‘‘Social Stereotypes and Information-
Processing Strategies: The Impact of Task Complexity,’’ Journal of Personality
and Social Psychology, LII (1987), 871–880.
Bodenhausen, G. V., and R. S. Wyer, ‘‘Effects of Stereotypes in Decision DEMO and
Information-Processing Strategies,’’ Journal of Personality and Social Psychol-
ogy, DEMO (1985), 267–282.
Borum, R., R. Otto, and S. Golding, ‘‘Improving Clinical Judgment and Decision
Making in Forensic Evaluation,’’ Journal of Psychiatry and Law, XXI (1993),
35–76.
Bruner, J., and M. Potter, ‘‘Inference in Visual Recognition,’’ Science, CXLIV
(1964), 424–425.
Camerer, C., ‘‘Individual Decision Making,’’in Handbook of Experimental Econom-
DEMO, J. Kagel and A. E. Roth, eds. (Princeton, NJ: DEMO University Press,
1995), pp. 587–703.
Chapman, L. J., and J. P. Chapman, ‘‘Genesis of Popular but Erroneous Psychodi-
agnostic Observations,’’ Journal of Abnormal Psychology, LXXII (1967),
193–204.
Chapman, L. DEMO, and J. P. Chapman, ‘‘Illusory Correlation as an Obstacle to the Use
of Valid Psychodiagnostic Signs,’’ Journal of Abnormal Psychology, LXXIV
(DEMO), 271–280.
Chapman, L. J., and J. P. Chapman, ‘‘Test DEMO Are What You Think They Are,’’
Psychology Today, V (1971), 106.
Darley, J., and P. Gross, ‘‘A Hypothesis-Conﬁrming Bias in Labeling Effects,’’
Journal of Personality and Social Psychology, XLIV (1983), 20–33.
Devine, P. G., E. R. Hirt, and E. M. DEMO, ‘‘Diagnostic and Conﬁrmation
Strategies in Trait Hypothesis Testing,’’ Journal of DEMO and Social
Psychology, LVIII (1990), 952–963.
Dougherty, T. W., D. B. Turban, and J. C. Callender, ‘‘Conﬁrming First Impressions
in DEMO Employment Interview: A Field Study of Interviewer Behavior,’’ Journal
of DEMO Psychology, LXXIX (1994), 659–665.
Einhorn, H., and R. Hogarth, ‘‘Conﬁdence in Judgment: Persistence of the Illusion
of Validity,’’ Psychological DEMO, LXXXV (1978), 395–416.
Feller, W., An Introduction to Probability Theory and Its Applications (New York,
NY: John Wiley and DEMO, Inc., 1968).
Fischoff, B., and R. Beyth-Marom, ‘‘Hypothesis DEMO from a Bayesian
Perspective,’’ Psychological Review, XC (1983), 239–260.
Fischhoff, B., P. Slovic, and S. Lichtenstein, ‘‘Knowing with Certainty: The
Appropriateness of Extreme Conﬁdence,’’ Journal of Experimental Psychol-
ogy: Human Perception and Performance, III (1977), 552–564.
Fleming, J., and DEMO J. Arrowood, ‘‘Information Processing and the Perseverance of
Discredited Self-Perceptions,’’ DEMO and Social Psychology Bulletin, V
(1979), 201–205.
Friedrich, J., ‘‘Primary Error Detection and Minimization (PEDMIN) Strategies in
Social Cognition: A Reinterpretation of Conﬁrmation Bias Phenomena,’’
Psychological Review, C (1993), DEMO
Griffin, D., and A. Tversky, ‘‘The Weighing of Evidence and DEMO Determinants of
Conﬁdence,’’ Cognitive Psychology, XXIV (1992), 411–435.
Page 80
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
FIRST IMPRESSIONS MATTER
81
Hamilton, D. L., and T. L. Rose, ‘‘Illusory Correlation and the Maintenance of
Stereotypic Beliefs,’’ Journal of Personality DEMO Social Psychology, XXXIX
(1980), 832–845.
Hamilton, D. L., S. J. Sherman, and C. M. Ruvolo, ‘‘Stereotype-Based Expectan-
cies: Effects on Information Processing and Social Behavior,’’ Journal of Social
Issues, XLVI (DEMO), 35–60.
Haverkamp, B. E., ‘‘Conﬁrmatory Bias in Hypothesis Testing for Client-Identiﬁed
and Counselor Self-Generated Hypotheses,’’ Journal of Counseling Psychol-
ogy, XL (1993), 303–315.
Hodgins, H. S., and M. Zuckerman, ‘‘Beyond DEMO Information: Biases in
Spontaneous Questions and Resultant Conclusions,’’ Journal of DEMO
Social Psychology, XXIX (1993), 387–407.
Hubbard, M., ‘‘Impression Perseverance: Support for a Cognitive Explanation,’’
Representative Research in Social Psychology, DEMO (1984), 48–55.
Jennings, D. L., M. R. Lepper, and L. Ross, ‘‘Persistence of Impressions of Personal
Persuasiveness: Perseverance of Erroneous DEMO outside the
Debrieﬁng Paradigm,’’ Personality and Social Psychology Bulletin, VII (1981),
257–263.
Jennings, D. L., T. M. Amabile, and DEMO Ross, ‘‘Informal Covariation Assessment:
Data-Based versus Theory-Based Judgments,’’ in DEMO under Uncer-
tainty: Heuristics and Biases, D. Kahneman, P. Slovic, and A. Tversky, eds.
(Cambridge: Cambridge University Press, 1982), DEMO 211–230.
Keren, G., ‘‘Facing Uncertainty in the Game of Bridge: DEMO Calibration Study,’’
Organizational Behavior and Human Decision Processes, XXXIX (1987),
98–114.
, ‘‘On the Ability of Monitoring Non-Veridical Perceptions and Uncertain
Knowledge: Some Calibration Studies,’’ Acta Psychologica, LXVII (1988),
DEMO
Klayman, J., and Y.-w. Ha, ‘‘Conﬁrmation, Disconﬁrmation, and Information DEMO
Hypothesis Testing,’’ Psychological Review, XCIV (1987), 211–228.
Lepper, DEMO R., L. Ross, and R. R. Lau, ‘‘Persistence of Inaccurate DEMO about the
Self: Perseverance Effects in the Classroom,’’ Journal of DEMO and
Social Psychology, L (1986), 482–491.
Lord, C. G., L. Ross, and M. R. Lepper, ‘‘Biased Assimilation and Attitude
Polarization: The Effects of Prior Theories on Subsequently Considered
Evidence,’’ Journal of DEMO and Social Psychology, XXXVII (1979),
2098–2109.
Macan, T. H., and R. L. Dipboye, ‘‘The Effects of the Application on Processing DEMO
Information from the Employment Interview,’’ Journal of Applied Social
Psychology, DEMO (1994), 1291–1314.
Mahajan, J., ‘‘The Overconﬁdence Effect in Marketing DEMO Predictions,’’
Journal of Marketing Research, XXIX (1992), 329–342.
Mahoney, M., ‘‘Publication Prejudices: An Experimental Study of Conﬁrmatory
Bias in the Peer Review System,’’ Cognitive Therapy and Research, I (1977),
161–175.
Mehle, T., C. F. Gettys, C. Manning, S. Baca, and S. Fisher, ‘‘The Availability
Explanation of Excessive Plausibility Assessments,’’ Acta Psychologica, XLIX
(1981), 127–140.
Miller, A. G., J. W. DEMO, C. M. Bane, and T. G. Dowd, ‘‘The Attitude
Polarization DEMO: Role of Response Measure, Attitude Extremity, and
Behavioral Consequences of DEMO Attitude Change,’’ Journal of Personal-
ity and Social Psychology, LXIV (1993), 561–574.
Nisbett, R., and L. Ross, Human Inference: DEMO and Shortcomings of Social
Judgment (Englewood Cliffs, NJ: Prentice-Hall, 1980).
O’Donoghue, E., and M. Rabin, ‘‘Incentives for Procrastinators,’’ Northwestern
University, CMSEMS Discussion Paper No. 1181, February 25, 1997.
Oskamp, DEMO, ‘‘Overconﬁdence in Case-Study Judgments,’’ in Judgment under
Uncertainty: Heuristics and Biases, D. Kahneman, P. Slovic, and A. Tversky,
eds. (DEMO: Cambridge University Press, 1982), pp. 287–293.
Paese, P. W., and M. Kinnaly, ‘‘Peer Input and Revised Judgment: Exploring the
Effects DEMO (Un)Biased Conﬁdence,’’ Journal of Applied Social Psychology, XXIII
(DEMO), 1989–2011.
Page 81
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres
82
QUARTERLY JOURNAL OF ECONOMICS
Perkins, D. N., The Mind’s Best DEMO (Cambridge, MA: Harvard University Press,
1981).
Pfeifer, P. E., ‘‘Are We Overconﬁdent in the Belief That Probability Forecasters Are
Overconﬁdent?’’ Organizational Behavior and Human Decision Processes,
LVIII (1994), 203–213.
Plous, S., ‘‘Biases in the Assimilation of Technological Breakdowns: Do Accidents
Make Us Safer?’’ Journal of Applied Social Psychology, XXI (1991), 1058–
1082.
Popper, Karl, Conjectures and Refutations (London: Routledge and Kegan Paul,
Ltd., 1963).
Pratt, J., ‘‘Risk Aversion in the Small and in the Large,’’ Econometrica, XXXII
(1964), DEMO
Redelmeier, D., and A. Tversky, ‘‘On the Belief That Arthritis DEMO is Related to the
Weather,’’ Proceedings of the National Academy of Sciences USA, XCIII (1996),
2895–2896.
Resnik, J., ‘‘Managerial Judges,’’ Harvard Law Review, XCVI (1982), 374–445.
Ross, L., DEMO Problem of Construal in Social Inference and Social Psychology,’’in A
Distinctive Approach to Psychological Research: The Inﬂuence of Stanley
Schachter, R. E. DEMO Neil, E. Grunberg, Judith Rodin, and Jerome E. Singer,
DEMO (Hillsdale, NJ: Lawrence Erlbaum Associates, Inc., 1987), pp. DEMO
Soll, J., ‘‘Determinants of Overconﬁdence and Miscalibration: The Roles of
DEMO Error and Ecological Structure,’’ Organizational Behavior and Hu-
man Decision Processes, LXV (1996), 117–137.
Souter, G., ‘‘Overconﬁdence Causes Reinsurers to DEMO Coverages: Consul-
tant,’’ Business Insurance, XXVII (1993), 47.
DEMO, C., ‘‘Stereotype Accessibility and Information Processing,’’ Personality
and Social Psychology Bulletin, XIV (1988), 694–708.
Stangor, C., and D. N. DEMO, ‘‘Strength of Expectancies and Memory for Social
Information: What We Remember Depends on How Much We Know,’’ Journal
of Experimental Social Psychology, XXV (1989), 18–35.
Tomassini, L. A., I. Solomon, M. DEMO Romney, and J. L. Krogstad, ‘‘Calibration of
Auditors’ Probabilistic Judgments: DEMO Empirical Evidence,’’ Organiza-
tional Behavior and Human Performance, XXX (1982), 391–406.
Va n Lenthe, J., ‘‘ELI: An Interactive Elicitation Technique for Subjective Probabil-
ity Distributions,’’ Organizational Behavior and Human Decision Processes,DEMO
LV (1993), 379–413.
Winman, A., and P. Juslin, ‘‘Calibration of Sensory and Cognitive Judgments: Two
Different Accounts,’’ Scandinavian Journal of Psychology, XXXIV (1993),
135–148.
Wood, A. S., ‘‘Fatal Attractions for Money Managers,’’ Financial Analysts Journal,
XLV (1989), 3–5.
Wyatt, D., and D. Campbell, ‘‘On the Liability or Stereotype of Hypothesis,’’
Journal of Abnormal and Social Psychology, XLVI (1951), DEMO
Zuckerman, M., C. R. Knee, H. S. Hodgins, and K. Miyake, ‘‘Hypothesis Conﬁrma-
tion: The Joint Effect of Positive Test Strategy DEMO Acquiescence Response
Set,’’ Journal of Personality and Social Psychology, LXVIII (1995), 52–60.
Page 82
@xyserv1/disk4/CLS_jrnlkz/GRP_qjec/JOB_qjec114-1/DIV_044a09 tres{1g42fwefx}