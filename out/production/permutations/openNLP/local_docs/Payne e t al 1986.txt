AD-A178 858
UNCLASSIFIED
ADAPTIVE UNIV DURHAM STRATEGY NC J SELECTION Id PAYNE
DEMO
IN AL DECISION 31 JUL 86 AKING(U) 86-1
DUKE
F/DEMO 5/10
1/1
ML
mhhmhEohEEEohE
EhhhEEEEmhhhhE
I......
JI~fL L
im'~
11125
1.1 L"L
11111L2
MICROCOPY
NATIONAL
RESOW~TION
DEMO
TEST
OF STANDARDS-
CHART
1963-A
ONR CONTRACT NUMBER: N00014-80-C-0114
WORK UNIT NUMBER: R & T 4425063
DEMO
LJ
0DISTRIBUTION
0
I
ADAPTIVE STRATEGY SELECTION IN
APPROVED FOR PUBLIC RELEASE,
UNLIMITED.
DECISION MAKING
JOHN W. PAYNE
DUKE UNIVERSITY
JAMES R. BETTMAN
DEMO UNIVERSITY
ERIC J. JOHNSON
CARNEGIE-MELLON UNIVERSITY
DTIC
L.CT E
AUG
13
THIS WORK WAS SUPPORTED BY THE ENGINEERING PSYCHOLOGY
PROGRAMS FROM THE OFFICE OF DEMO RESEARCH. REPRODUCTION IN
WHOLE OR IN PART IS PERMITTED FOR ANY PURPOSE OF THE UNITED
STATES GOVERNMENT.
8 6
8
13
096
!,.
.4-.
S. .:
* -F..
-
.J2.
-'4
SECURITY CLASSIFICATION DEMO THIS PAGE (Whion Des EnIer_
.
REPORT
86-1
2.
REPORT DOCUMENTATION DEMO
NUMBER
'
V4L_
GOVT ACCESSION NO.
I
'4
6
4.
TITLE (and Subltl)e.
ADAPTIVE STRATEGY SELECTION IN DECISION MAKING
_
S.
_
__)
___
_s__uc
SEFORE COMLZTM[G FORM
RECIP ENT*S CATALOG NUMUER
_N__S
DEMO OF REPORT & PERIOD COVERED
Research
6. PERFORMING ORO. REPORT NUMSER
7. AUTNORfe)
John W. Payne, Duke University
James R. Bettman, Duke DEMO
Eric J. Johnson, Carnegie-Mellon University
9. PERFORMING ORGANIZATION NAME AND ADDRESS
DEMO University
It.
CONTROLLING OFFICE NAME AND ADDRESS
ONR, Arlington, VA 22217-5000
_64
14. MONITORING AGENCY NAME & AOORESS(If different Ina Controlling Office)DEMO
e.
CONTRACT ON
GRANT NUMSER1()
N00014-80-C-0114
10.
PROGRAM ELEMENT PROJECT. DEMO
AREA I WORK UNIT NUMBERS
RT 4425063
12.
REPORT DATE
July 31, 1986
13. NUMBER
OF PAGES
IS. SECURITY CLASS. (of thle eporl)DEMO
Unclassified
I.
DISTRIBUTION STATEMENT (ofhis
RepPrt)
Approved for public release; distribution unlimited.
Ia.
DECLASSIFICATION/DOWNGRADING
SCHEDULE
17.
DISTRIBUTION STATEMENT (of the ebelrcac
entered In
Steoc
k".
If difforent hem RAped)
S1. SUPPLEMENTARY
DEMO
19.
KEY WORDS (Continue on .evere . "ifnece.ery a identity by block nubo,)
Decision Making, Strategies Adaptive, Cognitive Effort
Time Pressure, Process Tracing
AST ACT (Continueaon revere side
examine the role
n DEMO iddentify by block nunber)
effort and accuracy in the adaptive use of decision
If necessay
of
processes. A computer simulation study that used DEMO concept of elementary
information processes identified heuristic choice strategies which approximate
the accuracy of normative procedures while requiring substantially less effort.
However, no single heuristic did well across all task and context conditions.
Of particular interest DEMO the finding that under time constraints, several
heuristics were clearly more DEMO than a normative procedure. Two process
tracing studies showed a significant degree of correspondence between the ..
IAN 7.
1473
EDITION OF i NOV DEMO IS OBSOLETE
S/N 0102- LF- 014. 6601
SECURITY CLASSIFICATION OF THIS PAGE (Mhen bets fntard)
efficient strategies for a given decision problem identified by the simulation
and DEMO decision behavior. People vere highly adaptive to changes in the
nature of the alternatives available to them and to the presence of time
pressure.
DEMO
-, -
Ja
,
Adaptive Decisions
*Examples
*failed
of all relevant information about the alternatives and DEMO also allowed the
good and bad aspects of each alternative to compensate for one another.
of such decision rules are the various expectation models DEMO risky
choice and the additive utility model of multiattribute choice. Simon (DEMO),
however, suggested that decision strategies like additive utility were
incompatible with our knowledge of human cognition. Furthermore, such models
to account for important empirical findings, such as intransitivity in
preferences (Tversky, 1969). Consequently, a number of simplified decision
rules, or choice heuristics, have been proposed. Such heuristics reduce
information processing demands by ignoring some potentially DEMO problem
information and by avoiding tradeoffs among values. For example, the
DEMO heuristic (Tversky, 1969) chooses the alternative which is best
on DEMO most important attribute, ignoring all other information. While
heuristics can reduce DEMO processing demands, they can also lead to
decision errors such as DEMO
One of the major empirical findings of recent decision research is that
an individual will use a variety of strategies for making a choice. DEMO
3
\S
a person will use a compensatory type of strategy. At other times, the same
person will use a noncompensatory decision strategy. The use of a particular
strategy appears to be contingent on a number DEMO task and context variables
(Payne, 1982). Task variables are general characteristics of the decision
problem, such as number of alternatives and time pressure, which are not
dependent on the particular values of the alternatives in the decision set.
,
Context variables, in contrast, are associated with the particular values of
-"
[]
El
Codes
- 1IJ1
DEMO'5~
d.
W-
-r
4.
e
.
%1
...
~. *~
*.
'.** W
5-
Much research has been devoted to describing the information processing
strategies people use for making choices (Bettman, 1979; Svenson, DEMO).
Initially, this research focused on strategies that implied a complete DEMO
Adaptive Decisions
4
the choice objects, such as the correlation between attributes. One example
of a contingency effect is the increase in the use DEMO simplifying heuristics
as the number of alternatives increases (Payne, 1976).
Evidence of contingent information processing in decisions'has raised
the question of DEMO certain decision strategies are applied to solve certain
decision problems. In other words, what determines the decision on how to
choose? One general DEMO in trying to answer that question looks at
strategy selection as a function of both its costs, primarily the effort
required to use a rule, and its benefits, primarily the ability of a strategy
to DEMO the best alternative (Beach & Mitchell, 1978; Russo & Dosher, 1983).
The advantage of a cost-benefit approach to strategy selection is DEMO ability
to maintain the concept of calculated rationality (March, 1978), once the
costs of executing the decision process are included in the DEMO of
rationality. Furthermore, because the costs and benefits of various decision
DEMO will vary across different problems, the cost-benefit perspective
provides the potential DEMO explaining a variety of empirical results
concerning situation specific decision behavior.
The goal of this paper is
to examine the role of effort and DEMO
considerations in the adaptive use of different information processing
V
./
strategies for making a choice. First, an approach to understanding
contingent decision behavior using the concept of elementary information
processes and the method of DEMO simulation is introduced, and some prior
work by Johnson and Payne (1985) using that approach is
briefly discussed.
Next, a Monte-Carlo simulation DEMO of the effort and accuracy of choice
heuristics in
a variety of choice environments which extends the prior work by
Johnson and Payne (1985) in several directions is reported. Of particular
interest is
the impact of time constraints on the relative accuracy of
-_ PI
P
- -
Adaptive Decisions
5
decision strategies. Finally, two experimental studies of task and context
effects on decision behavior are reported. DEMO in
the simulation, the task
variable of interest is the degree DEMO time pressure confronting the decision
maker. These studies utilize a new computer-based process-tracing technique
to examine the adaptiveness of human choice processes. The degree DEMO
correspondence between the efficient strategies-identified by the computer
-:
simulation for a given type of decision problem and the actual information
processing strategies DEMO use is then addressed.
Hence, the major purposes of the paper DEMO threefold: 1)
To provide a
conceptual approach for modeling effort DEMO accuracy tradeoffs in choice; 2)
To report both simulation-based and DEMO evidence regarding-
patterns of
adaptivity in strategy selection in different choice environments; and 3) To
examine the extent to which the, empirical evidence on adaptivity validates the
conceptual approach used. As a secondary purpose, the empirical work provides
some of the most detailed process-tracing evidence to date DEMO responses
to time pressure in decision making.
Effort and Accuracy in Choice
One major difficulty in examining strategy selection from a cost-benefit
perspective has DEMO the lack of a conceptually appropriate measure of effort
that is easy to calculate. A closely related problem is
the lack of a common
DEMO which could be used to describe the process level similarities and
differences among the various choice models that have been proposed. This is
important DEMO strategy selection is
to be investigated at an information
processing level rather than at a more general level of analysis, such as
analytic vs. nonanalytic (Beach and Mitchell, 1978) or analytic vs. intuitive
(Hammond, 1986). A second area of concern with the cost-benefit approach has
Adaptive Decisions
6
been the lack of agreement on how to measure DEMO of choice. Johnson and
Payne (1985) have proposed solutions to these problems.
Measuring Strategy Effort. Building on earlier work by 0. Huber (1980),
Johnson (1979), and the ideas of Newell and Simon (1972), Johnson and Payne
(1985) suggest that decision strategies can DEMO decomposed into elementary
information processes (EIP's). A decision strategy DEMO rule could then be
thought of as a sequence of events, DEMO as reading the values of two
alternatives on an attribute, comparing DEMO, and so forth. A possible set of
EIP's for decision DEMO, similar to those suggested by Huber (1980) and
Johnson (1979), is listed in Table 1. One advantage of this approach is
DEMO
the EIP's provide a common language for describing seemingly diverse decision
strategies in terms of their underlying components.
Insert Table 1 about here
DEMO second advantage of this approach is
that a count of the total number
of elementary information processes required by a given strategy to reach DEMO
decision in a particular choice task environment can be used as a measure of
th effort associated with the use of that decision strategy DEMO
that task
environment (Johnson and Payne, 1985). Examples of the use of EIP counts to
measure processing load can be found in DEMO number of studies of cognition
(e.g., Card, Moran, & Newell, 1983; Carpenter & Just, 19750.
Measuring Accuracy. Accuracy of choice can be defined in
many ways. At
a very general level, quality of choice can be defined by basic principles
such as consistency in
preference. DEMO example, maintaining transitivity, or
the avoidance of errors such as selecting a dominated alternative, are often
suggested as normative decision principles. However, DEMO specific criteria
for decision quality can be developed in certain choice environments. In
the
Adaptive Decisions
N
* -in
area of risky choice, for instance, DEMO expected utility model, which can be
derived from certain principles of DEMO, is often suggested as a
normative decision procedure. A special case DEMO the EU model, the
maximization of expected value, has been used as a criterion to investigate
the accuracy of decision heuristics through computer DEMO (Thorngate,
1980). In the domain of nonrisky choice, the compensatory multi-attribute
utility (MAU) rule is often used as a criterion DEMO decision effectiveness
(e.g., Zakay & Wooler, 1984).
Examining Accuracy DEMO Effort in Choice. Johnson and Payne (1985)
examined both the DEMO and the accuracy of six decision rules for risky
choice. Effort was measured in terms of EIP's, and accuracy was measured both
terms of consistency in choice and EV maximization. The six decision rules
examined DEMO Johnson and Payne differed markedly in the amount of the available
information they considered. A priori, this was expected to be an important
determinant of both the accuracy and the effort resulting from their use. The
DEMO value (EV) rule, which is based on complete search of DEMO available
information, was at one extreme. The equiprobable heuristic is similar DEMO the
EV rule in that it examines all the alternatives and all outcomes. However,
it ignores one of the two attributes of a DEMO's outcomes, probability,
explicitly treating all events as equally likely. DEMO most-likely heuristic,
in contrast, examines only one outcome for each DEMO, the outcome with
the highest probability of occurrence, and selects the alternative with the
largest payoff for this outcome. The maximin heuristic ignores DEMO
entirely and selects the alternative with the largest minimum payoff.
Elimination by aspects (EBA) is a choice rule proposed by Tversky (1972). A
special version of EBA investigated by Thorngate (1980) that attends DEMO to
payoff information was also examined by Johnson and Payne. Each payoff of a
7
.
~4
"LS
V,
.~
Adaptive Decisions
8
gamble is compared to a cutoff equal to the DEMO payoff. If a payoff is less
than the cutoff, the gamble DEMO eliminated from further consideration. The
i~.
rule terminates when either (a) one alternative remains, or (b) all attributes
have been considered, DEMO one must choose randomly from the remaining
alternatives. Finally, the random DEMO rule served as a baseline, simply
choosing an alternative at random DEMO no search.
Johnson and Payne conducted a series of Monte Carlo studies that varied
several aspects of the choice environment. The task variables - DEMO of
risky alternatives and number of outcomes- were varied at levels of 2, 4, and
8. Another aspect of the choice environment varied DEMO a context variable,
the amount of variance in probabilities within each gamble. This variable was
chosen because Thorngate (1980), using a simulation approach, had suggested
siT..that probability information may be relatively unimportant in making accurate
risky choices. However, Thorngate's method for constructing gambles ensured
C'..'that the variance in the probability distribution would be small relative DEMO
a
the variance in payoffs. Hence, Johnson and Payne implemented an DEMO
method of probability generation that produced larger variances in the
probability distributions. Finally, the presence or absence of dominated
V.
*
alternatives in a choice set was the second context variable examined.
The Johnson and Payne DEMO identified choice rules that appeared
to provide approximately the accuracy of normative procedures while requiring
substantially less effort. The results, however, were highly DEMO upon
characteristics of the choice environments. In the environment that closely
resembled Thorngate's, for example, the equiprobable rule appeared quite
accurate. It DEMO also a rule that maintained roughly the same accuracy as the
number of outcomes was increased. In contrast, when the variance of the
probabilities was increased, the most-likely heuristic became the most
a.V
Adaptive Decisions
*
*
%
*
accurate, whereas the equiprobable heuristic displayed a marked decrease in
accuracy. Furthermore, the most-likely rule was the only one to maintain
accuracy as the number of outcomes increased in the DEMO environment.
Thorngate's earlier statement about the importance of probability information,
therefore, was found to be of limited generality.
Another interesting result was the effect of the presence or absence of
dominated alternatives. The removal DEMO dominated alternatives reduced the
accuracy of some heuristics to almost chance levels.. Finally, Johnson and
Payne also found that task effects tended to have a greater influence on the
efotrequired by strategies, while context effects tended to have a greater
influence on accuracy.
Johnson and Payne concluded that DEMO could be highly accurate,
but that no single heuristic would do well across all contexts. Instead, if a
decision maker wanted to maintain a high level of accuracy with a minimum of
effort, he or she would have to choose among a repertoire of strategies,
contingent DEMO situational demands. In other words, a decision maker
striving to minimize DEMO errors and effort would have to be highly adaptive
in the use of decision processes.
Thus, the Johnson and Payne simulations, using EIP'DEMO to measure effort
and various criteria for assessing accuracy, were able DEMO yield interesting
and important conclusions about adaptivity in choice. However, this DEMO also
raised two very important issues. First, the original Johnson and DEMO
(1985) work investigated a few decision rules in one particular type of risky.
decision environment. Hence, one issue is whether these results generalize to
other rules and different types of choice settings. Second, the simulation
work helps to identify adaptive strategies for decision makers, assuming that
they wish to minimize either errors, effort, or some combination of the DEMO
9
Adaptive Decisions
10
A major unanswered empirical question is the degree to DEMO human decision
makers actually display such adaptivity to either errors or effort. The
remaining sections of the paper examine these two issues, utilizing further
computer simulation for the first and two experiments for the second.
Study DEMO: A Monte-Carlo Simulation of Effort
and Accuracy in Choice
The purpose DEMO this study was to investigate the generality of the
Johnson and Payne (1985) simulations by extending both the range of decision
strategies and DEMO environments studied. This study examined a set of ten
decision strategies, DEMO more than investigated by Johnson and Payne (1985).
Forms of DEMO lexicographic and elimination-by-aspects strategies are included
that are more consistent with those originally described by Tversky (1969;
1972). In addition, several DEMO not considered in the earlier
simulation and two strategies are that are combinations of other strategies
(e.g., an EBA rule plus an additive DEMO) are examined. The specific
strategies used are described in more detail DEMO
A second major change involves the decision task. In contrast to the
earlier simulations, the choice alternatives are constructed to have a set of
outcomes which have the same probability for each alternative. In other
words, each of the alternatives may have a different value for each outcome,DEMO
but the probability of receiving each outcome is the same for all the
alternatives. This allows us to also interpret the current decision task DEMO a
riskless choice task, in which the probabilities function as attribute DEMO
that apply across alternatives. Under a riskless interpretation, one can look
DEMO a probability of .25, for example, as the weight given to a particular
attribute across all alternatives. Alternately, under a risky choice
scenario, the .25 is the probability of obtaining that outcome. In previous
-N.6
Adaptive Decisions
simulation work (Thorngate 1980, Johnson and Payne, 1985), the probabilities
varied across alternatives, preventing the extension of the results to
riskless choice. This relationship between risky choice problems and multi-
attribute decision DEMO is discussed more fully in Keeney and Raiffa
(1976).
Finally, in addition to the task and context variables studied in the
earlier DEMO, the present study investigates the impact of time
pressures upon decision DEMO Time pressure is potentially one of the
most significant task variables. Under time constraints, a heuristic like EBA
4
(Tversky, 1972) might DEMO more accurate than a strategy such as maximization of
expected value. The reason is that the rate at which a heuristic's accuracy
degrades DEMO increasing time pressure may be slower than the rate at which a
more comprehensive processing rule, e.g., EV., degrades. One possible reason
for this is that heuristics require fewer operations and will generally be
"further along" when time runs out. Furthermore: time pressure relates to the
DEMO to which people use heuristics because they have no other choice
(DEMO, 1981). A more normative decision strategy like expected utility
maximization DEMO exceed the information processing capabilities of a decision
maker, given any "reasonable" time limit for making the decision. If use of a
more normative rule is effectively impossible, then the task of deciding how
to choose becomes a selection of the "best" among a set of DEMO
heuristics, not a decision on whether to use some heuristic or DEMO more
normative rule.
Decision Strategies
The ten decision strategies were implemented using the EIPs and
production system representation proposed by Johnson and Payne (1985). The
ten decision strategies varied substantially in the amount of the DEMO
4.4t!
A ;
.
Adaptive Decisions
12
information used to make a choice. The most information DEMO was a
version of a Weighted Additive (WADD) compensatory process. This strategy
considers the values of each alternative on all the relevant attributes
(outcomes) and all the relative importances (weights or probabilities) of the
different attributes (outcomes) to the decision maker. The rule develops a
DEMO value for each attribute by multiplying the weight times the value
and sums over all attributes to arrive at an overall evaluation of an
DEMO Then the alternative with the highest evaluation is selected.
Â°,
Thus, the weighted additive rule selects an alternative based on an exhaustive
search of the available information. Such a process is often suggested as a
DEMO procedure for multiattribute choices (Ulvila & Brown, 1982). In
contrast, the Random (RAN) choice rule chooses an alternative at random with
no search of the available information. Hence, the Random rule serves as a
minimum baseline for measuring both accuracy and effort.
In addition to DEMO two baseline rules, six individual heuristics for
multiattribute choice were implemented, along with two combination strategies.
The Equalweight (EQW) rule examines all DEMO and all attribute values
for each alternative. However, the rule ignores DEMO about the
relative importance of each attribute. Instead, the equalweight rule DEMO
by summing the attribute values for each alternative to get an overall value,
and the alternative with the highest total is selected. In DEMO contexts, the
equal weight rule has been advocated as a highly DEMO simplificaton of the
choice process (Dawes, 1979; Einhorn and Hogarth, 1975). The equal weight
rule is identical to the equiprobable rule DEMO risky choice investigated by
Thorngate (1980) and Johnson and Payne (DEMO). The Elimination by Aspects
(EBA) rule (Tversky, 1972) DEMO by determining the most important attribute
(the outcome with the highest DEMO (probability)). Then, the cutoff value
%
%
Adaptive Decisions
13
for that attribute is retrieved, and all alternatives with values for that
attribute below the cutoff are eliminated. This process continues DEMO the
second most important attribute, then the third, and so on, until one
alternative remains. This version of EBA differs from that examined by
Thorngate (1980) and Johnson and Payne (1985). The present version of EBA
does order search by attribute importance, so it more closely resembles the
EBA model originally proposed by Tversky (1972).
The Majority of Confirming Dimensions (MCD) rule has been suggested by
Russo DEMO Dosher (1983). This rule involves processing pairs of alternatives.
The DEMO for each of the two alternatives are compared on each attribute,
and a running score is kept of how many times each alternative DEMO a better
value on an attribute. The alternative with a majority of winning attribute
values is selected. In the case of an equal number DEMO winning values for the
two alternatives, we implemented a version of DEMO rule where the alternative
winning the comparison on the last attribute is retained. The retained
(winning) alternative is then compared to the next DEMO among the set
of alternatives. The process of pairwise comparison repeats until all
alternatives have been evaluated and the final winning alternative identified.
The DEMO (SAT) rule (Simon, 1955) does not necessary examine all DEMO
alternatives in a set. Instead, alternatives are considered one at a DEMO
For each attribute of an alternative, it is determined whether the DEMO
value exceeds a cutoff value. If any attribute value is below the cutoff
value, that alternative is rejected. The first alternative in a set which has
values which pass the cutoffs for all attributes is chosen. DEMO is, a choice
can be made before all alternatives have been DEMO In the case where no
alternative passes all the cutoffs, a DEMO selection is made among the
alternatives.
Adaptive Decisions
14
We also implemented two versions of the lexicographic choice DEMO For
the strict Lexicographic (LEX) rule, the most important attribute DEMO
determined, and the values of all the alternatives on that attribute DEMO then
examined. The alternative with the highest value on that attribute is
selected. If there are ties, the second most important attribute is examined,
and so on until the tie is broken. However, because the attributes in the
simulation are generated as continuous random variates, ties almost never
occur. Thus, this rule is essentially the same as the most likely heuristic
for risky choice investigated in Thorngate (1980) and Johnson DEMO Payne
-S..
(1985). We also examined a Lexicographic Semi-Order (LEXSEMI) rule (Tversky,
1969). This rule is similar to the DEMO lexicographic rule, but introduces
the notion of a just-noticeable difference (JND). If several alternatives are
within a JND difference of the best DEMO on the most important
attribute, they are considered to be tied. DEMO alternatives are compared on
the next most important attribute, and the DEMO continues until one option
*
remains. The potential advantage of the Lexicographic semi-order rule is that
it ensures that an option which is marginally DEMO on the most important
attribute but much worse on other attributes will not necessarily be selected.
Finally, two combined strategies were implemented. The first was an
*Elimination-by-Aspects
plus Weighted Additive (EBA+ADD) rule. This rule used
DEMO EBA process until the number of available alternatives remaining was three
or less, and than used a weighted additive rule to evaluate the remaining
*alternatives
and select the best. The other combined strategy used
-
Elimination-by-Aspects DEMO Majority of Confirming Dimensions (EBA+MCD). This
rule again used an DEMO process to reduce the problem size
to three alternatives or less, DEMO then a majority of confirming dimensions
heuristic is used to select the winning alternative from the reduced set.
A
A-
7 -A
. .
'
:K'
Adaptive Decisions
V"
*major
-
These combinations were used because they DEMO been observed in several
previous choice process studies (e.g., Payne, DEMO; Bettman and Park, 1980).
In addition to the amount of information utilized, these heuristics
differ in how information about the alternatives and attributes of a decision
problem is likely to be processed. Some of DEMO rules imply an alternative-
based form of processing. That is, information DEMO processed regarding the
multiple attribute values of a single alternative before information about a
second alternative is processed. Examples of such rules are the DEMO
additive rule, the equalweight rule, and satisficing. Other decision rules
imply an attribute-based form of processing. That is, information is
processed regarding the values of several alternatives on a single attribute
before information about a DEMO attribute is processed. Examples of
attribute-based processing strategies are the EBA rule and the lexicographic
choice rules. The distinction between alternative-based (also called
"DEMO processing") and attribute-based decision strategies has played a
role in numerous discussions of decision models (e.g., Bettman, 1979;
Goldstein, 1986; Svenson, 1979), and has implications for the robustness of
the various strategies under time constraints. In particular, it can be
argued that under increasingly severe time pressure, it becomes more and more
important to examine all alternatives, even if on a limited set of attributes.
Thus, DEMO strategies may have an advantage (i.e., degrade more
slowly) under DEMO pressure.
Task and Context Variables
For purposes of comparison with Johnson and Payne (1985), we included
essentially the same set of task and context variables. We manipulated task
complexity through variations in the number of DEMO and number of
15
Adaptive Decisions
16
attributes. The numbers of alternatives were 2, 5, DEMO 8; the numbers of
attributes were also 2, 5, and DEMO
One context variable was the presence or absence of dominated
alternatives. Removing dominated alternatives produces efficient or Pareto-
optimal choice sets. The other context DEMO was the variance in the
relative weights assigned to the attributes. As noted earlier, Johnson and
Payne (1985) found that the variance of the probabilities impacted on which
heuristics were most efficient in risky choice. DEMO before, we examined both
low variance and high variance sets of DEMO The generation of the weights
paralleled the two procedures used in Johnson and Payne (1985) for generating
the probabilities of outcomes, with the difference that only one set of
weights were generated for a given DEMO problem.
Time Constraints
One new task variable was added, time pressure. DEMO levels of time
constraint were investigated. One level involved no time pressure. A given
rule could use as many operations as needed. The three DEMO levels of time
constraint were a maximum of (1)
50 DEMO's (severe time pressure), (2)
100
EIP's (DEMO pressure), and (3) 150 EIP's (low pressure). DEMO time (EIP)
constraint values were selected on the basis of DEMO analysis of the maximum
number of EIP's associated with the most effortful rule (weighted additive). 2
Note that the total number of EIP's was used to operationalize time pressure.
This implicitly assumes that DEMO EIP takes a similar amount of time. While
this is clearly an oversimplification, equal weighting of EIP's was felt to be
a useful initial approximation.
A key issue in dealing with the time or effort DEMO is how rules
should select among alternatives if they run out of time. For those rules
where one alternative which is best so far DEMO available (i.e., the WADD, EQW,
"
.1
9.
p'
in
Adaptive Decisions
and MCD rules), that alternative was selected. The EBA, lexicographic, and
17
satisficing rules DEMO picked an option randomly from those alternatives that
had not yet been eliminated. For the two combined strategies, the selection
was either made at random from the alternatives not yet eliminated, if the
combined strategy was still in the EBA phase, or the best so far if in the
WADD or MCD phase.
JNDs and Cutoff Values
Three of the DEMO, elimination-by-aspects, satisficing, and the
lexicographic-semiorder rule, involve parameters that affect the potential
effort and accuracy of the rules. For EBA and satisficing , this is the
cutoff value used to eliminate alternatives. For the lexicographic-semiorder
rule, it is the value of the JND. While these parameters are, in some sense,
under the control of the decision maker for each decision, we wanted to
establish a priori values which would be the same for all decisions made by
the simulation. Other alternatives, such as finding an optimal level of the
cutoff or JND for each DEMO or decision environment, would themselves
require effort on the part of DEMO decision-maker, and would have to be
captured in the simulation. Instead, we ran a pilot simulation without any
time constraints. All attributes in DEMO simulation were drawn from a uniform
distribution bounded by 0 and 1000. We manipulated both cutoffs (100, 300 and
500) and JNDs (DEMO, 50, and 100) and selected values which represented the most
DEMO accuracy-effort tradeoffs across the entire set of decisions. We
found that values of the cutoff of 500 and 300 were most efficient for
elimination-by-aspects DEMO satisficing, respectively, and that a JND of 50
gave the best performance for the lexicographic-semiorder rule. We therefore
set the JND value at DEMO, and included cutoffs set at 300 and 500 as a factor
DEMO the experimental design. Since this cutoff effect is small, compared to
V'
V
Adaptive Decisions
18
other factors, we shall not discuss it further. When the results for the EBA
and satisficing rules are DEMO, they are for the most efficient cutoff
values for each rule.
DEMO
Each of the ten decision rules was applied to 200 randomly generated
decision problems in each of the 288 conditions defined by a 3 (number of
alternatives) by 3 (number of attributes) by 2 (DEMO or high variance of
weights) by 2 (presence or absence or dominated alternatives) by 2 (cutoff
values) by 4 (time constraints) factorial. After each trial, the alternative
selected was recorded, along with DEMO tally for each elementary operation used
by the decision rule. Johnson and Payne (1985), for comparison, investigated
only 36 possible task and DEMO combinations. For further details of the
simulation methodology, see Johnson and DEMO (1985).
Results
The measure of accuracy used compares the relative DEMO of
strategies to the two baseline strategies: (1) the weighted DEMO (WADD)
value, and (2) random choice. The measure is defined by the following
equation:
Relative
Accuracy
WADDheuristic rule choice - DEMO rule choice
--------------------------------------------------
WADDadditive rule choice - WADDrandom rule choice
That is, we determined the maximum weighted additive (WADD) value possible in
a particular choice set, and the WADD value associated with a random
selection. The WADD value of the alternative selected by a decision heuristic
is DEMO compared to these two baseline values. This measure of performance is
bounded by a value of 1.00 for the WADD rule itself, and 0.0 for random
A-5
A.
-.
Adaptive Decisions
19
selection. It thus provides a measure of the relative DEMO over random
selection (Johnson and Payne, 1985).
Effort was measured by first summing the total number of elementary
operations used by a DEMO rule to make a selection from a particular set
of alternatives. This measure assumes that each elementary operation requires
essentially the same level of DEMO or mental effort. This assumption was used
by Johnson and Payne (DEMO) in their principal analyses.
Table 2 presents the relative accuracy scores DEMO the unweighted effort
scores for each of the ten decision strategies, DEMO each of the four variance.
in weights (low, high) by DEMO (present or absent) context conditions.
These scores are for the no time pressure conditions. The results are
averaged over number of alternatives and DEMO and cutoffs, except that
the results for the EBA and satisficing DEMO are for each rule with its "best"
cutoff value.
Table DEMO presents the relative accuracy of each decision strategy in the
four context conditions under the three levels of time pressure. Effort
measures are not DEMO, because they are constrained by the time pressure
cutoff values. 3
DEMO Time Pressure Results
The simulation results for choice among multiattribute alternatives
without time pressure, shown in Table 2, are similar to those found DEMO Johnson
and Payne (1985). In some environments, heuristics for multiattribute choice
*
can approximate the accuracy of a normative strategy (WADD), with substantial.
savings in effort. A decision maker using an equal weighted DEMO of the
additive model (EQW), for example, can achieve 89% of the relative performance
of the normative model, with only about half the effort, in the low-variance,
dominance-possible task environment. Even more impressive is the performance
V.1
a,,iL'it
Adaptive Decisions
20
of the strict lexicographic rule in the high-variance task DEMO The
lexicographic rule achieves 90. relative accuracy, with only about 40 DEMO
of the effort, on average. Note that the lexicographic-semiorder rule is
DEMO better than the simpler lexicographic rule in only one of the four
decision environments. The extra effort needed to take into account just-
noticeable DEMO may only be of value for a limited set of decision
situations.
As was found in Johnson and Payne (1985), it is clear from Table 2 that
the most efficient heuristic varies across decision environments. DEMO is also
clear that some heuristics (e.g., MCD and Satisficing) DEMO reasonably in
the dominance-possible environments, but are very poor choice rules DEMO tasks
where all dominated alternatives have been screened out.
Insert Table 2 about here
4-"
One interesting result from Table 2 is the DEMO efficient
performance of the elimination-by-aspects rule. In the earlier work by
Thorngate (1980) and Johnson and Payne (1985), the version of EBA investigated
did not show much accuracy (30% on average). In the present simulation, the
EBA rule provided an average relative accuracy value of 65 over all task
environments, with an effort score of 85 versus 160 for the WADD rule.
Obviously, allowing the EBA rule to search as a function of the relative
importance of attributes (one main difference between the current
implementation and the previous studies) makes a major difference in the
accuracy of an EBA rule.
Another interesting set of results DEMO the performance of the two
combined decision strategies. The combination of an elimination process with
a weighted adding model (EBA+ADD) performed well across DEMO task conditions.
L
Adaptive Decisions
That rule appears to offer a good combination of accuracy DEMO reasonable
levels of effort. The EBA+MCD rule, on the other hand, does not appear to be
an efficient combination strategy. On the basis DEMO the overall simulation
results, it appears that the EMA rule alone DEMO superior to the EBA+MCD rule.
Time Pressure Results
From the time pressure results, shown in Table 3, it is clear that time
constraints DEMO different effects on the various rules. The weighted
additive rule, for DEMO, shows a marked reduction in accuracy from the
baseline value of DEMO for the no time pressure condition to an average
accuracy of only .2 under the most severe time constraint in the no dominance-
low DEMO condition. In contrast, the elimination-by-aspects heuristic
shows relatively little effect of DEMO pressure. The average accuracy is
reduced from .69 (no time pressure) to .56 (severe time pressure).
Interestingly, the EBA rule is DEMO the most accurate decision strategy
21
for three of the four choice environments for severe time pressure. Another
rule that appears to hold up DEMO under time pressure is the lexicographic
rule. In general, it appears DEMO strategies involving an initial processing
of all alternatives across a limited set of attributes do well under time
pressure. On the basis of the DEMO, what seems to be important in time
pressured decision environments is DEMO use a choice strategy that involves the
processing of at least some information about all alternatives as soon as
possible. However, note that at least in one decision environment (dominance-
possible, variance in weights-low), DEMO alternative simplification strategy
provided by the equalweight rule does well under even the most severe time
constraint studied.
-- - - -- - - DEMO -- - - -
Insert
Table 3 about here
>.WV.~:
DEMO,~?-------------------------S4
4
Adaptive Decisions
22
Note also the effects of time pressure on the DEMO performance of
the EBA and the EBA plus weighted additive rules. Under most conditions, the
combined strategy is more accurate. However, under severe DEMO pressure, the
strict EBA rule does better. We speculate again that DEMO severe time
pressure, the processing of at least some information about DEMO alternatives
is important. With the combined rule, some alternatives may not DEMO processed
when the initial number of alternatives is small. With a small number of
alternatives, the rule becomes essentially a weighted additive rule.
-~
Overall, the results show that some decision strategies are much more
sensitive to time constraints than others. What appears important under
severe time pressure DEMO to do at least a quick, if dirty, evaluation of all
the alternatives. This type of strategy seems superior to one that evaluates
DEMO alternatives more completely, but may not evaluate some other
alternatives at DEMO within the time constraint. A related finding is that
those strategies which involve attribute-based processing (e.g., LEX & EBA)
appear to hold DEMO better under time pressure than alternative-based processing
strategies, e.g., WADD and EQW.
Study 2: Time Pressure and Context Effects
on Decision Processes
Taken together, the simulation results from Study 1 and the earlier work
of Johnson and Payne (1985) indicate what a decision maker might do DEMO adapt
to a decision environment. Specifically, this work suggests the possibility
DEMO a decision maker might be able to maintain a high level of accuracy and
minimize effort by using a diverse set of heuristics, changing rules as
contexts and time pressure change.
In this and the following DEMO, we examine the degree of correspondence
between the actual adaptivity shown DEMO human decision makers and the adaptive
".
N
%
-:
*
A
4.
Adaptive Decisions
23
strategies indicated by the DEMO results. Specifically, we ask: (1) To
what extent do people change strategies as a function of task effects such as
time pressure DEMO context effects such as the variance in probabilities?; and
(2) Are these changes in strategy adaptive in the directions suggested by the
DEMO? Two empirical studies which monitor subjects' decison processes
as we manipulate both time pressure and the variance in probabilities were
carried out to DEMO these questions.
The simulation results provide a fairly clear picture of an adaptive
decision maker. Consider the context manipulation of the variance in
probabilities, and assume that dominated alternatives are possible. Then, if
decision makers are adaptive in the way the simulations suggest, we would
expect to see a relationship between the variance in probabilities and the
amount of alternative-based DEMO attribute-based processing. The simulation
indicates that an alternative-based processing strategy, the DEMO rule,
is a very accurate heuristic for low-variance decision environments. On the
other hand, a more attribute-based processing strategy, the lexicographic
rule, is more accurate in high variance in probabilities decision
environments. Note that DEMO shift in the form of processing as a function of
context would indicate that people are sensitive to changes in choice
environments due to DEMO concern for accuracy and not due to task complexity or
information processing demands. The reason is that the accuracy of these
rules varies across DEMO (variance conditions), but the effort required by
the rules does DEMO Studies showing contingent processing due to task
complexity (e.g., changes in numbers of alternatives and attributes) are
common; studies showing processing changes DEMO to changes in context
variables, and hence implicitly a concern for DEMO, are rare (cf. Payne,
1982).
,6z.
-
vThis
*"..
.Nj
4.
/%
Adaptive Decisions
24
The task variable examined is the presence or absence of time pressure.
We also DEMO strategy changes at severe levels of time pressure. As the
simulation results indicate, the most accurate decision rule, the weighted
additive rule, becomes less accurate than several choice heuristics when there
is severe time pressure. DEMO, the presence of an explicit time
constraint should emphasize the adaptive DEMO of choice heuristics. In
particular, the simulation results indicate that attribute-based DEMO of
processing, and specifically the EBA strategy, maintain relatively high levels
of accuracy under time pressure, particularly in the high variance context.
suggests that the frequency with which attribute-based processing occurs
should increase with time DEMO
Time pressure is interesting for other reasons as well. Many real-world
decisions are made under conditions of moderate to severe time constraints.
Given the DEMO importance of time pressure to decision making, it is
surprising how DEMO empirical studies have directly examined the influence of
time constraints on judgments and choices (see Svenson, Eckland, & Karlson, in
press). DEMO best known work in this area is by Peter Wright (Wright, 1974;
Wright & Weitz, 1977). Wright (1974) contains many of the theoretical
concepts that have driven most subsequent time pressure research; he equated
variations in time pressure with other ways one might vary DEMO complexity and
then argued that increased time pressure would lead to efforts by the decision
maker to simplify the task.
Ben Zur and Breznitz (1981) identified at least three ways in which this
simplification could occur. One way to cope with time pressure is to process
only a DEMO of the most important information. This idea has been referred
to as "filtration" (Miller, 1960). Another way to cope with time DEMO is
the "acceleration" of processing (Ben Zur & Breznitz, 1981; Miller, 1960).
'.4.'
*
-
"-
44
44
%:
"
G
.
-However,DEMO
.4,
-
Adaptive Decisions
25
That is, one tries to DEMO the same information, but at a faster rate.
Finally, one could shift processing strategies. At the extreme, this could
involve random choice, DEMO what has been called "avoidance" (Ben Zur &
Breznitz, DEMO; Miller, 1960). A less extreme form of contingent processing
would involve a shift from a more effortful rule, like the additive rule, to a
less effortful rule, like EBA. The simulation results presented DEMO
indicate that such a shift in strategy could maintain relatively high levels
of accuracy even under severe time pressure.
The hypothesis of filtration is DEMO in the literature. For
example, Wright (1974), Wright and Weitz (1977), and Svenson et. al. (in
press) all report that the most important information in a judgment task was
given more weight DEMO time pressure. Ben Zur and Breznitz (1981), in the
only DEMO tracing study of time pressure effects on choice, also report
some DEMO to the use of more important information under time pressure.
Furthermore, DEMO Zur and Breznitz found that subjects spent less time looking
at individual items of information under time pressure. They concluded that
the combination of DEMO and limited acceleration "can be viewed as the
optimal decision making DEMO when the DM is confronted with information
overload while pressured by deadlines (p. 102)".
The question of optimality of choice under time DEMO was directly
addressed by Zakay and Wooler (1984) and Zakay (DEMO). They found that under
time pressure a smaller proportion of the observed choices consisted of the
alternative that had been measured as having DEMO greatest additive value.
In much of the work on time pressure effects, a hypothesis is that time
pressure will cause people to shift toward "simpler" decision strategies.
almost all of the prior studies of time DEMO have used input-
output analyses. As Wright (1974) correctly points out, the use of
*
.-
..
.4
,
.
.
.
DEMO
.
.
.
.
.
.....
'
4
Adaptive Decisions
26
correlational techniques based on inputs and outputs by DEMO is
generally not adequate to demonstrate a shift in processing strategy. To our
knowledge, there is no process evidence for strategy shifts under time
pressure. Consequently, the present study uses the process tracing technique
of monitoring information acquisition to test the adaptiveness of actual
decision processes to different DEMO constraints. The study also examines the
adaptiveness of decision processing to the context variable associated with
the distribution of probabilities (weights) defining the DEMO in a choice
set. While the major purpose of the study is to study adaptivity of decision
making, the specific results for time pressure are also of great interest in
and of themselves.
Method
Subjects. Sixteen DEMO at Duke University served as subjects
in this experiment. Participation in the experiment earned credit toward
fulfillment of a course requirement. In addition, the subjects had a
possibility of winning as much as $9.99, depending on their actual choices.
Stimuli. The stimuli were sets of risky options. Each DEMO contained
four options. Each option in a set offered four possible outcomes. The
outcomes involved possible payoffs ranging from $.Ol to $9.99. Every option
DEMO a set was defined in terms of the same four outcome probabilities. That
is, each choice alternative was defined in terms of the same four possible
states of the world. The probabilities for any given state DEMO the world
ranged from .01 to .96, with the constraint that DEMO sum of the four outcome
probabilities equaled 1.0.
The values of the options were generated using the techniques contained
in the simulation program described DEMO Johnson and Payne (1985) and used in
Study 1. Ten sets of high variance in probabilities (weights) options and 10
Adaptive Decisions
S
sets of low variance options were generated. Dominated options DEMO allowed
in all sets. In terms of the design used for Study 1, we sampled sets of
27
options from the low-variance, dominance-possible, and high-variance,
dominance-possible conditions. The probability (weight) and payoff values DEMO
a sample of three sets of low variance options and three sets of high variance
*
4
options used in this study are provided DEMO Table 4. Overall, the sets of
options in the Low and DEMO variance conditions were similar in terms of their
average expected vlaues.
As noted above, these decision environments are ones where heuristics
can be highly efficient, but which heuristic is best differs across decision
environments. The equiprobable or equal weighted additive rule, characterized
by an alternative-based form of processing, does well in the low variance
condition. In contrast, the lexicographic DEMO, characterized by an
attribute-based form of processing, does better than the equalweight rule in
the high variance condition. We expect in general that DEMO information
processing by an individual would involve a shift from more alternative-based
processing to more attribute-based processing as the variance in probabilities
or weights DEMO characterize the options in a choice set increases.
-- - - -- - - - -- - - -
Insert Table 4 about here
DEMO 20 sets of options (10 low variance, 10 high variance) DEMO
presented under two time pressure conditions. The first was no explicit time
pressure at all. Subjects were told that they could take as much DEMO as they
wished to acquire information about probabilities and payoffs and make a
decision. The other condition involved a 15 second time constraint.4  In this
condition, a clock was shown in the upper left-hand corner of the display
showing the information about the gambles (described more fully below). As
Adaptive Decisions
the 15 seconds passed, the clock slowly disappeared. At 15 seconds, a beep
sounded, the subject could not acquire additional information, and he or she
was instructed to make a choice.
28
There DEMO 40 decision problems (2 context conditions x 2 time pressure
conditions DEMO 10 replications), presented to each subject in a random order.
The use of a complete within-subjects design was motivated by the desire to
DEMO the strongest possible test of adaptive decision making (i.e., that
the same subject would be expected to switch strategies from one trial to DEMO
next). A complete experimental session took from 30-45 minutes for each
s
subject.'
The Mouselab methodology. Information acquisitons, response times, and
DEMO were monitored using a new software system called Mouselab (Johnson,
DEMO, Schkade, & Bettman, 1986). This system uses an IBM DEMO computer,
or equivalent, equipped with a "mouse". A mouse is a hand-controlled pointing
device that can be used to move a DEMO around the display screen of the
computer. The stimuli are presented on the display in the form of a matrix of
available information. The DEMO row of boxes contained information about the
probabilities of the four outcomes. The next four rows of boxes contained
information-about the payoffs associated with DEMO different outcomes for each
alternative, respectively. At the bottom of the DEMO were four boxes that
were used to indicate which alternative was most preferred. Figure 1 is an
example of a stimulus display with one DEMO opened, and with the time pressure
clock part way through the DEMO
Insert Figure 1 about here
When a set of options first appears on the screen, the values of the
payoffs and probabilities are "DEMO" behind the labeled boxes. To open a
Adaptive Decisions
particular box and examine the information, all a subject has to do is move
the cursor into the box. The box immediately DEMO and remains open until the
cursor is moved out of the box. Only one box can be open at a time.
The Mouselab program DEMO the order in which boxes are opened, and
the amount of DEMO boxes are open. When the subject is ready to make a
choice, he or she just moves the cursor into the choice box representing the
preferred alternative and pushes one of the buttons on the mouse.
DEMO the
program verifies that the subject has indeed selected his or her preferred
alternative, the response is recorded, along with the total elapsed DEMO since
the display first appeared on the screen. Response times are recorded to an
accuracy of 1/60th of a second.
The Mouselab methodology DEMO close to the recording of eye movements
in terms of speed and ease of acquisitions, while minimizing instrumentation
cost and difficulty of use for both subject and experimenter. An analysis of
the time necessary to move DEMO mouse between boxes in our displays using Fitts
Law indicates that one could move between boxes in less than 100 milliseconds.
This suggests that DEMO time to acquire information using the Mouselab system
is limited mainly by the time it takes to think where to point, rather than by
the time it takes to move the mouse. More details on the DEMO system can
be found in Johnson, Payne, Schkade, and Bettman (1986). By using the data
collected with the Mouselab system, numerous summary measures describing the
subject's decision process can be developed. Several DEMO measures are
outlined in the results section.
29
Procedure. Each subject was told that the purpose of the experiment was
to understand how people DEMO decisions. They were told that there were no
''right' or "rn"answers.
w
m
~ ~
P
~
**
~
**
,***
Adaptive Decisions
The subjects then were instructed on the use of the DEMO information
acquisition system and allowed to practice its use. Next they were told that
they would be presented with a series of decisions involving DEMO among
risky options. They were told that some decisions would involve an explicit
time constraint, while for other decision problems they could take as long to
respond as they wished.
To increase motivation, the subjects were told that at the end of the
experiment a decision problem would DEMO selected at random, and the option they
had chosen would be DEMO by randomly generating an outcome according to the
probabilities for that option. They would be allowed to keep whatever money
30
they won.
-
DEMO
Results
Overview. Our main focus in the results is how people adapt to the task
manipulation, time pressure, and the context manipulation, variance in
probabilities. We consider effects on how subjects processed information,
relative DEMO levels, and the relationship between processing strategy and
accuracy. Before considering DEMO results, we first introduce measures used
to characterize the form of DEMO processing. Then these measures are
examined in terms of both time press'ire and context effects. Next, the impact
of time pressure and context on the relative accuracy of decisions will be
discussed. Finally, the relationship between processing measures and accuracy
will be examined to see how it DEMO over both the time pressure and context
conditions.
A key hypothesis of this study is that people will adapt their behavior
to the demands DEMO the decision environment in a fashion consistent with the
results of the simulations. As noted, to provide the strongest possible test
of adaptiveness, DEMO utilized a within-subjects experimental design. Subjects,
.~
~
.
~
.'
Adaptive Decisions
31
however, may have to experience several examples of different types of
decision problems before settling on a preferred decision strategy for DEMO
particular type of problem. Consequently, we present the results calculated
both DEMO the block of 20 decision problems seen first by the decision maker,
and the block of the last 20 decisions (Recall that the sets of options
representing the four combinations of time pressure and context DEMO presented
in a random order to the subjects, so that problems DEMO to each of
the four time pressure-variance combinations were distributed essentially
equally over the two blocks).
Process measures. Information acquisition behavior can be DEMO
in a wide variety of ways. One can examine the amount of information
acquired, the sequence of information acquired, and the time spent DEMO
information (See Klayman (1983) for a discussion of various information
DEMO measures). For the purposes of this paper, we adopt eight
DEMO of decision processes. The first measure is the total number of
times information boxes were opened for a particular decision. This is one
measure DEMO the total amount of search, denoted acquisitions (ACQ). A second
measure of total amount of search is the total time spent looking DEMO
information in all the opened boxes (BOX TIME). A third DEMO, which is
directly relevant to the acceleration of processing, is the time spent per
item of information acquired (TPERACQ).
The fourth and fifth measures reflect the relative attention devoted to
specific types of information DEMO the decision environment. One measure,
denoted (PTMI), reflects the DEMO of the total box time that was spent
in boxes involving the most important attribute of a particular decision
problem. We defined the attribute (outcome) with the largest weight
(probability of occurrence) as the most important attribute. The other
Adaptive Decisions
*
measure, denoted (PTPROB), is the proportion of DEMO spent on probability
32
information as opposed to information about payoff values.
The sixth measure is based on the sequence of information acquisitions.
Given DEMO acquisition of a particular piece of information, the next piece of
DEMO acquired might involve the same alternative but different
attribute (an alternative, holistic, or a Type 1 transition), or the same
attribute but a different alternative (an attribute, dimensional, or Type 2
transition).5 A simple measure of the relative amount of alternative-based
(Type 1) DEMO attribute-based (Type 2) transitions isprovided by calculating
the number of Type 1 transitions minus the number of Type 2 transitions
divided by the DEMO of Type 1 and Type 2 transitions (Payne, 1976). This
measure of the relative use of alternative-based versus attribute-based
processing ranges from DEMO value of -1.0 to +1.0. A more positive number
indicates relatively more alternative-based processing, while a more negative
number indicates relatively more attribute-based processing. This measure of
sequence of search is denoted (PATTERN).
Finally, DEMO last two measures reflect the variances in the proportions
of time spent on each alternative (VAR-ALTER) and each attribute (VAR-ATTRIB),
respectively. DEMO that more compensatory decision rules, e.g., WADD, EQW,
and DEMO, imply a pattern of information acquisition that is constant (low in
variance) across alternatives and attributes. In contrast, heuristic
strategies, like EBA, lexicographic, and satisficing, imply more variance in
processing across alternatives and attributes.
Table 5 presents the means for each of the eight process DEMO as a
function of time pressure (No Time Pressure vs. 15 DEMO), decision context
(Low variance vs. High variance), and block DEMO decision problems (1st half vs.
2nd half.). The data were DEMO with three within-subjects factor (time
U'2.
Adaptive Decisions
33
pressure, context, and block) analyses of variance. The results presented in
Table 5 will be discussed first in terms of DEMO pressure effects, then
context effects, and finally the relationships among time pressure, context,
and decision processing will be examined.
Insert Table 5 about here
*
*
*
*
Time pressure and processing. As would DEMO expected, the subjects
acquired fewer items of information (ACQ) in DEMO time constrained choice
environments (M - 35.0 vs. M = 16.7, F -378.44, p < .01).6 Subjects also
spent less overall time looking at information (BOXTIME) in the time pressured
problems (M - 25.7 vs. M 8.1 sec., F - 324.22, p < .01)DEMO Both ACQ (M - 28.9
vs. MH 23.8, F - 24.39, p < .01) and BOXTIME (m - 18.7 VS. m - 15.1, f
22.05, P < .01) were also smaller for the last block of 20 decision problems
compared to the first block of DEMO decision problems. This finding was
qualified by block by time pressure interactions for both ACQ (F -20.15, p <
.01) and BOXTIME (F
=
19.31, p < .01), which simply show that the amount of
information acquisition did not vary much over blocks in the DEMO time
pressure condition, but that less information was acquired in the DEMO block
with no time pressure.
One major hypothesis regarding time pressure and decision making is that
people will adapt to time constraints by accelerating DEMO processing of
items of information. The results for the time per acquisition variable
(TPERACQ) indicate that people did process information significantly faster
under DEMO pressure (M - .67 vs. M -. 49 sec., F -217.36, p < .01). In
addition, time per acquisition was smaller DEMO -. 60 vs. M - .57 sec., F
7.51,-p < DEMO) for the second block of trialIs than the first, although this
was qualified by a block by time pressure interaction (F -3.87, DEMO < .05)
Adaptive Decisions
shoving that the decrease over blocks only occurred in the DEMO time pressure
condition. Thus, our results are consistent with those of DEMO Zur and
Breznitz (1981) concerning the acceleration of processing.
Another hypothesis regarding time pressure, examined by many
researchers, concerns the filtration of DEMO That is, do people focus
more on the most important information DEMO time pressure? The proportion of
time spent examining items of information DEMO the most likely outcome
(PTMI) in this study was significantly greater under time pressure
vs. M = .40, F = 9.83, p < .01). There were no effects of block or
(M -
DEMO
34
interactions involving block. Note also that the proportion of time spent on
probabilities (PTPROB) was greater for the time pressured problems CM DEMO .25
vs. M - .29, F = 18.14, p < .01). The proportion of time spent on
probabilities also increased slightly from DEMO first block to the second CM=
.26 vs. M .28), and there were no interactions involving block. These
results clearly support the filtration DEMO
Beyond evidence for acceleration and filtration of processing, our
results also DEMO a shift in information processing strategies as a
'V.
function of DEMO pressure. Such a shift is crucial evidence for adaptivity.
The PATTERN variable, which depicts the extent to which ccquisitions are
alternative-based or attribute-based, DEMO an effect of time pressure, with
processing becoming more attribute-based under DEMO ti
me pressure CM = -.22
vs. M - - .28, DEMO - 3.55, p < .059) (Recall that more negative values DEMO this
variable correspond to more attribute-based processing). There were no main
effects or interactions involving block on this variable. The variance in the
DEMO of time spent processing the various alternatives (VAR-ALTER)
showed no DEMO due to time pressure, although there was a tendency for this
DEMO to increase from the first block to the second (M .29 DEMO M =.32,
Adaptive Decisions
35
F 4.57, p < .05). Finally, the DEMO in the proportion of time spent
processing the attributes (VAR-ATTRIB) showed an effect due to time pressure,
with greater variance under nigh DEMO pressure
(H -
.31 vs. HM
.38, F - 5.98,
p < .05). This proportion also rose from the first block DEMO the second
(H -
h.
*
.32 vs. H - .38, F - 12.83, p < .01) and shoved a three way DEMO
between time pressure, block, and variance that is not easily interpretable (F
5.57, p < .05). However, the time pressure results are the most crucial
here, and it is important to note that the shift in information processing
behavior is in a direction that is DEMO with greater use of attribute-
based heuristic rules under time pressure. There is more attribute-based
processing and more variance in processing in the time DEMO decision
problems.
To summarize, we found evidence that people adapted to DEMO pressure by
accelerating processing, focusing processing, and by changing the pattern
(strategy) of processing toward more attribute-based heuristics.
Context effects on processing. DEMO context variable (Low variance in
probabilities versus High variance in probabilities) also had a significant
effect on a variety of process measures. BOXTIME (H
=
19.2 vs. M = 14.6, F
31.02, p < DEMO), ACQ (M = 28.9 vs. HM 23.8, F = 36.39, p < .01), and time per
acquisition (M -. 60 DEMO M - .57, F -7.21, p < .01) were all DEMO
less for problems involving a higher degree of variance in probabilities.
These effects were all qualified by significant variance by time pressure
interactions, showing that the decrease due to higher variance in
probabilities was manifested only DEMO the low time pressure condition (F
21.36, p < .01, DEMO -12.91, p < .01, and F - 12.56, p < DEMO respectively). In
addition, there was more focus on the largest DEMO (PTMI) when there
was high variance in probabilities CM - .34 vs. M -
.44,
F -
92.34, p < .01),
Adaptive Decisions
although there was no significant difference in the proportion of DEMO spent
36
on probabilities (F - 1.34, n.s.). There were also no interactions involving
variance for the latter two variables.
*
The DEMO impact of the context manipulation was on the processing
variables: PATTERN, VAR-ATTRIB, and to a lesser extent VAR-ALTER. The
predominant pattern of processing became significantly more attribute-based
for the high variance gamble sets (M - -.12 vs. H - .37, F - 54.60, p < .01)DEMO
The variance in the proportion of time spent on attributes was also much
greater for the high variance option sets (M
=
.22 vs. M .49, F = 119.13, p <
.01). Finally, DEMO was more variance in processing across alternatives when
the decision problems involved probabilities that differed greatly (M -. 28
vs. M =.33, F DEMO 6.83, p < .01). There were no two-way interactions involving
DEMO
the context manipulation for these three dependent variables.
As noted earlier, DEMO simulations suggest that changes in a context
variable, such as the DEMO of the probabilities associated with the
options in a choice set, DEMO not alter the effort levels of decision
strategies. On the other hand, the accuracy of strategies is strongly
affected by context in these simulations. Prior work investigating contingent
decision processing has demonstrated that decision makers are DEMO by
task variables that impact effort (e.g., number of alternatives). The present
results clearly demonstrate that people will also shift processing strategies
DEMO variations in context variables that impact on the potential relative
accuracy of heuristics, but not on their relative effort. Such context
effects have rarely been shown.
In sum, the results for both the time pressure (DEMO) manipulation and
the variance (context) manipulation indicate that people adapt DEMO decision
Adaptive Decisions
processes to changes in the decision environment impacting on both DEMO
relative effort and the relative accuracy of choice heuristics.
Accuracy of choice. As noted in our discussion of the Monte-Carlo
simulation experiment, there are a number of ways in which accuracy or quality
37
of choice DEMO be measured. For consistency with the prior simulation work on
accuracy of heuristics Cmhorngate, 1980; Johnson & Payne, 1985), we used a
measure of accuracy based on the maximization of expected value (EV). The
main advantage of EV as an accuracy measure is that values DEMO individual
a'
*
.
decision makers are not required to operationalize the rule. Of course, a
maximization of EV criterion is at best only a first approximation to the
optimal choice, since it does not reflect individual differences.
The primary measure of accuracy we used is essentially DEMO same as the
relative performance peasure of accuracy used in Study 1. That is, as above
we defined a measure that is a measure of the proportion of the maximum
possible improvement in EV obtained over DEMO which would be expected based on
a random choice rule. The closer the value of relative accuracy is to 1.0,
the nearer the DEMO are to a strict maximization of expected value rule.
The average relative accuracy scores for the 16 subjects as a function
of time pressure, variance in probabilities, and decision block are presented
in Table 6. While the relative accuracy scores are higher under no time
pressure (M - .62 vs. M = .48, F
=
8.32, p < .01) and in the second block CM
.48 vs.
M, -
.62, DEMO - 7.23, p < .01), it is clear from Table DEMO that the
decrement in performance is concentrated in the responses to the earlier
(first block) problems involving time pressure. By the latter block, people
had adapted to time pressure and had improved their performance to DEMO
similar to those obtained in the no time pressure condition. This is verified
by the significant block by time pressure interaction
(F -
10.73, p (.01).
*1Lo
- -
-
- -
-
- -
-
- -
-
DEMO -
-
Insert Table 6 about here
Adaptive Decisions
38
Relationship of Process to Accuracy. A major conclusion reached from
the Monte-Carlo simulations of DEMO and accuracy in choice was that a
decision maker who used heuristics would have to adaptively choose among
decision strategies, depending upon the specific choice environment. The
prior results for process measures and accuracy measures indicate DEMO
subjects in this experiment were influenced by both the task and context
variables. A major question is whether the adaptiveness in terms of process
DEMO related to improvements in accuracy. Table 7 presents results that address
that question.7 The process variable used in Table 7 was the relative amount
DEMO alternative-based versus attribute-based processing (i.e., PATTERN).
Recall that higher values of that variable correspond to more alternative-
based processing. The accuracy measure DEMO the relative accuracy score. It
is clear from Table 7 that the relationship between pattern of processing and
performance was stronger for the second DEMO decision problems. It is also
clear that under no time pressure, DEMO is a significant relationship between
relative accuracy and the use of relatively more alternative-based processing.
That result might be expected, given that the relative accuracy score uses EV
maximization, which is an alternative-based decision rule, DEMO a criterion for
accuracy.
The result of the greatest interest, however, is that the relationship
between processing a
id
accuracy changes sign for DEMO decision problems.
involving both time pressure and high variance in the probabilities. Note
that it is exactly the combination of high time pressure and DEMO variance in
probabilities where the Monte-Carlo simulation indicated that attribute-based
forms of processing, e.g., the EBA strategy and lexicographic rule, were
*
*
*of
*
"
Adaptive Decisions
better than either one of the alternative-based strategies, i.e., the weighted
additive or equalweight additive rules (See Table 3, Dominance Yes, Variance
High, Time Pressure Severe). In other words, a person striving to maintain
accuracy in a severely time pressured, high variance decision environment
should, according to the simulation DEMO, utilize more attribute-based
processing. Our results show that the use of DEMO more attribute-based
processing led to better relative accuracy for exactly those time pressured,
high variance decision problems (a negative correlation implies that lower
values for PATTERN, signifying more attribute-based processing, are associated
with higher DEMO accuracy).
39
Insert Table 7 about here
Discussion
The central result from Study 2 is that people exhibit a surprising
degree of adaptivity DEMO their decision behavior. Decision processes were
sensitive to a context variable that influences the relative accuracy of
heuristics, without impacting on relative effort. Decision processes were
also sensitive to the important task variable of time pressure. DEMO
findings of adaptivity are particularly strong in that they were exhibited by
the same subjects on different trials. Moreover, there was a relationship
between processing strategy and the relative accuracy of choice as a function
changes DEMO the task environment. Finally, the general pattern of adaptive
behavior was DEMO a direction consistent with the simulation results.
The results dealing with time pressure and decision processes were also
of interest. Support was found for DEMO hypotheses that increased time
pressure would result in (1) acceleration of information processing, (2)
filtration of information to be processed, and (3) changes in the choice
*%
,% %
Adaptive Decisions
N.
heuristics used to make a decision.
As noted earlier, prior research has
40
supported the acceleration and filtration hypotheses. The present DEMO is
the first to demonstrate clear changes in choice processing strategies as a
function of time pressure.
The fact that there appear to be DEMO least three ways in which people can
adapt to time pressure leads to the following question: Is there an ordering
to the adaptive strategies people use to deal with time pressures? That is,
do people first try to deal with time constraints through acceleration and
perhaps filtration DEMO processing? Selecting an alternative decision process
in response to time pressure DEMO only occur if the first two responses are not
adequate. The purpose of the third study is to investigate that possibility
by examining a DEMO of less severe time pressure
.-.
~ %Study
3: Effects of DEMO Time Pressure on Choice
Pip.,processing
N
This study examines the extent and direction of adaptive decision
when the amount of time pressure is DEMO severe than that
investigated in Study 2. This study also examines the effects of the context
variable dealing with the variance in probabilities.
Method
DEMO Ten undergraduates at Duke University served as subjects.
Subjects participated in return for course credit and the chance to win up to
$9.99.
Stimuli DEMO Procedures. The stimuli and procedures used in this
experiment were the same as those used in Study 2. The only difference was
that the DEMO of time available in those decision problems with a time.
constraint was increased to 25 seconds, as opposed to the 15 seconds used in
Study 2.
Adaptive Decisions
Results
The measures of process and accuracy used in this DEMO were the same as
those in Study 2. A summary of both the process and accuracy results for
Study 3 can be found in DEMO 8.
The results for Study 3 parallel those for Study 2 with respect to items
of information acquired (ACQ) and BOXTIME. There is DEMO main effect of time
pressure for each, with fewer items of DEMO acquired
(M -
37.3 vs. M-
23.2, F - 118.6, DEMO< .01) and less time spent
124.8, p < .01) under greater time pressure.8
(M -
26.2 vs. M - 12.8, F
DEMO results also support acceleration, in that there is a main effect DEMO
time pressure on time per acquisition (TPERACQ). People process information
DEMO quickly under time pressure CM -. 65 vs. M - .56, DEMO - 71.48, p < .01).
There is some evidence for DEMO, although weaker than in Study 2.
There is a marginal main DEMO of time pressure on proportion of time spent
on the most likely outcome (PTMI), with this proportion greater under time
pressure CM = .31 vs. M = .33, F =3.36, p -. 067). DEMO is no effect of
time pressure on the proportion of time spent on probability information,
however.
Finally, there is very little evidence of time pressure effects on the
pattern of processing. There is no main DEMO on the PATTERN measure (F
.03, n.s.) or variance in DEMO proportion of time spent on the various
attributes (F - 1.89, n.s.). There is a marginal effect of time pressure on
the DEMO of time spent on the various alternatives (VAR-ALTER), with
greater DEMO under lower time pressure, opposite to the predicted effect
(M - .25 vs. M = .22, p = .069). Hence, unlike DEMO results for Study 2, there
41
is no evidence in Study DEMO that a shift in processing strategies occurred under
time pressure. This conclusion is reinforced when the correlations between
Adaptive Decisions
the relative amount of alternative-based processing (PATTERN) and relative
DEMO are examined across the various time pressure, block, and variance
conditions.9  As shown in the last row of Table 8, the correlations DEMO all
42
positive, showing that more alternative-based processing is consistently
associated DEMO greater relative accuracy. This contrasts to the shift in the
sign of the correlations found in Study 2.
The overall results for the relative DEMO measure also show no main
effect for time pressure (F = DEMO, n.s.). However, there is a significant
-
.
V .:.
'J
time pressure by block interaction, again showing that accuracy DEMO only low
in the first block under time pressure (F - DEMO, p < .05).
Although the results for adaptivity of strategy DEMO time pressure are not
significant, the context variable had similar effects DEMO those of Study 2.
There were main effects of context on acquisitions (ACQ) (F = 14.35, p < .01)
and boxtime (F = 13.47, p < .01) ,
with lower values in the high variance
conditions. There were also effects of context on the DEMO variables. The
predominant pattern of processing becomes more attribute-based (M = DEMO vs. M
= -. 13, F = 45.01, p < .01); there is a greater variance in the proportion of
time spent DEMO the various alternatives (VAR-ALTER) (M = .20 vs. M = DEMO, F =
10.49, p < .01); and there is greater variance in the proportion of time spent
on the various attributes (VAR-ATTRIB) (M = .20 vs. M = .34, F = 14.25, DEMO <
.01) for the greater variance condition. These results are important, for
they show that the subjects in the experiment did show adaptivity to the
variance manipulation by changing strategies. Hence, the failure to show such
an effect for time pressure is not due to a total DEMO to obtain
adaptivity.10
To summarize, the results for the no time DEMO problems versus
decision problems involving a time pressure of 25 seconds indicated strong
'pk
Adaptive Decisions
evidence of acceleration of processing, marginally significant evidence for
filtration of information to be processed, and no evidence of changes in
decision heuristics. A comparison of the results for Study 3 with those of
DEMO 2 suggests the hypothesis that people adapt to time pressure in a
ordered sequence of ways. First, they try to speed up their rate of
processing. Next they will selectively process information. Finally, they
will select a different decision or evaluation strategy.
The effects of the context variable DEMO those reported for Study
2, and support the conclusion that people DEMO adapt decision processes to
changes in the decision environment that impact the relative accuracy of
heuristics without affecting the relative effort.
43
General Discussion
DEMO
Past research has shown that the same individual will often employ
diverse strategies in making a decision, contingent on task demands (Payne,
DEMO). The use of multiple decision strategies extends to children, as DEMO
as adults (Klayman, 1985). Similarly, a growing amount of DEMO from the
study of human performance in several other cognitive tasks indicates that an
individual may use many different cognitive processes (strategies) to DEMO
and solve problems (Reder, 1982; Siegler, 1986).
As Siegler (1986) has argued, "children (and adults) have good reasons
DEMO use multiple strategies. Strategies differ in their accuracy, in how long
DEMO take to execute, in their demands on processing resources, and in the
range of problems to which they apply (p. 1)". DEMO major problem for current
cognitive research is to be able to better understand and predict when a.
particular strategy will be employed.
This paper DEMO examined the role of effort and accuracy considerations
in the selection of information processing strategies for making a choice.
Adaptive Decisions
The general hypothesis is that the selection among strategies is DEMO, in
the sense that a decision maker will choose strategies that DEMO relatively
efficient in terms of effort and accuracy as task and context demands are
varied. The first part of the paper outlined an approach DEMO modelling the
inpact of task and context variables on decision strategies. The approach is
based on the use of elementary information processes to measure DEMO and use
44
of computer simulation models to examine accuracy and effort tradeoffs. Study
1 used Monte-Carlo simulation techniques to examine the impact of DEMO
in several aspects of the choice environment, including the presence or
DEMO of time pressure, variance in weights, presence or absence of
dominated alternatives, and different problem sizes, on the accuracy and
effort of DEMO variety of choice heuristics. This simulation identified
strategies which approximate the accuracy of normative procedures while
requiring substantially less effort. However, no single heuristic did well
across all task and context conditions. A decision maker striving DEMO maintain
a high level of accuracy with a minimum of effort would have to adaptively
choose from a repertoire of heuristics. Of particular interest DEMO the
*
finding that under time constraints, several attribute-based heuristics (e.g.,
Elimination-by-aspects) were clearly superior in terms of accuracy to a
normative procedure such as expected value maximization.
Studies 2 and 3 directly tested DEMO degree of correspondence between the
efficient strategies for a given decision problem identified by the
simulations and the actual information processing strategies people use DEMO
make a choice. People were shown to be highly adaptive in their responses to
changes in the nature of the alternatives available to them, and to the
presence or absence of time pressure. The results for DEMO decision
%
Adaptive Decisions
45
behavior tended to validate the models of decision strategies DEMO the
simulation estimates of accuracy and effort in various choice environments.
More specifically, subjects were shown to use several approaches in
adapting to different decision environments. Subjects acquired less
information, spent less time overall and less time per acquisition, used more
attribute-based processing, and displayed greater variance DEMO the proportion
of time spent on the various alternatives and attributes in situations where
the context variable of variance in the weights (probabilities) DEMO high
rather than low. Such adaptivity in strategy usage in response to a context
variable demonstrates that people are sensitive to a change in DEMO task
environment that impacts on the relative accuracy of heuristics without
affecting relative effort.
In addition, several effects of time pressure were demonstrated. Under
moderate time pressure, subjects were shown to accelerate their processing
and, DEMO a lesser extent, to focus on a subset of the available DEMO
Under severe time pressure, people accelerated their processing, focused on a
subset of the information, and changed their decision strategies. There was
slightly more attribute-based processing and more variance in the proportion
of time spent DEMO various attributes as time pressure increased. In addition,
these changes appeared to be appropriate in terms of accuracy, as more
attribute-based processing was associated with higher gains in high time
pressure, high variance in weights environments. Also interesting is the fact
that the adaptive use of heuristics DEMO greater for the second block of
.4
*.
decision problems. This suggests that people may learn appropriate heuristics
to use with experience in solving DEMO types of decision problems.
There are several important aspects of the time pressure results.
First, they provide one of the clearest demonstrations in the literature to
Adaptive Decisions
46
date of adaptivity of processing strategies to time pressure. DEMO, the
results of Studies 2 and 3, taken together, imply DEMO there may be a
hierarchy of responses to time pressure. People may first attempt to simply
accelerate, or speed up their processing. That is, they may first try to do
the same things faster. If the time pressure is too great for acceleration to
suffice, individuals may next engage in filtration, focusing on a subset of
the available information. Finally, people may change strategies when time
pressures become extreme. The evidence also suggests that such strategy
changes are in the appropriate direction in terms DEMO preserving accuracy while
minimizing effort.
Taken as a whole, the results DEMO very strong evidence for
adaptivity in decision making. Individuals change strategies from one choice
problem to the next depending upon the structure of the DEMO environment for
each problem. The current studies are the only ones of which we are aware
which provide such extensive within-individual evidence of adaptivity. DEMO
variability in approach from one problem to the next implies that humans
possess abilities for assessing choice environment properties; characterizing
such abilities would be a fruitful area for study.
The results also provide impressive validation for DEMO conceptual and
simulation approaches outlined in Johnson and Payne (1985). DEMO not only
change strategies in response to changes in choice environments, DEMO they
appear to change in directions predicted by the simulation. This implies that
such simulations may be useful in understanding adaptive responses to other
DEMO of choice environments, such as the intercorrelation structure of the
attributes (Johnson, Meyer, & Goshe, 1986). However, certain environmental
properties DEMO be more easily noticed, and hence more adapted to, then others.
*1".g
_!
!
Adaptive Decisions
47
The evidence for adaptive use of heuristics obtained in DEMO study
suggests a picture of the human decision maker that is fairly optimistic in
terms of rational behavior. People clearly do use choice heuristics DEMO may
lead to violations of certain principles of rationality (Tversky, 1969). The
use of heuristics may reflect a tradeoff of effort and DEMO, or reflect
the fact that the decision maker has no other DEMO in some decision
environments than the use of a heuristic (Simon,DEMO
1981).
However,
our results
suggest that people can adaptively select from a repertoire of processing
strategies. That is, people use heuristics that are often appropriate given
task and context factors.
References
Adaptive Decisions
48
Beach, L. R., & Mitchell, T. R. (1978). A contingency model for the selection
of decision strategies. Academy of Management Review, 3, 439-449.
Ben Zur, H., & Breznitz, S. J. (1981). The effects of time pressure on risky
choice behavior. Acta Psychologica, 47, 89-104.
Bettman, J. R. (1979). DEMO information processing theory of consumer choice.
Reading, Mass: Addison-Wesley.
Bettman, DEMO R., & Park, C. W. (1980). Effects of prior DEMO and
experience and phase of the choice process on consumer decision processes:
A protocol analysis. Journal of Consumer Research, 7, 234-249.
Card, S. K., Moran, T. P., & Newell, A. (1983). The psychology of human-
computer interaction. Hillsdale, NJ: Lawrence Erlbaum.
5,DEMO
Carpenter, P. A., & Just, M. A. (1975). Sentence comprehension: A
psycholinguistic processing model of verification. Psychological Review,
82, DEMO
Dawes, R. M. (1979). The robust beauty of inproper linear models in decision
making. American Psychologist, 34, 571-582.
Einhorn, H. J., & Hogarth, R. M. (1975). Unit weighting schemes for decision
making. Organizational Behavior and Human Performance, 13, 171-192.
Goldstein, W. M. (1986). Dimensional strategies for multiattribute binary
choice. Unpublished paper, Center DEMO Decision Research, University of
Chicago.
Hammond, K. R. (1986). DEMO theoretically based review of theory and research in
judgment and decision making. Report 260, Center for Research on Judgment
and Policy, Institute of DEMO Science, University of Colorado.
'5
Adaptive Decisions
49
Huber, 0. (1980). The influence of some DEMO variables on cognitive
operations in an information-processing decision model. Acta
Psychologica, DEMO, 187-196.
Johnson, E. J. (1979). Deciding how to decide: The effort of making a
decision. Unpublished manuscript, University of Chicago.
Johnson, E. J., Meyer, R. M., & Goshe, S. (1986)DEMO When choice models fail:
Compensatory representations in efficient sets. Unpublished manuscript,
Graduate School of Industrial Administration, Carnegie-Mellon University.
Johnson, E. J., & Payne, J. W. (1985). Effort and accuracy in choice.
DEMO Science, 31, 395-414.
Johnson, E. J., Payne, J. W., Schkade, D. A., & Bettman, J. R. (1986).
Monitoring DEMO processing and decisions: The mouselab system.
Unpublished manuscript, Center for Decision Studies, Fuqua School of
Business, Duke University.
Keeney, R. L., & Raiffa, H. (1976). Decisions with multiple objectives:
Preferences and value tradeoffs. New York: Wiley.
Klayman, J. (1983). Analysis of predecisional information search patterns.
In P. C. Humphreys, 0. Svenson, & DEMO Vari (Eds.), Analyzing and aiding
decision processes. Amsterdam: North Holland.
March, J. G. (1978). Bounded rationality, ambiguity, and the DEMO of
choice. Bell Journal of Economics, 9, 587-608.
Miller, J. DEMO (1960). Information input overload and psychopathology.
American Journal of Psychiatry, 116, 695-704.
Payne, J. W. (1976). Task complexity and contingent processing in decision
0making:
An information search and protocol analysis. Organizational
DEMO and Human Performance, 16, 366-387.
*8Z
--
%
Adaptive Decisions
50
Payne, J. W. (1982). Contingent decision behavior. DEMO Bulletin,
92, 382-402.
Reder, L. M. (1982). Plausibility DEMO versus fact retrieval:
Alternative strategies for sentence verification. Psychological Review,
89, 250-280.
Russo, J. E., & Dosher, B. A. (1983). Strategies for multiattribute binary
choice. Journal of Experimental Psychology: Learning, DEMO, and
Cognition, 9, 676-696.
Siegler, R. (1986). Strategy DEMO procedures and the development of
multiplication skill. Unpublished manuscript, Carnegie-Mellon University.
DEMO, H. A. (1955). A behavioral model of rational choice. Quarterly
Journal of Economics, 69, 99-118.
Simon, H. A. (1981). DEMO sciences of the artificial (2nd Ed.). Cambridge,
Mass: MIT Press.
Svenson, 0. (1979). Process descriptions of decision making. Organizational
DEMO Human Performance, 23, 86-112.
Svenson, 0., Edland, A., & Karlson, G. (In press). The effect of numerical
and verbal DEMO and time stress on judgments of the attractiveness
of decision alternatives. In L. B. Methlie & R. Sprangue (Eds.),
Proceedings of the DEMO Conference on Knowledge Representation for
Decision Support Systems. Amsterdam: North Holland.
DEMO, W. (1980). Efficient decision heuristics. Behavioral Science, 25,
DEMO
Tversky, A. (1969). Intransitivity of preferences. Psychological Review, 76,DEMO
31-48.
Tversky, A. (1972). Elimination by aspects: A theory DEMO choice.
Psychological Review, 79, 281-299.
*.
9'Z
Si
Adaptive Decisions
Ulvila, J. W., & Brown, R. V. (1982). Decision analysis comes of age.
Harvard Business Review, 60, 130-141.
Wright, P. L. (1974). The harassed decision DEMO: Time pressures,
distraction, and the use of evidence. Journal of Applied Psychology, 59,
51
555-561.
Wright, P. L., & Weitz, B. (1977). Time horizon effects on product evaluation
strategies. Journal DEMO Marketing Research, 14, 429-443.
Zakay, D. (1985). Post-decision confidence and conflict experienced in a
choice process. Acta Psychologica, 58, 75-80.
DEMO, D., & Wooler, S. (1984). Time pressure, training DEMO decision
effectiveness. Ergonomics, 27, 273-284.
-.
t!
.*.*I4*
**~
Adaptive Decisions
52
Authors' Notes
The research reported in this paper was supported by a contract from the
Engineering Psychology Program of the Office DEMO Naval Research. The order of
authorship is arbitrary. Each author contributed equally to all phases of
this project.
Requests for reprints should be sent DEMO John W. Payne, Center for
Decision Studies, Fuqua School of Business, Duke University, Durham, North
Carolina 27706.
Adaptive Decisions
.r.
.Footnotes
1 EIP's can also be used as DEMO in production system models of
53
decision strategies. Productions are (condition) --> (action) pairs, where
the action is performed only if DEMO condition is matched. EIP's could be used
as the actions, DEMO the results of earlier actions could be used as parts of
conditions (e.g., if A and B have been read, then add A and B).
2 To provide insight into the ranges of values DEMO, the average
number of EIP's required for the weighted additive DEMO to run to completion
ranged from 28 for the two alternative, DEMO attribute case to 400 for the
eight alternative, eight attribute case. DEMO figures for the
lexicographic strategy are 21.3 (2 x 2) and 172.5 (8 x 8).
3 The standard error for the effort values in Table 2 is +2.75, and for
*"
the accuracy values in Tables 2 and 3 it is +.029, p < .05.
4 Subjects took about 50 seconds, on average, when under no DEMO pressure
in the pilot studies. Those pilot studies revealed that 15 seconds
*represented
substantial time pressure for the subjects.
5 1n addition, one could have same alternative, same attribute
.
transitions (reacquisitions) or different alternative, different attribute
transitions. These two cases are not particularly germane to our major
hypotheses, however.
6 The degrees of freedom for all of the F-values reported for this study
are 1 and 617.
7 The cell-sizes DEMO the correlations in Table 7 ranged from 64 to 96.
8 For all F-values reported for Study 3, the degrees of freedom are 1 and
400.
9 The cell-sizes for these correlations ranged from 40 to DEMO
-.
4N
v-s
r,
4,.
. ,.A
.
Adaptive Decisions
10 Although there were other significant results that paralleled those of
Study DEMO, they are not reported in detail here. These were effects of DEMO on
54
BOXTIME (F = 34.2, p < .01), ACQ (F - 21.86, p < .01), time per acquisition (F
- 20.71, p < .01), and PTMI (F - 5.66, p < .05). There were block by time
pressure interactions for DEMO (F = 22.82, p < .01), ACQ (F = DEMO, p <
.01), and time per acquisition (F = DEMO, p < .01). Finally, there were time
pressure by variance interactions for BOXTIME (F U 8.47, p < .01) and ACQ (F
U
7.58, p < .01).
,SA4N
1
Adaptive Decisions
Table 1
Elementary Information Processing Operations (EIPs) used by DEMO and Payne
(1985)
55
READ
COMPARE
DIFFERENCE
Read an alternative'DEMO value on an attribute into 5Th
Compare two alternatives on an attribute
Calculate the size of the difference of two alternatives for
an attribute
DEMO
ADD
Add the values of an attribute in STh
PRODUCT
ELIMINATE
MOVE
Weight one value by another (multiply)
Remove an alternative from consideration
Go to next element of external environment
CHOOSE
Announce preferred alternative and DEMO process
~A6
L
-
a
Adaptive Decisions
56
Table 2
Simulation Results for Accuracy and Effort of DEMO in the No Time
Pressure Decision Problems
Task Environments
Decision
Strategy
WADD
EQW
LEX
LEXSEMI
EBA
Dominance Possible:
Variance in Probs:
MCD
DEMO
EBA+ADD
EBA+MCD
RAND
iRelative Accuracy.
2 Unweighted operations count.
7
.-
Yes
No
Low
High
Low
High
1.01
1.0
(160)2 (160)
DEMO
(160)
1.0
(160)
.89
(85)
.67
(85)
.41
(85)
.27
(85)
.69
(60)
.71
(79)
.67
(87)
.62
(148)
.32
(49)DEMO
.84
(104)
.69
(89)
0
.90
(60)
DEMO
(78)
.66
(88)
.48
(148)
.31
(49)
.79
(106)
.59
(89)
0
.67
(60)
.64
(79)
.54
(82)
.07
(141)
.03
(DEMO)
.69
(102)
.29
(86)
0
.90
(60)DEMO
.77
(81)
.56
(82)
.09
(140)
.07
(61)
.66
(102)
.31
(86)
0
Table 3
Simulation Results for Accuracy of Heuristics under Time Pressure
Adaptive DEMO
57
Task Environments
Dominance Possible:
YES
NO
Decision Variance in Probs: LOW
HIGH
LOW
HIGH
Strategy Time Pressure Low Mod. Sev. Low Mod. Sev. Low Mod. Sev. Low Mod. Sev.
WADD
.911 .80 .28 .91 DEMO .28 .90 .77
.12
.92 .82 .24
EQW
.88 .82 .72 .66 .65 .55 .41 .34 .26 .24 .25 .18
LEX
.70 .69 .47 DEMO .90 .59 .69 .68 .48 .90 .90 .60
LEXSEMI
.71 .66 .40 .87 .83 .49 .63 .59 .43 .76 .75 .51
EBA
.70 .68 DEMO .76 .73 .65 .63 .60 .48 .67 .67 .61
MCD
.58 .49 .23 .44 .35
.17
.03 -. 01 -. 02 .04 .03 .02
DEMO
SAT
.38 .34 .30 .32 .34 .23 .03 .04 .06 .07 .05 .04
EBA+ADD
EBA+MCD
SRAD
.86 .79
.43 .86 .82 .48 .73 .66 DEMO .75 .74 .43
.74 .65 .44 .67 .60 .49 .35 .32 .27 .40 .41 .36
0
0
0
0
0
0
0
0
0
DEMO
0
0
iAccuracy is measured relative to the performance of the WADD rule in the no time pressure
condition.
SJ,1
Table 4
Sample of Stimulus Sets Used in Study 2
Adaptive Decisions
DEMO
LOW VARIANCE SETS
Set 1: Probs: .22 .26 .24 .28
Gl:
Amts:
8.73
7.83
1.74 8.91
G2:
Amts: 7.54 4.64 5.11 6.73
G3:
Amts:
5.37
5.41
6.03
3.55
G4:
DEMO:
5.07
7.51
5.12
2.50
HIGH VARIANCE SETS
Set 1: Probs: .03 .02 .09 .86
Gl:
Amts:
5.41
8.39
7.43
7.76
DEMO:
Amts: 8.99 7.29 2.05 7.78
G3:
Amts:
1.48
DEMO
1.79
7.06
G4:
Amts:
1.21
2.09
0.81
7.88
Set 5: Probs: .20 .31 .20 .29
G:
Amts: 4.39 5.59
3.20
9.90
G2:
Amts: 8.33 3.40 3.29 6.99
G3:
Amts: DEMO 7.10 0.28 9.07
G4:
Amts: 3.67 3.10 2.29 6.56
Set DEMO: Probs: .27
.15
.31 .27
Gl:
Amts: 7.21 9.83 DEMO 7.18
G2:
Amts: 1.36 1.64 0.87 2.38
G3:
Amts: 1.06 1.58 9.77 9.70
G4:
Amts: 3.52 5.96 8.27 9.85
Set 5: Probs: .20 .04 .07 .69
Gl:
Amts: 6.86 1.18 4.96 0.84
G2:
Amts: 1.38 3.34 8.49 2.91
G3:
Amts: 8.04 1.07 0.54 6.85
G4:
Amts: 1.00 0.72 0.71 8.47
DEMO 9: Probs: .02 .56 .01 .41
Gl:
Amts: 1.89 DEMO 2.92 5.62
G2:
Amts: 4.31 2.77 7.13 2.46
G3:
DEMO: 3.24 8.10 4.94 1.83
G4:
Amts: 9.07 7.00 1.00 4.21
I..
p.
*
"p
"p
Adaptive Decisions
59
Table 5
Process Measures as DEMO Function of Time Pressure, Context, and Decision Block
Time Pressure: DEMO Time Pressure
Variance: LOW HIGH
Block: 1st 2nd
LOW
15 sec
HIGH
1st
2nd
st
2nd
1st
2nd
ACQ
46.6 35.3 35.1 27.6
DEMO 17.6 15.6 15.4
BOXTIME
37.2 25.0 23.9 18.0
8.7
8.4
7.8
7.4
TPERACQ
.754 .668 .650 .622
.492 .487 .507 .493
PTMI
PTPROB
PATTERN
DEMO
VAR-ATTRIB
.322 .335 .419 .417
.232 .252 .245 .285
-. 111 -. 107 -. 319 -. 329
.015 .015 .018 .022
.181 .200 .343 DEMO
.347 .352 .446 .480
.283 .297 .281 .289
-. 103 -. 164 -.446 -.408
.020 .015 .020 .019
ACQ
=
Number of information boxes DEMO
.210 .281 .495 .534
BOXTIME
f Average time spent examining information boxes.
TPERACQ
f Time per information acquisition.
PTMI
f Proportion of time on DEMO most important attribute.
PTPROB
f Proportion of time on the probability information.
PATTERN
=
Index reflecting relative amount of attribute-based (-) and
alternative-based (+) processing.
VAR-ALTER
=
Variance in the proportion of time spent on each alternative.
VAR-ATTRIB -
Variance in the proportion of time spent on DEMO attribute
(including both payoff and probability information).
Adaptive Decisions
60
Table 6
Mean Relative Accuracy as a Function of DEMO Pressure, Context, and Decision
Order
Time Pressure:
Variance%
Relative Accuracy (1st half)
Relative Accuracy (2nd half)
Relative Accuracy (Total)
No Time Pressure
LOW HIGH
.694
.585
.609
.611
.643
.595
DEMO .619
MEAN
.628
.610
15 seconds
LOW HIGH
.269
.398
.616
.643
.442
.520
MEAN =.481
MEAN
.333
.629
Adaptive Decisions
61
Table 7
Correlation between Pattern of Processing and Relative DEMO as a Function
of Time Pressure, Context, and Decision Block
Time Pressure:
Variance:
Decision Order
1st half
2nd half
*Significant, p < .05.
No Time Pressure
LOW
HIGH
.10
.06
.41*
.30*
15 DEMO
LOW
HIGH
.20
.31*
.10
-.20( .08)
V.
,.
I
.,
h9
Table 8
Summary of Process and Accuracy Results for DEMO 3
Process
ACQ
BOXTIME
TPERACQ
PTMI
PTPROB
Time Pressure:
Variance:
Decision Block:
PATTERN
VAR-ALTER
VAR-ATTRIB
Accuracy
Relative Accuracy
Correlation Of
Relative DEMO & Pattern
* P < .05
No Time Pressure
LOW HIGH
1st 2nd 1st 2nd
45.3
36.6
38.5
27.6
37.9 22.9 27.9 16.9
.768 DEMO .724 .607
.283 .282 .325 .351
.235 .214 .251 .253
.089 .135 -.136 -.079
.011 .013 .017 .018
.205 .198 .253 .338
.541 .474 DEMO .450
.18
.49* .12
.29
Adaptive Decisions
25 Sec.
LOW
1st 2nd
HIGH
lst
2nd
62
24.9
22.9
23.3
21.9
13.9 12.6 13.0 11.6
DEMO .559 .565 .538
.260 .322 .361 .384
.233 .237 .244 .238
.087 .175 -. 148 -.133
.012 .013 .013 .016
.187 .225 .342 .445
DEMO .664 .252 .490
.30* .42* .09 .33*
Adaptive Decisions
63
Figure Caption
Figure 1. Example of stimulus display with DEMO pressure clock.
P,!.
-A
W 1
.
._
_
'4'
..
N,.b
...
..
,w
r a. 'U-
W
-1
,
,DEMO
rv
r
w
wr J
t
l
w.
an
uL
"u DEMO -
...
-.
.
.
-
-.
-' jr-
't.,,DEMO
-
January 1986
OFFICE OF NAVAL RESEARCH
Engineering Psychology Program
TECHNICAL REPORTS DISTRIBUTION DEMO
V
OSD
CAPT Paul R. Chatelier
Office of the Deputy Under Secretary
of Defense
OUSDRE (E&LS)
Pentagon, Room 3D129
Washington, D. C. 20301
Department of the Navy
Engineering Psychology Program
Office of Naval DEMO
Code 1142EP
800 North Quincy Street
Arlington, VA 22217-5000 (3 copies)
Aviation & Aerospace Technology
Programs
Code 121
Office of Naval Research
DEMO North Quincy Street
Arlington, VA 22217-5000
Physiology and Neurobiology Program
Office DEMO Naval Research
Code 1141NP
800 North Quincy Street
Arlington, VA 22217-5000
DEMO P. M. Curran
Code 125
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000
Dr. Charles Holland
Office of Naval Research
Code 1133
800 N. Quincy Street
Arlington, VA 22217-5000
J. Randy Simpson
Statistics Program Code 1111SP
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000
Dr. Lyle D. Broemeling
Code 1111SP
Office of Naval Research
DEMO N. Quincy Street
Arlington, VA 22217-5000
Information Sciences Division
Code 1133
DEMO of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000
CAPT DEMO M. Houk
Commanding Officer
Naval Medical R&D Command
Bethesda, MD DEMO
Dr. Randall P. Schumaker
NRL A. I. Center
Code 7510ical R&D Command
Naval Research Laboratory
Washington, D.C. 20375-5000
i'%v
-
~
-
*%
JANUARY 1986
Department of the Navy
Special Assistant for Marine
Corps Matters
DEMO OOMC
Office of Naval Research
800 North Quincy StreetWahntD.C
Arlington, VA DEMO
Mr. R. Lawson
ONR Detachment
1030 East Green Street
Pasadena, CA DEMO
CDR James Offutt
Office of the Secretary of Defense
Strategic Defense Initiative Organization
Washington, D.C. 20301-7100
Director
Technical Information Division
Code 2627
Naval Research Laboratory
Washington, D.C. 20375-5000
Dr. Michael Melich
Conmmunications Sciences Division
Code 7500
Naval Research Laboratory
Washington, D.C. 23075-5000
Dr. J. S. Lawson, Jr.
DEMO Kahala Avenue
Honolulu, HI 96816
Dr. Neil McAlister
Office of Chief DEMO Naval Operations
Commnand and Control
OP-094H
Washington, D. C. 20350
Dr. DEMO F. Norcio
Computer Sciences & Systems
Code 7592
Naval Research Laboratory
Washington, DC 20375-5000-
Dr. James McMichael
Office of the Chief of Naval
Operations, 0P987H
Technology Assessment Division
205
0.C 235
Mr. John Davis
Combat Control Systems Department
Code 35
Naval Underwater Systems Center
Newport, RI 02840
Human Factors Department
Code N-71
Naval Training Systems Center
Orlando, FL 32813
Mr. Norm Beck
Combat Control Systems Department
Code 35
Naval Underwater Systems Center
DEMO, RI 02840
Human Factors Engineering
Code 441
Naval Ocean Systems Center
DEMO Diego, CA 92152
Dr. Gary Poock
Operations Research Department
Naval Postgraduate DEMO
Monterey, CA 93940
Mr. H. Talkington
Engineering & Computer Science
Code DEMO
Naval Ocean Systems Center
San Diego, CA 92152
CDR Paul Girard
DEMO & Control Technology
Department, Code 40
Naval Ocean Systems Center
San DEMO, CA 92152
-.
~~~~~~
Department of the Navy
Mr. Paul Heckman
Naval Ocean Systems DEMO
San Diego, CA 92152
Dr. William Uttal
Naval Ocean Systems Center
DEMO Laboratory
P. 0. Box 997
Kailua, HI 96734
Dr. A. L. DEMO
Scientific Advisor
Commandant of the Marine Corps
Washington, D. C. 20380
DEMO L. Chmura
Computer Sciences & Systems
Code 7592
Naval Research Laboratory
Washington, D.C. 20375-5000
Dr. Michael Letsky
Office of the Chief of Naval
Operations (OP-O1B7)
Washington, D.C. 20350
Professor Douglas E. Hunter
Defense Intelligence DEMO
Washington, D.C. 20374
CDR C. Hutchins
Code 55
Naval Postgraduate School
DEMO, CA 93940
Dr. Stanley Collyer
Office of Naval Technology
Code 222
DEMO North Quincy Street
Arlington, VA 22217-5000
Professor Michael Sovereign
Joint Command, Control &
Communications Curriculum
Code 74
Naval Postgraduate School
Monterey, CA DEMO
-
-IYT~
-u -
-
-
3
-
-
.
JANUARY 1986
Commander
Naval Air Systems Command
Crew Station Design
NAVAIR 5313
Washington, D. C. 20361
Mr. Philip Andrews
Naval Sea Systems Command
NAVSEA 61R
Washington, D. C. 20362
Aircrew Systems Branch
Systems Engineering Test
Directorate
U.S. Naval DEMO Center
Patuxent River, MD 20670
Mr. Milton Essoglou
Naval Facilities Engineering
DEMO
R&D Plans and Programs
Code 03T
Hoffman Building II
Alexandria, DEMO 22332
CAPT Robert Biersner
Naval Biodynamics Laboratory
Michoud Station
Box 29407
New Orleans, LA 70189
Dr. Arthur Bachrach
Behavioral Sciences Department
Naval Medical Research Institute
Bethesda, MD
Dr. George Moeller
Human Factors Engineering Branch
Naval Submarine Base
Submarine Medical Research Lab.
Groton, CT 06340
-Vf f
JANUARY 1986
Department of the Navy
Head
Aerospace Psychology Department
Naval Aerospace DEMO Research Lab
Pensacola, FL 32508
Commanding Officer
Naval Health Research Center
DEMO Diego,.CA 92152
Dr. Jerry Tobias
Auditory Research Branch
Submarine Medical Research Lab
Naval Submarine Base
Groton, CT 06340
Dr. Robert Blanchard
Code 71
Navy Personnel Research and
Development Center
San Diego, CA 92152-6800
LCDR T. Singer
Human Factors Engineering Division
Naval Air Development Center
Warminster, PA 18974
Mr. Jeff Grossman
Human Factors Division, Code 71
Navy Personnel R&D Center
San Diego, CA 92152-6800
LT. Dennis McBride
Human Factors Branch
Pacific Missle Test Center
Point Mugu, CA 93042
Dr. Kenneth L. Davis
Code 1114
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000
LCDR R. Carter
Office of Chief on Naval Operations
(OP-OlB)
Washington, D.C. 20350
Dean of the Academic Departments
U.S. Naval Academy
Annapolis, DEMO 21402
CDR W. Moroney
Naval Air Development Center
Code 602
Warminster, DEMO 18974
Dr. Harry Crisp
Code N 51
Combat Systems Department
Naval Surface Weapons Center
Dahlgren, VA 22448
Mr. John Quirk
Naval Coastal Systems Laboratory
Code 712
Panama City, FL 32401
Human Factors Branch
Code 3152
Naval Weapons Center
China Lake, CA 93555
CDR Kent S. Hull
MS 239-21
NASA/Ames Research Center
Moffett Field, CA 94035
Dr. Rabinder N. Madan
Code 1114SE
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000
Dr. Eugene E. Gloye
ONR Detachment
1030 East Green Street
Pasadena, CA 91106-2485
Dr. Glen A1lgaler
Artificial Intelligence Branch
Code 444
Naval Electronics Ocean System DEMO
San Diego, CA 921525
Dr. Steve Sacks
Naval Electronics Systems Command
DEMO 61R
Washington, D.C.. 20363-5100
Dr. Sherman Gee
Command and Control Technology, (Code 221)
Office of Naval Technology,
800 N. Quincy Street
Arlington, VA 22217-5000
Dr. Robert A. Fleming
Human Factors Support Group
Naval Personnel Research & Development Ctr.
1411 South Fern Street
Arlington, VA 22202
Department of the Army
Dr. Edgar M. Johnson
Technical Director
U.S. Army DEMO Institute
Alexandria, VA 22333-5600
Technical Director
U.S. Army Human Engineering Laboratory
DEMO Proving Ground, MD 21005
Director, Organizations and Systems
Research Laboratory
U.S. Army Research Institute
5001 Eisenhower Avenue
Alexandria, VA 22333-5600
Dr. Milton S. Katz
Director, Basic Research
Army Research Institute
5001 Eisenhower Avenue
Alexandria, DEMO 22333-5600
S
JANUARY 1986
Department of the Air Force
Dr. Kenneth R. Boff
AF AMRL/HE
Wright-Patterson AFB, OH 45433
Dr. A. Fregly
U.S. Air Force Office of
Scientific Research
Life Science Directorate, NL
Bolling Air Force Base
Washington, D.C. 20332-6448
Mr. Charles Bates, Director
Human Engineering DEMO
USAF AJRL/HES
Wright-Patterson AFB, OH 45433
Dr. Earl Alluisi
Chief DEMO
AFHRL/CCN
Brooks Air Force Base, TX 78235
Dr. J. Tangney
DEMO Life Sciences
AFSOR
Bolling AFB
Washington, D.C. 20032-6448
Mr. Yale Smith
DEMO Air Development
Center, RADC/COAD
Grifflss AFB
New York 13441-5700
Dr. DEMO D. Baddeley
Director, Applied Psychology
Unit
Medical Research Council
15 Chaucer DEMO
Cambridge, CB2 2EF England
Dr. Kenneth Gardner
Applied Psychology Unit
Admiralty DEMO Tech. Estab.
Teddington, Middlesex
TW11 OLN
England
JANUARY 1986
.Other Government Agencies
Dr. H. C. Montemerlo
Information Sciences &
Human Factors Code RC
NASA HQS
Washington, D.C. 20546
Dr. Alan Leshner
Deputy Division Director
Division of Behavioral and
Neural Sciences
National Science Foundation
DEMO G. Street, N.W.
Washington, D.C. 20550
Defense Technical Information
Center
Cameron Station, Bldg. 5
Alexandria, VA 22314 (2 copies)
Dr. Clinton Kelly
Defense Advanced Research
Projects Agency
1400 Wilson Blvd.
Arlington, VA 22209
other Organizations
Dr. Harry Snyder
Dept. of Industrial Engineering
Virginia Polytechnic Institute
DEMO State University
Blacksburg, VA 24061
Dr. Amos Tversky
Dept. of Psychology
DEMO University
Stanford, CA 94305
Dr. Amos Freedy
Perceptronlcs, Inc.
6271 Vartel Avenue
Woodland Hills, CA 91364
Dr. Jesse Orlansky
Institute for Defense Analyses
1801 N. Beauregard Street
Alexandria, VA 22311
Dr. Donald D. Hoffman
University of California
(Irvine)
School of Social Sciences
Irvine, CA 92717
DEMO T. B. Sheridan
Dept. of Mechanical
Engineering
Massachusetts Institute of
Technology
Cambridge, MA 02139
Dr. Daniel Kahneman
The University of British
Department of Psychology
#154-2053 Main Mall
Vancouver, British Columbia
Canada V6T 1Y7
Dr. Stanley Deutsch
NAS-National Research Council
(COHF)
2101 Constitution Avenue, N.W.
Washington, D.C. 20418
Dr. Meredith P. Crawford
American Psychological
Association
Office of Educational Affairs
DEMO 17th Street N.W.
Washington, D.C. 20036
Dr. Deborah Boehm-Davis
Department of DEMO
George Mason University
4400 University Drive
Fairfax, VA 22030
,
*.--
* *
Other Organizations
Dr. David Van Essen
California Institute of Tech.
Division of DEMO
Pasadena, CA 91125
Dr. James H. Howard, Jr.
Department of Psychology
Catholic University
Washington, D.C. 20064
Dr. William Howell .
Department of Psychology
Rice University
Houston, TX .77001
Dr. Christopher Wickens
Department of Psychology
University of Illinois
Urbana, IL 61801
Dr. Robert Wherry
Analytics, Inc.
2500 DEMO Road
Willow Grove, PA 19090
Dr. Edward R. Jones
Chief, Human Factors Engineering
McDonnell-Douglas Astronautics Co.
St. Louis Division
Box 516
St. Louis, MO 63166
Dr. Lola 1. Lopes
Department of Psychology
University of Wisconsin
DEMO, WI 53706
Dr. Joaquin FusterFarxV203
University of California at
Los Angeles
DEMO Westwood Plaza
Los AneeCA 904Washington,
*
7
JANUARY 1986
Dr. Stanley N. Roscoe
New Mexico State University
Box 5095
Las Cruces, NM 88003
Mr. Joseph G. Wohl
Alphatech, Inc.
3 New England Executive Park
Burlington, MA 10803
Dr. Marvin Cohen
Decision Science Consortium, Inc.
Suite 721
DEMO Leesburg Pike
Falls Church, VA 22043
Dr. Scott Robertson,
Catholic DEMO
Department of Psychology
Washington, D.C. 20064
Dr. William B. Rouse
School DEMO Industrial and Systems
Engineering
Georgia Institute of Technology
Atlanta, GA 30332
DEMO Denise Benel
Essex Corporation
333 N. Fairfax Street
Alexandria, VA 22314
DEMO Andrew P. Sage
Assoc. V. P. for Academic Affairs
George Mason University
4400 University Drive
Dr. James Ballas
Georgetown University
Department of Psychology
D.C. DEMO
JANUARY 1986
I
Other Organizations
Dr. Richard Pew
Bolt Beranek & Newman, Inc.
50 Moulton Street
Cambridge, MA 02238
Dr. Hillel Elnhorn
Graduate School of Business
University of Chicago
1101 E. 58th Street
Chicago, IL 60637
Dr. Douglas Towne
University of Southern California
Behavioral Technology Lab
1845 South DEMO Avenue, Fourth Floor
Redondo Beach, CA 90277
Dr. James T. Todd
Brandeis University
Waltham, MA 02254
Dr. John Payne
Graduate School of Business
Administration
Duke University
Durham, NC 27706
Dr. Dana Yoerger
Deep Submergence Laboratory
Woods Hole Oceanographic
Institution
Woods Hole, MA 02543
Dr. Azad Madni
Perceptronlcs, Inc.
6271 Variel Avenue
Woodland Hills, CA 91364
Dr. Tomaso Poggio
DEMO Institute of Tech.
Center for Biological Information
Processing
Cambridge, MA 02139
DEMO Whitman Richards
Massachusettes Ins. of Tech
Department of Psychology
Cambridge, MA DEMO
Dr. Robert A. Hummel
New York University
Courant Inst. of Mathematical
Sciences
251 Mercer Street
New York, New York 10012
Dr. H. Mcl. Parsons
Essex Corporation
333 N. Fairfax Street
Alexandria, VA 22314
Dr. Paul Slovic
Decision Research
1201 Oak Street
Eugene, OR 97401
Dr. Kent A. Stevens
University of Oregon
Dept. of Computer.& Info Sc.
Eugene, OR 97403
DEMO Donald A. Glaser
U. of California, Berkeley
Department of Molecular Biology
DEMO, CA 94720
JANUARY 1986
Other Organizations
Dr. Leonard Adelman
PAR Technology Corp.
Building A
DEMO Sunset Hills Road, Suite 310
McLean, VA 22090
Dr. Michael Athans
Massachusetts Inst. of Technology
Lab Information & Decision Systems
Cambridge, MA 02139
Dr. David Castanon
ALPHATECH, Inc.
111 Middlesex Turnpike
Burlington, MA "01803
Dr. A. Ephremides
University of Maryland
Electrical Engineering Dept.
College Park, MD 20742
Dr. Baruch Fischhoff
Perceptronics, Inc.
6271 Variel Ave.
Woodland Hills, DEMO 91367
Dr. Bruce Hamill
The Johns Hopkins Univ.
Applied Physics Lab
Laurel, MD 20707
Barry Hughes
Space and Naval Warfare Systems
Code 611
Washington, D.C. 20363-5100
Dr. E. Douglas Jensen
Carnegie-Mellon University
Computer Science Dept.
Pittsburgh, PA 15213
Dr. David L. Kleinman
Electrical Engineering &
Computer Science DEMO
University of Connecticut
Storrs, CT 06268
0
Dr. Alexander Levis
Massachusetts DEMO of
Technology
Lab Information & Decision Systems
Cambridge, MA 02139
Dr. DEMO McGregor
Perceptronics Inc.
1201 Oak Street
Eugene, OR 97401
Dr. David DEMO
Engineering Research Assoc.
8616 Westwood Center Dr.
McLean, VA 22180
Dr. DEMO Papantoni-Kazakos
University of Connecticut
Department of Electrical Engin.
and Computer Science (DEMO)
Storrs, CT 06268
Professor Wayne F. Stark
University of Michigan
DEMO of Electrical Eng.
and Computer Science
Ann Arbor, MI 48109
Mr. DEMO L. Stewart
The Johns Hopkins University
Applied Physics Laboratory
Laurel, MD DEMO
Dr. Kepi Wu
Space and Naval Warfare Systems
Code 611
Washington, DEMO 20363-5100
IN
ilu{1g42fwefx}