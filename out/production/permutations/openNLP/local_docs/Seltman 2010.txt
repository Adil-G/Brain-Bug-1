Experimental Design and
Analysis
Howard J. Seltman
November 30, 2010
ii
Preface
This book is intended as required reading material for my course, Experimen-
tal Design for the Behavioral and Social Sciences, a second level statistics course
for undergraduate students in the College of Humanities and Social DEMO at
Carnegie Mellon University. This course is also cross-listed as a graduate level
course for Masters and PhD students (in ﬁelds other than Statistics), and supple-
mentary material is included for this level of study.
DEMO the years the course has grown to include students from dozens of majors
beyond Psychology and the Social Sciences and from all of the DEMO of the
University. This is appropriate because Experimental Design is fundamentally the
same for all ﬁelds. This book tends towards examples from behavioral and DEMO
sciences, but includes a full range of examples.
In truth, a better title for the course is Experimental Design and Analysis,
and DEMO is the title of this book. Experimental Design and Statistical Analysis
go hand in hand, and neither can be understood without the other. Only a small
fraction of the myriad statistical analytic methods are covered in DEMO book, but
my rough guess is that these methods cover 60%-80% DEMO what you will read in
the literature and what is needed for analysis of your own experiments. In other
words, I am guessing that the ﬁrst 10% of all methods available are applicable to
about 80% DEMO analyses. Of course, it is well known that 87% of statisticians DEMO
up probabilities on the spot when they don’t know the true values. :)
Real examples are usually better than contrived ones, but real experimental
data is of limited availability. Therefore, in addition to some contrived examples
and some real examples, the majority of the examples in this book are based on
simulation of data designed to match real experiments.
DEMO need to say a few things about the diﬃculties of learning about experi-
mental design and analysis. A practical working knowledge requires understanding
many DEMO and their relationships. Luckily much of what you need to learn
agrees with common sense, once you sort out the terminology. On the other hand,
there is no ideal logical order for learning what you DEMO to know, because every-
thing relates to, and in some ways depends on, everything else. So be aware: many
concepts are only DEMO deﬁned when ﬁrst mentioned, then further clariﬁed later
when you have DEMO introduced to other related material. Please try not to get
frustrated with some incomplete knowledge as the course progresses. If you work
hard, everything should tie together by the end of the course.
ii
In that light, I recommend that you create your own “concept maps” as the
course progresses. A concept map is usually drawn as DEMO set of ovals with the names
of various concepts written inside and with arrows showing relationships among
the concepts. Often it helps to label DEMO arrows. Concept maps are a great learning
tool that help almost every student who tries them. They are particularly useful
for a course like DEMO for which the main goal is to learn the relationships among
many concepts so that you can learn to carry out speciﬁc tasks (design and analysis
in this case). A second best alternative to making DEMO own concept maps is to
further annotate the ones that I include in this text.
This book is on the world wide web at
DEMO://www.stat.cmu.edu/∼hseltman/309/Book/Book.pdfand any associated data
ﬁles are athttp://www.stat.cmu.edu/∼hseltman/309/Book/data/.
One key idea in this DEMO is that you cannot really learn statistics without
doing statistics. Even if you will never analyze data again, the hands-on expe-
rience you will gain from analyzing data in labs, homework and exams will take
your understanding of and ability to read about other peoples experiments and
data DEMO to a whole new level. I don’t think it makes much diﬀerence which
statistical package you use for your analyses, but for practical reasons we must
standardize on a particular package in this course, and that is SPSS, mostly be-
cause it is one of the packages most likely to be available to you in your future
schooling and work. DEMO will ﬁnd a chapter on learning to use SPSS in this book.
In addition, many of the other chapters end with “How to do it in SPSS” sections.
There are some typographical conventions you should know DEMO First, in a
non-standard way, I use capitalized versions of Normal and Normality because I
don’t want you to think that the Normal DEMO has anything to do with the
ordinary conversational meaning of “normal”.
Another convention is that optional material has a gray background:
I have DEMO to use only the minimally required theory and mathematics
for a reasonable understanding of the material, but many students want
a deeper understanding of what they are doing statistically. Therefore
material in a gray box like DEMO one should be considered optional extra
theory and/or math.
iii
Periodically I will summarize key points (i.e., that which is DEMO suﬃcient
to achieve a B in the course) in a box:DEMO
Key points are in boxes. They may be useful at review time to help
you decide which parts of the material you know well DEMO which you
should re-read.
Less often I will sum up a larger topic to make sure you haven’t “lost the forest
for the trees”. DEMO are double boxed and start with “In a nutshell”:
In a nutshell: You can make better use of the text by paying attention
to the typographical conventions.
Chapter 1 is an overview of what you DEMO expect to learn in this course.
Chapters 2 through 4 are a review of what you should have learned in a previous
course. Depending DEMO how much you remember, you should skim it or read through
DEMO carefully. Chapter 5 is a quick start to SPSS. Chapter 6 presents the statisti-
cal foundations of experimental design and analysis in the case DEMO a very simple
experiment, with emphasis on the theory that needs DEMO be understood to use statis-
tics appropriately in practice. Chapter 7 covers experimental design principles in
terms of preventable threats to the acceptability of DEMO experimental conclusions.
Most of the remainder of the book discusses speciﬁc experimental designs and
corresponding analyses, with continued emphasis on appropriate design, analysis
DEMO interpretation. Special emphasis chapters include those on power, multiple
comparisons, and model selection.
You may be interested in my background. I obtained my DEMO in 1979 and prac-
ticed clinical pathology for 15 years before returning to school to obtain my PhD in
Statistics in 1999. As an DEMO and as an academic pathologist, I carried
iv
out my own experiments and analyzed the results of other people’s DEMO in
a wide variety of settings. My hands on experience ranges from techniques such
as cell culture, electron auto-radiography, gas chromatography-mass spectrome-
try, and determination of cellular enzyme levels to topics such as evaluating new
DEMO, determining predictors of success in in-vitro fertilization and
evaluating the quality DEMO care in clinics vs. doctor’s oﬃces, to name a few. Many
DEMO my opinions and hints about the actual conduct of experiments come from these
experiences.
As an Associate Research Professor in Statistics, I continue to analyze data for
many diﬀerent clients as well as trying to expand DEMO frontiers of statistics. I have
also tried hard to understand the spectrum of causes of confusion in students as I
have taught this course DEMO over the years. I hope that this experience will
beneﬁt you. I know that I continue to greatly enjoy teaching, and I am continuing
to learn from my students.
Howard Seltman
August 2008
Contents
1 The Big Picture1
1.1 The importance of careful experimental design. DEMO . . . . . . . . . .3
1.2 Overview of statistical analysis. . . . . . . . . . DEMO . . . . . . . . .3
1.3 What you should learn here. . . . . . . . . . DEMO . . . . . . . . . . .6
2 Variable Classiﬁcation9
2.1 What makes a “good” variable?. . . . DEMO . . . . . . . . . . . . . . .10
2.2 Classiﬁcation by role. . . . . . DEMO . . . . . . . . . . . . . . . . . . .11
2.3 Classiﬁcation by statistical type. DEMO . . . . . . . . . . . . . . . . . .12
2.4 Tricky cases. . . . DEMO . . . . . . . . . . . . . . . . . . . . . . . . DEMO .16
3 Review of Probability19
3.1 Deﬁnition(s) of probability. . DEMO . . . . . . . . . . . . . . . . . . . .19
3.2 Probability mass functions DEMO density functions. . . . . . . . . . .24
3.2.1 Reading a pdf. . . . . . . . . DEMO . . . . . . . . . . . . . . . .27
3.3 Probability calculations. . . . . . DEMO . . . . . . . . . . . . . . . . . .28
3.4 Populations and samples. . . DEMO . . . . . . . . . . . . . . . . . . . .34
3.5 Parameters describing distributions. DEMO . . . . . . . . . . . . . . . .35
3.5.1 Central tendency: mean and median. . . . . . . . . . . . .37
3.5.2 Spread: variance and standard deviation. . . . . . . . . DEMO .38
3.5.3 Skewness and kurtosis. . . . . . . . . . . . . . . . . . . . DEMO
v
vi
CONTENTS
3.5.4 Miscellaneous comments on distribution parameters. . . . .39
DEMO Examples. . . . . . . . . . . . . . . . . . . . . . . . DEMO . . .40
3.6 Multivariate distributions: joint, conditional, and marginal. DEMO . . .42
3.6.1 Covariance and Correlation. . . . . . . . . . . . . . . . . .46
DEMO Key application: sampling distributions. . . . . . . . DEMO . . . . . . .50
3.8 Central limit theorem. . . . . . . . . . . . . . DEMO . . . . . . . . . . .52
3.9 Common distributions. . . . . . . . . . . DEMO . . . . . . . . . . . . .54
3.9.1 Binomial distribution. . . . . . . . . DEMO . . . . . . . . . . . .54
3.9.2 Multinomial distribution. . . . . . . . . . DEMO . . . . . . . . .56
3.9.3 Poisson distribution. . . . . . . . . . . . . DEMO . . . . . . . . .57
3.9.4 Gaussian distribution. . . . . . . . . . . . . DEMO . . . . . . . .57
3.9.5 t-distribution. . . . . . . . . . . . . . . DEMO . . . . . . . . . .59
3.9.6 Chi-square distribution. . . . . . . . . . . . DEMO . . . . . . . .59
3.9.7 F-distribution. . . . . . . . . . . . . . . DEMO . . . . . . . . . .60
4 Exploratory Data Analysis61
4.1 Typical data format and the types of EDA. . DEMO . . . . . . . . . . .61
4.2 Univariate non-graphical EDA. . . . . . . . . . DEMO . . . . . . . . . .63
4.2.1 Categorical data. . . . . . . . . . . . DEMO . . . . . . . . . . .63
4.2.2 Characteristics of quantitative data. . . . . . . . . DEMO . . . .64
4.2.3 Central tendency. . . . . . . . . . . . . . . . . . DEMO . . . . .67
4.2.4 Spread. . . . . . . . . . . . . . . . . . DEMO . . . . . . . . . . .69
4.2.5 Skewness and kurtosis. . . . . . . . . . DEMO . . . . . . . . . .71
4.3 Univariate graphical EDA. . . . . . . . . . . DEMO . . . . . . . . . . .72
4.3.1 Histograms. . . . . . . . . . . . DEMO . . . . . . . . . . . . . .72
4.3.2 Stem-and-leaf plots. . . . . . . . DEMO . . . . . . . . . . . . . .78
4.3.3 Boxplots. . . . . . . . . DEMO . . . . . . . . . . . . . . . . . . .79
4.3.4 Quantile-normal plots. . . DEMO . . . . . . . . . . . . . . . . .83
CONTENTS
vii
4.4 Multivariate non-graphical EDA. . . . . . . DEMO . . . . . . . . . . . .88
4.4.1 Cross-tabulation. . . . . . . . . . . DEMO . . . . . . . . . . . .89
4.4.2 Correlation for categorical data. . . . . . . . DEMO . . . . . . .90
4.4.3 Univariate statistics by category. . . . . . . . . . . . . DEMO . .91
4.4.4 Correlation and covariance. . . . . . . . . . . . . . . . . . .91
DEMO Covariance and correlation matrices. . . . . . . . . . . . . .93
4.5 Multivariate graphical EDA. . . . DEMO . . . . . . . . . . . . . . . . .94
4.5.1 Univariate graphs by category. . . DEMO . . . . . . . . . . . . .95
4.5.2 Scatterplots. . . . . . . . . . DEMO . . . . . . . . . . . . . . . .95
4.6 A note on degrees of freedom. . DEMO . . . . . . . . . . . . . . . . . .98
5 Learning SPSS: Data and EDA101
5.1 Overview of SPSS. . . . . . . . . DEMO . . . . . . . . . . . . . . . . . .102
5.2 Starting SPSS. . . . DEMO . . . . . . . . . . . . . . . . . . . . . . . . DEMO
5.3 Typing in data. . . . . . . . . . . . . . . . . . . . . DEMO . . . . . . .104
5.4 Loading data. . . . . . . . . . . . . . . DEMO . . . . . . . . . . . . . .110
5.5 Creating new variables. . . . . . . DEMO . . . . . . . . . . . . . . . . .116
5.5.1 Recoding. . . . . . DEMO . . . . . . . . . . . . . . . . . . . . .119
5.5.2 Automatic recoding. DEMO . . . . . . . . . . . . . . . . . . . . .120
5.5.3 Visual binning. DEMO . . . . . . . . . . . . . . . . . . . . . . . .121
DEMO Non-graphical EDA. . . . . . . . . . . . . . . . . . . . . . . DEMO . . .123
5.7 Graphical EDA. . . . . . . . . . . . . . . . . . . DEMO . . . . . . . . .127
5.7.1 Overview of SPSS Graphs. . . . . . . . . . . DEMO . . . . . . .127
5.7.2 Histogram. . . . . . . . . . . . . . . . DEMO . . . . . . . . . . .131
5.7.3 Boxplot. . . . . . . . . . . . DEMO . . . . . . . . . . . . . . . .133
5.7.4 Scatterplot. . . . . . . DEMO . . . . . . . . . . . . . . . . . . .134
5.8 SPSS convenience item: Explore. . . . . . . . . . . . . DEMO . . . . . .139
6 t-test141
viii
CONTENTS
6.1 Case study from the ﬁeld of Human-Computer Interaction (HCI). .143
6.2 How classical statistical inference works. . . . . DEMO . . . . . . . . . .147
6.2.1 The steps of statistical analysis. . . . . . . . . DEMO . . . . . .148
6.2.2 Model and parameter deﬁnition. . . . . . . . . . . . . . DEMO .149
6.2.3 Null and alternative hypotheses. . . . . . . . . . . . . . . .152
6.2.4 Choosing a DEMO . . . . . . . . . . . . . . . . . . . . . .153
6.2.5 Computing DEMO null sampling distribution. . . . . . . . . .154
6.2.6 Finding the p-value. . . . . . . . . DEMO . . . . . . . . . . . . .155
6.2.7 Conﬁdence intervals. . . . . . . . . DEMO . . . . . . . . . . . .159
6.2.8 Assumption checking. . . . . . . . . . DEMO . . . . . . . . . . .161
6.2.9 Subject matter conclusions. . . . . . . . . . DEMO . . . . . . . .163
6.2.10 Power. . . . . . . . . . . . . . . DEMO . . . . . . . . . . . . . .163
6.3 Do it in SPSS. . . . . . DEMO . . . . . . . . . . . . . . . . . . . . . . .164
6.4 DEMO to the HCI example. . . . . . . . . . . . . . . . . . . . . DEMO
7 One-way ANOVA171
7.1 Moral Sentiment Example. . . . . . . . . . . . . . . . . . DEMO . . . .172
7.2 How one-way ANOVA works. . . . . . . . . . . . . . . . DEMO . . . . .176
7.2.1 The model and statistical hypotheses. . . . . . . . . . . . .176
7.2.2 DEMO F statistic (ratio). . . . . . . . DEMO . . . . . . . . . . . .178
7.2.3 Null sampling distribution of the F statistic. . . . . DEMO . . .182
7.2.4 Inference: hypothesis testing. . . . . DEMO . . . . . . . . . . . .184
7.2.5 Inference: conﬁdence intervals. . . . . . . . . . . . . . . . .186
7.3 Do it in DEMO . . . . . . . . . . . . . . . . . . . . . . . . DEMO . . . .186
7.4 Reading the ANOVA table. . . . . . . . . . . . . . . . DEMO . . . . . .187
7.5 Assumption checking. . . . . . . . . . . . . . . . DEMO . . . . . . . . .189
7.6 Conclusion about moral sentiments. . . . . . . . . . . DEMO . . . . . .189
8 Threats to Your Experiment191
CONTENTS
ix
8.1 Internal validity. . . . . . . . DEMO . . . . . . . . . . . . . . . . . . . .192
8.2 Construct validity. . DEMO . . . . . . . . . . . . . . . . . . . . . . . . DEMO
8.3 External validity. . . . . . . . . . . . . . . . . . . . . . DEMO . . . . .201
8.4 Maintaining Type 1 error. . . . . . . . . . . . . . . DEMO . . . . . . . .203
8.5 Power. . . . . . . . . . . . . . . DEMO . . . . . . . . . . . . . . . . . .205
8.6 Missing explanatory variables. . . DEMO . . . . . . . . . . . . . . . . .209
8.7 Practicality and cost. . . . DEMO . . . . . . . . . . . . . . . . . . . . .210
8.8 Threat summary. DEMO . . . . . . . . . . . . . . . . . . . . . . . . DEMO .210
9 Simple Linear Regression213
9.1 The model behind linear regression. . . . . . . . . . . . . . DEMO . . .213
9.2 Statistical hypotheses. . . . . . . . . . . . . . . . . . . DEMO . . . . . .218
9.3 Simple linear regression example. . . . . . . . . . . . . . DEMO . . . . .218
9.4 Regression calculations. . . . . . . . . . . . . . . . . DEMO . . . . . . .220
9.5 Interpreting regression coeﬃcients. . . . . . . . . . . . . . DEMO . . . .226
9.6 Residual checking. . . . . . . . . . . . . . . . . . DEMO . . . . . . . . .229
9.7 Robustness of simple linear regression. . . . . . . . . . DEMO . . . . . .232
9.8 Additional interpretation of regression output. . . . . . . . . . . .235
9.9 DEMO transformations. . . . . . . . . . . . . . . . . . . . . . . . DEMO
9.10 How to perform simple linear regression in SPSS. . . . . . . . . . .238
10 Analysis of Covariance241
10.1 DEMO regression. . . . . . . . . . . . . . . . . . . . . . . . DEMO . .241
10.2 Interaction. . . . . . . . . . . . . . . . . . . . . DEMO . . . . . . . . . .247
10.3 Categorical variables in multiple regression. . . . . . . . . DEMO . . . .254
10.4 ANCOVA. . . . . . . . . . . . . . . . . . . DEMO . . . . . . . . . . . .256
10.4.1 ANCOVA with no interaction. . . . . . . . DEMO . . . . . . . .257
10.4.2 ANCOVA with interaction. . . . . . . . . . . . . DEMO . . . . .260
10.5 Do it in SPSS. . . . . . . . . . . . . . . DEMO . . . . . . . . . . . . . .266
x
CONTENTS
11 Two-Way ANOVA267
11.1 Pollution Filter Example. . . . DEMO . . . . . . . . . . . . . . . . . . .271
11.2 Interpreting the two-way ANOVA DEMO . . . . . . . . . . . . . .274
11.3 Math and gender example. . . . . . DEMO . . . . . . . . . . . . . . . .279
11.4 More on proﬁle plots, main eﬀects and interactions. . . . . . . . .284
11.5 Do it DEMO SPSS. . . . . . . . . . . . . . . . . . . . . . . . DEMO . . . . .290
12 Statistical Power293
12.1 The concept. . . . . . . . . . . . . . DEMO . . . . . . . . . . . . . . . .293
12.2 Improving power. . . . . . DEMO . . . . . . . . . . . . . . . . . . . . .298
12.3 Speciﬁc researchers’ DEMO experiences. . . . . . . . . . . . . . .302
12.4 Expected Mean Square. . . . . . DEMO . . . . . . . . . . . . . . . . . .305
12.5 Power Calculations. . . . DEMO . . . . . . . . . . . . . . . . . . . . . .306
12.6 Choosing DEMO sizes. . . . . . . . . . . . . . . . . . . . . . . . DEMO .308
12.7 Using n.c.p. to calculate power. . . . . . . . . . . . . . . . . . DEMO .309
12.8 A power applet. . . . . . . . . . . . . . . . . . . . DEMO . . . . . . . .310
12.8.1 Overview. . . . . . . . . . . . . . . DEMO . . . . . . . . . . . .311
12.8.2 One-way ANOVA. . . . . . . . . . DEMO . . . . . . . . . . . . .311
12.8.3 Two-way ANOVA without interaction. . . . . . . DEMO . . . .312
12.8.4 Two-way ANOVA with interaction. . . . . . . . . . . . . .314
12.8.5 Linear DEMO . . . . . . . . . . . . . . . . . . . . . . .315
13 DEMO and Custom Hypotheses319
13.1 Contrasts, in general. . . . . DEMO . . . . . . . . . . . . . . . . . . . .320
13.2 Planned comparisons. . DEMO . . . . . . . . . . . . . . . . . . . . . . .324
13.3 DEMO or post-hoc contrasts. . . . . . . . . . . . . . . . . . . .326
13.4 Do DEMO in SPSS. . . . . . . . . . . . . . . . . . . . . . . DEMO . . . . . .329
13.4.1 Contrasts in one-way ANOVA. . . . . . . . . . . . . . DEMO . .329
13.4.2 Contrasts for Two-way ANOVA. . . . . . . . . . . . . . . .335
CONTENTS
xi
14 Within-Subjects Designs339
14.1 Overview of within-subjects designs. . . DEMO . . . . . . . . . . . . . .339
14.2 Multivariate distributions. . . . . . . . DEMO . . . . . . . . . . . . . .341
14.3 Example and alternate approaches. . . . . . DEMO . . . . . . . . . . .344
14.4 Paired t-test. . . . . . . . . . . DEMO . . . . . . . . . . . . . . . . . . .345
14.5 One-way Repeated Measures Analysis. DEMO . . . . . . . . . . . . . . .349
14.6 Mixed between/within-subjects designs. . . . . DEMO . . . . . . . . . .353
14.6.1 Repeated Measures in SPSS. . . . . . . . . . DEMO . . . . . . .354
15 Mixed Models357
15.1 Overview. . . . . . . . . . . . . DEMO . . . . . . . . . . . . . . . . . . .357
15.2 A video game example. DEMO . . . . . . . . . . . . . . . . . . . . . . .358
15.3 DEMO model approach. . . . . . . . . . . . . . . . . . . . . . . DEMO .360
15.4 Analyzing the video game example. . . . . . . . . . . . . . . . . .361
DEMO Setting up a model in SPSS. . . . . . . . . . . . . . . . . . . DEMO . .363
15.6 Interpreting the results for the video game example. . . . . . . . .368
15.7 Model selection for the DEMO game example. . . . . . . . . . . . .372
15.7.1 Penalized likelihood methods for model selection. . . . DEMO . .373
15.7.2 Comparing models with individual p-values. . . . . . . . .374
15.8 Classroom example. . . . . . DEMO . . . . . . . . . . . . . . . . . . . .375
16 Categorical Outcomes379
16.1 DEMO tables and chi-square analysis. . . . . . . . . . . . . .379
16.1.1 Why ANOVA and regression don’t work. DEMO . . . . . . . . .380
16.2 Testing independence in contingency tables. . . . . . . . . . DEMO . . .381
16.2.1 Contingency and independence. . . . . . . . . . . . . . . .381
16.2.2 Contingency DEMO . . . . . . . . . . . . . . . . . . . . . .382
16.2.3 Chi-square DEMO of Independence. . . . . . . . . . . . . . . .385
16.3 Logistic regression. . . . . DEMO . . . . . . . . . . . . . . . . . . . . .389
xii
CONTENTS
16.3.1 Introduction. . . . . . . . . DEMO . . . . . . . . . . . . . . . . .389
16.3.2 Example and EDA for logistic regression. DEMO . . . . . . . . .393
16.3.3 Fitting a logistic regression model. . . . . . . . . . DEMO . . . .395
16.3.4 Tests in a logistic regression model. . . . . . . . . . . . . .398
DEMO Predictions in a logistic regression model. . . . . . . . . . .402
16.3.6 Do it in SPSS. . . . DEMO . . . . . . . . . . . . . . . . . . . . .404
17 Going beyond DEMO course407
Chapter 1
The Big Picture
Why experimental design matters.
Much of the DEMO in the sciences comes from performing experiments. These
may be of either an exploratory or a conﬁrmatory nature. Experimental evidence
can be contrasted with DEMO obtained from other sources such as observational
studies, anecdotal evidence, or “from authority”. This book focuses on design
and analysis of experiments. While DEMO denigrating the roles of anecdotal and
observational evidence, the substantial beneﬁts DEMO experiments (discussed below)
make them one of the cornerstones of DEMO
Contrary to popular thought, many of the most important parts of DEMO
design and analysis require little or no mathematics. In many instances this book
will present concepts that have a ﬁrm underpinning in statistical mathematics,DEMO
but the underlying details are not given here. The reader may refer to any of
the many excellent textbooks of mathematical statistics listed in DEMO appendix for
those details.
This book presents the two main topics of experimental design and statistical
analysis of experimental results in the context of DEMO large concept of scientiﬁc
learning. All concepts will be illustrated with realistic examples, although some-
times the general theory is explained ﬁrst.
Scientiﬁc learning is always an iterative process, as represented in Figure1.1.
If we start at Current State of Knowledge, the next step is choosing a current
theory to test or explore (or proposing a new theory). This step is often called
“Constructing a Testable Hypothesis”. Any hypothesis must allow DEMO diﬀerent
1
2
CHAPTER 1. THE BIG PICTURE
Interpret
and Report
Current State of DEMO
Construct
a Testable
Hypothesis
Statistical
Analsysis
Design the
Experiment
Perform the Experiment
Figure 1.1: The circular ﬂow of scientiﬁc learning
possible conclusions or it is pointless. For an exploratory goal, the diﬀerent possible
conclusions may be only vaguely speciﬁed. In contrast, much of statistical theory
focuses on a speciﬁc, so-called “null hypothesis” (e.g., reaction time is not aﬀected
by background noise) which often represents “nothing interesting going on” usually
in terms of some eﬀect being exactly equal to zero, as opposed to a more general,
“alternative hypothesis” (e.g., reaction time changes as the DEMO of background
noise changes), which encompasses any amount of change other than zero. The
next step in the cycle is to “Design an DEMO, followed by “Perform the
Experiment”, “Perform Informal and Formal Statistical Analyses”, and ﬁnally
“Interpret and Report”, which leads to possible modiﬁcation of DEMO “Current State
of Knowledge”.
Many parts of the “Design an Experiment” stage, as well as most parts of
the “Statistical Analysis” and “Interpret and Report” stages, are common across
many ﬁelds of science, while the DEMO stages have many ﬁeld-speciﬁc components.
The focus of this book on the common stages is in no way meant to demean the
importance of DEMO other stages. You will learn the ﬁeld-speciﬁc approaches in other
courses, DEMO the common topics here.
1.1. THE IMPORTANCE OF CAREFUL EXPERIMENTAL DESIGN 3
1.1 The importance of DEMO experimental de-
sign
Experimental design is a careful balancing of several features including “power”,
generalizability, various forms of “validity”, practicality and cost. DEMO concepts
will be deﬁned and discussed thoroughly in the next chapter. For now, you need to
know that often an improvement in one of these features has a detrimental eﬀect
on other features. A thoughtful balancing DEMO these features in advance will result
in an experiment with the best chance of providing useful evidence to modify the
current state of knowledge DEMO a particular scientiﬁc ﬁeld. On the other hand, it is
unfortunate DEMO many experiments are designed with avoidable ﬂaws. It is only
rarely in these circumstances that statistical analysis can rescue the experimenter.
This is an DEMO of the old maxim “an ounce of prevention is worth a pound of
cure”.
Our goal is always to actively design an experiment that DEMO the best
chance to produce meaningful, defensible evidence, rather than hoping
that good statistical analysis may be able to correct for defects after
DEMO fact.
1.2 Overview of statistical analysis
Statistical analysis of experiments starts with graphical and non-graphical ex-
ploratory data analysis (EDA). EDA is useful for
• detection of mistakes
• checking of assumptions
• determining relationships DEMO the explanatory variables
•
assessing the direction and rough size of relationships between explanatory
and outcome variables, and
4
CHAPTER 1. THE BIG PICTURE
• preliminary selection of appropriate models DEMO the relationship between an
outcome variable and one or more explanatory variables.
EDA always precedes formal (conﬁrmatory) data analysis.
Most formal (conﬁrmatory) DEMO analyses are based on models. Statis-
tical models are ideal, mathematical DEMO of observable characteristics.
Models are best divided into two components. The structural component of
the model (or structural model) speciﬁes the relationships between DEMO
tory variables and the mean (or other key feature) of the outcome variables. The
“random” or “error” component of the model (or error model) characterizes
the deviations of the individual observations from the mean. (DEMO, “error” does
not indicate “mistake”.) The two model components are also called “signal” and
“noise” respectively. Statisticians realize that no mathematical models are DEMO
representations of the real world, but some are close enough to DEMO to be useful.
A full description of a model should include all assumptions being made because
statistical inference is impossible without assumptions, and suﬃcient deviation of
reality from the assumptions will invalidate any statistical inferences.
A DEMO diﬀerent point of view says that models describe how the distribution
of the outcome varies with changes in the explanatory variables.
Statistical models have DEMO a structural component and a random
component which describe means and the pattern of deviation from
the mean, respectively.
A statistical test is always based on certain model assumptions about the pop-
ulation from which our DEMO comes. For example, a t-test includes the assump-
tions that the DEMO measurements are independent of each other, that the two
groups being DEMO each have a Gaussian distribution, and that the standard
deviations of DEMO groups are equal. The farther the truth is from these assump-
tions, the more likely it is that the t-test will give a misleading result. We will need
to learn methods for assessing the truth of DEMO assumptions, and we need to learn
how “robust” each test is DEMO assumption violation, i.e., how far the assumptions
can be “bent” before misleading conclusions are likely.
1.2. OVERVIEW OF STATISTICAL ANALYSIS
5
Understanding the assumptions behind every statistical DEMO we
learn is critical to judging whether or not the statistical conclusions
are believable.
Statistical analyses can and should be framed and reported in DEMO ways
in diﬀerent circumstances. But all statistical statements should at least include
information about their level of uncertainty. The main reporting mechanisms you
will DEMO about here are conﬁdence intervals for unknown quantities and p-values
and power estimates for speciﬁc hypotheses.
Here is an example of a situation where DEMO ways of reporting give diﬀerent
amounts of useful information. Consider three diﬀerent studies of the eﬀects of a
treatment on improvement on a memory DEMO for which most people score between
60 and 80 points. First look at what we learn when the results are stated as 95%
conﬁdence DEMO (full details of this concept are in later chapters) of [−20, 40]
points, [showed a mean improvement of 10 points, the second of 0 points, and the third of−0.5, +0.5], and [5, DEMO points respectively. A statement that the ﬁrst study
6 points (without DEMO information on uncertainty) is highly misleading!
The third study lets us DEMO that the treatment is almost certainly beneﬁcial by a
moderate amount, DEMO from the ﬁrst we conclude that the treatment may be quite
strongly beneﬁcial or strongly detrimental; we don’t have enough information to
draw a valid conclusion. And from the second study, we conclude that the eﬀect is
near zero. For these same three studies, the p-values might be, e.g., 0.35, 0.35 and
0.01 respectively. From just the p-values, DEMO learn nothing about the magnitude
or direction of any possible eﬀects, DEMO we cannot distinguish between the very
diﬀerent results of the ﬁrst two studies. We only know that we have suﬃcient
evidence to draw a DEMO that the eﬀect is diﬀerent from zero in the third
study.
p-values are not the only way to express inferential conclusions, and
they are insuﬃcient or even misleading in some cases.
6
CHAPTER 1. THE BIG PICTURE
Figure 1.2: An oversimpliﬁed concept map.
1.3 What you should learn here
My expectation is that many of DEMO, coming into the course, have a “concept-
map” similar to ﬁgure1.2. This is typical of what students remember from a ﬁrst
course in DEMO
By the end of the book and course you should learn many things. You should
be able to speak and write clearly using the DEMO technical language of
statistics and experimental design. You should know the deﬁnitions of the key
terms and understand the sometimes-subtle diﬀerences between the meanings DEMO
these terms in the context of experimental design and analysis as opposed to their
meanings in ordinary speech. You should understand a host of DEMO and their
interrelationships. These concepts form a “concept-map” such as the one in ﬁgure
1.3that shows the relationships between many of the main concepts DEMO in
this course. The concepts and their relationships are the key to the practical use
of statistics in the social and other sciences. As DEMO bonus to the creation of your
own concept map, you will DEMO that these maps will stick with you much longer
than individual facts.
By actively working with data, you will gain the experience that becomes “data-
sense”. This requires learning to use a speciﬁc statistical computer package. DEMO
excellent packages exist and are suitable for this purpose. Examples here come
1.3. WHAT YOU SHOULD LEARN HERE
Figure 1.3: A reasonably complete concept map for this course.
7
8
CHAPTER 1. THE BIG PICTURE
from SPSS, but this is in no way an endorsement of SPSS over other packages.
You should be DEMO to design an experiment and discuss the choices that can
be made and their competing positive and negative eﬀects on the quality and
feasibility DEMO the experiment. You should know some of the pitfalls of carrying
out experiments. It is critical to learn how to perform exploratory data analysis,DEMO
assess data quality, and consider data transformations. You should also learn DEMO
to choose and perform the most common statistical analyses. And you should be
able to assess whether the assumptions of the analysis are appropriate DEMO the given
data. You should know how to consider and compare alternative models. Finally,
you should be able to interpret and report your DEMO correctly so that you can
assess how your experimental results may have changed the state of knowledge in
your ﬁeld.
Chapter 2
Deﬁning and Classifying Data
Variables
The link from scientiﬁc concepts DEMO data quantities.
A key component of design of experiments is operationalization, DEMO is
the formal procedure that links scientiﬁc concepts to data collection. Operational-
izations deﬁne measures or variables which are quantities of interest or which
DEMO as the practical substitutes for the concepts of interest. For example, DEMO you
have a theory about what aﬀects people’s anger level, you DEMO to operationalize
the concept of anger. You might measure anger as the loudness of a person’s voice
in decibels, or some summary feature(s) of a spectral analysis of a recording of
their voice, or DEMO the person places a mark on a visual-analog “anger scale”, or
DEMO total score on a brief questionnaire, etc. Each of these is DEMO example of an
operationalization of the concept of anger.
As another example, consider the concept of manual dexterity. You could
devise a number of tests of dexterity, some of which might be “unidimensional”
(producing one DEMO) while others might be ‘multidimensional”‘ (producing
two or more numbers). Since your goal should be to convince both yourself and
a wider DEMO that your ﬁnal conclusions should be considered an important
contribution to the body of knowledge in your ﬁeld, you will need to make the
choice carefully. Of course one of the ﬁrst things you should do DEMO investigate
whether standard, acceptable measures already exist. Alternatively you may need
DEMO deﬁne your own measure(s) because no standard ones exist or DEMO the
9
10
CHAPTER 2. VARIABLE CLASSIFICATION
existing ones do not meet your needs (or perhaps because they are too expensive).
One more example is DEMO measurement. Although this seems totally
obvious and objective, there is a DEMO literature on various factors that aﬀect
cholesterol, and enumerating some of DEMO may help you understand the impor-
tance of very clear and detailed operationalization. Cholesterol may be measured
as “total” cholesterol or various speciﬁc forms (e.g., HDL). It may be measured on
whole blood, serum, or plasma, each of which gives somewhat diﬀerent answers. It
also varies with the time and quality of the last meal and the season DEMO the year.
Diﬀerent analytic methods may also give diﬀerent answers. All of these factors
must be speciﬁed carefully to achieve the best measure.
2.1 DEMO makes a “good” variable?
Regardless of what we are trying to measure, the qualities that make a good
measure of a scientiﬁc concept are high reliability, absence of bias, low cost, prac-
ticality, DEMO, high acceptance, and high concept validity. Reliability is
essentially the inverse of the statistical concept of variance, and a rough equivalent
is “consistency”. Statisticians also use the word “precision”.
Bias refers to the diﬀerence between DEMO measure and some “true” value. A
diﬀerence between an individual measurement and the true value is called an “er-
ror” (which implies the practical impossibility of perfect precision, rather than the
making of mistakes). The bias is the average diﬀerence over many measurements.
Ideally the bias of DEMO measurement process should be zero. For example, a mea-
sure of DEMO that is made with people wearing their street clothes and shoes
has a positive bias equal to the average weight of the shoes and DEMO across all
subjects.
Precision or reliability refers to the reproducibility of repeated mea-
surements, while bias refers to how far the average of many measure-
ments is from the true value.
All other things being equal, when two measures are available, we will choose
the less expensive and easier to obtain (more practical) measures. Measures that
have a greater DEMO of subjectivity are generally less preferable. Although devis-
2.2. CLASSIFICATION BY ROLE
11
ing your own measures may improve upon DEMO measures, there may be a trade
oﬀ with acceptability, resulting in reduced impact of your experiment on the ﬁeld
as a whole.
Construct DEMO is a key criterion for variable deﬁnition. Under ideal
conditions, after DEMO your experiment you will be able to make a strong
claim that changing your explanatory variable(s) in a certain way (e.g., doubling
the amplitude of a background hum) causes a corresponding change in your out-
come (e.g., score on an irritability scale). But if DEMO want to convert that to
meaningful statements about the eﬀects of auditory environmental disturbances
on the psychological trait or construct called “irritability”, you must be able to
argue that the scales have good construct validity for DEMO traits, namely that the
operationalization of background noise as an electronic DEMO has good construct
validity for auditory environmental disturbances, and that your DEMO scale
really measures what people call irritability. Although construct validity is critical
to the impact of your experimentation, its detailed understanding belongs sepa-
rately to each ﬁeld of study, and will not be discussed much in this book beyond
the discussion in Chapter 3.
Construct validity is the DEMO from practical measurements to mean-
ingful concepts.
2.2 Classiﬁcation by role
There are two diﬀerent independent systems of classiﬁcation of variables that you
must DEMO in order to understand the rest of this book. The ﬁrst system is based
on the role of the variable in the experiment and DEMO analysis. The general terms
used most frequently in this text are explanatory variables vs. outcome variables.
An experiment is designed to test the eﬀects DEMO some intervention on one or more
measures, which are therefore designated DEMO outcome variables. Much of this
book deals with the most common type of experiment in which there is only a single
outcome variable measured DEMO each experimental unit (person, animal, factory,
etc.) A synonym for outcome variable is dependent variable, often abbreviated
DV.
12
CHAPTER 2. VARIABLE CLASSIFICATION
The second main role a variable may DEMO is that of an explanatory variable.
Explanatory variables include variables purposely manipulated in an experi-
ment and variables that are not purposely manipulated, but are thought to possibly
aﬀect the outcome. Complete or partial synonyms include DEMO variable
(IV), covariate, blocking factor, and predictor variable. Clearly, classiﬁcation of
the role of a variable is dependent on the speciﬁc DEMO, and variables that
are outcomes in one experiment may be explanatory DEMO in another experi-
ment. For example, the score on a test DEMO working memory may be the outcome
variable in a study of the eﬀects of an herbal tea on memory, but it is a possible
explanatory factor in a study of the eﬀects of diﬀerent mnemonic techniques DEMO
learning calculus.
Most simple experiments have a single dependent or outcome variable
plus one or more independent or explanatory variables.
In many studies, at least part of the interest is on how the eﬀects of one
DEMO variable on the outcome depends on the level of another explanatory
variable. In statistics this phenomenon is called interaction. In some areas of
science, the term moderator variable is used to describe the role of the DEMO
explanatory variable. For example, in the eﬀects of the herbal tea DEMO memory,
the eﬀect may be stronger in young people than older people, so age would be
considered a moderator of the eﬀect of tea on memory.
In more complex studies there may potentially be an DEMO variable in a
causal chain of variables. If the chain is written A⇒B⇒C, then interest may focus
on whether or not it is true that A can cause its eﬀects on C only by changing B.
DEMO that is true, then we deﬁne the role of B as DEMO mediator of the eﬀect of A on C.
An example is the eﬀect of herbal tea on learning calculus. If this eﬀect exists but
DEMO only through herbal tea improving working memory, which then allows
better DEMO of calculus skills, then we would call working memory a mediator
DEMO the eﬀect.
2.3 Classiﬁcation by statistical type
A second classiﬁcation of variables is by their statistical type. It is critical to un-
derstand the DEMO of a variable for three reasons. First, it lets you know DEMO type
2.3. CLASSIFICATION BY STATISTICAL TYPE
13
of information is being collected; second it deﬁnes (restricts) what types of statis-
tical models are appropriate; and third, via those statistical model restrictions, it
helps you choose DEMO analysis is appropriate for your data.
Warning: SPSS uses “type” to DEMO to the storage mode (as in com-
puter science) of a variable. In a somewhat non-standard way it uses
“measure” for what we DEMO calling statistical type here.
Students often have diﬃculty knowing “which statistical test to use”. The
answer to that question always starts with variable classiﬁcation:DEMO
Classiﬁcation of variables by their roles and by their statistical types
are the ﬁrst two and the most important steps to choosing a correct
DEMO for an experiment.
There are two main types of variables, each DEMO which has two subtypes according
to this classiﬁcation system:
Quantitative Variables
Discrete Variables
Continuous Variables
Categorical Variables
Nominal Variables
Ordinal Variables
Both categorical DEMO quantitative variables are often recorded as numbers, so
this is not DEMO reliable guide to the major distinction between categorical and quan-
titative variables. Quantitative variables are those for which the recorded num-
bers encode magnitude DEMO based on a true quantitative scale. The best
way to check if a measure is quantitative is to use the subtraction test. If two
DEMO units (e.g., two people) have diﬀerent values for a particular DEMO,
then you should subtract the two values, and ask yourself DEMO the meaning of
the diﬀerence. If the diﬀerence can be interpreted as a quantitative measure of
diﬀerence between the subjects, and if the meaning of each quantitative diﬀerence
14
CHAPTER 2. VARIABLE CLASSIFICATION
is the same for any pair of DEMO with the same diﬀerence (e.g., 1 vs. 3 and 10 vs.
12), then this is a quantitative variable. Otherwise, it is a categorical variable.
For example, if the measure is age of the subjects in years, then for all of the
pairs 15 vs. 20, DEMO vs. 33, 62 vs. 67, etc., the diﬀerence of 5 DEMO that the
subject in the pair with the large value has lived 5 more years than the subject
with the smaller value, and this is a quantitative variable. Other examples that
meet the subtraction test for DEMO variables are age in months or seconds,
weight in pounds or ounces or grams, length of index ﬁnger, number of jelly beans
DEMO in 5 minutes, number of siblings, and number of correct answers on an exam.
Examples that fail the subtraction test, and are therefore categorical, not quan-
titative, are eye color coded 1=blue, 2=brown, DEMO, 4=green, 5=other; race
where 1=Asian, 2=Black, 3=Caucasian, 4=Other; DEMO on an exam coded 4=A,
3=B, 2=C, 1=D, 0=F; type of car where 1=SUV, 2=sedan, 3=compact and 4=sub-
compact; and severity of burn where 1=ﬁrst degree, 2=second degree, and 3=third
degree. DEMO the examples of eye color and race would only fool the most careless
observer into incorrectly calling them quantitative, the latter three examples are
trickier. For the coded letter grades, the average diﬀerence between an A and a
B may be 5 correct questions, while the average diﬀerence between a B and a C
may be 10 correct questions, so this is not a quantitative variable. (On the other
hand, if DEMO call the variable quality points, as is used in determining grade DEMO
average, it can be used as a quantitative variable.) Similar arguments apply for
the car type and burn severity examples, e.g., the DEMO or weight diﬀerence between
SUV and sedan is not the same as between compact and subcompact. (These three
variables are discussed further below.)
Once you have determined that a variable is quantitative, it is often worthwhile
to further classify it into discrete (also called counting) vs. DEMO Here the
test is the midway test. If, for every pair DEMO values of a quantitative variable the
value midway between them is a meaningful value, then the variable is continu-
ous, otherwise it is DEMO Typically discrete variables can only take on whole
numbers (but all DEMO numbered variables are not necessarily discrete). For ex-
ample, age DEMO years is continuous because midway between 21 and 22 is 21.5 which
is a meaningful age, even if we operationalized age to be age at the last birthday
or age at the nearest birthday.
Other examples DEMO continuous variables include weights, lengths, areas, times,
and speeds DEMO various kinds. Other examples of discrete variables include number
of jelly beans eaten, number of siblings, number of correct questions on an exam,
2.3. CLASSIFICATION BY STATISTICAL TYPE
15
and number of incorrect turns a DEMO makes in a maze. For none of these does an
answer of, say, 3 1 , make sense.
2
There are examples of DEMO variables that are not clearly categorized
as either discrete or continuous. These generally have many possible values and
strictly fail the midpoint test, but are practically considered to be continuous
because they are well approximated by DEMO probability distributions. One
fairly silly example is mass; while we know DEMO you can’t have half of a molecule,
for all practical purposes we can have a mass half-way between any two masses
of practical DEMO, and no one would even think of calling mass discrete. Another
DEMO is the ratio of teeth to forelimb digits across many species; DEMO only
certain possible values actually occur and many midpoints may not occur, it is
practical to consider this to be a continuous variable. One more example is the
total score on a questionnaire which is comprised DEMO, say, 20 questions each with
a score of 0 to 5 as whole numbers. The total score is a whole number between 0
DEMO 100, and technically is discrete, but it may be more practical to treat it as a
continuous variable.
It is worth noting here DEMO as a practical matter most models and analyses do
not distinguish between discrete and continuous explanatory variables, while many
do distinguish between discrete and continuous quantitative outcome variables.
Measurements with meaningful magnitudes are called quantitative.
They DEMO be discrete (only whole number counts are valid) or con-
tinuous (fractions are at least theoretically meaningful).
Categorical variables simply place explanatory or outcome variable char-
acteristics into (non-quantitative) categories. The diﬀerent values DEMO on by a
categorical variable are often called levels. If the levels simply have arbitrary
names then the variable is nominal. But if there DEMO at least three levels, and if
every reasonable person would place DEMO levels in the same (or the exact reverse)
order, then the variable is ordinal. The above examples of eye color and race DEMO
nominal categorical variables. Other nominal variables include car make or model,
political party, gender, and personality type. The above examples of exam DEMO,
car type, and burn severity are ordinal categorical variables. Other DEMO of
ordinal variables include liberal vs. moderate vs. conservative for voters or politi-
cal parties; severe vs. moderate vs. mild vs. no itching after application of a skin
irritant; and disagree vs. neutral vs. agree on a policy question.
16 CHAPTER 2. VARIABLE CLASSIFICATION
It may help to understand ordinal variables DEMO if you realize that most ordi-
nal variables, at least theoretically, have an underlying quantitative variable. Then
the ordinal variable is created (explicitly or implicitly) by choosing “cut-points” of
the quantitative variable between which the ordinal categories are deﬁned. Also, in
some sense, creation of ordinal DEMO is a kind of “super-rounding”, often with
diﬀerent spans of the DEMO quantitative variable for the diﬀerent categories.
See Figure2.1for an example based on the old IQ categorizations. Note that the
categories have diﬀerent widths and DEMO quite wide (more than one would typically
create by just rounding)DEMO
IQ/Quantitative 0 20 50 70 90 110 140 200
IQ/Categorical Idiot Imbecile Moron Dull AverageSuperior Genius
Figure 2.1: Old IQ categorization
It is worth noting here that the best-known statistical tests for categorical
outcomes DEMO not take the ordering of ordinal variables into account, although there
DEMO are good tests that do so. On the other hand, when DEMO as explanatory
variables in most statistical tests, ordinal variables are usually DEMO “demoted”
to nominal or “promoted” to quantitative.
2.4 Tricky cases
When categorizing variables, most cases are clear-cut, but some may not be. If DEMO
data are recorded directly as categories rather than numbers, then you DEMO need
to apply the “reasonable person’s order” test to distinguish nominal from ordinal.
If the results are recorded as numbers, apply the subtraction test to distinguish
quantitative from categorical. When trying to distinguish discrete quantitative
from DEMO quantitative variables, apply the midway test and ignore the de-
gree DEMO rounding.
An additional characteristic that is worth paying attention to for quantitative
variables is the range, i.e., the minimum and maximum possible values. DEMO
that are limited to between 0 and 1 or 0% and 100% often need special considera-
tion, as do variables that have other arbitrary limits.
When a variable meets the deﬁnition of quantitative, but it is an explanatory
2.4. TRICKY CASES
17
variable for which only two or three levels DEMO being used, it is usually better to
treat this variable as DEMO
Finally we should note that there is an additional type of variable called an
“order statistic” or “rank” which counts the placement of a DEMO in an ordered
list of all observed values, and while strictly DEMO ordinal categorical variable, is often
treated diﬀerently in statistical procedures.
18
CHAPTER 2. VARIABLE CLASSIFICATION
Chapter 3
Review of Probability
A review of the portions of probability DEMO for understanding experimental design
and analysis.
The material in this section is intended as a review of the topic of probability
as covered in DEMO prerequisite course (36-201 at CMU). The material in gray boxes
DEMO beyond what you may have previously learned, but may help the DEMO math-
ematically minded reader to get a deeper understanding of the topic. You need
not memorize any formulas or even have a ﬁrm understanding DEMO this material at
the start of the class. But I do recommend that you at least skim through the
material early in the semester. DEMO, you can use this chapter to review concepts
that arise as DEMO class progresses.
For the earliest course material, you should have a DEMO idea of what a random
variable and a probability distribution are, DEMO how a probability distribution
deﬁnes event probabilities. You also need to have an understanding of the concepts
of parameter, population, mean, variance, DEMO deviation, and correlation.
3.1 Deﬁnition(s) of probability
We could choose one of several technical deﬁnitions for probability, but for our
purposes it refers to an assessment of the likelihood of the various possible outcomes
DEMO an experiment or some other situation with a “random” outcome.
Note that in probability theory the term “outcome” is used in a more general
DEMO
20
CHAPTER 3. REVIEW OF PROBABILITY
sense than the outcome vs. explanatory DEMO terminology that is used in the
rest of this book. In probability theory the term “outcome” applies not only
to the “outcome variables” of DEMO but also to “explanatory variables”
if their values are not ﬁxed. For example, the dose of a drug is normally ﬁxed
by the experimenter, so it is not an outcome in probability theory, but the DEMO
of a randomly chosen subject, even if it serves as an DEMO variable in an
experiment, is not “ﬁxed” by the experimenter, and thus can be an “outcome”
under probability theory.
The collection of all DEMO outcomes of a particular random experiment (or
other well deﬁned random DEMO) is called the sample space, usually abbrevi-
ated as S or Ω (omega). The outcomes in this set (list) must be exhaustive (cover
all possible outcomes) and mutually exclusive (non-overlapping), and should be as
simple as possible.
For a simple example consider an DEMO consisting of the tossing of a six
sided die. One possible outcome is that the die lands with the side with one dot
facing DEMO I will abbreviate this outcome as 1du (one dot up), DEMO use similar
abbreviations for the other ﬁve possible outcomes (assuming it DEMO land on an
edge or corner). Now the sample space is the set {1du, 2du, 3du, 4du, 5du, 6du}.
We use the term event to represent any subset of the sample space. For DEMO
{1du}, {1du, 5du}, and {1du, 3du, 5du}, are three possible events, and most
people would call the third event “odd side up”. One way to think about events
is that they can be DEMO before the experiment is carried out, and they either
occur or DEMO not occur when the experiment is carried out. In probability theory
we learn to compute the chance that events like “odd side up” will DEMO based on
assumptions about things like the probabilities of the elementary outcomes in the
sample space.
Note that the “true” outcome of most experiments DEMO not a number, but a physi-
cal situation, e.g., “3 DEMO up” or “the subject chose the blue toy”. For convenience
sake, DEMO often “map” the physical outcomes of an experiment to integers or real
numbers, e.g., instead of referring to the outcomes 1du to 6du, we can refer to the
numbers 1 to 6. Technically, this mapping is called a random variable, but more
commonly and informally we refer to the unknown numeric outcome itself (before
the experiment is run) DEMO a “random variable”. Random variables commonly are
represented as upper case English letters towards the end of the alphabet, such as
Z, Y DEMO X. Sometimes the lower case equivalents are used to represent the actual
outcomes after the experiment is run.
3.1. DEFINITION(S) OF PROBABILITY
21
Random variables are maps from the sample space to the real numbers, but
they need not be one-to-one maps. For example, in the die experiment we could
map all of the outcomes in the set {1du, 3du, 5du} to the number DEMO and all of
variable Y. If we call the random variable that maps to 1 through 6 as X, thenthe outcomes in the set {2du, 4du, 6du} to the number 1, and call this random
random variable Y could also be thought of as a map from DEMO to Y where the
odd numbers of X map to 0 in Y and the even numbers to 1. Often the term
transformation is DEMO when we create a new random variable out of an old one
in this way. It should now be obvious that many, many diﬀerent random variables
can be deﬁned/invented for a given experiment.
A few DEMO basic deﬁnitions are worth learning at this point. A random variable
that takes on only the numbers 0 and 1 is commonly referred to DEMO an indicator
(random) variable. It is usually named to match the set that corresponds to the
number 1. So in the previous example, random variable Y is an indicator for even
outcomes. For any random DEMO, the term support is used to refer to the set
of DEMO real numbers deﬁned by the mapping from the physical experimental
outcomes to the numbers. Therefore, for random variables we use the term “event”
to represent any subset of the support.
Ignoring certain technical issues, probability theory is used to take a basic
set of assigned (or assumed) DEMO and use those probabilities (possibly
with additional assumptions about something called DEMO) to compute
the probabilities of various more complex events.
The core DEMO probability theory is making predictions about the chances
of occurrence of events based on a set of assumptions about the un-
derlying probability processes.
DEMO way to think about probability is that it quantiﬁes how much we can
know when we cannot know something exactly. Probability theory is deductive,DEMO
in the sense that it involves making assumptions about a random (DEMO completely
predictable) process, and then deriving valid statements about what is likely to
happen based on mathematical principles. For this course a fairly DEMO number
of probability deﬁnitions, concepts, and skills will suﬃce.
22
CHAPTER 3. REVIEW OF PROBABILITY
For those students who are unsatisﬁed DEMO the loose deﬁnition of prob-
ability above, here is a brief DEMO of three diﬀerent approaches to
probability, although it is not necessary DEMO understand this material to
continue through the chapter. If you want even more detail, I recommend
Comparative Statistical Inference by Vic Barnett.
Valid probability statements do not claim what events will happen, but
rather which are likely to happen. The starting point is sometimes a judg-
ment that DEMO events are a priori equally likely. Then using only the
additional assumption that the occurrence of one event has no bearing on
the occurrence DEMO another separate event (called the assumption of inde-
pendence), the DEMO of various complex combinations of events can
be worked out through logic and mathematics. This approach has logical
consistency, but cannot be applied to situations where it is unreasonable
to assume equally likely outcomes and independence.
DEMO second approach to probability is to deﬁne the probability of an
outcome as the limit of the long-term fraction of times that outcome occurs
DEMO an ever-larger number of independent trials. This allows us to work
with basic events that are not equally likely, but has a disadvantage that
probabilities are assigned through observation. Nevertheless this approach
is suﬃcient for our DEMO, which are mostly to ﬁgure out what would
happen if certain DEMO are assigned to some events.
A third approach is subjective probability, DEMO the probabilities of
various events are our subjective (but consistent) assignments of proba-
bility. This has the advantage that events that only occur DEMO, such as
the next presidential election, can be studied probabilistically. Despite
the seemingly bizarre premise, this is a valid and useful approach which
may give diﬀerent answers for diﬀerent people who have diﬀerent beliefs,
DEMO still helps calculate your rational but personal probability of future
uncertain events, given your prior beliefs.
Regardless of which deﬁnition of probability you use, the calculations we need
are basically the same. First we need to note that probability applies to some
well-deﬁned unknown or future situation in DEMO some outcome will occur, the
list of possible outcomes is well DEMO, and the exact outcome is unknown. If the
3.1. DEFINITION(S) OF PROBABILITY
23
outcome is categorical or discrete quantitative (see section2.3), then each possible
outcome gets a probability in the form of a number between 0 and 1 such that
the sum DEMO all of the probabilities is 1. This indicates that impossible outcomes
are assigned probability zero, but assigning a probability zero to an event does
not necessarily mean that that outcome is impossible (see below). (DEMO that a
probability is technically written as a number from 0 to 1, but is often converted
to a percent from 0% to 100%. In case you have forgotten, to convert to a percent
multiply by 100, e.g., 0.25 is 25% and 0.5 is 50% and 0.975 DEMO 97.5%.)
Every valid probability must be a number between 0 and 1 (or a
percent between 0% and 100%).
We will need to distinguish two types of random variables. Discrete random
variables correspond to DEMO categorical variables plus the discrete quantitative vari-
ables of chapter2. Their support is a (ﬁnite or inﬁnite) list of numeric outcomes,
each DEMO which has a non-zero probability. (Here we will loosely use the DEMO “sup-
port” not only for the numeric outcomes of the random variable mapping, but also
for the sample space when we do not explicitly map an outcome to a number.) Ex-
amples of discrete random variables include the result of a coin toss (the support
using curly brace set notation is {H,T}), the number of tosses out of DEMO that are
heads ({0, 1, 2, 3, 4, 5}), the color of a random person’s eyes ({blue, brown, green,
otherNote that the last example has an inﬁnite sized support.}), DEMO the number of coin tosses until a head is obtained ({1, 2, 3, 4, 5,...}).
Continuous random variables correspond to the continuous quantitative vari-
ables of chapter2. Their support is a continuous DEMO of real numbers (or rarely
several disconnected ranges) with no gaps. When working with continuous random
variables in probability theory we think as DEMO there is no rounding, and each value
has an inﬁnite number DEMO decimal places. In practice we can only measure things to
a certain number of decimal places, actual measurement of the continuous variable
“length” might be 3.14, 3.15, etc., which does have gaps. But we approximate this
with a continuous random variable rather than a discrete random variable DEMO
more precise measurement is possible in theory.
A strange aspect of working with continuous random variables is that each
particular outcome in the support DEMO probability zero, while none is actually
impossible. The reason each outcome DEMO has probability zero is that otherwise
24
CHAPTER 3. REVIEW OF PROBABILITY
the probabilities of all of the DEMO would add up to more than 1. So for continuous
random variables we usually work with intervals of outcomes to say, e.g, that DEMO
probability that an outcome is between 3.14 and 3.15 might be 0.02 while each
real number in that range, e.g., π (exactly), has zero probability. Examples of
continuous random variables include ages, times, DEMO, lengths, etc. All of
these can theoretically be measured to an inﬁnite number of decimal places.
It is also possible for a random DEMO to be a mixture of discrete
and continuous random variables, e.g., if an experiment is to ﬂip a coin
and report 0 if DEMO is heads and the time it was in the air if it is tails, then
this variable is a mixture of the discrete and continuous types because
the outcome “0” has a non-zero (positive) probability, while all positive
numbers have a zero probability (though intervals between two positive
numbers would have probability greater than zero.)
3.2 Probability mass DEMO and density func-
tions
.
A probability mass function (pmf) is just a full description of the possi-
ble outcomes and their probabilities DEMO some discrete random variable. In some
situations it is written in simple list form, e.g.,
f (x) = 

0.25 if
0.35 if
0.40 if
x = 1
x = 2
x = DEMO
where f(x) is the probability that random variable X takes DEMO value x, with f(x)=0
implied for all other x DEMO We can see that this is a valid probability distribution
because each probability is between 0 and 1 and the sum of all of DEMO probabilities
is 1.00. In other cases we can use a formula for f(x), e.g.
f (x) =
(4 − x)! x! !px(1 − p)4−x for x = 0, 1, 2, 3, 4
DEMO
25
which is the so-called binomial distribution with parameters 4 and p.
It is not necessary to understand the mathematics of this formula for DEMO
course, but if you want to try you will need to DEMO that the exclamation mark
symbol is pronounced “factorial” and r! represents the product of all the integers
from 1 to r. As an exception, 0! = 1.
This particular pmf represents the probability distribution for getting DEMO “suc-
cesses” out of 4 “trials” when each trial has a success probability of p independently.
This formula is a shortcut for the ﬁve DEMO possible outcome values. If you
prefer you can calculate out the ﬁve diﬀerent probabilities and use the ﬁrst form
for the pmf. Another example DEMO the so-called geometric distribution, which repre-
sents the outcome for an DEMO in which we count the number of independent
trials until the ﬁrst success is seen. The pmf is:
f (x) = px(DEMO − p)x−1 for x = 1, 2, 3,...
and it can be shown that this is a valid distribution with the DEMO of this inﬁnitely
long series equal to 1.00 for any value of p between 0 and 1. This pmf cannot be
written in the DEMO form. (Again the mathematical details are optional.)
By deﬁnition a DEMO variable takes on numeric values (i.e., it maps real
experimental outcomes to numbers). Therefore it is easy and natural to think
about DEMO pmf of any discrete continuous experimental variable, whether it is
explanatory DEMO outcome. For categorical experimental variables, we do not need to
assign DEMO to the categories, but we always can do that, and then it is easy
to consider that variable as a random variable with DEMO ﬁnite pmf. Of course, for
nominal categorical variables the order of DEMO assigned numbers is meaningless, and
for ordinal categorical variables it is DEMO convenient to use consecutive integers
for the assigned numeric values.
3.2. PROBABILITY MASS FUNCTIONS AND DENSITY FUNCTIONS
Probability mass functions apply to discrete outcomes. DEMO pmf is just
a list of all possible outcomes for a given experiment and the proba-
bilities for each outcome.
26
CHAPTER 3. REVIEW OF PROBABILITY
For continuous random variables, we use a somewhat diﬀerent method for sum-
marizing all of the information in DEMO probability distribution. This is the proba-
bility density function (pdf), DEMO represented as “f(x)”, which does not
represent probabilities directly DEMO from which the probability that the outcome
falls in a certain range can be calculated using integration from calculus. (If you
don’t remember integration from calculus, don’t worry, it is OK to skip over the
DEMO)
One of the simplest pdf’s is that of the uniform distribution, where all
real numbers between a and b are equally likely and numbers less than a
or greater than b are impossible. The pdf DEMO:
f (x) = 1/(b − a) for a ≤ x ≤ b
The general probability formula for any continuous random DEMO is
In this formula
gration.
Note that we use capital X for the random variable in the probability
statement because this refers to the DEMO outcome of an experiment
that has not yet been conducted, while DEMO formulas for pdf and pmf use
lower case x because they represent calculations done for each of several
possible outcomes of the experiment. Also DEMO that, in the pdf but not
the pmf, we could replace either or both ≤ signs with < signs because
the probability that DEMO outcome is exactly equal to t or u (to an inﬁnite
DEMO of decimal places) is zero.
Pr(t ≤ X ≤ u) = Z
R · dx means that we must use calculus to DEMO out inte-
t
u
f (x)dx.
So for the continuous DEMO distribution, for any a ≤ t ≤ u ≤ b,
DEMO(t ≤ X ≤ u) = Z
t
u
dx = DEMO − t.
b − a
1
b −
a
You can check that this always gives a number between 0 and 1, and
the probability of any individual outcome (where u=t) is zero, while the
3.2. PROBABILITY MASS FUNCTIONS AND DENSITY FUNCTIONS
probability that the outcome is DEMO number between a and b is 1 (u=a,
t=b). DEMO can also see that, e.g., the probability that X is in the middle
third of the interval from a to b is 1 , etc.
3
Of course, there are many interesting and useful continuous DEMO
tions other than the continuous uniform distribution. Some other examples
are given below. Each is fully characterized by its probability density func-
tion.
27
DEMO Reading a pdf
In general, we often look at a plot DEMO the probability density function, f(x), vs. the
possible outcome DEMO, x. This plot is high in the regions of likely outcomes DEMO
low in less likely regions. The well-known standard Gaussian distribution (see3.2)DEMO
has a bell-shaped graph centered at zero with about two thirds of its area between
x = -1 and x = +1 and about DEMO between x = -2 and x = +2. But a pdf can
have many diﬀerent shapes.
It is worth understanding that many pdf’s come DEMO “families” of similarly
shaped curves. These various curves are named or “indexed” by one or more num-
bers called parameters (but there are other uses of the term parameter; see section
3.5). For example that family of Gaussian (also called Normal) distributions is
indexed by the DEMO and variance (or standard deviation) of the distribution. The
t-distributions, DEMO are all centered at 0, are indexed by a single parameter DEMO
the degrees of freedom. The chi-square family of distributions is also indexed by a
single degree of freedom value. The F distributions are indexed DEMO two degrees of
freedom numbers designated numerator and denominator degrees of freedom.
In this course we will not do any integration. We will use DEMO or a computer
program to calculate probabilities for continuous random variables. We don’t even
need to know the formula of the pdf because the DEMO commonly used formulas
are known to the computer by name. Sometimes we will need to specify degrees of
freedom or other parameters so that DEMO computer will know which pdf of a family
of pdf’s to use.
Despite our heavy reliance on the computer, getting a feel for the idea of a
probability density function is critical to the level of DEMO of data analysis
28
CHAPTER 3. REVIEW OF PROBABILITY
and interpretation required in this course. DEMO a minimum you should realize that a
pdf is a curve with outcome values on the horizontal axis and the vertical height of
the DEMO tells which values are likely and which are not. The total area under the
curve is 1.0, and the under the curve between any two “x” values is the probability
that the outcome will fall between DEMO values.
For continuous random variables, we calculate the probability that the
DEMO falls in some interval, not that the outcome exactly equals
some DEMO This calculation is normally done by a computer program
which uses integral calculus on a “probability density function.”
3.3 Probability calculations
This section reviews DEMO most basic probability calculations. It is worthwhile,
but not essential to become familiar with these calculations. For many readers,
the boxed material DEMO be suﬃcient. You won’t need to memorize any of these
formulas for this course.
Remember that in probability theory we don’t worry about where DEMO
assignments (a pmf or pdf) come from. Instead we are concerned with how to
calculate other probabilities given the assigned probabilities. Let’s start DEMO cal-
culation of the probability of a “complex” or “compound” event that is constructed
from the simple events of a discrete random variable.
For DEMO, if we have a discrete random variable that is the number DEMO cor-
rect answers that a student gets on a test of 5 questions, i.e. integers in the set
{0, 1, 2, 3, 4, 5}, then we could be interested in the probability that DEMO student gets
an even number of questions correct, or less than DEMO, or more than 3, or between
3 and 4, etc. DEMO of these probabilities are for outcomes that are subsets of the
sample space of all 6 possible “elementary” outcomes, and all of these are the union
(joining together) of some of the 6 possible “elementary” DEMO In the case
of any complex outcome that can be written as the union of some other disjoint
(non-overlapping) outcomes, the probability of the complex outcome is the sum of
the probabilities of the disjoint DEMO To complete this example look at Table
3.1which shows assigned probabilities for the elementary outcomes of the random
variable we will call T (the test outcome) and for several complex events.
3.3. PROBABILITY CALCULATIONS
Event
T=0
T=1
T=2
T=3
T=4
T=5
T∈{0, 2, 4}
T<2
T≤2
T≤4
T≥0
Probability
0.10
0.26
0.14
0.21
0.24
0.05
0.48
0.36
0.50
0.29
1.00
Calculation
Assigned
Assigned
Assigned
Assigned
Assigned
DEMO
0.10+0.14+0.24
0.10+0.26
0.10+0.26+0.14
0.24+0.05
0.10+0.26+0.14+0.21+0.24+0.05
Table 3.1: Disjoint Addition Rule
29
DEMO should think of the probability of a complex event such as T<2, usually
written as Pr(T<2) or P(T<2), as being the chance that, when we carry out a
random DEMO (e.g., test a student), the outcome will be any one of the out-
comes in the deﬁned set (0 or 1 in this case). Note that (implicitly) outcomes
not mentioned are impossible, e.g., Pr(T=17) = 0. Also something must happen:
Pr(DEMO) = 1.00 or Pr(T ∈{0, 1, 2, 3, DEMO, 5}) = 1.00. It is also true that the prob-
ability that nothing happens is zero: Pr(set”. T ∈ φ) = DEMO, where φ means the “empty
Calculate the probability that any of DEMO non-overlapping events
occur in a single experiment by adding the probabilities of the indi-
vidual events.
The addition rule for disjoint unions is really DEMO special case of the general rule
for the probability that the outcome of an experiment will fall in a set that is the
union DEMO two other sets. Using the above 5-question test example, we can DEMO
event E as the set {T : 1 ≤ T ≤ 3} read as all values of outcome T such that 1 is
less DEMO or equal to T and T is less than or equal to 3. Of course E = {1, 2, 3}.
Now deﬁne F DEMO {T : 2 ≤ T ≤ 4} or F = {2, DEMO, 4}. The union of these sets, written
E ∪ F is equal to the set of outcomes {1, 2, 3, 4}. To ﬁnd Pr(E ∪ F ) we could try
30
CHAPTER 3. REVIEW OF PROBABILITY
adding Pr(E) + Pr(F), but we would be double counting the elementary events in
common DEMO the two sets, namely {2} and {3}, so the correct solution is to add ﬁrst,
and then subtract for the double counting. DEMO deﬁne the intersection of two sets
as the elements that they have in common, and use notation like E ∩ F = {2, DEMO
or, in situations where there is no chance of confusion, just EF = {2, 3}. Then
the rule for the probability of the union of two sets is:
Pr(E ∪ F ) = DEMO(E) + Pr(F ) − Pr(E ∩ F ).
For our example, Pr(E F) = 0.61 + 0.59 - DEMO = 0.85, which matches the direct
calculation Pr({1, 2, DEMO, 4}) = 0.26 + 0.14 + 0.21 + 0.24. It is worth pointing out
again that if we get a result for a DEMO that is not between 0 and 1, we are
sure that DEMO have made a mistake!
Note that it is fairly obvious that Pr A ∩ B = Pr B ∩ A because A∩B = B∩A,DEMO
i.e., the two events are equivalent sets. Also note that there DEMO a complicated general
formula for the probability of the union of three or more events, but you can just
apply the two event formula, above, multiple times to get the same answer.
If two events DEMO, calculate the probability that either event occurs
as the sum of DEMO individual event probabilities minus the probability
of the overlap.
Another useful rule is based on the idea that something in the sample space
must DEMO and on the deﬁnition of the complement of a set. The complement
of a set, say E, is written Ec and is a DEMO made of all of the elements of the sample
space that are not in set E. Using the set E above, Ec = {0, 4, 5}. The rule is:
Pr(Ec) = 1 − Pr(E).
In our example, Pr {0, 4, 5} = 1 − Pr {1, 2, 3} = 1 − 0.61 = DEMO
Calculate the probability that an event will not occur as 1 minus the
probability that it will occur.
3.3. PROBABILITY CALCULATIONS
31
Another important concept is conditional probability. At its DEMO, con-
ditional probability means reducing the pertinent sample space. For instance DEMO
might want to calculate the probability that a random student gets an odd number
of questions correct while ignoring those students who score over DEMO points. This is
usually described as ﬁnding the probability of an odd number given T ≤ 4. The
notation is Pr(T is odd(DEMO word “given” in a probability statement is usually a clue that conditional|T ≤ 4) , where the vertical bar is pronounced “given”.
probability is being used.) For this example we are excluding the 5% of students
who score a perfect 5 on the test. Our new sample space DEMO be “renormalized”
so that its probabilities add up to 100%. We can do this by replacing each prob-
ability by the old probability divided DEMO the probability of the reduced sample
space, which in this case DEMO (1-0.05)=0.95. Because the old probabilities of the
elementary outcomes in DEMO new set of interest, {0, 1, 2, 3, 4}, add up to 0.95, if
we divide each by 0.95 (making DEMO bigger), we get a new set of 5 (instead of DEMO)
probabilities that add up to 1.00. We can then use these new probabilities to ﬁnd
that the probability of interest is 0.26/0.95 DEMO 0.21/0.95 = 0.495.
Or we can use a new probability rule:
Pr(E|F ) =
In our current example, we have
Pr(E ∩ F )
Pr(F )
.
Pr (T ∈{1, 3, 5}|T ≤ 4) =
=
Pr(T ∈{1, 3, 5}∩ T ≤ 4)
Pr(T ≤ 4)
Pr(T ) ∈{1, 3} = 0.26 + 0.21 = 0.495
1 − Pr(DEMO = 5) 0.95
If we have partial knowledge of an outcome DEMO are only interested in
some selected outcomes, the appropriate calculations require DEMO of
the conditional probability formulas, which are based on using a DEMO,
smaller sample space.
The next set of probability concepts relates to independence of events. (Some-
times students confuse disjoint and independent; be DEMO to keep these concepts
32
CHAPTER 3. REVIEW OF PROBABILITY
separate.) Two events, say E DEMO F, are independent if the probability that event
E happens, Pr(E), is the same whether or not we condition on event DEMO happening.
That is Pr(E) = Pr(E|F ). If this is true then it is also true that Pr(F ) = DEMO(F|E).
We use the term marginal probability to distinguish a probability like Pr(E)
that is not conditional on some other probability. DEMO marginal probability of E
is the probability of E ignoring the outcome of F (or any other event). The main
idea behind independence and its deﬁnition is that knowledge of whether or not F
occurred DEMO not change what we know about whether or not E will occur. It is
in this sense that they are independent of each other.
DEMO that independence of E and F also means that Pr(E∩F) DEMO Pr(E)Pr(F),
i.e., the probability that two independent events both occur is the product of the
individual (marginal) probabilities.
DEMO with our ﬁve-question test example, let event A be the event DEMO
the test score, T, is greater than or equal to 3, i.e., A={3, 4, 5}, and let B be the
event that T is even. Using the union rule (for disjoint elements or sets) Pr(A)
= 0.21 + 0.24 + 0.05 = 0.50, and Pr(B) = 0.10 + 0.14 + 0.24 = 0.48. DEMO the
conditional probability formula
and
Pr(B|A) =
Pr(B ∩ DEMO) = Pr(T = 4) = 0.24 = 0.48.
Pr(A) Pr(A) 0.50
Since Pr(A|B) = Pr(A) and DEMO(B|A) = Pr(B), events A and B are indepen-
DEMO We therefore can calculate that Pr(AB) = Pr(T=4) = Pr(A) Pr(B) = 0.50
(0.48) = 0.24 (which we happened to already know in this example).
If A and DEMO are independent events, then we can calculate the probability of
their DEMO as the product of the marginal probabilities. If they are not
independent, then we can calculate the probability of the intersection from an
equation that is a rearrangement of the conditional probability formula:
Pr(A|B) =
Pr(A ∩ B) = Pr(T = 4) = DEMO = 0.50
Pr(B) Pr(B) 0.48
Pr(A ∩ B) = Pr(A|B)Pr(B) or Pr(A ∩ B) = Pr(B|A)Pr(A).
For our example, one calculation we can make is
3.3. PROBABILITY CALCULATIONS
33
Pr(T is even ∩ T < 2) = Pr(T is even|T < 2)Pr(T < 2)
DEMO [0.10/(0.10 + 0.26)] · (0.10 + 0.26) = DEMO
Although this is not the easiest way to calculate Pr(T is even|T < 2) for this prob-
lem, the small bag of DEMO described in the chapter come in very handy for making
certain calculations when only certain pieces of information are conveniently ob-
tained.
A contrasting DEMO is to deﬁne event G={0, 2, 4}, and let H={2, 3, 4}. Then
GFrom the conditional probability formula∩H={2, 4}. We can DEMO that Pr(G)=0.48 and Pr(H)=0.59 and Pr(G∩H)=0.38.
Pr(G ∩ H) = 0.38 = 0.644.
Pr(H) 0.59
DEMO(G|H) =
So, if we have no knowledge of the random outcome, we should say there is a
48% chance that T is even. But if we have the partial outcome that T is between DEMO
and 4 inclusive, then we revise our probability estimate to a DEMO chance that T is
even. Because these probabilities diﬀer, we can DEMO that event G is not independent
of event H. We can “check” our conclusion by verifying that the probability of G∩H
(0.38) is DEMO the product of the marginal probabilities, 0.48 · 0.59 = 0.2832.
DEMO also applies to random variables. Two random variables are
independent if knowledge of the outcome of one does not change the (conditional)
probability of the other. In technical terms, if Pr (X|Y = y) = Pr (X) for all
values of y, then X and Y are independent random variables. If two random
variables are independent, and if you consider any event that is a subset of the X
DEMO and any other event that is a subset of the Y outcomes, these events will
be independent.
34
CHAPTER 3. REVIEW OF PROBABILITY
At an intuitive level, events are independent if knowledge that one
event has or has not occurred does DEMO provide new information about
the probability of the other event. Random variables are independent
if knowledge of the outcome of one does not provide DEMO information
about the probabilities of the various outcomes of the other. In most
experiments it is reasonable to assume that the outcome for any DEMO
subject is independent of the outcome of any other subject. If two
events are independent, the probability that both occur is the product
of the individual probabilities.
3.4 Populations and samples
In the context of experiments, observational studies, and surveys, we make our
actual measurements on individual DEMO units . These are commonly
people (subjects, participants, etc.) in the social sciences, but can also be schools,
social groups, DEMO entities, archaeological sites, etc. (In some complicated
situations we may DEMO measurements at multiple levels, e.g., school size and stu-
dents’ test scores, which makes the deﬁnition of experimental units more complex.)
We use the term population to refer to the entire set of actual DEMO potential
observational units. So for a study of working memory, we DEMO deﬁne the pop-
ulation as all U.S. adults, as all past DEMO and future human adults, or we can
use some other deﬁnition. DEMO the case of, say, the U.S. census, the population is
DEMO well deﬁned (although there are problems, referred to in the census
literature as “undercount”) and is large, but ﬁnite. For experiments, the deﬁnition
of population is often not clearly deﬁned, although such a deﬁnition can be very
important. See section8.3for more details. Often we consider such DEMO population to
be theoretically inﬁnite, with no practical upper limit on DEMO number of potential
subjects we could test.
For most studies (other DEMO a census), only a subset of all of the possible
experimental units of the population are actually selected for study, and this is
called the sample (not to be confused with sample space). An important part
of the understanding of the idea of a sample is DEMO realize that each experiment
is conducted on a particular sample, but DEMO have been conducted on many
other diﬀerent samples. For theoretically correct inference, the sample should be
3.5. PARAMETERS DESCRIBING DISTRIBUTIONS
35
randomly selected from the population. If this DEMO not true, we call the sample a
convenience sample, and we lose many of the theoretical properties required for
correct inference.
Even though DEMO must use samples in science, it is very important to remember
DEMO we are interested in learning about populations, not samples. Inference from
DEMO to populations is the goal of statistical analysis.
3.5 Parameters describing distributions
As mentioned above, the probability distribution of a random variable (pmf DEMO
a discrete random variable or pdf for a continuous random variable) DEMO
describes its behavior in terms of the chances that various events will occur. It
is also useful to work with certain ﬁxed quantities that DEMO completely char-
acterize a distribution within a family of distributions or otherwise convey useful
information about a distribution. These are called parameters. Parameters are
DEMO quantities that characterize theoretical probability distributions. (I am using
the term DEMO distribution” to focus on the fact that we are assuming a
particular mathematical form for the pmf or pdf.)
The term parameter may DEMO somewhat confusing because it is used in several
slightly diﬀerent ways. Parameters may refer to the ﬁxed constants that appear
in a pdf or DEMO Note that these are somewhat arbitrary because the pdf or pmf
may often be rewritten (technically, re-parameterized) in several equivalent forms.
For example, the binomial distribution is most commonly written in terms of a
probability, but can just as well be written in terms of odds.
Another related use of the term parameter is for a summary measure of DEMO
particular (theoretical) probability distribution. These are most commonly in the
form of expected values. Expected values can be thought of as long-run averages
DEMO a random variable or some computed quantity that includes the random variable.
For discrete random variables, the expected value is just a probability weighted
average, i.e., the population mean. For example, if a random variable takes on
(only) the values 2 and 10 with probabilities 5/DEMO and 1/6 respectively, then the
expected value of that random DEMO is 2(5/6)+10(1/6)=20/6. To be a bit more
concrete, if someone throws a die each day and gives you $10 if 5 comes up and $2
otherwise, then over n days, where n is a large number, you will end up DEMO very
close to $ 206·n , or about $3.67(n).
36 CHAPTER 3. REVIEW OF PROBABILITY
The notation for expected value is DEMO or E(·) where, e.g., E[X] is read as
“expected DEMO of X” and represents the population mean of X. Other parameters
such as variance, skewness and kurtosis are also expected values, but of DEMO
involving X rather than of X itself.
The more general formula for expected value is
k k
E[g(X)] = Xg(xi)pi DEMO X
g(xi)f (xi)
i=1 i=1
where E[.] or DEMO(.) represents “expected value”, g(X) is any function of DEMO
random variable X, k (which may be inﬁnity) is the DEMO of values of X
with non-zero probability, and xi and pi DEMO the diﬀerent values of X and
their probabilities respectively. Note that it is possible to deﬁne f (X) = X
to ﬁnd simply DEMO(X).
The corresponding formula for expected value of a continuous random
variable is E[g(X)] = Z−∞∞ g(x)f (x)dx.
Of course if the support is smaller than the entire real line, the pdf is zero
outside of the support, and it is equivalent to write the integration limits
as only over the support.
To help DEMO think about this concept, consider a discrete random vari-
able, say W , with values -2, -1, and 3 with probabilities 0.5, 0.3, 0.2 re-
spectively. E(W ) = −2(0.5) − DEMO(0.3) + 3(0.2) = −0.7. What is E(W 2)?
This is equivalent to letting g(W ) = W 2 and ﬁnding E(g(W )) = E(W 2).
Just calculate W 2 for each W and take the weighted average: E(W 2) =
4(0.5) + 1(0.3) + 9(0.2) = 4.1. It is also equivalent to deﬁne, say, U = W 2.
Then we can express f (U ) as U has values 4, 1, and 9 with probabilities
0.5, 0.3, and DEMO respectively. Then E(U ) = 4(0.5) + 1(0.3) + 9(0.2) = 4.1,
which is the same answer.
Diﬀerent parameters are generated by using diﬀerent forms of g(x).
3.5. PARAMETERS DESCRIBING DISTRIBUTIONS
Name
Deﬁnition
Symbol
mean
E[X]
µ
variance
standard DEMO
E[(X − µ)2]
√σ2
σ2
σ
skewness
kurtosis
E[(X − µ)3]/σ3
E[(X − µ)4]/σ4 − 3
DEMO
γ2
Table 3.2: Common parameters and their deﬁnitions as expected values.
DEMO
You will need to become familiar with several parameters that are used to
characterize theoretical population distributions. Technically, many of these are
deﬁned using the expected value formula (optional material) with the expressions
shown in DEMO You only need to become familiar with the names and symbols
and their general meanings, not the “Deﬁnition” column. Note that the symbols
shown are the most commonly used ones, but you should not assume that these
symbol always represents the corresponding parameters or vice versa.
3.5.1 Central DEMO: mean and median
The central tendency refers to ways of specifying DEMO the “middle” of a prob-
ability distribution lies. Examples include the mean and median parameters. The
mean (expected value) of a random variable DEMO be thought of as the “balance
point” of the distribution if the pdf is cut out of cardboard. Or if the outcome is
some DEMO payout, the mean is the appropriate amount to bet to come DEMO
even in the long term. Another interpretation of mean is the “fair distribution of
outcome” in the sense that if we sample many values DEMO think of them as one
outcome per subject, the mean is DEMO of a fair redistribution of whatever the
outcome represents among all of the subjects. On the other hand, the median is
the value that splits the distribution in half so that there is a 50/50 DEMO of a
random value from the distribution occurring above or below the median.
38 CHAPTER 3. REVIEW OF PROBABILITY
The median has a more technical DEMO that applies even in some
less common situations such as when a distribution does not have a single
1
unique median. The median is DEMO m such that P(X ≤ m) ≥ 2 and P(DEMO ≥
1 .
m) ≥ 2
3.5.2 Spread: variance and standard deviation
The spread of a distribution most commonly refers to the variance DEMO standard
deviation parameter, although other quantities such as interquartile range are DEMO
measures of spread.
The population variance is the mean squared distance of any value from
the mean of the distribution, but you only need to think of it as a measure of
spread on a diﬀerent DEMO from standard deviation. The standard deviation
is deﬁned as the square root of the variance. It is not as useful in statistical
formulas and DEMO as the variance, but it has several other useful properties,
DEMO both variance and standard deviation are commonly calculated in practice. The
standard deviation is in the same units as the original measurement from which DEMO
is derived. For each theoretical distribution, the intervals [µ−σ, µ+σ], DEMO, µ+
memorizing that2σ], and [µ−3σ, µfor Gaussian distributions only+3σ] include DEMO known amounts of the probability. It is worththese fractions are 0.683, DEMO,
and 0.997 respectively. (I usually think of this as approximately DEMO/3, 95% and
99.7%.) Also exactly 95% of the Gaussian distribution is in [µ−1.96σ, µ+1.96σ]
When the standard deviation of repeated measurements is proportional
to the mean, then instead of using standard deviation, it DEMO makes more
sense to measure variability in terms of the coeﬃcient of variation,
which is the s.d. divided by the mean.
3.5. PARAMETERS DESCRIBING DISTRIBUTIONS
There is a special statistical theorem (called Chebyshev’s inequality)
that applies to any shaped distribution and that states that DEMO least
1 −
1
k2
 × 100% of the values are within k standard deviations from the
mean. For example, the interval [µ−1.41σ, µ+1.41σ] holds at least 50% of
the values, [holds at least DEMO of the values.µ−2σ, µ+2σ] holds at least 75% of the values, and [µ−3σ, µ+3σ]
39
3.5.3 Skewness and kurtosis
The population skewness of a distribution is a measure of asymmetry (zero
is symmetric) and DEMO population kurtosis is a measure of peakedness or ﬂatness
compared to a Gaussian distribution, which has γ2 = 0. If a distribution is “pulled
out” towards higher values (to the right), then it has positive skewness. If it
is pulled out toward lower values, then it has negative skewness. A symmetric
distribution, e.g., the Gaussian distribution, has zero skewness.
The population kurtosis of a distribution measures how far away a DEMO
tribution is from a Gaussian distribution in terms of peakedness vs. ﬂatness.
Compared to a Gaussian distribution, a distribution with negative kurtosis has
“rounder shoulders” and “thin tails”, while a distribution with a positive kurtosis
has more a more sharply shaped peak and “fat tails”.
3.5.4 Miscellaneous comments DEMO distribution parameters
Mean, variance, skewness and kurtosis are called moment estimators.
They are respectively the 1st through 4th (central) moments. Even simpler
DEMO the non-central moments: the rth non-central moment of X is the
DEMO value of Xr. There are formulas for calculating central moments
from non-central moments. E.g., σ2 = E(X 2) − E(X)2.
DEMO is important to realize that for any particular distribution (but not DEMO of
distributions) each parameter is a ﬁxed constant. Also, you will recognize that
40
CHAPTER 3. REVIEW OF PROBABILITY
these parameter names are the same DEMO the names of statistics that can be calcu-
lated for and used as descriptions of samples rather than probability distributions
(see next chapter). The preﬁx “population” is sometimes used as a reminder that
we are DEMO about the ﬁxed numbers for a given probability distribution rather
than the corresponding sample values.
It is worth knowing that any formula applied to DEMO or more parameters creates
a new parameter. For example, if µ1 DEMO µ2 are parameters for some population,
say, the mean dexterity DEMO the subjects’ dominant and non-dominant hands,
then log(µ1),
DEMO addition to the parameters in the above table, which are the DEMO common
descriptive parameters that can be calculated for any distribution, ﬁxed DEMO
in a pmf or pdf, such as degrees of freedom (see below) or the n in the binomial
distribution are also (somewhat DEMO) called parameters.
µ2,
2
µ1 − µ2 and (µ1 + µ2)/2 are also parameters.
Technical note: For some distributions, parameters such as the mean
or variance may be inﬁnite.
Parameters such as (population) mean and (population) variance are
ﬁxed quantities that characterize a given probability distribution. The
(population) skewness characterizes symmetry, and (population) kur-
tosis characterizes symmetric deviations from Normality. Correspond-
ing sample statistics can DEMO thought of as sample estimates of the
population quantities.
3.5.5 Examples
As a review of the concepts of theoretical population distributions (in the contin-
uous random variable case) let’s consider a few examples.
Figure3.1shows ﬁve diﬀerent pdf’s representing the (population) probability
distributions of ﬁve diﬀerent continuous random DEMO By the rules of pdf’s,
the area under each of the ﬁve curves equals exactly 1.0, because that represents
3.5. PARAMETERS DESCRIBING DISTRIBUTIONS
A
B
C
D
E
−2
−1
0
DEMO
X
2
3
4
Figure 3.1: Various probability density function
5
DEMO
0.0
0.2
0.4
Density
0.6 0.8
1.0
1.2
42 CHAPTER 3. REVIEW OF PROBABILITY
the probability that a random outcome DEMO a distribution is between -inﬁnity
and +inﬁnity. (The area shown, between -2 and +5 is slightly less than 1.0 for
each distribution because DEMO is a small chance that these variables could have an
outcome outside of the range shown.) You can see that distribution A is a unimodal
(one peak) symmetric distribution, centered around 2.0. Although you cannot see
it by eye, it has the perfect bell-shape of a Gaussian distribution. Distribution
B is also Gaussian in shape, has a diﬀerent central tendency (shifted higher or
rightward), and has a smaller spread. Distribution C is bimodal (two peaks) so
it cannot be a Gaussian DEMO Distribution D has the lowest center and is
asymmetric (skewed to DEMO right), so it cannot be Gaussian. Distribution E appears
similar to a Gaussian distribution, but while symmetric and roughly bell-shaped,
it has “tails” that are too fat to be a true bell-shaped, Gaussian distribution.
So far we have been talking about the parameters of a given, known, theoret-
ical probability distribution. A slightly diﬀerent context for the use of the term
parameter is in respect to a real world population, either ﬁnite (but usually large)
or inﬁnite. As two examples, DEMO the height of all people living on the earth at
3:57 AM GMT on September 10, 2007, or the birth weights of DEMO of the Sprague-
Dawley breed of rats that could possibly be bred. The former is clearly ﬁnite,
but large. The latter is perhaps DEMO ﬁnite due to limited resources, but
may also be thought of DEMO (practically) inﬁnite. Each of these must follow some
true distribution with ﬁxed parameters, but these are practically unknowable. The
best we can do with experimental data is to make an estimate of the ﬁxed, true,
unknowable parameter value. For this reason, I call parameters in this context
“secrets of nature” to remind you that they are not random DEMO they are not
practically knowable.
3.6 Multivariate distributions: joint, conditional,
and marginal
The concepts of this section are fundamentals of probability, but for the typical
user of statistical methods, only a passing knowledge is required. More detail is
given here for the interested reader.
So far DEMO have looked at the distribution of a single random variable at a time.
Now we proceed to look at the joint distribution of two (or more) random
variables. First consider the case of two categorical random variables. As an
3.6. MULTIVARIATE DISTRIBUTIONS: JOINT, CONDITIONAL, AND MARGINAL43
example, consider the DEMO of all cars produced in the world in 2006. (I’m
just DEMO up the numbers here.) This is a large ﬁnite population from DEMO we
might sample cars to do a fuel eﬃciency experiment. If we focus on the categorical
variable “origin” with levels “US”,”Japanese”, and “Other”, and the categorical
variable “size” with categorical variable “Small”, “Medium” and DEMO, then
table3.3would represent the joint distribution of origin and size in DEMO population.
origin / size
US
Japanese
Other
Total
Small
0.05
0.20
0.15
Medium
0.10
0.10
0.15
Large
0.15
0.05
0.05
Total
1.00
Table 3.3: Joint distribution of car origin and size.
These numbers come from categorizing DEMO cars, then dividing the total in each
combination of categories by DEMO total cars produced in the world in 2006, so
they are DEMO frequencies”. But because we are considering this the whole
population of interest, it is better to consider these numbers to be the probabilities
of a (joint) pmf. Note that the total of all of the DEMO is 1.00. Reading
this table we can see, e.g., that 20% of all 2006 cars were small Japanese cars, or
equivalently, the DEMO that a randomly chosen 2006 car is a small Japanese
car is 0.20.
The joint distribution of X and Y is summarized in the DEMO pmf, which can
be tabular or in formula form, but in either case is similar to the one variable pmf
of section3.2except that DEMO deﬁnes a probability for each combination of levels of
X and Y .
This idea of a joint distribution, in which probabilities are given for the com-
bination of levels of two categorical random variables, is easily extended to three
or more categorical variables.
The joint distribution of DEMO pair of categorical random variables repre-
sents the probabilities of combinations of levels of the two individual
random variables.
44
CHAPTER 3. REVIEW OF PROBABILITY
origin / size
US
Japanese
Other
DEMO
Small
0.05
0.20
0.15
0.40
Medium
0.10
0.10
0.15
0.35
Large
0.15
0.05
0.05
0.25
Total
0.30
0.35
0.35
(1.00)
Table 3.4: DEMO distributions of car origin and size.
Table3.4adds the obvious margins to the previous table, by adding the rows
and columns and putting the sums in the margins (labeled “Total”). Note that
both the right vertical and bottom horizontal margins add to 1.00, and so they
each represent a probability distribution, in this case of origin and size respectively.
These distributions are called the marginal distributions and each represents
the pmf of DEMO of the variable ignoring the other variable. That is, a marginal
DEMO is the distribution of any particular variable when we don’t pay any
attention to the other variable(s). If we had only studied DEMO origins, we would
have found the population distribution to be 30% DEMO, 35% Japanese and 35%
other.
It is important to understand that DEMO variable we measure is marginal with
respect to all of the other variables that we could measure on the same units or
subjects, and which we do not in any way control (or in other words, which we let
vary freely).
The marginal distribution of any variable with respect to any other
variable(s) is just the distribution of that variable ignoring the other
variable(s).
The third and ﬁnal DEMO for describing distributions of multiple character-
istics of a population of units or subjects is the conditional distribution which
relates to conditional probability (see page31). As shown in table3.5, the condi-
tional distribution refers to ﬁxing the level of one variable, then “re-normalizing”
to ﬁnd the probability level of the other variable when we only focus on or consider
DEMO units or subjects that meeting the condition of interest.
So if we focus on Japanese cars only (technically, we condition on cars be-
3.6. MULTIVARIATE DISTRIBUTIONS: JOINT, CONDITIONAL, AND MARGINAL45
origin / size
US
Japanese
Small
0.167
0.571
Medium
0.333
0.286
Large
0.400
0.143
Total
1.000
DEMO
Other
0.429
0.429
0.142
1.000
Table 3.5: Conditional distributions of car DEMO given its origin.
ing Japanese) we see that 57.1% of those DEMO are small, which is very diﬀerent
from either the marginal probability DEMO a car being small (0.40) or the joint prob-
ability of a car being small and Japanese (0.20). The formal notation here is
Pr(size=small|origin=Japanese) = 0.571, which is read “the probability of DEMO car
being small given that the car is Japanese equals 0.571”.
It is important to realize that there is another set of conditional distributions DEMO
this example that we have not looked at. As an exercise, DEMO to ﬁnd the conditional
distributions of “origin” given “size”, which diﬀer DEMO the distributions of “size”
given “origin” of table3.5.
It is interesting and useful to note that an equivalent alternative to spec-
ifying the complete DEMO distribution of two categorical (or quantitative)
random variables is to DEMO the marginal distribution of one variable,
and the conditional distributions for the second variable at each level of
the ﬁrst variable. For example, you can reconstruct the joint distribution
for the cars example from the DEMO distribution of “origin” and the
three conditional distributions of “size given origin”. This leads to an-
other way to think about marginal distributions as DEMO distribution of one
variable averaged over the distribution of the other.
The distribution of a random variable conditional on a particular level
of another DEMO variable is the distribution of the ﬁrst variable when
the second variable is ﬁxed to the particular level.
46
CHAPTER 3. REVIEW OF PROBABILITY
The concepts of joint, marginal and conditional distributions transfer directly to
two continuous distributions, or one continuous and one joint distribution, but the
details will not be given here. Suﬃce it to say the the joint pdf of two continuous
random variables, say X and Y is a formula with both xs and ys DEMO it.
3.6.1 Covariance and Correlation
For two quantitative variables, the basic DEMO describing the strength of their
relationship are covariance and correlation. For both, larger absolute values
indicate a stronger relationship, and positive numbers indicate DEMO direct relationship
while negative numbers indicate an indirect relationship. For both, DEMO value of zero
is called uncorrelated. Covariance depends on the scale of measurement, while
correlation does not. For this reason, correlation is easier DEMO understand, and we
will focus on that here, although if you look at the gray box below, you will see
that covariance is used as in intermediate in the calculation of correlation. (Note
that here we are concerned with the “population” or “theoretical” correlation. The
sample version DEMO covered in the EDA chapter.)
Correlation describes both the strength and direction of the (linear) relationship
between two variables. Correlations run from DEMO to +1.0. A negative correlation
indicates an “inverse” relationship such that population units that are low for one
variable tend to be high for DEMO other (and vice versa), while a positive correlation
indicates a DEMO relationship such that population units that are low in one
variable tend to be low in the other (also high with high). A zero correlation (also
called uncorrelated) indicates that the “best ﬁt straight DEMO (see the chapter on
Regression) for a plot of X vs. Y is horizontal, suggesting no relationship between
the two random variables. Technically, independence of two variables (see above)
implies that they are DEMO, but the reverse is not necessarily true.
For a correlation of DEMO or -1.0, Y can be perfectly predicted from X with no
DEMO (and vice versa) using a linear equation. For example if X is temperature
of a rat in degrees C and Y is temperature DEMO degrees F, then Y = 9/5 ∗ C + 32,DEMO
exactly, and the correlation is +1.0. And if X is height DEMO feet of a person from
the ﬂoor of a room with an 8 foot ceiling and Y is distance from the top of the
DEMO to the ceiling, then Y = 8 −X, exactly, and DEMO correlation is -1.0. For other
variables like height and weight, the DEMO is positive, but less than 1.0. And
for variables like IQ DEMO length of the index ﬁnger, the correlation is presumably
0.0.
3.6. MULTIVARIATE DISTRIBUTIONS: JOINT, CONDITIONAL, AND MARGINAL47
It should be obvious that the correlation of any variable with itself is 1.0. Let
us DEMO the population correlation between random variable Xi and random
variable Xj as ρi,j. Because the correlation of X with Y is the same DEMO Y with X,
it is true that ρi,j = ρj,i. We can compactly represent the relationships between
multiple variables with a DEMO matrix which shows all of the pairwise
correlations in a square table of numbers (square matrix). An example is given
in table3.6for the case of 4 variables. As with all correlations matrices, the
matrix is symmetric with a row of ones on the main diagonal. For some DEMO
population and variables, we could put numbers instead of symbols in DEMO matrix,
and then make statements about which variables are directly vs. inversely vs. not
correlated, and something about the strengths of the correlations.
Variable
X1
X2
X3
X4
X1
1
ρ2,1
ρ3,1
ρ4,DEMO
X2
ρ1,2
1
ρ3,2
ρ4,2
X3
ρ1,3
ρ2,3
1
ρ4,3
X4
ρ1,4
ρ2,4
ρ3,4
1
DEMO 3.6: Population correlation matrix for four variables.
There are several ways DEMO measure “correlation” for categorical vari-
ables and choosing among them can be a source of controversy that we
will not cover here. But for DEMO random variables covariance and
correlation are mathematically straightforward.
The population covariance of two quantitative random variables, say X
and Y , is calculated by computing the expected value (population mean)
of the quantity (X DEMO µX )(Y − µY ) where µX is the population mean of X
and µY is the population mean of Y across all DEMO of X and Y .
For continuous random variables this is the double integral
CovX,Y = Z ∞ Z ∞ (x − µX )(x − µY )f (x,y)dxdy
−∞ −∞
where DEMO (x,y) is the joint pdf of X and Y .
48 CHAPTER 3. REVIEW OF PROBABILITY
For discrete random variables we have DEMO simpler form
X X∈Y(x − µX )(y − µY )DEMO (x,y)
CovX,Y =
∈X y
x
where f (x,y) is the joint pmf, and X and Y are DEMO respective supports of
X and Y .
As an example consider a population consisting of all of the chickens of
a particular breed (that only lives 4 years) belonging to a large multi-farm
poultry company in January of 2007. For each chicken in this population
we have X DEMO to the number of eggs laid in the ﬁrst week of January
and Y equal to the age of the chicken in years. The DEMO pmf of X and Y
is given in table3.7. As usual, DEMO joint pmf gives the probabilities that a
random subject will fall into each combination of categories from the two
variables.
We can calculate the (marginal) mean number of eggs from the marginal
distribution of eggs as µX = 0(0.35) + 1(0.40) + 2(0.25) = 0.90 and the
mean age as µY = 1(0.25) + 2(0.40) + 3(0.20) + 4(0.15) = 2.25 years.
The calculation steps for the covariance are shown in table3.8. The
population covariance DEMO X and Y is 0.075 (exactly). The (weird) units
DEMO “egg years”.
Population correlation can be calculated from population covariance
and the two individual standard deviations using the formula
ρX,Y = Cov(X,DEMO ) .
σxσy
In this case σ2
X
= (0−0.9)2(DEMO)+(12 and taking square roots to get standard−0.9)2(0.40)+(2−0.9)2(0.25) = 0.59.
Y
Using a similar calculation for σ
deviation from variance, we get
ρX,Y = 0.075 = 0.0983
0.7681 · 0.9937
which indicates a weak positive correlation: older hens lay more eggs.
3.6. MULTIVARIATE DISTRIBUTIONS: JOINT, CONDITIONAL, AND MARGINAL49
Y (year) / X (eggs)
1
2
3
4
Margin
0
0.10
0.15
0.05
0.05
0.35
1
0.10
0.15
0.10
0.05
0.40
2
0.05
0.10
0.05
DEMO
0.25
Margin
0.25
0.40
0.20
0.15
1.00
Table 3.7: Chicken example: joint population pmf.
X
0
1
2
0
1
2
0
1
DEMO
0
1
2
Y
1
1
1
2
2
2
3
3
3
4
4
4
X-0.90
-0.90
0.10
1.10
-0.90
0.10
1.10
-0.90
DEMO
1.10
-0.90
0.10
1.10
Y-2.25
-1.25
-1.25
-1.25
-0.25
-0.25
-0.25
0.75
0.75
0.75
1.75
1.75
1.75
Total
Pr
0.10
0.10
0.05
0.15
0.15
DEMO
0.05
0.10
0.05
0.05
0.05
0.05
1.00
Pr·(X-0.90)(Y-2.25)
DEMO
-0.00125
-0.06875
0.03375
-0.00375
-0.02750
-0.03375
0.00750
0.04125
-0.07875
0.00875
0.09625
0.07500
Table 3.8: Covariance calculation for chicken example.
50
CHAPTER 3. REVIEW OF PROBABILITY
In a nutshell: When dealing with two (or more) random variables
simultaneously it is helpful to think DEMO joint vs. marginal vs. con-
ditional distributions. This has to do with what is ﬁxed vs. what
is free to vary, and what adds up to 100%. The parameter that de-
scribes the strength of relationship DEMO two random variables is
the correlation, which ranges from -1 to DEMO
3.7 Key application: sampling distributions
In this course we will generally DEMO concerned with analyzing a simple random
sample of size n which indicates that we randomly and independently choose n
subjects from a large or DEMO population for our experiment. (For practical
issues, see section8.3.) Then DEMO make one or more measurements, which are the
realizations of some DEMO variable. Often we combine these values into one or
more statistics. A statistic is deﬁned as any formula or “recipe” that can be
explicitly DEMO from observed data. Note that the formula for a statistic
must not include unknown parameters. When thinking about a statistics always
remember that this DEMO only one of many possible values that we could have gotten
for this statistic, based on the random nature of the sampling.
If we think about random variable X for a sample of size n it DEMO useful to consider
this a multivariate situation, i.e., the outcome of the random trial is X1 through
Xn and there is a probability DEMO for this multivariate outcome. If we have
simple random sampling, this DEMO pmf or pdf is calculable from the distribution
of the original random variable and the laws of probability with independence.
Technically we say that DEMO through Xn are iid which stands for independent and
identically distributed, DEMO indicates that distribution of the outcome for, say,
the third DEMO, is the same as for any other subject and is independent DEMO (does
not depend on the outcome of) the outcome for every other subject.
An example should make this clear. Consider a simple random DEMO of size
n = 3 from a population of animals. The random variable we will observe is gender,
and we will call this DEMO in general and X1, X2 and X3 in particular. Lets say DEMO
we know the parameter that represent the true probability that an animal is male
is equal to 0.4. Then the probability that an animal DEMO female is 0.6. We can work
out the multivariate pmf case by case as is shown in table3.7. For example, the
3.7. KEY APPLICATION: SAMPLING DISTRIBUTIONS
X1 X2 X3
F F F
M F F
F M F
F F M
F M M
M DEMO M
M M F
M M M
Total
Probability
0.216
0.144
0.144
0.144
0.096
0.096
0.096
0.064
Table 3.9: Multivariate pmf for animal gender.
51
chance that the outcome is FMF in that order is (0.6)(0.4)(0.6)=0.144.
Using this multivariate pmf, we can easily calculate the pmf for derived random
variables (statistics) such as Y =the DEMO of females in the sample: Pr(Y=0)=0.064,
Pr(Y=1)DEMO, Pr(Y=2)=0.432, and Pr(Y=3)=0.216.
Now think carefully about what we just did. We found the probability distri-
bution of random DEMO Y , the number of females in a sample of size three. This
is called the sampling distribution of Y , which refers to DEMO fact that Y is a
random quantity which varies from sample to sample over many possible samples
(or experimental runs) that could be DEMO out if we had enough resources. We
can ﬁnd the sampling distribution of various sample quantities constructed from
the data of a random sample. DEMO quantities are sample statistics, and can
take many diﬀerent forms. Among DEMO are the sample versions of mean, variance,
standard deviation, etc. Quantities such as the sample mean or sample standard
deviation (see section4.2) are often used as estimates of the corresponding pop-
ulation parameters. The sampling distribution of a sample statistic is then the
key way to DEMO how good of an estimate a sample statistic is. In addition, DEMO
use various sample statistics and their sampling distributions to make probabilistic
conclusions about statistical hypotheses, usually in the form of statements about
population parameters.
52
CHAPTER 3. REVIEW OF PROBABILITY
Much of the statistical analysis of DEMO is grounded in calcu-
lation of a sample statistic, computation of DEMO sampling distribution
(using a computer), and using the sampling distribution DEMO draw in-
ferences about statistical hypotheses.
3.8 Central limit theorem
The Gaussian (also called bell-shaped or Normal) distribution is a very common
one. DEMO central limit theorem (CLT) explains why many real-world variables
follow a Gaussian distribution.
It is worth reviewing here what “follows a particular distribution” DEMO means.
A random variable follows a particular distribution if the observed probability of
each outcome for a discrete random variable or the the observed DEMO of a
reasonable set of intervals for a continuous random variable are well approximated
by the corresponding probabilities of some named distribution (see Common Dis-
tributions, below). Roughly, this means that a histogram of DEMO actual random
outcomes is quite similar to the theoretical histogram of potential outcomes de-
ﬁned by the pmf (if discrete) or pdf (if continuous). For example, for any Gaussian
distribution with mean µ and standard deviation σ, we expect 2.3% of values to
fall below µ− 2σ, 13.6% to fall between µ−2σ and µ−σ, 34.1% between µ−σ DEMO µ,
34.1% between µ and µ+σ, 13.6% between µ+σ and DEMO, and 2.3% above µ+2σ.
In practice we would check a ﬁner DEMO of divisions and/or compare the shapes of
the actual and theoretical distributions either using histograms or a special tool
called the quantile-quantile plot.
DEMO non-mathematical language, the “CLT” says that whatever the pmf or pdf
DEMO a variable is, if we randomly sample a “large” number (say k) of independent
values from that random variable, the sum or DEMO of those k values, if collected
repeatedly, will have a Normal distribution. It takes some extra thought to un-
derstand what is going DEMO here. The process I am describing here takes a sample
of (DEMO) outcomes, e.g., the weights of all of the rats chosen DEMO an ex-
periment, and calculates the mean weight (or sum of weights). Then we consider
the less practical process of repeating the DEMO experiment many, many times
(taking a new sample of rats each time). If we would do this, the CLT says that a
histogram of all of these mean weights across all of these experiments DEMO show
3.8. CENTRAL LIMIT THEOREM
53
a Gaussian shape, even if the histogram of the individual weights of any one ex-
periment were not following DEMO Gaussian distribution. By the way, the distribution
of the means across DEMO experiments is usually called the “sampling distribution
of the mean”.
For practical purposes, a number as small as 20 (observations per experiment)
DEMO be considered “large” when invoking the CLT if the original distribution is
not very bizarre in shape and if we only want a reasonable DEMO to a
Gaussian curve. And for almost all original distributions, the DEMO k is, the closer
the distribution of the means or sums DEMO to a Gaussian shape.
It is usually fairly easy to ﬁnd the mean and variance of the sampling distri-
bution (see section3.7) of DEMO statistic of interest (mean or otherwise), but ﬁnding
the shape DEMO this sampling distribution is more diﬃcult. The Central Limit Theo-
rem lets us predict the (approximate) shape of the sampling distribution for sums
DEMO means. And this additional shape information is usually all that is needed to
construct valid conﬁdence intervals and/or p-values.
But wait, there’s more! The central limit theorem also applies to the sum
or mean of DEMO diﬀerent independent random variables as long as none of them
strongly dominates the others. So we can invoke the CLT as an explanation for DEMO
many real-world variables happen to have a Gaussian distribution. It is because
they are the result of many small independent eﬀects. For example, the weight
of 12-week-old rats varies around the mean weight of 12-week-old rats DEMO to a
variety of genetic factors, diﬀerences in food availability, diﬀerences in exercise,
diﬀerences in health, and a variety of other environmental factors, each of which
adds or subtracts a little bit relative to the overall mean.
See one of the theoretical statistics texts listed in DEMO bibliography for a proof
of the CLT.
The Central Limit Theorem is the explanation why many real-world
random variables tend to have a Gaussian DEMO It is also the
justiﬁcation for assuming that if we could repeat an experiment many
times, any sample mean that we calculate once per experiment would
follow a Gaussian distribution over the many experiments.
54
CHAPTER 3. REVIEW OF PROBABILITY
3.9 Common distributions
A brief description DEMO several useful and commonly used probability distributions
is given here. The casual reader will want to just skim this material, then use it
as reference material as needed.
The two types of distributions are discrete and DEMO (see above), which
are fully characterized by their pmf or DEMO respectively. In the notation section of
each distribution we use “X ∼” to mean “X is distributed as”.
What does it mean for a DEMO variable to follow a certain distribution? It
means that the pdf DEMO pmf of that distribution fully describes the probabilities
of events for that random variable. Note that each of the named distributions
described below are DEMO family of related individual distributions from which a spe-
ciﬁc distribution must be speciﬁed using an index or pointer into the family usually
called DEMO parameter (or sometimes using 2 parameters). For a theoretical discussion,DEMO
where we assume a particular distribution and then investigate what properties fol-
low, the pdf or pmf is all we need.
For data analysis, we usually need to choose a theoretical distribution that we
think will well approximate our measurement for the population from which our
sample was DEMO This can be done using information about what assumptions
lead to each distribution, looking at the support and shape of the sample distri-
bution, and using prior knowledge of similar measurements. Usually we choose a
family of distributions, then use statistical techniques to estimate the parameter
that chooses the particular distribution that best matches our data. Also, after
carrying out a statistical test that assumes a particular family of distributions, we
use model checking, such as residual analysis, to verify that our choice DEMO a good
one.
3.9.1 Binomial distribution
The binomial distribution is a discrete distribution that represents the number
of successes in n independent trials, each of which has success probability p. All of
the (inﬁnite) diﬀerent DEMO of n and p deﬁne a whole family of diﬀerent binomial
distributions. The outcome of a random variable that follows a binomial distribu-
tion DEMO a whole number from 0 to n (i.e., n+1 diﬀerent possible values). If n = 1,
the special name Bernoulli distribution DEMO be used. If random variable X fol-
lows a Bernoulli distribution with parameter p, then stating that Pr(X = 1) = p
3.9. COMMON DISTRIBUTIONS 55
and Pr(X = 0) = 1 − p fully deﬁnes the distribution of X.
If we let X represent DEMO random outcome of a binomial random variable with
parameters n and p, and let x represent any particular outcome (as a whole number
DEMO 0 to n), then the pmf of a binomial distribution tells us the probability that
the outcome will be x:
n! x! DEMO(1 − p)n−x.
Pr(X = x) = f (x) =
(n − x)!
As a reminder, the exclamation mark symbol is pronounced “factorial” and r!
represents the product of all the DEMO from 1 to r. As an exception, 0! = 1.
The DEMO, theoretical mean of a binomial distribution is np and the variance DEMO
npsample mean and variance will be similar to the theoretical values, DEMO the larger(1 − p). These refer to the ideal for an inﬁnite population. For a sample, the
the sample, the more DEMO we are that the sample mean and variance will be very
close to the theoretical values.
As an example, if you buy a lottery ticket for a daily lottery choosing your lucky
number each of 5 DEMO days in a lottery with a 1/500 chance of winning each
time, then knowing that these chances are independent, we could call DEMO number
of times (out of 5) that you win Y , and state that Y is distributed according to a
binomial distribution with DEMO = 5 and p = 0.002. We now know that if many people
each independently buy 5 lottery tickets they will each have an DEMO between 0
and 5, and the mean of all of those DEMO will be (close to) np = 5(0.002) = 0.01
DEMO the variance will be (close to)√0.0098 = 0.0999.) np(1 − p) = 5(0.002)(0.998) = 0.00998 (with
In DEMO example we can calculate n! = 5 · 4 · 3 · 2 · 1 = 120, and for x=2,
(n − DEMO)! = 3! = 3 · 2 · 1 = 6 and x! = 2! = 2 · 1 = 2. So
Pr(X DEMO 2) =  120  0.0022(0.998)3 = 0.0000398.
6 DEMO 2
Roughly 4 out of 100,000 people will win twice in 5 days.
It is sometimes useful to know that with large n DEMO binomial random variable
with parameter p approximates a Normal distribution with mean np and variance
np(1 − p) (except that there are DEMO in the binomial because it only takes on
whole numbers).
Common notation is X ∼ bin(n,p).
56
CHAPTER 3. REVIEW OF PROBABILITY
3.9.2 Multinomial distribution
The multinomial distribution DEMO a discrete distribution that can be used to
model situations where a subject has n trials each of which independently can
result in one DEMO k diﬀerent values which occur with probabilities (p1,p2,...,pk),
where p1 + p2 + ... + pk=1. The outcome of DEMO multinomial is a list of k numbers
adding up to n, DEMO of which represents the number of times a particular value
was achieved.
For random variable X following the multinomial distribution, the outcome is
the list of values (x1,x2,...,x3) and the pmf is:DEMO
Pr(X1 = x1,X2 = x2,...,X3 = x3) DEMO x1! · n! xk! !
x1 x2
p1 p2
···
xk
pk .
x2! ···
For example, consider a kind of candy that comes in an opaque bag and has
three colors (red, blue, and green) in diﬀerent amounts in each bag. If 30% of the
bags have red as the most common color, 20% have green, and DEMO have blue,
then we could imagine an experiment consisting of opening n randomly chosen
bags and recording for each bag which color was DEMO common. Here k = 3
and p1 = 0.30, p2 = DEMO, and p3 = 0.50. The outcome is three numbers, e.g.,
x1=number of times (out of 2) that red was most common, x2=number of times
blue is most common, and x3=number of times green is most common. If we
choose n=2, one calculation we can make is
Pr(x1 = 1,x2 = 1,x3 = 0) =
2! 0! ! 0.301 0.201 0.500 = 0.12
1! · 1! ·
DEMO the whole pmf can be represented in this tabular form (where DEMO of Reds”
means number of bags where red was most common, DEMO):
x1 (# of Reds) x2 (# of Blues) DEMO (# of Greens) Probability
2 0 0 0.09
0 2 0 0.04
0 0 2 0.25
1 1 0 0.12
1 0 1 DEMO
0 1 1 0.20
Common notation is X ∼ MN(n,p1,...,pk).
3.9. COMMON DISTRIBUTIONS
57
3.9.3 Poisson distribution
The Poisson distribution is a DEMO distribution whose support is the non-
negative integers (0, 1, DEMO,...). Many measurements that represent counts which
have no theoretical upper limit, such as the number of times a subject clicks on a
moving target on a computer screen in one minute, follow a Poisson distribution.
A Poisson distribution is applicable when the chance of a countable DEMO is pro-
portional to the time (or distance, etc.) available, when the chances of events in
non-overlapping intervals is independent, and when the chance of two events in a
very short interval is essentially DEMO
A Poisson distribution has one parameter, usually represented as λ (lambda).
The pmf is:
Pr(X = x) = f (DEMO) = e−λλx
x!
The mean is λ and the variance is DEMO λ. From the pmf, you can see that the
probability of DEMO events, Pr(X = 0), equals e−λ.
If the data DEMO a substantially larger variance than the mean, then a Poisson
distribution DEMO not appropriate. A common alternative is the negative binomial
distribution which has the same support, but has two parameters often denoted
p and r. The negative binomial distribution can be thought of as the number of
DEMO until the rth success when the probability of success is p for each trial.
It is sometimes useful to know that with large λ DEMO Poisson random variable
approximates a Normal distribution with mean λ and variance √λ (except that
there are gaps in the Poisson because it only takes on whole numbers).
Common notation is X ∼ Pois(λ)DEMO
3.9.4 Gaussian distribution
The Gaussian or Normal distribution is a continuous distribution with a sym-
metric, bell-shaped pdf curve as shown in Figure3.2. The members of this family
are characterized by two parameters, the mean and the variance (or standard de-
viation) usually written as µ and DEMO (or σ). The support is all of the real numbers,DEMO
but the “tails” are very thin, so the probability that X DEMO more than 4 or 5 standard
deviations from the mean is extremely small. The pdf of the Normal distribution
58
CHAPTER 3. REVIEW OF PROBABILITY
−5
0
X
5
10
Figure DEMO: Gaussian bell-shaped probability density function
is:
f (x) = DEMO(x−µ)2 .
2σ2
Among the family of Normal distributions, the DEMO normal distribution,
the one with µ = 0 and σ2 = 1 is special. It is the one for which you will ﬁnd
DEMO about the probabilities of various intervals in textbooks. This is useful
because the probability that the outcome will fall in, say, the interval DEMO minus
inﬁnity to any arbitrary number x for a non-standard normal distribution, say, X,
with mean µ = 0 and standard deviation DEMO = 1 is the same as the probability that
the outcome of a standard normal random variable, usually called Z, will be less
DEMO z = x−σµ , where the formula for z is the “z-score” formula.
Of course, there is not really anything “normal” about the Normal distribution,
so I always capitalize “Normal” or use Gaussian to remind DEMO that we are just
talking about a particular probability distribution, and DEMO making any judgments
about normal vs. abnormal. The Normal distribution is a very commonly used
density
0.00
0.04
0.08
0.12
3.9. COMMON DISTRIBUTIONS
59
distribution (see CLT, above). Also the DEMO distribution is quite ﬂexible in
that the center and spread can be set to any values independently. On the other
hand, every distribution that subjectively looks “bell-shaped” is not a Normal dis-
tribution. Some distributions are DEMO than Normal, with “thin tails” (negative
kurtosis). Some distributions are more “peaked” than a true Normal distribution
and thus have “fatter tails” (called positive kurtosis). An example of this is the
t-distribution (see below).
Common notation is X ∼ N(µ,σ2).
3.9.5 DEMO
The t-distribution is a continuous distribution with a symmetric, unimodal pdf
DEMO at zero that has a single parameter called the “degrees of freedom” (df).
In this context you can think of df as just an index or pointer which selects a
single distribution out of a DEMO of related distributions. For other ways to
think about df see section4.6. The support is all of the real numbers. The
t-distributions have fatter DEMO than the normal distribution, but approach the
shape of the normal DEMO as the df increase. The t-distribution arises most
commonly when evaluating how far a sample mean is from a population mean
when the standard DEMO of the sampling distribution is estimated from the
data rather than known. It is the fact that the standard deviation is an estimate
(i.e., a standard error) rather than the true value that causes the DEMO of the
distribution from Normal to t.
Common notation is X ∼ tdf .
3.9.6 Chi-square distribution
A chi-square distribution is a continuous distribution DEMO support on the pos-
itive real numbers whose family is indexed by a single “degrees of freedom” pa-
rameter. A chi-square distribution with df DEMO to a, commonly arises from the
sum of squares of a DEMO N(0,1) random variables. The mean is equal to
the DEMO and the variance is equal to twice the df.
Common notation is X ∼ χ2 .
df
60
CHAPTER 3. REVIEW OF PROBABILITY
3.9.7 F-distribution
The F-distribution is a DEMO distribution with support on the positive real
numbers. The family encompasses a large range of unimodal, asymmetric shapes
determined by two parameters which are usually called numerator and denomina-
tor degrees of freedom. The F-distribution is DEMO commonly used in analysis of
experiments. If X and Y are two independent chi-square random variables with
r and s df respectively, then X/r deﬁnes a new random variable that follows the
Y/s
F-distribution DEMO r and s df. The mean is s and the variance is a complicated
function of r and s. s−2
Common notation is X DEMO F(r,s).
Chapter 4
Exploratory Data Analysis
A ﬁrst look at the data.
As DEMO in Chapter 1, exploratory data analysis or “EDA” is a critical
DEMO step in analyzing the data from an experiment. Here are the main reasons we
use EDA:
• detection of mistakes
• checking of DEMO
• preliminary selection of appropriate models
• determining relationships among the explanatory variables, and
•
assessing the direction and rough size of relationships between explanatory
and outcome variables.
Loosely speaking, any method of looking at data that does not include formal
statistical modeling and inference falls under the DEMO exploratory data analysis.
4.1 Typical data format and the types of EDA
The data from an experiment are generally collected into a rectangular array (e.g.,
spreadsheet or database), most commonly with one row per DEMO subject
61
62
CHAPTER 4. EXPLORATORY DATA ANALYSIS
and one column for each subject DEMO, outcome variable, and explanatory
variable. Each column contains the numeric values for a particular quantitative
variable or the levels for a categorical variable. (Some more complicated experi-
ments require a more complex data layout.)
DEMO are not very good at looking at a column of numbers or a whole spread-
sheet and then determining important characteristics of the data. DEMO ﬁnd look-
ing at numbers to be tedious, boring, and/or overwhelming. Exploratory data
analysis techniques have been devised as an aid in DEMO situation. Most of these
techniques work in part by hiding certain aspects of the data while making other
aspects more clear.
Exploratory data analysis DEMO generally cross-classiﬁed in two ways. First, each
method is either non-graphical DEMO graphical. And second, each method is either
univariate or multivariate (usually just bivariate).
Non-graphical methods generally involve calculation of summary statistics,
DEMO graphical methods obviously summarize the data in a diagrammatic or pic-
torial way. Univariate methods look at one variable (data column) at a DEMO,
while multivariate methods look at two or more variables at a time to explore
relationships. Usually our multivariate EDA will be bivariate (looking at exactly
two variables), but occasionally it will involve three or DEMO variables. It is almost
always a good idea to perform univariate EDA on each of the components of a
multivariate EDA before performing the DEMO EDA.
Beyond the four categories created by the above cross-classiﬁcation, each DEMO the
categories of EDA have further divisions based on the role (DEMO or explana-
tory) and type (categorical or quantitative) of the DEMO(s) being examined.
Although there are guidelines about which EDA techniques DEMO useful in what
circumstances, there is an important degree of looseness DEMO art to EDA. Com-
petence and conﬁdence come with practice, experience, and close observation of
others. Also, EDA need not be restricted to techniques you have seen before;
sometimes you need to invent a DEMO way of looking at your data.
The four types of EDA are univariate non-graphical, multivariate non-
graphical, univariate graphical, and multivariate graphical.
This chapter ﬁrst discusses the non-graphical and graphical methods for looking
4.2. UNIVARIATE NON-GRAPHICAL EDA
63
at single variables, then moves on to looking at multiple variables at once, mostly
to investigate the relationships between the variables.
4.2 Univariate non-graphical EDA
The data that come from making DEMO particular measurement on all of the subjects in
a sample represent our observations for a single characteristic such as age, gender,
speed at a task, or response to a stimulus. We should think of these measurements
as representing a “sample distribution” of the variable, which in turn more or
less represents the “population distribution” of the variable. The usual DEMO of
univariate non-graphical EDA is to better appreciate the “sample distribution”
and also to make some tentative conclusions about what population distribution(s)
DEMO/are compatible with the sample distribution. Outlier detection is also a part of
this analysis.
4.2.1 Categorical data
The characteristics of interest for a DEMO variable are simply the range of
values and the frequency (or DEMO frequency) of occurrence for each value. (For
ordinal variables it is sometimes appropriate to treat them as quantitative vari-
ables using the techniques DEMO the second part of this section.) Therefore the only
useful univariate DEMO techniques for categorical variables is some form of
tabulation of the frequencies, usually along with calculation of the fraction (or
percent) of data that falls in each category. For example if we categorize subjects
by DEMO at Carnegie Mellon University as H&SS, MCS, SCS and “other”, then
there is a true population of all students enrolled in the 2007 Fall semester. If we
take a random sample of 20 students DEMO the purposes of performing a memory ex-
periment, we could list DEMO sample “measurements” as H&SS, H&SS, MCS, other,
DEMO, SCS, MCS, other, H&SS, MCS, SCS, SCS, other, MCS, MCS, H&SS, MCS,
other, H&SS, SCS. Our EDA would look like this:
Statistic/College H&SS MCS SCS other Total
Count 5 6 4 5 20
Proportion 0.25 DEMO 0.20 0.25 1.00
Percent 25% 30% 20% 25% 100%
Note that it is useful to have the total count (frequency) to verify that DEMO
64
CHAPTER 4. EXPLORATORY DATA ANALYSIS
have an observation for each subject DEMO we recruited. (Losing data is a common
mistake, and EDA is very helpful for ﬁnding mistakes.). Also, we should expect
that the proportions add up to 1.00 (or 100%) if we are calculating DEMO correctly
(count/total). Once you get used to it, you won’t need both proportion (relative
frequency) and percent, because they will be interchangeable in your mind.
A simple tabulation of the frequency of DEMO category is the best
univariate non-graphical EDA for categorical data.
4.2.2 Characteristics of quantitative data
Univariate EDA for a quantitative variable is a way DEMO make prelim-
inary assessments about the population distribution of the variable
using the data of the observed sample.
The characteristics of the population distribution DEMO a quantitative variable are
its center, spread, modality (number of DEMO in the pdf), shape (including “heav-
iness of the tails”), and outliers. (See section3.5.) Our observed data represent
just one sample out of an inﬁnite number of possible samples. The characteristics
of our DEMO observed sample are not inherently interesting, except to the degree
that DEMO represent the population that it came from.
What we observe in the sample of measurements for a particular variable that
we select for our DEMO experiment is the “sample distribution”. We need
to recognize that this would be diﬀerent each time we might repeat the same
experiment, due to selection of a diﬀerent random sample, a diﬀerent treatment
randomization, and DEMO random (incompletely controlled) experimental con-
ditions. In addition we can calculate “sample statistics” from the data, such as
sample mean, sample variance, sample standard deviation, sample skewness and
sample kurtosis. These again would vary for each repetition of the experiment, so
they don’t represent any deep truth, but rather represent some uncertain informa-
tion about the underlying population distribution and its parameters, which are
what we really care about.
4.2. UNIVARIATE NON-GRAPHICAL EDA
65
Many of the sample’s distributional characteristics are DEMO qualitatively in the
univariate graphical EDA technique of a histogram (see4.3.1)DEMO In most situations it
is worthwhile to think of univariate non-graphical EDA as telling you about aspects
of the histogram of the distribution of DEMO variable of interest. Again, these aspects
are quantitative, but because they refer to just one of many possible samples from
a population, they are best thought of as random (non-ﬁxed) estimates of the
ﬁxed, unknown parameters (see section3.5) of the distribution of the population
of DEMO
If the quantitative variable does not have too many distinct values, DEMO tabula-
tion, as we used for categorical data, will be a worthwhile univariate, non-graphical
technique. But mostly, for quantitative variables we are DEMO here with
the quantitative numeric (non-graphical) measures which are the various sam-
ple statistics. In fact, sample statistics are generally thought of as estimates of
the corresponding population parameters.
Figure4.1shows a histogram of a sample DEMO size 200 from the inﬁnite popula-
tion characterized by distribution C of ﬁgure3.1from section3.5. Remember that
in that section we examined the parameters that DEMO theoretical (pop-
ulation) distributions. Now we are interested in learning what we can (but not
everything, because parameters are “secrets of nature”) about these parameters
from measurements on a (random) sample of subjects DEMO of that population.
The bi-modality is visible, as is an outlier DEMO X=-2. There is no generally
recognized formal deﬁnition for outlier, but DEMO it means values that are outside
of the areas of a distribution that would commonly occur. This can also be thought
of as sample DEMO values which correspond to areas of the population pdf (or pmf)DEMO
with low density (or probability). The deﬁnition of “outlier” for DEMO boxplots
is described below (see4.3.3). Another common deﬁnition of “outlier” DEMO
any point more than a ﬁxed number of standard deviations from the mean to be
an “outlier”, but these and other deﬁnitions are arbitrary and vary from situation
to situation.
For quantitative variables (and possibly for ordinal variables) it is worthwhile
looking at the central tendency, spread, skewness, and kurtosis of the data for a
particular variable from an experiment. But for categorical variables, none of these
make any sense.
66
CHAPTER 4. EXPLORATORY DATA ANALYSIS
−2
−1
0
1
X
2
DEMO
4
Figure 4.1: Histogram from distribution C.
5
Frequency
0
5
DEMO
15
20
4.2. UNIVARIATE NON-GRAPHICAL EDA 67
4.2.3 Central tendency
The central tendency or DEMO of a distribution has to do with typical or
middle values. The common, useful measures of central tendency are the statis-
tics called (DEMO) mean, median, and sometimes mode. Occasionally other
means such as DEMO, harmonic, truncated, or Winsorized means are used as
measures of DEMO While most authors use the term “average” as a synonym
for arithmetic mean, some use average in a broader sense to also include geometric,
harmonic, and other means.
Assuming that we have n data values labeled x1 through xn, the formula for
calculating the sample (arithmetic) mean is
x¯ = P
n
The arithmetic mean is simply the DEMO of all of the data values divided by the
number of values. It can be thought of as how much each subject gets in DEMO “fair”
re-division of whatever the data are measuring. For instance, the DEMO amount
of money that a group of people have is the amount each would get if all of the
money were put in one DEMO, and then the money was redistributed to all people
evenly. I DEMO you can see that this is the same as “summing then dividing by n”.
For any symmetrically shaped distribution (i.e., one with a DEMO his-
togram or pdf or pmf) the mean is the point DEMO which the symmetry holds.
For non-symmetric distributions, the mean is the DEMO point”: if the histogram
is cut out of some homogeneous stiﬀ DEMO such as cardboard, it will balance on
a fulcrum placed at DEMO mean.
For many descriptive quantities, there are both a sample and DEMO population ver-
sion. For a ﬁxed ﬁnite population or for a theoretic inﬁnite population described
by a pmf or pdf, there is a single population mean which is a ﬁxed, often unknown,
value called the mean parameter (see section3.5). On the other hand, the “sam-
DEMO mean” will vary from sample to sample as diﬀerent samples are taken, and so is
a random variable. The probability distribution of the sample mean is referred to
as its sampling distribution. This term expresses the DEMO that any experiment
could (at least theoretically, given enough resources) DEMO repeated many times and
various statistics such as the sample mean can be calculated each time. Often
we can use probability theory to work DEMO the exact distribution of the sample
statistic, at least under certain DEMO
n
i=1 xi
.
The median is another measure of central tendency. The sample median is
68
CHAPTER 4. EXPLORATORY DATA ANALYSIS
the middle value after all of DEMO values are put in an ordered list. If there are an
even number of values, take the average of the two middle values. (DEMO there are ties
at the middle, some special adjustments are made DEMO the statistical software we
will use. In unusual situations for discrete random variables, there may not be a
unique median.)
For symmetric distributions, the mean and the median coincide. For unimodal
skewed (asymmetric) distributions, the mean is farther in the direction of the
“pulled out tail” of the distribution than the median is. Therefore, for many
cases of skewed distributions, the median is preferred as a measure of central
tendency. For example, according to the US Census Bureau 2004 Economic Survey,
the median income of US families, which represents the income above and below
which half of families fall, was $43,318. This seems a better measure of central
tendency than the mean of $60,828, which indicates how much each family would
have if we all shared equally. DEMO the diﬀerence between these two numbers is quite
substantial. Nevertheless, both DEMO are “correct”, as long as you understand
their meanings.
The median DEMO a very special property called robustness. A sample statistic
is “robust” if moving some data tends not to change the value of the statistic. DEMO
median is highly robust, because you can move nearly all of DEMO upper half and/or
lower half of the data values any distance away from the median without changing
the median. More practically, a few very high values or very low values usually
have no eﬀect on DEMO median.
A rarely used measure of central tendency is the mode, DEMO is the most likely
or frequently occurring value. More commonly we simply use the term “mode”
when describing whether a distribution has a single DEMO (unimodal) or two or
more peaks (bimodal or multi-modal). DEMO symmetric, unimodal distributions, the
mode equals both the mean and the median. In unimodal, skewed distributions
the mode is on the other side of the median from the mean. In multi-modal
distributions there is either DEMO unique highest mode, or the highest mode may well
be unrepresentative DEMO the central tendency.
The most common measure of central tendency is the mean. For
skewed distribution or when there is concern about outliers, the me-
dian may be preferred.
4.2. UNIVARIATE NON-GRAPHICAL EDA
69
4.2.4 Spread
Several statistics are commonly used DEMO a measure of the spread of a distribu-
tion, including variance, standard deviation, and interquartile range. Spread is an
indicator of how far away from the center we are still likely to ﬁnd data values.
DEMO variance is a standard measure of spread. It is calculated for a list of
numbers, e.g., the n observations of a particular measurement DEMO x1 through
xn, based on the n sample deviations (or just “deviations”). Then for any data
value, xi, the corresponding deviation DEMO (xi − x¯), which is the signed (- for lower
and + for higher) distance of the data value from the mean of all of the n data
values. It is not hard to DEMO that the sum of all of the deviations of a sample is
zero.
The variance of a population is deﬁned as the mean squared DEMO (see
section3.5.2). The sample formula for the variance of observed DEMO conventionally
has n−1 in the denominator instead of n to achieve the property of “unbiasedness”,
which roughly means that when calculated for many DEMO random samples
from the same population, the average should match the DEMO population
quantity (here, σ2). The most commonly used symbol for sample variance is s2,
and the formula is
s2 = P
DEMO
i=1(xi
−
(n − 1)
x¯
)2
which is essentially the average of the squared deviations, except for dividing by
n − 1 instead of n. This is a measure of spread, because the bigger the deviations
from the mean, the bigger the variance gets. (In most cases, squaring is better
than taking the absolute value DEMO it puts special emphasis on highly deviant
values.) As usual, a sample statistic like s2 is best thought of as a characteristic of
DEMO particular sample (thus varying from sample to sample) which is used as an esti-
mate of the single, ﬁxed, true corresponding parameter DEMO from the population,
namely σ2.
Another (equivalent) way to write the variance formula, which is particularly
useful for thinking about ANOVA is
s2 = SS
df
where SS is “sum of squared deviations”, often loosely called “sum of squares”,
and df is “degrees of freedom” (see section4.6).
70
CHAPTER 4. EXPLORATORY DATA ANALYSIS
Because of the square, variances are always non-negative, and they have the
somewhat unusual property of having squared units compared to the original data.
So if the random variable of DEMO is a temperature in degrees, the variance
has units “degrees squared”, and if the variable is area in square kilometers, the
variance is in units of “kilometers to the fourth power”.
Variances have the very DEMO property that they are additive for any
number of diﬀerent independent sources of variation. For example, the variance of
a measurement which has subject-to-subject variability, environmental variability,
and quality-of-measurement variability is equal to the sum of the three variances.
This property is not shared by the “standard DEMO
The standard deviation is simply the square root of the variance. Therefore
it has the same units as the original data, which helps make it more interpretable.
The sample standard deviation is usually represented by the DEMO s. For a
theoretical Gaussian distribution, we learned in the previous DEMO that mean
plus or minus 1, 2 or 3 standard deviations DEMO 68.3, 95.4 and 99.7% of the
probability respectively, and this should be approximately true for real data from
a Normal distribution.
The variance DEMO standard deviation are two useful measures of
spread. The variance is the mean of the squares of the individual
deviations. The standard deviation is DEMO square root of the variance.
For Normally distributed data, approximately 95% DEMO the values lie
within 2 sd of the mean.
A third measure of spread is the interquartile range. To deﬁne IQR, we
ﬁrst need to deﬁne the concepts of quartiles. The quartiles of a population or
DEMO sample are the three values which divide the distribution or observed data into
even fourths. So one quarter of the data fall below the DEMO quartile, usually written
Q1; one half fall below the second quartile (Q2); and three fourths fall below the
third quartile (Q3)DEMO The astute reader will realize that half of the values fall above
Q2, one quarter fall above Q3, and also that Q2 is DEMO synonym for the median.
Once the quartiles are deﬁned, it is DEMO to deﬁne the IQR as IQR = Q3 − Q1.
By deﬁnition, half of the values (and speciﬁcally the middle half) fall within an
interval whose width equals the IQR. If the data are more DEMO out, then the
IQR tends to increase, and vice versa.
4.2. UNIVARIATE NON-GRAPHICAL EDA
71
The IQR is a more robust measure DEMO spread than the variance or standard
deviation. Any number of values in the top or bottom quarters of the data can
be moved any DEMO from the median without aﬀecting the IQR at all. More
practically, DEMO few extreme outliers have little or no eﬀect on the IQR.
In contrast to the IQR, the range of the data is not very robust at all. The
range of a sample is the distance from DEMO minimum value to the maximum value:
range = maximum - minimum. If you collect repeated samples from a population,
the minimum, maximum and range tend to change drastically from sample to
sample, while the variance and standard deviation change less, and the IQR least
of all. The minimum and maximum of a sample may be useful for detecting
DEMO, especially if you know something about the possible reasonable values for
DEMO variable. They often (but certainly not always) can detect data entry errors
such as typing a digit twice or transposing digits (e.g., DEMO 211 instead of 21
and entering 19 instead of 91 for data that represents ages of senior citizens.)
The IQR has one more DEMO worth knowing: for normally distributed data
only, the IQR approximately equals 4/3 times the standard deviation. This means
that for Gaussian distributions, you can approximate the sd from the IQR by
calculating 3/4 DEMO the IQR.
The interquartile range (IQR) is a robust measure of spread.
4.2.5 Skewness and kurtosis
Two additional useful univariate descriptors are the DEMO and kurtosis of a dis-
tribution. Skewness is a measure of asymmetry. Kurtosis is a measure of “peaked-
ness” relative to a Gaussian shape. DEMO estimates of skewness and kurtosis are
taken as estimates of the corresponding population parameters (see section3.5.3).
If the sample skewness and kurtosis are calculated along with their standard errors,
we can roughly make conclusions DEMO to the following table where e is an
estimate of skewness and u is an estimate of kurtosis, and SE(e) and SE(DEMO) are
the corresponding standard errors.
72
CHAPTER 4. EXPLORATORY DATA ANALYSIS
Skewness (e) or kurtosis (u)
Conclusion
−2SE(e) < e < 2SE(e) not skewed
DEMO ≤−2SE(e) negative skew
e ≥ 2SE(e) positive skew
−2SE(u) < u < 2SE(u) not kurtotic
u ≤−2SE(u) negative kurtosis
u ≥ 2SE(u) positive kurtosis
For a positive skew, values far above the mode are more common than values far
below, and the reverse is true for a negative skew. When a sample (or distribution)
has positive kurtosis, then compared to a Gaussian DEMO with the same
variance or standard deviation, values far from the DEMO (or median or mode) are
more likely, and the shape DEMO the histogram is peaked in the middle, but with fatter
tails. DEMO a negative kurtosis, the peak is sometimes described has having “broader
DEMO than a Gaussian shape, and the tails are thinner, so that extreme values
are less likely.
Skewness is a measure of asymmetry. Kurtosis DEMO a more subtle mea-
sure of peakedness compared to a Gaussian distribution.
4.3 Univariate graphical EDA
If we are focusing on data from observation DEMO a single variable on n subjects, i.e.,
a sample of DEMO n, then in addition to looking at the various sample statistics
DEMO in the previous section, we also need to look graphically at DEMO distribu-
tion of the sample. Non-graphical and graphical methods complement each other.
While the non-graphical methods are quantitative and objective, they do not give
a full picture of the data; therefore, graphical methods, which are more qualitative
and involve a degree of subjective analysis, are also required.
4.3.1 Histograms
The only one of these techniques that makes sense for DEMO data is the
histogram (basically just a barplot of the tabulation DEMO the data). A pie chart
4.3. UNIVARIATE GRAPHICAL EDA
73
is equivalent, but not often used. The concepts of central tendency, spread and
skew have no meaning for nominal categorical data. For ordinal categorical data,
it sometimes makes sense to DEMO the data as quantitative for EDA purposes; you
need to use DEMO judgment here.
The most basic graph is the histogram, which is DEMO barplot in which each bar
represents the frequency (count) or proportion (count/total count) of cases for a
range of values. Typically DEMO bars run vertically with the count (or proportion)
axis running DEMO To manually construct a histogram, deﬁne the range of data
for DEMO bar (called a bin), count how many cases fall in DEMO bin, and draw the
bars high enough to indicate the count. DEMO the simple data set found inEDA1.dat
the histogram is shown in ﬁgure4.2. Besides getting the general impression of the
shape of the distribution, you can read oﬀ facts like “there are two cases with data
values DEMO 1 and 2” and “there are 9 cases with data values between 2 and
3”. Generally values that fall exactly on the boundary between DEMO bins are put
in the lower bin, but this rule is DEMO always followed.
Generally you will choose between about 5 and 30 bins, depending on the
amount of data and the shape of the distribution. Of course you need to see
the histogram to know the shape DEMO the distribution, so this may be an iterative
process. It is DEMO worthwhile to try a few diﬀerent bin sizes/numbers because,
especially with small samples, there may sometimes be a diﬀerent shape to the
histogram when the bin size changes. But usually the diﬀerence is small. DEMO
4.3shows three histograms of the same sample from a bimodal population using
three diﬀerent bin widths (5, 2 and 1). If you DEMO to try on your own, the
data are inEDA2.dat. The top DEMO appears to show a unimodal distribution.
The middle panel correctly shows the bimodality. The bottom panel incorrectly
suggests many modes. There is some art DEMO choosing bin widths, and although
often the automatic choices of a DEMO like SPSS are pretty good, they are
certainly not always adequate.
DEMO is very instructive to look at multiple samples from the same population to
get a feel for the variation that will be found in DEMO Figure4.4shows
histograms from multiple samples of size 50 from the same population as ﬁgure
4.3, while4.5shows samples of size 100. Notice that the variability is quite high,
especially for the smaller sample size, and that an incorrect impression (particularly
of unimodality) is quite possible, just by the bad luck of taking a particular sample.
74
CHAPTER 4. EXPLORATORY DATA ANALYSIS
0
2
4
X
6
8
DEMO 4.2: Histogram of EDA1.dat.
10
Frequency
0
2
4
6
8
DEMO
4.3. UNIVARIATE GRAPHICAL EDA
−5
0
5
10
15
20
25
X
DEMO
0
5
10
15
20
25
X
−5
0
5
10
15
20
25
X
Figure 4.3: Histograms of EDA2.dat with diﬀerent bin widths.
75
Frequency
0
2
4
6
8
Frequency
0
5
10
15
DEMO
0
5
15
25
0
0
0
2
2
2
Frequency
4
6
Frequency
4
6
DEMO
4
6
8
8
8
10
10
10
0
0
0
2
2
2
Frequency
4
6
Frequency
4
6
8
Frequency
4
6
DEMO
8
10
12
0
0
0
Frequency
2
4
6
8
Frequency
2
4
6
8
Frequency
2
4
6
10
8
76
CHAPTER DEMO EXPLORATORY DATA ANALYSIS
−5
0
5
10
X
20
−5
0
5
10
X
20
−5
0
5
10
X
20
−5
0
5
DEMO
X
20
−5
0
5
10
X
20
−5
0
5
10
X
20
−5
0
5
10
X
20
−5
0
5
10
DEMO
20
−5
0
5
10
X
20
Figure 4.4: Histograms of DEMO samples of size 50.
4.3. UNIVARIATE GRAPHICAL EDA
−5
0
5
10
X
20
−5
0
DEMO
10
X
20
−5
0
5
10
X
20
−5
0
5
10
X
20
−5
0
5
10
X
20
−5
0
5
DEMO
X
20
−5
0
5
10
X
20
−5
0
5
10
X
20
−5
0
5
10
X
20
Figure 4.5: Histograms of multiple samples of size 100.
77
0
0
0
Frequency
5
10
DEMO
5
10
Frequency
5
10
15
15
15
0
0
0
Frequency
5
10
15
Frequency
5
10
15
Frequency
5
10
20
20
DEMO
0
0
0
Frequency
5
10
Frequency
5
10
Frequency
5
10
15
15
15
78
CHAPTER 4. EXPLORATORY DATA ANALYSIS
With practice, histograms are one of the best ways to quickly learn
a lot about your data, including central tendency, spread, modality,
shape and outliers.
4.3.2 Stem-and-leaf plots
DEMO simple substitute for a histogram is a stem and leaf plot. A stem and leaf
plot is sometimes easier to make by hand than DEMO histogram, and it tends not to
hide any information. Nevertheless, a histogram is generally considered better for
appreciating the shape of a sample DEMO than is the stem and leaf plot.
Here is a stem and leaf plot for the data of ﬁgure4.2:
The decimal place is DEMO the "|".
1|000000
2|00
3|000000000
4|000000
5|00000000000
6|000
7|0000
8|0
DEMO
Because this particular stem and leaf plot has the decimal place at the stem,
each of the 0’s in the ﬁrst line represent DEMO, and each zero in the second line
represents 2.0, etc. So we can see that there are six 1’s, two 2’s etc. in our data.
A stem and leaf plot shows all data values and DEMO shape of the dis-
tribution.
4.3. UNIVARIATE GRAPHICAL EDA
l
79
Figure 4.6: A boxplot of the data from EDA1.dat.
4.3.3 Boxplots
Another very useful univariate graphical technique is DEMO boxplot. The boxplot
will be described here in its vertical format, DEMO is the most common, but a
horizontal format also is possible. DEMO example of a boxplot is shown in ﬁgure4.6,
which again represents the data inEDA1.dat.
Boxplots are very good at presenting information about the DEMO tendency,
symmetry and skew, as well as outliers, although they can be misleading about
aspects such as multimodality. One of the best DEMO of boxplots is in the form of
side-by-side boxplots (see multivariate DEMO analysis below).
Figure4.7is an annotated version of ﬁgure4.6. Here you can see that the
boxplot consists of a rectangular box bounded above and DEMO by “hinges” that
represent the quartiles Q3 and Q1 respectively, and DEMO a horizontal “median”
2
4
X
6
8
80
CHAPTER 4. EXPLORATORY DATA ANALYSIS
l
Upper whisker
IQR
Lower whisker
DEMO
Upper whisker end
Q3 or upper hinge
Median
Q1 or lower hinge
Lower whisker end
Figure 4.7: Annotated boxplot.
2
4
X
6
8
4.3. UNIVARIATE GRAPHICAL EDA
81
line through it. You can also see DEMO upper and lower “whiskers”, and a point
marking an “outlier”. The DEMO axis is in the units of the quantitative variable.
Let’s assume that the subjects for this experiment are hens and the data rep-
resent DEMO number of eggs that each hen laid during the experiment. We can read
certain information directly oﬀ of the graph. The median (not mean!) is 4 eggs,
so no more than half of the hens laid more than 4 eggs and no more than half of
the DEMO laid less than 4 eggs. (This is based on the technical DEMO of median;
we would usually claim that half of the hens lay more or half less than 4, knowing
that this may be only approximately correct.) We can also state that one quarter
of the hens lay less than 1 egg and one quarter lay more than DEMO eggs (again, this
may not be exactly correct, particularly for DEMO samples or a small number of
diﬀerent possible values). This leaves half of the hens, called the “central half”, to
lay between DEMO and 5 eggs, so the interquartile range (IQR) is Q3-Q1=5-3=2.
DEMO interpretation of the whiskers and outliers is just a bit more complicated.
Any data value more than 1.5 IQRs beyond its corresponding hinge in DEMO
direction is considered an “outlier” and is individually plotted. Sometimes values
beyond 3.0 IQRs are considered “extreme outliers” and are plotted with a diﬀerent
DEMO In this boxplot, a single outlier is plotted corresponding to 9 DEMO laid,
although we know from ﬁgure4.2that there are actually two hens that laid 9 eggs.
This demonstrates a general problem with plotting whole DEMO data, namely
that multiple points may be superimposed, giving a wrong impression. (Jittering,
circle plots, and starplots are examples of ways DEMO correct this problem.) This is
one reason why, e.g., combining DEMO tabulation and/or a histogram with a boxplot
is better than either alone.
Each whisker is drawn out to the most extreme data point DEMO is less than 1.5
IQRs beyond the corresponding hinge. Therefore, the DEMO ends correspond to
the minimum and maximum values of the data excluding the “outliers”.
Important: The term “outlier” is not well deﬁned in statistics, and the deﬁnition
varies depending on the purpose and situation. The “outliers” identiﬁed by a
boxplot, which could be called “boxplot outliers” are deﬁned as any points more
than 1.5 IQRs above Q3 or more than DEMO IQRs below Q1. This does not by itself
indicate a problem with those data points. Boxplots are an exploratory technique,
and you should DEMO designation as a boxplot outlier as just a suggestion that
the points might be mistakes or otherwise unusual. Also, points not designated
as boxplot outliers may also be mistakes. It is also important to realize that DEMO
number of boxplot outliers depends strongly on the size of the sample. In fact, for
82
CHAPTER 4. EXPLORATORY DATA ANALYSIS
data that is perfectly Normally distributed, we expect 0.70 percent (or about 1 in
150 cases) to DEMO “boxplot outliers”, with approximately half in either direction.
The boxplot information DEMO above could be appreciated almost as easily
if given in non-graphical format. The boxplot is useful because, with practice, all
of the above DEMO more can be appreciated at a quick glance. The additional things
you should notice on the plot are the symmetry of the distribution and DEMO
evidence of “fat tails”. Symmetry is appreciated by noticing if the median is in
the center of the box and if the whiskers are DEMO same length as each other. For
this purpose, as usual, the smaller the dataset the more variability you will see
from sample to DEMO, particularly for the whiskers. In a skewed distribution we
expect to DEMO the median pushed in the direction of the shorter whisker. If the
longer whisker is the top one, then the distribution is positively skewed (or skewed
to the right, because higher values are on the DEMO in a histogram). If the lower
whisker is longer, the DEMO is negatively skewed (or left skewed.) In cases
where the median is closer to the longer whisker it is hard to draw a DEMO
The term fat tails is used to describe the situation where a histogram has a lot
of values far from the mean relative to DEMO Gaussian distribution. This corresponds
to positive kurtosis. In a boxplot, many DEMO (more than the 1/150 expected
for a Normal distribution) suggests fat tails (positive kurtosis), or possibly many
data entry errors. Also, short whiskers suggest negative kurtosis, at least if the
sample size DEMO large.
Boxplots are excellent EDA plots because they rely on robust statistics like
median and IQR rather than more sensitive ones such as mean DEMO standard devi-
ation. With boxplots it is easy to compare distributions (DEMO for one variable
at diﬀerent levels of another; see multivariate graphical DEMO, below) with a high
degree of reliability because of the use of these robust statistics.
It is worth noting that some (few) DEMO produce boxplots that do not
conform to the deﬁnitions given here.
Boxplots show robust measures of location and spread as well as pro-
viding DEMO about symmetry and outliers.
4.3. UNIVARIATE GRAPHICAL EDA
83
Figure 4.8: A quantile-normal plot.
4.3.4 Quantile-normal plots
The ﬁnal univariate graphical EDA technique is the most complicated. It DEMO called
the quantile-normal or QN plot or more generality the quantile-quantile
or QQ plot. It is used to see how well a particular sample DEMO a particular
theoretical distribution. Although it can be used for any theoretical distribution,
we will limit our attention to seeing how well a DEMO of data of size n matches
a Gaussian distribution with mean and variance equal to the sample mean and
variance. By examining the quantile-normal DEMO we can detect left or right skew,
positive or negative kurtosis, and bimodality.
The example shown in ﬁgure4.8shows 20 data points that are approximately
normally distributed. Do not confuse a quantile-normal plot with a simple
DEMO plot of two variables. The title and axis labels are strong indicators that
this is a quantile-normal plot. For many computer programs, the word “quantile”
is also in the axis labels.
Many statistical tests have the DEMO that the outcome for any ﬁxed set
of values of the explanatory variables is approximately normally distributed, and
that is why QN plots are useful: if the assumption is grossly violated, the p-value
and conﬁdence DEMO of those tests are wrong. As we will see in the ANOVA
and regression chapters, the most important situation where we use a QN plot is
not for EDA, but for examining something called “residuals” (DEMO section9.4). For
84
CHAPTER 4. EXPLORATORY DATA ANALYSIS
basic interpretation of the QN plot DEMO just need to be able to distinguish the two
situations of “OK” (points fall randomly around the line) versus “non-normality”
(points follow a strong curved pattern rather than following the line).
If you are DEMO curious, here is a description of how the QN plot is
DEMO Understanding this will help to understand the interpretation,
but is not required in this course. Note that some programs swap the x
and DEMO axes from the way described here, but the interpretation is similar
DEMO all versions of QN plots. Consider the 20 values observed in this study.
They happen to have an observed mean of 1.37 and a DEMO deviation of
1.36. Ideally, 20 random values drawn from a distribution DEMO has a true
mean of 1.37 and sd of 1.36 have a perfect bell-shaped distribution and
will be spaced so that there is equal DEMO (probability) in the area around
each value in the bell curve.
In ﬁgure4.9the dotted lines divide the bell curve up into 20 equally
DEMO zones, and the 20 points are at the probability mid-points of DEMO
zone. These 20 points, which are more tightly packed near the DEMO than
in the ends, are used as the “Expected Normal Values” DEMO the QN plot of
our actual data.
In summary, the sorted DEMO data values are plotted against “Ex-
pected Normal Values”, and some DEMO of diagonal line is added to help
direct the eye towards a perfect straight line on the quantile-normal plot
that represents a perfect bell DEMO for the observed data.
The interpretation of the QN plot is given here. If the axes are reversed in
the computer package you are DEMO, you will need to correspondingly change your
interpretation. If all of DEMO points fall on or nearly on the diagonal line (with a
DEMO pattern), this tells us that a histogram of the variable will show a bell
shaped (Normal or Gaussian) distribution.
Figure4.10shows all of DEMO points basically on the reference line, but there
are several vertical DEMO of points. Because the x-axis is “observed values”, these
bands indicate DEMO, i.e., multiple points with the same values. And all of the
observed values are at whole numbers. So either the data are rounded DEMO we are
looking at a discrete quantitative (counting) variable. Either way, the data appear
4.3. UNIVARIATE GRAPHICAL EDA
85
−2
l
0
2
4
Expected Normal DEMO
l
l l l llllllllll l l l
l
l
Figure 4.9: A way to think about QN plots.
Density
0.00
0.05
0.10
0.15
0.20
0.25
0.30
86
CHAPTER 4. EXPLORATORY DATA ANALYSIS
Figure 4.10: Quantile-normal plot with ties.
to be nearly normally distributed.
In ﬁgure4.11note that we have many points DEMO a row that are on the same
side of the line (DEMO than just bouncing around to either side), and that suggests
that there is a real (non-random) deviation from Normality. The best way DEMO think
about these QN plots is to look at the low and high ranges of the Expected Normal
Values. In each area, see how the observed values deviate from what is expected,
i.e., in which “x” (Observed Value) direction the points appear to have moved
relative DEMO the “perfect normal” line. Here we observe values that are too high in
both the low and high ranges. So compared to a perfect DEMO shape, this distribution
is pulled asymmetrically towards higher values, which indicates positive skew.
Also note that if you just shift a distribution to DEMO right (without disturbing
its symmetry) rather than skewing it, it DEMO maintain its perfect bell shape, and
the points remain on the DEMO reference line of the quantile-normal curve.
Of course, we can also DEMO a distribution that is skewed to the left, in which
case DEMO high and low range points are shifted (in the Observed Value DEMO)
towards lower than expected values.
In ﬁgure4.12the high end points are shifted too high and the low end points
are shifted too low. DEMO data show a positive kurtosis (fat tails). The opposite
pattern DEMO a negative kurtosis in which the tails are too “thin” to be bell shaped.
4.3. UNIVARIATE GRAPHICAL EDA
Figure 4.11: Quantile-normal plot showing right skew.
Figure 4.12: Quantile-normal plot showing fat tails.
87
88
CHAPTER 4. EXPLORATORY DATA ANALYSIS
Figure 4.13: Quantile-normal plot showing a high outlier.
In ﬁgure4.13there is a single point that is oﬀ the DEMO line, i.e. shifted
to the right of where it should be. (Remember that the pattern of locations on
the Expected Normal Value axis DEMO ﬁxed for any sample size, and only the position
on the DEMO axis varies depending on the observed data.) This pattern shows
nearly DEMO data with one “high outlier”.
Finally, ﬁgure4.14looks a bit similar to DEMO “skew left” pattern, but the most
extreme points tend to return DEMO the reference line. This pattern is seen in bi-modal
data, e.g. DEMO is what we would see if we would mix strength measurements from
controls and muscular dystrophy patients.
Quantile-Normal plots allow detection of non-normality and DEMO
of skewness and kurtosis.
4.4 Multivariate non-graphical EDA
Multivariate non-graphical EDA techniques generally show the relationship be-
tween two or more variables in the DEMO of either cross-tabulation or statistics.
4.4. MULTIVARIATE NON-GRAPHICAL EDA
89
Figure 4.14: Quantile-normal plot showing bimodality.
4.4.1 Cross-tabulation
For categorical data (and quantitative data with only a few diﬀerent values) an
extension of tabulation called cross-tabulation is very useful. For two variables,
cross-tabulation is performed by making a two-way table with column DEMO
that match the levels of one variable and row headings that match the levels of
the other variable, then ﬁlling in the counts of all subjects that share a pair of
levels. The two variables might DEMO both explanatory, both outcome, or one of
each. Depending on the goals, row percentages (which add to 100% for each row),
column percentages (which add to 100% for each column) and/or DEMO percentages
(which add to 100% over all cells) are also useful.
Here is an example of a cross-tabulation. Consider the data in table4.1. DEMO
each subject we observe sex and age as categorical variables.
Table4.2shows the cross-tabulation.
We can easily see that the total number of young females DEMO 2, and we can
calculate, e.g., the corresponding cell percentage DEMO 2/11 × 100 = 18.2%, the row
percentage is 2/DEMO × 100 = 40.0%, and the column percentage is 2/7 DEMO 100 = 28.6%.
Cross-tabulation can be extended to three (and sometimes DEMO) variables by
making separate two-way tables for two variables at each DEMO of a third variable.
90
CHAPTER 4. EXPLORATORY DATA ANALYSIS
Subject ID
GW
JA
TJ
JMA
DEMO
JQA
AJ
MVB
WHH
JT
JKP
Age Group
young
middle
young
young
middle
old
old
young
old
young
middle
Sex
F
F
M
M
DEMO
F
F
M
F
F
M
Table 4.1: Sample Data for DEMO
Age Group / Sex
young
middle
old
Total
Female
2
2
3
7
Male
3
1
0
4
Total
5
3
3
11
Table DEMO: Cross-tabulation of Sample Data
For example, we could make separate age by gender tables for each education level.
Cross-tabulation is the basic bivariate DEMO EDA technique.
4.4.2 Correlation for categorical data
Another statistic that can be calculated for two categorical variables is their corre-
lation. But there are DEMO forms of correlation for categorical variables, and that
material is currently DEMO the scope of this book.
4.4. MULTIVARIATE NON-GRAPHICAL EDA
91
4.4.3 Univariate statistics by category
For one DEMO variable (usually explanatory) and one quantitative variable
(usually outcome), DEMO is common to produce some of the standard univariate non-
graphical statistics for the quantitative variables separately for each level of the
categorical variable, and then compare the statistics across levels of the categorical
variable. Comparing DEMO means is an informal version of ANOVA. Comparing
medians is a robust informal version of one-way ANOVA. Comparing measures of
spread is a good DEMO test of the assumption of equal variances needed for valid
analysis of variance.
Especially for a categorical explanatory variable and a quantitative
outcome variable, it is useful to produce a variety of univariate statis-
tics for DEMO quantitative variable at each level of the categorical vari-
able.
4.4.4 Correlation and covariance
For two quantitative variables, the basic statistics of interest are the sample co-
variance and/or sample correlation, which correspond to and are estimates of the
corresponding population parameters from section3.5. The sample covariance DEMO
a measure of how much two variables “co-vary”, i.e., how much (and in what
direction) should we expect one variable to change DEMO the other changes.
Sample covariance is calculated by computing (signed) deviations of
each measurement from the average of all measurements for that variable.
DEMO the deviations for the two measurements are multiplied together sepa-
rately for each subject. Finally these values are averaged (actually summed
and divided by n-1, to keep the statistic unbiased). Note that the units on
sample covariance are the products of the units of the two variables.
DEMO covariance values suggest that when one measurement is above the
mean the other will probably also be above the mean, and vice versa. Negative
92
CHAPTER 4. EXPLORATORY DATA ANALYSIS
covariances suggest that when one variable DEMO above its mean, the other is below its
mean. And covariances DEMO zero suggest that the two variables vary independently
of each other.
Technically, independence implies zero correlation, but the reverse is
not necessarily true.
DEMO tend to be hard to interpret, so we often use correlation DEMO
The correlation has the nice property that it is always between -1 and +1, with
-1 being a “perfect” negative linear correlation, +1 DEMO a perfect positive linear
correlation and 0 indicating that X and Y are uncorrelated. The symbol r or rx,y
is often used for DEMO correlations.
The general formula for sample covariance is
Cov(X,Y ) = P
n
i=1
(xi −
n − 1
x¯
)(yi −
y¯
)
It is worth noting that Cov(X,X) DEMO Var(X).
If you want to see a “manual example” of calculation of sample covari-
ance and correlation consider an example using the DEMO in table4.3. For
each subject we observe age and a strength measure.
Table4.4shows the calculation of covariance. The mean age is 50 and
the DEMO strength is 19, so we calculate the deviation for age as DEMO
and deviation for strength and strength-19. Then we ﬁnd the product of
the deviations and add them up. This total is 1106, and since n=11, the
covariance of x and y is -1106/10=-110.6. The fact that the covariance is
negative indicates that as age goes up strength DEMO to go down (and vice
versa).
The formula for the DEMO correlation is
Cor(X,Y ) = Cov(X,Y )
DEMO
4.4. MULTIVARIATE NON-GRAPHICAL EDA
where sx is the standard deviation of X DEMO sy is the standard deviation
of Y .
In this example, DEMO = 18.96, sy = 6.39, so
is a strong negative correlation.
r = −110.6
18.96·6.39 = −0.913. This
Subject ID
GW
JA
TJ
DEMO
JMO
JQA
AJ
MVB
WHH
JT
JKP
Age
38
62
22
38
45
69
75
38
80
32
51
Strength
20
15
30
21
DEMO
12
14
28
9
22
20
Table 4.3: Covariance Sample Data
DEMO
4.4.5 Covariance and correlation matrices
When we have many quantitative variables the most common non-graphical EDA
technique is to calculate all of the pairwise DEMO and/or correlations and
assemble them into a matrix. Note that the covariance of X with X is the variance
of X and the DEMO of X with X is 1.0. For example the covariance matrix
of table4.5tells us that the variances of X, Y , and Z are 5, 7, and 4 respectively,
the covariance of X and DEMO is 1.77, the covariance of X and Z is -2.24, and the
covariance of Y and Z is 3.17.
Similarly the correlation matrix DEMO ﬁgure4.6tells us that the correlation of X
and Y is 0.3, DEMO correlation of X and Z is -0.5. and the correlation of Y and Z
is 0.6.
94
CHAPTER 4. EXPLORATORY DATA ANALYSIS
Subject ID
GW
JA
TJ
JMA
DEMO
JQA
AJ
MVB
WHH
JT
JKP
Total
Age
38
62
22
38
45
69
75
38
80
32
51
Strength
20
15
30
21
DEMO
12
14
28
9
22
20
Age-50
-12
+12
-28
-12
-5
+19
+25
-12
+30
-18
+1
0
Str-19
+1
-4
+11
+2
DEMO
-7
-5
+9
-10
+3
+1
0
Table 4.4: Covariance Calculation
DEMO
-12
-48
-308
-24
+5
-133
-125
-108
-300
-54
+1
-1106
X
Y
Z
X
5.00
1.77
-2.24
Y
1.77
7.0
3.17
Z
DEMO
3.17
4.0
Table 4.5: A Covariance Matrix
The correlation between two DEMO variables is a number that runs
from -1 through 0 to +1 and indicates a strong inverse relationship,
no relationship, and a strong direct relationship, respectively.
4.5 Multivariate graphical EDA
There are few useful techniques for graphical EDA of two categorical random
variables. The only one used DEMO is a grouped barplot with each group rep-
resenting one level of one of the variables and each bar within a group representing
the DEMO of the other variable.
4.5. MULTIVARIATE GRAPHICAL EDA
X
Y
Z
X
1.0
0.3
-0.5
Y
DEMO
1.0
0.6
Z
-0.5
0.6
1.0
Table 4.6: A Correlation Matrix
DEMO
4.5.1 Univariate graphs by category
When we have one categorical (usually DEMO) and one quantitative (usually
outcome) variable, graphical EDA usually takes the form of “conditioning” on
the categorical random variable. This simply indicates DEMO we focus on all of
the subjects with a particular level of the categorical random variable, then make
plots of the quantitative variable for those subjects. We repeat this for each level
of the categorical variable, then compare the plots. The most commonly used of
these are side-by-side DEMO, as in ﬁgure4.15. Here we see the data from
EDA3.dat, which consists of strength data for each of three age groups. You can
DEMO the downward trend in the median as the ages increase. The spreads (IQRs)
are similar for the three groups. And all three groups are roughly symmetrical
with one high strength outlier in the youngest age DEMO
Side-by-side boxplots are the best graphical EDA technique for exam-
ining the relationship between a categorical variable and a quantitative
variable, as well as the distribution of the quantitative variable at each
level of the categorical DEMO
4.5.2 Scatterplots
For two quantitative variables, the basic graphical EDA technique DEMO the scatterplot
which has one variable on the x-axis, one on DEMO y-axis and a point for each case
in your dataset. If one variable is explanatory and the other is outcome, it is a
very, very strong convention to put the outcome on the y (vertical) axis.
One or two additional categorical variables can be accommodated on the DEMO
terplot by encoding the additional information in the symbol type and/or color.
96
CHAPTER 4. EXPLORATORY DATA ANALYSIS
l
(21,42]
(42,62]
DEMO Group
(62,82]
Figure 4.15: Side-by-side Boxplot of EDA3.dat.
Strength
10
15
20
25
30
35
l
l
l
l
l
20
30
40
50
60
70
Age
DEMO
80
Figure 4.16: scatterplot with two additional variables.
l
l
l
DEMO
l
l
l
l
l
l
l
l
l
ll
l
F/Dem
F/Rep
M/Dem
M/Rep
l
l
l
l
97
DEMO example is shown in ﬁgure4.16. Age vs. strength is shown, and DEMO colors
and symbols are used to code political party and gender.
In a nutshell: You should always perform appropriate EDA before
further analysis of your data. Perform whatever steps are necessary
to become more familiar with DEMO data, check for obvious mistakes,
learn about variable distributions, and learn about relationships be-
tween variables. EDA is not an exact science DEMO it is a very important
art!
4.5. MULTIVARIATE GRAPHICAL EDA
Strength
10
15
20
25
30
35
98
CHAPTER 4. EXPLORATORY DATA ANALYSIS
4.6 A note on degrees of DEMO
Degrees of freedom are numbers that characterize speciﬁc distributions in a family
of distributions. Often we ﬁnd that a certain family of distributions is DEMO in
a some general situation, and then we need to calculate DEMO degrees of freedom to
know which speciﬁc distribution within the family is appropriate.
The most common situation is when we have a particular statistic DEMO want to
know its sampling distribution. If the sampling distribution falls in the “t” family
as when performing a t-test, or in the “F” family when performing an ANOVA,
or in several other families, we need to ﬁnd the number of degrees of freedom to
ﬁgure out DEMO particular member of the family actually represents the desired
sampling distribution. One way to think about degrees of freedom for a statistic is
that DEMO represent the number of independent pieces of information that go into
the calculation of the statistic,
Consider 5 numbers with a mean of DEMO To calculate the variance of these
numbers we need to sum the squared deviations (from the mean). It really doesn’t
matter whether the mean is 10 or any other number: as long as all ﬁve deviations
are the same, the variance will be the same. This make sense because variance is a
pure measure of spread, not aﬀected by central tendency. But by mathematically
rearranging the deﬁnition of mean, it is not too hard to show that the sum of
the deviations (not squared) is always zero. Therefore, the ﬁrst four deviations
can (freely) be any numbers, but then the last one is forced to DEMO the number
that makes the deviations add to zero, and we DEMO not free to choose it. It is in
this sense that ﬁve numbers used for calculating a variance or standard deviation
have only four DEMO of freedom (or independent useful pieces of information).
In general, a variance or standard deviation calculated from n data values and one
DEMO has n − 1 df.
Another example is the “pooled” variance from k independent groups. If the
sizes of the groups are n1 through DEMO, then each of the k individual variance
estimates is based on DEMO from a diﬀerent mean, and each has one less
degree of DEMO than its sample size, e.g., ni − 1 for group i. We also say that
each numerator of a variance estimate, e.g., DEMO variance is i, has ni− 1 df. The pooled estimate
spooled2 DEMO SS1 + ··· + SSk
df1 + ··· + dfk
and we say that both the numerator SS and the entire pooled variance has DEMO
4.6. A NOTE ON DEGREES OF FREEDOM
99
dfk degrees of freedom, which suggests how many independent pieces of information
are available for the DEMO
100
CHAPTER 4. EXPLORATORY DATA ANALYSIS
Chapter 5
Learning SPSS: Data and EDA
An introduction to SPSS with emphasis on EDA.
SPSS (now called PASW Statistics, but still referred DEMO in this document as
SPSS) is a perfectly adequate tool for DEMO data, creating new variables, per-
forming EDA, and performing formal DEMO analyses. I don’t have any special
endorsement for SPSS, other than DEMO fact that its market dominance in the social
sciences means that there is a good chance that it will be available to you wherever
DEMO work or study in the future. As of 2009, the current DEMO is 17.0, and class
datasets stored in native SPSS format in DEMO 17.0 may not be usable with older
versions of SPSS. (Some DEMO shots shown here are not updated from previous
versions, but all DEMO procedures have been updated.)
For very large datasets, SAS tends DEMO be the best program. For creating custom
graphs and analyses R, DEMO is free, or the commercial version, S-Plus, are best,
DEMO R is not menu-driven. The one program I strongly advise against is Excel (or
any other spreadsheet). These programs have quite limited statistical facilities,
discourage structured storage of data, and have no facility for documenting your
work. This latter deﬁcit is critical! For any serious analysis DEMO must have a com-
plete record of how you created new variables and produced all of your graphical
and statistical output.
It is very DEMO that you will ﬁnd some error in your data at some point.
So it is highly likely that you will need to repeat all DEMO your analyses, and that
is painful without exact records, but easy or automatic with most good software.
Also, because it takes a long time from analysis to publishing, you will need these
101
102
CHAPTER 5. LEARNING SPSS: DATA AND EDA
records to remind yourself of exactly which steps you performed.
As hinted above, the basic steps you will take with most experimental data are:
1.Enter the data DEMO SPSS, or load it into SPSS after entering it into another
DEMO
2.Create new variables from old variables, if needed.
3.Perform exploratory data DEMO
4.Perform conﬁrmatory analyses (formal statistical procedures).
5.Perform model checking and DEMO comparisons.
6.Go back to step 4 (or even 2), if DEMO 5 indicates any problems.
7.Create additional graphs to communicate results.
Most people will ﬁnd this chapter easier to read when SPSS is running in DEMO
of them. There is a lot of detail on getting started and basic data management.
This is followed by a brief compilation of instructions DEMO EDA. The details of
performing other statistical analyses are at the end of the appropriate chapters
throughout this book.
Even if you are someone DEMO is good at jumping in to a computer program
without reading the instructions, I urge you to read this chapter because otherwise
you are likely to miss some of the important guiding principles of SPSS.
Additional DEMO resources may be found at
http://www.stat.cmu.edu/∼hseltman/SPSSTips.html.
5.1 Overview of SPSS
SPSS is a multipurpose data storage, graphical, and statistical DEMO At (almost)
all times there are two window types available, the Data Editor window(s) which
each hold a single data “spreadsheet”, and the Viewer window from which analyses
are carried out and results are viewed.
The Data Editor has two views, selected by tabs at the bottom of the window.
The Data View is a spreadsheet which DEMO the data in a rectangular format with
5.1. OVERVIEW OF SPSS
103
cases as rows and variables as columns. DEMO can be directly entered or imported
from another program using menu commands. (Cut-and-paste is possible, but not
advised.) Errors in data entry can also be directly corrected here.
You can also use menu commands in DEMO Data View to create new variables,
such as the log of an existing variable or the ratio of two variables.
The Variable View DEMO of the Data Editor is used to customize the information
about each variable and the way it is displayed, such as the number of decimal
places for numeric variables, and the labels for categorical variables coded as num-
bers.
The Viewer window shows the results of EDA, including graph production, for-
mal statistical analyses, and model checking. Most data DEMO can be carried
out using the menu system (starting in either DEMO), but some uncommon anal-
yses and some options for common analyses are only accessible through “Syntax”
(native SPSS commands). Often a special option is accessed by using the Paste
button found in most main DEMO boxes, and then typing in a small addition.
(More details on these variations is given under the speciﬁc analyses that require
them.)
DEMO throughout SPSS, each time you carry out a task through a DEMO, the
underlying non-menu syntax of that command is stored by SPSS, and can be
examined, modiﬁed and saved for documentation or reuse. In many situations,
there is a “Paste” button which takes you to DEMO “syntax window” where you can see
the underlying commands that would have been executed had you pressed OK.
SPSS also has a complete help DEMO and an advanced scripting system.
You can save data, syntax, and graphical and statistical output separately, in
various formats whenever you wish. (DEMO anything created in an earlier pro-
gram version is readable by later versions, but not vice versa.) Data is normally
saved in a DEMO SPSS format which few other programs can understand, but
universal formats DEMO “comma separated values” are also available for data inter-
change. You will be warned if you try to quit without saving changes to your DEMO,
or if if you forget to save the output from data analyses.
As usual with large, complex programs, the huge number of DEMO items avail-
able can be overwhelming. For most users, you will DEMO need to learn the basics
of interaction with the system and a small subset of the menu options.
Some commonly used menu items can DEMO quickly accessed from a toolbar, and
learning these will make you DEMO eﬃcient in your use of SPSS.
104
CHAPTER 5. LEARNING SPSS: DATA AND EDA
SPSS has a few quirks; most notably there are several places where you can
make selections, and then are supposed to click Change before clicking OK. If you
forget to click Change your changes are often silently forgotten. Another quirk
DEMO is well worth remembering is this: SPSS uses the term Factor DEMO refer to any
categorical explanatory variable. One good “quirk” is the Dialog Recall toolbar
button. It is a quick way to re-access previous data DEMO dialogs instead of
going through the menu system again.
5.2 Starting SPSS
Note: SPSS runs on Windows and Mac operating systems, but the DEMO of these
notes is Windows. If you are unfamiliar with Windows, DEMO link
Top 10 tips for Mac users getting started with Windowsmay help.
Assuming that SPSS is already installed on your computer system, just choose
it from the Windows Start menu or double click its icon to DEMO The ﬁrst screen
you will see is shown in ﬁgure5.1and gives several choices including a tutorial
and three choices that we will mainly use: “Type in data”, “Open an existing data
source”, and “Open another DEMO of ﬁle”. “Type in data” is useful for analyzing
small data sets not available in electronic form. “Open an existing data source”
is used DEMO opening data ﬁles created in SPSS. “Open another type of ﬁle” is used
for importing data stored in ﬁles not created by SPSS. After DEMO your choice,
click OK. Clicking Cancel instead of OK is the same as choosing “Type in data”.
Use Exit from the File menu DEMO you are ready to quit SPSS.
5.3 Typing in data
To enter your data directly into SPSS, choose “Type in data” from the opening
screen, or, if you are not at the opening screen, choose New then Data from the
File menu.
The window titled “Untitled SPSS DEMO Editor” is the Data Editor window
which is used to enter, DEMO and modify data. You can also start statistical analyses
from this window. Note the tabs at the bottom of the window labeled “Data View”
DEMO “Variable View”. In Data View (5.2), you can view, enter, and edit data for
all of your cases, while in Variable DEMO (5.3), you can view, enter, and edit
5.3. TYPING IN DATA
Figure 5.1: SPSS intro screen.
105
106
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.2: Data DEMO window: Data View.
Figure 5.3: Data Editor window: Variable View.
5.3. TYPING IN DATA
107
information about the variables themselves (see below). Also note the menu and
toolbar at the top of the DEMO You will use these to carry out various tasks
related to data entry and analysis. There are many more choices than needed by
a DEMO user, so don’t get overwhelmed! You can hover the mouse pointer DEMO
any toolbar button to get a pop-up message naming its function. This chapter
will mention useful toolbar items as we go along. (Note: DEMO items that are
inappropriate for the current context are grayed out.)
Before manually entering data, you should tell SPSS about the individual vari-
ables, which means that you should think about variable types and coding before
entering the data. Remember that the two data types are categorical DEMO quan-
titative and their respective subtypes are nominal and ordinal, and DEMO and
continuous. These data type correspond to the Measure column in the Variable
View tab. SPSS does not distinguish between discrete and continuous, so it calls
all quantitative variables “scale”. Ordinal and nominal variables are the DEMO
options for Measure. In many parts of SPSS, you will see DEMO visual reminder of
the Measure of your variables in the form of icons. A small diagonal yellow rule
indicates a “scale” variable (with a superimposed calendar or clock if the data hold
dates or times). DEMO small three level bar graph with increasing bar heights indicates
an “ordinal” variable. Three colored balls with one on top and two below indicates
DEMO data (with a superimposed “a” if the data are stored as DEMO instead
of numbers).
Somewhat confusingly SPSS Variable View has a column called Type which is
the “computer science” type rather than the “statistics” DEMO type. The choices
are basically numeric, date and string with various DEMO formats. This course
does not cover time series, so we won’t DEMO the “date” Type. Probably the only use
for the “string” Type is for alphanumeric subject identiﬁers (which should be as-
signed “nominal” Measure). All standard variables should be entered as numbers
(quantitative variables) or DEMO codes (categorical variables). Then, for cate-
gorical variables, we DEMO want to use the Values column to assign meaningful
labels to the numeric codes.
Note that, in general, to set or change something DEMO the Data Editor, you ﬁrst
click in the cell whose row DEMO column correspond to what you want to change,
then type the new information. To modify, rather than fully re-type an entry, press
DEMO key labeled “F2”.
When entering a variable name, note that periods DEMO underscores are allowed
in variable names, but spaces and most other DEMO marks are not. The
108
CHAPTER 5. LEARNING SPSS: DATA AND EDA
variable name must start with a letter, may contain digits, and must not end with
DEMO period. Variable names can be at most 64 characters long, are DEMO case sensitive,
and must be unique. The case that you enter is preserved, so it may be useful to
mix case, e.g., hotDogsPerHour to improve readability.
In either View of the Data Editor, you can neaten your work by dragging the
vertical bar between columns to DEMO column widths.
After entering the variable name, change whichever other column(DEMO) need to be
changed in the Variable View. For many variables DEMO includes entering a Label,
which is a human-readable alternate name for each variable. It may be up to
255 characters long with no DEMO on what you type. The labels replace the
variable names on much of the output, but the names are still used for specifying
variables for analyses.
Figure 5.4: Values dialog box.
For categorical variables, you DEMO almost always enter the data as numeric codes
(Type “numeric”), DEMO then enter Labels for each code. The Value Labels dialog
box (DEMO) is typical of many dialog boxes in SPSS. To enter Values DEMO a variable,
click in the box at the intersection of the variable’s row and the Value column in
the Variable View. Then click DEMO the “...” icon that appears. This will open the
“Value Labels” dialog box, into which you enter the words or phrases that label
each level of your categorical variable. Value labels can contain anything you like
DEMO to 255 characters long. Enter a level code number in the Value box, press Tab,
then enter the text for that level in the Value Label box. Finally you must click
the Add button for DEMO entry to be registered. Repeat the process as many times
as needed to code all of the levels of the variable. When you are DEMO, verify
5.3. TYPING IN DATA
109
that all of the information in the DEMO unlabeled box is correct, then click OK to
complete the process. DEMO any time while in the Value Label box (initially or in
DEMO future), you can add more labels; delete old labels by DEMO on the variable
in the large box, then clicking the Delete DEMO; or change level values or labels
by selecting the variable in DEMO large box, making the change, then clicking the
Change button. Version 16 has a spell check button, too.
If your data has missing values, you should use the Missing column of the
Variable View to let SPSS know the missing value code(s) for each variable.
The only other commonly used column in Variable View is the Measure column
DEMO above. SPSS uses the information in the column sporadically. Some-
times, DEMO certainly not always, you will not be able carry out the DEMO you
want if you enter the Measure incorrectly (or forget to DEMO it). In addition, setting
the Measure assures that you appropriately DEMO about the type of variable you
are entering, so it is DEMO really, really good idea to always set it.
Once you have DEMO all of the variable information in Variable View, you will
switch DEMO Data View to enter the actual data. At it’s simplest, you DEMO just click
on a cell and type the information, possibly using DEMO “F2” key to edit previously
entered information. But there are several ways to make data entry easier and
more accurate. The tab key moves DEMO through your data case by case, covering
all of the variables DEMO one case before moving on to the next. Leave a cell blank (or
delete its contents) to indicate “missing data”; missing data are displayed with a
dot in the spreadsheet (but don’t type a dot).
The Value Labels setting, accessed either through its toolbar button (DEMO
looks like a gift tag) or through the View menu, controls both whether columns
with Value Labels display the value or the label, and the behavior of those columns
during data entry. If Value Labels DEMO turned on, a “...” button appears when you
enter a cell DEMO the Data View spreadsheet that has Value Labels. You can click the
button to select labels for entry from a drop down box. Also, when Value Labels
is on, you can enter data either as the code or by typing out the label. (In any
case the code is what is stored.)
You should use Save (or Save as) from the File menu to save your data after
every data entry session and after any edits to your data. Note that in the DEMO
Data As” dialog box (5.5) you should be careful that the “Save in:” box is set
to save your data in the DEMO you want (so that you can ﬁnd it later). Enter
DEMO ﬁle name and click “Save” to save your data for future use. Under “Save as
type:” the default is “SPSS” with a “.sav” DEMO This is a special format that
110
CHAPTER 5. LEARNING SPSS: DATA AND EDA
can be read quickly by SPSS, but not at all by most other programs. For data
exchange between programs, several other export formats are allowed, with Excel
DEMO “Comma separated values” being the most useful.
Figure 5.5: Save Data DEMO dialog box.
5.4 Loading data
To load in data when you ﬁrst start SPSS, your can select a ﬁle in one of the two
lower boxes of the “Intro Screen”. At any other time you can DEMO data from the
File menu by selecting Open, then Data. This DEMO the “Open File” dialog box
(5.6).
It’s a good idea DEMO save any changes to any open data set before opening a new
ﬁle. In the Open File dialog box, you need to ﬁnd the ﬁle by making appropriate
choices for “Look in:” and “Files of DEMO:”. If your ﬁle has a “.txt” extension and
you are looking for ﬁles of type “.dat”, you will not be able to ﬁnd your ﬁle. As
a last resort, try looking for ﬁles of type “all ﬁles(*.*)”. Click Open after ﬁnding
your ﬁle.
If your DEMO is a native SPSS “.sav” ﬁle, it will open immediately. If DEMO is of
another type, you will have to go through some DEMO dialogs. For example, if
5.4. LOADING DATA
111
Figure 5.6: Open File dialog box.
you open an Excel ﬁle (.xls), you will see the “Opening Excel Data Source” dialog
box (5.7). Here you use a check box to tell SPSS whether or not your data has
variable names in the DEMO row. If your Excel workbook has multiple worksheets
you must select the one you want to work with. Then, optionally enter a Range
of rows and columns if your data does not occupy the entire range DEMO used cells in
the worksheet. Finish by clicking OK.
Figure 5.7: DEMO Excel Data Source dialog box.
112
CHAPTER 5. LEARNING SPSS: DATA AND EDA
The other useful type of data import is one of the simple forms of human-
readable DEMO such as space or tab delimited text (usually .dat or .txt) or comma
separated values (.csv). If you open one of these ﬁles, the “Text Import Wizard”
dialog box will open. The rest of this section describes the use of the text import
wizard.
Figure 5.8: Text Import Wizard - Step 1 of 6.
In “Step 1 of DEMO (5.8) you will see a question about predeﬁned formats which
we will skip (as being beyond the scope of this course), and below you will see
some form of the ﬁrst four lines of DEMO ﬁle (and you can scroll down or across to
see the DEMO ﬁle). (If you see strange characters, such as open squares, your ﬁle
probably has non-printable characters such as tab character in it.) Click Next to
continue.
In “Step 2 of 6” (5.9) you will see two very important questions that you must
answer accurately. The DEMO is whether your ﬁle is arranged so that each data col-
umn always starts in exactly the same column for every line of data (called “Fixed
width”) or whether there are so-called delimiters between the variable columns
(also called “ﬁelds”). Delimiters are usually either commas, tab DEMO or one
or more spaces, but other delimiters occasionally are seen. DEMO second question
is “Are variable names include at the top of the ﬁle?” Answer “no” if the ﬁrst
5.4. LOADING DATA
113
Figure 5.9: Text Import Wizard - Step 2 of 6.
line of the ﬁle is data, and “yes” if the ﬁrst line is made of column headers. After
answering these questions, click Next to continue.
In “Step 3 of 6” (5.10) your ﬁrst DEMO is to input the line number of the ﬁle
that has the ﬁrst real data (as opposed to header lines or blank lines). Usually
this is line 2 if there is a header line and DEMO 1 otherwise. Next is “How are your
cases represented?” Usually the default situation of “Each line represents a case”
is true. Under “How DEMO cases do you want to import?” you will usually use the
default of “All of the cases”, but occasionally, for very large DEMO sets, you may
want to play around with only a subset DEMO the data at ﬁrst.
In “Step 4 of 6” (5.11) you must answer the questions in such a way as to
make the DEMO preview” correctly represent your data. Often the defaults are
OK, but DEMO always. Your main task is to set the delimiters between the data
ﬁelds. Usually you will make a single choice among “Tab”, “Space”, DEMO,
and “Semicolon”. You may also need to specify what sets oﬀ text, e.g. there may
be quoted multi-word phrases in a space separated ﬁle.
If your ﬁle has ﬁxed width format instead of delimiters, “Step 4 of 6” has an
alternate format (5.12). Here you set the divisions between data columns.
114
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.10: Text DEMO Wizard - Step 3 of 6.
Figure 5.11: Text Import Wizard DEMO Step 4 of 6.
5.4. LOADING DATA
Figure 5.12: Text Import Wizard - Alternate Step 4 of 6.
Figure 5.13: Text Import Wizard - Step 5 of 6.
115
116
CHAPTER 5. LEARNING SPSS: DATA AND EDA
In “Step 5 of 6” (5.13) you will have the chance to change the names DEMO variables
and/or the data format (numeric, data or string). Ordinarily you don’t need to do
anything at this step.
Figure 5.14: Text Import Wizard - Step 6 of 6.
In “Step 6 of DEMO (5.14) you will have the chance to save all of your previous
choices to simplify future loading of a similar ﬁle. We won’t DEMO this feature in this
course, so you can just click the DEMO button.
The most common error in loading data is forgetting to specify the presence of
column headers in step 2. In that case the DEMO header (variable names) appear
as data rather than variable names.
5.5 Creating new variables
Creating new variables (data transformation) is commonly needed, and can be
somewhat complicated. Depending on what you are trying to DEMO, one of several
menu options starts the process.
For creating of DEMO simple data transformation, which is the result of applying a
mathematical DEMO to one or more existing variables, use the ComputeVariable
5.5. CREATING NEW VARIABLES
117
Figure 5.15: Compute Variable dialog box.
118
CHAPTER 5. LEARNING SPSS: DATA AND EDA
item on the Transform menu of the Data Editor. This open the Compute Variable
dialog box (5.15). First enter a new variable name in the Target Variable DEMO
(remembering the naming rules discussed above). Usually you will want DEMO click
the “Type & Label” box to open another dialog box which allows you to enter
a longer, more readable Label for the variable. (You will almost never want to
change the type to “String”.) DEMO Continue after entering the Label. Next you
will enter the “Numeric Expression” in the Compute Variable dialog box. Two
typical expressions are “log(weight)DEMO which creates the new variable by the taking
the log of the existing variable “weight”, and “weight/height**2” which computes
the body mass index from height and weight by dividing weight by the square
(second power) of the height. (Don’t enter the quotation marks.)
To create DEMO transformation, use whatever method you can to get the required
Numeric DEMO into the box. You can either type a variable name or double
click it in the variable list to the left, or single click it and click the right arrow.
Spaces don’t matter (except within variable names), and standard order of op-
erations are used, but can be overridden with parentheses as needed. Numbers,
operators (including * for times), and function names can be entered by clicking
the mouse, but direct typing is usually faster. In addition to the help system, the
list of functions may be helpful for ﬁnding the spelling of DEMO function, e.g., sqrt for
square root.
Comparison operators (such as DEMO, <. and >) can be used with the under-
standing DEMO the result of any comparison is either “true”, coded as 1, or “false”,
coded as 0. E.g., if one variable called “vfee” has numbers indicating the size
of a fee, and a variable called “surcharge” is 0 for no surcharge and 1 for a $25
surcharge, then we could create a new variable called “total” with the expression
DEMO(surcharge=1)”. In that case either 25 (25*1) or 0 (DEMO) is added to
“vfee” depending of the value of “surcharge”.
Advanced: To transform only some cases and leave others as “missing data”
use DEMO “If” button to specify an expression that is true only for the cases that
need to be transformed.
Some other functions worth knowing about DEMO ln, exp, missing, mean, min,
max, rnd, and sum. The function ln() takes the natural log, as opposed to log(),
which is common log. The function exp() is DEMO anti-log of the natural log, as op-
posed to 10**x which DEMO the common log’s anti-log. The function missing() returns
1 if the variable has missing data for the case in question or 0 otherwise. DEMO func-
tions min(), max(), mean() and sum(), used with several variables separated with
5.5. CREATING NEW VARIABLES
119
commas inside the parentheses, computes a new value for each case from several
existing variables for that case. The DEMO rnd() rounds to a whole number.
5.5.1 Recoding
In addition to simple transformations, we often need to create a new variable that
is a recoding of an old variable. This is usually used either to DEMO categories
in a categorical variable or to create a categorical version of a quantitative variable
by “binning”. Although it is possible to over-write the DEMO variable with the
new one, I strongly suggest that you always DEMO the old variable (for record
keeping and in case you make DEMO error in the encoding), and therefore you should
use the ’into Diﬀerent Variables” item under “Recode” on the “Transform” menu,
which opens DEMO “Recode into Diﬀerent Variables” dialog box (5.16).
Figure 5.16: Recode into Diﬀerent Variables Dialog Box.
First enter the existing variable name into DEMO “Input Variable -¿ Output Vari-
able” box. If you have several variables that need the same recoding scheme, enter
each of them before proceeding. Then, for each existing variable, go to the “Output
Variable” box DEMO enter a variable Name and Label for the new recoded variable,
and conﬁrm the entry with the Change button.
120
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.17: Recode DEMO Diﬀerent Variables: Old and New Values Dialog Box.
Then click the DEMO and New Values” button to open the “Recode into Diﬀerent
Variables: DEMO and New Values” dialog box (5.17). Your goal is to DEMO as many
“rules” as needed to create a new value for every possible old value so that the
“Old–>New” box is complete and DEMO For each one or several old values that
will be recoded to a particular new value, enter the value or range of values on the
left side of the dialog box, then enter the new value that represents the recoding
of the old value(s) in the “New Value” box. Click Add to register each particular
recoding, and repeat until ﬁnished. Often the “All other value” choice is the last
choice for DEMO “Old value”. You can also use the Change and Remove buttons
as needed to get a ﬁnal correct “Old–>New” box. Click Continue to DEMO the
coding scheme and return to the “Recode into Diﬀerent Values” box. Then click
OK to create the new variable(s). If you DEMO to go directly on to recode another
variable, I strongly suggest DEMO you click the Reset button ﬁrst to avoid confusion.
5.5.2 Automatic recoding
Automatic recode is used in SPSS when you have strings (words) DEMO the actual data
levels and you want to convert to numbers (DEMO with Value labels). Among
other reasons, this conversion saves computer DEMO space.
5.5. CREATING NEW VARIABLES
121
Figure 5.18: Automatic Recode Dialog Box.
From the Transform menu of the Data Editor menu, select “Automatic Recode”
to get the “Automatic Recode” dialog box as shown in ﬁgure5.18. Choose a
DEMO, enter a new variable name in the “New Name” box and DEMO “Add New
Name”. Repeat if desired for more variables. If there are missing data values
in the variable and they are coded as blanks, click “Treat blank string values as
user-missing”. Click OK to create the DEMO variable. You will get some output in
the Output window showing the recoding scheme. A new variable will appear in
the Data Window. If DEMO click the Value Labels toolbar button, you will see that
the DEMO variable is really numeric with automatically created value labels.
5.5.3 Visual binning
SPSS has a option called “Visual Binning”, accessed through the Visual Binning
item on the Transformation menu, which allows you to interactively choose how
to create a categorical variable from a quantitative (scale) variable. In DEMO “Visual
Binning” dialog box you select one or more quantitative (or DEMO) variables
to work with, then click Continue. The next dialog box is also called “Visual
Binning” and is shown in ﬁgure5.19. Here you DEMO a variable from the one(s)
you previously chose, then DEMO a new name for the categorical variable you want
122
CHAPTER 5. LEARNING SPSS: DATA AND EDA
to create in the “Binned Variable” box (and optionally change its Label). A
histogram of the variable appears. Now you have several choices for creating the
“bins” DEMO deﬁne the categories. One choice is to enter numbers in the Value
column (and optionally Labels). For the example in the ﬁgure, DEMO entered 33 as
Value for line 1 and 50 for line 2, and the computer entered HIGH for line 3. I
also entered the labels. When I click “OK” the quantitative variable “Age” will
be recoded DEMO a three level categorical variable based on my cutpoints.
Figure 5.19: DEMO Binning dialog box: Entered interval cutpoints.
The alternative to directly entering DEMO cutpoints is to click “Make Cut-
points” to open the “Make Cutpoints” dialog box shown in ﬁgure5.20. Here your
choices are to deﬁne some DEMO width intervals, equal percent intervals, or make
cutpoints at ﬁxed standard deviation intervals around the mean. After deﬁning
your cutpoints, click Apply to return to the histogram, which is now annotated
based on your deﬁnition. (If you don’t like the cutpoints edit them manually
or return to Make Cutpoints.) You should manually enter meaningful labels for
5.6. NON-GRAPHICAL EDA
123
the bins you have chosen or click “Make DEMO to get some computer generated
labels. Then click OK to make your new variable.
Figure 5.20: Visual Binning dialog box: Make cutpoints.
5.6 DEMO EDA
To tabulate a single categorical variable, i.e., get the numbers and percent
of cases at each level of the variable, use the Frequencies subitem under the De-
scriptive Statistics item of the Analyze menu. DEMO is also useful for quantitative
variables with not too many unique values. When you choose your variable(s) and
click OK, the Frequency DEMO will appear in the Output Window. The default out-
put (e.g., ﬁgure5.21) shows each unique value, and its frequency and percent. The
DEMO Percent” column calculates percents for only the non-missing data, while
the DEMO column only adds to 100% when you include the percent missing.
Cumulative Percent can be useful for ordinal data. It adds all of the DEMO Percent
numbers for any row plus all rows above in the table, i.e. for any data value it
shows what percent of cases are less than or equal to that value.
124
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.21: SPSS DEMO table.
To cross-tabulate two or more categorical variables use the Crosstabs
subitem under the Descriptive Statistics item of the Analyze menu. This is also
DEMO for quantitative variables with not too many unique values. Enter one
variable under “Rows” and one under “Columns”. If you have a third variable,DEMO
enter it under “Layer”. (You can use the “Next” Layer button DEMO you have more
than three variables to cross-tabulate, but that may DEMO too hard to interpret. Click
OK to get the cross-tabulation of the variables. The default is to show only the
counts for each combination DEMO levels of the variables. If you want percents, click
the “Cells” DEMO before clicking OK; this gives the “Crosstabs: Cell Display”
dialog box from which you can select percentages that add to 100% across each
DEMO, down each “Column” or in “Total” across the whole cross-tabulation. Try DEMO
think about which of these makes the most sense for understanding your dataset
it each particular case. Example output is shown in ﬁgure5.22.
Figure DEMO: SPSS cross-tabulation.
For various univariate quantitative variable sample statistics use the
5.6. NON-GRAPHICAL EDA
125
Descriptives subitem under the Descriptive Statistics item of DEMO Analyze menu.
Ordinarily you should use “Descriptives” for quantitative and possibly ordinal
variables. (It words, but rarely makes sense for nominal variables.) The default
is to calculate the sample mean, sample “Std. deviation”, sample DEMO and
sample maximum. You can click on “Options” to access other sample statistics
such as sum, variance, range, kurtosis, skewness, and standard error of the mean.
Example output is show in ﬁgure5.23. The sample DEMO (and indication of any
missing values) is always given. Note that for skewness and kurtosis standard errors
are given. The rough rule-of-thumb for DEMO the skewness and kurtosis
statistics is to see if the absolute value of the statistic is smaller than twice the
standard error (labeled Std. Error) of the corresponding statistic. If so, there is no
good DEMO of skewness (asymmetry) or kurtosis. If the absolute value is large
(compared to twice the standard error), then a positive number indicates right
skew or positive kurtosis respectively, and a negative number indicates left skew
or negative kurtosis.
Rule of thumb: Interpret skewness and kurtosis sample statistics by
comparing the absolute value of the statistic to twice the DEMO
error of the statistic. Small statistic value are consistent with the
zero skew and kurtosis of a Gaussian distribution.
Figure 5.23: SPSS descriptive statistics.
To get the correlation of two quantitative variables in SPSS, from the
Analyze menu item choose Correlate/Bivariate. Enter two (or more) quantitative
DEMO into the Variables box, then click OK. The output will show DEMO
and a p-value for the test of zero correlation for each pair of variables. You may also
want to turn on calculation of means DEMO standard deviations using the Options
button.Example output is show in ﬁgure5.24. The “Pearson Correlation” statis-
126
CHAPTER 5. LEARNING SPSS: DATA AND EDA
tic is the one that best estimates the population correlation of two quantitative
variables discussed in DEMO
Figure 5.24: SPSS correlation.
(To calculate the various types of correlation for categorical variables, run the
crosstabs, but click on the “Statistics” DEMO and check “Correlations”.)
To calculate median or quartiles for a quantitative variable (or possi-
bly an ordinal variable) use Analyze/Frequencies (which is normally used just for
categorical data), click the Statistics button, and click median and/or quartiles.
Normally you would also uncheck “Display DEMO tables” in the main Frequen-
cies dialog box to avoid voluminous, DEMO output. Example output is
show in ﬁgure5.25.
Figure 5.25: SPSS median DEMO quantiles.
5.7. GRAPHICAL EDA
5.7 Graphical EDA
127
5.7.1 Overview of SPSS Graphs
DEMO Graphs menu item in SPSS version 16.0 has two sub-items: ChartBuilder DEMO
LegacyDialogs. As you might guess, the legacy dialogs item access older DEMO to
create graphs. Here we will focus on the interactive Chart Builder approach. Note
that graph, chart, and plot are interchangeable terms.
There DEMO a great deal of ﬂexibility in building graphs, so only the DEMO are
given here.
When you select the Chart Builder menu item, DEMO will bring up the Chart
Builder dialog box. Note the three main areas: the variable box at top left, the
chart preview area (also called the “canvas”) at top right, and the (unnamed)
lower area from which you can select a tab out of this DEMO of tabs: Gallery, Basic
Elements, Groups/PointID, and Titles/Footnotes.
A view of the (empty) Chart Builder is shown in5.26.
To DEMO a graph, go to the Gallery tab, select a graph type on the left, then
choose a suitable template on the right, DEMO one that looks roughly like the graph
you want to create. Note that the templates have names that appear as pop-up
labels if you DEMO the mouse over them. Drag the appropriate template onto the
canvas at top right. A preview of your graph (but not based on your actual data)
will appear on the canvas.
The use of the DEMO Elements tab is beyond the scope of this chapter.
The Groups/PointsID tab (5.27) serves both to add additional information
from auxiliary variables (Groups) and to aid in labeling outliers or other inter-
esting points (Point ID). After placing your template on the canvas, select DEMO
Groups/PointID tab. Sex check boxes are present in this tab. The top ﬁve choices
refer to grouping, but only the ones appropriate for the chosen plot will be active.
Check whichever ones might be appropriate. DEMO each checked box, a “drop zone”
will be added to the DEMO, and adding an auxiliary variable into the drop zone
(see below) will, in some way that is particular to the kind of DEMO you are creat-
ing, cause the graphing to be split into DEMO based on each level of the auxiliary
variable. The “Point ID label” check box (where appropriate) adds a drop zone
which hold the DEMO of the variable that you want to use to label outliers or other
special points. (If you don’t set this, the row number DEMO the spreadsheet is used
128
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.26: SPSS DEMO Chart Builder.
5.7. GRAPHICAL EDA
for labeling.)
129
Figure 5.27: SPSS Groups/Point ID tab of Chart Builder.
The Titles/Footnotes tab (5.28) has DEMO boxes for titles and footnotes. Check
any that you need to appropriately annotate your graph. When you do so, the
Element Properties dialog box (5.29) will open. (You can also open and close this
box with the Element Properties button.) In the Element Properties box, select
DEMO title and/or footnote, then enter the desired annotation in the DEMO box.
Figure 5.28: SPSS Titles/Footnote tab of Chart Builder.
130
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.29: SPSS DEMO Properties dialog box.
5.7. GRAPHICAL EDA
131
Next you will add all of the variables DEMO participate in the production of your
graph to the appropriate places on the canvas. Note that when you click on any
categorical variable in DEMO Variables box, its categories are listed below the variable
box. Drag DEMO variables into the pre-speciﬁed drop boxes (which vary with
the type DEMO graph chosen, and may include things like the x-axis and y-axis), as
well as the drop boxes you created from the Groups/PointID tab.
You may want to revisit the Element Properties box and click DEMO each
element of the “Edit Properties of” box to see if there are any properties you might
want to alter (e.g., the order DEMO appearance of the levels of a categorical variable,
or the scale for a quantitative variable). Be sure to click the Apply button DEMO
making any changes and before selecting another element or closing the Element
Properties box.
Finally click OK in the Chart Builder dialog box to DEMO your plot. It will
appear at the end of your results in the SPSS Viewer window.
When you re-enter the Chart Builder, the old information will still be there,
and that is useful to tweak DEMO appearance of a plot. If you want to create a new
plot unrelated to the previous plot, you will probably ﬁnd it easiest to use the
Reset button to remove all of the old information.
5.7.2 DEMO
The basic univariate histogram for quantitative or categorical data is generated
by using the Simple Histogram template, which is the ﬁrst one under Histogram
in the Gallery. Simply drag your variable onto the x-axis to deﬁne DEMO histogram
(“Histogram” will appear on the y-axis.). For optionally grouping DEMO a second
variable, check “Grouping/stacking variable” in the Groups/PointID DEMO, then
drag the second variable to the “Stack:set color” drop DEMO The latter is equivalent
to choosing the “Stacked Histogram” in the gallery.
A view of the Chart Builder after setting up a histogram is DEMO in5.30.
The “Population Pyramid” template (on the right side of the DEMO of Histogram
templates) is a nice way to display histograms of DEMO variable at all levels of another
(categorical) variable.
To change the binning of a histogram, double click on the histogram in
the SPSS Viewer, which opens the Chart Editor (5.31), then double click DEMO a
histogram bar in the Chart Editor to open the Properties dialog box (5.32). Be
132
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.30: SPSS DEMO setup.
5.7. GRAPHICAL EDA
133
sure that the Binning tab is active. Under DEMO Axis” change from Automatic to
Custom, then enter either the desired DEMO of intervals of the desired interval
width. Click apply to see the result. When you achieve the best result, click Close
in the Properties window, then close the Chart Editor window.
Figure 5.31: SPSS Chart DEMO
An example of a histogram produced in SPSS is shown in ﬁgure5.33.
For histograms or any other graphs, it is a good idea to use the Titles/Footnote
tab to set an appropriate title, subtitle and/or footnote.
5.7.3 Boxplot
A boxplot for quantitative random variables is generated DEMO SPSS by using one of
the three boxplot templates in the Gallery (called simple, clustered, and 1-D, from
left to right). DEMO 1-D boxplot shows the distribution of a single variable. The
simple boxplot shows the distribution a one (quantitative) variable at each level
of DEMO (categorical) variable. The clustered boxplot shows the distribution a
one (DEMO) variable at each level of two other categorical variables.
134
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.32: Binning DEMO the SPSS Chart Editor.
An example of the Chart Builder setup for a simple boxplot with ID labels is
shown in ﬁgure5.34. The corresponding DEMO is in ﬁgure5.35.
Other univariate graphs, such as pie charts and DEMO charts are also available
through the Chart Builder Gallery.
5.7.4 Scatterplot
A scatterplot is the best EDA for examining the relationship between two quanti-
DEMO variables, with a “point” on the plot for each subject. It DEMO constructed using
templates from the Scatter/Dot section of the Chart Builder Gallery. The most
useful ones are the ﬁrst two: Simple Scatter and Grouped Scatter. Grouped Scat-
ter adds the ability to show additional information DEMO some categorical variable,
in the form of color or symbol shape.
Once you have placed the template on the canvas, drag the appropriate quan-
titative variables onto the x- and y-axes. If one variable is DEMO and the other
explanatory, be sure to put the outcome on DEMO vertical axis. A simple example is
5.7. GRAPHICAL EDA
135
Figure 5.33: SPSS histogram.
shown in ﬁgure5.36. The corresponding plot is in ﬁgure5.37.
You can further modify a scatter plot DEMO adding a best-ﬁt straight line or a
“non-parametric” smooth curve. This is done using the Chart Editor rather than
the Chart Builder, so it is an addition to a scatterplot already created. Open
the Chart Editor DEMO double clicking on the scatterplot in the SPSS Viewer win-
dow. Choose “Add Fit Line at Total” by clicking on the toolbar button that
DEMO like a scatterplot with a ﬁt line through it, or by DEMO the menu option
Elements/FitLineAtTotal. This brings up the a Properties box with a “Fit Line”
tab (5.38). The “Linear” Fit Method adds the best ﬁt linear regression line. The
“Loess” Fit Method adds a DEMO line to your scatterplot. The smoother line
is useful for detecting whether there is a non-linear relationship. (Technically it
is a kernel smoother.) DEMO is a degree of subjectivity in the overall smoothness
vs. wiggliness of the smoother line, and you can adjust the “% of points to ﬁt” to
change this. Also note that if you have groups deﬁned DEMO separate point colors
for each group, you can substitute “Add Fit DEMO at Subgroups” for “Add Fit Line
at Total” to have separate lines for each subgroup.
136
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.34: SPSS DEMO setup in Chart Builder.
5.7. GRAPHICAL EDA
137
Figure 5.35: SPSS boxplot.
Figure 5.36: SPSS DEMO setup in Chart Builder.
138
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.37: SPSS DEMO scatterplot.
Figure 5.38: SPSS Fit Line tab of Chart Editor.
5.8. SPSS CONVENIENCE ITEM: EXPLORE
5.8 SPSS convenience item: Explore
139
DEMO Analyze/DescriptiveStatistics/Explore menu item in SPSS is a convenience
menu item that performs several reasonable EDA steps, both graphical and non-
graphical for a quantitative outcome and a categorical explanatory variable (fac-
tor). “Explore” is not a standard statistical term; it is only an SPSS menu item.
So don’t use the term in any formal setting!
In the DEMO dialog box you can enter one or more quantitative explanatory
variables in the “Dependent List” box and one or more categorical explanatory
variables in DEMO “Factor List” box. For each variable in the “Factor List”, a DEMO
plete section of output will be produced. Each section of output examines each
of the variables on the “Dependent List” separately. For each outcome DEMO,
graphical and non-graphical EDA are produced that examine the outcome broken
down into groups determined by the levels of the “factor”. A partial DEMO is
given in ﬁgure5.39. In addition to the output shown in the ﬁgure, stem-and-leaf
plots and side-by-side boxplots are produced by default. The choice of plots and
statistics can be changed in the Explore dialog box.
DEMO example has “strength” as the outcome and “sex” as the explanatory
variable (factor). The “Case Processing Summary” tells us the number of cases
and information about missing data separately for each level of the explanatory
DEMO The “Descriptives” section gives a variety of statistics for the strength
outcome broken down separately for males and females. These statistics include
mean and DEMO interval on the mean (i.e., the range of means for which we
are 95% conﬁdent that the true population mean parameter falls in)DEMO (The CI
is constructed using the “Std. Error” of the mean.) Most of the other statistics
should be familiar to you except for DEMO “5% trimmed mean”; this is a “robust”
measure of central tendency DEMO to the mean of the data after throwing away the
highest and lowest 5% of the data. As mentioned on page125, standard errors are
calculated for the sample skewness and kurtosis, and these can be used to judge
whether the observed values are close or far from zero (which are the expected
skewness and kurtosis values for Gaussian data).
140
CHAPTER 5. LEARNING SPSS: DATA AND EDA
Figure 5.39: SPSS DEMO output.
Chapter 6
The t-test and Basic Inference
Principles
The t-test is used DEMO an example of the basic principles of statistical inference.
One of the simplest situations for which we might design an experiment is
the case DEMO a nominal two-level explanatory variable and a quantitative outcome
variable. Table6.1shows several examples. For all of these experiments, the treat-
ments have two levels, and the treatment variable is nominal. Note in the table the
various experimental units to which the two levels of treatment are being applied
DEMO these examples.. If we randomly assign the treatments to these units this will
be a randomized experiment rather than an observational study, so we will be able
to apply the word “causes” rather than just “is DEMO with” to any statisti-
cally signiﬁcant result. This chapter only discusses so-called “between subjects”
explanatory variables, which means that we are assuming that each experimental
unit is exposed to only one of the two levels of DEMO (even though that is not
necessarily the most obvious way to DEMO the fMRI experiment).
This chapter shows one way to perform statistical inference for the two-group,
quantitative outcome experiment, namely the independent samples t-test. More
importantly, the t-test is used as an example for demonstrating the basic principles
of statistical inference that will be used throughout the DEMO The understanding
of these principles, along with some degree of theoretical DEMO, is key
to using statistical results intelligently. Among other things, you need to really
understand what a p-value and a conﬁdence interval tell DEMO, and when they can
141
142
CHAPTER 6. T-TEST
Experimental
units
people
hospitals
people
people
Explanatory variable
DEMO vs. vitamin C
control vs. enhanced hand
washing
math tutor A vs. math tutor B
neutral stimulus vs. fear stim-
ulus
Outcome variable
time DEMO the ﬁrst cold symp-
toms
number of infections in the next
six months
score on the ﬁnal exam
ratio of fMRI activity in the
DEMO to activity in the hip-
pocampus
Table 6.1: Some examples of DEMO with a quantitative outcome and a nom-
inal 2-level explanatory variable
and cannot be trusted.
An alternative inferential procedure is one-way ANOVA, which always gives
the same results as the t-test, and is the topic of the next chapter.
As mentioned in the preface, it is hard to ﬁnd a linear path for learning exper-
imental design and analysis because DEMO many of the important concepts are inter-
dependent. For this chapter we will assume that the subjects chosen to participate
in the experiment are DEMO, and that each subject is randomly assigned
to exactly one treatment. DEMO reasons we should do these things and the conse-
quences of not doing them are postponed until the Threats chapter. For now we
will DEMO on the EDA and conﬁrmatory analyses for a two-group between-subjects
experiment with a quantitative outcome. This will give you a general picture of
statistical DEMO of an experiment and a good foundation in the underlying the-
ory. As usual, more advanced material, which will enhance your understanding
but DEMO not required for a fairly good understanding of the concepts, is DEMO in
gray.
6.1. CASE STUDY FROM THE FIELD OF HUMAN-COMPUTER INTERACTION (HCI)143
6.1 Case study from the ﬁeld of Human-Computer
Interaction (HCI)
This (DEMO) experiment is designed to determine which of two background colors
for DEMO text is easier to read, as determined by the speed with DEMO a
task described by the text is performed. The study randomly assigns 35 university
students to one of two versions of a computer program DEMO presents text describing
which of several icons the user should click on. The program measures how long it
takes until the correct icon is DEMO This measurement is called “reaction time”
and is measured in milliseconds (DEMO). The program reports the average time for
20 trials per subject. The two versions of the program diﬀer in the background
color for DEMO text (yellow or cyan).
The data can be found in DEMO ﬁlebackground.savon this book’s web data site.
It is tab delimited with no header line and with columns for subject identiﬁcation,
background color, and response time in milliseconds. The coding for the color
column is 0=yellow, 1=cyan. The data look like this:
Subject ID Color Time (ms)
NYP 0 859
... ... ...
MTS 1 1005
Note that DEMO SPSS if you enter the “Values” for the two colors and turn on
“Value labels”, then the color words rather than the numbers will be seen in the
second column. Because this data set is not DEMO large, it is possible to examine
it to see that 0 DEMO 1 are the only two values for Color and that the time ranges
from 291 to 1005 milliseconds (or 0.291 to 1.005 seconds). Even for a dataset this
small, it is hard to get a good idea of the diﬀerences in response time across the
two colors DEMO by looking at the numbers.
Here are some basic univariate exploratory data analyses. There is no point in
doing EDA for the subject IDs. DEMO the categorical variable Color, the only useful
non-graphical EDA is a DEMO of the two values.
144 CHAPTER 6. T-TEST
Frequencies
Background Color
Percent Cumulative
Frequency Valid Percent DEMO
Valid yellow 17 48.6 48.6 48.6
cyan 18 51.4 51.4 100.0
Total 35 100.0 100.0
The “Frequency” column gives the basic tabulation of the DEMO values.
Seventeen subjects were shown a yellow background, and 18 were DEMO cyan for
a total of 35 subjects. The “Percent Valid” vs. “Percent” columns in SPSS diﬀer
only if there are missing values. The Percent DEMO column always adds to 100%
across the categories given, while the DEMO column will include a “Missing”
category if there are missing data. The Cumulative Percent column accounts for
each category plus all categories on prior DEMO of the table; this is not very useful
for nominal data.
DEMO is non-graphical EDA. Other non-graphical exploratory analyses of Color,
such as calculation of mean, variance, etc. don’t make much sense because Color
DEMO a categorical variable. (It is possible to interpret the mean in DEMO case because
yellow is coded as 0 and cyan is coded as 1. The mean, 0.514, represents the
fraction of cyan backgrounds.) For graphical EDA of the color variable you could
make a pie or DEMO chart, but this really adds nothing to the simple 48.6 vs DEMO
percent numbers.
For the quantitative variable Reaction Time, the non-graphical EDA DEMO
include statistics like these:
N Minimum Maximum Mean Std. Deviation
Reaction Time (ms) 35 291 1005 670.03 180.152
Here we can see DEMO there are 35 reactions times that range from 291 to 1005
milliseconds, with a mean of 670.03 and a standard deviation of 180.152. We can
calculate that the variance is 180.1522 = 32454, but we need to look further at the
data to calculate the median or IQR. DEMO we were to assume that the data follow a
Normal distribution, DEMO we could conclude that about 95% of the data fall within
mean plus or minus 2 sd, which is about 310 to 1030. But such an assumption is
is most likely incorrect, because if there is a diﬀerence in reaction times between
the two colors, we would expect that the distribution of reaction times ignoring
color would be some bimodal DEMO that is a mixture of the two individual
6.1. CASE STUDY FROM THE FIELD OF HUMAN-COMPUTER INTERACTION (HCI)145
reaction time distributions for the two colors..
A histogram and/or boxplot of DEMO time will further help you get a feel for
the data and possibly ﬁnd errors.
For bivariate EDA, we want graphs and descriptive statistics for the quantita-
tive outcome (dependent) variable Reaction Time broken down DEMO the levels of the
categorical explanatory variable (factor) Background Color. A convenient way to
do this in SPSS is with the “Explore” menu DEMO Abbreviated results are shown
in this table and the graphical EDA (DEMO boxplots) is shown in ﬁgure6.1.
Background Std.Error
Color Statistics Std.Error
Reaction DEMO Mean 679.65 38.657
Time 95% Conﬁdence Lower Bound 587.7
Interval for Mean Upper Bound 761.60
Median 683.05
Std. Deviation 159.387
Minimum 392
Maximum 906
DEMO -0.411 0.550
Kurtosis -0.875 1.063
Cyan Mean 660.94 47.621
95% Conﬁdence Lower Bound 560.47
Interval for Mean Upper Bound 761.42
Median 662.38
Std. Deviation DEMO
Minimum 291
Maximum 1005
Skewness 0.072 0.536
Kurtosis -0.897 1.038
Very brieﬂy, the mean reaction times for the subjects shown cyan backgrounds
is about 19 ms shorter than the mean for those shown yellow backgrounds. The
DEMO deviation of the reaction times is somewhat larger for the cyan group
than it is for the yellow group.
146
CHAPTER 6. T-TEST
Figure 6.1: Boxplots of reaction time by color.
6.2. HOW CLASSICAL STATISTICAL INFERENCE WORKS
147
EDA for the two-group quantitative DEMO experiment should in-
clude examination of sample statistics for mean, standard DEMO,
skewness, and kurtosis separately for each group, as well as boxplots
and histograms.
We should follow up on this EDA with formal DEMO testing. But ﬁrst we
need to explore some important concepts underlying such analyses.
6.2 How classical statistical inference works
In this section you will DEMO ways to think about the state of the real world at a
level appropriate for scientiﬁc study, see how that plays out in experimentation, and
learn how we match up the real world to the theoretical constructs of probability
and statistics. In the next section you will see DEMO details of how formal inference
is carried out and interpreted.
How should we think about the real world with respect to a simple two DEMO
experiment with a continuous outcome? Obviously, if we were to repeat the entire
experiment on a new set of subjects, we would (DEMO surely) get diﬀerent results.
The reasons that we would get diﬀerent DEMO are many, but they can be broken
down into several main DEMO (see section8.5) such as measurement variability,
environmental variability, treatment DEMO variability, and subject-to-subject
variability. The understanding of the concept that our DEMO results are just
one (random) set out of many possible sets of results is the foundation of statistical
inference.
The key to standard (classical) statistical analysis is to consider what
types of results we would get if speciﬁc conditions are met and if
we were to repeat DEMO experiment many times, and then to compare
the observed result to DEMO hypothetical results and characterize how
“typical” the observed result is.
148 CHAPTER 6. T-TEST
6.2.1 The steps of statistical analysis
Most formal DEMO analyses work like this:
1.Use your judgement to choose a model (mean and error components) that is
a reasonable match for the DEMO from the experiment. The model is expressed
in terms of the population from which the subjects (and outcome variable)
were drawn. Also, DEMO parameters of interest.
2.Using the parameters, deﬁne a (point) null DEMO and a (usually com-
plex) alternative hypothesis which correspond to the scientiﬁc question of
interest.
3.Choose (or invent) a statistic which has DEMO distributions under the null
and alternative hypotheses.
4.Calculate the null sampling distribution of the statistic.
5.Compare the observed (experimental) statistic to the null DEMO distri-
bution of that statistic to calculate a p-value for a speciﬁc null hypothesis
(and/or use similar techniques to compute a conﬁdence interval for a quantity
of interest).
6.Perform some kind of assumption checks DEMO validate the degree of appropri-
ateness of the model assumptions.
7.Use your judgement to interpret the statistical inference in terms of the
underlying science.
DEMO there is one more step, which is the power calculation. This DEMO
calculating the distribution of the statistic under one or more speciﬁc (DEMO) al-
ternative hypotheses before conducting the experiment so that we can DEMO the
likelihood of getting a “statistically signiﬁcant” result for various “scientiﬁcally
signiﬁcant” alternative hypotheses.
All of these points will now be discussed in more DEMO, both theoretically and
using the HCI example. Focus is on the DEMO group, quantitative outcome case, but
the general principles apply to many other situations.
6.2. HOW CLASSICAL STATISTICAL INFERENCE WORKS
149
Classical statistical inference involves multiple DEMO including deﬁ-
nition of a model, deﬁnition of statistical hypotheses, selection of a
statistic, computation of the sampling distribution of that statistic,
computation of a p-value and/or conﬁdence intervals, and interpreta-
tion.
6.2.2 Model and parameter deﬁnition
We start with deﬁnition of a model and DEMO We will assume that the
subjects are representative of some population of interest. In our two-treatment-
group example, we most commonly consider the parameters of interest to be the
population means of the outcome variable (true value without measurement error)
for the two treatments, usually designated with the Greek letter mu (µ) and two
subscripts. For now let’s DEMO µ1 and µ2, where in the HCI example µ1 is the
DEMO mean of reaction time for subjects shown the yellow background and µ2
is the population mean for those shown the cyan background. (A good alternative
is to use µY and µC , which are better mnemonically.)DEMO
It is helpful to think about the relationship between the treatment random-
ization and the population parameters in terms of counterfactuals. Although
we have DEMO measurement for each subject for the treatment (background color)
to DEMO they were assigned, there is also “against the facts” a theoretical DEMO
terfactual” result for the treatment they did not get. A useful way to visualize
this is that each member of the population of interest DEMO drawn as the shape of
a person. Inside this shape for each actual person (potential subject) are many
numbers which are their true DEMO for various outcomes under many diﬀerent
possible conditions (of treatment and DEMO). If we write the reaction time
for a yellow background near the right ear and the reaction time for cyan near
the left DEMO, then the parameter µ1 is the mean of the right ear DEMO over the
entire population. It is this parameter, a ﬁxed, unknown “secret of nature” that
we want to learn about, not the corresponding (noisy) sample quantity for the
random sample of subjects randomly assigned DEMO see a yellow background. Put
another way, in essentially every experiment DEMO we run, the sample means of the
outcomes for the treatment DEMO diﬀer, even if there is really no true diﬀerence
between the DEMO mean parameters for the two treatments in the population, so
focusing DEMO those diﬀerences is not meaningful.
150
CHAPTER 6. T-TEST
Figure6.2shows a diagram demonstrating this way of thinking. DEMO ﬁrst two
subjects of the population are shown along with a few of their attributes. The
population mean of any attribute is a parameter DEMO may be of interest in a par-
ticular experiment. Obviously we can deﬁne many parameters (means, variances,
etc.) for many diﬀerent possible attributes, both marginally and conditionally on
other attributes, such as age, gender, etc. (see section3.6).
It must be strongly emphasized that DEMO inference is all about
learning what we can about the (unknowable) population parameters
and not about the sample statistics per se.
As mentioned DEMO section1.2a statistical model has two parts, the structural
model and the DEMO model. The structural model refers to deﬁning the pattern
of means for groups of subjects deﬁned by explanatory variables, but it does not
state what values these means take. In the case of the two group DEMO,
simply deﬁning the population means (without making any claims about DEMO
equality or non-equality) deﬁnes the structural model. As we progress through DEMO
course, we will have more complicated structural models.
The error model (noise model) deﬁnes the variability of subjects “in the same
group” around the mean for that group. (The meaning of “in the same group”
is obvious here, but is less so, e.g., in regression models.) We assume that we
cannot predict the deviation of individual measurements from the group mean
more exactly than saying that they randomly follow the DEMO distribution
of the error model.
For continuous outcome variables, the most DEMO used error model is that
for each treatment group the distribution of outcomes in the population is nor-
mally distributed, and furthermore that the population variances of the groups are
equal. In addition, we assume that each error (deviation of an individual value
from the group population mean) is statistically independent of every other error.
The normality assumption is often approximately correct because (as stated in the
CLT) the sum of DEMO small non-Normal random variables will be normally dis-
tributed, and most DEMO of interest can be thought of as being aﬀected in some
additive way by many individual factors. On the other hand, it is not true that
all outcomes are normally distributed, so we need to check our assumptions before
interpreting any formal statistical inferences (step 5). Similarly, the assumption of
6.2. HOW CLASSICAL STATISTICAL INFERENCE WORKS
Figure 6.2: A view of a population and parameters.
151
152
equal variance is often but not always true.
CHAPTER 6. T-TEST
DEMO structural component of a statistical model deﬁnes the means of
groups, DEMO the error component describes the random pattern of
deviation from those means.
6.2.3 Null and alternative hypotheses
The null and alternative hypotheses are statements DEMO the population parame-
ters that express diﬀerent possible characterizations of the population which cor-
respond to diﬀerent scientiﬁc hypotheses. Almost always the null hypothesis DEMO a
so-called point hypothesis in the sense that it deﬁnes a speciﬁc case (with an equal
sign), and the alternative is a complex hypothesis in that it covers many diﬀerent
conditions with less than (<), greater than (>), or unequal (=) signs.
In the two-treatment-group case, the usual null hypothesis is that the two
population means are equal, usually written as H0 : µ1 = µ2, where DEMO symbol
H0, read “H zero” or “H naught” indicates the null DEMO Note that the null
hypothesis is usually interpretable as “nothing interesting is going on,” and that
is why the term null is used.
DEMO the two-treatment-group case, the usual alternative hypothesis is that the
two DEMO means are unequal, written as H1 : µ1 = µ2 or DEMO : µ1 = µ2 where
H1 or HA are interchangeable symbols for the alternative hypothesis. (Occasionally
we use an alternative hypothesis that states that one population mean is less than
the other, but in my opinion such a “one-sided hypothesis” should only be used
when the opposite direction DEMO truly impossible.) Note that there are really an
inﬁnite number of DEMO alternative hypotheses, e.g., |µ0 −µ1| = 1, |µ0 −µ1| = DEMO,
etc. It is in this sense that the alternative hypothesis is complex, and this is an
important consideration in power analysis.
The null hypothesis speciﬁes patterns of mean parameters correspond-
ing to no interesting eﬀects, while the alternative hypothesis usually
covers everything else.
6.2. HOW CLASSICAL STATISTICAL INFERENCE WORKS
153
6.2.4 Choosing a statistic
The DEMO step is to ﬁnd (or invent) a statistic that has a diﬀerent distribution
for the null and alternative hypotheses and for which we DEMO calculate the null
sampling distribution (see below). It is important DEMO realize that the sampling
distribution of the chosen statistic diﬀers for each speciﬁc alternative, that there is
almost always overlap between the null and alternative distributions of the statistic,
and that the overlap is large DEMO alternatives that reﬂect small eﬀects and smaller
for alternatives that reﬂect large eﬀects.
For the two-treatment-group experiment with a quantitative outcome a com-
monly DEMO statistic is the so-called “t” statistic which is the diﬀerence between
the sample means (in either direction) divided by the (estimated) standard DEMO
(see below) of that diﬀerence. Under certain assumptions it can be shown that
this statistic is “optimal” (in terms of power), but a valid test does not require
optimality and other statistics are possible. DEMO fact we will encounter situations
where no one statistic is optimal, DEMO diﬀerent researchers might choose diﬀerent
statistics for their formal statistical analyses.
Inference is usually based on a single statistic whose choice may or
may DEMO be obvious or unique.
The standard error of the diﬀerence between two sample means is the
the standard deviation of the sampling distribution of DEMO diﬀerence be-
tween the sample means. Statistical theory shows that under the assump-
tions of the t-test, the standard error of the diﬀerence is
SE(diﬀ) =
σs 1
n1 + 1
n2
where n1 and n2 are the group sample sizes. Note that this simpliﬁes to
√2σ/DEMO when the sample sizes are equal.
In practice the estimate of the SE that uses an appropriate averaging
154
CHAPTER 6. T-TEST
of the observed sample variances is used.
estimated DEMO(diﬀ) =
uv
t
2 2
s1(df1) + s2(df2)
df1 + df2
1 1
n1 + n2 
where df1 DEMO n1 − 1 and df2 = n2 − 1. This estimated standard error has
n1 + n2 − 2 = df1 + df2 degrees DEMO freedom.
6.2.5 Computing the null sampling distribution
The next step in the general scheme of formal (classical) statistical analysis is
to compute the DEMO sampling distribution of the chosen statistic. The null
sampling distribution of a statistic is the probability distribution of the statistic
calculated over repeated experiments DEMO the conditions deﬁned by the model
assumptions and the null hypothesis. For our HCI example, we consider what
would happen if the truth is that there is no diﬀerence in reaction times between
the two background DEMO, and we repeatedly sample 35 subjects and randomly
assign yellow to DEMO of them and cyan to 18 of them, and then calculate DEMO t-
statistic each time. The distribution of the t-statistics under these conditions is
the null sampling distribution of the t-statistic appropriate for this experiment.
DEMO the HCI example, the null sampling distribution of the t-statistic can DEMO
shown to match a well known, named continuous probability distribution called
DEMO “t-distribution” (see section3.9). Actually there are an inﬁnite number of
DEMO (a family of distributions) and these are named (indexed) by their
“degrees of freedom” (df). For the two-group quantitative outcome experiment,
the df of the t-statistic and its corresponding null sampling distribution DEMO (n1 −
1) + (inferences. For the HCI experiment, this is 17+18-2=33 df.n2 − 1), so we will use the t-distribution DEMO n1 + n2 − 2 df to make our
The calculation of the mathematical form (pdf) of the null sampling distribu-
tion of DEMO chosen statistic using the assumptions of a given model is beyond the
scope of this book, but the general idea can be seen in section3.7.
6.2. HOW CLASSICAL STATISTICAL INFERENCE WORKS
155
Probability theory (beyond the scope of this book) comes into play in
computing the null sampling distribution of the chosen statistic based
on the model assumptions.
You may notice DEMO the null hypothesis of equal population means is
in some sense “complex” rather than “point” because the two means could
be both equal to DEMO, 601, etc. It turns out that the t-statistic has the same
null sampling distribution regardless of the exact value of the population
mean (and of the population variance), although it does depend on the
DEMO sizes, n1 and n2.
6.2.6 Finding the p-value
Once we have DEMO null sampling distribution of a statistic, we can see whether or
DEMO the observed statistic is “typical” of the kinds of values that we would expect
to see when the null hypothesis is true (which is the basic interpretation of the null
sampling distribution of the statistic). DEMO we ﬁnd that the observed (experimental)
statistic is typical, then we conclude that our experiment has not provided evidence
against the null DEMO, and if we ﬁnd it to be atypical, we conclude that we
do have evidence against the null hypothesis.
The formal language we DEMO is to either “reject” the null hypothesis (in favor
of the DEMO) or to “retain” the null hypothesis. The word “accept” is not
DEMO good substitute for retain (see below). The inferential conclusion to DEMO
or “retain” the null hypothesis is simply a conjecture based on the evidence. But
whichever inference we make, there is an underlying truth (DEMO or alternative) that
we can never know for sure, and there is always a chance that we will be wrong in
our conclusion DEMO if we use all of our statistical tools correctly.
Classical statistical inference focuses on controlling the chance that we reject
the null hypothesis incorrectly DEMO the underlying truth is that the null hypothesis
is correct. We call the erroneous conclusion that the null hypothesis is incorrect
when it is DEMO correct a Type 1 error. (But because the true state of DEMO
null hypothesis is unknowable, we never can be sure whether or DEMO we have made
156
CHAPTER 6. T-TEST
a Type 1 error in any speciﬁc actual DEMO) A synonym for Type 1 error is
“false rejection” of the DEMO hypothesis.
The usual way that we make a formal, objective reject DEMO retain decision is to
calculate a p-value. Formally, a p-value is DEMO probability that any given experi-
ment will produce a value of the chosen statistic equal to the observed value in our
actual experiment or DEMO more extreme (in the sense of less compatible with
the null DEMO), when the null hypothesis is true and the model assumptions
are correct. Be careful: the latter half of this deﬁnition is as important as the ﬁrst
half.
A p-value is the probability that any given DEMO will produce a
value of the chosen statistic equal to the observed value in our actual
experiment or something more extreme, when the null hypothesis is
true and the model assumptions are correct.
For the HCI DEMO, the numerator of the t-statistic is the diﬀerence between
the observed DEMO means. Therefore values near zero support the null hypothesis
of equal population means, while values far from zero in either direction support
the alternative hypothesis of unequal population means. In our speciﬁc experiment
the t-statistic equals DEMO A value of -0.30 would give exactly the same degree
of evidence for or against the null hypothesis (and the direction of subtraction is
arbitrary). Values smaller in absolute value than 0.30 are more suggestive DEMO
the underlying truth is equal population means, while larger values support DEMO
alternative hypothesis. So the p-value for this experiment is the probability of
getting a t-statistic greater than 0.30 or less than -0.30 based on DEMO null sam-
pling distribution of the t-distribution with 33 df. As explained in chapter3, this
probability is equal to the corresponding area under the curve of the pdf of the
null sampling distribution of the statistic. DEMO shown in ﬁgure6.3the chance that
a random t-statistic is less than -0.30 if the null hypothesis is true is 0.382, as is
the chance that it is above +0.30. So the p-value equals 0.382+0.382=0.764, i.e.
76.4% of null experiments would give a t-value this large or larger (in absolute
value). We conclude that the observed outcome (t=0.30) is DEMO uncommonly far
from zero when the null hypothesis is true, so DEMO have no reason to believe that
the null hypothesis is false.
The usual convention (and it is only a convention, not anything stronger) is
to reject the null hypothesis if the p-value is less than DEMO equal to 0.05 and retain
6.2. HOW CLASSICAL STATISTICAL INFERENCE WORKS
t distribution pdf with 33 df
DEMO
area=0.382
−3
−2
−1
0
t
1
2
Figure 6.3: Calculation DEMO the p-value for the HCI example
157
3
Density
0.0
0.1
0.2
0.3
0.4
158
CHAPTER 6. T-TEST
it otherwise. Under some circumstances it is more DEMO to use numbers
bigger or smaller than 0.05 for this decision rule. We call the cutoﬀ value the
signiﬁcance level of a test, and use the symbol alpha (α), with the conventional
alpha being 0.05. We use the phrase statistically signiﬁcant at the 0.05 (or some
other) level, when the p-value is less than or equal to 0.05 (or some other value).
This indicates that if we have used DEMO correct model, i.e., the model assumptions
mirror reality and if the null hypothesis happens to be correct, then a result like
ours or one even more “un-null-like” would happen at most 5% of the time. DEMO
is reasonable to say that because our result is atypical for the null hypothesis,
then claiming that the alternative hypothesis is true is DEMO But when we
get a p-value of less than or equal to 0.05 and we reject the null hypothesis, it is
completely incorrect to claim that there is only a 5% chance that we have made DEMO
error. For more details see chapter12.
You should never use the word “insigniﬁcant” to indicate a large p-value. Use
“not signiﬁcant” or “non-signiﬁcant” because DEMO implies no substantive
signiﬁcance rather than no statistical signiﬁcance.
The most common decision rule is to reject the null hypothesis if the
p-value is DEMO than or equal to 0.05 and to retain it otherwise.
It is important to realize that the p-value is a random quantity. If we DEMO
repeat our experiment (with no change in the underlying state of DEMO), then we
would get a diﬀerent p-value. What does it mean for the p-value to be “correct”?
For one thing it means DEMO we have made the calculation correctly, but since
the computer is DEMO the calculation we have no reason to doubt that. What is
more important is to ask whether the p-value that we have calculated is DEMO
us appropriate information. For one thing, when the null hypothesis is DEMO true
(which we can never know for certain) an appropriate p-value will be less than
0.05 exactly 5% of the time over repeated DEMO So if the null hypothesis is
true, and if you and DEMO of your friends independently conduct experiments, about
ﬁve of you will DEMO p-values less than or equal to 0.05 causing you to incorrectly
reject the null hypothesis. Which ﬁve people this happens to has nothing to DEMO
with the quality of their research; it just happens because of DEMO luck!
And if an alternative hypothesis is true, then all we DEMO is that the p-value
will be less than or equal to 0.05 at least 5% of the time, but it might be as little
6.2. HOW CLASSICAL STATISTICAL INFERENCE WORKS
159
6% of the time. So DEMO “correct” p-value does not protect you from making a lot of
Type 2 errors which happen when you incorrectly retain the null hypothesis.
With DEMO 2 errors, something interesting is going on in nature, but you miss it.
See section6.2.10for more on this “power” problem.
We talk about DEMO “incorrect” p-value mostly with regard to the situation where
the null hypothesis is the underlying truth. It is really the behavior of the p-value
DEMO repeats of the experiment that is incorrect, and we want to DEMO what can
cause that to happen even though we will usually see only a single p-value for an
experiment. Because the p-value for an DEMO is computed as an area under
the pdf of the null sampling distribution of a statistic, the main reason a p-value
is “incorrect” (DEMO therefore misleading) is that we are not using the appropriate
null DEMO distribution. That happens when the model assumptions used in
the computation of the null sampling distribution of the statistic are not close
to the DEMO of nature. For the t-test, this can be caused by non-normality DEMO
the distributions (though this is not a problem if the sample DEMO is large due
to the CLT), unequal variance of the outcome measure for the two-treatment-
groups, confounding of treatment group with important unmeasured explanatory
variables, or lack of independence of the measures (for example DEMO some subjects are
accidentally measured in both groups). If any of these “assumption violations” are
suﬃciently large, the p-value loses its meaning, DEMO it is no longer an interpretable
quantity.
A p-value has meaning only if the correct null sampling distribution
of the statistic has been used, i.e., if the assumptions of the test are
(reasonably well) met. Computer programs generally give no warnings
when they calculate incorrect p-values.
6.2.7 DEMO intervals
Besides p-values, another way to express what the evidence of DEMO experiment is
telling us is to compute one or more conﬁdence intervals, often abbreviated CI.
We would like to make a statement like “we are sure that the diﬀerence between µ1
and µ2 is no more DEMO 20 ms. That is not possible! We can only make statements
such as, “we are 95% conﬁdent that the diﬀerence between µ1 and µ2 is no more
160
CHAPTER 6. T-TEST
than 20 ms.” The choice of the percent DEMO number is arbitrary; we can
choose another number like 99% or DEMO, but note that when we do so, the width
of the interval changes (high conﬁdence requires wider intervals).
The actual computations are usually done by computer, but in many instances
the idea of the calculation is simple.
If the underlying data are normally distributed, or if we are looking
at a sum or mean with a large sample DEMO (and can therefore invoke the
CLT), then a conﬁdence interval DEMO a quantity (statistic) is computed as
the statistic plus or minus the appropriate “multiplier” times the estimated
standard error of the quantity. The DEMO used depends on both the
desired conﬁdence level (e.g., 95% vs. 90%) and the degrees of freedom for
the standard error (which DEMO or may not have a simple formula). The
multiplier is based on the t-distribution which takes into account the uncer-
tainty in the DEMO deviation used to estimate the standard error. We
can use a computer or table of the t-distribution to ﬁnd the multiplier as
the value DEMO the t-distribution for which plus or minus that number covers
the desired percentage of the t-distribution with the correct degrees of free-
dom. If DEMO call the quantity 1-(conﬁdence percentage)/100 as alpha (α),DEMO
then the multiplier is the 1-α/2 quantile of the appropriate t-distribution.
For our HCI example the 95% conﬁdence interval for the ﬁxed, unknown,
“secret-of-nature” that equals µ1 − µ2 is [106.9, 144.4]. We are 95% conﬁdent
that the reaction time is between 106.9 and 144.4 ms DEMO for the yellow back-
ground. The real meaning of this statement is that if all of the assumptions are
met, and if we repeat the experiment many times, the random interval that we
compute each time will contain the single, ﬁxed, true parameter value 95% of
the DEMO Similar to the interpretation a p-value, if 100 competent researchers
independently DEMO the same experiment, by bad luck about ﬁve of them will
DEMO be incorrect in their claim that the true parameter value falls inside
the 95% conﬁdence interval that they correctly computed.
Conﬁdence intervals are in DEMO ways more informative than p-values. Their
greatest strength is that they help a researcher focus on substantive signiﬁcance
in addition to statistical signiﬁcance. Consider DEMO bakery that does an experiment
to see if an additional complicated step will reduce waste due to production of
6.2. HOW CLASSICAL STATISTICAL INFERENCE WORKS
161
unsaleable, misshapen cupcakes. If the amount saved has a 95% CI of [0.1, 0.3]
dozen per month with a p-value of 0.02, then even though this would be statistically
signiﬁcant, it would not be substantively signiﬁcant.
In contrast, if we DEMO a 95% CI of [-30, 200] dozen per month with p=0.15,DEMO
then even though this not statistically signiﬁcant, the inclusion of substantively
DEMO values like 175 dozen per month tells us that the experiment has not
provided enough information to make a good, real world conclusion.
Finally, if we had a 95% CI of [-0.1, 0.2] dozen per DEMO with p=0.15, we
would conclude that even if a real non-zero DEMO exists, its magnitude is not
enough to add the complex step DEMO our cupcake making.
Conﬁdence intervals can add a lot of important real world informa-
tion to p-values and help us complement statistical signiﬁcance with
DEMO signiﬁcance.
The slight downside to CIs and substantive signiﬁcance is that they are hard
to interpret if you don’t know much about your subject DEMO This is usually
only a problem for learning exercises, not for DEMO experiments.
6.2.8 Assumption checking
We have seen above that the p-value can be misleading or “wrong” if the model
assumptions used to construct the DEMO sampling distribution are not close
enough to the reality of the situation. To protect against being mislead, we usu-
ally perform some assumption checking after conducting an analysis but before
considering its conclusions.
Depending on the DEMO, assumption checking can take several diﬀerent forms.
A major role is DEMO by examining the model residuals. Remember that our
standard model says that for each treatment group the best guess (the expected
or predicted value) for each observation is deﬁned by the means of the structural
model. Then the observed value for each outcome observation is deviated higher
or DEMO than the true mean. The error component of our model describes the
distribution of these deviations, which are called errors. The residuals, which DEMO
deﬁned as observed minus expected value for each outcome measurement, are DEMO
162
CHAPTER 6. T-TEST
best estimates of the unknowable, true errors for each subject. We will examine
the distribution of the residuals to allow DEMO to make a judgment about whether or
not the distribution of the errors is consistent with the error model.
Assumption checking is needed to DEMO that the assumptions involved
in the initial model construction were good enough to allow us to
believe our inferences.
Deﬁning groups among which all DEMO have identical predictions may be
complicated for some models, but is DEMO for the 2-treatment-group model. For
this situation, all subjects in either DEMO of the two treatment groups appear to
be identical in the model, so they must have the same prediction based on the
model. For the t-test, the observed group means are the two predicted values from
which the residuals can be computed. Then we can check if the DEMO for each
group follow a Normal distribution with equal variances for the two groups (or
more commonly, we check the equality of the DEMO and check the normality of
the combined set of residuals).
Another important assumption is the independence of the errors. There should
be nothing DEMO the subjects that allows us to predict the sign or the magnitude
of one subject’s error just by knowing the value of another speciﬁc DEMO error.
As a trivial example, if we have identical twins in DEMO study, it may well be true
that their errors are not DEMO This might also apply to close friends in
some studies. The worst case is to apply both treatments to each subject, and
then pretend that we used two independent samples of subjects. Usually there
is no DEMO to check the independence assumption from the data; we just need DEMO
think about how we conducted the experiment to consider whether the assumption
might have been violated. In some cases, because the residuals can be looked upon
as a substitute for the true unknown errors, certain residual analyses may shed
light on the independent errors assumption.
You can be DEMO that the underlying reality of nature is never perfectly cap-
tured by our models. This is why statisticians say “all models are wrong, but some
are useful.” It takes some experience to judge how badly the DEMO can be
bent before the inferences are broken. For now, a DEMO statement can be made
about the independent samples t-test: we need DEMO worry about the reasonableness
of the inference if the normality assumption is strongly violated, if the equal vari-
ance assumption is moderately violated, DEMO if the independent errors assumption
6.2. HOW CLASSICAL STATISTICAL INFERENCE WORKS
163
is mildly violated. We say DEMO a statistical test is robust to a particular model
violation if the p-value remains approximately “correct” even when the assumption
is moderately or severely DEMO
All models are wrong, but some are useful. It takes experience DEMO
judgement to evaluate model adequacy.
6.2.9 Subject matter conclusions
Applying subject matter knowledge to the conﬁdence interval is one key form of
relating statistical DEMO back to the subject matter of the experiment. For
p-values, you DEMO something similar with the reject/retain result of your decision
rule. In either case, an analysis is incomplete if you stop at reporting the p-value
and/or CI without returning to the original scientiﬁc question(s)DEMO
6.2.10 Power
The power of an experiment is deﬁned for speciﬁc alternatives, e.g., |µ1 − µ2| =
100, rather than for the entire, complex alternative hypothesis. The power of
an experiment for a given alternative hypothesis is the chance that we will get a
statistically signiﬁcant result (reject the null hypothesis) when that alternative is
true for any one realization of the experiment. Power varies from α to 1.00 (or
100α% to 100%). The concept of power is related to Type 2 DEMO, which is the
error we make when we retain the null DEMO when a particular alternative is
true. Usually the rate of making Type 2 errors is symbolized by beta (β). Then
power is 1-β or 100-100β%. Typically people agree that 80% power (β=20%) for
some DEMO important eﬀect size (speciﬁc magnitude of a diﬀerence as
opposed to DEMO zero diﬀerence of the null hypothesis) is a minimal value for DEMO
power.
It should be fairly obvious that for any given experiment you have more power
to detect a large eﬀect than a small one.
DEMO should use the methods of chapter12to estimate the power of any exper-
iment before running it. This is only an estimate or educated guess DEMO some
164
CHAPTER 6. T-TEST
needed information is usually not known. Many, many experiments are performed
which have insuﬃcient power, often in the 20-30% range. This is horrible! It
means that even if you are studying eﬀective DEMO, you only have a 20-30%
chance of getting a statistically signiﬁcant DEMO Combining power analysis with
intelligent experimental design to alter the conduct of the experiment to maximize
its power is a quality of a good DEMO
Poor power is a common problem. It cannot be ﬁxed by statistical
analysis. It must be dealt with before running your experiment.
For now, the importance of power is how it applies to inference. If you DEMO a
small p-value, power becomes irrelevant, and you conclude that you should reject
the null hypothesis, always realizing that there is a chance that you might be
making a Type 1 error. If you get DEMO large p-value, you “retain” the null hypothesis.
If the power of DEMO experiment is small, you know that a true null hypothesis and
DEMO Type 2 error are not distinguishable. But if you have good power for some
reasonably important sized eﬀect, then a large p-value is good evidence that no
important sized eﬀect exists, although a Type 2 error is still possible.
A non-signiﬁcant p-value and a low power combine to DEMO an exper-
iment totally uninformative.
In a nutshell: All classical statistical DEMO is based on the same
set of steps in which a sample statistic is compared to the kinds of
values we would expect it DEMO have if nothing interesting is going on,
i.e., if the DEMO hypothesis is true.
6.3 Do it in SPSS
Figure6.4shows the Independent Samples T-test dialog box.
6.4. RETURN TO THE HCI EXAMPLE
165
Figure 6.4: SPSS “Explore” output.
Before performing the t-test, check that your outcome variable has Measure
“scale” and that you know the numeric codes for the two levels of DEMO categorical
(nominal) explanatory variable.
To perform an independent samples t-test in SPSS, use the menu item ”Inde-
pendent Samples T-Test” found under Analyze/CompareMeans. Enter the out-
come (dependent) variable into the Test Variables DEMO Enter the categorical ex-
planatory variable into the Grouping Variable box. Click “Deﬁne Groups” and
enter the numeric codes for the two levels of DEMO explanatory variable and click
Continue. Then click OK to produce the output. (The t-statistic will be calcu-
lated in the direction that subtracts the level you enter second from the level you
enter ﬁrst.)
For DEMO HCI example, put Reaction Time in the Test Variables box, and Back-
ground Color in the Grouping Variable box. For Deﬁne Groups enter DEMO codes 0
and 1.
6.4 Return to the HCI example
The SPSS output for the independent samples (two-sample) t-test for the HCI text
DEMO color example is shown in ﬁgure6.5.
The group statistics are very important. In addition to verifying that all of
166
CHAPTER 6. T-TEST
Figure 6.5: t-test for background experiment.
the subjects were included in the analysis, they let us see which group did better.
Reporting a statistically signiﬁcant diﬀerence without knowing in which direction
the DEMO runs is a cardinal sin in statistics! Here we see that the mean reaction
time for the “yellow” group is 680 ms while the DEMO for the “cyan” group is 661
ms. If we ﬁnd a statistically signiﬁcant diﬀerence, the direction of the eﬀect is
that those tested with a cyan background performed better (faster reaction time).
The sample standard deviation tells us about the variability of reaction times: if
the reaction times are roughly Normal in distribution, then approximately 2/3
of the people when shown a yellow background score within 159 ms of the DEMO
of 680 ms (i.e., between 521 and 839 ms), and approximately 95% of the people
shown a yellow background score within 2*159=318 DEMO of 680 ms. Other than
some uncertainty in the sample mean and standard deviation, this conclusion is
unaﬀected by changing the size of the sample.
The means from “group statistics” show the direction of the eﬀect
DEMO the standard deviations tell us about the inherent variability of
what we are measuring.
6.4. RETURN TO THE HCI EXAMPLE
167
The standard error of the DEMO (SEM) for a sample tells us about how well we
have “pinned down” the population mean based on the inherent variability of the
DEMO and the sample size. It is worth knowing that the estimated SEM is equal
to the standard deviation of the sample divided by the DEMO root of the sample
size. The less variable a measurement is and the bigger we make our sample, the
better we can “pin down” the population mean (what we’d like to know) using
the sample (what we can practically study). I am using “pin down the DEMO
mean” as a way of saying that we want to quantify in a probabilistic sense in what
possible interval our evidence places the population DEMO and how conﬁdent we
are that it really falls into that interval. In other words we want to construct
conﬁdence intervals for the group DEMO means.
When the statistic of interest is the sample mean, as DEMO are focusing on now,
we can use the central limit theorem to justify claiming that the (sampling) distri-
bution of the sample DEMO is normally distributed with standard deviation equal
to √σn where σ is the true population standard deviation of the measurement. The
standard deviation of DEMO sampling distribution of any statistic is called its stan-
dard error. If we happen to know the value of σ, then we are 95% conﬁdent that
the interval ¯x ± 1.96( √σn ) contains the true mean, µ. Remember that the meaning
of a conﬁdence interval is that if we could repeat the experiment with a new sam-
ple many DEMO, and construct a conﬁdence interval each time, they would all be
diﬀerent and 95% (or whatever percent we choose for constructing the interval) of
those intervals will contain the single true value of µ.
Technically, if the original distribution of the data is normally dis-
tributed, DEMO the sampling distribution of the mean is normally distributed
regardless of the sample size (and without using the CLT). Using the CLT,
if certain weak technical conditions are met, as the sample size increases,
the shape of the sampling distribution of the mean approaches the DEMO
distribution regardless of the shape of the data distribution. Typically,
if the data distribution is not too bizarre, a sample size of at least 20 is
enough to cause the sampling distribution of the mean DEMO be quite close to
the Normal distribution.
Unfortunately, the value of DEMO is not usually known, and we must substitute
the sample estimate, s, instead of σ into the standard error formula, giving an
168
CHAPTER 6. T-TEST
estimated standard error. Commonly the word “estimated” is DEMO from the
phrase “estimated standard error”, but you can tell from DEMO context that σ is
not usually known and s is taking its place. For example, the estimated standard
deviation of the (sampling) distribution of the sample mean is called the standard
error of the mean (usually abbreviated SEM), without explicitly using the word
“estimated”.
Instead of DEMO 1.96 (or its rounded value, 2) times the standard deviation DEMO
the sampling distribution to calculate the “plus or minus” for a conﬁdence interval,
we must use a diﬀerent multiplier when we substitute the DEMO SEM for the
true SEM. The multiplier we use is the value (quantile) of a t-distribution that
deﬁnes a central probability of 95% (or some other value we choose). This value is
calculated by DEMO computer (or read oﬀ of a table of the t-distribution), DEMO it does
depend on the number of degrees of freedom of the standard deviation estimate,
which in the simplest case is n− 1 DEMO n is the number of subjects in the speciﬁc
experimental group of interest. When calculating 95% conﬁdence intervals, the
multiplier can be as large as 4.3 for a sample size of 3, but shrinks towards 1.96
as the sample size grows large. This makes sense: if we are more uncertain about
the true value of σ, we need to make a less well deﬁned (wider) claim about where
µ is.
So DEMO we interpret the SEM this way: we are roughly 95% certain DEMO
the true mean (µ) is within about 2 SEM of the sample mean (unless the sample
size is small).
The mean and standard error of the mean from “group statistics” tell
us about how DEMO we have “pinned down” the population mean based
on the inherent variability of the measure and the sample size.
The “Independent Samples Test” box DEMO the actual t-test results under the
row labeled “Equal variances assumed”. The columns labeled “Levene’s Test for
Equality of Variances” are not part of DEMO t-test; they are part of a supplementary
test of the assumption DEMO equality of variances for the two groups. If the Levene’s
Test p-value (labeled “Sig” , for “signiﬁcance”, in SPSS output) is less than or
equal to 0.05 then we would begin to worry that the DEMO variance assumption is
violated, thus casting doubt on the validity of DEMO t-test’s p-value. For our example,
the Levene’s test p-value of 0.272 suggests that there is no need for worry about
6.4. RETURN TO THE HCI EXAMPLE
169
that particular assumption.
The seven DEMO under “t-test for Equality of Means” are the actual t-test
results. The t-statistic is given as 0.30. It is negative when the mean of DEMO second
group entered is larger than that of the ﬁrst. The degrees of freedom are given
under “df”. The p-value is given under “Sig. (2-tailed)”. The actual diﬀerence
of the means is given next. The DEMO error of that diﬀerence is given next.
Note that the t-statistic is computed from the diﬀerence of means and the SE of
that diﬀerence DEMO diﬀerence/(SE of diﬀerence). Finally a 95% conﬁdence interval
is DEMO for the diﬀerence of means. (You can use the Options button DEMO compute
a diﬀerent sized conﬁdence interval.)
SPSS (but not many DEMO programs) automatically gives a second line labeled
“Equal variances not assumed”. DEMO is from one of the adjusted formulas to cor-
rect for unequal group variances. The computation of a p-value in the unequal
variance case DEMO quite an unsettled and contentious problem (called the Behrens-
Fisher problem) and the answer given by SPSS is reasonably good, but not gen-
erally agreed upon. So if the p-value of the Levene’s test is DEMO than or equal to
0.05, many people would use the second DEMO to compute an adjusted p-value (“Sig.
(2-tailed)”), SEM, DEMO CI based on a diﬀerent null sampling distribution for the
t-statistic in which the df are adjusted an appropriate amount downward. If there
is DEMO evidence of unequal variances, the second line is just ignored.
For DEMO assumption checking, ﬁgure6.6shows separate histograms of the
residuals for the two DEMO with overlaid Normal pdfs. With such a small sample
size, we DEMO expect perfectly shaped Normal distributions, even if the Nor-
mal error DEMO is perfectly true. The histograms of the residuals in this ﬁgure
look reasonably consistent with Normal distributions with fairly equal standard
deviation, so we are not too concerned about breaking the model assumptions of
normality or DEMO variance, and we have a fair amount of conﬁdence in our DEMO
ferences (validity or “correctness” of the p-value). In more complex DEMO, we
will usually substitute a “residual vs. ﬁt” plot and a DEMO plot of the
residuals for these assumption checking plots.
170
CHAPTER 6. T-TEST
Figure 6.6: Histograms of residuals.
In a nutshell: To analyze a two-group quantitative outcome experi-
ment, ﬁrst perform EDA DEMO get a sense of the direction and size of the
eﬀect, DEMO assess the normality and equal variance assumptions, and
to look for DEMO Then perform a t-test (or equivalently, a one-
way ANOVA). If the assumption checks are OK, reject or retain the
null hypothesis of equal population means based on a small or large
p-value, respectively.
Chapter 7
One-way ANOVA
One-way ANOVA examines equality of population means for DEMO quantitative out-
come and a single categorical explanatory variable with any number of levels.
The t-test of Chapter6looks at quantitative outcomes with a categorical DEMO
planatory variable that has only two levels. The one-way Analysis of Variance
(ANOVA) can be used for the case of a quantitative outcome DEMO a categorical
explanatory variable that has two or more levels of treatment. The term one-
way, also called one-factor, indicates that there is DEMO single explanatory variable
(“treatment”) with two or more levels, and DEMO one level of treatment is applied
at any time for a given subject. In this chapter we assume that each subject is ex-
posed DEMO only one treatment, in which case the treatment variable is being DEMO
“between-subjects”. For the alternative in which each subject is exposed to several
or all levels of treatment (at diﬀerent times) we use the DEMO “within-subjects”,
but that is covered Chapter14. We use the term two-way or two-factor ANOVA,
when the levels of two diﬀerent explanatory variables DEMO being assigned, and each
subject is assigned to one level of DEMO factor.
It is worth noting that the situation for which we can choose between one-way
ANOVA and an independent samples t-test is when the DEMO variable has
exactly two levels. In that case we always come to the same conclusions regardless
of which method we use.
The term “analysis DEMO variance” is a bit of a misnomer. In ANOVA we use
variance-like quantities to study the equality or non-equality of population means.
So we DEMO analyzing means, not variances. There are some unrelated methods,
171
172
CHAPTER 7. ONE-WAY ANOVA
such as “variance component analysis” which have DEMO as the primary focus
for inference.
7.1 Moral Sentiment Example
As an example of application of one-way ANOVA consider the research reported
in “Moral DEMO and cooperation: Diﬀerential inﬂuences of shame and guilt”
by de Hooge, Zeelenberg, and M. Breugelmans (Cognition & Emotion,21(5): 1025-
DEMO, 2007).
As background you need to know that there is DEMO well-established theory of Social
Value Orientations or SVO (seeWikipediafor a brief DEMO and references).
SVOs represent characteristics of people with regard to their basic motivations.
In this study a questionnaire called the Triple Dominance Measure DEMO used to
categorize subjects into “proself” and “prosocial” orientations. In this chapter we
will examine simulated data based on the results for the proself DEMO
The goal of the study was to investigate the eﬀects of emotion on cooperation.
The study was carried out using undergraduate economics and psychology DEMO
in the Netherlands.
The sole explanatory variable is “induced emotion”. This is a nominal cat-
egorical variable with three levels: control, guilt and DEMO Each subject was
randomly assigned to one of the three levels of treatment. Guilt and shame were
induced in the subjects by asking them DEMO write about a personal experience where
they experienced guilt or shame respectively. The control condition consisted of
having the subject write about what they DEMO on a recent weekday. (The validity
of the emotion induction was DEMO by asking the subjects to rate how strongly
they were feeling a variety of emotions towards the end of the experiment.)
After inducing DEMO of the three emotions, the experimenters had the subjects
participate in DEMO one-round computer game that is designed to test cooperation.
Each subject initially had ten coins, with each coin worth 0.50 Euros for the
subject but 1 Euro for their “partner” who is presumably connected separately
to DEMO computer. The subjects were told that the partners also had ten coins,
each worth 0.50 Euros for themselves but 1 Euro for the DEMO The subjects
decided how many coins to give to the interaction partner, without knowing how
many coins the interaction partner would give. In this game, both participants
would earn 10 Euros when both oﬀered all coins to the interaction partner (the
7.1. MORAL SENTIMENT EXAMPLE
173
cooperative option). If a cooperator gave DEMO 10 coins but their partner gave none,
the cooperator could end up with nothing, and the partner would end up with the
maximum of 15 Euros. Participants could avoid the possibility of earning nothing
by DEMO all their coins to themselves which is worth 5 Euros plus 1 Euro for each
coin their partner gives them (the selﬁsh option). The number of coins oﬀered was
the measure of cooperation.
The number DEMO coins oﬀered (0 to 10) is the outcome variable, and DEMO called
“cooperation”. Obviously this outcome is related to the concept of “cooperation”
and is in some senses a good measure of cooperation, but just as obviously, it is
not a complete measure of the concept.
Cooperation as deﬁned here is a discrete quantitative variable with a limited
range DEMO possible values. As explained below, the Analysis of Variance statistical
procedure, like the t-test, is based on the assumption of a Gaussian distribution
of the outcome at each level of the (categorical) explanatory variable. DEMO this
case, it is judged to be a reasonable approximation to DEMO “cooperation” as a
continuous variable. There is no hard-and-fast rule, but DEMO diﬀerent values might
be considered borderline, while, e.g., 5 diﬀerent DEMO would be hard to justify as
possibly consistent with a Gaussian distribution.
Note that this is a randomized experiment. The levels of “treatment” (emotion
induced) are randomized and assigned by the experimenter. If we do see evidence
that “cooperation” diﬀers among the groups, we can validly claim that induced
emotion causes diﬀerent degrees of cooperation. If we had only measured DEMO
subjects’ current emotion rather than manipulating it, we could only conclude
DEMO emotion is associated with cooperation. Such an association could have other
explanations than a causal relationship. E.g., poor sleep the night before could
cause more feelings of guilt and more cooperation, without the guilt having any
direct eﬀect on cooperation. (See section8.1for more on causality.)
The data can be found inMoralSent.dat. The data look like this:
emotion cooperation
DEMO 3
Control 0
Control 0
Typical exploratory data analyses include a tabulation of the frequencies of the
levels of a categorical explanatory variable like DEMO Here we see 39 controls,
42 guilt subjects, and 45 DEMO subjects. Some sample statistics of cooperation
broken down by each level of induced emotion are shown in table7.1, and side-by-
174
CHAPTER 7. ONE-WAY ANOVA
Figure 7.1: Boxplots of cooperation by induced emotion.
side boxplots shown in ﬁgure7.1.
Our initial impression is that cooperation DEMO higher for guilt than either shame
or the control condition. The mean cooperation for shame is slightly lower than
for the control. In terms DEMO pre-checking model assumptions, the boxplots show
fairly symmetric distributions with fairly DEMO spread (as demonstrated by the
comparative IQRs). We see four DEMO outliers for the shame group, but careful
thought suggests that this DEMO be unimportant because they are just one unit of
measurement (coin) into the outlier region and that region may be “pulled in’ a
DEMO by the slightly narrower IQR of the shame group.
7.1. MORAL SENTIMENT EXAMPLE
175
Induced
emo-
tion
Cooperation Control Mean
score DEMO Conﬁdence Lower Bound
Interval for Mean Upper Bound
Median
Std. Deviation
Minimum
Maximum
Skewness
Kurtosis
Guilt Mean
95% Conﬁdence Lower Bound
Interval for Mean DEMO Bound
Median
Std. Deviation
Minimum
Maximum
Skewness
Kurtosis
Shame Mean
95% Conﬁdence Lower Bound
Interval for Mean Upper Bound
Median
Std. Deviation
Minimum
Maximum
DEMO
Kurtosis
Statistic
3.49
2.48
4.50
3.00
3.11
0
10
0.57
-0.81
5.38
4.37
6.39
6.00
3.25
0
10
-0.19
-1.17
3.78
2.89
4.66
4.00
DEMO
0
10
0.71
-0.20
Std.Error
0.50
0.38
0.74
0.50
0.36
0.72
0.44
0.35
0.70
Table 7.1: Group statistics for the moral sentiment experiment.
176 CHAPTER 7. ONE-WAY ANOVA
7.2 How one-way ANOVA works
7.2.1 The DEMO and statistical hypotheses
One-way ANOVA is appropriate when the following model holds. We have a single
“treatment” with, say, k levels. “Treatment” may DEMO interpreted in the loosest
possible sense as any categorical explanatory variable. There is a population of
interest for which there is a true quantitative DEMO for each of the k levels
of treatment. The population outcomes for each group have mean parameters
that we can label µ1 through µk DEMO no restrictions on the pattern of means.
The population variances for the outcome for each of the k groups deﬁned by the
levels of DEMO explanatory variable all have the same value, usually called σ2, with
no restriction other than that σ2 > 0. For treatment i, the distribution of the
outcome is assumed to follow a Normal distribution with DEMO µi and variance σ2,
often written N (µi,σ2).
DEMO model assumes that the true deviations of observations from their corre-
sponding group mean parameters, called the “errors”, are independent. In this
context, independence indicates that knowing one true deviation would not help
us predict DEMO other true deviation. Because it is common that subjects who have
a high outcome when given one treatment tend to have a high outcome DEMO given
another treatment, using the same subject twice would violate the DEMO
assumption.
Subjects are randomly selected from the population, and then randomly DEMO
signed to exactly one treatment each. The number of subjects assigned to treat-
ment i (where 1 ≤ i ≤ k) is called DEMO if it diﬀers between treatments or just n if
all of the treatments have the same number of subjects. For convenience, deﬁne
N =(In case you have forgotten, the Greek capital sigma (Σ) stands for summation,P
i.e., adding. In this case, the notation says DEMO we should consider all values of
ni where i is set to 1, 2, ..., k, and then add them all up. DEMO example, if
we have k = 3 levels of treatment, and the group samples sizes are 12, 11, and 14
respectively, then n1 = 12, n2 = 11, n3 = 14 and N
DEMO + 11 + 14 = 37.) = P
k
i=1 ni, which is the total sample size.
k
i=1 ni = n1 + DEMO + n3 =
Because of the random treatment assignment, the sample DEMO for any treat-
ment group is representative of the population mean for assignment to that group
for the entire population.
7.2. HOW ONE-WAY ANOVA WORKS
Technically, the sample group means are unbiased estimators of the
population group means when treatment is randomly assigned. The DEMO
ing of unbiased here is that the true mean of the sampling distribution of
any group sample mean equals the corresponding population mean. Fur-
DEMO, under the Normality, independence and equal variance assumptions
it is true that the sampling distribution of Y¯i is N (µi,σ2/ni), exactly.
177
The statistical model for which one-way ANOVA is appropriate is DEMO
the (quantitative) outcomes for each group are normally distributed
with a common variance (σ2). The errors (deviations of individual
outcomes from DEMO population group means) are assumed to be inde-
pendent. The model DEMO no restrictions on the population group
means.
The term assumption in statistics refers to any speciﬁc part of a statistical
model. For one-way ANOVA, the assumptions are normality, equal variance, and
independence of errors. Correct DEMO of individuals to groups is sometimes
considered to be an implicit assumption.
The null hypothesis is a point hypothesis stating that “nothing interesting is
DEMO For one-way ANOVA, we use H0 : µ1 = ··· = DEMO, which states that all
of the population means are equal, without restricting what the common value is.
The alternative must include everything else, which can be expressed as “at least
one of the k population DEMO diﬀers from all of the others”. It is deﬁnitely wrong
to use HA : µ1 = ···6= µk because some cases, such as µ1 = 5, µ2 = 5, µ3 = 10,
are neither DEMO by H0 nor this incorrect HA. You can write the alternative
hypothesis as “HA : Not µ1 = ··· = µk or “the population DEMO are not all equal”.
One way to correctly write HA mathematically is HA : ∃ i,j : µi = µj.
This null hypothesis DEMO called the “overall” null hypothesis and is the hypothesis
tested by ANOVA, per se. If we have only two levels of our categorical explanatory
178
CHAPTER 7. ONE-WAY ANOVA
variable, then retaining or rejecting the overall null hypothesis, is all that needs to
be done in terms of hypothesis testing. But if we have 3 or more levels (k ≥ 3),
then we usually need to followup on rejection of the overall null hypothesis with
more speciﬁc hypotheses to determine for which population DEMO means we have
evidence of a diﬀerence. This is called contrast testing and discussion of it will be
delayed until chapter13.
The overall null DEMO for one-way ANOVA with k groups is
H0 : µ1 = ··· = µk. The alternative hypothesis is that “the population
means are not DEMO equal”.
7.2.2 The F statistic (ratio)
The next step in DEMO inference is to select a statistic for which we can compute
the null sampling distribution and that tends to fall in a diﬀerent region DEMO the
alternative than the null hypothesis. For ANOVA, we use the DEMO The
single formula for the F-statistic that is shown in most textbooks is quite complex
and hard to understand. But we can build it DEMO in small understandable steps.
Remember that a sample variance is calculated as SS/df where SS is “sum of
squared deviations from the mean” DEMO df is “degrees of freedom” (see page69).
In ANOVA we DEMO with variances and also “variance-like quantities” which are
not really the variance of anything, but are still calculated as SS/df. We will call
all of these quantities mean squares or MS. i.e., MS = SS/df , which is a key
formula that you should memorize. Note DEMO these are not really means, because
the denominator is the df, not n.
For one-way ANOVA we will work with two diﬀerent MS DEMO called “mean
square within-groups”, MSwithin, and “mean square between-groups”, MSbetween.
DEMO know the general formula for any MS, so we really just DEMO to ﬁnd the formulas
for SSwithin and SSbetween, and their corresponding DEMO
The F statistic denominator: MSwithin
MSwithin is a “pure” estimate of DEMO that is unaﬀected by whether the null or alter-
native hypothesis is true. Consider ﬁgure7.2which represents the within-group
7.2. HOW ONE-WAY ANOVA WORKS
179
deviations used in the calculation of DEMO for a simple two-group experiment
with 4 subjects in each group. The extension to more groups and/or diﬀerent
numbers of subjects is straightforward.
DEMO 1
Y¯
1 = 4.25
0 20
Group 2
Y¯
2 = 14.00
Figure 7.2: Deviations for within-group sum of squares
The deviation for subject j of group i in ﬁgure7.2is mathematically
j of group i
DEMO
equal to Yij − i where Yij is the observed value for subject
and Y¯i is the sample mean for group i.
I hope DEMO can see that the deviations shown (black horizontal lines extending
from DEMO colored points to the colored group mean lines) are due to DEMO underlying
variation of subjects within a group. The variation has standard deviation σ, so
that, e.g., about 2/3 of the times the deviation lines are shorter than σ. Regardless
of the truth of the DEMO hypothesis, for each individual group, MSi = SSi/dfi is a
good estimate of σ2. The value of MSwithin comes from a statistically DEMO
formula for combining all of the k separate group estimates of σ2. It is important
to know that MSwithin has N − k df.
DEMO an individual group, i, SSi = Pni (Yij −
Y¯
DEMO)2 and dfi = ni − 1. We
j=1
can use some statistical theory beyond the scope of this course to show
that in DEMO, MSwithin is a good (unbiased) estimate of σ2 if it DEMO deﬁned
as
MSwithin = SSwithin/dfwithin
180
CHAPTER 7. ONE-WAY ANOVA
where SSwithin = P
k
i=1 SSi, and dfwithin
= P
k
i=1 dfi
= P
k
i=1(ni
DEMO) = N−k.
MSwithin is a good estimate of σ2 (from our model) regardless of the
truth of H0. This is due to the way SSwithin is deﬁned. SSwithin (and
therefore MSwithin) has N-k degrees DEMO freedom with ni − 1 coming
from each of the k groups.
The F statistic numerator: MSbetween
Y¯
1 = 4.25
Y¯
= 9.125
Group 1
0 20
Group 2
Y¯
2 = 14.00
Figure 7.3: Deviations for between-group sum of squares
Now consider ﬁgure7.3which represents the between-group DEMO used
in the calculation of MSbetween for the same little 2-group 8-subject experiment
as shown in ﬁgure7.2. The single vertical black line is the DEMO of all of the
outcomes values in all of the treatment groups, usually called either the overall
mean or the grand mean. The colored vertical lines are still the group means. The
horizontal black lines are DEMO deviations used for the between-group calculations.
For each subject we get a deviation equal to the distance (diﬀerence) from that
subject’s group mean DEMO the overall (grand) mean. These deviations are squared
and summed to get SSbetween, which is then divided by the between-group df,
which is k − 1, to get MSbetween.
MSbetween is a good estimate of σ2 only when the null hypothesis is true. In
this case DEMO expect the group means to be fairly close together and close to the
7.2. HOW ONE-WAY ANOVA WORKS
181
grand mean. When the alternate hypothesis DEMO true, as in our current example, the
group means are farther apart and the value of MSbetween tends to be larger than
σ2. (We sometimes write this as “MSbetween is an inﬂated estimate of σ2”.)DEMO
SSbetween is the sum of the N squared between-group deviations, where
DEMO deviation is the same for all subjects in the same group. The formula
is
where
Y¯
k
SSbetween = X
=1
ni(
Y¯
DEMO
i
−
Y¯
)2
is the grand mean. Because the k DEMO deviations add up to
zero, we are free to choose only DEMO − 1 of them, and then the last one is
fully DEMO by the others, which is why dfANOVA. between = k− 1 DEMO one-way
Because of the way SSbetween is deﬁned, MSbetween is a DEMO estimate
of σ2 only if H0 is true. Otherwise it tends to be larger. SSbetween
(and therefore MSbetween) has k − 1 degrees DEMO freedom.
The F statistic ratio
It might seem that we only need MSbetween to distinguish the null from the alter-
native hypothesis, but that ignores the fact that we don’t usually know the value
of σ2. DEMO instead we look at the ratio
F = MSbetween
MSwithin
to evaluate the null hypothesis. Because the denominator is always (under null
and alternative hypotheses) an estimate of σ2 (i.e., tends to have a value near σ2),
and the numerator is either another estimate of σ2 (under the null hypothesis) or
is inﬂated (under the alternative hypothesis), it is clear that the (random) values
of the F-statistic (from experiment to experiment) tend to fall around 1.0 when
182
CHAPTER 7. ONE-WAY ANOVA
the null hypothesis is true and are DEMO when the alternative is true. So if we
can compute the sampling distribution of the F statistic under the null hypothesis,
then we DEMO have a useful statistic for distinguishing the null from the alternative
hypotheses, where large values of F argue for rejection of H0.
The F-statistic, deﬁned by F = MSbetween , tends to be larger if the
MSwithin
alternative hypothesis is true than if the null hypothesis is true.
DEMO Null sampling distribution of the F statistic
Using the technical condition that the quantities MSbetween and MSwithin are in-
dependent, we can apply probability and statistics techniques (beyond the scope
of this course) to show DEMO the null sampling distribution of the F statistic is that
of the “F-distribution” (see section3.9.7). The F-distribution is indexed by two
numbers called the numerator and denominator degrees of freedom. This indicates
that there are (inﬁnitely) many F-distribution pdf curves, and we must specify
these two DEMO to select the appropriate one for any given situation.
Not surprisingly the null sampling distribution of the F-statistic for any given
one-way ANOVA is DEMO F-distribution with numerator degrees of freedom equal to
dfbetween = k − 1 and denominator degrees of freedom equal to dfwithin = N − DEMO
Note that this indicates that the kinds of F-statistic values we will see if the
null hypothesis is true depends only on the number DEMO groups and the numbers
of subjects, and not on the values DEMO the population variance or the population
group means. It is worth mentioning that the degrees of freedom are measures
of the “size” of the DEMO, where bigger experiments (more groups or more
subjects) have bigger DEMO
We can quantify “large” for the F-statistic, by comparing it to DEMO null
sampling distribution which is the speciﬁc F-distribution which has
degrees of freedom matching the numerator and denominator of the
F-statistic.
7.2. HOW ONE-WAY ANOVA WORKS
df=1,10
df=2,10
df=3,10
df=3,DEMO
183
0
1
2
F
3
4
Figure 7.4: A variety DEMO F-distribution pdfs.
5
The F-distribution is a non-negative distribution in the sense that F
values, which are squares, can never be negative numbers. DEMO distribution
is skewed to the right and continues to have some tiny probability no matter
how large F gets. The mean of the distribution DEMO s/(s− 2), where s is the
denominator degrees of DEMO So if s is reasonably large then the mean
is near 1.00, but if s is small, then the mean is larger (e.g., k=2, n=4 per
group gives s=3+3=6, and a mean of 6/4=1.5).
Examples of F-distributions with diﬀerent numerator and denominator degrees
of DEMO are shown in ﬁgure7.4. These curves are probability density functions,
so the regions on the x-axis where the curve is high are the DEMO most likely
to occur. And the area under the curve between any two F values is equal to
the probability that a random variable DEMO the given distribution will fall
between those values. Although very low F values are more likely for, say, the
Density
0.0
0.5
1.0
DEMO
2.0
2.5
3.0
184
CHAPTER 7. ONE-WAY ANOVA
Observed F−statistic=2.0
shaded area is 0.178
0
DEMO
2
F
3
4
5
Figure 7.5: The F(3,10) pdf and the p-value for F=2.0.
F(1,10) distribution than the F(3,10) distribution, very high values are also more
common DEMO the F(1,10) than the F(3,10) values, DEMO this may be hard to
see in the ﬁgure. The bigger the numerator and/or denominator df, the more
concentrated the F values will be around 1.0.
7.2.4 Inference: hypothesis testing
There are two ways to use the null sampling distribution of F in one-way ANOVA:
to DEMO a p-value or to ﬁnd the “critical value” (see below).
DEMO close up of the F-distribution with 3 and 10 degrees of freedom is shown
in ﬁgure7.5. This is the appropriate null sampling distribution of DEMO F-statistic
for an experiment with a quantitative outcome and one categorical explanatory
variable (factor) with k=4 levels (each subject gets one of four diﬀerent possible
treatments) and with 14 subjects divided among the 4 groups. A vertical line
marks an F-statistic of 2.0 (the observed value from some experiment). The p-
value for this result is the chance DEMO getting an F-statistic greater than or equal to
Density
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
7.2. HOW ONE-WAY ANOVA WORKS
185
F−critical for alpha=0.05
0
1
2
DEMO
3
4
5
Figure 7.6: The F(3,10) pdf and its alpha=0.05 critical value.
2.0 when the null hypothesis is true, which is the shaded area. The total area is
always 1.0, and the shaded area is 0.178 in this example, so the p-value is 0.178
(not signiﬁcant at the usual 0.05 alpha level).
Figure7.6shows another close up of the F-distribution with 3 and 10 degrees of
freedom. We DEMO use this ﬁgure to deﬁne and calculate the F-critical value. For
a given alpha (signiﬁcance level), usually 0.05, the F-critical value is DEMO F value
above which 100α% of the null sampling distribution occurs. For experiments with
3 and 10 df, and using α = 0.05, DEMO ﬁgure shows that the F-critical value is 3.71.
Note that this value can be obtained from a computer before the experiment is run,
DEMO long as we know how many subjects will be studied and how many levels the
explanatory variable has. Then when the experiment is run, we can calculate the
observed F-statistic and compare it to F-critical. If DEMO statistic is smaller than
the critical value, we retain the null DEMO because the p-value must be bigger
than α, and if the DEMO is equal to or bigger than the critical value, we reject
DEMO null hypothesis because the p-value must be equal to or smaller than α.
Density
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
186
CHAPTER 7. ONE-WAY ANOVA
7.2.5 Inference: conﬁdence intervals
It is often worthwhile to express what we have learned from an experiment in
terms DEMO conﬁdence intervals. In one-way ANOVA it is possible to make conﬁdence
intervals for population group means or for diﬀerences in pairs of population group
DEMO (or other more complex comparisons). We defer discussion of the DEMO to
chapter13.
Construction of a conﬁdence interval for a population group means is
usually done as an appropriate “plus or minus” amount around a DEMO
2
group mean. We use MSition, the standard error of the DEMO is6.2.7, the multiplier for the standard error of the mean is DEMO so calledwithin as an estimate ofqMSwithin/nσi. As discussed in sec-, DEMO then for group
“quantile of the t-distribution” which deﬁnes a central area equal to the de-
sired conﬁdence level. This comes from a computer DEMO table of t-quantiles.
For a 95% CI this is often symbolized as t0.025,df where df is the degrees of
freedom of MSor minus (SEM times the multiplier).within, (N − k). Construct the DEMO as the sample mean plus
In a nutshell: In one-way ANOVA DEMO calculate the F-statistic as the
ratio MSbetween/MSwithin. Then the p-value is calculated as the area
under the appropriate null sampling distribution of F DEMO is bigger
than the observed F-statistic. We reject the null hypothesis if p ≤ α.
7.3 Do it in SPSS
To run a one-way DEMO in SPSS, use the Analyze menu, select Compare Means,
then One-Way ANOVA. Add the quantitative outcome variable to the “Dependent
List”, and the categorical explanatory variable to the “Factor” box. Click OK to
get DEMO output. The dialog box for One-Way ANOVA is shown in ﬁgure7.7.
You can also use the Options button to perform descriptive statistics by group,DEMO
perform a variance homogeneity test, or make a means plot.
7.4. READING THE ANOVA TABLE
187
Figure 7.7: One-Way ANOVA dialog box.
You can use the Contrasts button to specify particular planned contrasts among
DEMO levels or you can use the Post-Hoc button to make unplanned contrasts (cor-
rected for multiple comparisons), usually using the Tukey procedure for all pairs or
the Dunnett procedure when comparing each level to a DEMO level. See chapter
13for more information.
7.4 Reading the ANOVA table
The ANOVA table is the main output of an ANOVA analysis. It always DEMO the
“source of variation” labels in the ﬁrst column, plus additional DEMO for “sum
of squares”, “degrees of freedom”, “means square”, F, and the p-value (labeled
“Sig.” in SPSS).
For one-way ANOVA, DEMO are always rows for “Between Groups” variation
and “Within Groups” variation, DEMO often a row for “Total” variation. In one-way
ANOVA there is only a single F statistic (MSbetween/MSwithin), and this is shown
on the “Between Groups” row. There is also only one p-value, because there is only
one (overall) null hypothesis, namely H0 : µ1 = ··· = µk, and because the p-value
comes from comparing the (DEMO) F value to its null sampling distribution. The
calculation of MS DEMO the total row is optional.
Table7.2shows the results for the moral sentiment experiment. There are
several important aspects to this table that you should DEMO First, as
discussed above, the “Between Groups” lines refer to the variation of the group
means around the grand mean, and the “Within Groups” line refers to the variation
188
CHAPTER 7. ONE-WAY ANOVA
Between Groups
Within Groups
Total
Sum of DEMO
86.35
1181.43
1267.78
df
2
123
125
Mean Square
43.18
9.60
F
4.50
Table 7.2: ANOVA for the moral sentiment experiment.
Sig.
0.013
of the subjects around their group means. The “Total” line refers to variation DEMO
the individual subjects around the grand mean. The Mean Square for the Total
line is exactly the same as the variance of all of DEMO data, ignoring the group
assignments.
In any ANOVA table, the df column refers to the number of degrees of freedom
in the particular DEMO deﬁned on the same line. The MS on any line is always equal
to the SS/df for that line. F-statistics are given on DEMO line that has the MS that
is the numerator of the F-statistic (ratio). The denominator comes from the MS
of the “Within Groups” line for one-way ANOVA, but this is not always true for
other types of ANOVA. It is always true that there is a p-value DEMO each F-statistic,
and that the p-value is the area under the null sampling distribution of that F-
statistic that is above the (observed) F value shown in the table. Also, we can
always tell DEMO F-distribution is the appropriate null sampling distribution for
any F-statistic, by DEMO the numerator and denominator df in the table.
An ANOVA is a breakdown of the total variation of the data, in the form of
SS and df, into smaller independent components. For the one-way ANOVA, DEMO
break down the deviations of individual values from the overall mean of the data
into deviations of the group means from the overall mean, and then deviations
of the individuals from their group means. The independence DEMO these sources of
deviation results in additivity of the SS and df columns (but not the MS column).
So we note that SSTotal = SSBetween +SSWithin and dfTotal = dfBetween +dfWithin.
This fact can be DEMO to reduce the amount of calculation, or just to check that
DEMO calculation were done and recorded correctly.
Note that we can calculate MSTotal = 1267.78/125 = 10.14 which is the vari-
ance of all DEMO the data (thrown together and ignoring the treatment groups). You
DEMO see that MSTotal is certainly not equal to MSBetween + MSWithin.
Another use of the ANOVA table is to learn about an experiment when DEMO
is not full described (or to check that the ANOVA was DEMO and recorded
7.5. ASSUMPTION CHECKING 189
correctly). Just from this one-way ANOVA table, we can see that there were 3
treatment groups (because dfBetween is one less than the number of groups). Also,
we can DEMO that there were 125+1=126 subjects in the experiment.
Finally, it is DEMO knowing that MSwithin is an estimate of σ2, the variance of
DEMO around their group mean. So we can take the square root of MSwithin
to get an estimate of σ, the standard deviation. Then we know that the majority
(about 2 ) of the measurements for each group are within σ of the group mean and
3
most (about 95%) are within 2σ, assuming a Normal distribution. In this example
DEMO estimate of the s.d. is √9.60 = 3.10, so individual subject DEMO values
more than 2(3.10)=6.2 coins from their group means would be uncommon.
You should understand the structure of the one-way ANOVA table
DEMO that MS=SS/df for each line, SS and df are additive, F is
the ratio of between to within group MS, the p-value comes from the
F-statistic and its presumed (under model assumptions) null DEMO
distribution, and the number of treatments and number of subjects
can DEMO calculated from degrees of freedom.
7.5 Assumption checking
Except for the skewness of the shame group, the skewness and kurtosis statistics for
all three groups are within 2SE of zero (see Table7.1), and that one skewness is only
slightly beyond 2SE from zero. This suggests that there DEMO no evidence against the
Normality assumption. The close similarity of the three group standard deviations
suggests that the equal variance assumption is OK. And DEMO the subjects are
totally unrelated, so the independent errors assumption is DEMO Therefore we can
accept that the F-distribution used to calculate the p-value from the F-statistic is
the correct one, and we “believe” the p-value.
7.6 Conclusion about moral sentiments
With p = 0.013 < 0.05, we reject the null hypothesis that all three of the group
population means DEMO cooperation are equal. We therefore conclude that diﬀerences
190
CHAPTER 7. ONE-WAY ANOVA
in mean cooperation are caused by the DEMO emotions, and that among control,
guilt, and shame, at DEMO two of the population means diﬀer. Again, we defer
looking at DEMO groups diﬀer to chapter13.
(A complete analysis would also include examination DEMO residuals for additional
evaluation of possible non-normality or unequal spread.)
The F-statistic of one-way ANOVA is easily calculated by a computer.
The p-value DEMO calculated from the F null sampling distribution with
matching degrees of freedom. But only if we believe that the assump-
tions of the model DEMO (approximately) correct should we believe that
the p-value was calculated from the correct sampling distribution, and
it is then valid.
Chapter 8
Threats to Your Experiment
Planning to avoid criticism.
One of DEMO main goals of this book is to encourage you to think from the point
of view of an experimenter, because other points of view, such as that of a reader
of scientiﬁc articles or a consumer of scientiﬁc ideas, are easy to switch to after the
experimenter’s point of view is understood, but the reverse is often not true. In
other words, to enhance the usability of what you learn, you DEMO pretend that
you are a researcher, even if that is not DEMO ultimate goal.
As a researcher, one of the key skills you DEMO be developing is to try, in
advance, to think of all of the possible criticisms of your experiment that may arise
from the DEMO of an article you write or the reader of an article you publish.
This chapter discusses possible complaints about internal validity, external validity,
construct validity, Type 1 error, and power.
We are using “threats” DEMO mean things that will reduce the impact of
your study results on science, particularly those things that we have
some control over.
191
192
CHAPTER 8. THREATS TO YOUR EXPERIMENT
8.1 Internal validity
In a DEMO experiment in its simplest form we manipulate variable X
and observe the eﬀects on variable Y. For example, outcome Y could be number
of people who purchase a particular item in a store over a certain DEMO, and X
8.1. INTERNAL VALIDITY
193
could be some characteristics of the display for DEMO item, such as use of pictures
of people of diﬀerent “status” DEMO an in-store advertisement (e.g., a celebrity vs. an
unknown model). Internal validity is the degree to which we can appropriately
conclude that DEMO changes in X caused the changes in Y.
The study of causality goes back thousands of years, but there has been a resur-
gence of interest recently. For our purposes we can deﬁne causality as the DEMO of
nature in which an active change in one variable directly changes the probability
distribution of another variable. It does not mean that a DEMO “treatment”
is always followed by a particular outcome, but rather that DEMO probability is
changed, e.g. a higher outcome is more likely with DEMO particular treatment com-
pared to without. A few ideas about causality are worth thinking about now.
First, association, which is equivalent to non-zero DEMO (see section3.6.1)
in statistical terms, means that we observe that when one variable changes, an-
other one tends to change. We cannot have causation without association, but just
ﬁnding an association is not enought to justify a claim of causation.
Association does not necessarily imply causation.
DEMO variables X and Y (e.g., the number of televisions (X) in various countries
and the infant mortality rate (Y) of those DEMO) are found to be associated,
then there are three basic DEMO First X could be causing Y (televisions
lead to more health DEMO, which leads to better prenatal care) or Y could be
causing X (high infant mortality leads to attraction of funds from richer countries,
which leads to more televisions) or unknown factor Z could be causing both X
and Y (higher wealth in a country leads to more televisions and more prenatal
care clinics). It is worth memorizing DEMO three cases, because they should always
be considered when association is DEMO in an observational study as opposed to
a randomized experiment. (It DEMO also possible that X and Y are related in more
complicated ways including in large networks of variables with feedback loops.)
Causation (“X causes Y”) can be logically claimed if X and Y are associated,
and X precedes Y, and no plausible alternative explanations can be found, par-
ticularly those of the form “X just happens to vary along with some real cause of
changes in Y” (called confounding).
Returning to the advertisement example, one stupid thing to do is to place all of
the high status pictures in only the wealthiest neighborhoods DEMO the largest stores,
194
CHAPTER 8. THREATS TO YOUR EXPERIMENT
while the low status pictures DEMO only shown in impoverished neighborhoods or
those with smaller stores. In that case a higher average number of items purchased
for the stores with DEMO status ads may be either due to the eﬀect of socio-economic
status or store size or perceived status of the ad. When more than DEMO thing is
diﬀerent on average between the groups to be compared, DEMO problem is called
confounding and confounding is a fatal threat to internal validity.
Notice that the deﬁnition of confounding mentions “diﬀerent on average”. This
DEMO because it is practically impossible to have no diﬀerences between the subjects
in diﬀerent groups (beyond the diﬀerences in treatment). So our realistic goal is
to have no diﬀerence on average. For example if we DEMO studying both males and
females, we would like the gender ratio DEMO be the same in each treatment group.
For the store example, DEMO want the average pre-treatment total sales to be the
same in each treatment group. And we want the distance from competitors to be
the DEMO, and the socio-economic status (SES) of the neighborhood, and the racial
makeup, and the age distribution of the neighborhood, etc., etc. Even worse, we
want all of the unmeasured variables, both those DEMO we thought of and those we
didn’t think of, to be DEMO in each treatment group.
The sine qua non of internal validity is random assignment of treatment
to experimental units (diﬀerent stores in our ad example). Random treatment
assignment (also called randomization) is usually the DEMO way to assure that all
of the potential confounding variables are equal on average (also called balanced)
among the treatment groups. Non-random assignment will usually lead to either
consciously or unconsciously unbalanced groups. If one DEMO a few variables, such
as gender or SES, are known to be critical factors aﬀecting outcome, a good al-
ternative is block randomization, in which randomization among treatments is
performed separately for each level of the critical (non-manipulated) explanatory
factor. This helps to assure that the DEMO of this explanatory factor is balanced
(not confounded) across the levels of the treatment variable.
In current practice randomization is normally done using DEMO random
number generators. Ideally all subjects are identiﬁed before the experiment begins
and assigned numbers from 1 to N (the total number of subjects), and then a
computer’s random number generator is used to assign DEMO to the subjects
via these numbers. For block randomization this can be done separately for each
block. If all subjects cannot be identiﬁed before DEMO experiment begins, some way
must be devised to assure that each DEMO has an equal chance of getting each
treatment (if equal assignment DEMO desired). One way to do this is as follows. If
8.1. INTERNAL VALIDITY
195
there are k levels of treatment, then collect the subjects until k (or 2k or 3k,
etc) are DEMO, then use the computer to randomly assign treatments among
the available DEMO It is also acceptable to have the computer individually
generate a random number from 1 to k for each subject, but it must be assured
that the subject and/or researcher cannot re-run the process if DEMO don’t like the
assignment.
Confounding can occur because we purposefully, but DEMO, design our exper-
iment such that two or more things diﬀer DEMO once, or because we assign treatments
non-randomly, or because the randomization “failed”. As an example of designed
confounding, consider the treatments “drug plus psychotherapy” vs. “placebo” for
treating depression. If a diﬀerence is found, then we will not know whether the
success of the treatment is due DEMO the drug, the psychotherapy or the combination.
If no diﬀerence is DEMO, then that may be due to the eﬀect of drug canceling
DEMO the eﬀect of the psychotherapy. If the drug and the psychotherapy are known
to individually help patients with depression and we really do want DEMO study the
combination, it would probably better to have a study DEMO the three treatment
arms of drug, psychotherapy, and combination (with DEMO without the placebo), so
that we could assess the speciﬁc important questions of whether drug adds a ben-
eﬁt to psychotherapy and vice DEMO As another example, consider a test of the
eﬀects of a DEMO herbal supplement on memory. Again, a success tells us that
something DEMO the mix helps memory, but a follow-up trial is needed to DEMO if all of
the components are necessary. And again we have the possibility that one compo-
nent would cancel another out causing a “no DEMO outcome when one component
really is helpful. But we must also consider that the mix itself is eﬀective while
the individual components are not, so this might be a good experiment.
In terms of non-random assignment DEMO treatment, this should only be done
when necessary, and it should be recognized that it strongly, often fatally, harms
the internal validity DEMO the experiment. If you assign treatment in some pseudo-
random way, DEMO alternating treatment levels, you or the subjects may purposely
or inadvertently DEMO confounding factors into your experiment.
Finally, it must be stated that DEMO randomization cannot perfectly balance
all possible explanatory factors, it is the DEMO way to attempt this, particularly
for unmeasured or unimagined factors that DEMO aﬀect the outcome. Although
there is always a small chance that important factors are out of balance after
random treatment assignment (i.e., failed DEMO), the degree of imbalance
is generally small, and gets smaller DEMO the sample size gets larger.
196
CHAPTER 8. THREATS TO YOUR EXPERIMENT
In experiments, as opposed to observational studies, the assignment
of levels of the explanatory variable to study units is under the control
of the experimenter.
Experiments diﬀer from observational DEMO in that in an experiment at
least the main explanatory variables of interest are applied to the units of obser-
vation (most commonly subjects) under the control of the experimenter. Do not
be fooled into thinking that just because a lot of careful work has gone into a
DEMO, it must therefore be an experiment. In contrast to experiments, in obser-
vational studies the subjects choose which treatment they receive. For example,DEMO
if we perform magnetic resonance imaging (MRI) to study the eﬀects of string
instrument playing on the size of Broca’s area of the DEMO, this is an observational
study because the natural proclivities of the DEMO determine which “treatment”
level (control or string player) each subject has. The experimenter did not control
this variable. The main advantage of an DEMO is that the experimenter can
randomly assign treatment, thus removing nearly DEMO of the confounding. In the
absence of confounding, a statistically signiﬁcant DEMO in the outcome provides
good evidence for a causal eﬀect of the explanatory variable(s) on the outcome.
Many people consider internal validity to be not applicable to observational stud-
ies, but I think that in light of the availability of techniques to adjust for some
confounding factors DEMO observational studies, it is reasonable to discuss the internal
validity of DEMO studies.
Internal validity is the ability to make causal conclusions. The huge
advantage of randomized experiments over observational studies, is
that causal conclusions are a natural outcome of the former, but dif-
ﬁcult or impossible to justify in the latter.
Observational studies are always open to the possibility DEMO the eﬀects seen are
due to confounding factors, and therefore have DEMO internal validity. (As mentioned
above, there are a variety of statistical techniques, beyond the scope of this book,
which provide methods that attempt to “correct for” some of the confounding in
observational studies.) As another example consider the eﬀects of vitamin C on the
common cold. DEMO study that compares people who choose to take vitamin C versus
those who choose not to will have many confounders and low internal validity. DEMO
8.1. INTERNAL VALIDITY
197
study that randomly assigns vitamin C versus a DEMO will have good internal
validity, and in the presence of a DEMO signiﬁcant diﬀerence in the frequency
of colds, a causal eﬀect can DEMO claimed.
Note that confounding is a very speciﬁc term relating to the presence of a diﬀer-
ence in the average level of any explanatory DEMO across the treatment groups.
It should not be used according to its general English meaning of “something
confusing”.
Blinding (also called masking) is DEMO key factor in internal validity. Blind-
ing indicates that the subjects are prevented from knowing which (level of) treat-
ment they have received. DEMO subjects know which treatment they are receiving and
believe that it will aﬀect the outcome, then we may be measuring the eﬀect of
the belief rather than the eﬀect of the treatment. In psychology this is DEMO the
Hawthorne eﬀect. In medicine it is called the placebo eﬀect. As an example,
in a test of the causal eﬀects of acupuncture DEMO pain relief, subjects may report
reduced pain because they believe the DEMO should be eﬀective. Some re-
searchers have made comparisons between acupuncture with needles placed in the
“correct” locations versus similar but “incorrect” locations. When DEMO subjects
who are not experienced in acupuncture, this type of experiment DEMO much bet-
ter internal validity because patient belief is not confounding the eﬀects of the
acupuncture treatment. In general, you should attempt to prevent subjects from
knowing which treatment they are receiving, if that is possible and ethical, so that
you can avoid the placebo eﬀect (prevent DEMO of belief in eﬀectiveness of
treatment with the treatment itself), and ultimately prevent valid criticisms about
the interval validity of your experiment. On DEMO other hand, when blinding is not
possible, you must always be open to the possibility that any eﬀects you see are
due to DEMO subjects’ beliefs about the treatments.
Double blinding refers to blinding the subjects and also assuring that the
experimenter does not know which treatment the DEMO is receiving. For exam-
ple, if the treatment is a pill, a placebo pill can be designed such that neither the
subject nor DEMO experimenter knows what treatment has been randomly assigned
to each subject. This prevents confounding in the form of diﬀerence in treatment
application (e.g., DEMO experimenter could subconsciously be more encouraging to
subjects in one of the treatment groups) or in assessment (e.g, if there is some
subjectivity in assessment, the experimenter might subconsciously give better as-
sessment scores to subjects in one of the treatment groups). Of course, double
blinding is not always possible, and when it is not used you should be open to
198
CHAPTER 8. THREATS TO YOUR EXPERIMENT
the possibility that that any DEMO you see are due to diﬀerences in treatment
application or assessment by the experimenter.
Triple blinding refers to not letting the person doing the DEMO
analysis know which treatment labels correspond to which actual treat-
ments. Although rarely used, it is actually a good idea because there
are several places in most analyses where there is subjective judgment in-
volved, and a biased analyst may subconsciously make decisions that push
the results toward DEMO desired conclusion. The label “triple blinding” is also
applied to blinding of the rater of the outcome in addition to the subjects
and the DEMO (when the rater is a separate person).
Besides lack of DEMO and lack of blinding, omission of a control group
is a DEMO of poor internal validity. A control group is a treatment group that
represents some appropriate baseline treatment. It is hard to describe exactly what
DEMO baseline treatment” means, and this often requires knowledge of the
subject DEMO and good judgment. As an example, consider an experiment designed
to DEMO the eﬀects of “memory classes” on short-term memory performance. If
we have two treatment groups and are comparing subjects receiving two vs. ﬁve
classes, and we ﬁnd a “statistically signiﬁcant diﬀerence”, then we only know that
adding three classes causes a memory improvement, but not if two is better than
none. In some contexts this might not be important, but in others our critics will
claim that there are important unanswered causal DEMO that we foolishly did
not attempt to answer. You should always think about using a good control group,
although it is not strictly DEMO to always use one.
In a nutshell: It is only in DEMO, randomized experiments that we
can assure that the treatment precedes the DEMO, and that there
is little chance of confounding which would allow DEMO expla-
nations. It is these two conditions, along with statistically signiﬁcant
DEMO, which allow a claim of causality.
8.2. CONSTRUCT VALIDITY
8.2 Construct validity
199
Once we have made careful DEMO deﬁnitions of our variables and classiﬁed
their types, we still need DEMO think about how useful they will be for testing our
hypotheses. Construct validity is a characteristic of devised measurements that
describes how well the DEMO can stand in for the scientiﬁc concepts or
“constructs” that are the real targets of scientiﬁc learning and inference.
Construct validity addresses criticisms like DEMO have shown that changing X
causes a change in measurement Y, DEMO I don’t think you can justify the claims
you make about the causal relationship between concept W and concept Z”, or “Y
is a biased and/or unreliable measure of concept Z”.
The classicpaperon construct validity DEMO Construct Validity in Psy-
chological Tests by Lee J. Cronbach and Paul E. Meehl, ﬁrst published in
Psychological Bulletin, 52, 281-302 (1955)DEMO Construct validity in that arti-
cle is discussed in the context of four types of validity. For the ﬁrst two, it is
assumed that there is a “gold standard” against which we can compare the
measure DEMO interest. The simple correlation (see section3.6.1) of a measure
with the gold standard for a construct is called either concurrent validity
if the DEMO standard is measured at the same time as the new measure to
be tested or predictive validity if the gold standard is measured at DEMO
future time. Content validity is a bit ambiguous but basically refers to
picking a representative sample of items on a multi-item test. Here we DEMO
mainly concerned with construct validity, and Cronbach and Meehl state
that DEMO is pertinent whenever the attribute or quality of interest is not “op-
erationally deﬁned”. That is, if we deﬁne happiness to be the score on our
happiness test, then the test is a valid measure of happiness by deﬁnition.
But if we are referring to a concept without DEMO direct operational deﬁnition,
we need to consider how well our test stands in for the concept of interest.
This is the construct validity. DEMO and Meehl discuss the theoretical
basis of construct validity for psychology, DEMO this should be applicable to
other social sciences. They also emphasize that there is no single measure
of construct validity, because it is a complex, often judgment-laden set of
criteria.
200
CHAPTER 8. THREATS TO YOUR EXPERIMENT
Among other things, to assess contruct validity you should be sure that your
measure correlates with other DEMO for which it should correlate if it is a good
measure of the concept of interest. If there is a “gold standard”, then your measure
should have a high correlation with that test, at least in the kinds of situations
where you will be using it. And it DEMO not be correlated with measures of other
unrelated concepts.
It is worth noting that good construct validity doesn’t mean much if
your measure is DEMO also reliable. A good measure should not depend
strongly on who is administering the test (called high inter-rater reliabil-
ity), and repeat measurements should have a small statistical “variance”
(called test-retest reliability).
Most of what you will be learning about construct validity must be left to
DEMO and learning in your speciﬁc ﬁeld, but a few examples are DEMO here. In
public health studies, a measure of obesity is often DEMO What is needed for a
valid deﬁnition? First it should be DEMO that circular logic applies here: as
long as a measure is DEMO some form that we would recognize as relating to obesity
(as DEMO to, say, smoking), then if it is a good predictor of health outcomes
we can conclude that it is a good measure DEMO obesity by deﬁnition. The United
States Center for Disease Control (CDC) has classiﬁcations for obesity based on the
Body Mass Index (BMI), which is a formula involving only height and weight. The
BMI is DEMO simple substitute that has reasonably good concurrent validity for more
technical deﬁnitions of body fat such as percent total body fat which can be DEMO
estimated by more expensive and time consuming methods such as a buoyancy
method. But even total body fat percent may be insuﬃcient because some DEMO
outcomes may be better predicted by information about amount of fat at speciﬁc
locations. Beyond these problems, the CDC assigns labels (underweight, health
weight, at risk of overweight, and overweight) to speciﬁc ranges of BMI values.
But the cutoﬀ values, while partially based on scientiﬁc methods are also partly
arbitrary. Also these cutoﬀ values and the names and DEMO of categories have
changed with time. And surely the “best” cutoﬀ for predicting outcomes will vary
depending on the outcome, e.g., heart attack, stroke, teasing at school, or poor
self-esteem. So although there is DEMO degree of validity to these categories (e.g., as
shown by diﬀerent levels of disease for people in diﬀerent categories and correlation
8.3. EXTERNAL VALIDITY
201
with buoyancy tests) there is also some controversy about the construct validity.
Is the Stanford-Bidet “IQ” test a good measure DEMO “intelligence”? Many gallons
of ink have gone into discussion of this DEMO Low variance for individuals tested
multiple times shows that the test has high test-retest validity, and as the test is
self-administered and objectively scored there is no issue with inter-rater reliability.
There have been numerous studies DEMO good correlation of IQ with various
outcomes that “should” be correlated with intelligence such as future performance
on various tests. In addition, “factor analysis” suggests a single underlying factor
(called “G” for general intelligence). On the other hand, the test has been severely
criticized for cultural and racial bias. And other critics claim there are multiple
dimensions to intelligence, not just a single “intelligence” factor. In summation,
the IQ test DEMO a measure of the construct “intelligence” is considered by many
researchers to have low construct validity.
Construct validity is important because it makes us DEMO carefully
whether the measures we use really stand in well for the concepts
that label them.
8.3 External validity
External validity is synonymous with DEMO When we perform an
ideal experiment, we randomly choose subjects (in addition to randomly assigning
treatment) from a population of interest. Examples of populations of interest
are all college students, all reproductive aged women, DEMO teenagers with type I
diabetes, all 6 month old healthy Sprague-Dawley DEMO, all workplaces that use
Microsoft Word, or all cities in the Northeast with populations over 50,000. If we
randomly select our experimental DEMO from the population such that each unit
has the same chance (DEMO with special statistical techniques, a ﬁxed but unequal
chance) of ending up in our experiment, then we may appropriately claim that our
results apply to that population. In many experiments, we do not truly have a
random sample of the population of interest. In so-called “convenience samples”,DEMO
e.g., “as many of my classmates as I could attract with DEMO oﬀer of a free slice of
pizza”, the population these subjects DEMO may be quite limited.
202
CHAPTER 8. THREATS TO YOUR EXPERIMENT
After you complete your experiment, you will need to write a discussion of
your conclusions, and one of the key features of that discussion is your set of
claims DEMO external validity. First, you need to consider what population your
experimental DEMO truly represent. In the pizza example, your subjects may repre-
sent DEMO upperclassmen at top northeastern universities who like free food
and don’t mind participating in experiments. Next you will want to use your judg-
ment (and powers of persuasion) to consider ever expanding “spheres” of subjects
who might be similar to your subjects. For example, you could widen the popu-
lation to all northeastern students, then to all US students, DEMO to all US young
adults, etc. Finally you need to use DEMO background knowledge and judgment to
make your best arguments whether or not (or to what degree) you expect your
ﬁndings to apply to DEMO larger populations. If you cannot justify enlarging your
population, then your DEMO is likely to have little impact on scientiﬁc knowledge.
If you enlarge too much, you may be severely criticized for over-generalization.
Three special forms of non-generalizability (poor external validity) are
worth more discussion. First is DEMO If you randomly select
subjects, e.g., through phone records, or DEMO e-mail, then some sub-
jects may decline to participate. You should DEMO consider the very real
possibility that the decliners are diﬀerent in one or more ways from the
participators, and thus your results do not really apply to the population
of interest.
A second problem is dropout, which is when subject who start a study
do not complete it. DEMO can aﬀect both internal and external validity,
but the simplest form aﬀecting external validity is when subjects who are
too busy or less DEMO drop out only because of the length or burden of
the experiment rather than in some way related to response to treatment.
This type DEMO dropout reduces the population to which generalization can
be made, and DEMO experiments such as those studying the eﬀects of ongoing
behavioral therapy on adjustment to a chronic disease, this can be a critical
blow to external validity.
The third special form of non-generalizability relates to the terms DEMO
cacy and eﬀectiveness in the medical literature. Here the generalizability
refers to the environment and the details of treatment application rather
8.4. MAINTAINING TYPE 1 ERROR
than the subjects. If a well-designed clinical DEMO is carried out under high
controlled conditions in a tertiary medical center, and ﬁnds that drug X
cures disease Y with 80% success (DEMO, it has high eﬃcacy), then we are
still unsure whether DEMO can generalize this to real clinical practice in a
doctor’s oﬃce (DEMO, whether the treatment has high eﬀectiveness). Even
outside the medical DEMO, it is important to consider expanding spheres
of environmental and treatment DEMO variability.
203
External validity (generalizability) relates to the breadth of the pop-
ulation we have sampled and how well we can justify extending DEMO
results to an even broader population.
8.4 Maintaining Type 1 error
Type 1 error is related to the statistical concept that in the real DEMO of natural
variability we cannot be certain about our conclusions from an experiment. A
Type 1 error is a claim that a treatment is DEMO, i.e., we decide to reject the
null hypothesis, when that DEMO is actually false, i.e. the null hypothesis really is
true. Obviously DEMO any single real situation, we cannot know whether or not we
DEMO made a Type 1 error: if we knew the absolute truth, we would not make the
error. Equally obvious after a little thought DEMO the idea that we cannot be making
a Type 1 error when we decide to retain the null hypothesis.
As explained in more detail DEMO several other chapters, statistical inference is
the process of making appropriately DEMO claims in the face of uncertainty.
Type 1 error deals with the probabilistic validity of those claims. When we make
a statement such as DEMO reject the hypothesis that the mean outcome is the same
for both the placebo and the active treatments with alpha equal to 0.05” we DEMO
claiming that the procedure we used to arrive at our conclusion only leads to false
positive conclusions 5% of the time when the truth DEMO to be that there is no
diﬀerence in the eﬀect of treatment on outcome. This is not at all the same as the
204
CHAPTER 8. THREATS TO YOUR EXPERIMENT
claim that there is only DEMO 5% chance that any “reject the null hypothesis decision”
will be the wrong decision! Another example of a statistical statement is “we are
95% DEMO that the true diﬀerence in mean outcome between the placebo and
active treatments is between 6.5 and 8.7 seconds”. Again, the exact meaning of
this statement is a bit tricky, but understanding that is not critical for the current
discussion (but see6.2.7for more details).
Due to the inherent uncertainties of nature we can never make deﬁnite, unqual-
iﬁed claims from our experiments. The best we can do is set certain limits DEMO how
often we will make certain false claims (but see the DEMO section, on power, too).
The conventional (but not logically DEMO) limit on the rate of false positive
results out of all DEMO in which the null hypothesis really is true is 5%. The
terms Type 1 error, false positive rate, and “alpha” (α) are DEMO synonyms for
this limit.
Maintaining Type 1 error means doing all we can to assure that the false positive
rate really is set to DEMO nominal level (usually 5%) we have chosen. This
will be discussed much more fully in future chapters, but it basically involves
choosing an appropriate statistical procedure and assuring that the assumptions
of our chosen procedure DEMO reasonably met. Part of the latter is verifying that we
have chosen an appropriate model for our data (see section6.2.2).
A special case of not maintaining Type 1 error is “data snooping”. E.g., if you
perform many diﬀerent analyses of your data, each with a nominal Type 1 error
rate of 5%, and then report just the one(s) with p-values less than 0.05, you are
only fooling yourself and DEMO if you think you have appropriately analyzed your
experiment. As seen in the Section13.3, this approach to data analysis results in
a much larger chance of making false conclusions.
Using models with broken assumptions and/or DEMO snooping tend to
result in an increased chance of making false claims in the presence of
ineﬀective treatments.
8.5. POWER
8.5 Power
205
The power of an experiment refers to DEMO probability that we will correctly con-
clude that the treatment caused a change in the outcome. If some particular true
non-zero diﬀerence in outcomes DEMO caused by the active treatment, and you have
low power to DEMO that diﬀerence, you will probably make a Type 2 error (have a
“false negative” result) in which you conclude that the treatment was ineﬀective,
when it really was eﬀective. The Type 2 error rate, often called “beta” (β), is the
fraction of the time that a conclusion of “no eﬀect” will be made (over repeated
similar experiments) when some true non-zero eﬀect is really present. The power
is equal to 1 − β.
Before the experiment is performed, you have some control over the power of
your experiment, so you should estimate the power for various reasonable eﬀect
sizes and, whenever possible, adjust your DEMO to achieve reasonable power
(e.g., at least 80%). If you perform an experiment with low power, you are just
wasting time and money! See Chapter12for details on how to calculate and
increase the power DEMO an experiment.
The power of a planned experiment is the chance of getting a statisti-
cally signiﬁcant result when a particular real treatment eﬀect DEMO
Studying suﬃcient numbers of subjects is the most well known way
to assure suﬃcient power.
In addition to sample size, the main (partially) controllable experimental char-
acteristic that aﬀects power is variability. If you can DEMO variability, you can
increase power. Therefore it is worthwhile to have DEMO mnemonic device for help-
ing you categorize and think about the sources of variation. One reasonable
categorization is this:
• Measurement
• Environmental
DEMO Treatment application
• Subject-to-subject
206
CHAPTER 8. THREATS TO YOUR EXPERIMENT
(If you are a New York baseball fan, you can remember the acronym METS.)
It is not at all important to “correctly categorize” a particular source of variation.
DEMO is important is to be able to generate a list of the sources of variation in
your (or someone else’s) experiment so that DEMO can think about whether you are
able (and willing) to reduce each source of variation in order to improve the power
of your DEMO
Measurement variation refers to diﬀerences in repeat measurement values when
they should be the same. (Sometimes repeat measurements should change, for
example the DEMO of a balloon with a small hole in it in an experiment of air
leakage.) Measurement variability is usually quantiﬁed as the standard deviation of
many measurements of the same thing. The term precision applies here, though
technically precision is 1/variance. So a high precision implies a DEMO variance (and
thus standard deviation). It is worth knowing that DEMO simple and usually a cheap
way to improve measurement precision is to make repeated measurements and take
the mean; this mean is less variable than an individual measurement. Another
inexpensive way to improve precision, which should almost always be used, is to
have good explicit procedures for making the measurement and good training and
practice for whoever is making the DEMO Other than possibly increased
cost and/or experimenter time, there is DEMO down-side to improving measurement
precision, so it is an excellent way DEMO improve power.
Controlling environmental variation is another way to reduce the variability of
measurements, and thus increase power. For each experiment you should consider
what aspects of the environment (broadly deﬁned) can and should be DEMO
(ﬁxed or reduced in variation) to reduce variation in the outcome measurement.
For example, if we want to look at the eﬀects of a hormone treatment on rat
weight gain, controlling the diet, the DEMO of exercise, and the amount of social
interaction (such as ﬁghting) will reduce the variation of the ﬁnal weight mea-
surements, making DEMO diﬀerences in weight gain due to the hormone easier to
see. Other examples of environmental sources of variation include temperature,
humidity, background noise, lighting conditions, etc. As opposed to reducing mea-
surement variation, there is often a down-side to reducing environmental variation.
There is usually a DEMO between reducing environmental variation which in-
creases power but may reduce external validity (see above).
The trade-oﬀ between power and external validity also applies to treatment
application variation. While some people include this in environmental DEMO,
I think it is worth separating out because otherwise many people forget that it
8.5. POWER
207
is something that can be controlled in their experiment. DEMO application
variability is diﬀerences in the quality or quantity of treatment among subjects as-
signed to the same (nominal) treatment. A simple example DEMO when one treatment
group gets, say 100 mg of a drug. DEMO two drug manufacturers have diﬀerent pro-
duction quality such that all of the pills from the ﬁrst manufacturer have a mean
of 100 mg DEMO s.d. of 5 mg, while the second has a mean of DEMO mg and s.d. of 20
mg, the increased variability of the DEMO manufacturer will result in decreased
power to detect any true diﬀerences between the 100 mg dose and any other doses
studied. For treatments like DEMO therapy” decreasing variability is done
by standardizing the number of sessions and having good procedures and training.
On the other hand there may be DEMO concern that too much control of variation in a
treatment like behavioral therapy might make the experiment unrealistic (reduce
external validity).
Finally there is subject-to-subject variability. Remember that ideally we choose
a population from which DEMO draw our participants for our study (as opposed to us-
ing DEMO “convenience sample”). If we choose a broad population like “all Americans”
there is a lot of variability in age, gender, height, weight, intelligence, diet, etc.
some of which are likely to aﬀect our outcome (or even the diﬀerence in outcome
between the treatment groups). If we choose to limit our study population for one
or several DEMO these traits, we reduce variability in the outcome measurement (for
each treatment group) and improve power, but always at the expense of DEMO
ability. As in the case of environmental and treatment application variability, DEMO
should make an intelligent, informed decision about trade-oﬀs between power and
DEMO in terms of choosing your study population.
For subject-to-subject variation there is a special way to improve power without
reducing generalizability. This is the DEMO of a within-subjects design, in which
each subject receives two or DEMO treatments. This is often an excellent way to
improve power, although DEMO is not applicable in all cases. See chapter14for more
details. Remember that you must change you analysis procedures to ones which
do not assume DEMO errors if you choose a within-subjects design.
Using the language of section3.6, it is useful to think of all measure-
ments as being conditional on whatever environmental and treatment vari-
ables we choose to ﬁx, and marginal over those that we let vary.
208
CHAPTER 8. THREATS TO YOUR EXPERIMENT
Reducing variability improves power. In DEMO circumstances this
may be at the expense of decreased generalizability. Reducing mea-
surement error and/or use of within-subjects designs usually improve
power without DEMO generalizability.
The strength of your treatments (actually the diﬀerence in true DEMO be-
tween treatments) strongly aﬀects power. Be sure that you are DEMO studying very
weak treatments, e.g., the eﬀects of one ounce of beer on driving skills, or 1 mi-
crogram of vitamin C on catching colds, or one treatment session on depression
severity.
Increasing treatment strength increases power.
Another way to improve power without reducing generalizability is to DEMO
blocking. Blocking involves using subject matter knowledge to select one or more
factors whose eﬀects are not of primary importance, but whose levels deﬁne more
homogeneous groups called “blocks”. In an ANOVA, for example, the DEMO will be
an additional factor beyond the primary treatment of interest, DEMO inclusion of the
block factor tends to improve power if the blocks are markedly more homogeneous
than the whole. If the variability of the DEMO (for each treatment group) is
smaller than the variability ignoring the factor, then a good blocking factor was
chosen. But because a wide variety of subjects with various levels of the blocking
variable are all DEMO in the study, generalizability is not sacriﬁced.
Examples of blocking factors DEMO ﬁeld in an agricultural experiment, age in
many performance studies, and disease severity in medical studies. Blocking usu-
ally is performed when it DEMO assumed that there is no diﬀerential eﬀect of treatment
across the blocks, i.e., no interaction (see Section10.2). Ignoring an interaction
when one is present tends to lead to misleading results, due to an incorrect struc-
tural model. Also, if there is an interaction between treatment and blocks, that
usually becomes of primary interest.
A natural extension of blocking is some form of more complicated model with
multiple control variables explicitly DEMO in an appropriate mathematical
form in the structural model. Continuous control variables are also called covari-
ates.
8.6. MISSING EXPLANATORY VARIABLES
Treatment A
Treatment B
Small Stones
81/87
DEMO/270
0.93
0.87
Large Stones
192/263
55/80
0.79
0.69
Combined
273/350
289/350
0.78
0.83
Table 8.1: Simpson’s paradox in medicine
209
Blocking and use of control variables are good ways to improve DEMO
without sacriﬁcing generalizability.
8.6 Missing explanatory variables
Another threat to your experiment is not including important explanatory vari-
ables. For example, if the eﬀect of a treatment is to raise the mean outcome in
males and DEMO it in females, then not including gender as an explanatory vari-
DEMO (including its interaction with treatment) will give misleading results. (See
DEMO more on interaction.) In other cases, where there is no
interaction, ignoring important explanatory variables decreases power rather than
directly causing misleading results.
An extreme case of a missing variable is Simpson’s paradox. Described by
DEMO H. Simpson and others, this term describes the situation where the DEMO
served eﬀect is in opposite directions for all subjects as a single group (deﬁned based
on a variable other than treatment) vs. separately DEMO each group. It only occurs
when the fraction of subjects in each group diﬀers markedly between the treatment
groups. A nice medical example comes DEMO from the 1986 article Comparison of
treatment of renal calculi by operative surgery, percutaneous nephrolithotomy, and
extracorporeal shock wave lithotripsy by C. R. DEMO, et al. (Br Med J 292 (6524):
879-882) DEMO shown in table8.1.
The data show the number of successes divided by the number of times the
treatment was tried for two treatments for DEMO stones. The “paradox” is that for
“all stones” (combined) Treatment B is the better treatment (has a higher success
rate). but if the patients gall stones are classiﬁed as either “small” or “large”,
DEMO Treatment A is better. There is nothing artiﬁcial about this example; DEMO is
210
CHAPTER 8. THREATS TO YOUR EXPERIMENT
based on the actual data. DEMO there is really nothing “statistical” going on (in
terms of randomness); we are just looking at the deﬁnition of “success rate”. If
stone size is omitted as an explanatory variable, then Treatment B looks to be the
better treatment, but for each stone size Treatment A was the better treatment.
Which treatment would you choose? If you have small stones or if you have
large stones (the only two kinds), you should choose treatment A. Dropping the
important explanatory variable gives a DEMO (“marginal”) eﬀect, when the
“conditional” eﬀect is more relevant. Ignoring DEMO confounding (also called lurking)
variable “stone size” leads to misinterpretation.
DEMO worth mentioning that we can go too far in including explanatory variables.
This is both in terms of the “multiple comparisons” problem and something DEMO
“variance vs.bias trade-oﬀ”. The former artiﬁcially raises our Type 1 error if
uncorrected, or lowers our power if corrected. The latter, in this DEMO, can
be considered to lower power when too many relatively unimportant DEMO
variables are included.
Missing explanatory variables can decrease power and/or cause mis-
leading results.
8.7 Practicality and cost
Many attempts to improve an DEMO are limited by cost and practicality.
Finding ways to reduce threats to your experiment that are practical and cost-
eﬀective is an important part DEMO experimental design. In addition, experimental
science is usually guided by the DEMO principle, which stands for Keep It Simple,
Stupid. Many an DEMO has been ruined because it was too complex to be
carried out without confusion and mistakes.
8.8 Threat summary
After you have completed and DEMO your experiment, your critics may complain
that some confounding factors may DEMO destroyed the internal validity of your ex-
periment; that your experiment DEMO not really tell us about the real world concepts
8.8. THREAT SUMMARY 211
of interest because of poor construct validity; that your experimental results are
only narrowly applicable to certain subjects or environments DEMO treatment appli-
cation setting; that your statistical analysis did not appropriately DEMO Type
1 error (if you report “positive” results); or that DEMO experiment did not have
enough power (if you report “negative” results)DEMO You should consider all of these
threats before performing your experiment and make appropriate adjustments as
needed. Much of the rest of this book DEMO how to deal with, and balance
solutions to, these threats.
In a nutshell: If you learn about the various categories of threat to
your experiment, you will be in a better position to make choices that
balance competing risk, and you will design a better experiment.
212
CHAPTER 8. THREATS TO YOUR EXPERIMENT
Chapter 9
Simple Linear Regression
An analysis appropriate for a quantitative outcome DEMO a single quantitative ex-
planatory variable.
9.1 The model behind linear regression
When we are examining the relationship between a quantitative outcome and a
DEMO quantitative explanatory variable, simple linear regression is the most com-
monly DEMO analysis method. (The “simple” part tells us we are only con-
DEMO a single explanatory variable.) In linear regression we usually have many
DEMO values of the explanatory variable, and we usually assume that values
DEMO the observed values of the explanatory variables are also possible values
of the explanatory variables. We postulate a linear relationship between the pop-
ulation DEMO of the outcome and the value of the explanatory variable. If we let
Y be some outcome, and x be some explanatory variable, DEMO we can express the
structural model using the equation
E(Y |x) = β0 + β1x
where E(), which is read “expected DEMO of”, indicates a population mean; Y |x,
which is read “Y given x”, indicates that we are looking at the possible values of
Y when x is restricted to some single value; β0, DEMO “beta zero”, is the intercept
parameter; and β1, read “beta DEMO is the slope parameter. A common term for
any parameter or parameter estimate used in an equation for predicting Y from
213
214
CHAPTER 9. SIMPLE LINEAR REGRESSION
x is coeﬃcient. Often the “1” DEMO in β1 is replaced by the name of the
explanatory variable or some abbreviation of it.
So the structural model says that for each DEMO of x the population mean of Y
(over all of the DEMO who have that particular value “x” for their explanatory
variable) can DEMO calculated using the simple linear expression β0 + β1x. Of course
we cannot make the calculation exactly, in practice, because the two parameters
DEMO unknown “secrets of nature”. In practice, we make estimates of the DEMO
and substitute the estimates into the equation.
In real life we know that although the equation makes a prediction of the true
mean of DEMO outcome for any ﬁxed value of the explanatory variable, it would DEMO
unwise to use extrapolation to make predictions outside of the range of x values
that we have available for study. On the other hand DEMO is reasonable to interpolate,
i.e., to make predictions for unobserved DEMO values in between the observed x values.
The structural model is essentially the assumption of “linearity”, at least within
the range of the observed explanatory data.
It is important to realize that the “linear” in “linear DEMO does not imply
that only linear relationships can be studied. Technically it only says that the
beta’s must not be in a transformed form. DEMO is OK to transform x or Y , and that
allows many non-linear relationships to be represented on a new scale that makes
the DEMO linear.
The structural model underlying a linear regression analysis is that
the explanatory and outcome variables are linearly related such that
the population mean DEMO the outcome for any x value is β0 + β1x.
The error model that we use is that for each particular x, if we have or could
collect many subjects with that x value, their distribution around the population
mean is Gaussian with a spread, say σ2, DEMO is the same value for each value
of x (and corresponding DEMO mean of y). Of course, the value of σ2 is
DEMO unknown parameter, and we can make an estimate of it from DEMO data. The
error model described so far includes not only the assumptions of “Normality” and
“equal variance”, but also the assumption of “ﬁxed-x”. The “ﬁxed-x” assumption
is that the explanatory variable is measured without error. Sometimes DEMO is
possible, e.g., if it is a count, such as DEMO number of legs on an insect, but usually
there is some DEMO in the measurement of the explanatory variable. In practice,
9.1. THE MODEL BEHIND LINEAR REGRESSION
215
we need to be sure DEMO the size of the error in measuring x is small compared to
the variability of Y at any given x value. For more on DEMO topic, see the section
on robustness, below.
The error model underlying a linear regression analysis includes the
assumptions of ﬁxed-x, Normality, equal DEMO, and independent er-
rors.
In addition to the three error model DEMO just discussed, we also assume
“independent errors”. This assumption comes down DEMO the idea that the error
(deviation of the true outcome value DEMO the population mean of the outcome for a
given x value) DEMO one observational unit (usually a subject) is not predictable from
knowledge of the error for another observational unit. For example, in predicting
time to complete a task from the dose of a drug suspected to DEMO that time,
knowing that the ﬁrst subject took 3 seconds longer than the mean of all possible
subjects with the same dose should DEMO tell us anything about how far the next
subject’s time should be above or below the mean for their dose. This assumption
can be DEMO violated if we happen to have a set of identical twins in the study,
in which case it seems likely that if one DEMO has an outcome that is below the mean
for their assigned dose, then the other twin will also have an outcome that is below
the mean for their assigned dose (whether the doses are the same or diﬀerent).
A more interesting cause of correlated errors is when DEMO are trained in
groups, and the diﬀerent trainers have important individual DEMO that aﬀect
the trainees performance. Then knowing that a particular subject does better than
average gives us reason to believe that most of the DEMO subjects in the same group
will probably perform better than average because the trainer was probably better
than average.
Another important example of non-independent DEMO is serial correlation
in which the errors of adjacent observations are similar. This includes adjacency
in both time and space. For example, if we are studying the eﬀects of fertilizer on
plant growth, then similar soil, water, and lighting conditions would tend to make
the errors of DEMO plants more similar. In many task-oriented experiments, if
we allow each DEMO to observe the previous subject perform the task which is
measured as the outcome, this is likely to induce serial correlation. And worst of
all, if you use the same subject for every observation, just DEMO the explanatory
216
CHAPTER 9. SIMPLE LINEAR REGRESSION
variable each time, serial correlation is extremely likely. Breaking the assumption
of independent errors does not indicate that DEMO analysis is possible, only that linear
regression is an inappropriate analysis. DEMO methods such as time series methods
or mixed models are appropriate when errors are correlated.
The worst case of breaking the independent errors assumption DEMO re-
gression is when the observations are repeated measurement on the
same experimental unit (subject).
Before going into the details of linear regression, it is worth thinking about the
variable types for the explanatory and outcome variables and the relationship of
ANOVA to linear regression. For both DEMO and linear regression we assume
a Normal distribution of the outcome for each value of the explanatory variable.
(It is equivalent to say that all of the errors are Normally distributed.) Implic-
itly this indicates that the outcome should be a continuous quantitative variable.
Practically speaking, real measurements are rounded and therefore some of their
continuous nature is not available DEMO us. If we round too much, the variable is
essentially discrete DEMO, with too much rounding, can no longer be approximated
by the smooth Gaussian curve. Fortunately regression and ANOVA are both quite
robust to DEMO from the Normality assumption, and it is OK to use discrete
DEMO continuous outcomes that have at least a moderate number of diﬀerent values,
e.g., 10 or more. It can even be reasonable in some circumstances to use regression
or ANOVA when the outcome is ordinal with DEMO fairly small number of levels.
The explanatory variable in ANOVA is categorical and nominal. Imagine we
are studying the eﬀects of a drug on DEMO outcome and we ﬁrst do an experiment
comparing control (no drug) vs. drug (at a particular concentration). Regression
and ANOVA would give equivalent conclusions about the eﬀect of drug on the
outcome, but regression seems inappropriate. Two related reasons are that there
is no way to DEMO the appropriateness of the linearity assumption, and that after
a regression DEMO it is appropriate to interpolate between the x (dose) values,
and that is inappropriate here.
Now consider another experiment with 0, 50 and 100 mg of drug. Now ANOVA
and regression give diﬀerent answers DEMO ANOVA makes no assumptions about
the relationships of the three population means, but regression assumes a linear
relationship. If the truth is linearity, DEMO regression will have a bit more power
9.1. THE MODEL BEHIND LINEAR REGRESSION
217
0
2
4
x
6
DEMO
10
Figure 9.1: Mnemonic for the simple regression model.
than ANOVA. DEMO the truth is non-linearity, regression will make inappropriate
predictions, but at least regression will have a chance to detect the non-linearity.
ANOVA also DEMO some power because it incorrectly treats the doses as nominal
when they are at least ordinal. As the number of doses increases, it is more and
more appropriate to use regression instead of ANOVA, and we will be able to
better detect any non-linearity and correct for it, e.g., with a data transformation.
Figure9.1shows a way to think about and remember most of the regression
model assumptions. The four little Normal curves DEMO the Normally dis-
tributed outcomes (Y values) at each of four ﬁxed x values. The fact that the
four Normal curves have the DEMO spreads represents the equal variance assump-
tion. And the fact that the four means of the Normal curves fall along a straight
line represents DEMO linearity assumption. Only the ﬁfth assumption of independent
errors is not shown on this mnemonic plot.
0
5
Y
10
15
218
CHAPTER 9. SIMPLE LINEAR REGRESSION
9.2 Statistical hypotheses
For simple linear DEMO, the chief null hypothesis is H0 : β1 = 0, and the
corresponding alternative hypothesis is H1 : β1 = 0. If this DEMO hypothesis is true,
then, from E(Y ) = β0 DEMO β1x we can see that the population mean of Y is β0 for
every x value, which tells us that x has no eﬀect on Y . The alternative is that
changes in x are associated DEMO changes in Y (or changes in x cause changes in
Y DEMO a randomized experiment).
Sometimes it is reasonable to choose a diﬀerent null hypothesis for β1. For ex-
ample, if x is some gold standard for a particular measurement, i.e., a best-quality
measurement often involving DEMO expense, and y is some cheaper substitute, then
the obvious null hypothesis is β1 = 1 with alternative β1 = 1. For example, if x is
percent body fat measured using the cumbersome whole body DEMO method,
and Y is percent body fat measured using a formula based on a couple of skin fold
thickness measurements, then we expect either a slope of 1, indicating equivalence
of measurements (on average) or we expect a diﬀerent slope indicating that the
skin fold method DEMO over- or under-estimates body fat.
Sometimes it also makes sense to construct a null hypothesis for β0, usually
H0 : β0 = 0. This should only be done if each of the following is true. There DEMO
data that span x = 0, or at least there are DEMO points near x = 0. The statement
“the population mean of Y equals zero when x = 0” both makes scientiﬁc sense
and the DEMO between equaling zero and not equaling zero is scientiﬁcally
interesting. See the section on interpretation below for more information.
The usual regression null hypothesis DEMO H0 : β1 = 0. Sometimes it is
also meaningful to test H0 : β0 = 0 or H0 : β1 = 1.
9.3 DEMO linear regression example
As a (simulated) example, consider an experiment DEMO which corn plants are grown in
pots of soil for 30 days after the addition of diﬀerent amounts of nitrogen fertilizer.
The data are DEMO, which is a space delimited text ﬁle with column headers.
Corn DEMO ﬁnal weight is in grams, and amount of nitrogen added per DEMO is in
9.3. SIMPLE LINEAR REGRESSION EXAMPLE
l
l
l
l
l
l
l
DEMO
l
l
0
l
l
20
l
l
l
l
40
60
Soil Nitrogen (mg/pot)
l
l
l
l
ll
l
80
100
219
Figure 9.2: Scatterplot of corn data.
mg.
EDA, in DEMO form of a scatterplot is shown in ﬁgure9.2.
We want to use EDA to check that the assumptions are reasonable before
trying a regression DEMO We can see that the assumptions of linearity seems
plausible because we can imagine a straight line from bottom left to top right
going DEMO the center of the points. Also the assumption of equal spread is
plausible because for any narrow range of nitrogen values (horizontally), the spread
of weight values (vertically) is fairly similar. These assumptions should DEMO be
doubted at this stage if they are drastically broken. The assumption of Normality
is not something that human beings can test by looking DEMO a scatterplot. But if
we noticed, for instance, that there were only two possible outcomes in the whole
experiment, we could reject the idea that the distribution of weights is Normal at
each nitrogen level.
DEMO assumption of ﬁxed-x cannot be seen in the data. Usually we just think
about the way the explanatory variable is measured and judge whether DEMO not it
is measured precisely (with small spread). Here, it is not too hard to measure the
amount of nitrogen fertilizer added DEMO each pot, so we accept the assumption of
Final Weight (gm)
100
200
300
400
500
600
220
CHAPTER 9. SIMPLE LINEAR REGRESSION
ﬁxed-x. In some cases, we can actually perform repeated measurements of x on
the same case to see DEMO spread of x and then do the same thing for y at each of
a few values, then reject the ﬁxed-x assumption if the ratio of x to y variance is
larger than, e.g., around DEMO
The assumption of independent error is usually not visible in the data and
must be judged by the way the experiment was run. But DEMO serial correlation is
suspected, there are tests such as the Durbin-Watson DEMO that can be used to
detect such correlation.
Once we make an initial judgement that linear regression is not a stupid thing
to do DEMO our data, based on plausibility of the model after examining our DEMO, we
perform the linear regression analysis, then further verify the model assumptions
with residual checking.
9.4 Regression calculations
The basic regression analysis uses DEMO simple formulas to get estimates of the
parameters β0, β1, and σ2. These estimates can be derived from either of two
basic approaches DEMO lead to identical results. We will not discuss the more
complicated maximum likelihood approach here. The least squares approach is
fairly straightforward. It says DEMO we should choose as the best-ﬁt line, that line
which minimizes DEMO sum of the squared residuals, where the residuals are the
vertical DEMO from individual points to the best-ﬁt “regression” line.
The principle is shown in ﬁgure9.3. The plot shows a simple example with
four data points. DEMO diagonal line shown in black is close to, but not equal DEMO the
“best-ﬁt” line.
Any line can be characterized by its intercept and slope. The intercept is the
y value when x equals zero, which is 1.0 in the example. Be sure to look carefully
at the DEMO scale; if it does not start at zero, you might read oﬀ the intercept
incorrectly. The slope is the change in y for DEMO one-unit change in x. Because the
line is straight, you can DEMO this oﬀ anywhere. Also, an equivalent deﬁnition is the
change in DEMO divided by the change in x for any segment of the line. In the ﬁgure,
a segment of the line is marked with DEMO small right triangle. The vertical change is
2 units and the horizontal change is 1 unit, therefore the slope is 2/1=2. Using b0
for the intercept and b1 for the slope, the equation of the line is y = b0 + b1x.
9.4. REGRESSION CALCULATIONS
221
l
l
21−19=2
10−9=1
Slope=2/1=2
l
Residual=3.5−11=−7.5
DEMO
l
0
2
4
6
x
8
10
Figure 9.3: Least DEMO principle.
12
0
5
10
Y
15
20
25
222 CHAPTER 9. SIMPLE LINEAR REGRESSION
By plugging diﬀerent values for x DEMO this equation we can ﬁnd the corre-
sponding y values that are on the line drawn. For any given b0 and b1 we get DEMO
potential best-ﬁt line, and the vertical distances of the points from DEMO line are
called the residuals. We can use the symbol ˆyi, DEMO “y hat sub i”, where
“sub” means subscript, to indicate the ﬁtted or predicted value of outcome y for
subject i. (Some people also use the yi0 “y-prime sub i”.) For subject i, who DEMO
explanatory variable xi, the prediction is ˆyi = b0 + b1xi DEMO the residual is yi − yˆi.
The least square principle says that the best-ﬁt line is the one with the smallest
sum of squared DEMO It is interesting to note that the sum of the residuals
(DEMO squared) is zero for the least-squares best-ﬁt line.
In practice, we don’t really try every possible line. Instead we use calculus to
ﬁnd DEMO values of b0 and b1 that give the minimum sum of squared residuals. You
don’t need to memorize or use these equations, but here they are in case you are
interested.
b1 = P (xi −
(xi −
b0 = ¯y − b1
n
i=1
x¯)(yi DEMO y¯)
x¯)2
x¯
Also, the best estimate of σ2 DEMO
−
s2 = P n − 2
Whenever we ask a computer to perform simple linear regression, it uses these
equations to ﬁnd the best ﬁt line, then shows us the parameter estimates. Some-
times the symbols βˆ0 and βˆ1 are used instead of b0 and b1. Even DEMO these
symbols have Greek letters in them, the “hat” over the DEMO tells us that we are
dealing with statistics, not parameters.
n
DEMO(yi
i)2 .
yˆ
Here are the derivations of the coeﬃcient estimates. SSR indicates sum
of squared residuals, the quantity to minimize.
SSR
=
=
n
X(yi − (β0 + β1xi))2
y2 DEMO
i=1
n
X
=1
i
2 2
2yi(β0 + β1xi) DEMO β02 + 2β0β1xi + β1 xi

(9.1)
(9.2)
i
n
X (−2yi + 2β0 + 2β1xi)(9.3)
X
=1
DEMO
0 =
=1
−yi +
βˆ
0 +
βˆ
1
xi
(DEMO)
βˆ0
∂SSR
∂β1
0 =
xiyi
+ (¯y
−
xi(DEMO − y¯)
xi(xi − x¯)
A little algebra shows that this formula for
shown above because
variable z.
In multiple regression, the matrix formula for the coeﬃcient estimates is
(X0X)−1X0y, where DEMO is the matrix with all ones in the ﬁrst column (for
DEMO intercept) and the values of the explanatory variables in subsequent
columns.
DEMO
∂β0
=
0 =
0 =
βˆ
1
=
= ¯y
=
−n
n−
βˆ
1
x¯
X−2xiyi
−X
n
=1
n
−X
PP
DEMO
n
i=1
n
i=1
=1
y¯
+ n
βˆ
0 +
βˆ
1n
x¯
2
+ 2β0xi + 2β1xi
xiyi +
βˆ
0
n
DEMO
=1
xi +
βˆ
1

X
n
2
xi
=1
cP
n
i=1(zi
−
z¯
(9.5)
(9.6)
(9.7)
βˆ
1
x¯
n
) X
=1
xi +
(9.8)
i
βˆ
1 is equivalent to the one
) = c · 0 DEMO 0 for any constant c and
βˆ
1
X
n
2
xi
=1
(9.9)
i
i
i
i
i
i
i
(9.10)DEMO
223
Because the intercept and slope estimates are statistics, they have DEMO
distributions, and these are determined by the true values of β0, β1, and σ2, as
well as the positions of the x DEMO and the number of subjects at each x value.
If the model assumptions are correct, the sampling distributions of the intercept
and slope estimates both have means equal to the true values, β0 and β1, DEMO
are Normally distributed with variances that can be calculated according to fairly
simple formulas which involve the x values and σ2.
In practice, we have to estimate σ2 with s2. This has two consequences. First
we DEMO about the standard errors of the sampling distributions of each of the betas
9.4. REGRESSION CALCULATIONS
224 CHAPTER 9. SIMPLE LINEAR REGRESSION
instead of the standard deviations, because, by deﬁnition, SE’s are estimates of
s.d.’s of sampling distributions. Second, the sampling distribution of bj − βj (for
j=0 or 1) DEMO now the t-distribution withthe total number of subjects. (Loosely we say DEMO we lose two degrees of freedomn − 2 df (see section3.9.5), where n is
because they are used up in the estimation of the two beta parameters.) Using the
null hypothesis of βj = 0 this reduces to the null sampling distribution bj ∼ tn−2.
The computer DEMO calculate the standard errors of the betas, the t-statistic
values, and the corresponding p-values (for the usual two-sided alternative hypoth-
esis). We then compare these p-values to our pre-chosen alpha (usually α = 0.05)
to make the decisions whether to retain or reject the null DEMO
The formulas for the standard errors come from the formula for the
variance covariance matrix of the joint sampling distributions of βˆ0 and
βˆ1 DEMO is σ2(X0X)−1, where X is the matrix with all DEMO in the ﬁrst
column (for the intercept) and the values of the explanatory variable in
the second column. This formula also works in DEMO regression where
there is a column for each explanatory variable. The standard errors of the
coeﬃcients are obtained by substituting s2 for the unknown DEMO and taking
the square roots of the diagonal elements.
For simple regression this reduces to
SE(b0) = suv Px2
tnP(x ) − (Px)2
ssn
2
and
n
SE(b1) =
x)2 DEMO
P(x2) − (P
The basic regression output is shown in table9.1in a form similar to that
produced by SPSS, but somewhat abbreviated. Speciﬁcally, “standardized coeﬃ-
cients” are not included.
In this table we see the number 94.821 to the right of the “(Constant)” label
DEMO under the labels “Unstandardized Coeﬃcients” and “B”. This is called the
intercept estimate, estimated intercept coeﬃcient, or estimated constant, and can
9.4. REGRESSION CALCULATIONS
225
(Constant)
Nitrogen added
Unstandardized
Coeﬃcients
B Std. Error
94.821
5.269
18.116
.299
t
4.682
17.610
Sig.
.000
.000
95% DEMO Interval for B
Lower Bound Upper Bound
47.251
4.684
122.391
5.889
Table 9.1: Regression results for the corn experiment.
be written as b0, DEMO or rarely B0, but β0 is incorrect, because the parameter value
β0 is a ﬁxed, unknown “secret of nature”. (Usually we should DEMO say that b0
equals 94.8 because the original data and most experimental data has at most 3
signiﬁcant ﬁgures.)
The number 5.269 is DEMO slope estimate, estimated slope coeﬃcient, slope es-
timate for nitrogen added, or coeﬃcient estimate for nitrogen added, and can be
written as DEMO, βˆ1 or rarely B1, but β1 is incorrect. Sometimes symbols such as
βnitrogen or βN for the parameter and bnitrogen or bN for DEMO estimates will be used
as better, more meaningful names, especially when dealing with multiple explana-
tory variables in multiple (as opposed to simple) regression.
To the right of the intercept and slope coeﬃcients you will ﬁnd their standard
errors. As usual, standard errors are estimated standard deviations of the corre-
sponding sampling distributions. For example, the SE of 0.299 for BN gives an idea
of the scale of the variability of DEMO estimate BN , which is 5.269 here but will vary
with a standard deviation of approximately 0.299 around the true, unknown value
of βN if we repeat the whole experiment many times. The two t-statistics are DEMO
culated by all computer programs using the default null hypotheses of H0 : βj = 0
according to the general t-statistic formula
tj =
DEMO − hypothesized value of βj .
SE(bj)
Then the computer uses the null sampling distributions of the t-statistics, i.e.,
the t-distribution with n− 2 df, to compute the 2-sided p-values as the areas under
the null sampling distribution more extreme (farther from zero) than DEMO coeﬃcient
estimates for this experiment. SPSS reports this as “Sig.”, and DEMO usual gives the
misleading output “.000” when the p-value is really “< 0.0005”.
226
CHAPTER 9. SIMPLE LINEAR REGRESSION
In simple regression the p-value for DEMO null hypothesis H0 : β1 = 0
comes from the t-test for b1. If applicable, a similar test is made for
β0.
SPSS also gives Standardized Coeﬃcients (not shown here). These are the
coeﬃcient estimates obtained when both the explanatory and outcome variables
are converted to so-called DEMO by subtracting their means then dividing by
their standard deviations. Under these conditions the intercept estimate is zero,
so it is not shown. DEMO main use of standardized coeﬃcients is to allow compari-
son of the importance of diﬀerent explanatory variables in multiple regression by
showing the comparative DEMO of changing the explanatory variables by one stan-
dard deviation instead of by one unit of measurement. I rarely use standardized
coeﬃcients.
The output DEMO also shows the “95% Conﬁdence Interval for B” which is gen-
erated in SPSS by clicking “Conﬁdence Intervals” under the “Statistics” button.
In the DEMO example we can say “we are 95% conﬁdent that βN is between 4.68
and 5.89.” More exactly, we know that using the method of construction of coeﬃ-
cient estimates and conﬁdence intervals detailed above, and if the assumptions of
regression are met, then each time we perform an experiment in this setting we will
get a diﬀerent conﬁdence interval (center and width), and out of many conﬁdence
intervals 95% of them DEMO contain βN and 5% of them will not.
The conﬁdence interval for β1 gives a meaningful measure of the loca-
tion of the parameter DEMO our uncertainty about that location, regard-
less of whether or not DEMO null hypothesis is true. This also applies to
β0.
9.5 Interpreting regression coeﬃcients
It is very important that you learn to correctly and completely DEMO the co-
eﬃcient estimates. From E(Y |x) = β0 + DEMO we can see that b0 represents our
estimate of the mean outcome when x = 0. Before making an interpretation of b0,
9.5. INTERPRETING REGRESSION COEFFICIENTS
227
ﬁrst check the range of x values DEMO by the experimental data. If there is no
x data near zero, then the intercept is still needed for calculating ˆy and residual
values, but it should not be interpreted because it is an extrapolated value.
If there are x values near zero, then to interpret the intercept you must express
it in terms of the actual meanings of the DEMO and explanatory variables. For
the example of this chapter, we would DEMO that b0 (94.8) is the estimated corn plant
weight (in DEMO) when no nitrogen is added to the pots (which is the meaning of
x = 0). This point estimate is of limited DEMO, because it does not express the
degree of uncertainty associated with DEMO So often it is better to use the CI for b0.
In this case we say that we are 95% conﬁdent that the mean DEMO for corn plants
with no added nitrogen is between 47 and 122 gm, which is quite a wide range. (It
would be quite DEMO to report the mean no-nitrogen plant weight as 94.821
gm because it gives a false impression of high precision.)
After interpreting the estimate DEMO b0 and it’s CI, you should consider whether
the null hypothesis, β0 = 0 makes scientiﬁc sense. For the corn example, the null
hypothesis is that the mean plant weight equals zero when no nitrogen DEMO added.
Because it is unreasonable for plants to weigh nothing, we DEMO stop here and not
interpret the p-value for the intercept. For another example, consider a regression
of weight gain in rats over a 6 week period as it relates to dose of an anabolic
steroid. Because DEMO might be unsure whether the rats were initially at a stable
weight, it might make sense to test H0 : β0 = 0. If the null hypothesis is rejected
then we conclude that it is not DEMO that the weight gain is zero when the dose is
zero (DEMO group), so the initial weight was not a stable baseline weight.
Interpret the estimate, b0, only if there are data near zero DEMO setting
the explanatory variable to zero makes scientiﬁc sense. The meaning
of b0 is the estimate of the mean outcome when x = 0, and should
always be stated in terms of the actual variables of DEMO study. The p-
value for the intercept should be interpreted (with DEMO to retaining
or rejecting H0 : β0 = 0) only if DEMO the equality and the inequality of
the mean outcome to zero when the explanatory variable is zero are
scientiﬁcally plausible.
For interpretation of a DEMO coeﬃcient, this section will assume that the setting
is a randomized DEMO, and conclusions will be expressed in terms of causa-
228
CHAPTER 9. SIMPLE LINEAR REGRESSION
tion. Be sure to substitute association DEMO you are looking at an observational study.
The general meaning of a slope coeﬃcient is the change in Y caused by a one-unit
increase DEMO x. It is very important to know in what units x are measured, so that
the meaning of a one-unit increase can be clearly expressed. For the corn experi-
ment, the slope is the change in mean corn plant weight (in grams) caused by a one
mg DEMO in nitrogen added per pot. If a one-unit change is not substantively
meaningful, the eﬀect of a larger change should be used in the interpretation. For
the corn example we could say the a 10 mg DEMO in nitrogen added causes a
52.7 gram increase in plant weight on average. We can also interpret the CI for
β1 in the corn DEMO by saying that we are 95% conﬁdent that the change in
mean plant weight caused by a 10 mg increase in nitrogen is 46.8 DEMO 58.9 gm.
Be sure to pay attention to the sign of b1. If it is positive then b1 represents the
increase in outcome caused DEMO each one-unit increase in the explanatory variable. If
b1 is negative, DEMO each one-unit increase in the explanatory variable is associated
with a fall in outcome of magnitude equal to the absolute value of b1.
A DEMO p-value indicates that we should reject the null hypothesis that
β1 = 0. We can express this as evidence that plant weight is aﬀected DEMO changes
in nitrogen added. If the null hypothesis is retained, we DEMO express this as
having no good evidence that nitrogen added aﬀects plant weight. Particularly in
the case of when we retain the null hypothesis, the interpretation of the CI for β1
is better than simply relying DEMO the general meaning of retain.
The interpretation of b1 is the change (increase or decrease depending
on the sign) in the average outcome DEMO the explanatory variable
increases by one unit. This should always be stated in terms of the
actual variables of the study. Retention of the DEMO hypothesis H0 : β1 =
0 indicates no evidence that a change in x is associated with (or causes
for a randomized experiment) DEMO change in y. Rejection indicates that
changes in x cause changes in y (assuming a randomized experiment).
9.6. RESIDUAL CHECKING
9.6 Residual checking
229
Every regression analysis should include DEMO residual analysis as a further check on
the adequacy of the chosen regression model. Remember that there is a residual
value for each data DEMO, and that it is computed as the (signed) diﬀerence yi DEMO
A positive residual indicates a data point higher than expected, and DEMO negative
residual indicates a point lower than expected.
A residual is the deviation of an outcome from the predicated mean
value for all subjects DEMO the same value for the explanatory variable.
A plot of all residuals on the y-axis vs. the predicted values on the x-axis, called
a residual vs. ﬁt plot, is a good way to check the linearity and equal variance
assumptions. A quantile-normal plot of all of the residuals DEMO a good way to check
the Normality assumption. As mentioned above, DEMO ﬁxed-x assumption cannot be
checked with residual analysis (or any other DEMO analysis). Serial correlation can
be checked with special residual analyses, DEMO is not visible on the two standard
residual plots. The other types of correlated errors are not detected by standard
residual analyses.
To analyze DEMO residual vs. ﬁt plot, such as any of the examples shown DEMO ﬁgure
9.4, you should mentally divide it up into about 5 DEMO 10 vertical stripes. Then each
stripe represents all of the residuals for a number of subjects who have a similar
predicted values. For simple DEMO, when there is only a single explanatory
variable, similar predicted values is equivalent to similar values of the explanatory
variable. But be careful, if the slope is negative, low x values are on the right.
(Note that sometimes the x-axis is set to be the values of the explanatory variable,
in which case each stripe directly represents subjects DEMO similar x values.)
To check the linearity assumption, consider that DEMO each x value, if the mean of
Y falls on a DEMO line, then the residuals have a mean of zero. If we DEMO ﬁt
a straight line to a curve, then some or most DEMO the predicted means are incorrect,
and this causes the residuals for at least speciﬁc ranges of x (or the predicated Y )
DEMO be non-zero on average. Speciﬁcally if the data follow a simple curve, we will
tend to have either a pattern of high then low then high residuals or the reverse.
So the technique used to detect DEMO in a residual vs. ﬁt plot is to ﬁnd the
230
CHAPTER 9. SIMPLE LINEAR REGRESSION
B
l
l
l
l
l
DEMO
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
40
60
Fitted value
DEMO
l
l
l
lll
l
l l
ll
ll
l
l
l l
l
20
25
30
35
0
20
60
100
Fitted value DEMO value
Figure 9.4: Sample residual vs. ﬁt plots for testing linearity.
DEMO
l
l
ll
l
l
l
20
A
l
l
l
lll
ll
l
l
l
l
l
l
l
l
l
l
l
DEMO
l l
l
l
l
l
ll
l
l l
l l
l
l
l
l
l
l
l
40
60
80
l
100
DEMO value
l
l
l
l l
l
l
l
l
C
l
l
l
l
l
l
D
100
l
l
l
l l
DEMO
l
l
l
l
l
l
llll
l
l
l
lll
l
l
l l
ll
l
l l
l
l
l
l
l
DEMO l
l
l
l
l
l
l
l
ll
l l
ll
l l
l
l
l
l
ll
ll l
l
l
l
DEMO
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l l
ll l
l
20
l
l
l
l
(vertical) mean of the residuals for each vertical stripe, then actually DEMO mentally
connect those means, either with straight line segments, or possibly with a smooth
curve. If the resultant connected segments or curve is DEMO to a horizontal line
at 0 on the y-axis, then we DEMO no reason to doubt the linearity assumption. If
there is a clear curve, most commonly a “smile” or “frown” shape, then we suspect
DEMO
Four examples are shown in ﬁgure9.4. In each band the mean residual is
marked, and lines segments connect these. Plots A and B show no obvious pattern
away from a horizontal line other that the small DEMO of expected “noise”. Plots
C and D show clear deviations from normality, because the lines connecting the
mean residuals of the vertical bands show a clear frown (C) and smile (D) pattern,
rather DEMO a ﬂat line. Untransformed linear regression is inappropriate for the
−15
−10
Residual
−5
5
Residual
0
10
15
20
−10
−10
Residual
−5
DEMO
Residual
−5
0
5
5
10
9.6. RESIDUAL CHECKING
l
A
l
l
l
20
l
l
l
DEMO
l
l
40
60
Fitted value
40
60
80
100
l l
l
l l
l
l l l
l
l ll
l l
DEMO
l
l l l
l
l
ll
l l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
DEMO
l
ll l
ll
l
l
80
l
100
D
l
l l
l
l
l
l
l
l
l
ll
l
l
l
DEMO l
l l
ll
l
llll
l
ll l
ll
ll
ll
l
0
llllll l
l
llllll
l
lll
ll
ll
lll
l
DEMO
20
40
60
l
l
l
l
l
l
l
l
l
l
l
l
l
l
80
l
Fitted value Fitted value
Figure DEMO: Sample residual vs. ﬁt plots for testing equal variance.
C
l
DEMO
l
l
l
l
l
l
ll
ll
l
l
l
l
l
ll
lll
ll
lll
ll l
ll
l
l l
l
DEMO
l
l l
l
l
l
l
l
ll
l
l
ll
l
l
l ll
l lll
ll
l
l l
ll
ll
DEMO
l
l
l
l
l
l
l
l
l
l
l
l
l l
ll
l
l
l
l
l
l
ll
l
l
DEMO
l
231
l l
l
l
l
l
l
l
l
l
l
l
ll l
l
l
l
0
ll
20
l
l
DEMO
l
l
llll
l
40
60
80
Fitted value
B
l
l
l
l
l
ll l ll
ll
l
lll
ll
l
l
DEMO
ll
l
l
l
100
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l
l
ll
l
l
data DEMO produced plots C and D. With practice you will get better at reading
these plots.
To detect unequal spread, we use the vertical bands in a diﬀerent way. Ideally
the vertical spread of residual values is DEMO in each vertical band. This takes
practice to judge in light of the expected variability of individual points, especially
when there are few points per band. The main idea is to realize that the minimum
and DEMO residual in any set of data is not very robust, and DEMO to vary a
lot from sample to sample. We need to estimate a more robust measure of spread
such as the IQR. This can DEMO done by eyeballing the middle 50% of the data.
Eyeballing the middle 60 or 80% of the data is also a reasonable way to DEMO the
equal variance assumption.
−100
−100
Residual
0
50
Residual
0
50
100
Residual
−5
0
5
10
Residual
−10
−5
0
5
10
232
CHAPTER 9. SIMPLE LINEAR REGRESSION
Figure9.5shows four residual vs. ﬁt plots, each of which shows good linearity.
The red horizontal lines mark the DEMO 60% of the residuals. Plots A and B show
no evidence of unequal variance; the red lines are a similar distance apart in each
band. In plot C you can see that the red lines increase DEMO distance apart as you
move from left to right. This indicates unequal variance, with greater variance at
high predicted values (high x values DEMO the slope is positive). Plot D show a pattern
with unequal variance in which the smallest variance is in the middle of the DEMO
of predicted values, with larger variance at both ends. Again, this takes practice,
but you should at least recognize obvious patterns like DEMO shown in plots C and
D. And you should avoid over-reading the slight variations seen in plots A and B.
The residual vs. ﬁt DEMO can be used to detect non-linearity and/or
unequal variance.
The check of normality can be done with a quantile normal plot as seen DEMO
ﬁgure9.6. Plot A shows no problem with Normality of the residuals because the
points show a random scatter around the reference line (see section4.3.4). Plot B
is also consistent with Normality, perhaps showing slight skew to the left. Plot C
shows deﬁnite skew to the right, because at both ends we see that several points
are higher than expected. DEMO D shows a severe low outlier as well as heavy tails
(DEMO kurtosis) because the low values are too low and the high DEMO are too
high.
A quantile normal plot of the residuals of a regression analysis can be
used to detect non-Normality.
9.7 Robustness of simple DEMO regression
No model perfectly represents the real world. It is worth learning how far we can
“bend” the assumptions without breaking the value of DEMO regression analysis.
If the linearity assumption is violated more than a fairly small amount, the
regression loses its meaning. The most obvious way this happens is in the inter-
pretation of b1. We interpret b1 as DEMO change in the mean of Y for a one-unit
9.7. ROBUSTNESS OF SIMPLE LINEAR REGRESSION
−5
0
5
10
Observed Residual DEMO
llll
lll
ll
C
ll
l
l
l
l
l
l
l
l
l
−2
0
2
4
6
−150
−100
−50
0
Observed DEMO Quantiles
Observed Residual Quantiles
Figure 9.6: Sample QN plots of regression DEMO
A
B
l
l
l
ll
llll
lllll
llllll
llllllll
lll
llll
lll
lll
ll
l
l
l
l
l
l
l
l
l
DEMO
l
l
lllllllll
lll
lll
l
l
lll
lll
lll
lllllll
ll
llll
l
l
l
l
l
l
l
−10
−5
0
5
DEMO Residual Quantiles
D
l
l
l
l
l
lll
ll
lllllllllllllll
lllllllllllllllll
lll
l
l
l
l
l
233
l
l
l
l
ll
DEMO
lllll
llll
lll
lllll
llll
Quantiles of Standard Normal
−2
−1
0
1
2
Quantiles of Standard Normal
−2
−1
0
1
2
Quantiles DEMO Standard Normal
−2
−1
0
1
2
Quantiles of Standard Normal
−2
−1
0
1
2
234
CHAPTER 9. SIMPLE LINEAR REGRESSION
increase in x. If the relationship DEMO x and Y is curved, then the change in
Y for DEMO one-unit increase in x varies at diﬀerent parts of the curve, DEMO
the interpretation. Luckily it is fairly easy to detect non-linearity through EDA
(scatterplots) and/or residual analysis. If non-linearity is detected, you should try
to ﬁx it by transforming the x and/or y variables. DEMO transformations are
log and square root. Alternatively it is common to add additional new explanatory
variables in the form of a square, cube, DEMO of the original x variable one at a time
until the residual vs. ﬁt plot shows linearity of the residuals. For data that can
DEMO lie between 0 and 1, it is worth knowing (but not memorizing) that the square
root of the arcsine of y is often a good transformation.
You should not feel that transformations are “cheating”. The DEMO way
the data is measured usually has some degree of arbitrariness. Also, common
measurements like pH for acidity, decibels for sound, and the Richter earthquake
scale are all log scales. Often transformed values are transformed DEMO to the
original scale when results are reported (but the fact DEMO the analysis was on a
transformed scale must also be reported).
Regression is reasonably robust to the equal variance assumption. Moderate
degrees of DEMO, e.g., the band with the widest variation is up to twice as wide
as the band with the smallest variation, tend to cause minimal problems. For more
severe violations, the p-values are incorrect in the sense that their null hypotheses
tend to be rejected more that 100α% DEMO the time when the null hypothesis is true.
The conﬁdence intervals (DEMO the SE’s they are based on) are also incorrect. For
worrisome DEMO of the equal variance assumption, try transformations of the
y variable (because the assumption applies at each x value, transformation of x
will be ineﬀective).
Regression is quite robust to the Normality assumption. You DEMO need to worry
about severe violations. For markedly skewed or kurtotic residual distributions,
we need to worry that the p-values and conﬁdence intervals DEMO incorrect. In that
case try transforming the y variable. Also, in DEMO case of data with less than a
handful of diﬀerent y values or with severe truncation of the data (values piling
up at the ends of a limited width scale), regression may be inappropriate due DEMO
non-Normality.
The ﬁxed-x assumption is actually quite important for regression. If the vari-
ability of the x measurement is of similar or larger magnitude DEMO the variability of
the y measurement, then regression is inappropriate. Regression DEMO tend to give
smaller than correct slopes under these conditions, and DEMO null hypothesis on the
9.8. ADDITIONAL INTERPRETATION OF REGRESSION OUTPUT
235
slope will be retained far DEMO often. Alternate techniques are required if the ﬁxed-x
assumption is broken, DEMO so-called Type 2 regression or “errors in variables
regression”.
The independent errors assumption is also critically important to regression.
A slight violation, such as a few twins in the study doesn’t matter, but other mild
to moderate violations destroy the validity of the p-value and conﬁdence intervals.
In DEMO case, use alternate techniques such as the paired t-test, repeated measures
analysis, mixed models, or time series analysis, all of which model correlated errors
rather than assume zero correlation.
Regression analysis is not very DEMO to violations of the linearity,
ﬁxed-x, and independent errors assumptions. DEMO is somewhat robust
to violation of equal variance, and moderately robust DEMO violation of
the Normality assumption.
9.8 Additional interpretation of regression out-
put
Regression output usually includes a few additional components beyond the slope
and DEMO estimates and their t and p-values.
Additional regression output is shown in table9.2which has what SPSS labels
“Residual Statistics” on top and what it DEMO “Model Summary” on the bottom.
The Residual Statistics summarize the predicted (DEMO) and residual values, as well
as “standardized” values of these. The standardized values are transformed to Z-
scores. You can use this table DEMO detect possible outliers. If you know a lot about
the outcome variable, use the unstandardized residual information to see if the
minimum, maximum DEMO standard deviation of the residuals is more extreme than
you expected. If you are less familiar, standardized residuals bigger than about 3
in absolute value suggest that those points may be outliers.
The “Standard Error of DEMO Estimate”, s, is the best estimate of σ from our
model (on the standard deviation scale). So it represents how far data will fall
from the regression predictions on the scale of the outcome DEMO For the
corn analysis, only about 5% of the data falls DEMO than 2(49)=98 gm away from
236
Predicted Value
Residual
Std. Predicted Value
Std. Residual
R
0.966
Table DEMO: Additional regression results for the corn experiment.
the prediction line. Some DEMO report the mean squared error (MSE), which
is the estimate DEMO σ2.
The R2 value or multiple correlation coeﬃcient is equal to the square of the
simple correlation of x and y in simple regression, but not in multiple regression.
In either case, R2 can be interpreted as the fraction (or percent if multiplied by
100) of the DEMO variation in the outcome that is “accounted for” by regressing the
outcome on the explanatory variable.
A little math helps here. The total variance, var(Y), in a regression problem is
the sample variance of DEMO ignoring x, which comes from the squared deviations of y
values DEMO the mean of y. Since the mean of y is the best guess of the outcome
for any subject if the value of the DEMO variable is unknown, we can think
of total variance as measuring DEMO well we can predict y without knowing x.
If we perform regression and then focus on the residuals, these values represent
our residual error variance when predicting y while using knowledge of x. The
estimate of DEMO variance is called mean squared error or MSE and is the best
estimate of the quantity σ2 deﬁned by the regression model.
If we DEMO total minus residual error variance (var(Y)-MSE) we can call
the result “explained error”. It represents the amount of variability in y DEMO is
explained away by regressing on x. Then we can compute R2 as
R2 = explained variance = var(Y ) − MSE .
DEMO variance var(Y )
So R2 is the portion of the DEMO variation in Y that is explained away by using
the x information in a regression. R2 is always between 0 and 1. An R2 DEMO 0
Minimum
84.8
-63.2
-1.43
-1.26
R Square
0.934
Maximum
611.7
112.7
1.43
2.25
Adjusted
R Square
0.931
Mean Std. Deviation
348.2 183.8
0.0 DEMO
0.00 1.00
0.00 0.978
Std. Error of
the Estimate
50.061
CHAPTER 9. SIMPLE LINEAR REGRESSION
N
24
24
24
24
9.9. USING TRANSFORMATIONS
237
means that x provides no information about y. DEMO R2 of 1 means that use of
x information allows perfect prediction of y with every point of the scatterplot
exactly on the regression DEMO Anything in between represents diﬀerent levels of
closeness of the scattered points around the regression line.
So for the corn problem we can say DEMO 93.4% of the total variation in plant
weight can be explained by regressing on the amount of nitrogen added. Unfortu-
nately, there is no clear general interpretation of the values of R2. While R2 = 0.6
DEMO indicate a great ﬁnding in social sciences, it might indicate a DEMO poor
ﬁnding in a chemistry experiment.
R2 is a measure of the fraction of the total variation in the outcome
that can be explained DEMO the explanatory variable. It runs from 0 to
1, with 1 DEMO perfect prediction of y from x.
9.9 Using transformations
If you ﬁnd a problem with the equal variance or Normality assumptions, you will
probably want to see if the problem goes away if you use log(DEMO) or y2 or √y or 1/y
instead of y for DEMO outcome. (It never matters whether you choose natural vs.
common log.) For non-linearity problems, you can try transformation of x, y, or
both. If regression on the transformed scale appears to meet the assumptions DEMO
linear regression, then go with the transformations. In most cases, when reporting
your results, you will want to back transform point estimates and the ends of
conﬁdence intervals for better interpretability. By “back transform” I DEMO do
the inverse of the transformation to return to the original scale. The inverse of
common log of y is 10y; the inverse of natural log of y is ey; the inverse of y2 is
√y; the inverse of √y is y2; and the inverse of 1/DEMO is 1/y again. Do not transform
a p-value – the p-value remains unchanged.
Here are a couple of examples of transformation and how DEMO interpretations of
the coeﬃcients are modiﬁed. If the explanatory variable is dose of a drug and the
outcome is log of time to complete DEMO task, and b0 = 2 and b1 = 1.5, then we can
say the best estimate of the log of the task time DEMO no drug is given is 2 or that
the the best estimate of the time is 102 = 100 or e2 = 7.39 depending DEMO which log
238
CHAPTER 9. SIMPLE LINEAR REGRESSION
was used. We also say that DEMO each 1 unit increase in drug, the log of task time
DEMO by 1.5 (additively). On the original scale this is a DEMO increase
of 101.5 = 31.6 or e1.5 = 4.48. Assuming natural log, this says every time the dose
goes up by another 1 unit, the mean task time get multiplied by 4.48.
If the explanatory variable is common log of dose and the outcome is blood
sugar level, and b0 = 85 and b1 = 18 then we can say DEMO when log(dose)=0,
blood sugar is 85. Using 100 = 1, this tells us that blood sugar is 85 when dose
equals 1. For every 1 unit increase in log dose, the glucose goes up by 18. But a
one unit increase in log dose is DEMO ten fold increase in dose (e.g., dose from 10 to 100
is log dose from 1 to 2). So we can say DEMO every time the dose increases 10-fold
the glucose goes up by 18.
Transformations of x or y to a diﬀerent scale are very useful DEMO ﬁxing
broken assumptions.
9.10 How to perform simple linear regression in
SPSS
To perform simple linear regression in SPSS, select Analyze/Regression/Linear...
from the menu. You will see the “Linear Regression” dialog box as shown DEMO ﬁgure
9.7. Put the outcome in the “Dependent” box and the explanatory variable in the
“Independent(s)” box. I recommend checking the “Conﬁdence DEMO box for
“Regression Coeﬃcients” under the “Statistics...” button. Also click the “Plots...”
button to get the “Linear Regression: Plots” dialog box shown in ﬁgure9.8. From
here under “Scatter” put “*ZRESID” into the “Y” box and “*ZPRED” DEMO the
“X” box to produce the residual vs. ﬁt plot. Also check the “Normal probability
plot” box.
9.10. HOW TO PERFORM SIMPLE LINEAR REGRESSION IN SPSS
Figure 9.7: Linear regression dialog box.
Figure 9.8: Linear regression plots dialog box.
239
240
CHAPTER 9. SIMPLE LINEAR REGRESSION
In a nutshell: Simple linear regression is used to explore the relation-
ship between a quantitative outcome and DEMO quantitative explanatory
variable. The p-value for the slope, b1, is a test of whether or not
changes in the explanatory variable really are DEMO with changes
in the outcome. The interpretation of the conﬁdence interval for β1 is
usually the best way to convey what has been learned DEMO a study.
Occasionally there is also interest in the intercept. No interpretations
should be given if the assumptions are violated, as determined by
thinking about the ﬁxed-x and independent errors assumptions, and
checking the residual vs. ﬁt and residual QN plots for the other three
assumptions.
Chapter 10
Analysis of Covariance
An analysis procedure for looking at group DEMO on a continuous outcome when
some other continuous explanatory variable also has an eﬀect on the outcome.
This chapter introduces several new important concepts DEMO multiple re-
gression, interaction, and use of indicator variables, then DEMO them to present a
model appropriate for the setting of a quantitative outcome, and two explanatory
variables, one categorical and one quantitative. Generally DEMO main interest is in
the eﬀects of the categorical variable, and DEMO quantitative explanatory variable is
considered to be a “control” variable, such DEMO power is improved if its value is
controlled for. Using the principles explained here, it is relatively easy to extend
the ideas to additional categorical and quantitative explanatory variables.
The term ANCOVA, analysis of covariance, DEMO commonly used in this setting,
although there is some variation in how the term is used. In some sense ANCOVA
is a blending DEMO ANOVA and regression.
10.1 Multiple regression
Before you can understand ANCOVA, DEMO need to understand multiple regression.
Multiple regression is a straightforward extension of simple regression from one to
several quantitative explanatory variables (and also categorical variables as we will
see in the section10.4). For example, if we vary water, sunlight, and fertilizer to
see their eﬀects on DEMO growth, we have three quantitative explanatory variables.
241
242 CHAPTER 10. ANALYSIS OF COVARIANCE
In this case we write the DEMO model as
E(Y |x1,x2,x3) = β0 + β1x1 DEMO β2x2 + β3x3.
Remember that E(Y |x1,x2,x3) is DEMO as expected (i.e., average) value of Y (the
outcome) DEMO the values of the explanatory variables x1 through x3. Here, x1 DEMO
the amount of water, x2 is the amount of sunlight, x3 is the amount of fertilizer, β0
is the intercept, and the DEMO βs are all slopes. Of course we can have any number
of explanatory variables as long as we have one β parameter corresponding to DEMO
explanatory variable.
Although the use of numeric subscripts for the diﬀerent explanatory variables
(x’s) and parameters (β’s) is quite common, I think that it is usually nicer to
use meaningful mnemonic letters for the DEMO variables and corresponding
text subscripts for the parameters to remove the necessity of remembering which
number goes with which explanatory variable. Unless referring to DEMO in a
completely generic way, I will avoid using numeric subscripts DEMO (except for using
β0 to refer to the intercept). So DEMO above structural equation is better written as
E(Y |W,S,F ) = β0 + βW W + βSS + βF F.
In DEMO regression, we still make the ﬁxed-x assumption which indicates
that each DEMO the quantitative explanatory variables is measured with little or no
imprecision. All of the error model assumptions also apply. These assumptions
state that for DEMO subjects that have the same levels of all explanatory variables
the outcome is Normally distributed around the true mean (or that the errors are
Normally distributed with mean zero), and that the variance, σ2, DEMO the outcome
around the true mean (or of the errors) is the same for every other set of values of
the explanatory variables. DEMO we assume that the errors are independent of each
other.
Let’s examine what the (no-interaction) multiple regression structural model is
claiming, i.e., DEMO what situations it might be plausible. By examining the equation
for the multiple regression structural model you can see that the meaning of each
DEMO coeﬃcient is that it is the change in the mean outcome associated with (or
caused by) a one-unit rise in the corresponding explanatory DEMO when all of
the other explanatory variables are held constant.
We can see this by taking the approach of writing down the structural model
DEMO then making it reﬂect speciﬁc cases. Here is how we ﬁnd what happens to
10.1. MULTIPLE REGRESSION 243
the mean outcome when x1 is ﬁxed at, say 5, and x2 at, say 10, and x3 is allowed
to vary.
E(Y |x1,x2,x3) = β0 + β1x1 + β2x2 + β3x3
E(Y |x1 = 5,x2 = 10,x3) = β0 + 5β1 + 10β2 + β3x3
E(Y |x1 = DEMO,x2 = 10,x3) = (β0 + 5β1 + 10β2) DEMO β3x3
Because the βs are ﬁxed (but unknown) constants, this DEMO tells us that when
x1 and x2 are ﬁxed at the speciﬁed values, the relationship between E(Y ) and x3
can be represented on a plot with the outcome on the y-axis and x3 on DEMO x-axis
as a straight line with slope β3 and intercept equal to the number β0 + 5β1 + 10β2.
Similarly, we get the same slope with respect to x3 for any combination of x1 and
x2, and this idea extends to changing any one explanatory variable when the DEMO
are held ﬁxed.
From simplifying the structural model to speciﬁc cases we learn that the no-
interaction multiple regression model claims that not only DEMO there a linear rela-
tionship between E(Y ) and any x when the other x’s are held constant, it also
implies that the eﬀect of a given change in an x value does not depend DEMO what the
values of the other x variables are set to, DEMO long as they are held constant. These
relationships must be plausible in any given situation for the no-interaction mul-
tiple regression model to be DEMO Some of these restrictions can be relaxed
by including interactions (see DEMO).
It is important to notice that the concept of changing the value of one ex-
planatory variable while holding the others constant is DEMO in experiments,
but generally not meaningful in observational studies. Therefore, DEMO of
the slope coeﬃcients in observational studies is fraught with diﬃculties and the
potential for misrepresentation.
Multiple regression can occur in the experimental setting DEMO two or more
continuous explanatory variables, but it is perhaps more DEMO to see one ma-
nipulated explanatory variable and one or more observed control variables. In that
setting, inclusion of the control variables increases power, while the primary in-
terpretation is focused on the experimental treatment variable. Control variables
function in the same way as blocking variables (see8.5) DEMO that they aﬀect the
outcome but are not of primary interest, DEMO for any speciﬁc value of the control
variable, the variability in DEMO associated with each value of the main exper-
imental explanatory variable is reduced. Examples of control variables for many
244
l
CHAPTER 10. ANALYSIS OF COVARIANCE
l
l
l
l
l
DEMO
l
l
l
l
l
l
0−5 flashes/min
6−10 flashes/min
11−15 flashes/min
16−20 flashes/min
20
40
decibel
60
80
Figure DEMO: EDA for the distraction example.
psychological studies include things like ability (as determined by some auxiliary
information) and age.
As an example of multiple regression with two manipulated quantitative vari-
ables, consider an analysis of the data ofMRdistract.datwhich is from a (fake)
experiment testing the eﬀects of both visual and auditory distractions on reading
comprehension. The outcome is DEMO reading comprehension test score administered
after each subject reads an article in a room with various distractions. The test is
scored from 0 to DEMO with 100 being best. The subjects are exposed to auditory
distractions that consist of recorded construction noise with the volume randomly
set to vary DEMO 10 and 90 decibels from subject to subject. The visual dis-
traction is a ﬂashing light at a ﬁxed intensity but with frequency randomly DEMO to
between 1 and 20 times per minute.
Test score
30
40
50
60
70
10.1. MULTIPLE REGRESSION
245
(Constant)
db
freq
Unstandardized
Coeﬃcients
B Std. Error
74.688 3.260
-0.200 0.043
-1.118 0.208
t
22.910
-4.695
-5.38
Sig.
<0.0005
<0.0005
<0.0005
95% Conﬁdence Interval for B
Lower Bound Upper DEMO
68.083 81.294
-0.286 -0.114
-1.539 -0.697
Table 10.1: Regression results for DEMO experiment.
R
0.744
R Square
0.553
Adjusted
R Square
0.529
Std. Error of
the Estimate
6.939
Table 10.2: Distraction experiment model summary.
Exploratory data analysis is diﬃcult in the multiple regression setting because
we need more DEMO a two dimensional graph. For two explanatory variables and
one outcome variable, programs like SPSS have a 3-dimensional plot (in SPSS
try Graphs/DEMO and choose the “Simple 3-D Scatter” template in the
Scatter/Dot gallery; double click on the resulting plot and click the “Rotating 3-D
Plot” toolbar button to make it “live” which allows you to rotate the DEMO so as to
view it at diﬀerent angles). For more than two explanatory variables, things get
even more diﬃcult. One approach that can help, but has some limitations, is to plot
the outcome separately DEMO each explanatory variable. For two explanatory
variables, one variable can be DEMO demoted to categories (e.g., using the
visual bander in SPSS), and then a plot like ﬁgure10.1is produced. Simple
regression ﬁt lines are DEMO for each category. Here we can see that increasing the
value of either explanatory variable tends to reduce the mean outcome. Although
the ﬁt DEMO are not parallel, with a little practice you will be able DEMO see that given
the uncertainty in setting their slopes from the data, they are actually consistent
with parallel lines, which is an indication DEMO no interaction is needed (see below
for details).
The multiple DEMO results are shown in tables10.110.2, and10.3.
246
CHAPTER 10. ANALYSIS OF COVARIANCE
Regression
Residual
Total
Sum of
Squares
DEMO
1781.6
3983.9
df
2
37
39
Mean Square
1101.1
48.152
F
22.9
Sig.
<0.0005
Table 10.3: Distraction experiment ANOVA.
Really important fact: There is an one-to-one relationship between the
coeﬃcients in the multiple regression output DEMO the model equation
for the mean of Y given the x’s. There is exactly one term in the
equation for each line in the DEMO table.
Here is an interpretation of the analysis of this experiment. (DEMO reported
numbers are rounded to a smaller, more reasonable number of DEMO places –
usually 3 signiﬁcant ﬁgures.) A multiple regression analysis (additive model, i.e.,
with no interaction) was performed using sound distraction DEMO in decibels and
visual distraction frequency in ﬂashes per minute as explanatory variables, and
test score as the outcome. Changes in both distraction types cause a statistically
signiﬁcant reduction in test scores. For each 10 db DEMO in noise level, the test
score drops by 2.00 points (p<0.0005, 95% CI=[1.14, 2.86]) at any ﬁxed visual
distraction level. For each per minute increase in the visual distraction blink rate,
the DEMO score drops by 1.12 points (p<0.0005, 95%CI=[0.70,1.54]) at DEMO ﬁxed
auditory distraction value. About 53% of the variability in test scores is accounted
for by taking the values of the two distractions into DEMO (This comes from
adjusted R2.) The estimate of the standard deviation of test scores for any ﬁxed
combination of sound and light distraction DEMO 6.9 points.
The validity of these conclusions is conﬁrmed by the following assumption
checks. The quantile-normal plot of the residuals conﬁrms Normality of errors,DEMO
the residual vs. ﬁt plot conﬁrms linearity and equal variance. (Subject DEMO is a
mild outlier with standardized residual of -2.3). The ﬁxed-x assumption is met
because the values of the distractions are precisely set DEMO the experimenter. The
independent errors assumption is met because separate subjects are used for each
test, and the subjects were not allowed to collaborate.
It is also a good idea to further conﬁrm linearity for each DEMO variable
10.2. INTERACTION
247
with plots of each explanatory variable vs. the residuals. DEMO plots also look
OK here.
One additional test should be performed before accepting the model and anal-
ysis discussed above for these data. We DEMO test the “additivity” assumption
which says that the eﬀect (on the DEMO) of a one-unit rise of one explanatory
variable is the same DEMO every ﬁxed value of the other variable (and vice versa). DEMO
violation of this assumption usually takes the form of “interaction” which is the
topic of the next section. The test needed is the p-value DEMO the interaction term
of a separate multiple regression model run with an interaction term.
One new interpretation is for the p-value of <0.0005 for the F statistic of
22.9 in the ANOVA table for the multiple DEMO The p-value is for the null
hypothesis that all of the slope parameters, but not the intercept parameter, are
equal to zero. So DEMO this experiment we reject H0 : βV = βA = 0 (DEMO better yet,
H0 : βvisual = βauditory = 0
Multiple regression is a direct extension of simple regression to mul-
tiple explanatory variables. DEMO new explanatory variable adds one
term to the structural model.
10.2 Interaction
Interaction is a major concept in statistics that applies whenever there are DEMO
or more explanatory variables. Interaction is said to exist between two or more
explanatory variables in their eﬀect on an outcome. Interaction is never DEMO
an explanatory variable and an outcome, or between levels of a DEMO explanatory
variable. The term interaction applies to both quantitative and categorical ex-
planatory variables. The deﬁnition of interaction is that the eﬀect of a DEMO in
the level or value of one explanatory variable on the mean outcome depends on the
level or value of another explanatory variable. Therefore DEMO relates to the
structural part of a statistical model.
In the absence of interaction, the eﬀect on the outcome of any speciﬁc change
in one explanatory variable, e.g., a one unit rise in a quantitative DEMO or a
change from, e.g., level 3 to level 1 of a categorical variable, does not depend on
248
CHAPTER 10. ANALYSIS OF COVARIANCE
Setting
1
2
3
4
xS DEMO
2 4
3 4
2 6
3 6
E(Y)
100-5(2)-3(4)=78
100-5(3)-3(4)=73
100-5(2)-3(DEMO)=72
100-5(3)-3(6)=67
diﬀerence
from baseline
-5
-6
-11
Table 10.4: Demonstration of the additivity of E(Y ) = 100 − 5xS − 3xL.
the level or value of the other explanatory DEMO(s), as long as they are held
constant. This also tells us that, e.g., the eﬀect on the outcome of changing from
DEMO 1 of explanatory variable 1 and level 3 of explanatory variable 2 to level 4 of
explanatory variable 1 and level 2 of explanatory DEMO 2 is equal to the sum
of the eﬀects on the outcome of only changing variable 1 from level 1 to 4 plus
the DEMO of only changing variable 2 from level 3 to 1. For this reason the lack
of an interaction is called additivity. The distraction example DEMO the previous
section is an example of a multiple regression model for which additivity holds
(and therefore there is no interaction of the two explanatory variables in their
eﬀects on the outcome).
A mathematic example DEMO make this more clear. Consider a model with
quantitative explanatory variables “decibels of distracting sound” and “frequency
of light ﬂashing”, represented by xS and xL respectively. Imagine that the param-
eters are actually known, so that we can use numbers instead of symbols for this
example. The structural DEMO demonstrated here is E(Y ) = 100 − 5xS − 3xL.
Sample calculations are shown in Table10.4. Line 1 shows the arbitrary starting
DEMO xS = 2, xL = 4. The mean outcome is 78, which we can call the “base-
line” for these calculations. If we DEMO the light level the same and change the
sound to 3 (DEMO 2), the mean outcome drops by 5. If we return to xS = 2, but
change xL to 6 (setting 3), DEMO the mean outcome drops by 6. Because this is
a non-interactive, DEMO, additive, model we expect that the eﬀect of simultaneously
changing xS from 2 to 3 and xL from 4 to 6 will be DEMO drop of 5+6=11. As shown
for setting 4, this is indeed DEMO This would not be true in a model with interaction.
Note that the component explanatory variables of an interaction and the lines
containing these DEMO explanatory variables in the coeﬃcient table of the
multiple regression output, DEMO referred to as main eﬀects. In the presence of an
interaction, DEMO the signs of the coeﬃcient estimates of the main eﬀects are the
10.2. INTERACTION
249
same, we use the term synergy if the interaction coeﬃcient has the same sign.
This indicates a “super-additive” eﬀect, where the whole is more than the sum of
the parts. If the interaction DEMO has opposite sign to the main eﬀects, we
use the term DEMO to indicate a “sub-additive” eﬀects where simultaneous
changes in both explanatory variables has less eﬀect than the sum of the individual
eﬀects.
The key DEMO understanding the concept of interaction, how to put it into a DEMO
tural model, and how to interpret it, is to understand the construction of one or
more new interaction variables from the existing explanatory DEMO An inter-
action variable is created as the product of two (DEMO more) explanatory variables.
That is why some programs and textbooks use DEMO notation “A*B” to refer to the
interaction of explanatory variables A and B. Some other programs and textbooks
use “A:B”. Some computer programs DEMO automatically create interaction vari-
ables, and some require you to create DEMO (You can always create them yourself,
even if the program DEMO a mechanism for automatic creation.) Peculiarly, SPSS
has the automatic mechanism for some types of analyses but not others.
The creation, use, DEMO interpretation of interaction variables for two quanti-
tative explanatory variables is discussed next. The extension to more than two
variables is analogous but more DEMO Interactions that include a categorical
variable are discussed in the next section.
Consider an example of an experiment testing the eﬀects of the dose DEMO a drug
(in mg) on the induction of lethargy in rats as measured by number of minutes
that the rat spends resting or DEMO in a 4 hour period. Rats of diﬀerent ages
are used and age (in months) is used as a control variable. Data for DEMO (fake)
experiment are found inlethargy.dat.
Figure10.2shows some EDA. Here the DEMO variable, age, is again cate-
gorized, and regression ﬁt lines DEMO added to the plot for each level of the age
categories. (DEMO analysis uses the complete, quantitative version of the age
variable.) What you should see here is that the slope appears to change as DEMO
control variable changes. It looks like more drug causes more lethargy, DEMO older
rats are more lethargic at any dose. But what suggests interaction here is that the
three ﬁt lines are not parallel, so we get the (correct) impression that the aﬀect of
any dose increase DEMO lethargy is stronger in old rats than in young rats.
In multiple regression with interaction we add the new (product) interaction
variable(s) as additional explanatory variables. For the case with two explanatory
250
CHAPTER 10. ANALYSIS OF COVARIANCE
l
l
l
l
0
l
DEMO months
9−11 months
13−16 months
l
ll
l
ll
l
l
ll
5
10
15
20
25
dose
ll
l
30
Figure 10.2: EDA for the lethargy example.
Rest/sleep time (minutes)
50
100
150
200
250
10.2. INTERACTION 251
variable, this becomes
E(Y |x1,x2) = DEMO + β1x1 + β2x2 + β12(x1 · x2)
where β12 is the single parameter that represents the interaction eﬀect and (x1 ·x2)
can either be thought of a the single new interaction variable (data column) or as
the product of the two individual explanatory variables.
Let’s examine what the multiple regression with interaction model is claim-
ing, i.e., in what situations it might be plausible. By examining the equation for
the structural model you can see that the eﬀect of a DEMO unit change in either
explanatory variable depends on the value of the other explanatory variable.
We can understand the details by taking the approach DEMO writing down the
model equation then making it reﬂect speciﬁc cases. Here, we use more meaningful
variable names and parameter subscripts. Speciﬁcally, βd*a DEMO the symbol for the
single interaction parameter.
E(Y |dose, age) = β0 + βdosedose + βageage + βd*adose · age
E(Y DEMO, age = a) = β0 + βdosedose + aβage + aβd*a · dose
E(Y |dose, age = a) = (β0 + aβage) + (βdose + aβd*a)dose
Because the βs are ﬁxed (unknown) constants, this equation tells us that when
age is ﬁxed DEMO some particular number, a, the relationship between E(Y ) and dose
is a straight line with intercept equal to the number β0 DEMO aβage and slope equal
to the number βdose + aβd*a. The key feature of the interaction is the fact that
the slope with respect DEMO dose is diﬀerent for each value of a, i.e., for each age.
A similar equation can be written for ﬁxed dose and varying DEMO The conclusion
is that the interaction model is one where the eﬀects of any one-unit change in
one explanatory variable while holding the other(DEMO) constant is a change in the
mean outcome, but the size (and maybe direction) of that change depends on the
value(s) that the other explanatory variable(s) is/are set to.
Explaining the meaning of the interaction parameter in a multiple regression
with continuous explanatory DEMO is diﬃcult. Luckily, as we will see below, it
is much easier in the simplest version of ANCOVA, where there is one categorical
and one continuous explanatory variable.
The multiple regression results are shown in DEMO, and10.7.
252
(Constant)
Drug dose
Rat age
DoseAge IA
R
0.992
R Square
0.985
Adjusted
R Square
0.984
Std. Error of
the Estimate
7.883
DEMO 10.6: Lethargy experiment model summary.
Regression
Residual
Total
Sum of
Squares
DEMO
3480
225729
df
3
56
59
Mean Square
1101.1
48.152
F
22.868
Table 10.7: Lethargy experiment ANOVA.
Sig.
<0.0005
CHAPTER 10. ANALYSIS OF DEMO
Unstandardized
Coeﬃcients
B Std. Error
48.995 5.493
0.398 0.282
0.759 0.500
0.396 0.025
t
8.919
1.410
1.517
15.865
Sig.
<0.0005
0.164
0.135
<0.0005
DEMO Conﬁdence Interval for B
Lower Bound Upper Bound
37.991 59.999
-0.167 0.962
-0.243 1.761
0.346 0.446
Table 10.5: Regression results for lethargy experiment.
10.2. INTERACTION
253
Here is an interpretation of the analysis of this DEMO written in language
suitable for an exam answer. A multiple regression analysis including interaction
was performed using drug dose in mg and rat age DEMO months as explanatory vari-
ables, and minutes resting or sleeping during DEMO 4 hour test period as the outcome.
There is a signiﬁcant interaction (t=15.86, p<0.0005) between dose and age in
their eﬀect on lethargy. (Therefore changes in either or both explanatory variables
cause changes in the lethargy outcome.) Because the coeﬃcient estimate for the
interaction is of the same sign as the signs of the individual coeﬃcients, it is easy to
give a general idea about the eﬀects of the explanatory DEMO on the outcome.
Increases in both dose and age are associated with (cause, for dose) an increase in
lethargy, and the eﬀects DEMO “super-additive” or “synergistic” in the sense that the
eﬀect of simultaneous ﬁxed increases in both variables is more than the sum of the
eﬀects DEMO the same increases made separately for each explanatory variable. We
can also see that about 98% of the variability in resting/sleeping time is DEMO
for by taking the values of dose and age into account. The estimate of the standard
deviation of resting/sleeping time for any ﬁxed DEMO of dose and age is 7.9
minutes.
The validity of these conclusions is conﬁrmed by the following assumption
checks. The quantile-normal plot of the DEMO conﬁrms Normality of errors,
the residual vs. ﬁt plot conﬁrms linearity and equal variance. The ﬁxed-x assump-
tion is met because the dose DEMO precisely set by the experimenter and age is precisely
observed. The independent errors assumption is met because separate subjects are
used for each test, and the subjects were not allowed to collaborate. Linearity is
further conﬁrmed DEMO plots of each explanatory variable vs. the residuals.
Note that the p-value for the interaction line of the regression results (coeﬃ-
cient) table DEMO us that the interaction is an important part of the model. Also
note that the component explanatory variables of the interaction (main eﬀects) DEMO
almost always included in a model if the interaction is included. In the presence
of a signiﬁcant interaction both explanatory variables must aﬀect the DEMO, so
(except in certain special circumstances) you should not interpret DEMO p-values of
the main eﬀects if the interaction has a signiﬁcant p-value. On the other hand,
if the interaction is not signiﬁcant, generally the appropriate next step is to per-
form a new multiple regression DEMO excluding the interaction term, i.e., run an
additive model.
If we want to write prediction equations with numbers instead of symbols, we
should use Y 0 or Yˆ on the left side, to indicate a “best estimate” rather than the
254
CHAPTER 10. ANALYSIS OF COVARIANCE
true but unknowable values represented by DEMO(Y ) which depends on the β values.
For this example, DEMO prediction equation for resting/sleeping minutes for rats of
age 12 months at any dose is
Yˆ
= 49.0 + 0.398(dose) + 0.76(12) + 0.396(dose · 12)
which is
Yˆ
= 58.1 + 5.15(dose).
Interaction between two explanatory variables is present when DEMO
eﬀect of one on the outcome depends on the value of the other. In-
teraction is implemented in multiple regression by including a new
DEMO variable that is the product of two existing explanatory
variables. The model can be explained by writing equations for the
relationship between one explanatory DEMO and the outcome for
some ﬁxed values of the other explanatory variable.
10.3 Categorical variables in multiple regression
To use a categorical variable with DEMO levels in multiple regression we must re-code
the data column as k − 1 new columns, each with only two diﬀerent codes (most
DEMO we use 0 and 1). Variables that only take on the values 0 or 1 are called
indicator or dummy variables. They should DEMO considered as quantitative
variables. and should be named to correspond to their “1” level.
An indicator variable is coded 0 for any case that DEMO not match the
variable name and 1 for any case that does match the variable name.
One level of the original categorical variable is DEMO the “baseline”. If
there is a control or placebo, the baseline DEMO usually set to that level. The baseline
level does not have a corresponding variable in the new coding; instead subjects
with that level of the categorical variable have 0’s in all of the new variables. Each
DEMO variable is coded to have a “1” for the level of the categorical variable that
matches its name and a zero otherwise.
10.3. CATEGORICAL VARIABLES IN MULTIPLE REGRESSION
255
It is very important to DEMO that when new variables like these are con-
structed, they replace DEMO original categorical variable when entering variables into
a multiple regression analysis, DEMO the original variables are no longer used at all.
(The originals DEMO not be erased, because they are useful for EDA, and because
you want to be able to verify correct coding of the indicator DEMO)
This scheme for constructing new variables insures appropriate multiple regres-
sion analysis of categorical explanatory variables. As mentioned above, sometimes
you need to create these variables explicitly, and sometime a statistical program
will create them for you, either explicitly or silently.
The choice of the baseline variable only aﬀects the convenience of presentation
of results and does not aﬀect DEMO interpretation of the model or the prediction of
future values.
As an example consider a data set with a categorical variable for favorite condi-
DEMO The categories are ketchup, mustard, hot sauce, and other. If DEMO arbitrarily
choose ketchup as the baseline category we get a coding like this:
Indicator Variable
Level mustard hot sauce other
ketchup 0 0 DEMO
mustard 1 0 0
hot sauce 0 1 0
other 0 0 1
Note that this indicates, e.g., that every subject that likes DEMO best has a 1
for their “mustard” variable, and zeros for DEMO “hot sauce” and “other” variables.
As shown in the next section, DEMO coding ﬂexibly allows a model to have no
restrictions on the relationships of population means when comparing levels of the
categorical variable. It is DEMO to understand that if we “accidentally” use a
categorical variable, usually DEMO values 1 through k, in a multiple regression, then
we are inappropriately forcing the mean outcome to be ordered according to the
levels DEMO a nominal variable, and we are forcing these means to be DEMO spaced.
Both of these problems are ﬁxed by using indicator variable recoding.
To code the interaction between a categorical variable and a quantitative vari-
DEMO, we need to create another k − 1 new variables. These DEMO are the
products of thethe resulting new data columns has zeros for all rows corresponding to all levels ofk − 1 indicator variable(s) and the quantitative variable. Each of
the categorical variable except one (the one included in the name of the interaction
256
CHAPTER 10. ANALYSIS OF COVARIANCE
variable), and has the value DEMO the quantitative variable for the rows corresponding
to the named level.
Generally a model includes all or none of a set of indicator variables DEMO cor-
respond with a single categorical variable. The same goes for the k − 1 interaction
variables corresponding to a given categorical variable and DEMO explana-
tory variable.
Categorical explanatory variables can be incorporated into multiple
regression models by substituting k − 1 indicator variables for any k-
level DEMO variable. For an interaction between a categorical
and a quantitative variable k − 1 product variables should be created.
10.4 ANCOVA
The term ANCOVA (analysis of covariance) is used somewhat diﬀerently by dif-
ferent analysts and computer programs, but the most common meaning, and the
one we DEMO use here, is for a multiple regression analysis in which there DEMO at least
one quantitative and one categorical explanatory variable. Usually the categorical
variable is a treatment of primary interest, and the quantitative variable is a “con-
trol variable” of secondary interest, which is included to improve power (without
sacriﬁcing generalizability).
Consider a particular quantitative outcome and two or more treatments that we
are comparing for their eﬀects on the DEMO If we know one or more explanatory
variables are suspected to both aﬀect the outcome and to deﬁne groups of subjects
that are more DEMO in terms of their outcomes for any treatment, then we
know DEMO we can use the blocking principle to increase power. Ignoring the other
explanatory variables and performing a simple ANOVA increases σ2 and makes it
DEMO to detect any real diﬀerences in treatment eﬀects.
ANCOVA extends the idea of blocking to continuous explanatory variables,
as long as a simple DEMO relationship (usually linear) holds between the
control variable and the outcome.
10.4. ANCOVA
10.4.1 ANCOVA with no interaction
257
An example will make DEMO more concrete. The data inmathtest.datcome from
a (fake) experiment testing the eﬀects of two computer aided instruction (CAI)
programs on performance on a math test. The programs are labeled A and B,
where DEMO is the control, older program, and B is suspected to be an improved
version. We know that performance depends on general mathematical ability DEMO
the students math SAT is used as a control variable.
First let’s look at t-test results, ignoring the SAT score. EDA shows a slightly
higher mean math test score, but lower median for program B. A t-test shows no
signiﬁcant diﬀerence with t=0.786, p=0.435. It is worth noting that the CI for
the mean diﬀerence between programs is [-5.36, 12.30], so we are 95% conﬁdent
that the eﬀect of program B relative to the old program A is somewhere between
lowering the mean score DEMO 5 points and raising it by 12 points. The estimate of
σ (square root of MSwithin from an ANOVA) is 17.1 test points.
DEMO showing the relationship between math SAT (MSAT) and test score sep-
arately for each program is shown in ﬁgure10.3. The steepness of the DEMO and
the fact that the variation in y at any x is smaller than the overall variation in y
for either program demonstrates the DEMO of using MSAT as a control variable.
The lines are roughly parallel, suggesting that an additive, no-interaction model is
appropriate. The line for DEMO B is higher than for program A, suggesting its
superiority.
First DEMO is a good idea to run an ANCOVA model with interaction to verify that
the ﬁt lines are parallel (the slopes are not statistically signiﬁcantly diﬀerent). This
is done by running a multiple regression model DEMO includes the explanatory vari-
ables ProgB, MSAT, and the interaction between them (i.e, the product variable).
Note that we do not DEMO to create a new set of indicator variables because there
are only two levels of program, and the existing variable is already an indicator
variable for program B. We do need to create the interaction variable DEMO SPSS. The
interaction p-value is 0.375 (not shown), so there DEMO no evidence of a signiﬁcant
interaction (diﬀerent slopes).
The results DEMO the additive model (excluding the interaction) are shown in tables
10.810.9, and10.10.
Of primary interest is the estimate of the beneﬁt of using program B over
program A, which is 10 points (t=2.40, p=0.020) with a 95% conﬁdence interval
of 2 to 18 points. Somewhat surprisingly the estimate of σ, which now refers to
258
(Constant)
ProgB
Math SAT
CHAPTER 10. ANALYSIS OF COVARIANCE
l
l
l
l
ll
l
ll
l
l
l
l
l
400
DEMO
600
700
Math SAT
Figure 10.3: EDA for the math test / CAI example.
Tutor A
Tutor B
l
l
l
l
l
ll
l
l
l
800
l
l
l
l
l
l
l
Unstandardized
DEMO
B Std. Error
-0.270 12.698
10.093 4.206
0.079 0.019
t
-0.021
2.400
4.171
Sig.
0.983
0.020
<0.0005
95% Conﬁdence Interval for B
Lower Bound Upper Bound
-25.696 25.157
1.671 18.515
0.041 0.117
Table 10.8: Regression results for CAI experiment.
Test score
10
20
30
40
50
60
70
DEMO
10.4. ANCOVA
259
R
0.492
R Square
0.242
Adjusted
R Square
0.215
DEMO Error of
the Estimate
15.082
Table 10.9: CAI experiment model summary.
DEMO
Residual
Total
Sum of
Squares
4138
12966
17104
df
2
57
59
Mean Square
2069.0
227.5
F
0.095
Table 10.10: CAI experiment ANOVA.
Sig.
<0.0005
the standard deviation of test score for any combination of program and MSAT is
only slightly reduced from 17.1 to 15.1 points. The DEMO model explains 22%
of the variabilty in test scores (adjusted r-squared DEMO 0.215), so there are probably
some other important variables “out there” to be discovered.
Of minor interest is the fact that the “control” DEMO, math SAT score, is
highly statistically signiﬁcant (t=4.17, p<0.0005). Every 10 additional math SAT
points is associated with a 0.4 DEMO 1.2 point rise in test score.
In conclusion, program B improves DEMO scores by a few points on average for
students of all ability levels (as determined by MSAT scores).
This is a typical ANOVA story where the power to detect the eﬀects of a
treatment is DEMO by including one or more control and/or blocking variables,
which are chosen by subject matter experts based on prior knowledge. In this
DEMO the eﬀect of program B compared to control program A was detectable using
MSAT in an ANCOVA, but not when ignoring it in the t-test.
The simpliﬁed model equations are shown here.
E(Y |ProgB,MSAT ) = β0 + βProgBProgB + βMSATMSAT
Program A: E(Y |ProgB DEMO 0,MSAT ) = β0 + βMSATMSAT
Program B: E(Y DEMO = 1,MSAT ) = (β0 + βProgB) + βMSATMSAT
260
CHAPTER 10. ANALYSIS OF COVARIANCE
To be perfectly explicit, βMSAT is the slope parameter for MSAT and βProgB
is the parameter for the DEMO variable ProgB. This parameter is technically a
“slope”, but really determines DEMO diﬀerence in intercept for program A vs. program
B.
For the analysis of the data shown here, the predictions are:
Program A: (
Program B: (
Yˆ
Yˆ
( |ProgB,MSAT
|ProgB = DEMO,MSAT
|ProgB = 1,MSAT
Yˆ
) = −0.27 + 10.09ProgB + 0.08MSAT
) = −0.27 + 0.08MSAT
) = 9.82 + 0.08MSAT
Note DEMO although the intercept is a meaningless extrapolation to an impossible
MSAT score of 0, we still need to use it in the prediction equation. Also note, that
in this no-interaction model, the simpliﬁed equations for DEMO diﬀerent treatment
levels have diﬀerent intercepts, but the same slope.
ANCOVA DEMO no interaction is used in the case of a quantitative
outcome with both a categorical and a quantitative explanatory vari-
able. The main use DEMO for testing a treatment eﬀect while using a
quantitative control variable to gain power.
10.4.2 ANCOVA with interaction
It is also possible that a DEMO interaction between a control variable and
treatment will occur, or that DEMO quantitative explanatory variable is a variable of
primary interest that interacts with the categorical explanatory variable. Often
when we do an ANCOVA, we are “hoping” that there is no interaction because
that indicates a more complicated DEMO, which is harder to explain. On the other
hand sometimes a DEMO complicated view of the world is just more interesting!
The multiple regression results shown in tables10.11and10.12refer to an
experiment testing the eﬀect of three DEMO treatments (A, B and C) on a
quantitative outcome, performance, which can range from 0 to 200 points, while
controlling for DEMO variable S, which can range from 0 to 100 points. The DEMO
are available atPerformance.dat. EDA showing the relationship between skill and
10.4. ANCOVA
RxA
RxB
RxC
l
l
l
l
l
l
261
DEMO
l
l
l
l
0
20
l
l
40
Skill
60
80
Figure 10.4: EDA for the performance ANCOVA example.
l
l
l
l
l l
l
l
l
l
l
l
ll
l
l
l
DEMO
50
Performance
100
150
262
CHAPTER 10. ANALYSIS OF COVARIANCE
performance separately for each treatment is DEMO in ﬁgure10.4. The treatment
variable, called Rx, was recoded to k− 1 = 2 indicator variables, which we will call
RxB and RxC, with level A as the baseline. Two interaction variables were created
by multiplying S by RxB and S by RxC to create the single, two column interaction
of Rx and S. Because it is logical and DEMO to consider the interaction between
a continuous explanatory variable and a k level categorical explanatory variable,
where k > 2, as a single interaction with k − 1 degrees of freedom and k − 1
DEMO in a coeﬃcient table, we use a special procedure in SPSS (or other similar
programs) to ﬁnd a single p-value for the null hypothesis that model is additive
vs. the alternative that there is an DEMO The SPSS procedure using the
Linear Regression module is to use two “blocks” of independent variables, placing
the main eﬀects (here RxB, RxC, and Skill) into block 1, and the going to the
“Next” block and placing the two interaction variables (here, RxB*S and RxC*S)DEMO
into block 2. The optional statistic “R Squared Change” must also be selected.
The output that is labeled “Model Summary” (Table10.11) and that DEMO pro-
duced with the “R Squared Change” option is explained here. Lines are shown
for two models. The ﬁrst model is for the explanatory DEMO in block 1 only,
i.e., the main eﬀects, so it is for the additive ANCOVA model. The table shows
that this model DEMO an adjusted R2 value of 0.863, and an estimate of 11.61 DEMO the
standard error of the estimate (σ). The second model DEMO the single 2 df interac-
tion to produce the full interaction ANCOVA model with separate slopes for each
treatment. The adjusted R2 is larger DEMO that this is the better model. One
good formal test of the necessity of using the more complex interaction model over
just the additive DEMO is the “F Change” test. Here the test has an F statistic of
6.36 with 2 and 84 df and a p-value of 0.003, so we reject the null hypothesis that
the additive model is suﬃcient, and work only with the interaction model (model
2) for further DEMO (The Model-1 “F Change test” is for the necessity
of the DEMO model over an intercept-only model that predicts the intercept for
all subjects.)
Using mnemonic labels for the parameters, the structural model that goes with
this analysis (Model 2, with interaction) is
E(Y |Rx, S) = β0 + βRxBRxB + βRxCRxC + βSS + βRxB*SRxB DEMO S + βRxC*SRxC · S
You should be able to construct this equation directly from the names of the
explanatory variables in Table10.12.
Using DEMO, the parameter estimates are β0 = 14.56, βRxB = 17.10, DEMO =
17.77, βS = 0.92, βRxB*S = 0.23, and βRxC*S DEMO 0.50.
10.4. ANCOVA
Model
1
2
Model
1
2
R
0.931
0.941
R DEMO
0.867
0.885
Adjusted R
Square
0.863
0.878
Change Statistics
R Square
Change
0.867
0.017
F Change
187.57
6.36
df1
3
2
df2
86
84
DEMO Error of
the Estimate
11.61
10.95
Sig. F Change
<0.0005
0.003
DEMO 10.11: Model summary results for generic experiment.
Model
1 (Constant)
RxB
RxC
S
2 (Constant)
RxB
RxC
S
RxB*S
RxC*S
Unstandardized
Coeﬃcients
B Std. Error
2.22 3.39
27.30 3.01
39.81 3.00
1.18 0.06
DEMO 5.00
17.10 6.63
17.77 6.83
0.92 0.10
0.23 0.14
0.50 0.14
t
0.95
9.08
13.28
19.60
2.91
2.58
2.60
8.82
1.16
3.55
Sig.
0.344
<0.0005
<0.0005
<0.0005
0.005
0.012
0.011
<0.0005
0.108
0.001
Table 10.12: Regression results for generic experiment.
263
264
CHAPTER 10. ANALYSIS OF COVARIANCE
To understand this complicated model, we need to write simpliﬁed equations:
RxA: E(Y |Rx=A, S) = β0 + βSS
RxB: E(Y |Rx=B, S) = (DEMO + βRxB) + (βS + βRxB*S)S
RxC: E(Y DEMO, S) = (β0 + βRxC) + (βS + βRxC*S)DEMO
Remember that these simpliﬁed equations are created by substituting in 0’s
and 1’s for RxB and RxC (but not into parameter subscripts), and then fully
simplifying the equations.
By examining these three equations we can DEMO understand the model. From
the ﬁrst equation we see that β0 is the mean outcome for subjects given treatment
A and who have S=0. (It is often worthwhile to “center” a variable like S by
subtracting DEMO mean from every value; then the intercept will refer to the DEMO of
S, which is never an extrapolation.)
Again using the DEMO equation we see that the interpretation of βS is the slope
of Y vs. S for subjects given treatment A.
From the second equation, the intercept for treatment B can be seen to be
(β0 + βRxB), and this is the mean outcome when S=0 for subjects DEMO treatment
B. Therefore the interpretation of βRxB is the diﬀerence in mean outcome when
S=0 when comparing treatment B to treatment A (a positive parameter value
would indicate a higher outcome for B than A, and a negative parameter value
would indicate a lower outcome). Similarly, the interpretation of βRxB*S is the
change in slope from treatment A to DEMO B, where a positive βRxB*S means
that the B slope is DEMO than the A slope and a negative βRxB*S means that
the B slope is less steep than the A slope.
The null hypotheses then DEMO these speciﬁc meanings. βRxB = 0 is a test of
whether the intercepts diﬀer for treatments A and B. βRxC = 0 is a DEMO of whether
the intercepts diﬀer for treatments A and C. βRxB*S = 0 is a test of whether the
slopes diﬀer for treatments A DEMO B. And βRxC*S = 0 is a test of whether the
slopes diﬀer for treatments A and C.
Here is a full interpretation of DEMO performance ANCOVA example. Notice
that the interpretation can be thought of a description of the EDA plot which uses
ANCOVA results to specify which DEMO one might make about the plot
that are statistically veriﬁable.
Analysis of the data from the performance dataset shows that treatment and
10.4. ANCOVA
265
skill interact in their eﬀects on performance. Because skill DEMO of zero are a gross
extrapolation, we should not interpret the DEMO
If skill=0 were a meaningful, observed state, then we would say all of the things
in this paragraph. The estimated mean performance for DEMO with zero skill
given treatment A is 14.6 points (a 95% DEMO would be more meaningful). If it were
scientiﬁcally interesting, we DEMO also say that this value of 14.6 is statistically
diﬀerent from zero (t=2.91, df=84, p=0.005). The intercepts for treatments B and
C (mean performances when skill level is zero) are both statistically signiﬁcantly
DEMO from the intercept for treatment A (t=2.58,2.60, df=84, p=0.012, 0.011).
The estimates are 17.1 and 17.8 points higher for B DEMO C respectively compared
to A (and again, CIs would be useful here).
We can also say that there is a statistically signiﬁcant DEMO of skill on per-
formance for subjects given treatment A (t=8.82, p< 0.0005). The best estimate
is that the mean performance increases by 9.2 points for each 10 point increase
in skill. The slope DEMO performance vs. skill for treatment B is not statistically
signiﬁcantly diﬀerent for that of treatment A (t=1.15, p=0.108). The slope of
performance DEMO skill for treatment C is statistically signiﬁcantly diﬀerent for that
of treatment A (t=3.55, p=0.001). The best estimate is that the slope DEMO subjects
given treatment C is 0.50 higher than for treatment A (DEMO, the mean change in
performance for a 1 unit increase in DEMO is 0.50 points more for treatment C than
for treatment A). We can also say that the best estimate for the slope of DEMO eﬀect
of skill on performance for treatment C is 0.92+0.50=1.42.
Additional testing, using methods we have not learned, can be performed to
show DEMO performance is better for treatments B and C than treatment A at all
observed levels of skill.
In summary, increasing skill has a positive eﬀect on performance for treatment
A (of about 9 points per 10 point rise in skill level). Treatment B has a higher
projected DEMO than treatment A, and the eﬀect of skill on subjects given
DEMO B is not statistically diﬀerent from the eﬀect on those given treatment
A. Treatment C has a higher projected intercept than treatment A, and the eﬀect
of skill on subjects given treatment C is statistically diﬀerent DEMO the eﬀect on
those given treatment A (by about 5 additional DEMO per 10 unit rise in skill).
266
CHAPTER 10. ANALYSIS OF COVARIANCE
If an ANCOVA has a signiﬁcant DEMO between the categorical
and quantitative explanatory variables, then the slope of DEMO equation
relating the quantitative variable to the outcome diﬀers for diﬀerent
levels of the categorical variable. The p-values for indicator variables
test intercept diﬀerences DEMO the baseline treatment, while the in-
teraction p-values test slope diﬀerences DEMO the baseline treatment.
10.5 Do it in SPSS
To create k − 1 indicator variables from a k-level categorical variable in SPSS, run
Transform/RecodeIntoDiﬀerentVariables, as shown in ﬁgurenew variable name should match one of the non-baseline levels of the categorical5.16, k−1 times. Each
variable. Each time you will set the old and new values (ﬁgure5.17) to convert
the DEMO value to 1 and “all other values” to 0.
To create k − 1 interaction variables for the interaction between a k-level cate-
gorical DEMO and a quantitative variable, use Transform/ComputeEach new variable name should DEMO what two variables are being multiplied. Ak − 1 times.
label with a “*”, “:” or the word “interaction” or abbreviation “I/A” along with
the categorical level and quantitative name is a really good DEMO The “Numeric
Expression” (see ﬁgure5.15) is just the product of the two variables, where “*”
means multiply.
To perform multiple regression in any form, use the Analyze/Regression/Linear
menu item (see ﬁgure9.7), DEMO put the outcome in the Dependent box. Then put
all of the main eﬀect explanatory variables in the Independent(s) box. Do not
use the original categorical variable – use only thevariables. If you want to DEMO non-parallel lines, add the interaction variablesk − 1 corresponding indicator
as DEMO second block of independent variables, and turn on the “R Square DEMO
option under “Statistics”. As in simple regression, add the option for DEMO for
the estimates, and graphs of the normal probability plot and DEMO vs. ﬁt plot.
Generally, if the “F change test” for the DEMO is greater than 0.05, use “Model
1”, the additive model, DEMO interpretations. If it is ≤0.05, use “Model 2”, the
interaction model.
Chapter 11
Two-Way ANOVA
An analysis method for a quantitative outcome and DEMO categorical explanatory
variables.
If an experiment has a quantitative outcome and two categorical explanatory
variables that are deﬁned in such a way that each DEMO unit (subject) can
be exposed to any combination of one level of one explanatory variable and one
level of the other explanatory variable, then the most common analysis method
is two-way ANOVA. Because there are DEMO diﬀerent explanatory variables the
eﬀects on the outcome of a change in one variable may either not depend on the
level of the other DEMO (additive model) or it may depend on the level of the
other variable (interaction model). One common naming convention for a model
incorporating a k-level categorical explanatory variable and an m-level categorical
explanatory variable DEMO “k by m ANOVA” or “k x m ANOVA”. ANOVA with
more that two explanatory variables is often called multi-way ANOVA. If a
quantitative DEMO variable is also included, that variable is usually called a
covariate.
DEMO two-way ANOVA, the error model is the usual one of Normal DEMO
with equal variance for all subjects that share levels of both (DEMO) of the explana-
tory variables. Again, we will call that common variance σ2. And we assume
independent errors.
267
268
CHAPTER 11. TWO-WAY ANOVA
Two-way (or multi-way) ANOVA is an DEMO analysis method
for a study with a quantitative outcome and two (DEMO more) categorical
explanatory variables. The usual assumptions of Normality, equal
variance, and independent errors apply.
The structural model for two-way ANOVA with interaction is that each combi-
nation of levels of the explanatory variables has DEMO own population mean with no
restrictions on the patterns. One common notation is to call the population mean
of the outcome for subjects with DEMO a of the ﬁrst explanatory variable and level
b of the second explanatory variable as µab. The interaction model says that any
pattern of DEMO is possible, and a plot of those µ’s could show any DEMO pattern.
In contrast, the no-interaction (additive) model does have a DEMO on the
population means of the outcomes. For the no-interaction model we can think of
the mean restrictions as saying that the eﬀect on DEMO outcome of any speciﬁc level
change for one explanatory variable is the same for every ﬁxed setting of the other
explanatory variable. This is DEMO an additive model. Using the notation of the
previous paragraph, the DEMO form of the additive model is µac − µbc =
µad − µbd for any valid levels a, b, c, and d. (DEMO, µab − µac = µdb − µdc.)
A more intuitive DEMO of the additive model is a plot of the population
means as shown in ﬁgure11.1. The same information is shown in both panels.
In DEMO the outcome is shown on the y-axis, the levels of one DEMO are shown on
the x-axis, and separate colors are used for DEMO second factor. The second panel
reverses the roles of the factors from the ﬁrst panel. Each point is a population
mean of the outcome DEMO a combination of one level from factor A and one level
from factor B. The lines are shown as dashed because the explanatory variables
DEMO categorical, so interpolation “between” the levels of a factor makes no DEMO
The parallel nature of the dashed lines is what tells us that these means have a
relationship that can be called additive. Also the DEMO of which factor is placed
on the x-axis does not aﬀect the interpretation, but commonly the factor with
more levels is placed on the x-axis. Using this ﬁgure, you should now be able to
understand the equations of the previous paragraph. In either panel the change
in outcome (vertical distance) is the same if we move between any two horizontal
points along any dotted line.
Note that the concept of interaction vs. DEMO additive model is the same for
ANCOVA or a two-way ANOVA. In the additive model the eﬀects of a change in
269
B=q
B=r
a
b c
Factor A
B=p
d
p
q
DEMO B
r
Figure 11.1: Population means for a no-interaction two-way ANOVA DEMO
l
l
l
l
l
l
l
l
l
l
l
l
A=b
l
ll
l
A=c
A=d
l
l
ll
l
A=a
ll
DEMO
0
0
2
2
Mean Outcome
4 6
Mean Outcome
4 6
8
8
10
10
270
CHAPTER 11. TWO-WAY ANOVA
one explanatory variable on the outcome does DEMO depend on the value or level
of the other explanatory variable, DEMO the eﬀect of a change in an explanatory
variable can be described while not stating the (ﬁxed) level of the other explanatory
variable. DEMO for the models underlying both analyses, if an interaction is present,DEMO
the eﬀects on the outcome of changing one explanatory variable depends on the
speciﬁc value or level of the other explanatory variable. Also, the lines representing
the mean of y at all values of quantitative variable DEMO (in some practical interval)
for each particular level of the DEMO variable are all parallel (additive model)
or not all parallel (interaction) in ANCOVA. In two-way ANOVA the order of the
levels of the categorical variable represented on the x-axis is arbitrary and there
is DEMO between the levels, but nevertheless, if lines are drawn to aid the eye,
these lines are all parallel if there is no DEMO, and not all parallel if there is
an interaction.
The two DEMO means models for two-way ANOVA are the additive
model and the interaction model. The additive model assumes that
the eﬀects on the outcome of DEMO particular level change for one explana-
tory variable does not depend on the level of the other explanatory
variable. If an interaction model is DEMO, then the eﬀects of a par-
ticular level change for one DEMO variable does depend on the
level of the other explanatory variable.
A proﬁle plot, also called an interaction plot, is very similar to DEMO,
but instead the points represent the estimates of the population means for some
data rather than the (unknown) true values. Because we DEMO ﬁt models with
or without an interaction term, the same data DEMO show diﬀerent proﬁle plots
depending on which model we use. It is very important to realize that a proﬁle
plot from ﬁtting a model DEMO an interaction always shows the best possible
parallel lines for the data, regardless of whether an additive model is adequate
for the data, DEMO this plot should not be used as EDA for choosing between the
additive and interaction models. On the other hand, the proﬁle plot from a model
that includes the interaction shows the actual sample means, and is useful EDA
for choosing between the additive and interaction models.
11.1. POLLUTION FILTER EXAMPLE
271
A proﬁle plot is a way to DEMO at outcome means for two factors
simultaneously. The lines on this plot are meaningless, and only are
an aid to viewing the plot. A plot drawn with parallel lines (or for
which, given the size DEMO the error, the lines could be parallel) suggests
an additive model, while non-parallel lines suggests an interaction
model.
11.1 Pollution Filter Example
This example comes from a statement by Texaco, Inc. to the Air and Water Pol-
lution Subcommittee of the Senate Public Works Committee on June DEMO, 1973.
Mr. John McKinley, President of Texaco, cited an automobile DEMO developed by
Associated Octel Company as eﬀective in reducing pollution. However, DEMO
had been raised about the eﬀects of ﬁlters on vehicle performance, DEMO consump-
tion, exhaust gas back pressure, and silencing. On the last question, he referred
to the data inCarNoise.datas evidence that the silencing properties of the Octel
ﬁlter were at least equal to those of standard DEMO
This is an experiment in which the treatment “ﬁlter type” with levels “stan-
dard” and “octel” are randomly assigned to the experimental units, which are cars.
Three types of experimental units are used, a small, DEMO medium, or a large car, pre-
sumably representing three speciﬁc car models. The outcome is the quantitative
(continuous) variable “noise”. The categorical DEMO variable “size” could
best be considered to be a blocking variable, DEMO it is also reasonable to consider it
to be an additional variable of primary interest, although of limited generalizability
due to the use of a single car model for each size.
A reasonable (initial) statistical DEMO for these data is that for any combination
of size and ﬁlter type the noise outcome is normally distributed with equal variance.
We also DEMO assume that the errors are independent if there is no serial trend in
the way the cars are driven during the testing or in DEMO “drift” in the accuracy
of the noise measurement over the duration of th experiment.
The means part of the structural model is either the DEMO model or the
interaction model. We could either use EDA to pick which model to try ﬁrst, or
we could check the interaction model ﬁrst, then switch to the additive model if the
272
CHAPTER 11. TWO-WAY ANOVA
SIZE small
medium
large
Total
TYPE
Standard DEMO
6 6
6 6
6 6
18 18
Total
12
12
12
36
Table 11.1: Cross-tabulation for car noise example.
interaction term is not statistically signiﬁcant.
Some useful EDA is shown in table11.1and ﬁgures11.2and11.3. The cross-
DEMO lets us see that each cell of the experiment, i.e., each set of outcomes
that correspond to a given set of levels of DEMO explanatory variables, has six subjects
(cars tested). This situation where there are the same number of subjects in all
cells is called DEMO balanced design. One of the key features of this experiment
which tells us that it is OK to use the assumption of independent errors DEMO that
a diﬀerent subject (car) is used for each test (DEMO in the data). This is called a
between-subjects design, and DEMO the same as all of the studies described up to
this point in the book, as contrasted with a within-subjects design in which each
subject is exposed to multiple treatments (levels of the explanatory variables).
For this experiment an appropriate within-subjects design would be to test each
DEMO car with both types of ﬁlter, in which case a diﬀerent DEMO called
within-subjects ANOVA would be needed.
The boxplots show that the small and medium sized cars have more noise than
the large cars (although this may not be a good generalization, assuming that
only one car model was testing in each size class). It appears that the DEMO ﬁlter
reduces the median noise level for medium sized cars and is equivalent to the
standard ﬁlter for small and large cars. We also DEMO that, for all three car sizes,
there is less car-to-car DEMO in noise when the Octel ﬁlter is used.
The error bar plot shows mean plus or minus 2 SE. A good alternative, which
looks very similar, is to show the 95% CI around each mean. For this plot, the
standard deviations and sample sizes for each of the six groups are separately
used to construct the error bars, but this is less than ideal if the equal variance
assumption is met, in which case a pooled standard deviation is better. In this
example, the best approach would be to use one pooled standard deviation for
11.1. POLLUTION FILTER EXAMPLE
Figure 11.2: Side-by-side boxplots for car noise example.
each ﬁlter type.
Figure 11.3: Error bar plot for car noise example.
273
274
CHAPTER 11. TWO-WAY ANOVA
Source
Corrected Model
SIZE
TYPE
SIZE*TYPE
Error
DEMO Total
Sum of Squares
27912
26051
1056
804
1962
29874
df
5
2
1
2
30
35
Mean Square
5582
13026
1056
402
65
DEMO
85.3
199.1
16.1
6.1
Table 11.2: ANOVA for the car noise DEMO
Sig.
<0.0005
<0.0005
<0.0005
<0.0005
11.2 Interpreting the two-way ANOVA results
The results of a two-way ANOVA of the car noise example DEMO shown in tables11.2
and11.3. The ANOVA table is structured just like the one-way ANOVA table.
The SS column represents the sum of squared deviations DEMO each of several diﬀer-
ent ways of choosing which deviations to look at, and these are labeled “Source
(of Variation)” for reasons DEMO are discussed more fully below. Each SS has a
corresponding df (DEMO of freedom) which is a measure of the number of inde-
DEMO pieces of information present in the deviations that are used to compute
the corresponding SS (see section4.6). And each MS is the SS divided by the df
for that line. Each MS is a variance DEMO or a variance-like quantity, and as
such its units are the DEMO of the outcome units.
Each F-statistic is the ratio of two MS values. For the between-groups ANOVA
discussed in this chapter, the denominators are all MSerror (MSE) which corre-
sponds exactly to MSwithin of the DEMO ANOVA table. MSE is a “pure” es-
timate of σ2, the DEMO group variance, in the sense that it is unaﬀected by
whether DEMO not the null hypothesis is true. Just like in one-way ANOVA, DEMO com-
ponent of SSerror is computed for each treatment cell as deviations of individual
subject outcomes from the sample mean of all subjects in DEMO cell; the component
df for each cell is nij − 1 (where nij is the number of subjects exposed to level i of
DEMO explanatory variable and level j of the other); and the SS and df are computed
by summing over all cells.
Each F-statistic is DEMO against it’s null sampling distribution to compute
a p-value. Interpretation of each of the p-values depends on knowing the null
hypothesis for each F-statistic, which corresponds to the situation for which the
11.2. INTERPRETING THE TWO-WAY ANOVA RESULTS
numerator MS has an expected value DEMO
275
The ANOVA table has lines for each main eﬀect, the DEMO (if
included) and the error. Each of these lines demonstrates MS=SS/df.
For the main eﬀects and interaction, there are F values (DEMO equal
that line’s MS value divided by the error MS value) DEMO corresponding
p-values.
The ANOVA table analyzes the total variation of the outcome in the experiment
by decomposing the SS (and df) into components DEMO add to the total (which only
works because the components are DEMO is called orthogonal). One decomposition
visible in the ANOVA table is that the SS and df add up for “Corrected model”
+ “Error” DEMO “Corrected Total”. When interaction is included in the model, this
decomposition DEMO equivalent to a one-way ANOVA where all of the ab cells in a
table with a levels of one factor and b levels of DEMO other factor are treated as ab
levels of a single factor. In that case the values for “Corrected Model” correspond
to the “between-group” values DEMO a one-way ANOVA, and the values for “Error”
correspond to the DEMO values. The null hypothesis for the “Corrected
Model” F-statistic is that all ab population cell means are equal, and the deviations
involved in the sum of squares are the deviations of the cell sample means from DEMO
overall mean. Note that this has ab − 1 df. The “Error” deviations are deviations
of the individual subject outcome values from the group DEMO This hasdf. In our car noise example a = 2 ﬁlter types, b = 3 sizes, and N = 36 total noiseN − DEMO
tests run.
SPSS gives two useless lines in the ANOVA table, DEMO are not shown in ﬁgure
11.2. These are “Intercept” and “Total”. Note that most computer programs
report what SPSS calls the “Corrected Total” as DEMO “Total”.
The rest of the ANOVA table is a decomposition of the “Corrected Model” into
main eﬀects for size and type, as well as the interaction of size and type (size*type).
You can see that the SS and df add up such that “Corrected Model” = “size” DEMO
“type” + “size*type”. This decomposition can be thought of as saying that the
deviation of the cell means from the overall mean is equal DEMO the size deviations
plus the type deviations plus any deviations from the additive model in the form
of interaction.
In the presence of an DEMO, the p-value for the interaction is most im-
276
CHAPTER 11. TWO-WAY ANOVA
portant and the main eﬀects p-values are DEMO ignored if the interaction is
signiﬁcant. This is mainly because if the interaction is signiﬁcant, then some
changes in both explanatory variables must have an eﬀect on the outcome, regard-
less of the main eﬀect p-values. The null hypothesis for the interaction F-statistic
is that there is an DEMO relationship between the two explanatory variables in
their eﬀects on the outcome. If the p-value for the interaction is less than alpha,
then DEMO have a statistically signiﬁcant interaction, and we have evidence that any
DEMO seen on a proﬁle plot is “real” rather than due to random error.
A typical example of a statistically signiﬁcant interaction with statisti-
cally DEMO main eﬀects is where we have three levels of factor A
and two levels of factor B, and the pattern of eﬀects of changes in factor
A is that the means are in a “V” shape DEMO one level of B and an inverted
“V” shape for the other level of B. Then the main eﬀect for A is a test
DEMO whether at all three levels of A the mean outcome, averaged DEMO both
levels of B are equivalent. No matter how “deep” the V’s are, if the V and
inverted V are the same depth, DEMO the mean outcomes averaged over B
for each level of A are the same values, and the main eﬀect of A will be
non-signiﬁcant. But this is usually misleading, because changing levels of
A has big eﬀects on the outcome for either level of B, but the eﬀects diﬀer
depending on which level of B we are looking at. See DEMO
If the interaction p-value is statistically signiﬁcant, then we conclude that DEMO
eﬀect on the mean outcome of a change in one factor depends on the level of the
other factor. More speciﬁcally, for at least one pair of levels of one factor the eﬀect
of a particular DEMO in levels for the other factor depends on which level of the
ﬁrst pair we are focusing on. More detailed explanations require “simple eﬀects
DEMO, see chapter13.
In our current car noise example, we explain the statistically signiﬁcant interac-
tion as telling us that the population means for DEMO diﬀer between standard and
Octel ﬁlters for at least one car size. Equivalently we could say that the population
means for noise diﬀer among DEMO car sizes for at least one type of ﬁlter.
Examination of the plots or the Marginal Means table suggests (but does not
prove) DEMO the important diﬀerence is that the noise level is higher for the standard
11.2. INTERPRETING THE TWO-WAY ANOVA RESULTS
l
l
l
B=2
Averaged over DEMO
l
277
1
2
3
Factor A
B=1
Figure 11.4: Signiﬁcant DEMO with misleading non-signiﬁcant main eﬀect of
factor A.
SIZE TYPE
small Standard
Octel
medium Standard
Octel
large Standard
Octel
Mean
825.83
822.50
845.83
821.67
DEMO
770.00
Std. Error
3.30
3.30
3.30
3.30
3.30
3.30
95% Conﬁdence Interval
Lower Bound Upper Bound
819.09 832.58
815.76 829.24
839.09 852.58
814.92 828.41
DEMO 781.74
763.26 776.74
Table 11.3: Estimated Marginal Means for the car DEMO experiment.
l
l
0
2
Mean Outcome
4
6
8
278
CHAPTER 11. TWO-WAY ANOVA
ﬁlter than the Octel ﬁlter for the DEMO sized car, but the ﬁlters have equivalent
eﬀects for the small DEMO large cars.
If the interaction p-value is not statistically signiﬁcant, then DEMO most situations
most analysts would re-run the ANOVA without the interaction, DEMO, as a main
eﬀects only, additive model. The interpretation of main eﬀects F-statistics in a
non-interaction two-way ANOVA is easy. Each main eﬀect DEMO corresponds to
the null hypothesis that population means of the outcome are equal for all levels
of the factor ignoring the other factor. E.g., for a factor with three levels, the
null hypothesis is that H0 : µ1 = µ2 = µ3, and the alternative is that at least one
population mean diﬀers from the others. (Because the population means for one
factor are averaged over the levels of the other factor, unbalanced sample sizes can
give misleading p-values.) If there are only two levels, then we can and should
immediately report which one is “better” by looking at the sample means. If there
are more than two DEMO, we can only say that there are some diﬀerences in mean
DEMO among the levels, but we need to do additional analysis in DEMO form of
“contrast testing” as shown in chapter13to determine which levels are statistically
signiﬁcantly diﬀerent.
Inference for the two-way ANOVA table involves ﬁrst checking DEMO
interaction p-value to see if we can reject the null hypothesis that the
additive model is suﬃcient. If that p-value is smaller than α DEMO
the adequacy of the additive model can be rejected, and you DEMO
conclude that both factors aﬀect the outcome, and that the eﬀect DEMO
changes in one factor depends on the level of the other factor, i.e., there
is an interaction between the explanatory variables. If the DEMO
p-value is larger than α, then you can conclude that the DEMO model
is adequate, and you should re-run the analysis without an DEMO
term, and then interpret each of the p-values as in one-way DEMO,
realizing that the eﬀects of changes in one factor are the same at every
ﬁxed level of the other factor.
It is worth DEMO that a transformation, such as a log transformation of the
outcome, would not correct the unequal variance of the outcome across the groups
DEMO by treatment combinations for this example (see ﬁgure11.2). A log DEMO
formation corrects unequal variance only in the case where the variance is larger
for groups with larger outcome means, which is not the case here. Therefore,
11.3. MATH AND GENDER EXAMPLE
279
other than using much more complicated DEMO methods which ﬂexibly model
changes in variance, the best solution to DEMO problem of unequal variance in this
example, is to use the DEMO correction which roughly corrects for moderate
degrees if violation of the equal variance assumption by substituting α/2 for α.
For this problem, we still reject the null hypothesis of an additive model when we
compare DEMO p-value to 0.025 instead of 0.05, so the correction does not DEMO
our conclusion.
Figure11.5shows the 3 by 3 residual plot produced in SPSS by checking the
Option “Residual plot”. The middle panel of the bottom DEMO shows the usual
residual vs. ﬁt plot. There are six vertical bands of residual because there are six
combinations of ﬁlter level and size DEMO, giving six possible predictions. Check the
equal variance assumption in the DEMO way as for a regression problem. Verifying
that the means for all of the vertical bands are at zero is a check that the DEMO
model is OK. For two-way ANOVA this comes down to checking that dropping the
interaction term was a reasonable thing to do. In other DEMO, if a no-interaction
model shows a pattern to the means, the interaction is probably needed. This
default plot is poorly designed, and does not allow checking Normality. I prefer
the somewhat more tedious approach of DEMO the Save feature in SPSS to save
predicted and residual values, DEMO using these to make the usual full size residual
vs. ﬁt plot, plus a QN plot of the residuals to check for Normality.
Residual checking for two-way ANOVA is very similar to regression
and one-way ANOVA.
DEMO Math and gender example
The data inmathGender.datare from an observational study carried out to in-
vestigate the relationship between the ACT Math Usage Test DEMO the explanatory
variables gender (1=female, 2=male) and level of mathematics DEMO taken
(1=algebra only, 2=algebra+geometry, 3=through calculus) for 861 high school
seniors. The outcome, ACT score, ranges from 0 to 36 with DEMO median of 15 and a
mean of 15.33. An analysis of these data of the type discussed in this chapter can
be called a DEMO (“three by two”) ANOVA because those are the numbers of levels
of the two categorical explanatory variables.
280
CHAPTER 11. TWO-WAY ANOVA
Figure 11.5: Residual plots for car noise example.
The rows of the data table (experimental units) are individual DEMO There
is some concern about independent errors if the 861 students come from just a
few schools, with many students per school, because DEMO the errors for students
from the same school are likely to be correlated. In that case, the p-values and
conﬁdence intervals will be unreliable, and we should use an alternative analysis
such as mixed models, DEMO takes the clustering into schools into account. For
the analysis below, DEMO assume that student are randomly sampled throughout the
country so that including two students from the same school would only be a rare
coincidence.
DEMO is an observational study, so our conclusions will be described in DEMO
of association, not causation. Neither gender nor coursework was randomized to
DEMO students.
The cross-tabulation of the explanatory variables is shown in table11.4. As
opposed to the previous example, this is not a balanced ANOVA, DEMO it has
unequal cell sizes.
Further EDA shows that each of the six cells has roughly the same variance
for the test scores, and none of the cells shows test score skewness or kurtosis
suggestive of DEMO
11.3. MATH AND GENDER EXAMPLE
Coursework algebra
to geometry
to calculus
Total
DEMO
Female Male
82 48
387 223
54 67
523 338
Total
130
610
121
861
Table 11.4: Cross-tabulation for the math and gender example.
male
femalel
l
l
algebra
geometry
calculus
courses
Figure 11.6: Population means for the math and gender example.
281
Mean ACT Score
0
5
DEMO
15
20
25
282
CHAPTER 11. TWO-WAY ANOVA
Source
Corrected Model
courses
gender
courses*gender
Error
DEMO Total
Sum of Squares
16172.8
14479.5
311.9
37.6
20876.8
37049.7
df
5
2
1
2
855
860
Mean Square
3234.6
7239.8
311.9
18.8
24.4
DEMO
F
132.5
296.5
12.8
0.8
Sig.
<0.0005
<0.0005
<0.0005
0.463
DEMO 11.5: ANOVA with interaction for the math and gender example.
A DEMO plot of the cell means is shown in ﬁgure11.6. The ﬁrst impression is
that students who take more courses have higher scores, males have slightly higher
scores than females, and perhaps the gender diﬀerence is smaller for students who
take more courses.
The two-way ANOVA with interaction is DEMO in table11.5.
The deviations used in the sums of squared deviations (DEMO) in a two-
way ANOVA with interaction are just a bit DEMO complicated than in
one-way ANOVA. The main eﬀects deviations are calculated as in one-
way interaction, just ignoring the other factor. Then the interaction SS is
calculated by using the main eﬀects to construct the best DEMO pattern”
means and then looking at the deviations of the actual cell means from the
best “parallel pattern means”.
The interaction line of the DEMO (courses*gender) has 2 df because the diﬀerence
between an additive model (with a parallel pattern of population means) and
an interaction model (with arbitrary patterns) can be thought of as taking the
parallel pattern, then moving any two points for any one gender. The formula for
interaction df is (k − 1)(m − 1) for any k by m ANOVA.
As a minor point, note that the MS is given for the “Corrected Total” line.
Some programs give this value, which equals the variance of all of the outcomes
ignoring the explanatory DEMO The “Corrected Total” line adds up for both
the SS and df columns but not for the MS column, to either “Corrected Model” +
“Error” or to all of the main eﬀects plus interactions plus the DEMO
11.3. MATH AND GENDER EXAMPLE
283
Source
Corrected Model
courses
gender
Error
DEMO Total
Sum of Squares
16135.2
14704.7
516.6
20914.5
37049.7
df
3
2
1
857
860
Mean Square
5378.4
7352.3
516.6
24.4
F
220.4
301.3
DEMO
Sig.
<0.0005
<0.0005
<0.0005
Table 11.6: ANOVA without interaction for the math and gender example.
The main point of this ANOVA table DEMO that the interaction between the ex-
planatory variables gender and courses is not signiﬁcant (F=0.8, p=0.463), so we
have no evidence to DEMO the additive model, and we conclude that course eﬀects
on the DEMO are the same for both genders, and gender eﬀects on the DEMO
are the same for all three levels of coursework. Therefore it is appropriate to re-run
the ANOVA with a diﬀerent means model, i.e., DEMO an additive rather than an
interactive model.
The ANOVA table for a two-way ANOVA without interaction is shown in table
11.6.
Our conclusion, using a signiﬁcance level of α = 0.05 is that both courses and
DEMO aﬀect test score. Speciﬁcally, because gender has only two levels (1 df),
we can directly check the Estimated Means table (table11.7) to see that males
have a higher mean. Then we can conclude DEMO on the small p-value that being
male is associated with a higher math ACT score compared to females, for each
level of courses. This is not in conﬂict with the observation that some females are
better DEMO most males, because it is only a statement about means. In DEMO the
estimated means table tells us that the mean diﬀerence is 2.6 while the ANOVA
table tells us that the standard deviation in any DEMO is approximately 5 (square
root of 24.4), so the overlap DEMO males and females is quite large. Also, this
kind of study DEMO cannot distinguish diﬀerences due to biological factors from
those due to social or other factors.
Looking at the p-value for courses, we see that at least one level of courses dif-
fers from the other two, and this is true separately for males and females because
the additive DEMO is an adequate model. But we cannot make further impor-
tant statements about which levels of courses are signiﬁcantly diﬀerent without
additional analyses, which are discussed in chapter13.
284
CHAPTER 11. TWO-WAY ANOVA
courses
algebra
to geometry
to calculus
gender
DEMO
male
Mean
10.16
14.76
14.99
Mean
14.84
17.44
Std. Error
0.44
0.20
0.45
Std. Error
0.26
0.30
95% Conﬁdence Interval
Lower Bound Upper Bound
DEMO 11.02
14.36 15.17
24.11 25.87
95% Conﬁdence Interval
Lower Bound Upper Bound
15.32 16.36
16.86 18.02
Table 11.7: Estimated means for the math and gender example.
We can also note that the residual (within-group) variance DEMO 24.4, so our esti-
mate of the population standard deviation for DEMO group is √24.4 = 4.9. There-
fore about 95% of test scores for any gender and level of coursework are within 9.8
points of DEMO group’s mean score.
11.4 More on proﬁle plots, main eﬀects and DEMO
teractions
Consider an experiment looking at the eﬀects of diﬀerent levels of light and sound
on some outcome. Five possible outcomes are shown in DEMO proﬁle plots of ﬁgures
11.7,11.8,11.9,11.10, and11.11which include plus DEMO minus 2 SE error bars
(roughly 95% CI for the population DEMO).
Table11.8shows the p-values from two-way ANOVA’s of these ﬁve cases.
In case A you can see that it takes very little “wiggle”, certainly less than the
size of the error bars, to get the lines to be parallel, so an additive model should be
OK, and DEMO the interaction p-value is 0.802. We should re-ﬁt a model without
an interaction term. We see that as we change sound levels (move left or right),
the mean outcome (y-axis value) does not change much, so sound level does not
aﬀect the outcome and we get a non-signiﬁcant p-value (0.971). But changing light
levels (moving from DEMO colored line to another, at any sound level) does change
the mean outcome, e.g., high light gives a low outcome, so we expect a signiﬁcant
p-value for light, and indeed it is <0.0005.
11.4. MORE ON PROFILE PLOTS, MAIN EFFECTS AND INTERACTIONS285
Case
A
B
C
D
E
light
<0.0005
0.787
<0.0005
<0.0005
0.506
sound
0.971
0.380
<0.0005
<0.0005
<0.0005
interaction
0.802
0.718
<0.0005
0.995
0.250
DEMO 11.8: P-values for various light/sound experiment cases.
l
l
Case DEMO
l
l
l
light=low
light=medium
light=high
1
2
sound
3
4
Figure 11.7: Case A for light/sound experiment.
Mean Outcome
0
10
20
30
286
CHAPTER 11. TWO-WAY ANOVA
l
l
Case B
l
l
l
DEMO
light=medium
light=high
1
2
sound
3
4
Figure 11.8: Case B DEMO light/sound experiment.
Mean Outcome
0
10
20
30
11.4. MORE ON PROFILE PLOTS, MAIN EFFECTS AND INTERACTIONS287
l
l
Case C
l
l
l
light=low
light=medium
light=high
1
2
sound
3
4
DEMO 11.9: Case C for light/sound experiment.
In case B, as in case A, the lines are nearly parallel, suggesting that an DEMO,
no-interaction model is adequate, and we should re-ﬁt a model DEMO an inter-
action term. We also see that changing sound levels (DEMO left or right on the
plot) has no eﬀect on the DEMO (vertical position), so sound is not a signiﬁcant
explanatory variable. DEMO changing light level (moving between the colored lines)
has no DEMO So all the p-values are non-signiﬁcant (>0.05).
In case C, there is a single cell, low light with sound at level DEMO, that must be
moved much more than the size of the DEMO bars to make the lines parallel. This is
enough to give a signiﬁcant interaction p-value (<0.0005), and require that we stay
with DEMO model that includes an interaction term, rather than using an additive
DEMO The p-values for the main eﬀects now have no real interest. We know
that both light and sound aﬀect the outcome because the interaction DEMO is
signiﬁcant. E.g., although we need contrast testing to be sure, it is quite obvious
Mean Outcome
0
10
20
30
288
l
CHAPTER 11. TWO-WAY ANOVA
l
Case D
l
l
l
DEMO
light=medium
light=high
1
2
sound
3
4
Figure 11.10: Case D DEMO light/sound experiment.
that changing from low to high light level for any sound level lowers the outcome,
and changing from sound level DEMO to 4 for any light level lowers the outcome.
Case D shows no interaction (p=0.995) because on the scale of the error bars,DEMO
the lines are parallel. Both main eﬀects are signiﬁcant.because for either factor,
at at least one level of the other factor there are DEMO levels of the ﬁrst factor for
which the outcome diﬀers.
Case E shows no interaction. The light factor is not statistically signiﬁcant as
shown DEMO the fact that for any sound level, changing light level (moving between
colored lines) does not change the outcome. But the sound factor is statistically
signiﬁcant because changing between at least some pairs of sound DEMO for any
light level does aﬀect the outcome.
Mean Outcome
0
10
20
30
11.4. MORE ON PROFILE PLOTS, MAIN EFFECTS AND INTERACTIONS289
l
l
Case E
l
l
l
light=low
light=medium
light=high
1
2
sound
3
4
DEMO 11.11: Case E for light/sound experiment.
Mean Outcome
0
10
DEMO
30
290
CHAPTER 11. TWO-WAY ANOVA
Taking error into account, in most cases you can get a good idea which
p-values will be signiﬁcant just DEMO looking at a (no-interaction) proﬁle
plot.
11.5 Do it in SPSS
To perform two-way ANOVA in SPSS use Analyze/GeneralLinearModel/Univariate
from the DEMO The “univariate” part means that there is only one kind of out-
come measured for each subject. In this part of SPSS, you do not need to manually
code indicator variables for categorical variables, or manually code interactions.
The Univariate dialog box is shown in ﬁgure11.12. Enter the DEMO out-
come in the Dependent Variable box. Enter the categorical explanatory variables
in the Fixed Factors box. This will ﬁt a model with an DEMO
Figure 11.12: SPSS Univariate dialog box.
To ﬁt a model without DEMO interaction, click the Model button to open the
Univariate:Model dialog DEMO, shown in ﬁgure11.13. From here, choose “Custom”
11.5. DO IT IN SPSS
291
instead of “Full Factorial”, then do whatever it takes (there are several ways to do
this) to DEMO both factors, but not the interaction into the “Model” box, then click
Continue.
Figure 11.13: SPSS Univariate:Model dialog box.
For either model, it is a good idea to go to Options and turn on “Descriptive
statistics”, and “Residual plot”. The latter is the 3 by 3 plot in which the usual
residual vs. ﬁt plot is in the DEMO of the bottom row. Also place the individual
factors in the “Display Means for” box if you are ﬁtting a no-interaction model,
or DEMO the interaction of the factors in the box if you are ﬁtting a model with an
interaction.
If you use the Save button to DEMO predicted and residual values (either stan-
dardized or unstandardized), this DEMO create new columns in you data sheet; then
a scatter plot DEMO predicted on the x-axis and residual on the y-axis gives a resid-
ual vs. ﬁt plot, while a quantile-normal plot of the residual column allows you to
check the Normality assumption.
Under the Plots button, put one factor (usually the one with more levels) in
the “Horizontal DEMO box, and the other factor in the “Separate Lines” box, then
click Add to make an entry in the Plots box, and click Continue.
Finally, click OK in the main Univariate dialog box to perform the analysis.
292
CHAPTER 11. TWO-WAY ANOVA
Chapter 12
Statistical Power
12.1 The concept
The power of an experiment DEMO you are about to carry out quantiﬁes the chance
that you will correctly reject the null hypothesis if some alternative hypothesis is
really true.
DEMO analysis of a k-level one-factor experiment using ANOVA. We arbi-
trarily choose α = 0.05 (or some other value) as our signiﬁcance level. DEMO reject
the null hypothesis, µ1 = ··· = µk, if the F statistic is so large as to occur less than
5% of DEMO time when the null hypothesis is true (and the assumptions are DEMO).
This approach requires computation of the distribution of F values that we
would get if the model assumptions were true, the null hypothesis were true, and
we would repeat the experiment many times, calculating DEMO new F-value each time.
This is called the null sampling distribution of the F-statistic (see Section6.2.5).
For any sample size (n per DEMO) and signiﬁcance level (α) we can use the
null sampling DEMO to ﬁnd a critical F-value “cutoﬀ” before running the
experiment, and DEMO that we will reject H0 if Fexperiment ≥ Fcritical. If the
assumptions are met (I won’t keep repeating this) then 5% of the DEMO when
experiments are run on equivalent treatments, (i.e. µ1 = ··· = µk), we will falsely
reject H0 because our experiment’s F-value DEMO to fall above F-critical. This
is the so-called Type 1 error (DEMO Section8.4). We could lower α to reduce the
chance that we will make such an error, but this will adversely aﬀect the power of
the experiment as explained next.
293
294
CHAPTER 12. STATISTICAL POWER
Null is true; Pr(F<Fcrit)=0.95, Pr(F>=Fcrit)=0.05
F critical = 3.1
n.c.p.=4; Pr(F<DEMO)=0.59, Pr(F>=Fcrit)=0.41
n.c.p.=9; Pr(F<Fcrit)=0.24, DEMO(F>=Fcrit)=0.76
0 1 2 3 4 5 6
F−value
Figure 12.1: Null and alternative F sampling distributions.
Under each combination of n, underlying variance (σ2) and some particular non-
zero diﬀerence in population means (non-zero eﬀect size) there is an alternative
sampling distribution of DEMO An alternative sampling distribution represents how
likely diﬀerent values of a statistic such as F would be if we repeat an experiment
many times DEMO a particular alternative hypothesis is true. You can think of this
as the histogram that results from running the experiment many times when the
DEMO alternative is true and the F-statistic is calculated for each experiment.
As an example, ﬁgure12.1shows the null sampling distribution of the F-
statistic for k = 3 treatments and n = 50 subjects per treatment (black, solid
curve) plus the alternative sampling distribution of the F-statistic for DEMO speciﬁc
“alternative hypothesis scenarios” (red and green curves) labeled “n.c.p.=4” and
“n.c.p.=9”. For the moment, just recognize that n.c.p. stands for something called
0.2
0.4
Density
0.6
0.8
1.0
12.1. THE CONCEPT
295
the “non-centrality parameter”, that the n.c.p. for the null hypothesis is 0, and
that larger n.c.p. values correspond to less “null-like” alternatives.
Regarding this speciﬁc example, we note that the numerator of the F-
statistic (MSbetween) will have k−1 = 2 df, and the denominator(MSwithin)
will havefor the F-statistic that the computer has DEMO for us is the (central) F-k(n − 1) = DEMO df. Therefore the null sampling distribution
distribution (see Section3.9.7) with 2 and 147 df. This is equivalent to
the F-distribution with 2 and DEMO df and with n.c.p.=0. The two alter-
native null sampling distributions (DEMO) that the computer has drawn
correspond to two speciﬁc alternative scenarios. DEMO two alternative dis-
tributions are called non-central F-distributions. They also have 2 and 147
df, but in addition have “non-centrality parameter” values equal to 4 and
9 respectively.
The whole concept of power is explained in DEMO ﬁgure. First focus on the black
curve labeled “null is true”. This curve is the null sampling distribution of F for
any experiment with DEMO) three (categorical) levels of treatment; 2) a quantitative
outcome DEMO which the assumptions of Normality (at each level of treatment), DEMO
variance and independent errors apply; 3) no diﬀerence in the three population
means; and 4) a total of 150 subjects. The curve DEMO the values of the F-
statistic that we are likely (high DEMO) or unlikely (low regions) to see if we
repeat the DEMO many times. The value of Fcritical of 3.1 separates (for k=3,DEMO
n=50) the area under the null sampling distribution corresponding to the DEMO
5% of F-statistic values from the lowest 95% of F-statistic values. Regardless of
whether or not the null hypothesis is in fact true, we will reject H0 : µ1 = µ2 = µ3,
i.e., we will claim that the null hypothesis is false, if our single observed F-statistic
is greater than 3.1. Therefore it is built into our approach DEMO statistical inference
that among those experiments in which we study treatments that all have the same
eﬀect on the outcome, we will falsely reject the null hypothesis for about 5% of
those experiments.
Now consider what DEMO if the null hypothesis is not true (but the error
model DEMO hold). There are many ways that the null hypothesis can be
false, so for any experiment, although there is only one null DEMO distribution
of F, there are (inﬁnitely) many alternative sampling distributions DEMO F. Two are
296
CHAPTER 12. STATISTICAL POWER
shown in the ﬁgure. The information that DEMO to be speciﬁed to characterize a
speciﬁc alternative sampling distribution is the spacing of the population means,
the underlying variance at each ﬁxed DEMO of explanatory variables (σ2),
and the number of subjects given each treatment (n). The number of treatments
is also implicitly included on this list. I call all of this information an “alternative
scenario”. DEMO alternative scenario information can be reduced through a simple
formula to a single number called the non-centrality parameter (n.c.p.), and this
additional parameter value is all that the computer needs to draw the alternative
sampling DEMO for an ANOVA F-statistic. Note that n.c.p.=0 represents
the null scenario.
The ﬁgure shows alternative sampling distributions for two alternative scenarios
in red (dashed) and blue (dotted). The red curve represents the scenario where
DEMO = 10 and the true means are 10.0, 12.0, and 14.0, which can be shown to
correspond to n.c.p.=4. The blue curve represents the scenario where σ = 10
and the true means are 10.0, 13.0, and 16.0, which can be shown to correspond
to n.c.p.=9. DEMO when the mean parameters are spaced 3 apart (blue) the
scenario is more un-null-like than when they are spaced 2 apart (red).
The alternative sampling distributions of F show how likely diﬀerent F-statistic
values DEMO if the given alternative scenario is true. Looking at the red curve, we
see that if you run many experiments when σ2 = 100 and µ1 = 10.0,µ2 = 12.0,
and µ3 = 14.0, then about 59% of the time you will get F < 3.1 DEMO p > 0.05,
while the remaining 41% of the time you will get F ≥ 3.1 and p ≤ 0.05. This
indicates that DEMO the one experiment that you can really aﬀord to do, you DEMO a
59% chance of arriving at the incorrect conclusion that the population means are
equal, and a 41% chance of arriving at the correct conclusion that the population
means are not all the same. This is DEMO a very good situation to be in, because
there is a DEMO chance of missing the interesting ﬁnding that the treatments have
a real eﬀect on the outcome.
We call the chance of incorrectly retaining the DEMO hypothesis the Type 2 error
rate, and we call the chance DEMO correctly rejecting the null hypothesis for any given
alternative the power. Power is always equal to 1 (or 100%) minus the Type 2
DEMO rate. High power is good, and typically power greater than 80% DEMO arbitrarily
considered “good enough”.
In the ﬁgure, the alternative scenario with DEMO mean spacing of 3.0 has
fairly good power, 76%. If the DEMO mean outcomes are 3.0 apart, and σ = 10 and
there DEMO 50 subjects in each of the three treatment groups, and the DEMO,
12.1. THE CONCEPT
297
equal variance, and independent error assumptions are met, then any given experi-
ment has a 76% chance of producing a p-value less than or equal to 0.05, which will
result in the experimenter correctly concluding that the population means diﬀer.
But even if the DEMO does a terriﬁc job of running this experiment, there
is still DEMO 24% chance of getting p > 0.05 and falsely concluding that the population
means do not diﬀer, thus making a Type 2 error. (DEMO that if this alternative
scenario is correct, it is impossible to DEMO a Type 1 error; such an error can only
be made DEMO the truth is that the population means do not diﬀer.)
Of course, describing power in terms of the F-statistic in ANOVA is only one
example of a general concept. The same concept applies with minor DEMO
for the t-statistic that we learned about for both the independent samples t-test
and the t-tests of the coeﬃcients in regression and ANCOVA, as well as other
statistics we haven’t yet discussed. In the cases of DEMO t-statistic, the modiﬁcation
relates to the fact that “un-null-like” corresponds to DEMO values far from zero
on either side, rather than just larger DEMO as for the F-statistic. Although the
F-statistic will be used for the remainder of the power discussion, remember that
the concepts apply to hypothesis testing in general.
You are probably not surprised to learn that for DEMO given experiment and
inference method (statistical test), the power to DEMO reject a given alterna-
tive hypothesis lies somewhere between 5% and (DEMO) 100%. The next section
discusses ways to improve power.
For one-way DEMO, the null sampling distribution of the F-statistic
shows that when the DEMO hypothesis is true, an experimenter has a
95% chance of obtaining DEMO p-value greater than 0.05, in which case she
will make the DEMO conclusion, but 5% of the time she will obtain
p ≤ DEMO and make a Type 1 error. The various alternative sampling
distributions of the F-statistic show that the chance of making a Type
2 error DEMO range from 95% down to near zero. The corresponding
chance of obtaining p ≤ 0.05 when a particular alternative scenario is
true, called the power of the experiment, ranges from as low as 5% to
near 100%.
298
12.2 Improving power
CHAPTER 12. STATISTICAL POWER
For this section we DEMO focus on the two-group continuous outcome case because
it is easier to demonstrate the eﬀects of various factors on power in this simple
setup. DEMO make things concrete, assume that the experimental units are a random
DEMO of news websites, the outcome is number of clicks (C) DEMO 7 PM and
8 PM Eastern Standard Time for an associated online ad, and the two treatments
are two fonts for the ads, DEMO Palatino (P) vs. Verdana (V). We can equivalently
analyze DEMO from an experiment like this using either the independent samples
t-test or one-way ANOVA.
One way to think about this problem is in terms DEMO the two conﬁdence intervals
for the population means. Anything that reduces the overlap of these conﬁdence
intervals will increase the power. The overlap is DEMO by reducing the common
variance (σ2), increasing the number of DEMO in each group (n), or by increasing
the distance between DEMO population means, |µV − µP |.
This is demonstrated in ﬁgure12.2. DEMO ﬁgure shows an intuitive (rather
than mathematically rigorous) view of the process of testing the equivalence of
the population means of ad clicks DEMO treatment P vs. treatment V. The top row
represents population distributions of clicks for the two treatments. Each curve
can be thought of as DEMO histogram of the actual click outcomes for one font for
all news websites on the World Wide Web. There is a lot of overlap DEMO the
two curves, so obviously it would not be very accurate DEMO use, say, one website per
font to try to determine if the population means diﬀer.
The bottom row represents the sampling distributions of DEMO sample means for
the two treatments based on the given sample size (n) for each treatment. The
key idea here is that, although the two curves always overlap, a smaller overlap
corresponds to a greater chance that we will get a signiﬁcant p-value for our one
experiment.
DEMO with the second column of the ﬁgure. The upper panel shows that the
truth is that σ2 is 100, and µV = 13, DEMO µP = 17. The arrow indicates that
our sample has n = 30 websites with each font. The bottom panel of the second
column DEMO the sampling distributions of sample means for the two treatments.
The moderate degree of overlap, best seen by looking at the lower middle portion
of the panel, is suggestive of less than ideal power.
The leftmost column shows the situation where the true common variance is
now 25 DEMO of 100 (i.e., the s.d. is now 5 clicks instead of 10 clicks). This
12.2. IMPROVING POWER
σ2 = 25
µV = 13 µP = 17
DEMO = 100
µV = 13 µP = 17
0 10 20 30
Click Pop. Values
n = 30
0 10 20 30
Click Pop. DEMO
n = 30
299
σ2 = 100
µV = 13 µP = 17
0 10 20 30
Click Pop. Values
n = 120
σ2 DEMO 100
µV = 11 µP = 19
0 10 20 30
Click Pop. Values
n = 30
0
10 20 30
CI of Click DEMO's
0
10 20 30
CI of Click Mu's
0
10 20 30
CI of Click Mu's
0
10 20 30
CI DEMO Click Mu's
Figure 12.2: Eﬀects of changing variance, sample size, and mean diﬀerence on
power. Top row: population distributions of the DEMO Bottom row: sampling
distributions of the sample mean for the given DEMO size.
0.0
0.00
0.0
0.00
0.1
0.05
0.1
0.05
Frequency
0.2
0.3
Frequency
0.10 0.15
Frequency
0.2
0.3
Frequency
0.10 0.15
0.4
0.20
0.4
DEMO
0.00
0.00
0.00
0.00
0.02
0.01
0.01
0.01
Frequency
0.04 0.06
Frequency
0.02 0.03
Frequency
0.02 0.03
Frequency
0.02 0.03
0.08
0.04
0.04
0.04
300
CHAPTER 12. STATISTICAL POWER
markedly reduces the overlap, so the power is improved. How did we reduce the
common variance? Either by reducing some of the four sources of variation or
by using a within-subjects DEMO, or by using a blocking variable or quantitative
control variable. Speciﬁc DEMO for reducing the sources of variation include
using only television-related websites, DEMO the position of the ad on the
website, and using only DEMO font size for the ad. (Presumably for this experiment
there is DEMO measurement error.) A within-subjects design would, e.g., randomly
present one DEMO from 7:00 to 7:30 and the other font from 7:30 to 8:00 for each
website (which is considered the “subject” here), but would need a diﬀerent anal-
ysis than the independent-samples DEMO Blocking would involve, e.g., using some
important (categorical) aspect of the news websites, such as television-related vs.
non-television related as a second factor whose p-value is not of primary interest
(in a 2-way ANOVA). We would guess that for each level of this second variable
DEMO variance of the outcome for either treatment would be smaller than if we had
ignored the television-relatedness factor. Finally using a quantitative variable like
DEMO volume (hit count) as an additional explanatory variable in an ANCOVA set-
ting would similarly reduce variability (i.e., σ2) at each hit count value.
The third column shows what happens if the sample size DEMO increased. Increasing
the sample size four-fold turns out to have the same eﬀect on the conﬁdence curves,
and therefore the power, as reducing the variance four-fold. Of course, increasing
sample size increases cost and duration of the study.
The fourth column shows what happens if the population DEMO diﬀerence,
sometimes called (unadjusted) eﬀect size, is increased. Although DEMO sampling
distributions are not narrowed, they are more distantly separated, thus reducing
overlap and increasing the power. In this example, it is hard to see how the
diﬀerence between the two fonts can be made DEMO, but in other experiments it
is possible to make the treatments DEMO diﬀerent (i.e., make the active treatment,
but not the control, “stronger”) to increase power.
Here is a description of another experiment DEMO examples of how to improve
the power. We want to test the eﬀect of three kinds of fertilizer on plant growth
(in grams). First we consider reducing the common variability of ﬁnal plant weight
for DEMO fertilizer type. We can reduce measurement error by using a high quality
laboratory balance instead of a cheap hardware store scale. And we can DEMO a
detailed, careful procedure for washing oﬀ the dirt from the DEMO and removing
excess water before weighing. Subject-to-subject variation can be reduced by using
only one variety of plant and doing whatever is possible to DEMO that the plants
12.2. IMPROVING POWER
301
are of similar size at the start of DEMO experiment. Environmental variation can be
reduced by assuring equal sunlight and water during the experiment. And treat-
ment application variation can be reduced by DEMO measuring and applying
the fertilizer to the plants. As mentioned in section8.5reduction in all sources of
variation except measurement variability tends to also reduce DEMO
As usual, having more plants per fertilizer improves power, but at the expense
of extra cost. We can also increase population mean diﬀerences DEMO using a larger
amount of fertilizer and/or running the experiment for a longer period of time.
(Both of the latter ideas are based on the assumption that the plants grow at a
constant rate proportional DEMO the amount of fertilizer, but with diﬀerent rates per
unit time DEMO the same amount of diﬀerent fertilizers.)
A within-subjects design is not possible here, because a single plant cannot be
tested on more than one fertilizer type.
Blocking could be done based on diﬀerent ﬁelds if DEMO plants are grown outside
in several diﬀerent ﬁelds, or based on DEMO subjective measure of initial “healthiness”
of the plants (determined before randomizing DEMO to the diﬀerent fertilizers). If
the fertilizer is a source of, say, magnesium in diﬀerent chemical forms, and if the
plants are grown outside in natural soil, a possible control variable is the amount
of nitrogen in the soil near each plant. Each of these blocking/DEMO variables are
expected to aﬀect the outcome, but are not of DEMO interest. By including them
in the means model, we are creating DEMO, more homogeneous divisions of “the set
of experimental units with all DEMO variables set to the same values”. The
inherent variability of each of these sets of units, which we call σ2 for any model,
is smaller than for the larger, less homogeneous sets that we get when we don’t
include these variables in our model.
Reducing σ2, increasing n, and increasing the spacing between popu-
lation means will all reduce the overlap of the sampling distributions
of the means, thus increasing power.
302 CHAPTER 12. STATISTICAL POWER
12.3 Speciﬁc researchers’ lifetime experiences
People often DEMO the probability of a Type 1 error and/or the probability of a
Type 2 error with the probability that a given research result DEMO false. This section
attempts to clarify the situation by looking at several speciﬁc (fake) researchers’
experiences over the course of their careers.
Remember DEMO a given null hypothesis, H0, is either true or false, DEMO we can
never know this truth for sure. Also, for a DEMO experiment, the standard decision
rule tells us that whenwe should retain DEMO But again, we can never know for sure whether our inferencep DEMO α we should reject the null hypothesis, and when p > DEMO
is actually correct or incorrect.
Next we need to clarify the deﬁnitions of some common terms. A “positive”
result for an experiment means ﬁndingreject DEMO and claim an interesting ﬁnding. “Negative” means ﬁndingp ≤ α, which DEMO the situation for which wep > α, which
is the situation DEMO which we retain H0 and therefore don’t have enough evidence
to claim an interesting ﬁnding. “True” means correct (i.e. reject H0 when H0 is
false or retain H0 when H0 is true), and “false” mean DEMO These terms are
commonly put together, e.g., a false positive refers to the case where p ≤ 0.05, but
the null hypothesis is actually true.
Here are some examples in which we pretend that we DEMO omniscience, al-
though the researcher in question does not. Let α DEMO 0.05 unless otherwise speci-
ﬁed.
1.Neetika Null studies the eﬀects of various chants on blood sugar level. Every
week she studies 15 controls and DEMO people who chant a particular word from
the dictionary for 5 minutes. After 1000 weeks (and 1000 words) what is
her Type 1 DEMO rate (positives among null experiments), Type 2 error rate
(negatives among non-null experiments) and power (positives among non-
null experiments)? DEMO percent of her positives are true? What percent of
her negatives DEMO true?
This description suggests that the null hypothesis is always true, i.e. I assume
that chants don’t change blood sugar level, and DEMO not within ﬁve
minutes. Her Type 1 error rate is α = 0.05. Her Type 2 error rate (sometimes
called β) and power DEMO not applicable because no alternative hypothesis is
ever true. Out of 1000 experiments, 1000 are null in the sense that the
null hypothesis is true. Because the probability of getting p ≤ 0.05 in an
12.3. SPECIFIC RESEARCHERS’ LIFETIME EXPERIENCES
303
experiment where the null hypothesis is DEMO is 5%, she will see about 50
positive and 950 negative DEMO For Neetika, although she does not
know it, every time she sees p ≤ 0.05 she will mistakenly reject the null
hypothesis, for a 100% error rate. But every time she sees p > 0.05 DEMO will
correctly retain the null hypothesis for an error rate of 0%.
2.Stacy Safety studies the eﬀects on glucose levels of injecting cats with DEMO
taneous insulin at diﬀerent body locations. She divides the surface of a cat
into 1000 zones and each week studies injection of 10 cats DEMO water and 10
cats with insulin in a diﬀerent zone.
This description suggests that the null hypothesis is always false. Because
Stacy is studying DEMO powerful treatment and will have a small measurement
error, her power DEMO be large; let’s use 80%=0.80 as an example. Her Type
2 DEMO rate will be β=1-power=0.2, or 20%. Out of 1000 experiments, all
1000 are non-null, so Type 1 error is not applicable. With a power of 80%
we know that each experiment has an 80% chance DEMO giving p ≤ 0.05 and a
20% chance of given p > 0.05. So we expect around 800 positives and 200
negatives. Although Stacy DEMO know it, every time she sees p ≤ 0.05 she
will DEMO reject the null hypothesis, for a 0% error rate. But every DEMO
she sees p > 0.05 she will mistakenly retain the null hypothesis for an error
rate of 100%.
3.Rima Regular works for a large DEMO ﬁrm performing initial screen-
ing of potential new oral hypoglycemic drugs. Each week for 1000 weeks she
gives 100 rats a placebo and 100 DEMO a new drug, then tests blood sugar. To
increase power (at the expense of more false positives) she chooses α = 0.10.
For concreteness let’s assume that the null hypothesis is true 90% of the
DEMO Let’s consider the situation where among the 10% of candidate drugs
that work, half have a strength that corresponds to power equal to 50% (for
the given n and σ2) and the other half correspond DEMO power equal to 70%.
Out of 1000 experiments, 900 are null DEMO around 0.10*900=90 positive and
810 negative experiments. Of the 50 non-null experiments with 50% power,
we expect around 0.50*50=25 positive and 25 negative DEMO Of the
50 non-null experiments with 70% power, we expect around DEMO pos-
itive and 15 negative experiments. So among the 100 non-null experiments
(i.e., when Rima is studying drugs that really work) 25+35=60 out of 100
will correctly give p ≤ 0.05. Therefore Rima’s average power DEMO 60/100 or
60%.
304
CHAPTER 12. STATISTICAL POWER
Although Rima doesn’t know it, when she sees p ≤ 0.05 and rejects the
null hypothesis, around 60/(DEMO)=0.40=40% of the time she is correctly
rejecting the null hypothesis, DEMO therefore 60% of the time when she rejects
the null hypothesis she is making a mistake. Of the 810+40=850 experiments
for which she ﬁnds DEMO > 0.05 and retains the null hypothesis, she is correct
810/(810+40)=0.953=95.3% of time and she makes an error 4.7% of the
DEMO (Note that this value of approximately 95% is only a coincidence, and
not related to α = 0.05; in fact α = 0.10 for this problem.)
These error rates are not too bad given DEMO goals, but they are not very
intuitively related to α = DEMO and power equal to 50 or 70%. The 60% error
rate among drugs that are ﬂagged for further study (i.e., have p ≤ DEMO) just
indicates that some time and money will be spent to DEMO out which of these
drugs are not really useful. This is better than not investigating a drug that
really works. In fact, Rima might make even more money for her company if
she raises α to DEMO, causing more money to be wasted investigating truly use-
less drugs, but preventing some possible money-making drugs from slipping
through as useless. By DEMO way, the overall error rate is (90+40)/1000=13%.
Conclusion: For your career, you cannot know the chance that a negative result
is an error or the chance that a positive result is an error. DEMO these are what
you would really like to know! But you do know that when you study “ineﬀective”
treatments (and perform an appropriate statistical analysis) you have only a 5%
chance of incorrectly claiming they are “eﬀective”. And you know that the more
you increase the power of DEMO experiment, the better your chances are of detecting
a truly eﬀective DEMO
It is worth knowing something about the relationship of power to conﬁdence
intervals. Roughly, wide conﬁdence intervals correspond to experiments with
low power, DEMO narrow conﬁdence intervals correspond to experiments with good
power.
The error rates that experimenters are really interested in, i.e., the
probability that I DEMO making an error for my current experiment, are
not knowable. These DEMO rates diﬀer from both α and β=1-power.
12.4. EXPECTED MEAN SQUARE
12.4 Expected Mean Square
305
Although a full DEMO of “expected mean squares” is quite technical, a su-
perﬁcial understanding DEMO not diﬃcult and greatly aids understanding of several
other topics. EMS tells us what values we will get for any given mean square
(MS) statistic under either the null or an alternative distribution, on average DEMO
repeated experiments.
of the population treatment means, andk λ λi = DEMO −
i=1
and σ2 = P
−
k 1
population treatment means, we can deﬁne ¯µ
µ¯
. The quantity σ2 is not a variance, because it is calculated
A
2
i
A
If we have k
as the mean
(where λ is read “lambda”),
= DEMO
k µi
i=1
k
A
can similarly deﬁne σ2 and σ2
B A∗B
from ﬁxed parameters rather than from random quantities, but it obviously is a
“variance-like” quantity. Notice that we can express our usual null DEMO as
H0 : σ2 = 0 because if all of the µ’s are equal, then all of the λ’s equal zero. We
for a 2 way design.
Let σ2 be the true error variance (including subject-to-subject, treatment ap-
e
plication, environmental, and measurement variability). We haven’t been using
the subscript “e” up to this point, but here we will use it to be sure we can distin-
guish various symbols DEMO all include σ2. As usual, n is the number of subjects
DEMO group. For 2-way ANOVA, a (instead of k) is the DEMO of levels of factor A
and b is the number of levels of factor B.
The EMS tables for one-way and two-way designs are DEMO in table12.1and
12.2.
Remember that all of the between-subjects ANOVA F-statistics are ratios of
mean squares with various means squares in the numerator and DEMO the error
mean square in the denominator. From the EMS tables, DEMO can see why, for
either design, under the null hypothesis, DEMO F ratios that we have been using are
appropriate and have “central F” sampling distributions (mean near 1). You can
also see why, under any alternative, these F ratios tend to get bigger. You DEMO
also see that power can be increased by increasing the spacing between population
means (“treatment strength”) via increased values of |λ|, by increasing n, or by
2
2
decreasing σ . This formula also demonstrates that the value of σ is irrelevant to
e
e
the sampling DEMO of the F-statistic (cancels out) when the null hypothesis
is true, i.e., σA2 = 0.
306
CHAPTER 12. STATISTICAL POWER
Source of Variation
Factor A
Error (residual)
MS
MSA
MSerror
EMS
σ
σ
2 nσ2
e + A
DEMO
e
Table 12.1: Expected mean squares for a one-way ANOVA.
Source DEMO Variation
Factor A
Factor B
A*B interaction
Error (residual)
MS
DEMO
MSB
MS
MS
A∗B
error
EMS
σ
σ
σ
σ
2
e
2
e
2
e
2
e
+
+
+
bnσ2
A
anσ2
DEMO
nσ2
AB
Table 12.2: Expected mean squares for a two-way ANOVA.
DEMO the mathematically inclined, the EMS formulas give a good idea
of DEMO aspects of an experiment aﬀect the F ratio.
12.5 Power Calculations
In case it is not yet obvious, I want to reiterate why it is imperative to calculate
power for your experiment before running it. It DEMO possible and common for exper-
iments to have low power, e.g., in the range of 20 to 70%. If you are studying a
DEMO which is eﬀective in changing the population mean of your outcome, DEMO
your experiment has, e.g., 40% power for detecting the true mean diﬀerence, and
you conduct the experiment perfectly and analyze it appropriately, DEMO have a 60%
chance of getting a p-value of greater than 0.05, in which case you will erroneously
conclude that the treatment is ineﬀective. To prevent wasted experiments, you
should calculate power and only perform the experiment if there is a reasonably
high power.
It is worth noting DEMO you will not be able to calculate the “true” power of your
experiment. Rather you will use a combination of mathematics and judgement to
DEMO a useful estimation of the power.
12.5. POWER CALCULATIONS 307
There are an inﬁnite number of alternative hypothesis. DEMO any of them we can
increase power by 1) increasing n (sample size) or 2) decreasing experimental error
(σ2). Also, DEMO the alternatives, those with larger eﬀect sizes (population mean
e
diﬀerences) will have more power. These statements derive directly from the EMS
interpretive form of the F equation (shown here for 1-way ANOVA):
DEMO + nσ2
e A
MSA
MSerror ≈
Expected Value of F = Expected value of
σe2
Obviously increasing n or σ2 increases the average DEMO of F. Regarding the
A
eﬀect of changing σ2, a small DEMO will make this more clear. Consider the case
e
nσ2 = 10 and σ2 = 10. In this case the average F value is DEMO/10=2. Now
A e
where
reduce σe2 to 1. In this case the average F value is 11/1=11, which is much bigger,
resulting in more power.
In practice, we try to calculate the power of an experiment for one or a few
reasonable alternative hypotheses. We DEMO not to get carried away by considering
alternatives with huge eﬀects that are unlikely to occur. Instead we try to devise
alternatives that are DEMO conservative and reﬂect what might really happen (see
the next section)DEMO
What we need to know to calculate power? Beyond k and DEMO (α), we need to
know sample size (which we may be able to increase if we have enough resources),
an estimate of experimental error (variance or σ2, which we may be able DEMO reduce,
e
possibly in a trade-oﬀ with generalizability), and reasonable estimates of true eﬀect
sizes.
For any set of these three things, which we will call an “alternative hypoth-
esis scenario”, we can ﬁnd the sampling distribution of F under that alternative
hypothesis. Then it is DEMO to ﬁnd the power.
We often estimate σ2 with residual MS, DEMO error MS (MSE), or within-group
e
MS from previous similar DEMO Or we can use the square of the actual or
guessed standard deviation of the outcome measurement for a number of subjects
exposed to DEMO same (any) treatment. Or, assuming Normality, we can use expert
knowledge toguesstimatethe 95% range of a homogenous group of subjects, then
estimate σe as that range divided by 4. (This works because 95% of a normal
distribution is encompassed by mean plus or minus 2 s.d.) A similar trick is to
estimate σe as 3/4 of the DEMO (see Section4.2.4), then square that quantity.
Be careful! If you DEMO too large (pessimistic) of a value for σ2 your computed
e
308
CHAPTER 12. STATISTICAL POWER
power will be smaller than your true DEMO If you use too small (optimistic) of a
value for σe2 your computed power will be larger than your true power.
12.6 Choosing DEMO sizes
As mentioned above, you want to calculate power for “reasonable” DEMO sizes that
you consider achievable. A similar goal is to choose eﬀects sizes such that smaller
eﬀects would not be scientiﬁcally interesting. In either DEMO, it is obvious that
choosing eﬀect sizes is not a statistical DEMO, but rather one requiring subject
matter or possibly policy level expertise.
DEMO will give a few simple examples here, choosing subject matter that DEMO known to
most people or easily explainable. The ﬁrst example is for a categorical outcome,
even though we haven’t yet discussed statistical analyses DEMO such experiments.
Consider an experiment to see if a certain change in a TV commercial for a political
advisor’s candidate will make a diﬀerence DEMO an election. Here is the kind of
thinking that goes into deﬁning the eﬀect sizes for which we will calculate the
power. From prior DEMO matter knowledge, he estimate that about one fourth of
the voting DEMO will see the commercial. He also estimates that a change of 1%
in the total vote will be enough to get him excited that DEMO this commercial
is a worthwhile expense. So therefore an eﬀect size of 4% diﬀerence in a favorable
response towards his candidate is the eﬀect DEMO that is reasonable to test for.
Now consider an example of a farmer who wants to know if it’s worth it to
move her DEMO crop in the future to a farther, but more sunny slope. DEMO
estimates that the cost of initially preparing the ﬁeld is $2000, DEMO yearly extra
cost of transportation to the new ﬁeld is $200, DEMO she would like any payoﬀ to
happen within 4 years. The eﬀect size is the diﬀerence in crop yield in pounds
of tomatoes per DEMO She can put 1000 plants in either ﬁeld, and a pound DEMO
tomatoes sells for $1 wholesale. So for each 1 pound of eﬀect size, she gains $1000
per year. Over 4 years she needs to pay oﬀ $2000+4($200)=$2800. She concludes
that she needs to have DEMO power, say 80%, to detect an eﬀect size of 2.8/4=0.7
additional pounds of tomatoes per plant (i.e., a gain of $700 DEMO year).
Finally consider a psychologist who wants to test the eﬀects of a drug on mem-
ory. She knows that people typically remember DEMO out of 50 items on this test. She
really wouldn’t get too excited if the drug raised the score to 41, but she certainly
wouldn’t want to miss it if the drug raised the score to DEMO She decides to “power
12.7. USING N.C.P. TO CALCULATE POWER 309
her study” for µ1 = DEMO vs. µ2 = 42.5. If she adjusts n to get 80% power for
these population test score means, then she has an 80% chance of getting p ≤ 0.05
when the true eﬀect is a diﬀerence DEMO 2.5, and some larger (calculable) power for a
diﬀerence of DEMO, and some smaller (calculable) non-zero, but less than ideal, DEMO
for a diﬀerence of 1.0.
In general, you should consider the DEMO eﬀect size that you consider inter-
esting and try to achieve reasonable power for that eﬀect size, while also realizing
that there is more power for larger eﬀects and less power for smaller eﬀects. Some-
times DEMO is worth calculating power for a range of diﬀerent eﬀect sizes.
12.7 Using n.c.p. to calculate power
The material in this section is optional.
DEMO we will focus on the simple case of power in a one-way between-subjects
design. The “manual” calculation steps are shown here. Understanding these may
DEMO your understanding of power calculation in general, but ordinarily you will DEMO
a computer (perhaps a web applet) to calculate power.
Under any particular alternative distribution the numerator of F is inﬂated,
and F DEMO the non-central F distribution with k − 1 and k(n − 1) degrees of
freedom and with “non-centrality parameter” equal to:
k
i=1
n.c.p. = n · Pσ2
e
λ2
i
where n is DEMO proposed number of subjects in each of the groups we are comparing.
The bigger the n.c.p., the more the alternative sampling distribution moves to the
right and the more power we have.
Manual calculation example: Let α = 0.10 and n = 11 per cell. In a similar
DEMO MSE=36. What is the power for the alternative hypothesis HA : µ1 =
10, µ2 = 12, µ3 = 14, µ4 = 16?
1.Under the null hypothesis the F-statistic will follow the central F DEMO
(i.e., n.c.p.=0) with k − 1 = 3 and k(DEMO − 1) = 40 df. Using a computer or F
table DEMO ﬁnd Fcritical = 2.23.
2.Since ¯µ=(10+12+14+16)/4=13, the λ’s are -3,-1,1,3, so the non-centrality
parameter is
310 CHAPTER 12. STATISTICAL POWER
11(9 + 1 + 1 + DEMO) = 6.11.
36
3.The power is the area under the non-central DEMO curve with 3,40 df and
n.c.p.=6.11 that is to the right of 2.23. Using a computer or non-central
F table, we ﬁnd that the area is 0.62. This means that we have a 62% chance
DEMO rejecting the null hypothesis if the given alternate hypothesis is true.
4.An interesting question is what is the power if we double the sample DEMO to 22
per cell. dferror is now 21*4=84 and Fcritical is now 2.15. The n.c.p.=12.22.
From the appropriate non-central F distribution we ﬁnd that DEMO power in-
creases to 90%.
In practice we will use a Java applet to calculate power.
In R, the commands that give the values in the above example are:
qf(1-0.10, 3, 40) # result is 2.226092 for alpha=0.10
1-pf(2.23, 3, 40, 6.11) DEMO result is 0.6168411
qf(1-0.10, 3, 84) # result is DEMO
1-pf(2.15,3, 84, 12.22) # result is 0.8994447
In DEMO, put the value of 1-α (here, 1-0.10=0.90) in a spreadsheet
cell, e.g., in a column named “P”. The use Transform/Compute DEMO create
a variable called, say, ”Fcrit”, using the formula “IDF.F(DEMO,3,40)”. This
will give 2.23. The use Transform/Compute to create a variable called,
say, “power”, using the formula “1-NCDF.F(DEMO,3,40,6.11)”. This will
give 0.62.
12.8 A power applet
The Russ Lenth power applet is very nice way to calculate power. DEMO is available on
the web at http://www.cs.uiowa.edu/~rlenth/Power. If you are using it more
that occasionally you should copy the applet DEMO your website. Here I will cover
ANOVA and regression. Additional topic are in future chapters.
12.8. A POWER APPLET
311
12.8.1 Overview
To get started with the DEMO Power Applet, select a method such as Linear Regres-
sion or DEMO ANOVA, then click the “Run Selection” button. A new window
will DEMO with the applet for the statistical method you have chosen. Every time
you see sliders for entering numeric values, you may also click the small square at
upper right to change to a text box form DEMO entering the value. The Help menu
item explains what each input slider or box is for.
12.8.2 One-way ANOVA
This part of the applet DEMO for one-way and two-way balanced ANOVA. Re-
member that balanced indicates equal numbers of subjects per group. For one-
way ANOVA, leave the “Built-in models” drop-down box at the default value of
“One-way ANOVA”.
Figure 12.3: One-way ANOVA with Lenth power applet.
Enter “n” under “Observations per factor DEMO, and click to study the
power of “F tests”. A window DEMO that looks like ﬁgure12.3.
On the left, enter “k” under “levels[treatment] (Fixed)”. Under “n[Within]
(Random)” you can change n.
On the right enter σe (σ) under “SD[Within]” (on the standard deviation, DEMO
variance scale) and α under “Signiﬁcance level”. Finally you need to DEMO the
312
CHAPTER 12. STATISTICAL POWER
“eﬀect size” in the form of “SD[treatment]”. DEMO this applet the formula is
SD[treatment] = sP
k
i=1
λ
1
2
i
where λi is µi −
µ¯
as in section12.4.
k DEMO
For HA : µ1 = 10, µ2 = 12, µ3 = 14, µ4 = 16, ¯µ = 13 and λ1 = −3, λ2 = −1,
λ3 = +1, λ4 = +3.
SD[treatment] =
sP
s
k
i=1 λi2
k − 1
(−3)2 + (DEMO)2 + (+1)2 + (+3)2
= 3
= q20/3
= 2.58
You can also use the menu item “SD Helper” DEMO Options to graphically set
the means and have the applet calculate SD[treatment].
Following the example of section12.7we can plug in SD[treatment]=2.58, n =
11, and σe = 6 to get power=0.6172, which matches the manual DEMO of
section12.7
At this point it is often useful to make a power plot. Choose Graph under the
Options menu item. The most useful DEMO has “Power[treatment]” on the y-axis
and “n[Within]” on the x-axis. Continuing with the above example I would choose
to plot power “from” 5 “to” DEMO “by” 1. When I click “Draw”, I see the power
for DEMO experiment for diﬀerent possible sample sizes. An interesting addition can
be obtained by clicking “Persistent”, then changing “SD[treatment]” in the main
window to another reasonable value, e.g., 2 (for HA : µ1 = 10, DEMO = 10, µ3 = 10,
µ4 = 14), and DEMO OK. Now the plot shows power as a function of n for two (or
more) eﬀect sizes. In Windows you can use the DEMO key combination
to copy the plot to the clipboard, then paste DEMO into another application. The result
is shown in ﬁgure12.4. The lower curve is for the smaller value of SD[treatment].
12.8.3 Two-way ANOVA without interaction
DEMO “Two-way ANOVA (additive model)”. Click “F tests”. In the new DEMO,
on the left enter the number of levels for each of the two factors under “levels[row]
12.8. A POWER APPLET
Figure 12.4: One-way ANOVA power plot from Lenth power applet.
313
314
CHAPTER 12. STATISTICAL POWER
(Fixed)” and “levels[col] (Fixed)”. DEMO the number of subjects for each cell under
“Replications (Random)”.
DEMO the estimate of σ under “SD[Residual]” and the enter the “Signiﬁcance
level”.
Calculate “SD[row]” and “SD[col]” as in the one-way ANOVA calculation for
“SD[treatment]”, but the means for either factor are now averaged over all levels
DEMO the other factor.
Here is an example. The table shows cell population means for each combina-
tion of levels of the two treatment factors DEMO which additivity holds (e.g., a proﬁle
plot would show parallel lines).
Row factor / Column Factor Level 1 Level 2 Level 3 DEMO Mean
Level 1 10 20 15 15
Level 2 13 23 18 18
Col. Mean 11.5 21.5 16.5 16.5
Averaging over the other factor DEMO see that for the column means, using some
fairly obvious invented DEMO we get HColAlt : µC1 = 11.5,µC2 = 21.5,µC3 =
16.5. The row means are HRowAlt : µR1 = 15,µR2 = DEMO
2
2
Therefore SD[row] is the square root of ((−1.5) DEMO (+1.5) )/1 which is 2.12.
2
2
2
The value of SD[col] is the square root of ((−5) + (+5) + (0) )/2 which equals
5. If we choose α DEMO 0.05, n = 8 per cell, and estimate σ at 8, then the power is a
not-so-good 24.6% for HRowAlt, but a DEMO good 87.4% for HColAlt.
12.8.4 Two-way ANOVA with interaction
You may someday ﬁnd it useful to calculate the power for a two-way ANOVA
interaction. DEMO fairly complicated!
Select “Two-way ANOVA”. Click “F tests”. In the new window, on the left
enter the number of levels for each of the two factors under “levels[row] (Fixed)”
and “levels[col] (Fixed)”. Enter DEMO number of subjects for each cell under “Repli-
cations (Random)”.
DEMO the estimate of σ under “SD[Residual]” and the enter the “Signiﬁcance
level”.
The treatment eﬀects are a bit more complicated here. Consider a table DEMO cell
means in which additivity does not hold.
12.8. A POWER APPLET 315
Row factor / Column Factor Level 1 DEMO 2 Level 3 Row Mean
Level 1 10 20 15 15
Level 2 13 20 18 17
Col. Mean 11.5 20.0 16.5 16
For DEMO row eﬀects, which come from the row means of 15 and DEMO, we subtract
16 from each to get the λ values of DEMO and 1, then ﬁnd SD[row]=q = 1.41.
For the column eﬀects, which come from the column means of 11.5, 20.0, and
16.5, we subtract their common mean of 16 to get
and then ﬁnd DEMO SD[col]=q = 4.
To calculate “SD[row*col]” we need to calculate for each of the 6 cells, the value
of µij − (¯µ + DEMO
λ value for the
(−1)2+(1)2
1
λ values DEMO -4.5, 4.0, and 0.5,
27.
(−4.5)2+(4.0)2+(DEMO)2
2
+ λ.j) where µij indicates the ith row and DEMO column, and λi. is the
ith row mean, and λ.j is the λ value for the jth column mean. For
example, for the top left cell we get 10-(16-4.5-1.0)=-0.5. The complete table is
DEMO factor / Column Factor Level 1 Level 2 Level 3 Row Mean
Level 1 -0.5 1.0 -0.5 0.0
Level 2 +0.5 -1.0 0.5 0.0
DEMO Mean 0.0 0.0 0.0 0.0
You will know you constructed the table correctly if all of the margins are zero.
To ﬁnd SD[row*col], sum the squares of all of the (non-marginal) cells, then divide
by (factors, then take the square root. Here we get SD[row*col]=r− 1) and (c− 1) where r and c are the number of DEMO in the row and columnq 25 =
0.25+1.0+0.25+0.25+1.0+0.
1·2
1.22.
If we choose α = 0.05, n = 10 per cell, and estimate DEMO at 3, then the power is a
not-so-good 23.8% for detecting DEMO interaction (gettin an interaction p-value less
than 0.05). This is DEMO in ﬁgure12.5.
12.8.5 Linear Regression
We will just look at simple linear regression (one explanatory variable). In addition
to the α, n, and σ, and the eﬀect size for the slope, we need DEMO characterize the
spacing of the explanatory variable.
Choose “Linear regression” in the applet and the Linear Regression dialog
shown in ﬁgure12.6appears. Leave “No. of DEMO (number of explanatory
variables) at 1, and set “Alpha”, “Error SD” (estimate of σ), and “(Total) Sample
316
CHAPTER 12. STATISTICAL POWER
Figure 12.5: Two-way ANOVA with Lenth power applet.
size”.
Under “SD of x[j]” enter the standard deviation of the DEMO values you will use.
Here we use the fact that the spread of any number of repetitions of a set of values
is the DEMO as just one set of those values. Also, because the x DEMO are ﬁxed, we
use n instead of n− 1 in the DEMO of the standard deviation formula. E.g.,
if we plan to use 5 subjects each at doses, 0, 25, 50, and 100 (which have a mean
of 43.75), then SD of x[j] = DEMO (0−43.75)2+(25−43.75)2+(50−43.75)2+(100−43.75)2 = 36.98.
4
DEMO in this value and σ = 30, and a sample size DEMO 3*4=12, and an eﬀect
size of beta[j] (slope) equal to DEMO, we get power = 48.8%, which is not good enough.
In a nutshell: Just like the most commonly used value for alpha is
0.05, you will ﬁnd that (arbitrarily) the most common approach people
take is to ﬁnd the value of n that achieves a power DEMO 80% for some
speciﬁc, carefully chosen alternative hypothesis. Although there is
DEMO bit of educated guesswork in calculating (estimating) power, it is
DEMO advised to make some power calculations before running an
experiment to ﬁnd out if you have enough power to make running the
experiment worthwhile.
12.8. A POWER APPLET
317
Figure 12.6: Linear regression with Lenth power applet.
318
CHAPTER 12. STATISTICAL POWER
Chapter 13
Contrasts and Custom
Hypotheses
Contrasts ask speciﬁc questions as opposed DEMO the general ANOVA null vs. alter-
native hypotheses.
In a one-way ANOVA with a k level factor, the null hypothesis is µ1 = ··· = µk,
and the alternative is that at least one group (treatment) population mean of the
outcome diﬀers from the others. If k = 2, and the null hypothesis is rejected we
need only look at the sample means to see which treatment is “better”. But if DEMO >
2, rejection of the null hypothesis does not give the full information of interest. For
some speciﬁc group population means we would DEMO to know if we have suﬃcient
evidence that they diﬀer from certain other group population means. E.g., in a
test of the eﬀects of control and two active treatments to increase vocabulary,
we might ﬁnd DEMO based on a the high value for the F-statistic we are justiﬁed in
rejecting the null hypothesis µ1 = µ2 = µ3. If the DEMO means of the outcome are
50, 75 and 80 respectively, we need additional testing to answer speciﬁc questions
like “Is the control population DEMO lower than the average of the two active
treatment population means?” and “Are the two active treatment population
means diﬀerent?” To answer DEMO like these we frame “custom” hypotheses,
which are formally expressed as contrast hypothesis.
Comparison and analytic comparison are other synonyms for contrast.
319
320 CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
13.1 Contrasts, in general
A contrast null hypothesis compares two population means or combinations of pop-
ulation DEMO A simple contrast hypothesis compares two population means,
e.g. H0 : µ1 = µ5. The corresponding inequality is the alternative hypothesis:
H1 : µ1 = µ5.
A contrast null hypotheses that has multiple population means on either or
both sides of the equal sign is called a DEMO contrast hypothesis. In the
vast majority of practical cases, the multiple DEMO means are combined as
their mean, e.g., the custom null hypothesis H0 : µ1+µ2 = µ3+µ4+µ5 represents a test
2 3
of the DEMO of the average of the ﬁrst two treatment population means to the
average of the next three. An example where this would be useful DEMO interesting
is when we are studying ﬁve ways to improve vocabulary, DEMO ﬁrst two of which are
diﬀerent written methods and the last three of which are diﬀerent verbal methods.
It is customary to rewrite the DEMO hypothesis with all of the population means
on one side of the equal sign and a zero on the other side. E.g.,or H0 : µ1+2 µ2 − µ3+µ34+µ5 = 0. This mathematical form, whose left DEMO is checkedH0 : µ1 − µ5 = 0
for equality to zero is the standard form for a contrast. In addition to hypothesis
testing, it is also often of interest to place a conﬁdence interval around DEMO contrast
of population means, e.g., we might calculate that the 95% CI for µ3 − µ4 is [-5.0,
+3.5].
As in the DEMO of classical statistics, we proceed by ﬁnding the null sampling
distribution DEMO the contrast statistic. A little bit of formalism is needed so that
we can enter the correct custom information into a computer program, which will
then calculate the contrast statistic (estimate of the population contrast), the
standard error of the statistic, a corresponding t-statistic, and the DEMO p-
value. As shown later, this process only works under the DEMO circumstances
called “planned comparisons”; otherwise it requires some modiﬁcations.
Let γ (gamma) represent the population contrast. In this section, will use an
DEMO from a single six level one-way ANOVA, and use subscripts 1 DEMO 2 to
distinguish two speciﬁc contrasts. As an example of a simple (population) contrast,
deﬁnethe third vs. the fourth treatments. As an DEMO of a complex contrast letγ1 to be µ3 − µ4, a DEMO of the population means of the outcomes forγ2
be µ1+µ2 µ3+µ4+µ5 , a contrast of the population mean of the outcome for the ﬁrst
DEMO 3
−
two treatments to the population mean of the outcome for the third through ﬁfth
treatments. We can write the corresponding hypothesis as DEMO : γ1 = 0, HA1 :
13.1. CONTRASTS, IN GENERAL 321
γ1 = 0 and H02 : γ2 = 0, HA2 : γ2 = 0.
If we call the corresponding estimates, g1 and g2 then the appropriate estimates
y¯3+¯y4+¯y5 . In the hypothesis testing situation, we
3
4 and g2 = y¯1+¯y2
are g1 = ¯y3 − y¯ 2 −
are testing whether or not these DEMO are consistent with the corresponding
null hypothesis. For a conﬁdence interval on a particular population contrast (γ),
these estimates will be at DEMO center of the conﬁdence interval.
In the chapter on probability theory, DEMO saw that the sampling distribution of
any of the sample means from a (one treatment) sample of size n using the assump-
tions DEMO Normality, equal variance, and independent errors is ¯yi ∼ N (DEMO,σ2/n), i.e.,
across repeated experiments, a sample mean DEMO Normally distributed with the “cor-
rect” mean and the variance equal to the common group variance reduced by a
factor of n. Now we DEMO to ﬁnd the sampling distribution for some particular
combination of sample means.
To do this, we need to write the contrast in “standard form”. The standard
form involves writing a sum with one term for each DEMO mean (µ), whether
or not it is in the particular DEMO, and with a single number, called a contrast
coeﬃcient in front of each population mean. For our examples we get:
g1 = (0)µ1 + (0)µ2 + (0)µ3 + (1)µ4 + (−1)µ5 + (0)µ6
g2 = (1/2)µ1 + (1/2)µ2 + (−1/3)µ3 + (−1/3)µ4 + (−1/3)µ5 + (0)µ6.
In a more DEMO framing of the contrast we would write
g = C1µ1 + ··· + Ckµk.
In other words, each contrast can be summarized by specifying its k coeﬃcients
(C values). And it turns out that the k coeﬃcients are what most computer
programs want as input when you DEMO the contrast of a custom null hypothesis.
In our examples, the DEMO (and computer input) for null hypothesis H01
are [0, 0, 1, -1, 0, 0], and for H02 they are [1/DEMO, 1/2, -1/3, -1/3, -1/3, 0]. DEMO
that the zeros are necessary. For example, if you just entered DEMO, -1], the computer
would not understand which pair of treatment population means you want it to
compare. Also, note that any valid set of contrast coeﬃcients must add to zero.
and
322
CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
It is OK to multiply DEMO set of coeﬃcients by any (non-zero) number.
E.g., we could DEMO specify H02 as [3, 3, -2, -2, -2, 0] DEMO [-3, -3, 2, 2, 2,
0]. These alternate contrast coeﬃcients give the same p-value, but they do
give diﬀerent estimates of γ, and that must be taken in to account when
you interpret conﬁdence intervals. If you really want to get a conﬁdence
interval on DEMO diﬀerence in average group population outcome means for
the ﬁrst two vs. the next three treatments, it will be directly interpretable
only in the fraction form.
A positive estimate for γ indicates higher means for the DEMO with positive
coeﬃcients compared to those with negative coeﬃcients, while a DEMO estimate
for γ indicates higher means for the groups with negative coeﬃcients compared to
those with positive coeﬃcients
To get a computer program to DEMO a custom hypothesis, you must
enter the k coeﬃcients that specify DEMO hypothesis.
If you can handle a bit more math, read the DEMO behind contrast estimates
provided here.
The simplest case is for two independent random variables Y1 and
Y2 for which the population means are µ1 DEMO µ2 and the variances are
and σ22. (We allow unequal variance, because even under the equal
σ2
1
variance assumption, the sampling distribution of two means, depends on
their sample sizes, which might not DEMO equal.) In this case it is true that
E(C1Y1 + DEMO) = C1µ1 + C2µ2 and Var(C1Y1 + C2Y2) =
If in addition, the distributions of the random variables are Normal, we
DEMO conclude that the distribution of the linear combination of the random
variables is also Normal. Therefore Y1 ∼ N (µ1,σ2), Y2 ∼ N (µ2,σ2), ⇒
1
2
C1Y1 + C2Y2 ∼ N (C1µ1 + C2µ2
, C 2σ2 + C 2σ
1 1 2
2).
2
C 2σ2 + C 2σ2.
1 1 2 2
13.1. CONTRASTS, IN GENERAL
323
We will also use the fact that if each of several independent random
variables has variance σ2, then the variance of a sample mean of m of these
has variance σ2/DEMO
From these ideas (and some algebra) we ﬁnd that in a one-way ANOVA
with k treatments, where the group sample means are independent, if
we let σ2 be the common population variance, and ni DEMO the number of
subjects sampled for treatment i, then Var(g) = Var(C1
)].
σ2[PIn a real data analysis, we don’t DEMO σ2 so we substitute its estimate,
the within-group mean square. Then the square root of the estimated
variance is the standard error of DEMO contrast estimate, SE(g).
k
i=1(C 2
i /ni
Y¯
1 + ··· + Ck
Y¯
k) =
For any normally distributed quantity, g, which is an estimate of a
parameter, γ, we can construct a t-statistic, (g − γ)/SE(g)DEMO Then the
sampling distribution of that t-statistic will be that of the t-distribution
with df equal to the number of degrees of freedom in DEMO standard error
(dfwithin).
From this we can make a hypothesis DEMO using H0 : γ = 0, or we can
construct a DEMO interval for γ, centered around g.
For two-way (or higher) DEMO without interaction, main eﬀects contrasts
are constructed separately for each factor, where the population means represent
setting a speciﬁc level for one factor DEMO ignoring (averaging over) all levels of the
other factor.
For two-way ANOVA with interaction, contrasts are a bit more complicated.
E.g., if DEMO factor is job classiﬁcation (with k levels) and the other factor is incentive
applied (with m levels), and the outcome is productivity, we might be interested
in comparing any particular combination of factor levels to any other combination.
In this case, a one-way ANOVA with k · m levels is probably the best way to go.
If we DEMO only interested in comparing the size of the mean diﬀerences for two
particular levels of one factor across two levels of the other factor, then we are
more clearly in an “interaction framework”, and contrasts written for the two-way
ANOVA make the most sense. E.g., if the subscripts on mu represent the levels
of the two factors, we might be interested in a conﬁdence interval on the contrast
324
CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
(µ1,3 − µ1,5) − (µ2,3 − µ2,5).
The contrast idea extends DEMO to two-way ANOVA with no interac-
tion, but can be more DEMO if there is an interaction.
13.2 Planned comparisons
The ANOVA module of most statistical computer packages allow entry of custom
hypotheses through contrast coeﬃcients, but the p-values produced are only valid
under stringent conditions called planned DEMO or planned contrasts or
planned custom hypotheses. Without meeting these conditions, DEMO p-values will
be smaller than 0.05 more than 5% of the time, often far more, when the null
hypothesis is true (i.e., DEMO you are studying ineﬀectual treatments). In other
words, these requirement DEMO needed to maintain the Type 1 error rate across the
entire experiment.
Note that for some situations, such as genomics and proteomics, where
DEMO is very large, a better goal than trying to keep the DEMO of making any
false claim at only 5% is to reduce the total fraction of positive claims that
are false positive. This is called DEMO of the false discovery rate (FDR).
The conditions needed for DEMO comparisons are:
1.The contrasts are selected before looking at the results, i.e., they are planned,
not post-hoc (after-the-fact).
2.The tests are ignored if the overall null hypothesis (µ1 = ··· = µk) is not
rejected in the ANOVA.
3.The contrasts are orthogonal (see DEMO). This requirement is often ignored,
with relatively minor consequences.
13.2. PLANNED COMPARISONS 325
4.The number of planned contrasts is no more DEMO the corresponding degrees
of freedom (k − 1, for one-way ANOVA).
The orthogonality idea is that each contrast should be based on DEMO
dependent information from the other contrasts. For the 36309 course,
you can consider this paragraph optional. To test for orthogonality of two
contrasts DEMO which the contrast coeﬃcients arek C1 ···Ck and D1 ···Dk,
i=1(CiDi). If the sum is zero, then the contrasts are orthogo-
compute P
nal. E.g., if k=3, then µ − 0.5µ − DEMO is orthogonal to µ − µ , but
1 2 3 2 3
not to µ1 − µ2 because (1)(0)+(-0.5)(1)+(-0.5)(-1)=0, but (1)(1)+(-0.5)(-
1)+(-0.5)(0)=1.5.
To reiterate the requirements of planned comparisons, let’s consider the conse-
quences of breaking each requirement. If you construct your contrasts after looking
at your experimental results, you will naturally choose to compare the biggest and
the smallest sample means, which suggests that you are implicitly comparing all
of the sample means to ﬁnd DEMO interesting pair. Since each comparison has a
95% chance of correctly retaining the null hypothesis when it is true, after m in-
dependent tests you have a 0.95m chance of correctly concluding that there are no
DEMO diﬀerences when the null hypothesis is true. As examples, for m=3, 5,
and 10, the chance of correctly retaining all of the null hypotheses are 86%, 77%
and 60% respectively. Put another way, DEMO which groups to compare after
looking at results puts you at risk of making a false claim 14, 23 and 40% of the
time respectively. (In reality the numbers are often slightly better because of lack
of independence of the contrasts.)
The same kind of argument applies DEMO looking at your planned comparisons
without ﬁrst “screening” with the overall p-value of the ANOVA. Screening pro-
tects your Type 1 experiment-wise error rate, while lack of screening raises it.
Using orthogonal contrasts is also required DEMO maintain your Type 1 experiment-
wise error rate. Correlated null hypotheses tend to make the chance of having
several simultaneous rejected hypotheses happen more DEMO than should occur
when the null hypothesis is really true.
Finally, DEMO more than k− 1 planned contrasts (or k− 1 and m− DEMO contrasts
for a two-way k × m ANOVA without interaction) increases DEMO Type 1 error
326
CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
because each additional test is DEMO additional chance to reject the null hypothesis
incorrectly whenever the null hypothesis actually is true.
Many computer packages, including SPSS, assume that for DEMO set of custom
hypotheses that you enter you have already checked that these four conditions
apply. Therefore, any p-value it gives you is wrong if you have not met these
conditions.
It is up to you DEMO make sure that your contrasts meet the conditions of
“planned contrasts”; DEMO the computer package will give wrong
p-values.
In SPSS, anything entered DEMO “Contrasts” (in menus) or “LMATRIX” (in Syn-
tax, see Section5.1) is tested as if it is a planned contrast.
As an example, consider a trial of control vs. two active treatments (k = DEMO).
Before running the experiment, we might decide to test if DEMO average population
means for the active treatments diﬀers from the control, DEMO if the two active
treatments diﬀer from each other. The contrast coeﬃcients are [1, -0.5, -0.5] and
[0, 1, -1]. These are DEMO before running the experiment. We need to realize
that we should only examine the contrast p-values if the overall (between-groups,
2 df) DEMO test gives a p-value less than 0.05. The contrasts are orthogonal because
(1)(0)+(-0.5)(1)+(-0.5)(-1)=0. Finally, there are only k-1=2 contrasts, so we have
not selected too many.
13.3 Unplanned or post-hoc contrasts
What should we do if we want DEMO test more than k − 1 contrasts, or if we ﬁnd
DEMO interesting diﬀerence that was not in our planned contrasts after looking at
our results? These are examples of what is variously called unplanned compar-
isons, multiple comparisons, post-hoc (after-the-fact) comparisons, or data snoop-
ing. The answer is that we need to add some sort of penalty DEMO preserve our Type
1 experiment-wise error rate. The penalty can either take the form of requiring a
larger diﬀerence (g value) before an DEMO test is considered “statistically sig-
niﬁcant”, or using a smaller α DEMO (or equivalently, using a bigger critical F-value
or critical t-value).
13.3. UNPLANNED OR POST-HOC CONTRASTS
327
How big of a penalty to DEMO is mostly a matter of considering the size of the
“family” of comparisons within which you are operating. (Amount of dependence
among the contrasts can also have an eﬀect.) For example, if you pick out DEMO
biggest and the smallest means to compare, you are implicitly comparing DEMO pairs
of means. In the ﬁeld of probability, the symbol 
DEMO
b
 (read a choose b) is used to
indicate the number of diﬀerent groups of size b that can be formed from DEMO set of
a a!
b = b!(a−b)! where a! =
afactorial”. The simpliﬁcation for pairs,objects. The formula is  b
a DEMO (a − 1) ··· (1) is read “a
= 2, is 
a
2
 =
a!
2!(a−2)! = a(a − 1)/2. For
example, if we have a factor DEMO 6 levels, there are 6(5)/2=15 diﬀerent paired
comparisons we can make.
Note that these penalized procedures are designed to be applied DEMO ﬁrst
looking at the overall p-value.
The simplest, but often overly DEMO penalty is the Bonferroni correc-
tion. If m is the size of the family of comparisons you are making, the Bonferroni
procedure says to reject any post-hoc comparison test(s) if p ≤ α/m. So for k = 6
treatment levels, you can make post-hoc comparisons of all pairs while preserving
Type 1 error at 5% if you reject DEMO only when p ≤ α/15 = 0.0033.
The meaning of conservative is that this procedure is often more stringent
than necessary, and using some other valid procedure might show a statistically
signiﬁcant result in some DEMO where the Bonferroni correction shows no statistical
signiﬁcance.
The Bonferroni procedure is completely general. For example, if we want to
try all contrasts of the class “compare all pairs and compare the mean of any two
DEMO to any other single group”, the size of this class can DEMO computed, and the
Bonferroni correction applied. If k=5, there are 10 pairs, and for each of these
we can compare the mean of the pair to each of the three other groups, so the
family has 10*3+10=40 possible comparisons. Using the Bonferroni correction
with m=40 will ensure DEMO you make a false positive claim no more than 100α%
of the time.
Another procedure that is valid speciﬁcally for comparing pairs is the DEMO
procedure. The mathematics will not be discussed here, but the procedure DEMO
commonly available, and can be used to compare any and all DEMO of group pop-
ulation means after seeing the results. For two-way ANOVA without interaction,
the Tukey procedure can be applied to each factor (ignoring or averaging over the
other factor). For a k × DEMO ANOVA with a signiﬁcant interaction, if the desired
328
CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
contrasts are between arbitrary cells (combinations of levels of the two factors),
the Tukey procedure can be applied after reformulating the analysis as a one-way
ANOVA with k DEMO m distinct (arbitrary) levels. The Tukey procedure is more
powerful (DEMO conservative) than the corresponding Bonferroni procedure.
It is worth mentioning again DEMO that none of these procedures is needed for
k = 2. If you try to apply them, you will either get some form of “not applicable”
or you will get no penalty, i.e., the overall DEMO = µ2 hypothesis p-value is what is
applicable.
Another post-hoc procedure is Dunnett’s test. This makes the appropriate
penalty correction for comparing one (control) group to all other groups.
The total number of available post-hoc procedures is huge. Whenever you see
such an embarrassment of riches, you can correctly conclude that there is some
lack of consensus on the matter, and that applies here. I recommend against using
most of these, and certainly it is very bad practice to try as many as needed DEMO
you get the answer you want!
The ﬁnal post-hoc procedure discussed here is the Scheﬀ´e procedure.
This is a very general, but conservative procedure. It is applicable for the
family of all possible contrasts! One way DEMO express the procedure is to
consider the usual uncorrected t-test for a contrast of interest. Square the
t-statistic to get an F statistic. Instead DEMO the usual F-critical value for the
overall null hypothesis, often written DEMO F (1−α,k−1,N−k), the penalized
critical F value for DEMO post-hoc contrast is (k − 1)F (1 − α,k − 1,N − k).
Here, N is the total sample size for a one-way ANOVA, and − k is the
degrees of freedom in the estimate of σ2.
The critical F value for a DEMO penalized contrast can be obtained as
(k−1)×qf(0.95,k−1,N−k) in R or from (k−1)×IDF.F(0.95,k−1,N−k)
in SPSS.
N
Although Scheﬀ´e is a choice in the SPSS Post-Hoc dialog box, it doesn’t
make much sense to choose this because it only compares DEMO possible pairs,
but applies the penalty needed to allow all possible contrasts. In practice,
the Scheﬀ´e penalty makes sense when you see DEMO interesting complex post-
hoc contrast, and then want to see if DEMO actually have good evidence
13.4. DO IT IN SPSS
329
that it is “real” (statistically signiﬁcant). You can either use the menu
or syntax in SPSS to DEMO the contrast estimate (g) and its standard
error (SE(g)), or calculate these manually. Then ﬁnd F = (g/SE(g))2 and
reject H0 only if this value exceeds the Scheﬀ´e penalized F cutoﬀ value.
When you have both planned and unplanned comparisons (which should be
most of the time), it is not worthwhile (re-)examining any planned comparisons
that also show up in the list of DEMO comparisons. This is because the un-
planned comparisons have a penalty, DEMO if the contrast null hypothesis is rejected
as a planned comparison we already know to reject it, whether or not it is rejected
on the post-hoc list, and if it is retained as a planned comparison, there is no way
it will be rejected when the penalty is added.
Unplanned contrasts should be tested only after applying an appro-
priate DEMO to avoid a high chance of Type 1 error. The most useful
post-hoc procedures are Bonferroni, Tukey, and Dunnett.
13.4 Do it in DEMO
SPSS has a Contrast button that opens a dialog box for specifying planned con-
trasts and a PostHoc button that opens a dialog box DEMO specifying various post-hoc
procedures. In addition, planned comparisons can be speciﬁed DEMO using the Paste
button to examine and extend the Syntax (see DEMO) of a command to include
one or more contrast calculations.
13.4.1 DEMO in one-way ANOVA
For a k-level one-way (between-subjects) ANOVA, accessed DEMO Analyze/OneWayANOVA
on the menus, the Contrasts button opens the “One-Way DEMO: Contrasts”
dialog box (see ﬁgure13.1). From here you can enter the coeﬃcients for each
330
CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
Figure 13.1: One-way ANOVA contrasts dialog box.
planned contrast. For a given contrast, enter the k coeﬃcients that deﬁne any
given contrast into the box labeled “Coeﬃcients:” as DEMO decimal number (no frac-
tions allowed). Click the “Add” button DEMO entering each of the coeﬃcients. For
a k-level ANOVA, you must DEMO all k coeﬃcients, even if some are zero. Then you
should DEMO if the “Coeﬃcient Total” equals 1.000. (Sometimes, due to rounding,
this might be slightly above or below 1.000.) If you have any additional contrasts
to add, click the Next button and repeat the process. Click the Continue button
when you are ﬁnished.
When entering contrast coeﬃcients DEMO one-way ANOVA, SPSS will warn you
and give no result if DEMO enter more or less than the appropriate number of co-
coeﬃcients do not add to 1.0, or if the contrasts are not orthogonal. Also, iteﬃcients. It will not warn you if you enter more than k − 1 contrasts, if your
will not prevent you from incorrectly analyzing post-hoc comparisons as planned
comparisons.
The results for an example are given DEMO Table13.1. You should always look at
the Contrast Coeﬃcients table to verify which contrasts you are testing. In this
table, contrast 1, using DEMO (0.5, 0.5, -1) is testing H01 : µ1+µ2
2
− µ3 = 0.
Contrast 2 with coeﬃcients (1, -1, 0) DEMO testing H02 : µ1 − µ2 = 0.
13.4. DO IT IN SPSS
331
Contrast Coeﬃcients
additive
Contrast 1 2 DEMO
1 0.5 0.5 -1
2 1 -1 0
Contrast Tests
Contr Value of Std.
ast Contrast Error
hrs Assume 1 -0.452 0.382
equal variance DEMO 0.485 0.445
Does not assume 1 -0.452 0.368
equal variance 2 0.485 0.466
t
-1.18
1.09
-1.23
1.04
df
47
47
35.58
28.30
Table DEMO: Contrast results for one-way ANOVA.
Sig.
(2-tailed)
0.243
0.282
0.228
0.307
The Contrast Tests table shows the results. Note that “hrs” is DEMO name of the
outcome variable. The “Value of the Contrast” entry is the best estimate of the
contrast. For example, the best estimate of µ1 −µ2 is 0.485. The standard error of
this estimate (based on the equal variance section) is 0.445 giving a t-statistic of
0.485/0.445=1.09, which corresponds to a p-value of 0.282 using the t-distribution
with 47 df. So we retain the null hypothesis, and an approximate 95% CI for
µ1 − µ2 is 0.485 ± 2 × 0.445 = [−0.405, 1.375]. If you have evidence of unequal
variance (violation of the equal variance assumption) you can use the lower section
which is labeled “Does not assume equal variances.”
In SPSS, the two post-hoc tests that make the most sense are Tukey HSD and
Dunnett. Tukey should be used DEMO the only post-hoc testing is among all pairs
of population means. Dunnett should be used when the only post-hoc testing is
between a control DEMO all other population means. Only one of these applies to a
given experiment. (Although the Scheﬀ´e test is useful for allowing post-hoc testing
of all combinations of population means, turning that procedure on in SPSS does
not make sense because it still only tests all pairs, in which case Tukey is more
appropriate.)
Table13.2shows the Tukey results for this DEMO, which looks at the eﬀects
of three diﬀerent additives on an DEMO called hrs. Note the two columns labeled
I and J. For each combination of levels I and J, the “Mean Diﬀerence (I-J)” DEMO
332
CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
hrs
Tukey HSD
(I) (J)
additive additive
1 2
3
2 1
3
3 1
DEMO
Tukey HSD
Homogeneous Subsets
hrs
additive
2
1
3
Sig.
N
17
16
17
Subset for
alpha=0.05
1
16.76
17.244
17.453
0.270
Table 13.2: Tukey Multiple Comparison results for one-way ANOVA.
Multiple Comparisons
Mean
Diﬀerence (I-J)
0.485
-0.209
-0.485
-0.694
0.209
0.694
Std.Error
0.445
0.445
0.445
0.439
DEMO
0.439
Sig.
0.526
0.886
0.526
0.263
0.886
0.263
95% Conﬁdence Interval
Lower Bound
-0.593
-1.287
-1.563
-1.756
-0.869
-0.367
Upper Bound
1.563
0.869
0.593
DEMO
1.287
1.756
13.4. DO IT IN SPSS
333
gives the mean diﬀerence subtracted in DEMO order. For example, the ﬁrst mean
diﬀerence, 0.485, tells us DEMO the sample mean for additive 1 is 0.485 higher than
the sample mean for additive 2, because the subtraction is I (level 1) minus J
(level 2). The standard error of each diﬀerence is given. This standard error is
used in the Tukey procedure to calculate DEMO corrected p-value that is appropriate
for post-hoc testing. For any contrast that is (also) a planned contrast, you should
ignore the information given in the Multiple Comparisons table, and instead use
the information in the planned comparisons section of the output. (The p-value
for a planned comparison is smaller than for the corresponding post-hoc test.)
The Tukey procedure DEMO also gives a post-hoc 95% CI for each contrast.
Note again that if a contrast is planned, we use the CI from the planned contrasts
section and ignore what is in the multiple comparisons section. Contrasts DEMO are
made post-hoc (or analyzed using post-hoc procedures because they do DEMO meet
the four conditions for planned contrasts) have appropriately wider conﬁdence
DEMO than they would have if they were treated as planned contrasts.
The Homogeneous Subsets table presents the Tukey procedure results in a
diﬀerent way. DEMO levels of the factor are presented in rows ordered by the sample
means of the outcome. There are one or more numbered columns that DEMO
“homogeneous subsets.” One way to read this table is to say that all pairs are
signiﬁcantly diﬀerent except those that are in the same DEMO In this example,
with only one subset, no pairs have DEMO signiﬁcant diﬀerence.
Figure 13.2: Univariate contrasts dialog box.
334
CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
You can alternately use the DEMO item Analyze/GeneralLinearModel/Univariate
for one-way ANOVA. Then the Contrasts button does not allow setting arbitrary
contrasts. Instead, there a ﬁxed set of named planned contrasts. Figure13.2shows
the “Univariate: Contrasts” dialog box. In this ﬁgure the contrast type has been
changed from the default “None” to “Repeated”. Note DEMO word “Repeated” un-
der Factors conﬁrms that the change of contrast type has actually been registered
by pressing the Change button. Be sure to DEMO click the Change button whenever
you change the setting of the Contrast choice, or your choice will be ignored! The
pre-set contrast choices include “Repeated” which compares adjacent levels, “Sim-
ple” which compares either the ﬁrst or last level to all other levels, polynomial
which looks for increasing orders of polynomial trends, and a few other less useful
ones. These are all intended as planned contrasts, to be chosen before running the
experiment.
Figure 13.3: Univariate syntax window.
To make a custom set of planned contrasts in the Univariate procedure, click
the Paste button of the Univariate dialog box. This brings up a syntax window
with the SPSS DEMO commands that are equivalent to the menu choices you have
made so far (see Figure13.3). You can now insert some appropriate subcommands
to test your custom hypotheses. You can insert the extra lines anywhere between
DEMO ﬁrst line and the ﬁnal period. The lines that you would add to the Univariate
syntax to test H01 : µ1 −
µ2+µ3
2
DEMO 0 and H02 : µ2 − µ3 = 0 are:
/DEMO = "first vs. second and third" additive 1 -1/2 -1/2
13.4. DO IT IN SPSS 335
Custom Hypothesis Tests #1
Contrast Results (K Matrix)
Dependent
Contrast hrs
L1 Contrast Estimate 0.138
Hypothesized Value DEMO
Diﬀerence(Estimate-Hypothesized) 0.138
Std. Error 0.338
Sig. 0.724
95% Conﬁdence Interval DEMO Bound -0.642
for Diﬀerence Upper Bound 0.918
Based on user-speciﬁed contrast coeﬃcients: ﬁrst vs. second and third
Table 13.3: Planned contrast in one-way DEMO using LMATRIX syntax.
.
/LMATRIX = "second vs. third" additive DEMO 1 -1
Note that you can type any descriptive phrase inside the quotes, and SPSS will
not (cannot) test if your phrase actually corresponds to the null hypothesis deﬁned
by your contrasts. Also note that DEMO are allowed here. Finally, note that the
name of the factor (additive) precedes its list of coeﬃcients.
The output of the ﬁrst of these LMATRIX subcommands is shown in Table
13.3. This gives the p-value DEMO 95%CI appropriate for a planned contrast.
13.4.2 Contrasts for Two-way ANOVA
Contrasts in two-way (between-subjects) ANOVA without interaction work just
like in one-way DEMO, but with separate contrasts for each factor. Using the
Univariate procedure DEMO the Analyze/GeneralLinearModel menu, if one or both
factors has more DEMO two levels, then pre-deﬁned planned contrasts are available
with the Contrasts DEMO, post-hoc comparisons are available with the Post-Hoc
button, and arbitrary planned contrasts are available with Paste button and LMA-
TRIX subcommands added to DEMO Syntax.
For a k × m two-way ANOVA with interaction, two DEMO of contrasts make
sense. For planned comparisons, out of the km DEMO treatment cells, you can test
336
CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
TRIX subcommand you can only DEMO a particular subset of these: comparisonsup to (k − 1)(DEMO 1) pairs out of the 
between any two levels of DEMO factor when the other factor is ﬁxed at any particular
level. To do this, you must ﬁrst check the order of the two factors in the DESIGN
line of the pasted syntax. If the factors are DEMO A and B, the line will look
either like
km
2
DEMO = km(km−1) total pairs. With the LMA-
2
/DESIGN=A B A*B
or
/DESIGN=B A B*A
Let’s assume that we have the “A*B” form with, say, 3 levels of factor A and
2 levels DEMO factor B. Then a test of, say, level 1 vs. 3 of factor A when factor B is
ﬁxed at level 2 is DEMO as follows: Start the LMATRIX subcommand in the
usual way:
/LMATRIX="compare A1B2 to A3B2"
Then add coeﬃcients for the varying DEMO, which is A in this example:
/LMATRIX="compare A1B2 to A3B2" A 1 0 -1
Finally add the “interaction coeﬃcients”. There are km of these and the rule is
“the ﬁrst factor varies slowest”. DEMO means that if the interaction is speciﬁed as
A*B in the DESIGN statement then the ﬁrst set of coeﬃcients corresponds to all
levels of DEMO when A is set to level 1, then the next set DEMO all levels of B when A is
set to level 2, DEMO For our example with we need to set A1B2 to 1 and A3B2 to
-1, while setting everything else to 0. The correct subcommand is:
/LMATRIX="compare A1B2 to A3B2" A 1 0 -1 DEMO 0 1 0 0 0 -1
It is helpful to space out the A*B coeﬃcients in blocks to see what is going on
better. DEMO ﬁrst block corresponds to level 1 of factor A, the second DEMO to level
2, and the third block to level 3. Within DEMO block the ﬁrst number is for B=1
and the second number for B=2. It is in this sense that B is changing quickly
and DEMO slowly as we move across the coeﬃcients. To reiterate, position 2 DEMO the
13.4. DO IT IN SPSS
337
A*B list corresponds to A=1 and DEMO, while position 6 corresponds to A=3 and
B=2. These two have DEMO that match those of the A block (1 0 -1) and the
desired contrast (µA1B2 − µA3B2).
To test other types of planned pairs or to make post-hoc tests of all pairs, you
can convert the analysis to a one-way ANOVA by combining the factors using DEMO
calculation such as 10*A+B to create a single factor that encodes the information
from both factors and that has km diﬀerent levels. Then just DEMO one-way ANOVA
with either the speciﬁc planned hypotheses or the with the Tukey post-hoc proce-
dure.
The other kind of hypothesis testing that makes DEMO in two-way ANOVA with
interaction is to test the interaction eﬀects directly with questions such as “is the
eﬀect of changing from level 1 DEMO level 3 of factor A when factor B=1 the same or
diﬀerent from the eﬀect of changing from level 1 to level 3 of DEMO A when factor
B=2?” This corresponds to the null hypothesis: DEMO : (µA3B1 − µA1B1) − (µA3B2 −
µA1B2) = 0. This can be tested as a planned contrast within the context of DEMO
two-way ANOVA with interaction by using the following LMATRIX subcommand:
/DEMO"compare A1 to A3 for B1 vs. B2" A*B -1 1 DEMO 0 1 -1
First note that we only have the interaction coeﬃcients in the LMATRIX sub-
command for this type of contrast. Also note DEMO because the order is A then B
in A*B, the A DEMO move change slowly, so the order of eﬀects is A1B1 A1B2
DEMO A2B2 A3B1 A3B2. Now you can see that the above subcommand matches
the above null hypothesis. For an example of interpretation, assume that for ﬁxed
levels of both B=1 and B=2, A3-A1 is positive. Then a positive Contrast Estimate
for this contrast would indicate that the outcome diﬀerence DEMO B=1 is greater
than the diﬀerence with B=2.
338
CHAPTER 13. CONTRASTS AND CUSTOM HYPOTHESES
Chapter 14
Within-Subjects Designs
ANOVA must be modiﬁed to take correlated errors DEMO account when multiple
measurements are made for each subject.
14.1 Overview of within-subjects designs
Any categorical explanatory variable for which each subject experiences all DEMO the
levels is called a within-subjects factor. (Or sometimes a subject DEMO experience
several, but not all levels.) These levels could be diﬀerent “treatments”, or they
may be diﬀerent measurements for the same treatment (DEMO, height and weight as
outcomes for each subject), or they DEMO be repetitions of the same outcome over
time (or space) for each subject. In the broad sense, the term repeated measure
is a synonym for a within-subject factor, although often the term repeated measures
analysis is used in a narrower sense to indicate the speciﬁc set of DEMO discussed
in Section14.5.
In contrast to a within-subjects factor, any factor DEMO which each subject ex-
periences only one of the levels is a between-subjects factor. Any experiment
that has at least one within-subjects factor is DEMO to use a within-subjects de-
sign, while an experiment that uses DEMO between-subjects factor(s) is called a
between-subjects design. Often the term DEMO design or mixed within-
and between-subjects design is used when there is at least one within-subjects
factor and at least one between-subjects factor in DEMO same experiment. (Be care-
ful to distinguish this from the so-called DEMO models of chapter15.) All of the
339
340
CHAPTER 14. WITHIN-SUBJECTS DESIGNS
experiments discussed in the preceding chapters are DEMO designs.
Please do not confuse the terms between-groups and within-groups with the
terms between-subjects and within-subjects. The ﬁrst two terms, which we ﬁrst
encountered in the ANOVA chapter, are names of speciﬁc SS and MS compo-
nents and are named because of how we deﬁne the deviations that DEMO summed
and squared to compute SS. In contrast, the terms between-subjects DEMO within-
subjects refer to experimental designs that either do not or do make multiple
measurements on each subject.
When a within-subjects factor is used DEMO an experiment, new methods are
needed that do not make the DEMO of no correlation (or, somewhat more
strongly, independence) of errors for the multiple measurements made on the same
subject. (See section6.2.8to review the independent errors assumption.)
Why would we want to make multiple DEMO on the same subjects?
There are two basic reasons. First, DEMO primary interest may be to study the
change of an outcome over time, e.g., a learning eﬀect. Second, studying multiple
outcomes for each subject allows each subject to be his or her own “control”, i.e.,
we can eﬀectively remove subject-to-subject variation from our investigation of the
DEMO eﬀects of diﬀerent treatments. This reduced variability directly increases
power, often DEMO We may use this increased power directly, or we may
use DEMO indirectly to allow a reduction in the number of subjects studied.
These are very important advantages to using within-subjects designs, and such
designs are widely used. The major reasons for not using within-subjects designs
are when DEMO is impossible to give multiple treatments to a single subject or because
of concern about confounding. An example of a case where a within-subjects
DEMO is impossible is a study of surgery vs. drug treatment for a disease; subjects
generally would receive one or the other treatment, not DEMO
The confounding problem of within-subjects designs is an important concern.
Consider the case of three kinds of hints for solving a logic problem. Let’s DEMO
the time till solution as the outcome measure. If each subject ﬁrst sees problem
1 with hint 1, then problem 2 with hint 2, then problem 3 with hint 3, then we
will probably have DEMO major diﬃculties. First, the eﬀects of the hints carry-
over from DEMO trial to the next. The truth is that problem 2 is solved when the
subject has been exposed to two hints, and problem 3 when the subject has been
exposed to all three hints. The eﬀect DEMO hint type (the main focus of inference) is
confounded with the cumulative eﬀects of prior hints.
14.2. MULTIVARIATE DISTRIBUTIONS
341
The carry-over eﬀect is generally dealt with by DEMO suﬃcient time between
trials to “wash out” the eﬀects of previous trials. That is often quite eﬀective, e.g.,
when the treatments are drugs, and we can wait until the previous drug leaves the
system before studying the next drug. But in cases such as the hint study, this
approach may not be eﬀective or may take too much time.
DEMO other, partially overlapping, source of confounding is the fact that when
testing hint 2, the subject has already had practice with problem 1, and when
testing hint three she has already had practice with problems 1 and 2. This is the
learning eﬀect.
The learning eﬀect can DEMO dealt with eﬀectively by using counterbalancing.
The carryover eﬀect is also partially corrected by counterbalancing. Counterbal-
ancing in this experiment could take the form DEMO collecting subjects in groups of
six, then randomizing the group to DEMO possible orderings of the hints (123, 132,
213, 231, 312, 321). Then, because each hint is evenly tested at DEMO points along the
learning curve, any learning eﬀects would “balance out” DEMO the three hint types,
removing the confounding. (It would probably DEMO be a good idea to randomize
the order of the problem presentation in this study.)
You need to know how to distinguish within-subjects DEMO between-
subjects factors. Within-subjects designs have the advantages of more
power and allow observation of change over time. The main disadvan-
tage is possible DEMO, which can often be overcome by using
counterbalancing.
14.2 Multivariate distributions
DEMO of the analyses in this chapter require you to think about multivariate
distributions. Up to this point, we have dealt with outcomes that, DEMO all
subjects that have the same given combination of explanatory variables, DEMO as-
sumed to follow the (univariate) Normal distribution. The mean and variance,
along with the standard bell-shape characterize the kinds of outcome DEMO that
we expect to see. Switching from the population to the sample, we can put the
value of the outcome on the x-axis of a plot and the relative frequency of that
342
CHAPTER 14. WITHIN-SUBJECTS DESIGNS
value on the y-axis to get a DEMO that shows which values are most likely and
from which we can visualize how likely a range of values is.
To represent the outcomes DEMO two treatments for each subject, we need a so-
called, bivariate distribution. To produce a graphical representation of a bivariate
distribution, we use the two axes (say, y1 and y2) on a sheet of paper for the two
diﬀerent outcome values, and therefore each pair of outcomes corresponds to a
point on the paper with y1 equal to DEMO ﬁrst outcome and y2 equal to the second
outcome. Then the third dimension (coming up out of the paper) represents how
likely each DEMO of outcome is. For a bivariate Normal distribution, this is
like DEMO real bell sitting on the paper (rather than the silhouette of DEMO bell that we
have been using so far).
Using an analogy between a bivariate distribution and a mountain peak, we can
represent a bivariate distribution in 2-dimensions using a ﬁgure corresponding to a
topographic map. DEMO the center and the contours of one particular
bivariate Normal distribution. This distribution has a negative correlation between
the two values for each subject, so the distribution is more like a bell squished along
a diagonal DEMO from the upper left to the lower right. If we have no correlation
between the two values for each subject, we get a nice round bell. You can see
that an outcome like Y1 = 2, Y2 = 6 is fairly likely, while one like Y1 = 6, Y2 = 2
is quite unlikely. (By the way, bivariate distributions can have shapes other than
Normal.)
The idea of the bivariate DEMO can easily be extended to more than two
dimensions, but is DEMO course much harder to visualize. A multivariate distribution
with k-dimensions has a k-length vector (ordered set of numbers) representing its
mean. It also DEMO a k×k dimensional matrix (rectangular array of numbers) repre-
senting the variances of the individual variables, and all of the paired covariances
(DEMO section3.6.1).
For example a 3-dimensional multivariate distribution representing the out-
comes of three treatments in a within-subjects experiment would be characterized
by a DEMO vector, e.g.,
µ =

µ1
µ2
µ3

,
14.2. MULTIVARIATE DISTRIBUTIONS
343
Figure 14.1: Contours enclosing 1/3, 2/DEMO and 95% of a bivariate Normal distribu-
tion with a negative covariance.
and a variance-covariance matrix, e.g.,
Σ =

σ12 γ1,2 γ1,3
γ1,2 γ2,3
γ1,3 γ2,3 σ32
σ2
DEMO

.
Here we are using γi,j to represent the covariance of variable Yi with Yj.
Sometimes, as an alternative to a variance-covariance matrix, people use a
variance vector, e.g.,
σ2 =

DEMO a correlation matrix, e.g.,
Corr =

1
ρ1,2
DEMO,
3
σ
σ
σ
2
1
2
2
2
3

,
ρ1,2
1
ρ2,3
ρ1,3
ρ2,3
1

.
344 CHAPTER 14. WITHIN-SUBJECTS DESIGNS
Here we are using ρi,j to DEMO the correlation of variable Yi with Yj.
If the distribution is also Normal, we could write the distribution as Y ∼
N (µ, Σ).
14.3 Example and alternate approaches
Consider an example related to DEMO disease osteoarthritis. (This comes from the
OzDASL web site,OzDASL. For DEMO purposes, I slightly altered the data,
which can be found DEMO both the tall and wide formats on the data web page
of this book:osteoTall.savandosteoWide.sav.) Osteoarthritis is a mechanical
degeneration of joint surfaces causing pain, swelling and loss of joint function
in one or more joints. Physiotherapists treat the aﬀected joints to increase the
range of movement (ROM). In this study 10 subjects were each given a trial of
DEMO with two treatments, TENS (an electric nerve stimulation) and short DEMO
diathermy (a heat treatment), plus control.
We cannot perform ordinary (between-subjects) one-way ANOVA for this ex-
periment because each subject was exposed to all three treatments, so the errors
(ROM outcomes for a DEMO subject for all three treatments minus the population
means of outcome for those treatment) are almost surely correlated, rather than
independent. Possible appropriate DEMO fall into four categories.
1.Response simpliﬁcation: e.g. call the diﬀerence of DEMO of the measurements
on each subject the response, and use standard DEMO If the within-
subjects factor is the only factor, an appropriate DEMO is a one-sample t-
test for the diﬀerence outcome, with the DEMO hypothesis being a zero mean
diﬀerence. In cases where the within-subjects factor is repetition of the same
measurement over time or space and there DEMO a second, between subjects-
factor, the eﬀects of the between subjects factor on the outcome can be
studied by taking the mean of DEMO of the outcomes for each subject and using
standard, between-subjects one-way DEMO This approach does not fully
utilize the available information. Often it cannot answer some interesting
questions.
2.Treat the several responses on one subject as DEMO single “multivariate” re-
sponse and model the correlation between the components of that response.
The main statistics are now matrices rather than individual numbers. DEMO
14.4. PAIRED T-TEST 345
approach corresponds to results labeled “multivariate” under “repeated DEMO
sures ANOVA” for most statistical packages.
3.Treat each response as a separate (univariate) observation, and treat “sub-
ject” as a (random) blocking factor. This corresponds to within-subjects
ANOVA with subject included as a random DEMO and with no interaction
in the model. It also corresponds to the “univariate” output under “re-
peated measures”. In this form, there are assumptions about the nature of
the within-subject correlation that are not met fairly DEMO To use the
univariate approach when its assumptions are not met, DEMO is common to use
some approximate correction (to the degrees of DEMO) to compensate for
a shifted null sampling distribution.
4.Treat each measurement DEMO univariate, but explicitly model the correlations.
This is a more modern DEMO approach called “mixed models” that sub-
sumes a variety of models in a single uniﬁed approach, is very ﬂexible in
modeling correlations, and DEMO has improved interpretability. As opposed
to “classical repeated measures analysis” (approaches DEMO and 3), mixed models
can accommodate missing data as oppposed to dropping all data from every
subject who is missing one or more DEMO), and it accommodates
unequal and/or irregular spacing of repeated measurements. Mixed models
can also be extended to non-normal outcomes. (See chapter15.)
14.4 Paired t-test
The paired t-test uses response simpliﬁcation to handle the DEMO errors. It
only works with two treatments, so we will ignore DEMO diathermy treatment in
our osteoarthritis example for this section. The simpliﬁcation here is to compute
the diﬀerence between the two outcomes for each subject. DEMO there is only one
“outcome” for each subject, and there is DEMO longer any concern about correlated
errors. (The subtraction is part of DEMO paired t-test, so you don’t need to do it
yourself.)
DEMO SPSS, the paired t-test requires the “wide” form of data in DEMO spreadsheet
rather than the “tall” form we have used up until now. The tall form has one
outcome per row, so it has many rows. The wide form has one subject per row
with two or DEMO outcomes per row (necessitating two or more outcome columns).
346
CHAPTER 14. WITHIN-SUBJECTS DESIGNS
The paired t-test uses a one-sample t-test DEMO the single column of com-
puted diﬀerences. Although we have not yet discussed the one-sample
t-test, it is a straightforward extension of other t-tests like the independent-
sample t-test of Chapter6or the one for regression coeﬃcients DEMO Chapter
9. We have an estimate of the diﬀerence in outcome between the two treat-
ments in the form of the mean of the DEMO column. We can compute
the standard error for that diﬀerence (which DEMO the square root of the vari-
ance of the diﬀerence column divided by the number of subjects). Then
we can construct the t-statistic DEMO the estimate divided by the SE of the
estimate, and under DEMO null hypothesis that the population mean diﬀer-
ence is zero, this DEMO follow a t-distribution with n − 1 df, where n is DEMO
number of subjects.
The results from SPSS for comparing control to TENS ROM is shown in table
14.1. The table tells us that the DEMO point estimate of the diﬀerence in population
means for ROM between control and TENS is 17.70 with control being higher
(because the direction of the subtraction is listed as control minus TENS). The
uncertainty in DEMO estimate due to random sampling variation is 7.256 on the
standard deviation scale. (This was calculated based on the sample size of 10 and
the observed standard deviation of 22.945 for the observed sample.) We are 95%
conﬁdent that the true reduction in ROM caused by TENS relative DEMO the control
is between 1.3 and 34.1, so it may be DEMO small or rather large. The t-statistic
of 2.439 will follow the t-distribution with 9 df if the null hypothesis is true and
the assumptions DEMO met. This leads to a p-value of 0.037, so we reject DEMO null
hypothesis and conclude that TENS reduces range of motion.
For comparison, the incorrect, between-subjects one-way ANOVA analysis of
these data gives a DEMO of 0.123, leading to the (probably) incorrect conclusion
that the DEMO treatments both have the same population mean of ROM. For future
discussion we note that the within-groups SS for this incorrect analysis is 10748.5
DEMO 18 df.
For educational purposes, it is worth noting that it DEMO possible to get the same
correct results in this case (or DEMO one-factor within-subjects experiments) by
performing a two-way ANOVA in which “subject” DEMO the other factor (besides
treatment). Before looking at the results DEMO need to note several important facts.
Mean
17.700
Paired Diﬀerences
95% Conﬁdence
Std. Interval of the
Std. Error DEMO
Deviation Mean Lower Upper
22.945 7.256 1.286 34.114
t
2.439
df
9
Sig.
(2-tailed)
0.037
347
Table 14.1: Paired t-test for control-TENS DEMO in the osteoarthritis experiment.
14.4. PAIRED T-TEST
There is an important concept relating to the repeatability of levels of a factor.
A factor is DEMO to be a ﬁxed factor if the levels used are the same levels you
would use if you repeated the experiment. Treatments are generally DEMO factors.
A factor is said to be a random factor if a diﬀerent set of levels would be used
if you repeated the experiment. DEMO is a random factor because if you would
repeat the experiment, DEMO would use a diﬀerent set of subjects. Certain types of
blocking factors are also random factors.
The reason that we want to use subject DEMO a factor is that it is reasonable to
consider that some subjects will have a high outcome for all treatments and others
a low DEMO for all treatments. Then it may be true that the errors relative
to the overall subject mean are uncorrelated across the k treatments given DEMO a
single subject. But if we use both treatment and subject as factors, then each
combination of treatment and subject has only one outcome. In this case, we have
zero degrees of freedom for the within-subjects (error) SS. The usual solution is
to use the interaction MS DEMO place of the error MS in forming the F test for the
treatment eﬀect. (In SPSS it is equivalent to ﬁt a model without an interaction.)
Based on the formula for expected MS of an DEMO (see section12.4), we
can see that the interaction MS is DEMO to the error MS if there is no interaction
and larger otherwise. Therefore if the assumption of no interaction is correct (i.e,.
treatment eﬀects are similar for all subjects) then we get the “correct” p-value,
and if there really is an interaction, we get too small of an F value (too large of a
p-value), so the test is conservative, which means that it may give excess Type 2
errors, but won’t give excess Type 1 errors.
The two-way ANOVA results are shown in table14.2. Although we normally
ignore the intercept, it is included here to demonstrate the idea that in within-
subjects ANOVA (and other cases called nested ANOVA) the denominator of the
F-statistic, which DEMO labeled “error”, can be diﬀerent for diﬀerent numerators (which
348
CHAPTER 14. WITHIN-SUBJECTS DESIGNS
Source
Intercept
rx
subject
Hypothesis
Error
Hypothesis
DEMO
Hypothesis
Error
Type III Sum
of Squares
173166.05
8379.45
1566.45
2369.05
8379.45
2369.05
df
1
9
1
9
9
9
Mean Square
173166.05
931.05
DEMO
263.23
931.05
263.23
F
185.99
5.951
3.537
Sig.
<0.0005
0.035
0.037
DEMO 14.2: Two-way ANOVA results for the osteoarthritis experiment.
correspond to the DEMO null hypotheses). The null hypothesis of main interest
here is that the three treatment population means are equal, and that is tested
and rejected on the line called “rx”. The null hypothesis for the random DEMO
eﬀect is that the population variance of the subject-to-subject means (of DEMO three
treatments) is zero.
The key observation from this table is DEMO the treatment (rx) SS and MS
corresponds to the between-groups SS and MS in the incorrect one-way ANOVA,
while the sum of DEMO subject SS and error SS is 10748.5, which is the within-groups
DEMO for the incorrect one-way ANOVA. This is a decomposition of the four sources
of error (see Section8.5) that contribute to σ2, which is estimated by SSwithin in
the one-way ANOVA. In this two-way ANOVA the DEMO variability
is estimated to be 931.05, and the remaining three sources DEMO 263.23 (on
the variance scale). This smaller three-source error MS DEMO the denominator for the
numerator (rx) MS for the F-statistic of the treatment eﬀect. Therefore we get a
larger F-statistic and more power DEMO we use a within-subjects design.
How do we know which error terms to use for which F-tests? That requires
more mathematical statistics than we cover in this course, but SPSS will produce
an EMS table, DEMO it is easy to use that table to ﬁgure out which ratios are 1.0
when the null hypotheses are true.
It is worth mentioning DEMO in SPSS a one-way within-subjects ANOVA can be
analyzed either as a two-way ANOVA with subjects as a random factor (or even
as a ﬁxed factor if a no-interaction model is selected) or as a repeated measures
analysis (see next section). The p-value for the overall null hypothesis, that the
population outcome means are equal for all levels of the factor, is the same for
14.5. ONE-WAY REPEATED MEASURES ANALYSIS
each analysis, although which auxiliary statistics are produced diﬀers.
349
A two-level one-way within-subjects experiment can equivalently be
analyzed DEMO a paired t-test or a two-way ANOVA with a random sub-
ject factor. The latter also applies to more than two levels. The extra
DEMO comes from mathematically removing the subject-to-subject
component of the underlying variance (DEMO).
14.5 One-way Repeated Measures Analysis
Although repeated measures analysis is a very general term for any study in which
multiple measurements are made DEMO the same subject, there is a narrow sense of
repeated measures DEMO which is discussed in this section and the next section.
This is a set of speciﬁc analysis methods commonly used in social sciences, but
less commonly in other ﬁelds where alternatives such as mixed models tends DEMO be
used.
This narrow-sense repeated measures analysis is what you get if you choose
“General Linear Model / Repeated Measures” in SPSS. It includes DEMO second
and third approaches of our list of approaches given in the introduction to this
chapter. The various sections of the output are labeled DEMO or multivariate
to distinguish which type of analysis is shown.
This section discusses the k-level (k ≥ 2) one-way within-subjects ANOVA
using repeated DEMO in the narrow sense. The next section discusses the mixed
within/between subjects two-way ANOVA.
First we need to look at the assumptions of DEMO measures analysis. One-
way repeated measures analyses assume a Normal distribution of the outcome for
each level of the within-subjects factor. The errors are DEMO to be uncorrelated
between subjects. Within a subject the multiple measurements are assumed to
be correlated. For the univariate analyses, the assumption is that a technical
condition called sphericity is met. Although the technical condition is DEMO
to understand, there is a simpler condition that is nearly equivalent: compound
symmetry. Compound symmetry indicates that all of the variances are equal
DEMO all of the covariances (and correlations) are equal. This variance-covariance
350
CHAPTER 14. WITHIN-SUBJECTS DESIGNS
pattern is seen fairly often when there DEMO several diﬀerent treatments, but is
unlikely when there are multiple measurements DEMO time, in which case adjacent
times are usually more highly correlated DEMO distant times.
In contrast, the multivariate portions of repeated measures analysis DEMO are
based on an unconstrained variance-covariance pattern. Essentially, all of the DEMO
ances and covariances are estimated from the data, which allows accommodation
DEMO a wider variety of variance-covariance structures, but loses some power, particu-
larly when the sample size is small, due to “using up” some of the data and degrees
of freedom for estimating a more complex DEMO structure.
Because the univariate analysis requires the assumption of sphericity, it DEMO cus-
tomary to ﬁrst examine the Mauchly’s test of sphericity. Like other tests of as-
sumptions (e.g., Levene’s test of equal variance), DEMO null hypothesis is that there is
no assumption violation (here, that the variance-covariance structure is consistent
with sphericity), so a large (>DEMO) p-value is good, indicating no problem with
the assumption. Unfortunately, DEMO sphericity test is not very reliable, being often
of low power DEMO also overly sensitive to mild violations of the Normality assump-
tion. It is worth knowing that the sphericity assumption cannot be violated with
k DEMO 2 levels of treatment (because there is only a single covariance DEMO the
two measures, so there is nothing for it to be DEMO unequal to), and therefore
Mauchly’s test is inapplicable and not calculated when there are only two levels of
treatment.
The basic overall univariate DEMO of equality of population means for the within-
subjects factor is labeled “Tests of Within-Subjects Eﬀects” in SPSS and is shown
in table14.3. If DEMO accept the sphericity assumption, e.g., because the test of
sphericity is non-signiﬁcant, then we use the ﬁrst line of the treatment section
and the ﬁrst line of the error section. In this case F=MSbetween divided DEMO
MSwithin=1080.9/272.4=3.97. The p-value is based on the F-distribution with
2 and 18 df. (This F and p-value are exactly the same as the two-way ANOVA
with subject as a random factor.)
If the sphericity DEMO is violated, then one of the other, corrected lines of
the Tests of Within-Subjects Eﬀects table is used. There is some controversy about
DEMO to use which correction, but generally it is safe to go DEMO the Huynh-Feldt
correction.
The alternative, multivariate analysis, labeled “Multivariate Tests” in SPSS
is shown in table14.4. The multivariate tests are tests of the DEMO overall null
hypothesis (that all of the treatment population means are DEMO) as was used for
14.5. ONE-WAY REPEATED MEASURES ANALYSIS
351
Source
rx
Error(rx)
Sphericity DEMO
Greenhouse-Geisser
Huynh-Feldt
Lower-bound
Sphericity Assumed
Greenhouse-Geisser
Huynh-Feldt
Lower-bound
Type III Sum
of Squares
2161.8
2161.8
2161.8
2161.8
4904.2
4904.2
4904.2
4904.2
df
2
1.848
DEMO
1.000
18
16.633
18,000
9.000
Mean Square
1080.9
1169.7
1080.9
1169.7
272.4
272.4
544.9
F
3.967
3.967
3.967
3.967
294.8
Table 14.3: Tests of Within-Subjects Eﬀects for the osteoarthritis experiment.
the univariate analysis.
The approach DEMO the multivariate analysis is to ﬁrst construct a set of
k − 1 orthogonal contrasts. (The main eﬀect and interaction p-values are
the same for every set of orthogonal contrasts.) Then SS are computed for
each contrast in the usual way, and also “sum of cross-products” are also
formed for pairs of contrasts. These numbers are put into a k DEMO 1 by k − 1
matrix called the SSCP (sums of DEMO and cross products) matrix. In
addition to the (within-subjects) treatment DEMO matrix, an error SSCP
matrix is constructed analogous to computation of DEMO SS. The ratio of
these matrices is a matrix with F-values on the diagonal and ratios of
treatment to error cross-products oﬀ the diagonal. DEMO need to make a
single F statistic from this matrix to get a p-value to test the overall null
hypothesis. Four methods are provided DEMO reducing the ratio matrix to a
single F value. These are called Pillai’s Trace, Wilk’s Lambda, Hotelling’s
Trace, and Roy’s Largest Root. There is a fairly extensive, diﬃcult-to-
understand literature comparing these methods, but DEMO most cases they
give similar p-values.
The decision to reject or retain the overall null hypothesis of equal population
outcome means for all levels DEMO the within-subjects factor is made by looking at
Sig.
.037
.042
.042
.042
352
CHAPTER 14. WITHIN-SUBJECTS DESIGNS
Eﬀect
modality
Pillai’s Trace
Wilk’s Lambda
Hotelling’s DEMO
Roy’s Largest Root
Value
0.549
0.451
1.220
1.220
F
4.878
4.878
4.878
4.878
Hypothesis df
2
2
2
2
Error df
8
8
8
DEMO
Table 14.4: Multivariate Tests for the osteoarthritis experiment.
Sig.
0.041
0.041
DEMO
0.041
the p-value for one of the four F-values computed by SPSS. I recommend that you
use “Pillai’s trace”. The thing you should not DEMO is pick the line that gives the
answer you want! In a one-way within-subjects ANOVA, the four F-values will
always agree, while in DEMO complex designs they will disagree to some extent.
Which approach should we use, univariate or multivariate? Luckily, they agree
most of the time. When they disagree, it could be because the univariate approach
is somewhat more powerful, particularly for small studies, and is thus preferred.
Or DEMO could be that the correction is insuﬃcient in the case of far deviation from
sphericity, in which case the multivariate test is preferred as more robust. In
general, you should at least look for outliers or mistakes if there is a disagreement.
An additional section of the repeated DEMO analysis shows the planned
contrasts and is labeled “Tests of Within-Subjects Contrasts”. This section is the
same for both the univariate and multivariate approaches. DEMO gives a p-value for
each planned contrast. The default contrast set is “polynomial” which is generally
only appropriate for a moderately large number of DEMO of a factor representing
repeated measures of the same measurement over time. In most circumstances,
you will want to change the contrast type DEMO simple (baseline against each other
level) or repeated (comparing adjacent DEMO).
It is worth noting that post-hoc comparisons are available for the within-
subjects factor under Options by selecting the factor in the Estimated DEMO
Means box and then by checking the “compare main eﬀects” box and choosing
Bonferroni as the method.
14.6. MIXED BETWEEN/WITHIN-SUBJECTS DESIGNS
14.6 Mixed between/within-subjects designs
353
One DEMO the most common designs used in psychology experiments is a two-factor
ANOVA, where one factor is varied between subjects and the other within subjects.
The analysis of this type of experiment is a straightforward combination of DEMO
analysis of two-way between subjects ANOVA and the concepts of within-subject
analysis from the previous section.
The interaction between a within- and a between-subjects DEMO shows up in the
within-subjects section of the repeated measures analysis. As usual, the interaction
should be examined ﬁrst. If the interaction is signiﬁcant, then (changes in) both
factors aﬀect the outcome, regardless of DEMO p-values for the main eﬀects. Simple
eﬀects contrasts in a mixed design are not straightforward, and are not available in
SPSS. A proﬁle plot is a good summary of the results. Alternatively, it is common
to run separate one-way ANOVA analyses for each level of one factor, possibly
using planned and/or post-hoc testing. In this case we test the DEMO eﬀects
hypotheses about the eﬀects of diﬀerences in level of one factor at ﬁxed levels of
the other factor, as is appropriate in the case of interaction. Note that, depending
on which factor is restricted to a single level for these analyses, the appropriate
ANOVA could be either within-subjects or between-subjects.
If the interaction is not signiﬁcant, then the analysis can be re-run without the
interaction. Either the univariate or multivariate tests DEMO be used for the overall
null hypothesis for the within-subjects factor.
There is also a separate section for the overall null hypothesis for the DEMO
tween subjects factor. Because this section compares means between levels of the
between-subjects factor, and those means are reductions of the various levels of
the within-subjects factor to a single number, there is no concern about correlated
errors, and there is only a single univariate test of the overall null hypothesis.
For each factor you may select a set of DEMO contrasts (assuming that there
are more than two levels and that DEMO overall null hypothesis is rejected). Finally,
post-hoc tests are available for the between-subjects factor, and either the Tukey
or Dunnett test is usually appropriate (where Dunnett is used only if there is no
interest in comparisons other than to the control level). For the within-subjects
DEMO the Bonferroni test is available with Estimated Marginal Means.
354
CHAPTER 14. WITHIN-SUBJECTS DESIGNS
Repeated measures analysis is appropriate when one (or more) fac-
tors is a within-subjects factor. Usually univariate and multivariate
tests agree for the overall null hypothesis for the within-subjects fac-
tor DEMO any interaction involving a within-subjects factor. Planned
(main eﬀects) contrasts are appropriate for both factors if there is no
signiﬁcant interaction. Post-hoc comparisons DEMO also be performed.
14.6.1 Repeated Measures in SPSS
To perform a repeated measures analysis in SPSS, use the menu item “Analyze
/ General Linear Model / Repeated Measures.” The example uses the data in
circleWide.sav. This DEMO in the “wide” format with a separate column for each level
of the repeated factor.
Figure 14.2: SPSS Repeated Measures Deﬁne Factor(s) DEMO box.
Unlike other analyses in SPSS, there is a dialog box DEMO you must ﬁll out before
seeing the main analysis dialog box. This is called the “Repeated Measures Deﬁne
Factor(s)” dialog box as DEMO in Figure14.2. Under “Within-Subject Factor
14.6. MIXED BETWEEN/WITHIN-SUBJECTS DESIGNS
355
Name” you should enter a (new) name that describes what is diﬀerent among the
levels of your within-subjects factor. Then enter the “Number of Levels”, and click
Add. In a more complex design you need to do this for each within-subject factor.
DEMO, although not required, it is a very good idea to enter a “Measure Name”,
which should describe what is measured at each DEMO of the within-subject factor.
Either a term like “time” or units like “milliseconds” is appropriate for this box.
Click the “Deﬁne” button to continue.
DEMO 14.3: SPSS Repeated Measures dialog box.
Next you will see the DEMO Measures dialog box. On the left is a list of
all variables, at top right right is the “Within-Subjects Variables” box with lines
for each of the levels of the within-subjects variables you deﬁned previously. You
DEMO move the k outcome variables corresponding to the k levels of the within-
subjects factor into the “Within-Subjects Variables” box, either one at a time or
all together. The result looks something like Figure14.3. Now enter DEMO between-
subjects factor, if any. Then use the model button to DEMO the interaction if
356
CHAPTER 14. WITHIN-SUBJECTS DESIGNS
desired, for a two-way ANOVA. Usually you will want to use the contrasts button
to change the within-subjects contrast DEMO from the default “polynomial” type to
either “repeated” or “simple”. If you want to do post-hoc testing for the between-
subjects factor, use the Post-Hoc button. Usually you will want to use the options
button to DEMO means for the levels of the factor(s). Finally click OK to get
your results.
Chapter 15
Mixed Models
A ﬂexible approach to correlated data.
15.1 Overview
DEMO data arise frequently in statistical analyses. This may be due to group-
ing of subjects, e.g., students within classrooms, or to repeated measurements on
each subject over time or space, or to multiple related outcome measures at one
point in time. Mixed model analysis provides a general, ﬂexible approach in these
situations, because it allows a wide variety of correlation patterns (or variance-
covariance structures) to be explicitly modeled.
As DEMO in chapter14, multiple measurements per subject generally result
in the correlated DEMO that are explicitly forbidden by the assumptions of standard
(between-subjects) AN(C)OVA and regression models. While repeated measures
analysis of the type DEMO in SPSS, which I will call “classical repeated measures
analysis”, can model general (multivariate approach) or spherical (univariate ap-
proach) variance-covariance DEMO, they are not suited for other explicit struc-
tures. Even more DEMO, these repeated measures approaches discard all
results on any subject with DEMO a single missing measurement, while mixed mod-
els allow other data DEMO such subjects to be used as long as the missing data meets
the so-called missing-at-random deﬁnition. Another advantage of mixed models is
that they DEMO handle uneven spacing of repeated measurements, whether in-
tentional or unintentional. DEMO important is the fact that mixed model analysis is
357
358
CHAPTER 15. MIXED MODELS
often more interpretable than classical repeated measures. DEMO, mixed models
can also be extended (as generalized mixed models) DEMO non-Normal outcomes.
The term mixed model refers to the use of both ﬁxed and random eﬀects in
the same analysis. As explained in section14.1, ﬁxed eﬀects have levels that are
of primary interest and would be DEMO again if the experiment were repeated.
Random eﬀects have levels that are not of primary interest, but rather are thought
of as a random selection from a much larger set of levels. Subject eﬀects are almost
DEMO random eﬀects, while treatment levels are almost always ﬁxed eﬀects. Other
DEMO of random eﬀects include cities in a multi-site trial, batches in DEMO chemical
or industrial experiment, and classrooms in an educational setting.
As DEMO in more detail below, the use of both ﬁxed and random DEMO
in the same model can be thought of hierarchically, and there DEMO a very close
relationship between mixed models and the class of models called hierarchical linear
models. The hierarchy arises because we can think of DEMO level for subjects and
another level for measurements within subjects. In more complicated situations,
there can be more than two levels of the DEMO The hierarchy also plays out in
the diﬀerent roles of the ﬁxed and random eﬀects parameters. Again, this will be
discussed more fully below, but the basic idea is that the ﬁxed eﬀects parameters
tell how population means diﬀer between any set of treatments, while the random
eﬀect parameters represent the general variability among subjects or other units.
Mixed models DEMO both ﬁxed and random eﬀects. These correspond
to a hierarchy of levels with the repeated, correlated measurement
occurring among all of the lower level units for each particular upper
level unit.
15.2 A video game example
DEMO a study of the learning eﬀects of repeated plays of a video game where
age is expected to have an eﬀect. The data are DEMO The quantitative
outcome is the score on the video game (in DEMO of points). The explanatory
variables are age group of the subject and “trial” which represents which time the
subject played the game (1 to 5). The “id” variable identiﬁes the subjects. Note
15.2. A VIDEO GAME EXAMPLE
359
the the data are in the DEMO format with one observation per row, and multiple rows
per subject,DEMO
Figure 15.1: EDA for video game example with smoothed lines for DEMO age group.
Some EDA is shown in ﬁgure15.1. The plot shows all of the data points, with
game score plotted against trial number. Smoothed lines are shown for each of
the three age groups. The plot DEMO evidence of learning, with players improving
their score for each game DEMO the previous game. The improvement looks fairly
linear. The y-intercept (oﬀ DEMO graph to the left) appears to be higher for older
players. DEMO slope (rate of learning) appears steeper for younger players.
At this point you are most likely thinking that this problem looks like an DEMO
COVA problem where each age group has a diﬀerent intercept and slope for the
relationship between the quantitative variables trial and score. But ANCOVA
DEMO that all of the measurements for a given age group category have uncor-
related errors. In the current problem each subject has several measurements DEMO
360
CHAPTER 15. MIXED MODELS
the errors for those measurements will almost DEMO be correlated. This shows
up as many subjects with most or all of their outcomes on the same side of their
group’s ﬁtted line.
DEMO Mixed model approach
The solution to the problem of correlated within-subject errors in the video game
example is to let each subject have his DEMO her own “personal” intercept (and possibly
slope) randomly deviating from the mean intercept for each age group. This results
in a group of DEMO “personal” regression lines (or non-parallel if the slope is
also random)DEMO Then, it is reasonable (but not certain) that the errors DEMO
the personal regression lines will be uncorrelated. One way to do this is to use
subject identiﬁcation as a categorical variable, but this is treating the inherently
random subject-to-subject eﬀects as ﬁxed eﬀects, and “wastes” one parameter for
each subject in order to estimate his or her personal DEMO A better approach
is to just estimate a single variance parameter which represents how spread out
the random intercepts are around the common intercept DEMO each group (usually
following a Normal distribution). This is the DEMO models approach.
From another point of view, in a mixed model DEMO have a hierarchy of levels. At
the top level the units are often subjects or classrooms. At the lower level we could
have repeated DEMO within subjects or students within classrooms. The
lower level measurements that are within the same upper level unit are correlated,
when all of DEMO measurements are compared to the mean of all measurements for
a given treatment, but often uncorrelated when compared to a personal (or class
DEMO) mean or regression line. We also expect that there are various DEMO
and unmeasured aspects of the upper level units that aﬀect all of the lower level
measurements similarly for a given unit. For example various DEMO skills and
traits may aﬀect all measurements for each subject, and DEMO classroom traits
such as teacher characteristics and classroom environment aﬀect all of the students
in a classroom similarly. Treatments are usually applied randomly to DEMO upper-
level units. For example, some subjects receive a drug and DEMO receive a placebo,
Or some classrooms get an aide and others do not.
In addition to all of these aspects of hierarchical data DEMO, there is a vari-
ety of possible variance-covariance structures for the DEMO among the lower
level units. One common structure is called compound symmetry, which indicates
the same correlation between all pairs of measurements, as DEMO the sphericity char-
15.4. ANALYZING THE VIDEO GAME EXAMPLE
361
acteristic of chapter14. This is DEMO natural way to represent the relationship between
students within a classroom. If the true correlation structure is compound sym-
metry, then using a random intercept for each upper level unit will remove the
correlation among lower DEMO units. Another commonly used structure is autore-
gressive, in which measurements DEMO ordered, and adjacent measurements are more
highly correlated than distant measurements.
DEMO summarize, in each problem the hierarchy is usually fairly obvious, but
the user must think about and specify which ﬁxed eﬀects (explanatory variables,
including transformations and interactions) aﬀect the average responses for all sub-
jects. Then the user must specify which of the ﬁxed eﬀect coeﬃcients DEMO suﬃcient
without a corresponding random eﬀect as opposed to those ﬁxed coeﬃcients which
only represent an average around which individual units vary randomly. In DEMO
dition, correlations among measurements that are not fully accounted for by DEMO
random intercepts and slopes may be speciﬁed. And ﬁnally, if there DEMO multiple
random eﬀects the correlation of these various eﬀects may need to be speciﬁed.
To run a mixed model, the user must make many choices including
the nature of the hierarchy, the ﬁxed eﬀects and the random eﬀects.
In almost all situations several related models are considered and DEMO form of
model selection must be used to choose among related models.
The interpretation of the statistical output of a mixed model requires an DEMO
standing of how to explain the relationships among the ﬁxed and random eﬀects
in terms of the levels of the hierarchy.
15.4 Analyzing the DEMO game example
Based on ﬁgure15.1we should model separate linear relationships between trial
number and game score for each age group. Figure15.2, shows smoothed lines for
each subject. From this ﬁgure, it looks like we need a separate slope and intercept
for each age group. It is also fairly DEMO that in each group there is random subject-
to-subject variation in the intercepts. We should also consider the possibilities that
the “learning trajectory” is DEMO rather than linear, perhaps using the square of
the trial number DEMO an additional covariate to create a quadratic curve. We should
362
CHAPTER 15. MIXED MODELS
Figure 15.2: EDA for video game example with smoothed lines for each subject.
15.5. SETTING UP A MODEL IN SPSS
363
also check if a DEMO slope is needed. It is also prudent to check if the random
intercept is really needed. In addition, we should check if an autoregressive model
is needed.
15.5 Setting up a model in SPSS
The mixed DEMO section of SPSS, accessible from the menu item “Analyze /
Mixed Models / Linear”, has an initial dialog box (“Specify Subjects and DEMO
peated”), a main dialog box, and the usual subsidiary dialog DEMO activated by
clicking buttons in the main dialog box. In the initial dialog box (ﬁgure15.3) you
will always specify the upper level of DEMO hierarchy by moving the identiﬁer for
that level into the “subjects” box. For our video game example this is the subject
“id” column. For DEMO classroom example in which we study many students in each
classroom, DEMO would be the classroom identiﬁer.
Figure 15.3: Specify Subjects and Repeated DEMO Box.
364
CHAPTER 15. MIXED MODELS
If we want to model the correlation DEMO the repeated measurements for each
subject (other than the correlation induced DEMO random intercepts), then we need to
specify the order of the measurements within a subject in the bottom (“repeated”)
box. For the video game example, the trial number could be appropriate.
Figure 15.4: DEMO Linear Mixed Eﬀects Dialog Box.
The main “Linear Mixed Models” dialog box is shown in ﬁgure15.4. (Note
that just like in regression analysis use of transformation of the outcome or a
quantitative explanatory variable, i.e., DEMO covariate, will allow ﬁtting of curves.) As
usual, you must DEMO a quantitative outcome variable in the “Dependent Variable”
box. In the “Factor(s)” box you put any categorical explanatory variables (but not
the subject variable itself). In the “Covariate(s)” box you put DEMO quantitative
explanatory variables. Important note: For mixed models, specifying factors
and covariates on the main screen does not indicate that they will be DEMO in the
model, only that they are available for use in DEMO model.
The next step is to specify the ﬁxed eﬀects components of the model, using
15.5. SETTING UP A MODEL IN SPSS
365
the Fixed button which DEMO up the “Fixed Eﬀects” dialog box, as shown in
ﬁgure15.5. Here DEMO will specify the structural model for the “typical” subject,
which is just like what we did in ANCOVA models. Each explanatory variable or
DEMO that you specify will have a corresponding parameter estimated, and
that DEMO will represent the relationship between that explanatory variable and
the outcome if there is no corresponding random eﬀect, and it will represent the
mean relationship if there is a corresponding random eﬀect.
Figure 15.5: Fixed Eﬀects Dialog Box.
For the video example, I speciﬁed main eﬀects for age group and trial plus their
interaction. (You will always want to include the main eﬀects for any interaction
you specify.) Just like in ANCOVA, this model allows a diﬀerent intercept and
slope for each age group. The ﬁxed intercept (included unless the “Include in-
tercept” check box is unchecked) represents the (mean) intercept for the baseline
age group, DEMO the k − 1 coeﬃcients for the age group factor (with DEMO = 3 levels)
represent diﬀerences in (mean) intercept for the other age groups. The trial co-
366
CHAPTER 15. MIXED MODELS
eﬃcient represents the (mean) slope for DEMO baseline group, while the interaction
coeﬃcients represent the diﬀerences in (mean) slope for the other groups relative to
the baseline group. (As DEMO other “model” dialog boxes, the actual model depends
only on what DEMO in the “Model box”, not how you got it there.)
DEMO the “Random Eﬀects” dialog box (ﬁgure15.6), you will specify which DEMO
eters of the ﬁxed eﬀects model are only means around which individual subjects
vary randomly, which we think of as having their own personal values. Mathemat-
ically these personal values, e.g., a personal intercept for DEMO given subject, are equal
to the ﬁxed eﬀect plus a random DEMO from that ﬁxed eﬀect, which is zero on
average, but which has a magnitude that is controlled by the size of the random
DEMO, which is a variance.
Figure 15.6: Random Eﬀects Dialog Box.
15.5. SETTING UP A MODEL IN SPSS
367
In the random eﬀects DEMO box, you will usually want to check “Include In-
tercept”, to allow a separate intercept (or subject mean if no covariate is used)
for each subject (or each level of some other upper level variable). If you specify
any random eﬀects, then you must indicate that there is a separate “personal”
value of, say, the intercept, for each subject by placing the subject identiﬁer in the
“Combinations” box. (This step is very easy to forget, so get in the habit of doing
this every time.)
To model a random slope, move the covariate that deﬁnes that slope into the
“Model” box. In this DEMO, moving trial into the Model box could be used to
model DEMO random slope for the score by trial relationship. It does not make sense
to include a random eﬀect for any variable unless there is DEMO a ﬁxed eﬀect for
that variable, because the ﬁxed eﬀect represents DEMO average value around which
the random eﬀect varies. If you have more than one random eﬀect, e.g., a random
intercept and a random DEMO, then you need to specify any correlation between
these using the DEMO Type” drop-down box. For a single random eﬀect,
use “identity”. Otherwise, “unstructured” is usually most appropriate because it
allows correlation among the random eﬀects (see next paragraph). Another choice
is “diagonal” which assumes no correlation between the random eﬀects.
What does it mean for two random DEMO to be correlated? I will illustrate
this with the example of DEMO random intercept and a random slope for the trial
vs. game score relationship. In this example, there are diﬀerent intercepts and
slopes for each age group, so we need to focus on any one age group for this
discussion. The ﬁxed eﬀects deﬁne a mean intercept and mean DEMO for that age
group, and of course this deﬁnes a mean DEMO regression line for the group. The
idea of a random intercept and a random slope indicate that any given subject
will “wiggle” a bit DEMO this mean regression line both up or down (random
intercept) and clockwise or counterclockwise (random slope). The variances (and
therefore standard DEMO) of the random eﬀects determine the sizes of typical
deviations from DEMO mean intercept and slope. But in many situations like this
video game example subjects with a higher than average intercept tend to have a
DEMO than average slope, so there is a negative correlation between the DEMO
intercept eﬀect and the random slope eﬀect. We can look at it like this: the
next subject is represented by a random draw of an intercept deviation and a
slope deviation from a distribution with mean DEMO for both, but with a negative
correlation between these two random DEMO Then the personal intercept
and slope are constructed by adding these random deviations to the ﬁxed eﬀect
coeﬃcients.
368
CHAPTER 15. MIXED MODELS
Some other buttons in the main mixed DEMO dialog box are useful. I rec-
ommend that you always click the Statistics button, then check both “Parameter
estimates” and “Tests for covariance parameters”. The parameter estimates are
needed for interpretation of the results, similar to what we did for ANCOVA (see
chapter10). The tests for covariance parameters aid in determining which random
eﬀects are needed in a given DEMO The “EM Means” button allows generation
of “expected marginal means” which average over all subjects and other treatment
variables. In the current video game DEMO, marginal means for the three video
groups is not very useful DEMO this averages over the trials and the score varies
dramatically over the trials. Also, in the face of an interaction between age group
and trial number, averages for each level of age group are really meaningless.
As you can see there are many choices to be made when DEMO a mixed model.
In fact there are many more choices possible than described here. This ﬂexibility
makes mixed models an important general purpose tool DEMO statistical analysis, but
suggests that it should be used with caution DEMO inexperienced analysts.
Specifying a mixed model requires many steps, each of DEMO requires
an informed choice. This is both a weakness and a strength of mixed
model analysis.
15.6 Interpreting the results for the video game
DEMO
Here is some of the SPSS output for the video game example. We start with the
model for a linear relationship between trial and DEMO with separate intercepts and
slopes for each age group, and including DEMO random per-subject intercept. Table
15.1is called “Model Dimension”. Focus on the “number of parameters” column.
The total is a measure of overall complexity of DEMO model and plays a role in model
selection (see next section)DEMO For quantitative explanatory variables, there is only
one parameter. For categorical DEMO, this column tells how many parameters
are being estimated in the DEMO The “number of levels” column tells how many
lines are devoted to an explanatory variable in the Fixed Eﬀects table (see below),
DEMO lines beyond the number of estimated parameters are essentially blank (with
15.6. INTERPRETING THE RESULTS FOR THE VIDEO GAME EXAMPLE369
Fixed Intercept
Eﬀects DEMO
trial
agegrp * trial
Random Eﬀects Intercept
Residual
Total
Number
of Levels
1
3
1
3
1
9
Covariance
Structure
Identity
Number of
Parameters
DEMO
2
1
2
1
1
8
Table 15.1: Model dimension for DEMO video game example.
Subject
Variables
id
parameters labeled as redundant and a period in the rest of the columns). We
can see that DEMO have a single random eﬀect, which is an intercept for each DEMO
of id (each subject). The Model Dimension table is a DEMO quick check that the
computer is ﬁtting the model that you intended to ﬁt.
The next table in the output is labeled “Information Criteria” DEMO contains
many diﬀerent measures of how well the model ﬁts the data. I recommend that
you only pay attention to the last one, “Schwartz’s Bayesian Criterion (BIC)”, also
called Bayesian Information Criterion. In this DEMO, the value is 718.4. See the
section on model comparison for DEMO about information criteria.
Next comes the Fixed Eﬀects tables (tables15.2and15.3). DEMO tests of ﬁxed
eﬀects has an ANOVA-style test for each ﬁxed eﬀect in the model. This is nice
because it gives a single overall DEMO of the usefulness of a given explanatory vari-
able, without focusing DEMO individual levels. Generally, you will want to remove
explanatory variables that DEMO not have a signiﬁcant ﬁxed eﬀect in this table, and
then DEMO the mixed eﬀect analysis with the simpler model. In this example, DEMO
eﬀects are signiﬁcant (less than the standard alpha of 0.05). DEMO that I converted
the SPSS p-values from 0.000 to the correct form.
The Estimates of Fixed Eﬀects table does not appear by default; it is produced
by choosing “parameter estimates” under Statistics. We can see that DEMO group 40-
50 is the “baseline” (because SPSS chooses the last DEMO). Therefore the (ﬁxed)
intercept value of 14.02 represents the DEMO game score (in thousands of points)
for 40 to 50 DEMO olds for trial zero. Because trials start at one, the intercepts
DEMO not meaningful in themselves for this problem, although they are needed DEMO
calculating and drawing the best ﬁt lines for each age group.
370
CHAPTER 15. MIXED MODELS
Source
Intercept
agegrp
trial
agegrp * trial
DEMO df
1
2
1
2
Denominator
df
57.8
80.1
118.9
118.9
F
266.0
10.8
1767.0
70.8
Sig.
<0.0005
<0.0005
<0.0005
<0.0005
Table DEMO: Tests of Fixed Eﬀects for the video game example.
Parameter
Intercept
DEMO(20,30)
agegrp=(30,40)
agegrp=(40,50)
trial
(20,30)*trial
(30,40)*trial
(40,50)*trial
Estimate
14.02
-7.26
-3.49
0
3.32
3.80
2.14
0
Std.
Error
1.11
1.57
1.45
DEMO
0.22
0.32
0.29
0
df
55.4
73.0
64.2
.
118.9
118.9
118.9
.
t
12.64
-4.62
-2.40
.
15.40
11.77
7.35
.
Sig.
<0.0005
<0.0005
0.019
.
<0.0005
<0.0005
<0.0005
.
95% Conf. Int.
DEMO Upper
Bound Bound
11.80 16.24
-10.39 -4.13
-6.39 -0.59
. .
2.89 3.74
3.16 4.44
1.57 2.72
. .
Table 15.3: Estimates of Fixed Eﬀects for the video game example.
15.6. INTERPRETING THE RESULTS FOR THE VIDEO GAME EXAMPLE371
As in ANCOVA, writing out the full regression model then simplifying tells us
that the DEMO for 20 to 30 year olds is 14.02-7.26=6.76 and this is signiﬁcantly
lower than for 40 to 50 year olds (t=-4.62, p<0.0005, 95% CI for the diﬀerence is
4.13 to 10.39 thousand points lower)DEMO Similarly we know that the 30 to 40 years
olds have a lower intercept than the 40 to 50 year olds. Again these intercepts
DEMO are not directly interpretable because they represent trial zero. (It
would DEMO worthwhile to recode the trial numbers as zero to four, then DEMO the
analysis, because then the intercepts would represent game scores the DEMO time
someone plays the game.)
The trial coeﬃcient of 3.32 represents that average gain in game score (in
thousands of points) for DEMO subsequent trial for the baseline 40 to 50 year old
age group. The interaction estimates tell the diﬀerence in slope for other age groups
DEMO to the 40 to 50 year olds. Here both the 20 to 30 year olds and the 30 to
40 year olds learn quicker DEMO the 40 to 50 year olds, as shown by the signiﬁcant
DEMO p-values and the positive sign on the estimates. For example, we DEMO
95% conﬁdent that the trial to trial “learning” gain is 3.16 to 4.44 thousand points
higher for the youngest age group compared to the DEMO age group.
Interpret the ﬁxed eﬀects for a mixed model in the same way as an
ANOVA, regression, or ANCOVA depending on the DEMO of the ex-
planatory variables(s), but realize that any of the coeﬃcients that have
a corresponding random eﬀect represent the mean over DEMO subjects,
and each individual subject has their own “personal” value for that
coeﬃcient.
The next table is called “Estimates of Covariance Parameters” (table15.4). It
is very important to realize that while the parameter estimates DEMO in the Fixed
Eﬀects table are estimates of mean parameters, the DEMO estimates in this
table are estimates of variance parameters. The intercept variance is estimated as
6.46, so the estimate of the standard deviation is 2.54. This tells us that for any
given age group, e.g., DEMO oldest group with mean intercept of 14.02, the individual
subjects will DEMO “personal” intercepts that are up to 2.54 higher or lower than
the group average about 68% of the time, and up to 4.08 higher or lower about 95%
of the time. The null hypothesis for this DEMO is a variance of zero, which
would indicate that a random DEMO is not needed. The test statistic is called
a Wald Z statistic. Here we reject the null hypothesis (Wald Z=3.15, p=0.002)
372
CHAPTER 15. MIXED MODELS
Parameter
Residual
Intercept(Subject=id) Variance
Estimate
4.63
6.46
Std.
Error
0.60
2.05
Wald
Z
7.71
3.15
Sig.
<0.0005
0.002
95% Conf. Int.
Lower Upper
Bound Bound
3.59 5.97
3.47 12.02
Table DEMO: Estimates of Covariance Parameters for the video game example.
and conclude DEMO we do need a random intercept. This suggests that there are
important unmeasured explanatory variables for each subject that raise or lower
their performance DEMO a way that appears random because we do not know the
value(s) of the missing explanatory variable(s).
The estimate of the residual variance, with standard deviation equal to 2.15
(square root of DEMO), represents the variability of individual trial’s game scores
around the individual regression lines for each subjects. We are assuming that
once a personal DEMO line is drawn for each subject, their actual measurements
will randomly DEMO around this line with about 95% of the values falling within
4.30 of the line. (This is an estimate of the same σ2 as in a regression or ANCOVA
problem.) The p-value for the residual is not very meaningful.
Random eﬀects estimates are variances. Interpret a random eﬀect
DEMO estimate as the magnitude of the variability of “personal”
coeﬃcients from the mean ﬁxed eﬀects coeﬃcient.
All of these interpretations are contingent on choosing DEMO right model. The
next section discusses model selection.
15.7 Model selection for the video game example
Because there are many choices among models to DEMO to a given data set in the mixed
model setting, we DEMO an approach to choosing among the models. Even then,
we must always remember that all models are wrong (because they are idealized
simpliﬁcations of Nature), but some are useful. Sometimes a single best model
15.7. MODEL SELECTION FOR THE VIDEO GAME EXAMPLE
373
is chosen. Sometimes DEMO matter knowledge is used to choose the most useful
models (for DEMO or for interpretation). And sometimes several models, which
diﬀer but DEMO roughly equivalent in terms of ﬁt to the data, are presented DEMO
the ﬁnal summary for a data analysis problem.
Two of the most commonly used methods for model selection are penal-
ized likelihood and testing DEMO individual coeﬃcient or variance estimate p-values.
Other more sophisticated methods include model averaging and cross-validation,
but they will not be covered in this DEMO
15.7.1 Penalized likelihood methods for model selection
Penalized likelihood methods calculate the likelihood of the observed data using
a particular model (see chapter3). But because it is a fact that the likelihood
always goes up DEMO a model gets more complicated, whether or not the addi-
tional DEMO is “justiﬁed”, a model complexity penalty is used. Several
diﬀerent penalized DEMO are available in SPSS, but I recommend using the
BIC (Bayesian information criterion). AIC (Akaike information criterion) is
another commonly used DEMO of model adequacy. The BIC number penalizes
the likelihood based on both the total number of parameters in a model and the
number of DEMO studied. The formula varies between diﬀerent programs based
on whether or not a factor of two is used and whether or not the sign DEMO changed.
In SPSS, just remember that “smaller is better”.
The absolute DEMO of the BIC has no interpretation. Instead the BIC values
can be computed for two (or more) models, and the values compared. A smaller
BIC indicates a better model. A diﬀerence of under 2 is DEMO so you might use
other considerations to choose between models that diﬀer in their BIC values by
less than 2. If one model has DEMO BIC more than 2 lower than another, that is good
evidence DEMO the model with the lower BIC is a better balance between complexity
and good ﬁt (and hopefully is closer to the true model of Nature).
In our video game problem, several diﬀerent models were ﬁt and their BIC
values are shown in table15.5. Based on the “smaller DEMO better” interpretation, the
(ﬁxed) interaction between trial and age group DEMO clearly needed in the model, as is
the random intercept. The DEMO complexity of a random slope is clearly not
justiﬁed. The use of quadratic curves (from inclusion of a trial2 term) is essentially
no DEMO than excluding it, so I would not include it on grounds DEMO parsimony.
374
CHAPTER 15. MIXED MODELS
Interaction
yes
yes
yes
yes
no
random DEMO
yes
no
yes
yes
yes
random slope
no
no
no
yes
no
quadratic curve
no
no
yes
no
no
BIC
718.4
783.8
718.3
727.1
DEMO
Table 15.5: BIC for model selection for the video game example.
DEMO BIC approach to model selection is a good one, although there DEMO some
technical diﬃculties. Brieﬂy, there is some controversy about the appropriate
DEMO for mixed models, and it is probably better to change the DEMO
method from the default “restricted maximum likelihood” to “maximum likeli-
hood” when comparing models that diﬀer only in ﬁxed eﬀects. Of course you
never DEMO if the best model is one you have not checked because you didn’t think
of it. Ideally the penalized likelihood approach is best done DEMO running all rea-
sonable models and listing them in BIC order. If one model is clearly better than
the rest, use that model, DEMO consider whether there are important diﬀering
implications among any group of similar low BIC models.
15.7.2 Comparing models with individual p-values
Another approach to DEMO selection is to move incrementally to one-step more or
less complex models, and use the corresponding p-values to choose between them.
This method has some deﬁciencies, chief of which is that diﬀerent “best” models
can result just from using diﬀerent starting places. Nevertheless, this method,
usually called stepwise model selection , is commonly used.
Variants of step-wise selection include DEMO and backward forms. Forward
selection starts at a simple model, then DEMO all of the reasonable one-step-
more-complicated models and chooses the one with the smallest p-value for the
new parameter. This continues until no addition DEMO have a signiﬁcant
p-value. Backward selection starts at a complicated model and removes the term
with the largest p-value, as long as that p-value is larger than 0.05. There is no
guarantee that any kind of DEMO model” will be reached by stepwise methods, but
in many cases DEMO good model is reached.
15.8. CLASSROOM EXAMPLE
15.8 Classroom example
375
The (fake) data inschools.txtrepresent DEMO randomized experiment of two diﬀerent
reading methods which were randomly assigned to third or ﬁfth grade classrooms,
one per school, for 20 diﬀerent schools. The experiment lasted 4 months. The
outcome is the after minus DEMO diﬀerence for a test of reading given to each
student. The average sixth grade reading score for each school on a diﬀerent
statewide standardized DEMO (stdTest) is used as an explanatory variable for each
school (DEMO).
It seems likely that students within a classroom will be more similar to each
other than to students in other classrooms due to DEMO school level characteris-
tics are measured by the standardized test. Additional unmeasured characteristics
including teacher characteristics, will likely also raise or lower the outcome for a
given classroom.
Cross-tabulation shows that each classroom has either grade DEMO or 5 and either
placebo or control. The classroom sizes are 20 to 30 students. EDA, in the form
of a scatterplot of standardized test scores vs. experimental test score diﬀerence
are shown in ﬁgure15.7. Grade DEMO are represented in color and treatment
diﬀerences by symbol type. There is a clear positive correlation of standardized test
score and the outcome (reading score diﬀerence), indicating that the standardized
test score was a good DEMO of a control variable. The clustering of students within
schools is clear once it is realized that each diﬀerent standardized test score value
represents DEMO diﬀerent school. It appears that ﬁfth graders tend to have a larger
rise than third graders. The plot does not show any obvious eﬀect DEMO treatment.
A mixed model was ﬁt with classroom as the upper level (“subjects” in SPSS
mixed models) and with students at the lower DEMO There are main eﬀects for
stdTest, grade level, and treatment group. There is a random eﬀect (intercept) to
account for school to DEMO diﬀerences that induces correlation among scores for
students within a school. Model selection included checking for interactions among
the ﬁxed eﬀects, and checking the necessity of including the random intercept. The
only change suggested is to DEMO the treatment eﬀect. It was elected to keep the
non-signiﬁcant treatment in the model to allow calculation of a conﬁdence interval
for its eﬀect.
DEMO are some results:
We note that non-graphical EDA (ignoring the DEMO variables) showed
that individual students test score diﬀerences varied between a DEMO of 14 and a
376
CHAPTER 15. MIXED MODELS
Figure 15.7: EDA for school example
Source
Intercept
grade
treatment
stdTest
Numerator df
1
1
1
1
Denominator
df
DEMO
16.1
16.1
15.9
F
14.3
12.9
1.2
25.6
Sig.
0.002
0.002
0.289
<0.0005
Table 15.6: Tests of Fixed Eﬀects for the school example.
15.8. CLASSROOM EXAMPLE
Parameter
Intercept
grade=3
grade=5
treatment=0
treatment=1
stdTest
Estimate
-23.09
DEMO
0
1.79
0
0.44
Std.
Error
6.80
1.65
0
1.63
0
0.09
df
15.9
16.1
.
16.1
.
15.9
t
-3.40
-3.59
.
1.10
DEMO
5.05
Sig.
0.004
0.002
.
0.289
.
<0.0005
95% Conf. Int.
DEMO Upper
Bound Bound
-37.52 -8.67
-9.45 -2.43
. .
-1.67 5.26
. .
0.26 0.63
Table 15.7: Estimates of Fixed Eﬀects for the school example.
377
Parameter
Residual
Intercept(Subject=sc.) Variance
Estimate
25.87
10.05
Std.
Error
1.69
3.94
Wald
Z
15.33
2.55
Sig.
<0.0005
0.011
95% Conf. Int.
Lower Upper
Bound Bound
22.76 29.40
4.67 21.65
Table 15.8: Estimates of Covariance Parameters for the school example.
378 CHAPTER 15. MIXED MODELS
rise of 35 points.
The “Tests of DEMO Eﬀects” table, Table15.6, shows that grade (F=12.9,
p=0.002) and stdTest (F=25.6, p<0.0005) each have a signiﬁcant eﬀect on a stu-
dent’s reading score diﬀerence, but treatment (F=1.2, p=0.289) does DEMO
The “Estimates of Fixed Eﬀects” table, Table15.7, gives the same p-values
plus estimates of the eﬀect sizes and 95% conﬁdence intervals for those DEMO
For example, we are 95% conﬁdent that the improvement seen by DEMO graders is
2.43 to 9.45 more than for third graders. We are particularly interested in the
conclusion that we are 95% conﬁdent that treatment DEMO 0 (control) has an
eﬀect on the outcome that is between 5.26 points more and 1.67 points less than
treatment 1 (new, DEMO treatment).
We assume that students within a classroom perform similarly due to school
and/or classroom characteristics. Some of the eﬀects of the DEMO and school
characteristics are represented by the standardized test which has a standard devi-
ation of 8.8 (not shown), and Table15.7shows that each one unit rise in standard-
ized test score is associated with a DEMO unit rise in outcome on average. Consider
the comparison of schools at the mean vs. one s.d. above the mean of standardized
test score. DEMO values correspond to µstdTest and µstdTest + 8.8. This corresponds
to a 0.44*8.8=3.9 point change in average reading scores for a classroom. In addi-
DEMO, other unmeasured characteristics must be in play because Table15.8shows
that the DEMO classroom-to-classroom variance is 10.05 (s.d.= 3.2 points). In-
dividual student-to-student, diﬀerences with a variance 23.1 (s.d. = 4.8 points),
have DEMO somewhat large eﬀect that either school diﬀerences (as measured by the
DEMO test) or the random classroom-to-classroom diﬀerences.
In summary, we ﬁnd that students typically have a rise in test score over the
four month DEMO (It would be good to center the stdTest values by subtracting
DEMO mean, then rerun the mixed model analysis; this would allow the Intercept to
represent the average gain for a ﬁfth grader with active DEMO, i.e., the baseline
group). Sixth graders improve on average by 5.9 more than third graders. Being in
a school with a higher DEMO test score tends to raise the reading score gain.
Finally there is no evidence that the treatment worked better than the placebo.
In a DEMO: Mixed eﬀects models ﬂexibly give correct estimates of
treatment and other DEMO eﬀects in the presence of the correlated
errors that arise from a data hierarchy.
Chapter 16
Analyzing Experiments with
Categorical Outcomes
Analyzing data with non-quantitative outcomes
DEMO of the analyses discussed up to this point assume a Normal distribution for
the outcome (or for a transformed version of the outcome) DEMO each combination of
levels of the explanatory variable(s). This means that we have only been cover-
ing statistical methods appropriate for quantitative DEMO It is important to
realize that this restriction only applies to the outcome variable and not to the ex-
planatory variables. In this chapter DEMO methods appropriate for categorical
outcomes are presented.
16.1 Contingency tables and chi-square analysis
This section discusses analysis of experiments or observational studies with a DEMO
egorical outcome and a single categorical explanatory variable. We have already
discussed methods for analysis of data with a quantitative outcome and categorical
explanatory DEMO(s) (ANOVA and ANCOVA). The methods in this section are
also useful for observational data with two categorical “outcomes” and no explana-
DEMO variable.
379
380
CHAPTER 16. CATEGORICAL OUTCOMES
16.1.1 Why ANOVA and regression don’t work
DEMO is nothing in most statistical computer programs that would prevent you
from analyzing data with, say, a two-level categorical outcome (usually designated
generically as “success” and “failure”) using ANOVA or regression or ANCOVA.
But if you do, your conclusion will be wrong in a number of diﬀerent ways. The
basic reason that these methods don’t work is that the DEMO of Normality
and equal variance are strongly violated. Remember that these assumptions relate
to groups of subjects with the same levels of all of DEMO explanatory variables.
The Normality assumption says that in each of these groups the outcomes are
Normally distributed. We call ANOVA, ANCOVA, and regression DEMO to this
assumption because moderate deviations from Normality alter the null sampling
distributions of the statistics from which we calculate p-values only a small DEMO
But in the case of a categorical outcome with only a few (as few as two) possible
outcome values, the outcome is so far from the smooth bell-shaped curve of a
Normal distribution, that the null sampling distribution is drastically altered and
the p-value completely unreliable.
The DEMO variance assumption is that, for any two groups of subjects with
DEMO levels of the explanatory variables between groups and the same levels
within groups, we should ﬁnd that the variance of the outcome is the same. If we
consider the case of a binary outcome with coding DEMO and 1=success, the
variance of the outcome can be shown to DEMO equal to pi(1 − pi) where pi is the
probability DEMO getting a success in group i (or, equivalently, the mean DEMO for
group i). Therefore groups with diﬀerent means have diﬀerent variances, violating
the equal variance assumption.
A second reason that regression and ANCOVA are unsuitable for categorical
outcomes is that they are based on the DEMO equation E(Y ) = β0 + x1β1 +
··· + xkβk, which both is inherently quantitative, and can give numbers out of
DEMO of the category codes. The least unreasonable case is when the categorical
outcome is ordinal with many possible values, e.g., coded 1 to DEMO Then for any
particular explanatory variable, say, βi, a one-unit DEMO in xi is associated with
a βi unit change in outcome. This works only over a limited range of xi values,
and then DEMO are outside the range of the outcome values.
For binary outcomes where the coding is 0=failure and 1=success, a mean
outcome of, say, 0.75 corresponds to 75% successes and 25% failures, so we can
think of the prediction as being the probability of success. But again, outside of
some limited range of xi values, the predictions will correspond to the absurdity
16.2. TESTING INDEPENDENCE IN CONTINGENCY TABLES
381
of probabilities less than 0 DEMO greater than 1.
And for nominal categorical variables with more than two levels, the prediction
is totally arbitrary and meaningless.
Using statistical methods designed for Normal, quantitative outcomes
when the outcomes are really categorical gives wrong p-values due
to violation of the Normality and equal variance assumptions, and
also gives meaningless out-of-range predictions for some levels of the
explanatory variables.
DEMO Testing independence in contingency tables
16.2.1 Contingency and independence
A contingency table counts the number of cases (subjects) for each combination of
levels DEMO two or more categorical variables. An equivalent term is cross-tabulation
(see DEMO). Among the deﬁnitions for “contingent” in the The Oxford
English Dictionary is “Dependent for its occurrence or character on or upon some
prior DEMO or condition”. Most commonly when we have two categorical
measures on each unit of study, we are interested in the question of whether the
probability distribution (see section3.2) of the levels of one measure depends DEMO the
level of the other measure, or if it is independent DEMO the level of the second measure.
For example, if we have DEMO treatments for a disease as one variable, and two
outcomes (cured and not cured) as the other outcome, then we are interested DEMO
the probabilities of these two outcomes for each treatment, and we DEMO to know
if the observed data are consistent with a null hypothesis that the true underlying
probability of a cure is the same for DEMO three treatments.
In the case of a clear identiﬁcation of one variable as explanatory and the
other as outcome, we focus on the probability distribution of the outcome and
how it changes or does not change DEMO we look separately at each level of the
explanatory variable. The “no change” case is called independence, and indicates
that knowing the level of the (purported) explanatory variable tells us no more
about the possible DEMO than ignoring or not knowing it. In other words, if the
382
CHAPTER 16. CATEGORICAL OUTCOMES
variables are independent, then the “explanatory” variable doesn’t really explain
anything. But if we ﬁnd evidence to reject the DEMO hypothesis of independence,
then we do have a true explanatory variable, and knowing its value allows us to
reﬁne our predictions about the level of the other variable.
Even if both variables are outcomes, we can test their association in the same
way as just mentioned. In DEMO, the conclusions are always the same when the roles
of the DEMO and outcome variables are reversed, so for this type of analysis,DEMO
choosing which variable is outcome vs. explanatory is immaterial.
Note that if the outcome has only two possibilities then we only need the
probability DEMO one level of the variable rather than the full probability distribution
(DEMO of possible values and their probabilities) for each level of the DEMO
variable. Of course, this is true simply because the probabilities of DEMO levels must
add to 100%, and we can ﬁnd the other DEMO by subtraction.
The usual statistical test in the case of a categorical outcome and a
categorical explanatory variable is whether or not the two DEMO
are independent, which is equivalent to saying that the probability
distribution DEMO one variable is the same for each level of the other
variable.
16.2.2 Contingency tables
It is a common situation to measure two categorical DEMO, say X (with k levels)
and Y (with m DEMO) on each subject in a study. For example, if we measure
gender and eye color, then we record the level of the gender variable and the level
of the eye color variable for each subject. DEMO the ﬁrst task after collecting
the data is to present it in an understandable form such as a contingency table
(also known as a cross-tabulation).
For two measurements, one with k levels and the other with m levels, the
contingency table is a k × m table with cells for each combination of one level
from each variable, and each cell is ﬁlled with the corresponding count (also called
frequency) DEMO units that have that pair of levels for the two categorical variables.
For example, table16.1is a (fake) contingency table showing the results of
asking 271 college students what their favorite music is and what their DEMO ice
16.2. TESTING INDEPENDENCE IN CONTINGENCY TABLES
favorite
music
rap
jazz
classical
rock
DEMO
other
total
chocolate
5
8
12
39
10
4
78
favorite ice cream
vanilla strawberry
10
9
3
10
22
7
61
7
23
DEMO
15
8
5
62
other
38
6
3
9
8
6
70
Table 16.1: Basic ice cream and music contingency table.
total
60
46
22
73
48
22
271
383
cream ﬂavor is. This table was DEMO in SPSS by using the Cross-tabs menu item
under Analysis / Descriptive Statistics. In this simple form of a contingency table
we see the DEMO counts and the marginal counts. The margins are the extra
column on the right and the extra row at the bottom. The cells are DEMO rest of the
numbers in the table. Each cell tells us how many subjects gave a particular pair of
answers to the two questions. DEMO example, 23 students said both that strawberry
is their favorite ice DEMO ﬂavor and that jazz is their favorite type of music. The
right margin sums over ice cream types to show that, e.g., a DEMO of 60 students
say that rap is their favorite music type. The bottom margin sums over music
types to show that, e.g,, 70 students report that their favorite ﬂavor of ice cream
is neither chocolate, vanilla, nor strawberry. The total of either margin, 271, is
sometimes called the “grand total” and represent the total number of subjects.
We DEMO also see, from the margins, that rock is the best liked music genre, and
classical is least liked, though there is an DEMO degree of arbitrariness in this
conclusion because the experimenter was free to choose which genres were in or not
in the “other” group. (The best practice is to allow a “ﬁll-in” if someone’s choice
is not DEMO, and then to be sure that the “other” group has no DEMO with larger
frequencies that any of the explicit non-other categories.) Similarly, chocolate is
the most liked ice cream ﬂavor, and subject to the concern about deﬁning “other”,
vanilla and strawberry are nearly tied for DEMO
Before continuing to discuss the form and content of contingency tables, DEMO is
good to stop and realize that the information in a contingency table represents
results from a sample, and other samples would give somewhat diﬀerent results.
As usual, any diﬀerences that we see in the sample may or may not reﬂect real
384
rap
jazz
favorite
music
classical
rock
folk
other
total
chocolate
5
DEMO
8
17.4%
12
54.5%
39
53.4%
10
20.8%
4
18.2%
78
28.8%
favorite ice cream
vanilla strawberry other
10 7 38
17.7% 11.7% 63.3%
DEMO 23 6
19.6% 50.0% 13.0%
3 4 3
13.6% 18.2% 13.6%
10 15 9
13.7% 20.5% 12.3%
22 8 8
45.8% 16.7% 16.7%
7 DEMO 6
31.8% 22.7% 27.3%
61 62 70
22.5% 22.9% 25.8%
total
60
100%
46
100%
22
100%
73
100%
48
100%
22
100%
271
DEMO
Table 16.2: Basic ice cream and music contingency table with row DEMO
CHAPTER 16. CATEGORICAL OUTCOMES
diﬀerences in the population, so you should DEMO careful not to over-interpret the
information in the contingency table. In this sense it is best to think of the
contingency table as a DEMO of EDA. We will need formal statistical analysis to
test hypotheses about the population based on the information in our sample.
Other information that DEMO be present in a contingency table includes various
percentages. So-called row percents add to 100% (in the right margin) for each
row of DEMO table, and column percents add to 100% (in the bottom margin) for
each column of the table.
For example, table16.2shows the ice DEMO and music data with row percents.
In SPSS the Cell button brings up check boxes for adding row and/or column
percents. If one DEMO is clearly an outcome variable, then the most useful and
readable DEMO of the table is the one with cell counts plus percentages that
add up to 100% across all levels of the outcome for each DEMO of the explanatory
variable. This makes it easy to compare the outcome distribution across levels
of the explanatory variable. In this example there is DEMO clear distinction of the
roles of the two measurements, so arbitrarily DEMO one to sum to 100% is a good
approach.
16.2. TESTING INDEPENDENCE IN CONTINGENCY TABLES
385
Many important things can be DEMO from this table. First, we should look
for the 100% numbers DEMO see which way the percents go. Here we see 100% on the
right side of each row. So for any music type we can DEMO the frequency of each
ﬂavor answer and those frequencies add up to 100%. We should think of those row
percents as estimates of the DEMO population probabilities of the ﬂavors for each
given music type.
Looking at the bottom (marginal) row, we know that, e.g., averaging over all
music types, approximately 26% of students like “other” ﬂavors best, DEMO approx-
imately 29% like chocolate best. Of course, if we repeat DEMO study, we would get
somewhat diﬀerent results because each study looks DEMO a diﬀerent random sample
from the population of interest.
In terms of the main hypothesis of interest, which is whether or not the two
questions are independent of each other, it is equivalent to ask whether all of the
row probabilities are similar to each other and to DEMO marginal row probabilities.
Although we will use statistical methods to assess independence, it is worthwhile
to examine the row (or column) percentages for equality. In this table, we see
rather large diﬀerences, e.g., chocolate is high for classical and rock music fans,
but low for DEMO music fans, suggesting lack of independence.
A contingency table summarizes the DEMO from an experiment or ob-
servational study with two or more categorical variables. Comparing
a set of marginal percentages to the corresponding row or DEMO
percentages at each level of one variable is good EDA for checking
independence.
16.2.3 Chi-square test of Independence
The most commonly used test of DEMO for the data in a contingency ta-
ble is the chi-square test of independence. In this test the data from a k by
m DEMO table are reduced to a single statistic usually called either X 2 or
χ2 (chi-squared), although X 2 is better because statistics usually have Latin, not
Greek letters. The null hypothesis is that the two categorical variables are inde-
pendent, or equivalently that the distribution of either variable is the same at each
level of the other variable. The DEMO hypothesis is that the two variables are
386
CHAPTER 16. CATEGORICAL OUTCOMES
not independent, or equivalently that the distribution of one variable depends on
(varies with) the level of the DEMO
If the null hypothesis of independence is true, then the X DEMO statistic is asymp-
totically distributed as a chi-square distribution (see section3.9.6) with (k −
1)(m−1) df. Under the alternative hypothesis of non-independence the X 2 statistic
will be larger on average. The p-value DEMO the area under the null sampling distri-
bution larger than the observed X 2 statistic. The term asymptotically distributed
indicates that the null sampling DEMO can not be computed exactly for a
small sample size, but DEMO the sample size increases, the null sampling distribution
approaches the shape DEMO a particular known distribution, which is the chi-square
distribution in the DEMO of the X 2 statistic. So the p-values are reliable for “large”
sample sizes, but not for small sample sizes. Most textbooks quote a rule that no
cell of the expected counts table (see below) DEMO have less than ﬁve counts for the
X 2 test to be reliable. This rule is conservative, and somewhat smaller counts also
give reliable p-values.
Several alternative statistics are sometimes used instead of the chi-square statis-
DEMO (e.g., likelihood ratio statistic or Fisher exact test), but these will not be covered
here. It is important to realize that these DEMO tests may disagree for small sam-
ple sizes and it is not clear (or meaningful to ask) which one is “correct”.
The calculation DEMO the X 2 statistic is based on the formula
X 2 = k m (Observedij − Expectedij)2
X
=1 j
X
Expectedij
i
=1
where k and m are the number of rows and columns DEMO the contingency table (i.e.,
the number of levels of the DEMO variables), Observedij is the observed count
for the cell with one variable at level i and the other at level j, and Expectedij is
the expected count based on independence. The basic idea here is DEMO each cell
contributes a non-negative amount to the sum, that a DEMO with an observed count
very diﬀerent from expected contributes a lot, DEMO that “a lot” is relative to the
expected count (denominator).
DEMO a computer program is ordinarily used for the calculation, an un-
DEMO of the principles is worthwhile. An “expected counts” table can be
constructed by looking at either of the marginal percentages, and then computing
the expected counts by multiplying each of these percentages by the total counts
DEMO the other margin. Table16.3shows the expected counts for the ice cream exam-
ple. For example, using the percents in the bottom margin of table16.2, if the two
16.2. TESTING INDEPENDENCE IN CONTINGENCY TABLES
favorite
music
rap
jazz
classical
rock
DEMO
other
total
chocolate
17.3
13.2
6.3
21.0
13.8
6.3
78
favorite ice cream
vanilla strawberry
13.5
10.4
5.0
16.4
10.8
5.0
61
13.7
10.5
DEMO
16.7
11.0
5.0
62
other
15.5
11.9
5.7
18.9
12.4
5.7
70
total
60
46
22
73
48
22
271
Table 16.3: Expected counts for ice cream and music contingency table.
387
variables are independent, then we expect 22.9% of people to like strawberry best
among each group DEMO people deﬁned by their favorite music. Because 73 people
like rock best, under the null hypothesis of independence, we expect (on average)
0.229 ∗ 73 = 16.7 people to like rock and strawberry best, as shown in table16.3.
Note that there is no reason that the DEMO counts should be whole numbers,
even though observed counts must be.
By combing the observed data of table16.1with the expected values of table
DEMO, we have the information we need to calculate the X 2 DEMO For the ice
cream data we ﬁnd that
X 2 = (DEMO − 17.3)2
5
! + (10 − 13.5)2 ! DEMO ··· + (6 − 5.7)2 ! = 112.86.
10
6
DEMO for the ice cream example, jazz paired with chocolate shows a DEMO deviation
from independence and of the 24 terms of the X 2 sum, that cell contributes (5 −
17.3)2/5 = 30.258 DEMO the total of 112.86. There are far fewer people who like that
particular combination than would be expected under independence. To test if all
DEMO the deviations are consistent with chance variation around the expected values,
we compare the X 2 statistic to the χ2 distribution with (6 − 1)(4 − 1) = 15 df. This
distribution has DEMO of its probability below 25.0, so with X 2 = 112.86, we reject
H0 at the usual α = 0.05 signiﬁcance level. In DEMO, 0.00001 of the probability is
below 50.5, so the p-value is far less than 0.05. We reject the null hypothesis of
independence of DEMO cream and music preferences in favor of the conclusions that
the distribution of preference of either variable does depend on preference for the
other DEMO
388
CHAPTER 16. CATEGORICAL OUTCOMES
You can choose among several ways to DEMO violation (or non-violation) of the
null hypothesis for a “chi-square test of independence” of two categorical variables.
You should use the context of DEMO problem to decide which one best expresses the
relationship (or lack DEMO relationship) between the variables. In this problem it
is correct to DEMO any of the following: ice cream preference is not independent of
DEMO preference, or ice cream preference depends on or diﬀers by music DEMO,
or music preference depends on or diﬀers by ice cream preference, or knowing a
person’s ice cream preference helps in predicting their music preference, or knowing
a person’s music preference helps in predicting their ice cream preference.
The chi-square test is based on a statistic that is DEMO when the ob-
served cell counts diﬀer markedly from the expected counts under the
null hypothesis condition of independence. The corresponding null
sampling distribution DEMO a chi-square distribution if no expected cell
counts are too small.
Two additional points are worth mentioning in this abbreviated discussion of
testing independence DEMO categorical variables. First, because we want to avoid
very small expected DEMO counts to assure the validity of the chi-square test of
independence, DEMO is common practice to combine categories with small counts into
combined categories. Of course, this must be done in some way that makes sense
in the context of the problem.
Second, when the contingency table is larger than 2 by 2, we need a way to
perform the equivalent of contrast tests. One simple solution is to create subtables
corresponding DEMO the question of interest, and then to perform a chi-square test
DEMO independence on the new table. To avoid a high Type 1 error rate we need
to make an adjustment, e.g., by using a DEMO correction, if this is post-hoc
testing. For example to see if DEMO preference is higher for classical than jazz,
we could compute chocolate vs. non-chocolate counts for the two music types to
get table16.4. This DEMO a X 2 statistic of 8.2 with 1 df, and a DEMO of 0.0042.
If this is a post-hoc test, we need to DEMO that there are 15 music pairs and 4
ﬂavors plus 6 ﬂavor pairs and 6 music types giving 4*15+6*6=96 similar tests, that
might just as easily have been noticed as “interesting”. The Bonferroni correction
implies using DEMO new alpha value of 0.05/96=0.00052, so because 0.0042 > 0.00052,DEMO
we cannot make the post-hoc conclusion that chocolate preference diﬀers for jazz
vs. classical. In other words, if the null hypothesis of independence is true, and we
16.3. LOGISTIC REGRESSION
favorite
music
jazz
classical
total
favorite ice cream
chocolate DEMO chocolate
8 38
17.4% 82.6%
12 10
54.5% 45.5%
20
29.4%
48
70.6%
total
46
100%
22
100%
68
100%
Table 16.4: Cross-tabulation of chocolate for jazz vs. classical.
389
data snoop looking for pairs of DEMO of one factor being diﬀerent for presence
vs. absence of a particular category of the other factor, ﬁnding that one of the 96
diﬀerent p-values is 0.0042 is not very surprising or unlikely.
16.3 Logistic regression
DEMO Introduction
Logistic regression is a ﬂexible method for modeling and testing the relationships
between one or more quantitative and/or categorical explanatory variables and DEMO
binary (i.e., two level) categorical outcome. The two levels of DEMO outcome can
represent anything, but generically we label one outcome “success” DEMO the other
“failure”. Also, conventionally, we use code 1 to represent success and code 0 to
represent failure. Then we can look at DEMO regression as modeling the success
probability as a function of the explanatory variables. Also, for any group of
subjects, the 0/1 coding DEMO it true that the mean of Y represents the observed
fraction of successes for that group.
Logistic regression resembles ordinary linear regression in many DEMO Besides
allowing any combination of quantitative and categorical explanatory variables
(with DEMO latter in indicator variable form), it is appropriate to include functions of
the explanatory variables such as log(x) when needed, as DEMO as products of pairs
of explanatory variables (or more) to represent interactions. In addition, there
is usually an intercept parameter (β0) plus one parameter for each explanatory
variable (β1 through βk), and these are used in the linear combination form: β0 +
390
CHAPTER 16. CATEGORICAL OUTCOMES
x1β1 + ··· + xkβk. We will DEMO this sum eta (written η) for convenience.
Logistic regression diﬀers from ordinary linear regression because its outcome
is binary rather than quantitative. In DEMO linear regression the structural
(means) model is that E(Y ) = η. This is inappropriate for logistic regression
because, among other reasons, the outcome can only take two arbitrary values,
while eta can take any value. The solution to this dilemma is to use the DEMO
model
log
E(Y )
1 − E(Y ) ! DEMO log
Pr(Y = 1)
Pr(Y = 0) ! DEMO η.
Because of the 0/1 coding, E(Y ), read as the “expected value of Y” is equivalent
to the probability of DEMO, and 1 − E(Y ) is the probability of failure. DEMO ratio
of success to failure probabilities is called the odds. Therefore our means model
for logistic regression is that the log of the odds (or just “log odds”) of success
is equal to the linear combination of explanatory variables represented as eta. In
other words, for any explanatory variable j, if βj > 0 then an increase in that
variable is associated with an increase in the chance of success and vice DEMO
The means model for logistic regression is that the log odds of suc-
cess equals a linear combination of the parameters and explanatory
variables.
DEMO shortcut term that is often used is logit of success, which DEMO equivalent to the
log odds of success. With this terminology the means model is logit(S)=η, where
S indicates success, i.e., Y=1.
It takes some explaining and practice to get used to working with DEMO and log
odds, but because this form of the means model DEMO most appropriate for modeling
the relationship between a set of explanatory variables and a binary categorical
outcome, it’s worth the eﬀort.
First consider the term odds, which will always indicate the odds of success
for us. By deﬁnition
odds(Y = 1) =
= Pr(Y = 1) .
Pr(Y = 0)
Pr(Y = 1)
1 − Pr(Y = 1)
The odds of success is deﬁned DEMO the ratio of the probability of success to the
probability of failure. The odds of success (where Y=1 indicates success) contains
16.3. LOGISTIC REGRESSION
Pr(Y = 1)
0
0.1
0.2
0.25
DEMO/3
0.5
2/3
0.75
0.8
0.9
1
Pr(Y = 0)
1
0.9
0.8
0.75
2/3
0.5
1/3
0.25
0.2
DEMO
0
Odds
0
1/9
0.25
1/3
0.5
1
2
3
4
9
∞
Log Odds
-∞
-2.197
-1.383
-1.099
-0.693
0.000
0.693
DEMO
1.386
2.197
∞
Table 16.5: Relationship between probability, odds and log odds.
391
the same information as the probability of success, but is on a diﬀerent scale.
Probability runs from 0 to 1 with 0.5 DEMO the middle. Odds runs from 0 to ∞ with
1.0 in the middle. A few simple examples, shown in table16.5, make this clear.
DEMO how the odds equal 1 when the probability of success and failure are equal.
The fact that, e.g., the odds are 1/9 DEMO 9 for success probabilities of 0.1 and 0.9
respectively demonstrates how 1.0 can be the “center” of the odds range of 0 to
inﬁnity.
DEMO is one way to think about odds. If the odds are 9 or 9/1, which is often
written as 9:1 and read 9 to 1, then this tells us that for every nine successes there
is one failure on average. For odds of 3:1, for every 3 successes there is one failure
on average. For odds equal DEMO 1:1, there is one failure for each success on average.
DEMO odds of less than 1, e.g., 0.25, write it as DEMO:1 then multiply the numerator
and denominator by whatever number gives whole numbers in the answer. In this
case, we could multiple by 4 to get 1:4, which indicates that for every one success
there are four failures on average. As a ﬁnal example, if the odds are 0.4, then this
is 0.4:1 or 2:5 when I multiply by 5/5, so on average there will be ﬁve failures for
every two successes.
To calculate probability, p, when you know DEMO odds use the formula
p =
odds
1 + odds
.
392
CHAPTER 16. CATEGORICAL OUTCOMES
The odds of success is deﬁned as DEMO ratio of the probability of success
to the probability of failure. It ranges from 0 to inﬁnity.
The log odds of success is deﬁned DEMO the natural (i.e., base e, not base 10) log of
the odds of success. The concept of log odds is very hard DEMO humans to understand,
so we often “undo” the log odds to get odds, which are then more interpretable.
Because the log is a natural log, we undo log odds by taking Euler’s constant
(e), which is approximately 2.718, to the power of the log odds. DEMO example, if
the log odds are 1.099, then we can ﬁnd e1.099 as exp(1.099) in most computer
languages or in Google search to ﬁnd that the odds are 3.0 (or 3:1). Alternatively,
in Windows calculator (scientiﬁc view) enter 1.099, then click the Inv (inverse)
check box, and click the “ln” (natural log) button. (The “exp” button is not an
equivalent calculation in Windows DEMO) For your handheld calculator, you
should look up how to do this using 1.099 as an example.
The log odds scale runs from DEMO to +∞ with 0.0 in the middle. So zero
represents the situation where success and failure are equally likely, positive log
odds values represent a greater probability of success than failure, and negative log
odds values represent a greater probability of failure than success. Importantly,
because log DEMO of −∞ corresponds to probability of success of 0, and log DEMO
of +equal eta” cannot give invalid probabilities as predictions for any combination of∞ corresponds to probability of success of 1, the model “log odds of success
explanatory variables.
It is important to note that in addition DEMO population parameter values for an
ideal model, odds and log odds DEMO also used for observed percent success. E.g., if
we observe 5/DEMO successes, then we say that the (observed) odds of success
DEMO 0.2/0.8=0.25.
The log odds of success is simply the natural log of the odds of success.
It ranges from minus inﬁnity to plus DEMO, and zero indicates that
success and failure are equally likely.
As DEMO, any model prediction, which is the probability of success in this situa-
tion, applies for all subjects with the same levels of all of the explanatory variables.
In logistic regression, we are assuming that for any such group of subjects the prob-
16.3. LOGISTIC REGRESSION
393
ability of success, which we can call p, applies individually and independently to
each of the set of similar subjects. These are the conditions that deﬁne a binomial
distribution (see section3.9.1). If we have n subjects all with with the same level
of DEMO explanatory variables and with predicted success probability p, then our er-
DEMO model is that the outcomes will follow a random binomial distribution written
as Binomial(n,p). The mean number of successes will be DEMO product np, and the
variance of the number of success will DEMO np(1 − p). Note that this indicates that
there is no separate variance parameter (σ2) in a logistic regression model; instead
the variance varies with the mean and is determined by the mean.
DEMO error model for logistic regression is that for each ﬁxed combi-
nation of explanatory variables the distribution of success follows the
binomial distribution, with success probability, p, determined by the
means model.
16.3.2 Example and DEMO for logistic regression
The example that we will use for logistic regression is a simulated dataset (LRex.dat)
based on a real experiment where the experimental units are posts to an Internet
forum and the outcome DEMO whether or not the message received a reply within the
ﬁrst hour of being posted. The outcome variable is called “reply” with 0 as DEMO
failure code and 1 as the success code. The posts are all to a single high volume
forum and are computer generated. The time DEMO posting is considered unimportant
to the designers of the experiment. The explanatory variables are the length of
the message (20 to 100 words), whether it is in the passive or active voice (coded
as an indicator variable for the “passive” condition), and the gender of the DEMO
ﬁrst name signed by the computer (coded as a “male” indicator DEMO).
Plotting the outcome vs. one (or each) explanatory variable is not helpful when
there are only two levels of outcome because many DEMO points end up on top of
each other. For categorical explanatory variables, cross-tabulating the outcome
and explanatory variables is good EDA.
For quantitative explanatory variables, one reasonably good possibility is to
break the explanatory variable into several groups (e.g., using Visual Binning in
SPSS), and then DEMO plot the mean of the explanatory variable in each bin vs. the
394
CHAPTER 16. CATEGORICAL OUTCOMES
observed fraction of successes in that bin. DEMO a binning of the
length variable vs. the fraction of successes with separate marks of “0” for active
vs. “1” for passive voice. The DEMO are from a non-parametric smoother (loess)
that helps in identifying DEMO general pattern of any relationship. The main things
you should notice are that active voice messages are more likely to get a quick
reply, as are shorter messages.
10
0
(20,30]
(40,50]
(60,70]
1
Length (words)
Figure 16.1: EDA for forum message DEMO
0
0
1
1
0
0
1
1
0
1
active
passive
0
1
0
1
(80,90]
Pr(success)
0.0
0.2
0.4
0.6
0.8
1.0
16.3. LOGISTIC REGRESSION
395
EDA for continuous explanatory variables can take the DEMO of cate-
gorizing the continuous variable and plotting the fraction of success
vs. failure, possibly separately for each level of some other categorical
explanatory variable(s).
16.3.3 Fitting a logistic regression model
The means model DEMO logistic regression is that
logit(S) = β0 + β1x1 + DEMO + βkxk.
For any continuous explanatory variable, xi, at any ﬁxed levels of all of the other
explanatory variables this is linear on DEMO logit scale. What does this correspond
to on the more natural probability scale? It represents an “S” shaped curve that
either rises or falls (monotonically, without changing direction) as xi increases. If
the curve is rising, as indicated by a positive sign on βi, then it DEMO Pr(S)=1
as xi increases and Pr(S)=0 as xi decreases. For a negative βi, the curve starts
near Pr(S)=1 and falls toward Pr(S)=0. Therefore a logistic regression model is
DEMO appropriate if the EDA suggest a monotonically rising or falling curve. The
curve need not approach 0 and 1 within the observed range of DEMO explanatory
variable, although it will at some extreme values of that DEMO
It is worth mentioning here that the magnitude of βi is related to the steepness
of the rise or fall, and the value of the intercept relates to where the curve sits left
to right.
The DEMO of a logistic regression model involves the computer ﬁnding the best
estimates of the β values, which are called b or B values as in linear regression.
Technically logistic regression is a form of generalized (not general) linear model
and is solved by an iterative method rather than the single step (closed form)
solutions of linear regression.
In SPSS, there are some model selection choices built-in to the logistic regres-
sion module. These are the same as for linear regression and include “Enter” DEMO
just includes all of the explanatory variables, “Backward conditional (stepwise)”
which starts with the full model, then drops possibly unneeded explanatory vari-
ables one at a time to achieve a parsimonious model, and “Forward conditional
396
CHAPTER 16. CATEGORICAL OUTCOMES
Dependent Variable Encoding
Original Value Internal Value
DEMO a quick reply 0
Got a quick reply 1
Table 16.6: DEMO Variable Encoding for the forum example.
(stepwise)” which starts with DEMO simple model and adds explanatory variables until
nothing “useful” can be added. Neither of the stepwise methods is guaranteed to
achieve a “best” model DEMO any ﬁxed criterion, but these model selection techniques
are very commonly DEMO and tend to be fairly good in many situations. Another
way to perform model selection is to ﬁt all models and pick the one DEMO the lowest
AIC or BIC.
The results of an SPSS logistic regression analysis of the forum message ex-
periment using the backward conditional selection DEMO are described here. A
table labeled “Case Processing Summary” indicates that 500 messages were tested.
The critical “Dependent Variable Encoding” table (Table16.6) shows DEMO “Got
a quick reply” corresponds to the “Internal Value” of “1”, DEMO that is what SPSS
is currently deﬁning as success, and the DEMO regression model is estimating the
log odds of getting a quick reply as a function of all of the explanatory variables.
Always check the DEMO Variable Encoding. You need to be certain which
outcome category is the one that SPSS is calling “success”, because if it is not the
one that you are thinking of as “success”, then all of your interpretations will be
backward from the truth.
The next table is Categorical DEMO Codings. Again checking this table is
critical because otherwise you might interpret the eﬀect of a particular categorical
explanatory variable backward from the truth. DEMO table for our example is table
16.7. The ﬁrst column identiﬁes each categorical variable; the sections of the
table for each variable are interpreted entirely separately. For each variable with,
say k levels, the table has k lines, one for each level as indicated in the second
column. The third column shows how many experimental units had each level DEMO
the variable, which is interesting information but not the critical information DEMO
the table. The critical information is the ﬁnal k − 1 columns which explain the
coding for each of theIn our example, we made the coding match the coding we want by using thek − 1 DEMO variables created by SPSS for the variable.
Categorical button and then selecting “ﬁrst” as the “Reference category”. Each
16.3. LOGISTIC REGRESSION
Male gender? Female
Male
Passive Active voice
voice? DEMO voice
Frequency
254
246
238
262
Parameter
coding
(1)
.000
DEMO
.000
1.000
Table 16.7: Categorical Variables Codings for the forum example.
DEMO
Hosmer and Lemeshow Test
Step Chi-square df Sig.
1 4.597 8 0.800
2 4.230 8 0.836
Table 16.8: Hosmer-Lemeshow Goodness of Fit Test for the forum example.
of the k − 1 variables is labeled “(DEMO)” through “(k-1)” and regardless of how we
coded the variable elsewhere in SPSS, the level with all zeros is the “reference
category” (baseline) for the purposes of logistic regression, and each of the k-1
variables is an indicator for whatever level has the Parameter DEMO of 1.000 in
the Categorical Variables Coding table. So for our example the indicators indicate
male and passive voice respectively.
Correct interpretation of logistic DEMO results in SPSS critically
depends on correct interpretation of how both the outcome and ex-
planatory variables are coded.
SPSS logistic regression shows an DEMO section called “Block 0” which
ﬁts a model without any explanatory variables. In backward conditional model
selection Block 1 shows the results of interest. DEMO numbered steps represent
diﬀerent models (sets of explanatory variables) which are checked on the way to
the “best” model. For our example there DEMO two steps, and therefore step 2
represents the ﬁnal, best model, which we will focus on.
398
CHAPTER 16. CATEGORICAL OUTCOMES
One result is the Hosmer and Lemeshow DEMO of goodness of ﬁt, shown
in Table16.8. We only look at DEMO 2. The test is a version of a goodness-of-
ﬁt chi-square test with a null hypothesis that the data ﬁt the model adequately.
Therefore, a p-value larger than 0.05 suggests an adequate model ﬁt, while a small
p-value indicates some problem with the model such as non-monotonicity, variance
inappropriate for the binomial model at each combination of explanatory variables,
DEMO the need to transform one of the explanatory variables. (Note that DEMO and
Lemeshow have deprecated this test in favor of another more recent one, that is
not yet available in SPSS.) In our case, a p-value of 0.836 suggests no problem
with model ﬁt (but the test is not very powerful). In the event of an indication DEMO
lack of ﬁt, examining the Contingency Table for Hosmer and Lemeshow DEMO may
help to point to the source of the problem. This test is a substitute for residual
analysis, which in raw form is uninformative in logistic regression because there are
only two possible values for the DEMO at each ﬁxed combination of explanatory
variables.
The Hosmer-Lemeshow test is a reasonable substitute for residual
analysis in logistic regression.
The Variables in the DEMO table (Table16.9) shows the estimates of the
parameters, their standard DEMO, and p-values for the null hypotheses that each
parameter equals zero. DEMO of this table is the subject of the next section.
16.3.4 Tests in a logistic regression model
The main interpretations for a logistic regression DEMO are for the parameters.
Because the structural model is
logit(S) DEMO β0 + β1x1 + ··· + βkxk
the interpretations are similar to those of ordinary linear regression, but the linear
combination of parameters and explanatory variables gives the log odds of success
rather than the expected DEMO directly. For human interpretation we usually
convert log odds to odds. As shown below, it is best to use the odds scale for inter-
preting coeﬃcient parameters. For predictions, we can convert to the probability
scale for easier interpretation.
16.3. LOGISTIC REGRESSION
length
passive(1)
Constant
B
-0.035
-0.744
1.384
DEMO
0.005
0.212
0.308
Wald
46.384
12.300
20.077
df
1
1
1
Sig.
<0.005
<0.005
<0.005
Exp(B)
0.966
0.475
3.983
Table 16.9: Variables in the equation for the forum message example.
399
The coeﬃcient estimate results from the SPSS section labeled “Variables in the
Equation” are DEMO in table16.9for the forum message example. It is this table
that you should examine to see which explanatory variables are included in the
diﬀerent DEMO, i.e., which means model corresponds to which step. Only results
for step 2 are shown here; step 1 (not shown) indicates that in a model including
all of the explanatory variables the p-value for DEMO is non-signiﬁcant (p=0.268).
This model’s prediction equation is
logit(S) = β0 + βlength(length) + βpassive(passive)
and ﬁlling in the estimates we get
logit(
dS) = 1.384 − 0.035(length) − 0.744(passive).
The intercept is the average log odds of success when all of the explanatory
variables are zero. In this model DEMO is the meaningless extrapolation to an active
voice message with zero words. If this were meaningful, we could say that the
estimated log odds for such messages is 1.384. To get to a more human scale DEMO
take exp(1.384)=e1.384 which is given in the last column of the table as 3.983 or
3.983:1. We can express this as DEMO four successes for every one failure.
We can also convert to the probability scale using the formula p =
i.e., an 80% chance of success. As usual for an intercept, the interpretation of the
estimate is meaningful if setting all explanatory variables to zero is meaningful and
is DEMO a gross extrapolation. Note that a zero log odds corresponds to odds of e0 = 1
which corresponds to a probability of
to interpret DEMO p-value for the intercept (constant) in logistic regression because it
tests whether the probability of success is 0.5 when all explanatory variables equal
DEMO
1
1+1
3.983
1+3.983
= 0.799,
= 0.5. Therefore it is almost never valid
400
CHAPTER 16. CATEGORICAL OUTCOMES
The intercept estimate in logistic regression is DEMO estimate of the log
odds of success when all explanatory variables equal zero. If “all
explanatory variables are equal to zero” is meaningful for DEMO problem,
you may want to convert the log odds to odds or to probability. You
should ignore the p-value for the intercept.
For DEMO k-level categorical explanatory variable like “passive”, SPSS creates k− 1
indicator DEMO and estimates k−1 coeﬃcient parameters labeled Bx(1) through
Bx(k-1)DEMO In this case we only have Bpassive(1) because k = DEMO for the passive
variable. As usual, Bpassive(1) represents the eﬀect of increasing the explanatory
variable by one-unit, and for an indicator variable this is a change from baseline
to the speciﬁed non-baseline condition. The DEMO diﬀerence from ordinary linear
regression is that the “eﬀect” is a change in the log odd of success.
For our forum message example, the estimate of -0.744 indicates that at any
ﬁxed message length, a passive message has a log odds of success 0.744 lower than
a corresponding DEMO message. For example, if the log odds of success for active
DEMO for some particular message length is 1.744, then the log odds DEMO success
for passive messages of the same length is 1.000.
Because log odds is hard to understand we often rewrite the prediction equation
as DEMO like
where B0L = 1.384 − 0.
tiate both sides to get
odds(
dS) = eB0Le−0.744(passive).
The left hand side of this equation is the estimate of the odds of success. Because
e−0.744 DEMO 0.475 and e0 = 1, this says that for active voice DEMO(
for passive voice odds( 0L . In other words, at any message length,dS) = eB0L and
compared to active voice, DEMO odds of success aredS) = 0.475e multiplied (not added) by DEMO
B
to get the odds for passive voice.
So the usual way to interpret the eﬀect of a categorical variable on a binary
outcome DEMO to look at “exp(B)” and take that as the multiplicative change in odds
when comparing the speciﬁed level of the indicator variable DEMO the baseline level.
logit(
dS) = B0L − 0.744(passive)DEMO
035L for some ﬁxed message length, L. Then we exponen-
16.3. LOGISTIC REGRESSION
401
If B=0 and therefore exp(B) is 1.0, then there is no eﬀect of that variable on the
outcome (DEMO the p-value will be non-signiﬁcant). If exp(B) is greater DEMO 1, then
the odds increase for the speciﬁed level compared to DEMO baseline. If exp(B) is less
than 1, then the odds decrease for the speciﬁed level compared to the baseline. In
our example, 0.475 is less than 1, so passive voice, compared to active DEMO, lowers
the odds (and therefore probability) of success at each DEMO length.
It is worth noting that multiplying the odds by a ﬁxed number has very diﬀerent
eﬀects on the probability scale for diﬀerent baseline DEMO values. This is just what
we want so that we can keep the probabilities between 0 and 1. If we incorrectly
claim that for DEMO one-unit increase in x probability rises, e.g., by 0.1, then DEMO
becomes meaningless for a baseline probability of 0.95. But if we say that, e.g., the
odds double for each one unit increase in DEMO, then if the baseline odds are 0.5 or 2
or 9 (with probabilities 0.333, 0.667 and 0.9 respectively) then a one-unit increase
DEMO x changes the odds to 1, 4 and 18 respectively (with probabilities 0.5, 0.8, and
0.95 respectively). Note that all new DEMO are valid, and that a doubling of
odds corresponds to a DEMO probability change for midrange probabilities than for
more extreme probabilities. This discussion also explains why you cannot express
the interpretation of a logistic regression DEMO on the probability scale.
The estimate of the coeﬃcient for an indicator variable of a categorical
explanatory variable in a logistic regression is in DEMO of exp(B). This
is the multiplicative change in the odds of success for the named vs.
the baseline condition when all other DEMO variables are held
constant.
For a quantitative explanatory variable, the interpretation DEMO the coeﬃcient
estimate is quite similar to the case of a categorical explanatory variable. The
diﬀerences are that there is no baseline, and that x can take on any value, not
just 0 and 1. In general, we can say that the coeﬃcient for a given continuous
explanatory variable represents the (additive) change in log odds of success when
DEMO explanatory variable increases by one unit with all other explanatory variables
held constant. It is easier for people to understand if we change to DEMO odds
scale. Then exp(B) represents the multiplicative change in the DEMO of success for
a one-unit increase in x with all other explanatory variables held constant.
For our forum message example, our estimate is that when the voice is ﬁxed
at either active or passive, the log odds of success (getting a reply within one
402
CHAPTER 16. CATEGORICAL OUTCOMES
hour) decreases by 0.035 for each additional word or by 0.35 for each additional
ten words. It is better DEMO use exp(B) and say that the odds are multiplied by DEMO
(making them slightly smaller) for each additional word.
It is even more meaningful to describe the eﬀect of a 10 word increase in DEMO
length on the odds of success. Be careful: you can’t multiply DEMO(B) by ten. There
are two correct ways to ﬁgure this DEMO First you can calculate e−0.35 = 0.71, and
conclude that the DEMO are multiplied by 0.71 for each additional ten words. Or
you can realize that if for each additional word, the odds are multiplied by 0.966,
then adding a word ten times results in multiplying the DEMO by 0.966 ten times.
So the result is 0.96610 = 0.71, DEMO the same conclusion.
The p-value for each coeﬃcient is a test of βx = 0, and if βx = 0, then when x
DEMO up by 1, the log odds go up by 0 and DEMO odds get multiplied by exp(0)=1. In
other words, if DEMO coeﬃcient is not signiﬁcantly diﬀerent from zero, then changes
in that DEMO variable do not aﬀect the outcome.
For a continuous explanatory variable in logistic regression, exp(B) is
the multiplicative change in odds of DEMO for a one-unit increase in
the explanatory variable.
16.3.5 Predictions in a logistic regression model
Predictions in logistic regression are analogous to ordinary linear DEMO First
create a prediction equation using the intercept (constant) and one coeﬃcient
for each explanatory variable (including k − 1 indicators for a k-level categorical
variable). Plug in the estimates of the coeﬃcients and DEMO set of values for the
explanatory variables to get what we called η, above. This is your prediction of
the log odds of success. Take exp(η) to get the odds of success, then compute
DEMO to get the probability of success. Graphs of the probability of success vs.
1+odds
levels of a quantitative explanatory variable, with all other explanatory variable
ﬁxed at some values, will be S-shaped (or its mirror DEMO), and are a good way
to communicate what the means model represents.
For our forum messages example, we can compute the predicted log odds of
success for a 30 word message in passive voice as DEMO = 1.384−0.035(30)−0.744(1) =
16.3. LOGISTIC REGRESSION
403
−0.41. Then the odds of success for such DEMO message is exp(-0.41)=0.664, and the
probability of success is DEMO/1.664=0.40 or 40%.
Computing this probability for all message lengths from 20 to 100 words sep-
arately for both voices gives ﬁgure16.2which is a DEMO summary of the means
model.
active
passive
20
40
60
80
Length (words)
Figure 16.2: Model predictions for forum message example.
100
DEMO(success)
0.0
0.2
0.4
0.6
0.8
1.0
404
CHAPTER 16. CATEGORICAL OUTCOMES
Prediction of probabilities for a set of DEMO variables involves
calculating log odds from the linear combination of coeﬃcient esti-
mates and explanatory variables, then converting to odds and ﬁnally
probability.
16.3.6 Do it in SPSS
In SPSS, Binary Logistic is a choice under Regression on the Analysis menu. The
dialog box for logistic regression is DEMO in ﬁgure16.3. Enter the dependent
variable. In the “Covariates” box enter both quantitative and categorical explana-
tory variables. You do not need to manually DEMO k-level categorical variables
to indicators. Select the model selection method. The default is to “Enter” all
variables, but you might want to switch to one of the available stepwise methods.
You should always select “Hosmer-Lemeshow goodness-of-ﬁt” DEMO Options.
Figure 16.3: SPSS dialog box for logistic regression.
If you DEMO any categorical explanatory variables listed in the “Covariates” box,
click on “Categorical” to open the dialog box shown in ﬁgure16.4. Move only the
16.3. LOGISTIC REGRESSION
405
categorical variables over to the “Categorical Covariates” box. DEMO default is for
SPSS to make the last category the baseline (DEMO) category. For variables
that are already appropriately named indicator variables, like passive and male
in our example, you will want to change the “Reference Category” to “First” to
improve the interpretability of the coeﬃcient tables. DEMO sure to click the “Change”
button to register the change in reference category.
Figure 16.4: SPSS Categorical Deﬁnition dialog box for logistic regression.
The interpretation of the SPSS output is shown in the preceding sections.
406
CHAPTER 16. CATEGORICAL OUTCOMES
Chapter 17
Going beyond this course
407
408
CHAPTER 17. GOING BEYOND THIS COURSE
Index
additive model,268
additivity,248
alpha,158
alternative hypothesis,152
alternative DEMO,294
analysis of covariance, see ANCOVA
analytic comparison, see contrast
ANCOVA,241
ANOVA,171
multiway,267
one-factor, see ANOVA, one-way
one-way,171
DEMO,267
ANOVA table,187
antagonism,249
AR1, see autoregressive
association,193
DEMO,177
equal spread,214
ﬁxed-x,214,234
independent errors,162,215
linearity,214
Normality,214
asymptotically distributed,386
autoregressive,360
average,67
balanced design,DEMO
Bayesian Information Criterion,373
Bernoulli distribution,54
between-subjects design,272, see DEMO,
between-subjects
between-subjects factor, see factor, between-
subjects
bias,10
BIC, see Bayesian Information Criterion
bin,73
binary,389
binomial distribution,54
blind
double, see double blind
triple, see triple blind
blinding,197
block DEMO,194
blocking,208
Bonferroni correction,327
boxplot,79
carry-over,340
causality,193
cell,272
cell counts,382
cells,382
Central Limit Theorem,52
central DEMO,37,67
Chebyshev’s inequality,39
chi-square distribution,59
chi-square test,385
CI, see conﬁdence interval
CLT, see central limit theorem
coeﬃcient,214
409
410
coeﬃcient of variation,38
column percent,384
complex hypothesis, see hypothesis, com-
plex
compound symmetry,349,360
concept map,6
conditional distribution,44
conﬁdence interval,159,167
confounding,194
contingency table,381
contingency tables,382
DEMO,320
contrast coeﬃcient,321
contrast hypothesis,319
complex,320
simple,320
control group,198
control variable,208
correlation,46
correlation matrix,47
counterbalancing,341
DEMO,149
covariance,46
covariate,208,267
cross-tabulation,89
custom hypotheses, see DEMO
CV, see coeﬃcient of variation
data snooping,326
decision rule,158
DEMO of freedom,59,98
dependent variable, see variable, outcome
design
between-subjects,339
mixed,339
within-subjects,339
df, see degrees of freedom
distribution
INDEX
conditional, see conditional distribu-
tion
joint, see joint distribution
marginal, see marginal distribution
multivariate,341
double blind,197
dummy variable,254
DV, see variable, dependent
EDA,3
eﬀect size,163,308
EMS, see expected DEMO square
error,161,215
Type 1,155,203
Type 2,159,163,296
error model, see model, error
eta,389
event,20
example
DEMO,344
expected mean square,305
expected values,35
experiment,196
explanatory variable, see variable, ex-
planatory
exploratory data analysis,3
extrapolate,214
F-critical,DEMO
F-distribution,60
factor
between-subjects,339
ﬁxed,346
random,346
within-subjects,339
false negative,302
false positive,302
fat tails,82
INDEX
411
ﬁxed factor, see factor, ﬁxed
frequencies, see tabulation
frequency,382
Gaussian distribution,57
gold standard,218
grand mean,180
Hawthorne eﬀect,DEMO
HCI,143
histogram,73
Hosmer-Lemeshow Test,397
hypothesis
complex,152
point,152
iid,50
independence,31
independent variable, see variable, ex-
planatory
indicator DEMO,21,254
interaction,12,247
interaction plot,270
interpolate,214
interquartile range,70
IQR, see interquartile range
IV, see variable, independent
joint distribution,42
kurtosis
population,39
sample,71
learning eﬀect,341
level,15
linear DEMO, see regression, linear
log odds,392
logistic regression,389
logit,390
main eﬀects,248,253
marginal counts,382
marginal distribution,44
margins,382
DEMO,197
mean,67
population,35
mean square,178
mean squared error,236
means model, see model, structural
measure,9
median,67
mediator,12
DEMO design, see design, mixed
mode,68
model
error,4,150
means, see model, structural
noise, see model, error,150
structural,4,DEMO
model selection,373
models,4
moderator,12
Moral Sentiment,172
MS, DEMO mean square
MSE,236
multinomial distribution,56
multiple comparisons,326
multiple correlation coeﬃcient,236
multivariate distributions,341
n.c.p., see non-centrality parameter
negative binomial distribution,57
noise model, see model, error
non-centrality parameter,295,309
Normal DEMO,57
null hypothesis,152
412
null sampling distribution, see sampling
distribution, null
observational study,196
DEMO,390
one-way ANOVA, see ANOVA, one-way
operationalization,9
outcome, see DEMO, outcome
outlier,65,81
p-value,156
parameter,35,67
pdf, see probability density function
penalized likelihood,373
placebo eﬀect,197
planned comparisons,324
DEMO, see probability mass function
point hypothesis, see hypothesis, point
Poisson DEMO,57
population,34
population kurtosis, see kurtosis, popu-
lation
population mean, see mean, population
population skewness, see skewness, pop-
ulation
population DEMO deviation, see stan-
dard deviation, population
population variance, see variance, pop-
ulation
post-hoc comparisons,326
power,163,296
precision,206
probability,19
DEMO,31
marginal,32
probability density function,26
probability mass function,24
proﬁle plot,270
INDEX
QN plot, see quantile-normal plot
QQ plot, see DEMO plot
quantile-normal plot,83
quantile-quantile plot,83
quartiles,70,79
R squared,236
random factor, see factor, random
random treatment assignment,194
random DEMO,20
randomization, see random treatment as-
signment
range,71
recoding,119
DEMO
simple linear,213
reliability,10
repeated measure,339
residual,161
residual vs. ﬁt plot,229
residuals,220,222
robustness,4,68,163
row percent,DEMO
sample,34,64
convenience,35
simple random,50
sample deviations,69
sample space,20
sample statistics,51,65
sampling distribution,51,67
alternative,293,DEMO
null,154
Schwartz’s Bayesian Criterion, see Bayesian
Information Criterion
SE, see standard error
serial correlation,215
side-by-side boxplots,95
INDEX
413
signal, see model, structural text import wizard,111
signiﬁcance DEMO,158 value labels,108
simple random sample, see sample, sim- variable deﬁnition,107
ple random variable view,103
Simpson’s paradox,209 visual binning,DEMO
skewness SS, see sum of squares
population,39 standard deviation,70
DEMO,71 population,38
sources of variation, see variation, sources standard error,167
of standardized coeﬃcients,226
sphericity,349 statistic,50
spread,38,69 DEMO signiﬁcance,158
SPSS stem and leaf plot,78
boxplot,133 stepwise model selection,374
correlation,125 structural model, see model, structural
creating variables,DEMO substantive signiﬁcance,160
cross-tabulate,123 sum of squares,69
data editor,102 support,21
data transformation,116 synergy,249
data view,102 Syntax (in SPSS),103
descriptive statistics,124
dialog recall,104
Excel ﬁles,111
explore,139
frequencies,123
functions,118
histogram,131
importing data,111
measure,107
DEMO,126
overview,102
quartiles,126
recoding,119
automatic,120
scatterplot,134
regression line,135
smoother line,135
tabulate,123
t-distribution,59
tabulation,63
transformation,DEMO,116
triple blind,198
true negative,302
true positive,302
Type 1 error, see error, Type 1
Type 2 error, see error, DEMO 2
uncorrelated,46
units
observational,34
unplanned comparisons,326
validity
construct,11,199
external,201
internal,193
414
variable,9
classiﬁcation
by role,11
by type,12
dependent, see variable, outcome
explanatory,11
independent, see variable, explana-
tory
mediator, DEMO mediator
moderator, see moderator
outcome,11
variance,69
population,38
variation
DEMO of,205
within-subjects design,207, see design,
within-subjects
within-subjects factor, see factor, within-
subjects
Z-score,226
INDEX{1g42fwefx}