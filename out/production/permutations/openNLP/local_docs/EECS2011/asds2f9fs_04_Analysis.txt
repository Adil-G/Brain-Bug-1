<-----Page 0----->Analysis of
Algorithms

Input

Last Update: Aug 21, 2014

Algorithm

EECS2011: Analysis of Algorithms

Output

1

<-----Page 1----->Part 1:
Running Time

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

2

<-----Page 2----->Running Time

Running Time

â€¢ Most algorithms transform input
objects into output objects.
â€¢ The running time of an
algorithm typically grows with
the input size.
â€¢ Average case time is often
difficult to determine.
â€¢ We focus on the worst case
running time.
o Easier to analyze
o Crucial to applications such as
games, finance and robotics

Last Update: Aug 21, 2014

best case
average case
worst case
120
100
80
60
40
20
0

1000

EECS2011: Analysis of Algorithms

2000

3000

4000

Input Size

3

<-----Page 3----->Experimental
Studies

8000
7000

Time (ms)

â€¢ Write a program
implementing the algorithm
â€¢ Run the program with
inputs of varying size and
composition, noting the
time needed
â€¢ Plot the results

9000

6000
5000
4000
3000
2000
1000
0
0

50

100

Input Size

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

4

<-----Page 4----->Limitations of Experiments
â€¢ It is necessary to implement the algorithm, which
may be difficult, time consuming or costly.
â€¢ Results may not be indicative of the running time
on other inputs not included in the experiment.
â€¢ In order to compare two algorithms, the same
hardware and software environments must be
used.

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

5

<-----Page 5----->Theoretical Analysis
â€¢ Uses a high-level description of
the algorithm instead of an implementation
â€¢ Characterizes running time as a function of the
input size, n
â€¢ Takes into account all possible inputs
â€¢ Allows us to evaluate the speed of an algorithm
independent of the hardware/software
environment
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

6

<-----Page 6----->Pseudocode
â€¢
â€¢
â€¢
â€¢
â€¢

High-level description of an algorithm
More structured than English prose
Less detailed than a program
Preferred notation for describing algorithms
Hides program design issues

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

7

<-----Page 7----->Pseudocode Details
â€¢ Method call

â€¢ Control flow
â€“
â€“
â€“
â€“
â€“

if â€¦ then â€¦ [else â€¦]
while â€¦ do â€¦
repeat â€¦ until â€¦
for â€¦ do â€¦
Indentation replaces braces

â€¢ Method declaration
Algorithm method (arg [, argâ€¦])
Input â€¦
Output â€¦

Last Update: Aug 21, 2014

method (arg [, argâ€¦])

â€¢ Return value
return expression

â€¢ Expressions:
ï‚¬ Assignment
ï€½ Equality testing
n2 Superscripts and other
mathematical formatting
allowed

EECS2011: Analysis of Algorithms

8

<-----Page 8----->The Random Access Machine
(RAM) Model
A RAM consists of
â€¢ A CPU
â€¢ A potentially unbounded bank of
memory cells, each of which can hold
an arbitrary number or character
â€¢ Memory cells are numbered and
accessing any cell in memory takes
unit time

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

2

1

0

9

<-----Page 9----->Seven Important Functions
ï± Seven functions that often appear in algorithm analysis:
ï® Constant ï‚» 1
ï® Logarithmic ï‚» log n
ï® Linear ï‚» n
ï® Quadratic ï‚» n2
ï® Cubic ï‚» n3

T(n)

ï® N-Log-N ï‚» n log n

ï® Exponential ï‚» 2n

ï± In a log-log chart,
the slope of the line
corresponds to the growth rate

1E+29
1E+27
1E+25
1E+23
1E+21
1E+19
1E+17
1E+15
1E+13
1E+11
1E+9
1E+7
1E+5
1E+3
1E+1
1E-1
1E-1

Cubic
Quadratic

Linear

1E+2

1E+5

1E+8

n
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

10

<-----Page 10----->Primitive Operations
â€¢ Basic computations performed
by an algorithm
Examples:
â€¢ Identifiable in pseudocode
â€“ Evaluating an expression
â€“ Assigning a value to a
â€¢ Largely independent from the
variable
programming language
â€“ Indexing into an array
â€¢ Exact definition not important
â€“ Calling a method
(we will see why later)
â€“ Returning from a method
â€¢ Assumed to take a constant
amount of time in the RAM model

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

11

<-----Page 11----->Counting Primitive Operations
By inspecting the pseudocode, we can determine the maximum
number of primitive operations executed by an algorithm, as a
function of the input size

STEP

3

4

5

6

7

8

TOTAL

# ops

2

2

1+2n

2n

0 to 2n

1

4n+6 to 6n+6

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

12

<-----Page 12----->Estimating Running Time
â€¢ Algorithm arrayMax executes 6n + 6 primitive
operations in the worst case, 4n + 6 in the best case.
Define:
a = Time taken by the fastest primitive operation
b = Time taken by the slowest primitive operation

â€¢ Let T(n) be worst-case time of arrayMax. Then
a (4n + 6) ï‚£ T(n) ï‚£ b(6n + 6)
â€¢ Hence, the running time T(n) is bounded by two
linear functions
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

13

<-----Page 13----->Growth Rate of Running Time
â€¢ Changing the hardware/ software environment
o Affects T(n) by a constant factor, but
o Does not alter the growth rate of T(n)

â€¢ The linear growth rate of the running time T(n) is
an intrinsic property of algorithm arrayMax

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

14

<-----Page 14----->Why Growth Rate Matters
if runtime is...

time for n + 1

time for 2 n

time for 4 n

c lg n

c lg (n + 1)

c (lg n + 1)

c(lg n + 2)

cn

c (n + 1)

2c n

4c n

c n lg n

~ c n lg n
+ cn

2c n lg n +
2cn

4c n lg n +
4cn

c n2

~ c n2 + 2c n

4c n2

16c n2

c n3

~ c n3 + 3c n2

8c n3

64c n3

c 2n

c 2 n+1

c 2 2n

c 2 4n

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

runtime
quadruples
when
problem
size
doubles

15

<-----Page 15----->Comparison of Two Algorithms
insertion sort is

n2 / 4

merge sort is

2 n lg n

sort a million items?
insertion sort takes
roughly 70 hours
while

merge sort takes
roughly 40 seconds
This is a slow machine, but if
100 x as fast, then itâ€™s 40 minutes
versus less than 0.5 seconds
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

16

<-----Page 16----->Constant Factors
â€¢ The growth rate is not
affected by
T(n)

o constant factors or
o lower-order terms

â€¢ Examples
o 102n + 105
is a linear function
o 105n2 + 108n
is a quadratic function

1E+25
1E+23
1E+21
1E+19
1E+17
1E+15
1E+13
1E+11
1E+9
1E+7
1E+5
1E+3
1E+1
1E-1
1E-1

Quadratic
Quadratic

Linear
Linear

1E+2

1E+5

1E+8

n

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

17

<-----Page 17----->Big-Oh Notation
â€¢ Given functions f(n) and
g(n), we say that f(n) is
O(g(n)) if there are
positive constants
c and n0 such that
f(n) ï‚£ cg(n) for n ï‚³ n0
â€¢ Example: 2n + 10 is O(n)
o
o
o
o

2n + 10 ï‚£ cn
(c ï€­ 2) n ï‚³ 10
n ï‚³ 10/(c ï€­ 2)
Pick c = 3 and n0 = 10

Last Update: Aug 21, 2014

10,000
3n
2n+10

1,000

n

100

10

1
1

EECS2011: Analysis of Algorithms

10

100

1,000

n

18

<-----Page 18----->Big-Oh Example
1,000,000

â€¢ Example:
the function n2 is not O(n)

n^2
100n

100,000

10n

o n2 ï‚£ cn
10,000
o nï‚£c
o The above inequality cannot 1,000
be satisfied for all sufficiently
100
large n, since c must be a
constant

n

10
1
1

10

100

1,000

n
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

19

<-----Page 19----->More Big-Oh Examples
ï±

7n - 2
7n-2 is O(n)
need c > 0 and n0 ï‚³ 1 such that 7 n - 2 ï‚£ c n for n ï‚³ n0
this is true for c = 7 and n0 = 1

ï±

3 n3 + 20 n2 + 5
3 n3 + 20 n2 + 5 is O(n3)
need c > 0 and n0 ï‚³ 1 such that 3 n3 + 20 n2 + 5 ï‚£ c n3 for n ï‚³ n0
this is true for c = 4 and n0 = 21

ï±

3 log n + 5
3 log n + 5 is O(log n)
need c > 0 and n0 ï‚³ 1 such that 3 log n + 5 ï‚£ c log n for n ï‚³ n0
this is true for c = 8 and n0 = 2

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

20

<-----Page 20----->Big-Oh and Growth Rate
â€¢ The big-Oh notation gives an upper bound on the
growth rate of a function
â€¢ The statement â€œf(n) is O(g(n))â€ means that the
growth rate of f(n) is no more than the growth rate
of g(n)
â€¢ We can use the big-Oh notation to rank functions
according to their growth rate

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

21

<-----Page 21----->Big-Oh Rules
â€¢ If f(n) is a polynomial of degree d,
then f(n) is O(nd), i.e.,
o drop lower-order terms
o drop constant factors

â€¢ Use the smallest possible class of functions
o Say â€œ2n is O(n)â€ instead of â€œ2n is O(n2)â€

â€¢ Use the simplest expression of the class
o Say â€œ3n + 5 is O(n)â€ instead of â€œ3n + 5 is O(3n)â€

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

22

<-----Page 22----->Asymptotic Algorithm Analysis
â€¢ The asymptotic analysis of an algorithm
determines the running time in big-Oh notation
â€¢ To perform the asymptotic analysis
o We find the worst-case number of primitive
operations executed as a function of the input size
o We express this function with big-Oh notation

â€¢ Example:
o We say that algorithm arrayMax â€œruns in O(n) timeâ€

â€¢ Since constant factors and lower-order terms are
eventually dropped anyhow, we can disregard
them when counting primitive operations
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

23

<-----Page 23----->Computing Prefix Averages
â€¢ We further illustrate
asymptotic analysis with two
algorithms for prefix averages
â€¢ The i-th prefix average of an
array X is average of the first
(i + 1) elements of X:
A[i] = (X[0] + X[1] + â€¦ + X[i])/(i+1)

35

X
A

30
25
20
15
10

â€¢ Computing the array A of
prefix averages of another
array X has applications to
financial analysis
Last Update: Aug 21, 2014

5
0

EECS2011: Analysis of Algorithms

1

2

3

4

5

6

7

24

<-----Page 24----->Prefix Averages (Quadratic)
The following algorithm computes prefix averages in
quadratic time by applying the definition

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

25

<-----Page 25----->Arithmetic Progression
â€¢ The running time of
prefixAverage1 is
O(1 + 2 + â€¦+ n)
â€¢ The sum of the first n
integers is n(n + 1) / 2
â€“ There is a simple visual
proof of this fact

â€¢ Thus, algorithm
prefixAverage1 runs in
O(n2) time
Last Update: Aug 21, 2014

7
6
5
4
3
2
1
0
1

EECS2011: Analysis of Algorithms

2

3

4

5

6
26

<-----Page 26----->Prefix Averages 2 (Linear)
The following algorithm uses a running sum to improve efficiency

Algorithm prefixAverage2 runs in O(n) time!
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

27

<-----Page 27----->Math you need to Review
â€¢ Properties of powers:
ğ‘ğ‘+ğ‘ = ğ‘ğ‘ âˆ— ğ‘ğ‘
ğ‘ğ‘âˆ’ğ‘ = ğ‘ğ‘ / ğ‘ğ‘

â€¢ Summations
â€¢ Powers

ğ‘

â€¢ Logarithms
â€¢ Proof techniques
â€“ Induction

â€“ ...

â€¢ Basic probability

ğ‘âˆ—ğ‘

ğ‘ ğ‘

= ğ‘
ğ‘ğ‘ = ğ‘ğ‘ logğ‘ğ‘ = ğ‘ ğ‘ logğ‘ğ‘
â€¢ Properties of logarithms:
log ğ‘ ğ‘¥ âˆ— ğ‘¦ = log ğ‘ ğ‘¥ + log ğ‘ ğ‘¦
log ğ‘ ğ‘¥/ğ‘¦ = log ğ‘ ğ‘¥ âˆ’ log ğ‘ ğ‘¦
log ğ‘ ğ‘¥ ğ‘ = ğ‘ log ğ‘ ğ‘¥
ğ‘¥ log ğ‘¦ = ğ‘¦ log ğ‘¥
log ğ‘ ğ‘¥ = log ğ‘ ğ‘¥ / log ğ‘ ğ‘

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

28

<-----Page 28----->Relatives of Big-Oh
big-Omega
ï®

f(n) is ï—(g(n)) if there is a constant c > 0
and an integer constant n0 ï‚³ 1 such that

f(n) ï‚³ c g(n)

for n ï‚³ n0

big-Theta
ï®

f(n) is ï‘(g(n)) if there are constants câ€™ > 0 and câ€™â€™ > 0
and an integer constant n0 ï‚³ 1 such that
câ€™ g(n) ï‚£ f(n) ï‚£ câ€™â€™ g(n)

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

for n ï‚³ n0
29

<-----Page 29----->Intuition for Asymptotic
Notation
ï± big-Oh

f(n) is O(g(n))
if f(n) is asymptotically
less than or equal to g(n)

ï± big-Omega

f(n) is ï—(g(n))
if f(n) is asymptotically
greater than or equal to g(n)

ï± big-Theta

f(n) is ï‘(g(n))
if f(n) is asymptotically
equal to g(n)

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

30

<-----Page 30----->Example Uses of the
Relatives of Big-Oh
ï®

ï®

5n2 is ï—(n2)
f(n) is ï—(g(n)) if there is a constant c > 0 and an integer constant n0 ï‚³ 1
such that f(n) ï‚³ c g(n) for n ï‚³ n0 .
Let c = 5 and n0 = 1.
5n2 is ï—(n)

f(n) is ï—(g(n)) if there is a constant c > 0 and an integer constant n0 ï‚³ 1
such that f(n) ï‚³ c g(n) for n ï‚³ n0 .
Let c = 1 and n0 = 1.

ï®

5n2 is ï‘(n2)
f(n) is ï‘(g(n)) if it is ï—(n2) and O(n2). We have already seen the former,
for the latter recall that f(n) is O(g(n)) if there is a constant c > 0 and
an integer constant n0 ï‚³ 1 such that f(n) < c g(n) for n ï‚³ n0 .
Let c = 5 and n0 = 1.

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

31

<-----Page 31----->Part 1: Summary
â€¢ Analyzing running time of algorithms
o Experimentation & its limitations
o Theoretical analysis

â€¢
â€¢
â€¢
â€¢
â€¢

Pseudo-code
RAM: Random Access Machine
7 important functions
Asymptotic notations: O(), ï—() , ï‘()
Asymptotic running time analysis of algorithms

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

32

<-----Page 32----->Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

33

<-----Page 33----->Part 2: Correctness

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

34

<-----Page 34----->Outline
â€¢ Iterative Algorithms:
Assertions and Proofs of Correctness
â€¢ Binary Search: A Case Study

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

35

<-----Page 35----->Assertions
â€¢ An assertion is a statement about the state of the data
at a specified point in your algorithm.
â€¢ An assertion is not a task for the algorithm to perform.
â€¢ You may think of it as a comment that is added for the
benefit of the reader.

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

36

<-----Page 36----->Loop Invariants
â€¢ Binary search can be implemented as an iterative
algorithm (it could also be done recursively).
â€¢ Loop Invariant: An assertion about the current state
useful for designing, analyzing and proving the
correctness of iterative algorithms.

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

37

<-----Page 37----->Other Examples of Assertions
â€¢ Pre-conditions: Any assumptions that must
be true about the input instance.
â€¢ Post-conditions: The statement of what
must be true when the algorithm/program
returns.
â€¢ Exit-condition: The statement of what must
be true to exit a loop.

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

38

<-----Page 38----->Iterative Algorithms
Take one step at a time
towards the final destination
loop {
if (done) { exit loop }

take step
}

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

39

<-----Page 39----->From Pre-Condition to Post-Condition
Pre-Condition

Post-Condition
Loop Invariant

Loop

Post-Loop

Pre-Loop

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

40

<-----Page 40----->Establishing Loop Invariant
1. from the pre-condition on the input instance,
establish the loop invariant.

1

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

41

<-----Page 41----->Maintain Loop Invariant
2

â€¢ Suppose that
1) We start in a safe location (loop invariant
just established from pre-condition)
2) If we are in a safe location (loop invariant), we
always step to another safe location (loop invariant)

â€¢ Can we be assured that the computation will
always keep us in a safe location?
â€¢ By what principle?
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

42

<-----Page 42----->Maintain Loop Invariant
By Induction the computation will always
be in a safe location.
ğ‘†(ğ‘–) = loop invariant
at the end of iteration ğ‘–
(beginning of iteration ğ‘– + 1)
1

ğ‘†(0)
ğ‘ğ‘›ğ‘‘

2
Last Update: Aug 21, 2014

âŸ¹ âˆ€ğ‘–, ğ‘† ğ‘–

âˆ€ğ‘–, ğ‘† ğ‘– âŸ¹ ğ‘† ğ‘– + 1
EECS2011: Analysis of Algorithms

43

<-----Page 43----->Ending The Algorithm
â€¢ Define Exit Condition
â€¢ Termination: With sufficient progress,
the exit condition will be met.
â€¢ When we exit, we know

3

o loop invariant is true
o exit condition is true

3) from these we must establish the post-condition.
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

44

<-----Page 44----->Iterative Algorithm
Loop-Invariant

Pre-Condition

Exit-Condition

Post-Condition

YES

1

NO

Pre-loop

Post-loop

3
2

Last Update: Aug 21, 2014

Loop Body

EECS2011: Analysis of Algorithms

45

<-----Page 45----->Definition of Correctness
<PreCond> & <code> ïƒ <PostCond>
If the input meets the pre-conditions,
then the output must meet the post-conditions.
If the input does not meet the preconditions, then
nothing is required.

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

46

<-----Page 46----->Binary Search:
a case study

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

47

<-----Page 47----->Define Problem: Binary Search
â€¢ PreConditions
â€“ Key
25
â€“ Sorted indexed List A
3

5

6

13

18

21

21

25

36

43

49

51

53

60

72

74

83

88

91

95

51

53

60

72

74

83

88

91

95

â€¢ PostConditions
â€“ Find key in list (if there).
3

5

6

13

18

Last Update: Aug 21, 2014

21

21

25

36

43

49

EECS2011: Analysis of Algorithms

48

<-----Page 48----->Define Loop Invariant
â€¢ Maintain a sub-list.
â€¢ LI: If the key is contained in the original list,
then the key is contained in the sub-list.
key 25
3

5

6

13

18

Last Update: Aug 21, 2014

21

21

25

36

43

49

51

53

EECS2011: Analysis of Algorithms

60

72

74

83

88

91

49

95

<-----Page 49----->Define Step
â€¢ Cut sub-list in half.
â€¢ Determine which half the key would be in.
â€¢ Keep that half.
mid

key 25
3

5

6

13

18

21

21

25

36

If key â‰¤ A[mid],
then key is in
left half.
Last Update: Aug 21, 2014

43

49

51

53

60

72

74

83

88

91

If key > A[mid],
then key is in
right half.

EECS2011: Analysis of Algorithms

50

95

<-----Page 50----->Define Step
â€¢ It is faster not to check if the middle element
is the key.
â€¢ Simply continue.
key 43
3

5

6

13

18

21

21

25

36

If key â‰¤ A[mid],
then key is in
left half.
Last Update: Aug 21, 2014

43

49

51

53

60

72

74

83

88

91

If key > A[mid],
then key is in
right half.

EECS2011: Analysis of Algorithms

51

95

<-----Page 51----->Make Progress
â€¢ The size of the list becomes smaller.
3

5

6

13

18

21

21

25

36

43

49

51

53

60

72

74

83

88

91

95

3

5

6

13

18

21

21

25

36

43

49

51

53

60

72

74

83

88

91

95

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

52

<-----Page 52----->Exit Condition
key 25
3

5

6

13

18

21

21

25

36

43

49

51

53

60

72

74

83

88

91

95

â€¢ LI: If the key is contained in the
original list, then the key is
contained in the sub-list.

â€¢ If element = key,
return associated
entry.

â€¢ Sub-list contains one element.

â€¢ Otherwise return false.

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

53

<-----Page 53----->Running Time
The sub-list is of size ğ‘›,

ğ‘›
2

,

ğ‘›
4

,

ğ‘›
8

, â€¦, 1

Each step O(1) time.
Total time = O(log n)
key 25
3

5

6

13

18

21

21

25

36

If key â‰¤ A[mid],
then key is in
left half.
Last Update: Aug 21, 2014

43

49

51

53

60

72

74

83

88

91

If key > A[mid],
then key is in
right half.

EECS2011: Analysis of Algorithms

54

95

<-----Page 54----->Algorithm BinarySearch ( A[1..n] , key)
<precondition>: A[1..n] is sorted in non-decreasing order
<postcondition>: If key is in A[1..n], output is its location
pï‚¬1, qï‚¬n
while p < q do
<Loop-invariant>: if key is in A[1..n], then key is in A[p..q]
mid ï‚¬

ğ‘+ğ‘
2

if key ï‚£ A[mid] then q ï‚¬ mid
else p ï‚¬ mid + 1
end while
if key = A[p]
then return (p)
else return (â€œkey not in listâ€)
end algorithm

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

55

<-----Page 55----->Simple, right?
â€¢ Although the concept is simple, binary search is
notoriously easy to get wrong.
â€¢ Why is this?

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

56

<-----Page 56----->Boundary Conditions
â€¢ The basic idea behind binary search is easy to grasp.
â€¢ It is then easy to write pseudo-code that works for a
â€˜typicalâ€™ case.
â€¢ Unfortunately, it is equally easy to write pseudo-code
that fails on the boundary conditions.

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

57

<-----Page 57----->Boundary Conditions
if key ï‚£ A[mid]
then q ï‚¬ mid
else p ï‚¬ mid + 1

or

if key < A[mid]
then q ï‚¬ mid
else p ï‚¬ mid + 1

What condition will break the loop invariant?

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

58

<-----Page 58----->Boundary Conditions

mid

key 36
3

5

6

13

18

21

21

25

36

43

49

51

53

60

72

74

83

88

91

Code: key ï‚³ A[mid] ï‚® select right half

Bug!!
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

59

95

<-----Page 59----->Boundary Conditions
if key ï‚£ A[mid]
then q ï‚¬ mid
else p ï‚¬ mid + 1

OK

Last Update: Aug 21, 2014

if key < A[mid]
then q ï‚¬ mid - 1
else p ï‚¬ mid

OK

EECS2011: Analysis of Algorithms

if key < A[mid]
then q ï‚¬ mid
else p ï‚¬ mid + 1

Not OK !!

60

<-----Page 60----->Boundary Conditions
ïƒª p ï€«qïƒº
mid ï€½ ïƒª
ïƒ« 2 ïƒºïƒ»

ïƒ© p ï€«qïƒ¹
mid ï€½ ïƒª
ïƒª 2 ïƒºïƒº

or

key 25
3

5

6

13

18

21

21

25

Shouldnâ€™t matter, right?
Last Update: Aug 21, 2014

36

43

49

51

53

60

72

74

83

88

91

ïƒ©p ï€«q ïƒ¹
Select mid ï€½ ïƒª
ïƒª 2 ïƒºïƒº

EECS2011: Analysis of Algorithms

61

95

<-----Page 61----->Boundary Conditions

mid

key 25
3

5

6

13

18

21

21

If key â‰¤ A[mid],
then key is in
left half.
Last Update: Aug 21, 2014

ïƒ©p ï€«q ïƒ¹
Select mid ï€½ ïƒª
ïƒª 2 ïƒºïƒº
25

36

43

49

51

53

60

72

74

83

88

91

If key > A[mid],
then key is in
right half.
EECS2011: Analysis of Algorithms

62

95

<-----Page 62----->Boundary Conditions

mid

key 25
3

5

6

13

ïƒ©p ï€«q ïƒ¹
Select mid ï€½ ïƒª
ïƒª 2 ïƒºïƒº

18

21

21

25

36

If key â‰¤ A[mid],
then key is in
left half.
Last Update: Aug 21, 2014

43

49

51

53

60

72

74

83

88

91

If key > A[mid],
then key is in
right half.

EECS2011: Analysis of Algorithms

63

95

<-----Page 63----->Boundary Conditions
No progress toward goal:
Loops Forever!

Another bug!
mid

key 25
3

5

6

13

18

21

21

25

36

If key â‰¤ A[mid],
then key is in
left half.
Last Update: Aug 21, 2014

ïƒ©p ï€«q ïƒ¹
Select mid ï€½ ïƒª
ïƒª 2 ïƒºïƒº
43

49

51

53

60

72

74

83

88

91

If key > A[mid],
then key is in
right half.

EECS2011: Analysis of Algorithms

64

95

<-----Page 64----->Boundary Conditions
ğ‘+ğ‘

ğ‘+ğ‘

ğ‘+ğ‘

mid ï‚¬
2
if key ï‚£ A[mid]
then q ï‚¬ mid
else p ï‚¬ mid + 1

mid ï‚¬
2
if key < A[mid]
then q ï‚¬ mid - 1
else p ï‚¬ mid

mid ï‚¬
2
if key ï‚£ A[mid]
then q ï‚¬ mid
else p ï‚¬ mid + 1

OK

OK

Not OK !!

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

65

<-----Page 65----->Getting it Right
â€¢ How many possible algorithms?
â€¢ How many correct algorithms?
or mid ï‚¬
ğ‘+ğ‘

mid ï‚¬
2
if key ï‚£ A[mid]
then q ï‚¬ mid
else p ï‚¬ mid + 1

?

or if key < A[mid] ?

or

Last Update: Aug 21, 2014

ğ‘+ğ‘
2

then q ï‚¬ mid - 1
?
else p ï‚¬ mid

EECS2011: Analysis of Algorithms

66

<-----Page 66----->Alternative Algorithm:
Less Efficient but More Clear
Algorithm BinarySearch ( A[1..n] , key)
<precondition>: A[1..n] is sorted in non-decreasing order
<postcondition>: If key is in A[1..n], output is its location
pï‚¬1, qï‚¬n
while p < q do
<Loop-invariant>: if key is in A[1..n], then key is in A[p..q]
ğ‘+ğ‘
mid ï‚¬
2
if key < A[mid]
then q ï‚¬ mid - 1
Still O(log n), but with
else if key > A[mid]
slightly larger constant.
then p ï‚¬ mid + 1
else return (mid)
end while
return (â€œkey not in listâ€)
end algorithm
Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

67

<-----Page 67----->Part 2: Summary
From Part 2, you should be able to:
ïƒ˜ Use the loop invariant method to think about iterative algorithms.
ïƒ˜ Prove that the loop invariant is established.
ïƒ˜ Prove that the loop invariant is maintained in the â€˜typicalâ€™ case.
ïƒ˜ Prove that the loop invariant is maintained at all boundary conditions.
ïƒ˜ Prove that progress is made in the â€˜typicalâ€™ case
ïƒ˜ Prove that progress is guaranteed even near termination, so that the
exit condition is always reached.
ïƒ˜ Prove that the loop invariant, when combined with the exit condition,
produces the post-condition.

Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

68

<-----Page 68----->Last Update: Aug 21, 2014

EECS2011: Analysis of Algorithms

69

