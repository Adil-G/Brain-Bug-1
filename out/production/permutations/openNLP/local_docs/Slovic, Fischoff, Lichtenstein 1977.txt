Ann. Rev. Psychol. 1977. 28:1-39
Copyright © 1977 by Annual Reviews DEMO All rights reserved
BEHAVIORAL .DECISION
THEORYl
Paul Slavic, Baruch Fischhaff, and Sarah Lichtenstein2
Decision Research. Eugene. Oregon 97401
Behavioral decision theory has two DEMO facets. normative and descriptive.
The normative theory is concerned with prescribing courses of action that conform
most closely to the decision maker's beliefs DEMO values. Describing these beliefs and
values and the manner in which individuals incorporate them into their decisions
is the aim of descriptive decision theory.
DEMO review is organized around these two facets. The first section deals with
descriptive studies of judgment, inference, and choice; the second section discusses
the development of decision-aiding techniques.
As we reviewed the literature, several trends caught our attention. One is that
decision making is being studied by DEMO from an increasingly diverse set of
disciplines, including medicine, economics, DEMO, political science, geography,
engineering, marketing, and management science, DEMO well as psychology. Neverthe­
less, the importance of psychological concepts is DEMO, in both the normative
and descriptive work. Whereas past descriptive studies DEMO mainly of rather
superficial comparisons between actual behavior and normative models, DEMO
now focuses on the psychological underpinnings of observed behavior. Likewise. the
prescriptive enterprise is being psychologized by challenges to the acceptability of
the fundamental DEMO of utility theory (140, 188, 256).
IThis is the DEMO survey of this topic to appear in the Annual Review of Psychology. Its
predecessors were articles by Edwards (78). Becker & McClintock (DEMO). and Rapoport &
Wallsten (226). The present review covers publications appearing between Janurary 1. 1971,
and December 31. 1975, with occasional exceptions.
2Support for this review was provided by the Advanced Research DEMO Agency of the
Department of Defense and was monitored by the Office of Naval Research under Contract
No. NOOOI4·76·0074 (ARPA Order No. 3052) DEMO subcontract to Oregon Research Insti­
tute from Decisions and Designs, Inc.
DEMO wish to thank Barbara Combs, Robyn Dawes. Lewis R. Goldberg, and Jerry LaCava
for their comments on an early draft of the manuscript.
DEMO Collins and Peggy Roecker have earned our gratitude and respect for handling an
arduous secretarial job with competence and good humor.
+265
Annu. Rev. DEMO 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
2 SLOYIC, FISCHHOFF & LICHTENSTEIN
Second, increasing effort is being devoted DEMO the development of practical methods
for helping people cope with uncertainty. Here psychological research provides
guidance about how to elicit the judgments needed for DEMO techniques.
Third, the field is growing rapidly, as evidenced by the numerous reviews and
bibliographies produced during the past 5 years. Slovic & DEMO (254) re­
viewed the literature on Bayesian and regression approaches to studying informa­
tion processing in decision making and judgment; Dillon (73) covered utility theory
with a view towards its application in agricultural contexts; MacCrimmon (1 87)
examined work in management decision making; Shulman & Elstein (247) discussed
the implications of judgment and decision making research for teachers; Nickerson
& Feehrer (209) searched for studies relevant to the training of decision makers
(since there aren't many, they DEMO for a general review); Beach (2 1a) reviewed
research about experts' judgments under uncertainty; Ylek & Wagenaar (292) sur­
veyed DEMO entire field, and Kozielecki (1 57) and Lee (1 65) have provided its first
textbooks.
A selective and annotated bibliography on Behavioral Decision Theory has been
compiled by Barron (1 8). Kusyszyn (DEMO, 162) has provided bibliographies covering
the psychology of gambling, risk-taking, and subjective probability. Houle (1 24) has
accumulated a massive bibliography DEMO Bayesian statistics and related behavioral
work, which by 1975 included 106 DEMO books, 1322 journal articles, and
about 800 other publications. By the time you read this, Kleiter, Gachowetz &
Huber (1 53) will have assembled the most complete bibliography ever in this field.
They DEMO supplied us with more than 1000 relevant references, all produced
between DEMO 1 and 1975.
To ease cognitive strain (and stay within sight DEMO our page allotment), we have
focused on psychological aspects of individual judgment and decision making. Thus
we omit group and organizational decision making, Bayesian statistics, and much
of the work on the axiomatic formulations of decision theory. Game theory is
reviewed elsewhere in this volume. Even with DEMO narrow focus, we have had to limit
our coverage severely, concentrating on those references to which our prejudices
have led us .
. DEMO RESEARCH
Probabilistic Judgment
Because of the importance of probabilistic reasoning to decision making, consider­
able effort has been devoted to studying how people perceive, process, and evaluate
the probabilities of uncertain events. Early research on "intuitive statistics" led
Peterson & Beach (2 18) to an optimistic conclusion:
... man gambles well. He survives and prospers while using DEMO fallible information to
infer the states of his uncertain environment and to predict future events (p. 29). Experi­
ments that have compared human inferences with those of statistical man show that the
normative model provides DEMO good first approximation for a psychological theory of
inference. Inferences made by subjects are influenced by appropriate variables in appropri­
ate directions (pp. 42-43).
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF DEMO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY 3
MODEL-BASED PARADIGMS One result of this high regard DEMO our intellectual
capability has been a reliance on normative models in descriptive research. Thus
Barclay, Beach & Braithwaite (15) proposed beginning with a normative model and
adjusting its form or parameters to produce a descriptive DEMO This approach is
best exemplified by the study of conservatism-the tendency, DEMO integrating
probabilistic information, to produce posterior probabilities nearer the prior
probabilities DEMO those specified by Bayes' theorem. In 1971, conservatism was
identified as the primary finding of Bayesian information integration research (254).
Reports of the phenomenon have continued to appear, in tasks involving normally
distributed populations (75, 290, 305), and in that old favorite, the DEMO (book­
bag and poker chip) task (3, 196). Even filling the bookbags with male and female
Polish surnames fails to lessen DEMO effect (261). Donnell & DuCharme's (75) subjects
became DEMO when told the normative response, but when the task changed, their
learning failed to generalize. As the next section shows, conservatism occurs only
in certain kinds of inference tasks. In a variety of other settings, people's inferences
are too extreme.
Cascaded inference Real-life problems often have DEMO stages, with inferences
at each stage relying on data which are DEMO inferences from unreliable
observations or reports. For example, a physician who DEMO the condition of the
patient's lungs as a cue for diagnosis must first infer that condition from unreliable
data (e.g. the sound of a thumped chest). Several normative models for such cas­
caded or DEMO inference tasks have been developed in recent years (2 17, 238).
Schum (239) has shown the relevance of cascaded inference models DEMO the judicial
problem of witness credibility and the probative value of witness testimony.
Descriptive studies of cascaded inference, comparing subjects' responses in the
DEMO with a normative model, have consistently shown a result just the DEMO
site of conservatism: subjects' posterior probabilities are more extreme than those
prescribed by the model (100, 217, 266). The extremity of subjects' responses has
been traced-to their use of a simple, but DEMO, "best-guess" strategy (103,
137, 257, 266), which is insensitive to data unreliability.
HEURISTICS AND BIASES In these recent studies DEMO conservatism and cascaded
inference, one can see an increasing skepticism about DEMO normative model's ability
to fulfill its descriptive role, and the DEMO of humans as good intuitive statisticians
is no longer paramount. A psychological Rip van Winkle who dozed off after
reading Peterson & Beach (2 18) and roused himself only recently would be startled
by the widespread change of attitude exemplified by statements such as "In his
evaluation of evidence, man is apparently not a conservative Bayesian: he is not
DEMO at all" (1 38, p. 450), or " ... DEMO's cognitive capacities are not adequate
for the tasks which confront him" (1 14, p. 4), or " ... people systematically violate
the principles of rational decision making when judging probabilities, making
predictions, DEMO otherwise attempting to cope with probabilistic tasks" (252, p.
169)DEMO
Van Winkle would be further surprised to see Hammond (1 14) and Dawes (69)
putting information-processing deficiencies on a par with motivational conflicts as
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY DEMO WATERLOO on 10/28/09. For personal use only.
4 SLOYIC, FISCHHOFF & LICHTENSTEIN
causes of the ills that plague humanity, and to see financial analysts, accountants,
geographers, statisticians, and DEMO being briefed on the implications of these
intellectual shortcomings (14, 12 1a, 248, 249, 253, 282).
In 1971, when reviewing the literature on probabilistic inference, Slovic & Lich­
tenstein (254) found only a handful of studies that looked at subjects' information­
processing heuristics. Since then, rather than simply comparing behavior with
normative models, almost DEMO descriptive study of probabilistic thinking has
attempted to determine how the underlying cognitive processes are molded by the
interaction between the demands of the DEMO and the limitations of the thinker.
Much of the impetus for this change can be attributed to Tversky & Kahneman's
(1 38, DEMO, 28�286) demonstrations of three judgmental heuristics-representative­
ness, availability and anchoring-which DEMO probabilistic judgments in a
variety of tasks. Although always efficient, and DEMO times valid, these heuristics can
lead to biases that are large, persistent, and serious in their implications for decision
making.
Judgment by representativeness What is the probability that object B belongs to
class A? Or what is the probability that process A will generate event B? Kahneman
& Tversky (1 38) hypothesized that people answer such questions by DEMO the
essential features of A and of B and assessing the degree of similarity between them,
the degree to which B is "representative" of A. When B is very similar to A, as when
DEMO outcome is highly representative of the process from which it originates, DEMO its
probability is judged to be high.
Several lines of evidence support this hypothesis. Tversky & Kahneman (284)
demonstrated a belief in what they called "the law of small numbers," whereby even
small samples are viewed as highly representative of the populations from which
they are DEMO This belief led their subjects, research psychologists, to underesti­
mate the error and unreliability inherent in small samples of data. Kahneman &
Tversky (1 38) showed that both subjective sampling distributions and posterior
probability DEMO were insensitive to sample size, a normatively important but
psychologically nonrepresentative DEMO In a subsequent paper, Kahneman &
Tversky (139) demonstrated that people's intuitive predictions violate normative
principles in ways that can be DEMO to representativeness biases. For one,
representativeness causes prior probabilities to be neglected. For another, predic­
tions tend not to be properly regressive, DEMO insensitive to considerations of data
reliability.
Judgment by availability Other judgmental biases are due to use of the "availabil­
ity" heuristic (285) DEMO an event is judged likely or frequent if it is easy to
imagine or recall relevant instances. In life, instances offrequent events are typically
easier to recall than instances of less frequent events, and likely occurrences are
usually easier to imagine than unlikely ones. Thus availability is often DEMO valid cue
for the assessment of frequency and probability. However, since DEMO is also
affected by subtle factors unrelated to likelihood, such as DEMO, recency, and
emotional saliency, reliance on it may result in DEMO biases.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY 5
Judgment by adjustment Another error-prone heuristic is "anchoring and adjust­
ment." With this process. a natural starting point or anchor is used as a first
approximation to the judgment. The anchor is DEMO adjusted to accommodate the
implications of additional information. Typically. the adjustment is imprecise and
insufficient (248). Tversky & Kahneman (286) showed how anchoring and adjust­
ment could cause the overly narrow confidence intervals found DEMO many investiga­
tors (1 75) and the tendency to misjudge the probability of conjunctive and
disjunctive events (16. 57. 317).
Related work Numerous studies have replicated and extended the Kahneman &
Tversky studies. and others have independently arrived at similar conclusions. The
representativeness heuristic has received DEMO most attention. Wise & Mockovak
(310). Bar-Hillel (17). and Teigen (278. 279) have documented the importance of
similarity structures in DEMO judgment. Like Kahneman & Tversky (1 38).
Marks & Clarkson (191. 192) and Svenson (271) observed that subjects' posterior
probabilities DEMO binomial bookbag and poker chip tasks were predominantly in­
fluenced by the most representative aspect of the sample. the proportion of red chips.
Contrary DEMO the normative model. population proportion and sample size were
relatively unimportant. Leon & Anderson (166) did find an influence of these two
characteristics DEMO as a result. claimed that Kahneman & Tversky's subjects must
have misunderstood the task. Ward (302). however. argued that the conflicting
results were most likely due to differences in the tasks. rather than to DEMO
tion of instructions. Hammerton (113). Lyon & Slovic (1 84). Nisbett & Borgida
(210). and Borgida & Nisbett3 have replicated Kahneman & Tversky's finding that
subjects neglect population base rates when DEMO the probability that an individ­
ual belongs to a given category. Nisbett & Borgida argued that this neglect stems
in part from the abstract, pallid, statistical character of base-rate information. They
found that concrete. case-specific information. even from a sample of one, may have
much greater importance, DEMO rather dramatic illustration of the law of small numbers.
Additional evidence for representativeness comes from studies by Brickman &
Pierce (45). Holzworth & Doherty (123), Bauer (20, 21). and Lichtenstein. Earle &
Slovic (1 73).
Availability and anchoring have been studied less often. Evidence of availability
bias has been found by Borgida & Nisbett3 DEMO Slovic, Fischhoff & Lichtenstein
(252). Anchoring has been hypothesized to account for the effects of response mode
upon bet preferences (176, DEMO). and it has been proposed as a method that people
use to reduce strain when making ratio judgments (106). Pitz (219) gave the anchor­
ing heuristic a key role in his model describing DEMO people create subjective proba­
\;lility distributions for imperfectly known (uncertain) quantities.
Overconfidence The evidence presented above suggests that the heuristic selected.
the DEMO it is employed. and the accuracy of the judgment it produces are all highly
problem-specific; they may even vary with different representations of the same
lE. Borgida & R. E. Nisbett. Abstract vs. concrete information: The senses engulf the mind.
Unpublished. University of Michigan. 1976.
Annu. Rev. Psychol. DEMO:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
6 SLOVIC, FISCHHOFF & LICHTENSTEIN
problem. Indeed, heuristics may be faulted DEMO a general theory of judgment because
of the difficulty of knowing which will be applied in any particular instance.
There is, however, one DEMO valid generalization that may be derived from this
literature. Except for some Bayesian inference tasks, people tend to be overconfident
in their judgments. This may be seen in their nonregressive predictions (139), in their
disregard for the extent of the data base upon which their judgments rest (138), or
its reliability (217), and in the miscalibration of their probabilities for discrete and
continuous propositions (175). Howell (128) has repeatedly shown that people
overestimate their own abilities on tasks requiring DEMO (e.g. throwing darts). Langer
(163) dubbed this effect "the illusion of control" and demonstrated that it can be
induced by introducing skill factors (such as competition and choice) into chance
situations.
In DEMO task that had people estimate the odds that they had been able to select the
correct answer to general knowledge questions, Slovic, Fischhoff & Lichtenstein
(251) found that wrong answers were often given with certainty. Furthermore,
subjects had sufficient faith in their odds that they were DEMO to participate in a
gambling game that punished them severely for their overconfidence.
How do we maintain this overconfidence? One possibility is that the environment
is often not structured to show our limits. Many decisions we DEMO are quite
insensitive to errors in estimating what we want (utilities) or what is going to happen
(probabilities}-so that errors in estimation are hard to detect (294a). Sometimes we
receive no feedback at all. Even when we do, we may distort its meaning to exagger­
ate our judgmental prowess, perhaps convincing ourselves that the outcome we got
was what we really wanted. Langer & Roth (164) found that subjects DEMO experi­
enced initial successes in a repetitive task overremembered their own past successes.
Fischhoff & Beyth (93) found that people asked to recall DEMO own predictions about
past events remembered having assigned higher probabilities to events that later
occurred than was actually the case. Fischhoff (89) also DEMO that people (a)
overestimate the extent to which they would DEMO been able to predict past events
had they been asked to do so, and (b) exaggerate the extent to which others should
have been able to predict past events. These hindsight biases are further evidence
DEMO overconfidence for they show that people have inordinately high opinions of their
own predictive abilities.
Descriptive theories Most of the research on heuristics and DEMO can be considered
pretheoretical. It has documented the descriptive shortcomings of the normative
model and produced concepts such as representativeness and anchoring that may
DEMO as the bases for new descriptive theories. Although theory development has
been limited thus far, efforts by Wallsten (300, 301) and Shanteau (243, 244) to
produce descriptive algebraic models are noteworthy. Shanteau's DEMO is based
upon the averaging model of Anderson's integration theory (DEMO). Wallsten's model,
formulated and tested within the framework of conjoint measurement, assumes that
limited capacity causes people to process dimensions of information sequentially and
weight them differentially, according to their salience.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/DEMO/09. For personal use only.
BEHAVIORAL DECISION THEORY 7
Choice
In their introduction to two volumes on DEMO developments in mathemati­
cal psychology, Krantz et al (159) explained DEMO exclusion of the entire area of
preferential choice as follows:
There is no lack whatever of technically excellent papers in this area but DEMO give no sense
of any real cumulation of knowledge. What are established laws of preferential choice
behavior? (Since three of the editors have DEMO in this area, our attitude may reflect
some measure of our DEMO frustration) (p. xii).
This sense of frustration is understandaule when one reviews recent research on
choice. The field is in a state DEMO transition, moving away from the assumption that
choice probability is expressable DEMO a monotone function of the scale values or
utilities of the alternatives. Present efforts are aimed at developing more detailed,
molecular concepts that DEMO choice in terms of information-processing phenom­
ena. Researchers appear to be searching for heuristics or modes of processing
information that are common to a DEMO domain of subjects and choice problems.
However, they are finding that DEMO nature of the task is a prime determinant of the
observed behavior.
ELIMINATION BY ASPECTS One major new choice theory is Tversky's (280, 281)
elimination-by-aspects (EHA) model. The model describes choice as a covert se­
quential elimination process. Alternatives are viewed as sets of aspects (e.g. cars
described by price, model, color, etc). At each stage in the choice process an aspect
is selected with probability proportional DEMO its importance; alternatives that are
unsatisfactory on the selected aspect are DEMO Tversky showed that the EHA
model generalizes the models of Luce (DEMO) and Restle (228) while avoiding some
of the counter-examples to DEMO these earlier models are susceptible. Searching for
even broader applicability, Corbin & Marley (62) proposed a random utility model
that includes the EHA model as a special case. Other models built around the
concept of DEMO elimination of alternatives have been developed by Hogarth
(121, 122) DEMO Pollay (220).
PROCESS DESCRIPTION Most recent empirical research has been DEMO with
describing the decision maker's methods for processing information before choos­
ing. Whereas earlier work focused on external products (e.g. choice proportions and
rankings) and used rather simple methods, process-descriptive studies must employ
more DEMO procedures for collecting and analyzing data. Thus we find a return
to introspective methods (28, 199, 272) in which subjects are asked DEMO think aloud
as they choose among various multiattribute alternatives. Hettman & Jacoby (31)
and Payne (214) supplemented the think-aloud procedure by requiring subjects to
seek information from envelopes on an "information board. " Russo & Rosen (231)
used eye-movement data conjointly with verbal protocols. One goal of these studies
is to represent the choice process graphically as DEMO tree or network (discrimination
net) of successive decisions. Swinth, Gaumnitz & Rodriguez (275) developed a
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use DEMO
8 SLOVIC, FISCHHOFF & LICHTENSTEIN
method of controlled introspection that enables subjects to build and validate their
own discrimination nets. Bettman (27) showed DEMO to describe such nets via graph­
theoretical concepts. Uneasy about the subjectivity of introspective techniques,
Hogarth (121) used an ingenious blend of DEMO and empiricism to develop a
computer algorithm that builds the tree without recourse to subjective inputs.
Can introspective methods be trusted? Nisbett & Wilson4 reopened an old debate
by arguing that people lack awareness of the DEMO that affect their judgments.
After documenting this claim with results from six experiments, they concluded that
"Investigators who are inclined to place themselves DEMO the mercy of such [introspec­
tive] reports ... would be better advised to remain in the armchair" (p. 35). While
important, this criticism may be overstated. Students of choice have in many in­
stances DEMO their introspective reports against theoretical predictions (199) and
data from other sources' (see also 214).
What do these methodologies tell us DEMO choice? First they indicate that sub­
jects use many rules and DEMO enroute to a decision. These include conjunctive,
disjunctive, lexicographic and DEMO rules, and the principle of dominance
(274). A typical choice may involve several stages, utilizing different rules at differ­
ent junctures. Early in the process, subjects tend to compare a number of alternatives
on the same attribute and use conjunctive rules to reject some alternatives from
DEMO consideration (26, 214, 245, 272). Later they appear to employ compensa­
tory weighting of advantages and disadvantages on the reduced set DEMO alternatives
(2 14). Features of the task that complicate the DEMO, such as incomplete data,
incommensurable data dimensions, information overload, DEMO pressures, and many
alternatives seem to encourage strain-reducing,n oncompensatory strategies (214,
255, 313, 314). Svenson (272) and Russo & Rosen (23 1) found subjects reducing
memory load by comparing two alternatives at a time and retaining only the better
one for later DEMO Russo & Doshers observed simple strategies, such as
counting the number DEMO dimensions favoring each alternative or ignoring small
differences between alternatives on a particular dimension. In some instances, these
strategies led to suboptimal choices.
In general, people appear to prefer strategies that are easy to justify and do not
involve reliance on relative weights, trade-off functions, or other DEMO compu­
tations. One implication of this was noted by Slovic (250), whose subjects were
forced to choose among pairs of alternatives that were equal in value for them.
Rather than choose randomly, subjects consistently followed the easy and defensible
strategy of selecting the alternative that was superior DEMO the more important dimen­
sion.
SCRIPT PROCESSING Abelson'S (I) new approach to explaining decisions war­
rants further study. It is based on DEMO concept of a "cognitive script," which is a
4R. E. DEMO & T. D. Wilson. Awareness of factors influencing one's own evaluations.
judgments. and behavior. Unpublished, University of Michigan, 1976.
'J. E. Russo & B. A. Dosher. Dimensional Evaluation.' A heuristic for binary choice. Unpub­
lished, University of California, Santa Barbara, 1975.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. DEMO personal use only.
BEHAVIORAL DECISION THEORY 9
coherent sequence of events expected by the individual DEMO the basis of prior learning
or experience. When faced with a decision, individuals are hypothesized to bring
relevant scripts into play. For example, DEMO Y's application for graduate
school may be rejected because Y reminds the decision maker of Candidate X who
was accepted and failed miserably. DEMO script might assimilate the candidate
into a category (He's one DEMO those shy types who does well in courses, but doesn't
DEMO enough initiative in research). Script theory, though still in a DEMO speculative
stage, suggests a type of explanation for choice that has DEMO far been overlooked.
CONSUMER CHOICE Much research on choice has been done within the domain
of consumer psychology. Comprehensive reviews of this research have DEMO pro­
vided by Jacoby (134, 135). Although some of this work is application of multiple
regression, conjoint measurement, and analysis of DEMO to describe consumers'
values (30, 107, 312), many DEMO studies have investigated basic psychological
questions. For example, one major issue DEMO been the effect of amount and display
of information on the optimality of choice. Jacoby and his colleagues have argued
that more information is DEMO necessarily helpful, as it can overload consume�s and
lead them to DEMO suboptimal products. Russo, Krieser & Miyashita (230) observed .
that DEMO had great difficulty finding the most economical product among an
array of different prices and packages. Even unit prices, which do the arithmetic for
the consumer, had little effect on buyer behavior when posted on the shelf below
each product. However, when prices per unit were listed in order from high to low
cost, shoppers began to buy less expensive products.
Models of Risky Choice
Decision making under conditions of risk has DEMO studied extensively. This is
probably due to the availability of (0) an appealing research paradigm, choices
among gambles, and (b) a DEMO normative theory, the subjectively expected
utility (SEU) model, against which behavior can be compared. The SEV model
assumes that people behave as DEMO they maximized the sum of the products of
utility and probability.
Early studies of the model's descriptive adequacy produced conflicting results.
Situational and DEMO parameters were found to have strong effects, leading Rapoport
& Wallsten (226) to observe that a researcher might accept SEV with one set of bets
and reject it with another, differently structured set. Proponents of the SEV model
point out that it gives a good global fit DEMO choice data, particularly for simple
gambles.6 In addition, certain assumptions of the model, like the independent (mul­
tiplicative) combination of probabilities and payoffs, have been verified for simple
gambles (244, 299).
However, during the .past 5 years, the proponents of SEU have been DEMO
outnumbered by its critics. Coombs (60) has argued that risky choice is determined
not by SEU, but by a compromise between maximization of expected value (EY)
6B. Goodman, M. Saltzman, W. Edwards & D. Krantz. Prediction o/ bids /or two-outcome
gambles in a casino DEMO Unpublished, 1976.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by DEMO OF WATERLOO on 10/28/09. For personal use only.
10
SLOVIC, FISCHHOFF & LICHTENSTEIN
and optimization of risk. He proposed an alternative to SEU, "portfolio theory,"
in which risk preferences play a central role. That role is illustrated in a study by
Coombs & Huang (6 1) in which gamble B was constructed as a probability mixture
of two other gambles, A and C. Many subjects preferred gamble B (with its interme­
diate risk level) to gambles A DEMO C, thus violating a fundamental axiom of SEU
theory.
Zagorski (3 18) demonstrated a result that appears to violate SEU and many other
algebraic models as well. Zagorski's subjects were shown pairs of gambles (A, B)
and were asked to judge the amount of money (A-B) that would induce them to
trade the better gamble (A) for the worse gamble (B). He demonstrated that one
can DEMO quadruples of gambles A, B, C, and D such that
(A-B) + (B-C) � (A-D) + (D-C)
In DEMO words, path independence is violated. The difference between gambles A
and DEMO depends on whether the intermediate gamble is B or D.
A favorite approach of SEU critics is to develop counterexamples to the funda­
mental DEMO of the theory. The paradoxes of Allais (4) and Ellsberg (DEMO) are two
of the most famous, both designed to invalidate Savage's (232) independence princi­
ple. Until recently, few theorists were convinced. MacCrimmon (185) showed that
business executives who violated various axioms could DEMO be led, via discussion,
to see the error of their DEMO However, Slovic & Tversky (256) challenged Mac­
Crimmon's discussion DEMO on the grounds that it pressured the subjects to
accept the axioms. They presented subjects with arguments for and against the
independence axiom and DEMO persistent violations, even after the axiom was
presented in a clear DEMO presumably compelling fashion. Moskowitz (200) used a
variety of problem representations (matrix formats, trees, and verbal presentations)
to clarify the principle and maximize its acceptability, yet still found that the
independence axiom was rejected. Even MacCrimmon's faith in many of the key
axioms has DEMO shaken by recent data (see 188), leading him to suggest DEMO
reevaluation of the theory is in order.
Kahneman & Tversky (140,DEMO) attempted this sort of reevaluation, presenting
evidence for two pervasive violations of SEU theory. One, the "certainty effect,"
causes consequences that are obtained with certainty to be valued more than uncer­
tain consequences. DEMO Allais paradox may be due to this effect. The second, labeled
DEMO "reference effect," leads people to evaluate alternatives relative to a DEMO
point corresponding to their status quo, adaptation level, or expectation. By altering
the reference point, formally equivalent versions of the same decision problem may
elicit different preferences. These effects pose serious problems for the normative
DEMO and its application.
Payne (2 13) proposed replacing the SEU model with information processing
theories that describe how probabilities and payoffs are integrated DEMO decisions. He
presented a "contingent process" model to describe the sequential processes in­
volved in choice among gambles. For support, he cited a number of display and
response-mode effects that are due to processing difficulties (1 76, 177, 179, 215).
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For DEMO use only.
BEHAVIORAL DECISION THEORY 11
Kozielecki's (1 58) discussion of the DEMO representation of risky tasks carried a
similar message.
Kunreuther (1 60) has argued that utility theory would be of little value to a DEMO
maker trying to predict how people would respond to various flood or earthquake
insurance programs. First, the theory makes predictions that are not borne out by
actual behavior-for example, that people will prefer policies with high deductibles
or that subsidizing premiums will increase insurance purchasing. Second, it gives
no guidance about the social, situational, and cognitive factors that are DEMO to
influence insurance purchase. Like Payne, Kunreuther called for an alternative
DEMO, founded on the psychology of human information processing, and presented
a model of his own to support his case.
Readers interested in additional DEMO on the. staggering SEU model should
consult Barron & MacKenzie (1 DEMO), Davenport & Middleton (66), Fryback, Good­
man & Edwards (99), Ronen (229), and Svenson (273).
Regression Approaches
The regression paradigm uses analysis of variance, conjoint measurement, and
mUltiple DEMO techniques to develop algebraic models that describe the method
by which individuals weight and combine information.
INTEGRATION THEORY Working within the framework of "information inte­
gration theory," Anderson and his colleagues have shown that simple DEMO
models describe information use quite well in an impressive variety of judgment�l,
decision making, attitudinal, and perceptual tasks (6, 7). DEMO models typically
have revealed stimulus averaging, although some subtracting and multiplying DEMO
been observed. Particularly relevant to decision making are studies of risk taking
and inference (244), configurality in clinical jUdgment (5), intuitive DEMO (167,
168), preference for bus transportation (210a), and judgment in stud poker (18 1).
There is no doubt that algebraic models derived from Anderson's techniques provide
good surface descriptions of DEMO processes. However, as Graesser & Ander­
son (106) have observed, establishment of an algebraic model is only the first step
towards disclosing DEMO underlying cognitive mechanisms, which may be rather
different from the surface DEMO of the model.
POLICY CAPTURING Another form of the regression paradigm uses correlational
statistics to provide judgmental models in realistic settings. The most systematic
DEMO of these procedures has been made by Hammond and his colleagues
(DEMO 17) within "social judgment theory." This theory assumes that most DEMO
depend upon a mode of thought that is quasi-rational, that is, a synthesis of analytic
and intuitive processes. The elements of quasi-rational thought DEMO cues (attributes),
their weights, and their functional relationships (linear and nonlinear) to both the
environment and the judge's responses. Brunswik's lens model and multiple regres­
sion analysis are used to derive DEMO representing the judge's cue utilization
policy. Judgmental performance is analyzed into knowledge and "cognitive con­
trol," the latter being the ability to employ one's knowledge consistently (118).
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For DEMO use only.
12 SLOVIC, FISCHHOFF & LICHTENSTEIN
By 1971 it was evident that linear models could describe college students' cue­
weighting policies in a wide variety of laboratory tasks (254). During the past 5
years, such DEMO have been used with similar success to analyze complex real­
world judgments. Judges in these studies have included business managers (119,193,
201, 202), graduate admissions committees (68, 237), auditors, accountants, and
loan officers (13, 172, 315), military officers (277), literary critics (84), and trout
hatchery employees (1 82), as they attempted to predict business failures and stock
market performance, select graduate students, plan work force and production
schedules, evaluate accounting procedures, Air Force cadets, and theatrical plays,
and recommend trout streams. Even United States senators have been modeled and
their roll-call votes predicted (298). As in the laboratory studies, linear equations
have accounted for most of the predictable variance in these complex judgments .
. The coefficients DEMO these equations have provided useful descriptions of the judges'
cue-weighting policies and have pinpointed the sources of interjudge disagreement
and nonoptimal cue use.
DEMO policies were being captured in the field, other researchers were deepening
DEMO understanding of the models. Dawes & Corrigan (70) observed that linear
models have typically been applied in situations in which (a) the DEMO variables
are monotonically related to the criterion (or can be easily DEMO to be mono­
tonic), and (b) there is error in the independent and dependent variables. They
demonstrated that these conditions insure good DEMO by linear models, regardless of
whether the weights in such models DEMO optimal. Thus the linearity observed in
judges' behaviors may be reflecting DEMO a characteristic of linear models, not a
characteristic of human judgment.
DEMO other work, theoretical and methodological refinements of the lens model have
DEMO developed by Castellan (52, 53) and Stenson (267). Cook (59) and Stewart &
Carter (268) have worked towards developing interactive computer programs· for
policy capturing. Mertz & Doherty (195) and DEMO (37) examined the influence
of various task characteristics on the configurality and consistency of policies. Miller
(197) demonstrated that improper cue labels DEMO mislead judges despite the avail­
ability of adequate statistical information about cue validities. Lichtenstein, Earle
& Slovic (173) and Birnbaum (32) showed that even though regression equations
can be used to describe cue-combination policies, subjects often average cues, in
violation of the additivity inherent in the equations. Wiggins (306) discussed the
problems of identifying and characterizing individual DEMO in judgmental
policies, and Ramanaiah & Goldberg (222) explored the DEMO and correlates of
such differences. McCann, Miller & Moskowitz (193) DEMO the problems of
capturing policies in particularly complex and dynamic tasks such as production
planning.
MULTIPLE CUE PROBABILITY LEARNING Considerable effort has been in­
DEMO in studying how people learn to make inferences from several probabilistic
cues. Most of this work goes under the label "multiple-cue probability learning"
(MCPL) and relies on the lens model for conceptual and analytic DEMO Typi­
cally, the cues are numerical and vary in their importance DEMO in the form (linear
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from DEMO
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY
or nonlinear) of their relationship to the criterion being judged. The criterion usually
contains error, making perfect prediction impossible. Because these tasks embody
the essential features of diagnostic inference, they are studied for their potential
applied significance as well as their contributions to basic knowledge.
DEMO & Lichtenstein (254) reviewed MCPL studies published prior to 1971.
They concluded that: (a) subjects can learn to use linear cues appropriately; (b)
learning of nonlinear functions is slow, and especially difficult when subjects are not
forewarned that relations may be nonlinear; (c) subjects are inconsistent, particu­
larly when task predictability is low; (d) subjects fail to take proper account of cue
intercorrelations; and (e) outcome feedback is not very helpful.
Research during the past half decade has confirmed and extended these conclu­
sions. Difficulties people have in coping DEMO intercorrelated cues have been docu­
mented in numerous studies (8, 9, 178, 236). Hammond and his colleagues (lIS)
used the MCPL paradigm to analyze the effects of psychoactive drugs on cognition.
They DEMO that some drugs that are used to enhance emotional control interfered
with learning and communication in ways that may be detrimental to therapy.
Bjorkman (33) and Castellan (54) reviewed results from
cues and criteria.
studies using nonmetric
0
Other research has worked towards developing a theory to DEMO MCPL results
in terms of erroneous intuitions about probabilistic tasks, the DEMO in which
individuals acquire and test hypotheses, and their cognitive limitations. DEMO exam­
ple, Brehmer (38, 40, 41) has studied how DEMO formulate and test hypotheses
as they search for rules that will produce satisfactory iriferences. Hypotheses about
the functional rule relating cues and criterion appear DEMO be sampled from a hierar­
chical set based on previous experience and dominated by the positive linear rule.
Testing of hypotheses about rules shows DEMO appreciation of the probabilistic
nature of the task. Subjects keep searching for deterministic rules that will account
for the randomness in the task; since there are none, they change rules frequently
(i.e. become inconsistent) and eventually resample rules they had previously dis­
carded.
Even when subjects are DEMO of the correct rules, they have trouble applying
them consistently (31, 36, 42, 1I8). Nonlinear rules are particularly hard to apply.
Brehmer, Hammond, and their colleagues have thus conceptualized inference as a
DEMO analogous to motor behavior: with both, we can know what we want to do
without necessarily being able to do it.
Dynamic Decision DEMO
At the time of Rapoport & Wallsten's review, one active DEMO area was dynamic
decision making (DDM), the study of tasks DEMO which "decisions are made sequen­
tially in time; the task specifications may change over time, either independently or
as a result of previous decisions; information available for later decisions may be
contingent upon the outcomes of earlier decisions; and implications of any decision
may reach into the future" (224, p. 345). The present half-decade began promisingly
with Rapoport & Burkheimer's (225) explication of formal models for deferred
DEMO making and the manner in which they might be utilized in psychological
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO DEMO 10/28/09. For personal use only.
13
14
SLOVIC, FISCHHOFF & LICHTENSTEIN
experiments. Shortly thereafter, Ebert (77) DEMO finding no difference between
stochastic and deterministic versions of a task which Rapoport (223) earlier had
found to differ. After that, relative silence.
Several possible reasons for this decline in interest come to mind. The DEMO
cal sophistication of DDM may deter some researchers, as may the DEMO computer
and long start-up time often required. Furthermore, DDM models are DEMO complex
and require so many assumptions that the interpretation of experimental results is
typically ambiguous-witness the morass of explanations facing Ebert (77) for DEMO
his experiment and Rapoport's produced different results. Kleiter (151) noted par­
ticular problems with creating cover stories that induce subjects to accept DEMO
assumptions underlying the model and with ascertaining that subjects understood
the task. He also questioned "the metahypothesis that human behavior is optimal"
(DEMO 374), which limits psychological theories to variations on the optimal model, (e.g.
using subjective probability estimates rather than "objective" relative frequencies DEMO
assuming a reduced planning horizon). In his own work, Kleiter (152) has assessed
people's planning horizons and has used a non-normative variance-preference model
to predict betting behavior in a multistage game (154). These predictions relied on
the asstimption that people were perfect Bayesian information DEMO
A more active area of DDM research deals with sequential information purchas­
ing or sampling. Levine & Samet (169) allowed subjects to purchase DEMO
from three fallible sources until they could decide which of eight possible targets
was the object of an enemy advance. They found that information DEMO was
greater and accuracy was lower in low reliability conditions. Similar results were
obtained by Snapper & Peterson (259), whose subjects appeared to be relatively
unresponsive to changes in information quality because of a policy DEMO purchasing
"intermediate" amounts of information.
Another sequential task that has attracted some attention is optional stopping:
the decision maker must choose between DEMO a currently available outcome
versus sampling further outcomes that may be of greater or lesser worth. Although
earlier research (see 225a) found that DEMO performed well when options were
generated by a random but stationary process, Brickman (44) found very poor
performance with options that tended to increase or decrease in value. In particular,
subjects persisted much longer DEMO sampling options with a descending than with an
ascending sequence. Brickman likened this behavior to "throwing good money after
bad." His subjects' "DEMO the money and run" strategy with ascending series was
similar to DEMO found by Corbin, Olson & Abbondanza (63). Their subjects seem to
have called it quits as soon as an option appeared that DEMO a good bit better than
its predecessors. Olander (212), too, described satisficing (rather than maximizing)
principles that may guide subjects' DEMO about searching further.
Are Important Decisions Biased?
A coherent picture emerges from research described so far. Because of limited
information-processing capacity and ignorance DEMO the rules for optimal information
processing and decision making, people's DEMO are subject to systematic biases.
Can these results be generalized from the lab to the real world?
Annu. Rev. Psychol. 1977.28:1-39. Downloaded DEMO arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY 15
A number of critics are doubtful. Edwards (80) argued that experimenters, by
denying subjects necessary tools and providing neither DEMO time nor the guidance
to find them, have exaggerated human intellectual DEMO Winkler & Murphy
(309) criticized laboratory experiments for being overly simplified and too well
structured when compared with the real-world situations they are DEMO to model.
They suggested that people may perform poorly in the lab because of improper
generalization from their real-world experiences. For example, because real-world
information tends to be redundant and unreliable, people may naturally devalue the
reliable information provided in experiments, producing conservatism. In addition,
experimental subjects may be poorly motivated and forced to deal with unfamiliar
tasks and DEMO areas without adequate training-even in the meaning of the
response mode (DEMO).
In rebuttal, one could argue that laboratory studies may show DEMO at their
best. Use of unfamiliar substantive topics may free them from preconceived notions
that could prejudice their judgments. Provision of all information necessary DEMO an
optimal decision (and little else) is, as noted by DEMO & Murphy (309), a boon
seldom offered by the real DEMO It may create demand characteristics forcing
subjects toward optimal responses (90, 97, 302). An alternative rebuttal is that there
are many real-life situations which are quite like the laboratory, forcing people to
make a decision without the benefit of training and experience. People typically buy
cars DEMO houses and decide to marry and divorce under such circumstances, func­
DEMO as their own best approximation to experts.
Perhaps the best way to resolve this argument is to look at the evidence.
EXPERTS IN THE DEMO The robustness of biases is shown in formal
experiments using experts as subjects. As examples: Tversky & Kahneman's (284)
"law of small numbers" results were obtained with statistically savvy psychologists.
Las Vegas casino patrons showed the same irrational reversals of preferences for
gambles as did DEMO students (176, 177). Bankers and stock market experts
predicting closing prices for selected stocks showed substantial overconfidence and
performed so poorly that DEMO would have done better with a "know nothing"
strategy (264). Lichtenstein & Fischhoff (174) found that the probability assess­
ments DEMO psychology graduate students were no better for questions within their area
of expertise than for questions relating to general knowledge.
The "experts" in DEMO studies were selected on the basis of what they knew about
the subject area, not what they knew about judgment and decision making (DEMO they
were substantive rather than normative experts). Can normative experts be created
in the laboratory by proper training? The evidence is mixed, DEMO either that
some biases are robust or that we have failed to understand the psychology of our
subjects well enough to assist them.
OUT DEMO THE FIELD With the exception of some well-calibrated weather forecast­
ers (DEMO below), similar biases have been found in a variety of field studies.
For example, Brown, Kahr & Peterson (49, p. 431) observed overconfidence in the
probability assessments of military intelligence analysts. Kidd (149) found that
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
16
SLOVIC. FISCHHOFF & LICHTENSTEIN
engineers for the United Kingdom's Central DEMO Generating Board consis­
tently underestimated repair time for inoperative units. Bond (DEMO) observed subopti­
mal play among 53 blackjack players at four South DEMO Tahoe casinos. "By
wagering small bets in a sub-fair game, [these] blackjack gamblers practically guar­
anteed loss of their betting capital to the DEMO" (p. 413). Flood plain residents
misperceive the probability of floods in ways readily explained in terms of availabil­
ity and representativeness (253). Surveying research published in psychological and
educational journals. Cohen (56) DEMO Brewer & Owen (43) found that investigators
regularly design experiments with inadequate statistical power, reflecting a belief in
the "law of small DEMO" (284). Misinterpretation of regression toward the mean
appears to be as endemic to some areas of psychology (101) as to Kahneman &
Tversky's (1 39) subjects.
A major legal debate concerns DEMO incarceration of individuals for being "danger­
ous." What little evidence there is regarding the validity of dangerousness judgments
indicates substantial "over-prediction," incarceration of people who would not have
misbehaved had they been set free (72, 242). Although this bias may reflect a greater
aversion to freeing someone who causes trouble than to erring in the other direction,DEMO
some observers have attributed it to judgmental problems such as failure to consider
base rates, ignorance of the problems of predicting rare events, DEMO of nonex­
istent correlations, and insensitivity to the reliability of evidence (198a).
Jurors appear to have great difficulty ignoring first impressions of DEMO accused's
personality, pretrial publicity, and other forms of inadmissible evidence (46, 270),
tendencies which may represent both hindsight and anchoring biases (92). The
vagaries of eyewitness testimony and witnesses' overconfidence DEMO erroneous knowl­
edge are quite well known (5 1, 180).
Zieve (3 19) has described at length the misinterpretation and abuse DEMO laboratory
test results by medical clinicians. Although some of these errors are due to igno­
rance, others reflect naive statistical reasoning. A classic case of the "law of small
numbers" is Berkson, Magath & Hum's (25) discovery that aspiring lab technicians
were expected by their DEMO to show greater accuracy in performing blood cell
counts than was possible given sampling variation. These instructors would marvel
that the best students (those who would not cheat) had the greatest difficulty in
producing acceptable counts. In a phenomenological study of orthopedic surgeons,
Knafl & Burkett (I SS) found a variety of simplifying heuristics, some of them in DEMO
form of general treatment philosophies (e.g. "don't cut unless you absolutely have
to").
The immense decisions facing our society (e.g; nuclear power) have prompted the
development of formal analytic techniques to replace traditional, error-prone, "seat
of the pants" decision making. Fischhoff (9 1) reviewed a variety of cost-benefit
analyses and risk assessments performed with these techniques and found them
liable to omissions of important consequences reflecting DEMO biases. In case
studies of policy analyses, Albert Wohlstetter (3 11 ) found that American intelli­
gence analysts consistently underestimated Soviet missile strength, a bias possibly
due to anchoring. Roberta Wohlstetter's (3 1I a) study of American unpreparedness
at Pearl Harbor found the U.S. Congress and military investigators guilty of hind­
sight bias in their judgment of the DEMO Harbor command staff's negligence.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use DEMO
BEHAVIORAL DECISION THEORY 17
Even if policy analyses are performed correctly, they still must be explained
(sold?) to the public. In the area of natural hazard management, well-founded
government policies have foundered because people do not perceive flood hazards
the way policy makers expect them to (253). For example, the National Flood
Insurance Program has had only limited success because the endangered people will
not buy the highly subsidized and DEMO very attractive insurance offered
them (160).
THE ULTIMATE TEST "If behavioral decision theory researchers are so smart,
why aren't they DEMO?"
"They're not in business."
"Then why aren'DEMO people who are in business falling over themselves to utilize
their results?"
Well, although psychological research has not swept the world's DEMO makers
like wildfire, it has kindled some nonnegligible interest. The concern DEMO fore­
casters and decision analysts have shown for research in probability assessment is
described elsewhere in this review. The Department of Defense is de'DEMO sophiS­
ticated decision aids to relieve military commanders of the need to integrate infor­
mation in their heads (148). United States intelligence analysts have shown interest
in the use of Bayesian approaches for processing of DEMO information (79a,
147). Researchers in accounting' (see also DEMO) have advocated considering informa­
tion-processing limits in designing financial reports. The DEMO College of Radi­'
ology has launched a massive "Efficacy Study" to see how radiologists use the
probabilistic information from X rays. Bettman (29), Armstrong, Kendall & Ross
(10), and others have DEMO that legislation intended to provide consumers with
necessary information (e.g. unit DEMO, true interest rates) must consider how those
consumers do in fact process information.
DECISION AIDS
"What do you do for a living?"DEMO
"Study decision making."
"Then you can help me. I have some big decisions to make."
"Well, actually ... "
That sinking feeling of inadequacy experienced by many of us doing psychological
research DEMO decision making is probably not felt by most experts in decision analysis,
multiattribute utility theory, or other decision aiding techniques. Proponents of
these approaches have remedies for what ails you-techniques to help users make
better DEMO in any and all circumstances.
Most of these decision aids rely on the principle of divide and conquer. This
"decomposition" approach is a DEMO response to the problem of cognitive
overload. The decision aid fractionates the total problem into a series of structurally
related parts, and the decision maker is asked to make subjective assessments for
'T. A. Climo. Cash flow statements /or investors. Unpublished. University of Kent at Canter­
bury, DEMO
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
18 SLOVIC, FISCHHOFF & LICHTENSTEIN
only the smallest components. Such assessments are presumably simpler and more
manageable than assessing more global entities. Research showing DEMO decomposi­
tion improves judgment has been reported by Armstrong, Denniston & DEMO
(1 1), Gettys et al (104), and by Edwards and his colleagues (254, pp. 717-2 1).
Critics oft he DEMO approach would argue that many oft he aids require
assessments of quantities the decision maker has never thought about, and that these
apparently simple assessments may be psychologically more complex than the origi­
nal decision. In DEMO situations, people may really know what they want to do better
DEMO they know how to assess the inputs required for the decision aid.
Decision aids which do not rely on decomposition, but instead require the deci­
sion maker to state preferences among whole, nonfractionated alternatives, are DEMO
called "wholistic." The models in these aids are used to smooth or correct the
wholistic judgments and to partial them into components.
Since DEMO of the decision aids rely on assessments of probability, we start DEMO
section with a review of probability elicitation techniques.
Assessing Probabilities
What's the best way to assess probabilities? Spetzler & Stiiel von Holstein (DEMO) have
written an excellent description of how the Decision Analysis Group DEMO Stanford
Research Institute approaches this problem. They recommended (a) carefully struc­
turing the problem with the client ("mental acrobatics should be minimized",
p. 343), (b) minimizing biases that might affect the DEMO, (c) using personal
interviews rather than computer-interactive techniques with new DEMO, and (d)
using several different elicitation methods, both direct DEMO indirect. Their favorite
elicitation technique is a reference bet involving a "DEMO wheel," a disk with
two differently colored sectors whose relative size is adjustable. The assessor is
offered two bets, each with the same payoff. One bet concerns the uncertain quantity
(you win if next year's sales exceed $X)j the other bet concerns the disk (you win
if the pointer lands in the orange sector after the disk DEMO spun). The relative size of
the two sectors is varied until the assessor is indifferent between the two bets. The
proportion of the DEMO which is orange is taken as the probability of the event stated
in the other bet.
Despite the appeal of this method (it is formally justified within axiomatic models
of subjective probability, does not require the assumption that the utility of money
is linear with money, and requires no numerical response from the assessor), we have
been unable to DEMO any research on its use.
DISCRETE EVENTS Comparisons among several direct methods for assessing the
probabilities of discrete events (probabilities vs odds vs log odds) have failed to
identify one clearly preferable response mode (35, 73a, 105). Beach (22) found a
mean within-subject correlation of only 0.49 between probabilities assessed directly
and indirectly (via bids for bets). DuCharme & Donnell (76) found equally conserva­
tive inferences using DEMO, probabilities, and an indirect method similar in concept
to, but DEMO complicated than, the reference bet method discussed by Spetzler &
Stilel von Holstein (260).
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY 19
These studies focused on the assessment of middle-range DEMO; even less
is known about assessing very large or very small DEMO Slovic, Fischhoff' &
Lichtenstein (251 ) have shown that subjects grossly misuse odds of greater than
50: 1. Selvidge (24 1) has made some common-sense suggestions for assessing very
small probabilities. She advised DEMO structuring and decomposing the problem, then
ranking various unlikely events, and finally attaching numbers to those events with
the help of reference events (like dying in various rare accidents).
Once you have assessed a DEMO, how good is it? When there is an agreed­
upon "DEMO probability"-as with bookbag and poker chip tasks-the assessed
probability may be compared with the "truth." But more often the assessed proba­
bility DEMO a degree of belief in some proposition, so that no criterion "true"
probability value exists. One test of such probabilities is coherence, that is, do they
abide by the axioms of probability? (290, 316). A second kind of validity, called
calibration, may be examined if one collects a large number of assessments for which
the DEMO of the associated propositions is known. For discrete propositions, calibra­
tion DEMO that for every collection of propositions assigned the same numerical
probability, DEMO hit rate or proportion which actually is true should be equal to the
assessed probability. The research on calibration has recently been reviewed exten­
DEMO (1 75), so only a summary of findings will be DEMO here: (a) Experienced
weather forecasters, when performing their customary tasks, are excellently cali­
brated. (b) Everybody else stinks. (c) People are overconfident except with very easy
tasks.
UNCERTAIN QUANTITIES The most common DEMO for assessing probability
density functions across uncertain quantities is the fractile method. An assessor who
names a value of an uncertain quantity as its DEMO fractile, for example, is saying that
there is just a 25% chance that the true value will be smaller than that specified
value. DEMO von Holstein (263) and Vlek (290) have studied the consistency between
the fractile method and other elicitation methods. Stael von Holstein found DEMO
even after four sessions most subjects were inconsistent. Vlek's subjects showed
greater consistency.
Continuous probability density functions can also be tested for calibration. DEMO
sors are calibrated when, over many such assessments, the proportion of true
answers falling below a given fractile is equal to that fractile. DEMO evidence on
calibration (175) may be summarized as follows: (a) A strong and nearly universal
bias exists: the assessed distributions are DEMO tight, so that from 20% to 50% of the
true values, instead of 2%, fall outside of the 0.01 to 0.99 range of the distributions.
(b) Training improves performance.
SCORING RULES Scoring rules are DEMO which assign a score to an assessed
probability (or a vector DEMO probabilities) as a function of both the true outcome of
the DEMO being assessed and the size of the probability associated with the true
outcome. Such rules are strictly proper if and only if the only DEMO for maximiz­
ing one's expected score is to tell the truth-to state one's true belief without
hedging. Usually the only rules considered DEMO those which reward expertise: given
Annu. Rev. Psychol. 1977.28:1-39. Downloaded DEMO arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
20
SLOVIC,
FISCHHOFF & LICHTENSTEIN
that one tells the truth, the more one knows, the larger the score [an exception is
Vlek's (29 1) fair betting game]. Scoring rules have recently been discussed DEMO
Murphy & Winkler (205, 206) and by Shuford & Brown (50, 246).
Scoring rules may be used for three purposes. The first use is as an indirect method
for measuring probabilities. A list DEMO bets is generated from the scoring rule. Each
bet gives two numbers, how much the assessor wins if the event in question occurs
and how much is lost if it does not. The assessor selects his DEMO her preferred bet from
the list; this choice implies a probability. DEMO & Peterson (1 36) and Seghers,
Fryback & Goodman (DEMO) found this method unsatisfactory; their subjects were
apparently using other strategies rather than trying to maximize winnings.
The second use of scoring rules DEMO to educate assessors about probability assess­
ments made with other methods. Several studies have used scoring rule feedback
(246, 262, 308) without DEMO whether it helped. Hoffman & Peterson (1 20)
reported that DEMO who received such feedback improved their scores on a
subsequent task, DEMO Vlek (290) found no such improvement. Scoring rules are now
widely used by weather forecasters, and this may be why they are so wen calibrated
(1 75). Murphy & Winkler (207) reported that a majority of 689 weather forecasters
(a) described themselves as being DEMO thinking in probabilistic terms
(though their job is to report probabilities DEMO they do it well), and (b) rejected the
idea that their forecasts can be properly evaluated by a single quantitative measure
like DEMO scoring rule (though many had had experience with such feedback).
DEMO third use for scoring rules is to evaluate assessors. When all assessors are
working in the same situation, the assessor with the highest score is the best assessor.
However, not all situations are equal; there DEMO more uncertainty in forecasting rain
in Chicago than in Oregon. Thus Oregon forecasters will earn higher scores simply
because of where they work. Murphy (203) has shown that the Brier scoring rule
(the one used DEMO meteorology) may be partitioned into three additive components,
measuring (a) the inherent uncertainty in the task, (b) the resolution of DEMO assessor
(Le. the degree to which the assessor can successfully assign DEMO different
from the overall hit rate), and (c) the assessor's calibration. None of the components
is itself a proper scoring rule, but the difference between the total score and the
inherent uncertainty component DEMO proper, and this difference could be used to
compare assessors in DEMO situations (204).
The astute reader will note that the research DEMO not provide an adequate answer
to the question. asked at the start of this section: What is the best way to assess
probabilities? DEMO addition, the research has yielded few theoretical ideas. Only Pitz
(219) has speculated on the cognitive processes underlying probability assessment.
Finally, although DEMO few studies have noted that training improves performance in
eliciting probabilities, DEMO definitive long-range learning study is still needed.
Mul
tiattrib ute Utility Theory
Suppose you must choose one object or course of action from a DEMO Each object or
action is describable in terms of a number of dimensions or attributes of value to
you, and the outcomes of your choice are certain. Then multiattribute utility theory
Annu. Rev. Psychol. 1977.28:1-39. DEMO from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY 21
(MAUT) prescribes that you compute, for each object j, the following weighted
utilities, summed across the attributes i:DEMO
j = 7w;Uij
MAU
where w; is the relative importance DEMO the ith attribute and uij is the utility of the
jth object on the ith attribute. For example, when choosing a car, w; might be the
importance of design, and uij would indicate how beautifully designed car j is. The
theory prescribes that you choose the car DEMO the largest MAU. While this model
is the most common, variants DEMO which incorporate additional features such as
uncertainty, multiplicativity (rather than additivity) of the weighted utilities, time
factors, and the possibility that your choice will affect others (293).
MAUT is a decision aid strongly grounded in theory. The axioms of the theory
lead to the models, to methods for measuring the utilities and weights, and to
specified tests that show which of the models is applicable. MAUT models have been
DEMO extensively in the last 5 years (94-96, 141, 143, 233, 234). If these sources
are too technical, the review papers DEMO MacCrimmon (1 86), Fischer (86, 88), von
Winterfeldt & Fischer (296), Humphreys (13 1), and Huber (1 DEMO) may be helpful.
ASSESSMENT TECHNIQUES The first step in constructing a DEMO is to list the
attributes. Techniques for doing this are rarely discussed. Among those who have
faced the problem, some have used the Delphi technique (e.g. 102, 21 1). Humphreys
& Humphreys (1 32) suggested using George Kelly'S repertory grid technique.
Dalkey, Lewis & DEMO (65) proposed evaluating diverse problems (e.g. job choice,
modes DEMO transportation) not on the basis of their apparent attributes but on DEMO
common set of attributes reflecting quality of life (e.g. security, fun, freedom). Beach
et al (23) described an extensive interviewing technique, involving several interac­
tions with different decision makers, to arrive at DEMO list of attributes.
It seems obvious that the omission of an important attribute can seriously alter
the results of a MAUT application. However, Aschenbrenner & Kasubek (12) found
reasonably similar results for preferences among apartments DEMO MAU analyses
based on two different, only partially overlapping sets of DEMO
Weights and utilities can be assessed either directly or indirectly. Direct ap­
proaches, which are simple but not theoretically justified, include ranking or DEMO
scales, or just asking the assessor for the relevant numbers. For DEMO, the assessor
may be presented with graph paper and asked to DEMO a curve. Utility functions
may also be derived by constructing indifference curves for pairs of variables (189,
190); these methods are lengthy, tedious, and clearly impractical when there are
many variables. After two DEMO curves for the same pair of variables are
assessed, a "staircase" method can be used by the analyst to uncover the utility
curves for each of the variables, assuming that the variables are value independent
(see 156, p. 51-6 1).
Indirect methods are justified within DEMO theory, but are exceedingly complex.
They rely on a comparison between DEMO gamble and a sure thing, and thus introduce
probabilities into an DEMO riskless situation. For example, to assess the weight
Annu. Rev. Psychol. DEMO:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
22 SLOVIC, FISCHHOFF & LICHTENSTEIN
of one attribute from a set of 14 attributes describing apartments (such as number
of bedrooms, general cleanliness, etc), the analyst says, "Apartment A has the best
(most preferred) level of all 14 attributes. Apartment B has the worst level of all
14 attributes. Apartment C has the best level on one DEMO and the worst level
on each of the other 13. State a probability p such that you are indifferent between
receiving C for sure DEMO receiving a gamble wherein you will obtain A with
probability p and B with probability (l-p). What is the value of p that makes you
indifferent?" The value of p that you name is DEMO weight; such a question must be
asked for each attribute.
The DEMO indirect methods for assessing utilities are similar to the indirect method
for assessing weights, except that "Apartment C" now has an intermediate level for
one alternative, and the worst level for all others. In the variable-probability method,
as with assessing weights, the task is to name a probability that makes the sure thing
(Apartment C) indifferent to DEMO gamble. In the fixed-probability method, the
probabilities associated with the gamble DEMO held constant at (1 12, 112), and the
assessor must name that intermediate value on one attribute of the sure thing which
DEMO to indifference. In either case, one answer gives only one point DEMO the utility
curve, so that several responses are required to estimate DEMO shape, for each attribute.
Kneppreth et al (1 56) have DEMO an excellent review of the methods for assess­
ing utilities, explaining DEMO method in detail, noting advantages and disadvantages,
and referencing relevant DEMO That research has been unsystematic and allows
no clear conclusions. Perhaps future researchers should model their work on a study
by Vertinsky & Wong (289). Comparing an indifference curve method with the
indirect fixed-probability method, they looked at test-retest reliability and a host of
other indices, including the acceptance of particular rationality axioms, realism of
the task, confidence DEMO the method, bias in the interpretation of probability, and a
measure of the width of an indifference band across the variables. They found DEMO
the indirect method was more reliable and easier for the subjects, DEMO the indiffer­
ence curve technique predicted more subsequent choices.
ISSUES In MAUT, two issues are paramount. The first is: Is it valid? Early re­
search in the use of MAUT frequently involved correlating the results DEMO the model
with unaided wholistic judgments of the same situations made by the same subjects
(e.g. 130, 132, 294, and earlier papers DEMO in the reviews mentioned above).
A high correlation between the model and the wholistic judgments, the usual result,
was taken as evidence that the model was valid. This conclusion seems faulty to us.
If DEMO wholistic preferences are good enough to constitute criteria for a decision
aid like MAUT, who needs the decision aid? Furthermore, a decade or more of
research has abundantly documented that humans are quite bad at DEMO complex
unaided decisions (248); it could thus be argued thlit DEMO correlations with such
flawed judgments would suggest a lack of validity. More sophisticated approaches
have been taken by Fischer (87), who showed greater agreement among three
different decomposition procedures than among three different wholistic proce­
DEMO, and by Newman (208), who proposed applying Cronbach's (DEMO) theory of
generalizability to the problem of validating MAUT techniques.
Annu. DEMO Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY 23
But most practitioners and theorists approach the validity DEMO as follows: the
theory specifies the models, the assessment procedures, DEMO the tests for choosing
which model applies. Thus if you accept the axioms (yes, I do want my choices to
be transitive; I should not be swayed by irrelevant alternatives, etc) and pass the
DEMO, then you can be assured that you are doing the right DEMO There is no
remaining validity question.
The second issue concerns error. Indirect elicitation techniques for both weights
and utilities are, as previously noted, DEMO complex, but theoretically justifiable. The
direct methods, in contrast, seem DEMO, but are theoretically unjustified. If one
assumes that the decision maker DEMO underlying weights, utilities, and preferences,
which approach, direct or DEMO, elicits these underlying values with least error?
Von Winterfeldt (293) discussed but did not resolve this issue. Practitioners can (and
often DEMO) perform sensitivity analyses (how much can I change this parameter before
the decision changes?). Such sensitivity analyses will identify potential problems of
measurement but not solve them.
The tests which are used to determine DEMO MAUT model is applicable are
equally complex. The test for additivity uses the weights derived from the indirect
method. If the weights across all DEMO attributes sum to 1.0, an additive model may
be used. Otherwise, a mUltiplicative model is used. No error theory is available to
tell DEMO whether a sum of, say, 1.4 is "close enough" to 1.0 to justify an additive
model. An alternative, and seemingly easier, DEMO is available for additivity (see 296,
p. 70). Unfortunately, no alternatives are available for two other necessary tests.
These tests are DEMO two kinds of utility independence [called "preferential indepen­
dence" and "DEMO independence" by Keeney (1 42), and "WCUI" and "DEMO" by
others (see 296)]. The following question; with reference DEMO the location of the
Mexico City airport (1 42), is DEMO the starting point for these tests: "How many
people seriously injured or killed per year, call that number x, makes you indifferent
DEMO the option: [x injured or killed and 2500 persons subjected to DEMO noise
levels] and the option: [one person injured or killed and DEMO,500,000 subjected to high
noise level]?" Several such questions must be asked for each attribute and for all
pairs of attributes. The DEMO avoidance of these tests may not reflect laziness,
but a genuine suspicion that using an unjustified model may lead to fewer errors than
DEMO a model on the basis of confused responses to complex questions such as
these. As von Winterfeldt (293) has noted, "even after DEMO go through the process
of model elimination and selection, you will DEMO have to make up your mind about
the possible trade-offs between assessment error and modeling error" (p. 65).
The flavor of the DEMO assessment methods and the three tests mentioned above
may be appreciated by reading 54 pages of dialogue between an analyst (Keeney)
and an expert as they evaluate alternatives for the production of electrical energy
(144).
RECENT RESEARCH The "new look" in MAUT research is to DEMO its uses.
Can it be done? What problems are encountered? What can be learned from apply­
ing MAUT? Gardiner & Edwards (102) showed that in a highly controversial issue
(coastal land development) two DEMO of experts (developers and conservationists)
Annu. Rev. Psychol. 1977.28:1-39. DEMO from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
24
SLOVIC. FISCHHOFF & LICHTENSTEIN
showed notably less disagreement about the evaluation DEMO proposed apartment
buildings in their MAUT evaluations than in their wholistic evaluations. O'Connor
(2 11) reported the difficulties in getting many experts DEMO agree on evaluations of
water .quality while trying to (0) minimize the amount of experts' time needed for
the evaluation, (b) DEMO redundant or strongly interrelated attributes, and
(c) cope with possible DEMO factors (if the water is loaded with arsenic,
nothing else DEMO). Guttentag & Sayeki (1 10) used a MAUT technique to illumi­
nate the cultural differences in values and beliefs about peace issues DEMO Japa­
nese and Americans. In one of two reports of real applications (i.e. working with
clients who paid for the advice), Keeney observed the changes in a MAUT system
after 2 years of use (145). In the second report, he described the complexities of
deciding where and when to build a new airport in Mexico City (142). Additional
proposals for applications of MAUT, without relevant data, have been DEMO for the
development of social indicators (258), military system effectiveness (287), and solid
waste management (ISO). Finally, computer programs DEMO aid elicitation of MAUT
have been written (1 46).
Decision DEMO
ysis
The most general approach for systematically evaluating alternative actions is deci­
sion analysis. an approach developed largely at the Harvard Business School (22 1,
235) and two private contract research firms, the Stanford DEMO Institute (1 25),
and Decisions and Designs. Inc. (49)DEMO In facing a new problem. the analyst lists the
decision alternatives, DEMO a model of their interrelations, assesses the
probabilities of relevant contingencies, finds out what the decision maker wants, and
finally, assays the DEMO value or utility of each alternative. To do this, decision
analysts DEMO a bag of tricks drawn from crafts such as operations research, DEMO
statistics, SEU and MAUT, which allow the analyst to "in DEMO, address any
decision problem with unimpeachable rigor" (49, p. 64). A common tool is the
decision tree which diagrams the uncertain DEMO arising from a decision.
Among the problems that have been given full-dress decision analyses are whether
to seed hurricanes in hopes of reducing their DEMO (1 26), how to establish
planetary quarantine requirements for trips DEMO Mars and Jupiter (1 27), what value
nuclear power generating DEMO have for Mexico (265), and how to design export
controls DEMO computer sales to the Soviet Bloc (7 1). Many environmental DEMO
statements, cost-benefit analyses, and risk assessments constitute variants on deci­
sion analytic-methodology (55, 91, 198, 216).
Although many of these DEMO are already highly sophisticated, the basic
methodology is still developing-<>ften in response to specific problems. Work in the
last 5 years has DEMO our ability to evaluate decision trees efficiently (288), assess
the DEMO of decision flexibility (1 94). and understand how models approximate DEMO
processes they are intended to describe (276).
Some awareness of DEMO issues can be found in decision analysis. One
example attempts to use the best psychological scaling techniques for eliciting
probability judgments (260). Another emphasizes communicating effectively with
decision makers; the analyst is encouraged to develop a role "not too dissimilar to
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal DEMO only.
BEHAVIORAL DECISION THEORY 25
that of a psychoanalyst" (49, p. 9). Brown (48) raised a cognitive problem that
warrants further examination. DEMO noted that decision analyses often fail to model
responses to future events. As a result, when those future events actually occur, they
are DEMO to in totally unanticipated ways, because in the flesh they look
DEMO than they did at the time of the analysis.
Man/Machine Systems
For years, one of the most promising areas in decision aiding has been the develop­
ment of computerized aids for helping decision makers cope DEMO complex problems.
Systems designed to elicit MAUT appraisals fall into this category, as do the
approaches described below.
REGRESSION APPROACHES Research within the regression paradigm has shown
that people have difficulty both applying the judgmental policies DEMO wish to
implement and describing the policies they actually are implementing. Hammond
and colleagues have developed computer-graphics systems to combat both of these
problems (l13a, 11 7). Since these techniques can describe the policies of several
participants in a given situation, they have been used to resolve interpersonal and
intergroup conflicts (39) and to facilitate policy formation at DEMO societal level (2,
11 6).
Another major decision-aiding technique DEMO bootstrapping, which replaces judges
with algebraic models of their own weighting DEMO Recent research has contin­
ued to demonstrate that these models perform as well as or better than the judges
themselves (14, 68, 119, 202, 237, 307). Additional work promises to further en­
hance the usefulness of bootstrapping. Einhorn (8 1, 82) showed how expert judg­
ment and statistical techniques can incorporate poorly defined and hard to DEMO
variables into judges' models. Dawes & Corrigan (70) demonstrated that DEMO most
situations the criterion being judged could be predicted well by models with unit
weights (see also 83, 297). These unit-weighting results DEMO that in many deci­
sion settings, all the judge needs to DEMO is what variables to throw into the
equation, which direction (+ or -) to weight them, and how to add. Actually,
DEMO Franklin had this insight about unit weighted linear models back in 1772
(1 86, p. 27).
PIP One of the earliest proposals DEMO sharing the decision-making load between the
machine and the decision maker was (79) the Probabilistic Information Processing
System (PIP). In situations where judges must revise their probabilities upon receipt
of new information, the PIP system accepts the judges' subjective assessments of
prior probabilities, and of DEMO probability of each datum conditional on each hypoth­
esis, and then DEMO them according to Bayes' theorem in order to produce
posterior probabilities DEMO the hypotheses. A review in 1971 (254) revealed an abun­
dance of research on PIP; since then, however, the flood has receded. A few recent
studies have. discussed what to do when the data DEMO not conditionally independent
of one another and have examined how well subjects handle such data (74, 129, 266).
A couple of interesting medical applications have been proposed (21a, 108, 109).
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/DEMO/09. For personal use only.
26
SLOVIC, FISCHHOFF & LICHTENSTEIN
DYNAMIC SYSTEMS Some of the most ambitious interactive man/machine sys­
tems have been developed to handle dynamic decision-making DEMO The prob­
lems studied by researchers in this area are extremely varied and the systems
developed to solve them tend to be highly specific. DEMO a pattern of conceptual­
izing the task, developing the mathematics and DEMO to handle it, and then
validating the system in one or DEMO series of experiments is common. As an example,
a team at Perceptronics, Inc. has developed a highly sophisticated system to assist
naval officers tracking "the elements of a simulated fishing fleet [one trawler and one
iceberg] as it moves about in an expanse of ocean," a DEMO that vaguely resembles
a futuristic version of Battleships (67, sect. 3, p. 1). The system tracks the decision
maker's responses continuously and uses utilities inferred from them to recommend
maximum expected utility decisions (98). From an experiment testing the system
with 12 Naval Reserve DEMO during four 90-minute sessions, Davis et al (67)
concluded that it worked in realistic decision-making situations, was accepted by
experienced operators, DEMO markedly improved performance.
Such systems may be designed either as products that will actually work in some
field situation or as research tools. Perhaps DEMO of their expense, most products
have been designed to solve specific DEMO problems with no civilian analog
[although readers concerned about the possible presence of Soviet frogpersons in
their bathtub or swimming pool might want to DEMO Irving (13 3)]. It is difficult
for the nonexpert to DEMO the validity of these systems and the acceptability of their
advice.
With systems designed for research purposes, a critical issue is the tradeoff
between realism and generality. One strategy is to design systems whose complexity
begins DEMO approach that found in the real world-at the risk of investing too much
of available resources in the machine and too little in understanding DEMO people use
it. Some human factors questions worth studying are (a) how do variations in the
basic system (e.g. different instructions or information displays) affect people's
performance? (b) how do person and DEMO errors interact? (c) how should
machine output be adjusted to DEMO decision makers' cognitive styles and work
paces (170, 17 1)? and (d) when do people heed the machine's advice (DEMO 11 . 11 2)?
Another problem with these systems is DEMO their very complexity makes it
difficult to compare results from one research context to the next. Perhaps the only
way to do that is DEMO interpret the results in terms of basic psychological Gudgmental)
phenomena. If that tack is taken, then one might ask whether the development of
general behavioral principles would not be served best by using a number DEMO simpler,
cheaper, and more flexible systems, such as the tactical and negotiations game used
by the Streuferts and colleagues (e.g. 269). Research showing why man/machine
systems should be adopted might provide a DEMO convincing case than the demon­
stration in a complex simulation that decision makers do better with the machine's
help. The skeptic may argue DEMO such demonstrations merely show that one can
design a simulated task in which it helps to have machine assistance.
Using Deci
sion Ai
ds
DEMO decision makers use these sophisticated techniques? Bootstrapping is now being
applied DEMO a variety of repeated decisions. On the other hand, apparently few, if any,
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by DEMO OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY
27
PIP systems are operational today despite the mass DEMO research refining its methodol­
ogy. For most aids, a clear picture DEMO hard to come by. In the scientific literature
one can find demonstration projects showing a procedure's viability. However, when
a technique passes the test of getting someone to pay for it, the result typically
becomes proprietary. For reasons of national or industrial security, the details of
such projects are not divulged, nor are the decision makers' responses to DEMO Most
overviews by those in the decision aiding business understandably tend to be quite
optimistic.
Brown (47, 49), however, has presented an insightful discussion of factors that
may limit decision makers' receptiveness to decision analysis and presumably to
other techniques as well. One is the fact DEMO decision makers often employ an
analyst to reduce the uncertainty in a problem situation, not to acknowledge and
quantify it. Another source of resistance is the absence of top-level decision makers
familiar with the technique; a third is the bad experiences of decision makers who
try to solo DEMO the technique without proper training. Brown, Kahr & Peterson (49)
suggested that decision analysis is a clinical skill that should only be DEMO after
internship with an expert.
Another problem is that decision makers may, even after careful coaching, reject
the basic conception (e.g. the axioms) on which the aids are based. Protocols of
conversations between analysts and decision makers leave the impression that deci­
sion makers are under considerable DEMO to adopt the analyst's perspective. It
is debatable whether satisfaction with the results of such an analysis show that the
analyst has really DEMO the decision maker's needs. Conrath (58) and Reeser
(227) found that decision makers reject decision analysis (and related techniques)
for being both overly complicated and divorced from reality. Individuals who may
accept DEMO assumptions of such analysis may still reject their logical implications if
they are unintuitive or too difficult to explain and justify to others.
A DEMO discussed earlier is whether decision makers can provide the required
probability, DEMO, and modeling judgments. Because of the vagaries of such judg­
ments, the decision aider runs the risk of grinding through highly sophisticated
analyses DEMO inputs of very little value. Certainly "garbage in-garbage out" applies
to decision aiding-with the particular danger that undue respect may be given to
DEMO produced by high-powered and expensive grinding. Relatively little is
known about the sensitivity of decision aids to errors in elicitation and problem
structuring. Von DEMO & Edwards (294a) have proved that under very general
conditions probability and utility estimates can be somewhat inaccurate without
leading to appreciably suboptimal DEMO Their proof is applicable to the case
where decision options are continuous (e.g. invest X dollars). However, Lichten­
stein, Fischhoff & Phillips (1 75) have shown how a moderate error in probability
estimation DEMO lead to a substantial decrease in expected utility when the decision
options are discrete (e.g. operate vs don't operate). Von Winterfeldt & Edwards
(295) have identified a large class of errors which can DEMO to large expected losses
and are extremely difficult to detect. They arise from the selection of dominated
decision alternatives as the result of inappropriately DEMO the decision problem.
How much is a decision aid worth? This DEMO question is typically answered
with arguments why aids should, in principle, be worth the resources invested in
Annu. Rev. Psychol. 1977.28:1-39. Downloaded DEMO arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
28
SLOVIC, FISCHHOFF & LICHTENSTEIN
them. Recently Watson & Brown (303) provided enlightenment with a formal model
for performing a decision analysis of DEMO decision analysis. The model is accompanied
by three case studies (304) that highlight the difficulties of performing a hindsightful
analysis. Ironically, the greatest value of two of these analyses came from their
contribution to organizational DEMO (reduction of controversy and improve­
ment of communication), considerations that DEMO left out of the formal model for
the sake of simplicity.
CONCLUSION
One reason for the vitality of the research described here is the DEMO importance
of deliberative decision making in our daily lives. In a nontraditional society individ­
uals must rely on their analytical resources rather than habit DEMO guiding their affairs.
A rapidly changing and interrelated world cannot allow itself the lUXUry of trial and
error as it attempts to cope with DEMO like nuclear power and natural hazard
management. Economists, engineers, operations researchers, decision analysts and
others are developing sophisticated procedures for these problems. It is our job as
psychologists to remind them of the human component DEMO implementing these
techniques and explaining their conclusions to the public-in particular to point out
the errors that may arise from judgmental biases. We must DEMO the public to make
its private decisions and to develop a critical perspective on those decisions made
in its behalf.
Literature Cited!
1. Abelson, R. P. 1976. Script processing
in attitude formation and deCision mak­
ing. DEMO Cognition and Social Behavior,
ed. J. S. Carroll, J. W. DEMO Hillsdale,
NJ: Erlbaum. In press
2. Adelman, L., Stewart, T. R., Ham­
mond, K. R. 1975. A case history of DEMO
application of social judgment theory to
policy formulation. Policy Sci. 6: DEMO
3. Alker, H. A., Hermann, M. G. 197 1.
Are DEMO decisions artificially intel­
ligent? The effect of task and personality
on DEMO in processing informa­
tion. J. Pers. Soc. Psycho! 19:3 1-4 1
4. Allais, P. M. 1953. The behavior of ra­
tional man in risk situations-A cri­
tique of the axioms and postulates of the
American DEMO Econometrika 21:
503-46
5. Anderson, N. H. 1972. Looking for
DEMO in clinical judgment. Psy­
chol. Bull 78:93-102
6. Anderson, N. DEMO 1974. Algebraic mod­
els in perception. In Handbook of Per-
ception, DEMO E. C. Carterette, M. P.
Friedman, pp. 21 5-98. New York: Aca­
demic. 556 pp.
7. Anderson, N. H. 1974. Information in­
DEMO theory: A brief survey. In
Measurement, Psychophysics, and Neu­
ral DEMO Processing, ed. D. H.
Krantz, R. C. Atkinson, R. D. DEMO,
P. Suppes, 2:236--305. San Francisco:
Freeman. 468 pp.
DEMO Armelius, B., Armelius, K. 1974. Utili­
zation of redundancy in DEMO
judgments: Data from a suppressor
variable task. Am. J. Psychol. 87:DEMO
9. Armelius, K., Armelius, B. 1976. The
effect of cue-criterion DEMO, cue
intercorrelations and the sign of the cue
intercorrelation on performance DEMO sup­
pressor variable tasks. OBHP. In press
10. Armstrong, G. M., Kendall, C. L.,
Russ, F. A. 1975. Applications of con­
DEMO information processing research
to public policy issues. Commun. Res.
2:232-45
of Ex
ITo conserve space, frequently cited sources have been abbreviated as follows: JEP (J
perimental Ps
ychology); OBHP (Organizational Behavior and Human Per
f
ournal
ormance).
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from DEMO
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY
29
11 . Armstrong, J. S., Denniston, W. B. Jr.,
Gordon, M. M. 1975. The use of the
decomposition principle in making
judgments. OBHP 14:257-63
12. Aschenbrenner, K. M., DEMO, W.
1976. Convergence of multiattribute
evaluations when different sets of at­
DEMO are used. In Proceedings of the
Fifth Research Conference on Subjective
Probability. Utility. and Decision Mak­
ing. ed. H. Jungermann, G. de Zeeuw.
In press
13. Ashton, R. H. 1974. Cue utilization and
expert judgments: DEMO comparison of in­
dependent auditors with other judges.
J. Appl Psychol 59:437-44
14. Ashton, R. H. 1975. User prediction
models in accounting: DEMO alternative
use. Account. Rev. 50:7 10-22
15. Barclay, S., Beach, L. R., Braithwaite,
W. P. 1971. Normative models in the
DEMO of cognition. OBHP 6:389-413
16. Bar-Hillel, M. 1973. On the DEMO
probability of compound events. OBHP
9:396-406
17. Bar-Hillel, M. 1974. DEMO and
probability. OBHP 11 :277-82
18. Barron, F. H. 1974. Behavioral decision
theory: A topical bibliography for man­
agement scientists. Interfaces 5:56-62
19. Barron, F. H., Mackenzie, K. D. 1973.
A constrained optimization model of
risky decisions. J. Math. Psychol. 10:
60-72
20. Bauer, M. 1971. Accuracy and congru­
ence in estimations of probabilities and
odds DEMO binomial distributions. Umea
Psyc�ol Rep. 36. Umea, Sweden: Univ.
Umea
21. Bauer, M. 1973. Inference strategies in
Bayesian tasks not requiring high scale­
level responses. Umeii Psychol Rep. 61.
Ume£, Sweden: Univ. Ume�
21a. DEMO, B. H. 1975. Expert judgment
about uncertainty: Bayesian decision
making in realistic settings. OBHP
14: 10-59
22. Beach, L. R. 1974. A DEMO on the
intrasubject similarity of subjective
probabilities obtained by estimates and
by bets. OBHP 11 :250-52
23. Beach, L. R., Townes, B. DEMO, Campbell,
F. L., Keating, G. W. 1976. Developing
and DEMO a decision aid for birth plan­
ning decisions. OBHP 15:99-1 16
24. Becker, G. M., McClintock, C. G. 1967.
Value: Behavioral DEMO theory. Ann.
Rev. Psychol 18:239-86
25. Berkson, J., Magath, DEMO B., Hum, M.
1940. The error of estimate of the blood
cell count as made with the hemocy­
tometer. Am. J. Physioi. 128:DEMO
26. Ber!, J., Lewis, G., Morrison, R. S.
1976. DEMO models of choice in
important and nonrepetitive situations.
See Ref. 1
27. Bettman, J. R. 1971. A graph theory
approach to comparing consumer infor­
mation processing models. Manage. Sci.
18:1 14-28
28. Bettman, J. R. 1974. Toward a statistics
for consumer decision net models. J.
Consum. Res. DEMO:7 1-80
29. Bettman. J. R. 1975. Issues in designing
consumer information environments. J.
Consum. Res. 2:1 69-77
30. Bettman, J. R., DEMO, N., Lutz, R.
1975. Multiattribute measurement
models and multiattribute attitude DEMO
ory: A test of construct validity. J. Con­
sum. Res. 1:DEMO
3 1 . Bettman, J. R., Jacoby, J. 1975. Pat­
DEMO of processing in consumer infor­
mation acquisition. Papers in Consumer
Psychol. No. 150. West Lafayette, Ind:
Purdue Univ.
32. Birnbaum, M. H. DEMO Intuitive nu­
merical prediction. Am. J. Psychol In
press
33. Bjorkman, DEMO 1973. Inference behavior
in nonmetric ecologies. In Human
Judgment and Social Interaction. ed. L.
Rappoport, D. A. Summers, pp. 144-
68. New York: Holt, Rinehart & Win­
ston. 403 pp.
34. Bond, N. A. DEMO 1974. Basic strategy and
expectation in casino blackjack. OBHP
12:41 3-28
35. Braithwaite, A. 1974. A note compar­
ing three measures of subjective proba­
bility, their validity and reliability. Acta
Psychol 38:337-42
36. Brehmer, B. 1971. Subjects' ability to
use functional rules. Psychon. Sci.
24:DEMO
37. Brehmer, B. 1973. Note on clinical
judgment and the formal DEMO
of clinical tasks. Ume& PsychoL Rep. 77.
Ume£, Sweden: Univ·. DEMO
38. Brehmer, B. 1974. Hypotheses about re­
lations between scaled variables DEMO the
learning of probabilistic inference tasks.
OBHP 11 :1-27
39. Brehmer, B. 1976. Social judgment the­
ory and the analysis of interpersonal
conflict. DEMO Bull In press
40. Brehmer, B., Kuylenstierna, J., Lil­
jergren, J. 1974. Effects of function form
and cue validity on subjects' DEMO
in probabilistic inference tasks. OBHP
11 :338-54
Annu. Rev. Psychol. 1977.28:DEMO Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
30
SLOVIC, FISCHHOFF & LICHTENSTEIN
41. Brehmer, B., Kuylenstierna, J., Lil­
jergren, J. 1975. Effects of information
about the probabilistic nature of the
task on learning of uncertain inference
tasks. Umea PsychoL Rep. 90. DEMO,
Sweden: Univ. Umea
Brehmer, B., Quarnstrom, G. 1976. In­
formation integration and subjective
weights in multiple-cue judgments.
OBHP. In press
Brewer, J. K., Owen, P. W. 1973. A
note on the power DEMO statistical tests in
the Journal of Educational Measure­
ment. J. Educ. Meas. 10:71-4
Brickman, P. 1972. Optional stopping
on ascending and descending series.
OBHP 7:53-62
Brickman, P., Pierce, S. M. 1972. Esti­
mates of conditional probabilities of
confirming versus disconfirming events
as a function of DEMO situation and
prior evidence. JEP 95:235-37
Brooks, W. N., Doob, A. N. 1975. Jus­
tice and the jury. J. Soc. Issues
31:1 71-82
Brown. R. V. 1971. Marketing applica­
tions of personalist decision DEMO
MSI Field Res. Proj Rep. P-55.
Cambridge: Manage. Sci. Inst.
Brown, R. V. 1975. Modeling subse­
quent acts for decision analysis. DDI
Tech. DEMO 75-1. McLean, Va: Deci­
sions & Designs
Brown, R. V., Kahr, A. S., Peterson, C.
1974. Decision Analysis for the Man­
ager. New York: Holt, Rinehart &
Winston. 618 pp.
Brown, DEMO A., Shuford, E. H. 1973.
Quantifying uncertainty into numerical
probabilities for the reporting of intelli­
gence. RAND Rep. 1 l85-ARPA. . Santa
Monica: Rand Corp.
Buckhout, R. 1974. Eyewitness testi­
mony. Sci. Am. 231 :DEMO 1
Castellan, N. J. Jr. 1972. The analysis of
mUltiple criteria DEMO multiple-cue judg­
ment tasks. OBHP 8:242-61
Castellan, N. J. Jr. DEMO Comments on
the "lens model" equation and the anal­
ysis of multiple-cue judgment tasks.
Psychometrika 38:87-100
Castellan, N. J. Jr. 1976. Decision mak­
ing with multiple probabilistic cues. In
Cognitive Theory, ed. N. J. Castellan
Jr., D. B. Pisoni, G. R. Potts, Vol. 2.
Hillsdale, NJ: Erlbaum. In press
Coates, J. F. 1976. The role of formal
models in technology assessment. Tech.
Forecasting Soc. Change. In press
Cohen, J. 1962. The statistical power of
abnormal-social psychological research.
J. Abnorm. Soc. DEMO 65:145-53
57. Cohen, J., Chesnick, E. I., Haran, DEMO
1972. A confirmation of the inertial-1jI
effect in sequential choice and decision.
Br. J. PsychoL 63.4. 1-6
58. Conrath, D. W. 1973. From statistical
decision theory to practice: Some prob­
lems with the transition. Manage. Sci.
19:873-83
59. Cook, R. L. 1974. An interactive and
iterative approach to computer-aided
policy capturing. Prog. Res. Hum.
Judgment Soc. Interaction Rep. 64.
DEMO: Inst. Behav. Sci., Univ. Colo­
rado
60. Coombs, C. H. DEMO Portfolio theory
and the measurement of risk. In Human
Judgment and Decision Processes, ed.
M. F. Kaplan, S. Schwartz. pp. 64-83.
New York: Academic. 325 pp.
61. Coombs, C. H., Huang, L. C. 1974.
Tests of the betweenness property of ex­
pected utility. MMPP Rep. 74-13. DEMO
Arbor: Univ. Michigan
62. Corbin, R. M., Marley, A. A. 1974.
Random utility models with equality:
An apparent but not actual DEMO
tion of random utility models. J. Math.
PsychoL 11 :274-93
63. DEMO, R. M., Olson, C. L., Abbon­
danza, M. 1975. DEMO effects in op­
tional stopping decisions. OBHP 14:
207-16
64. Cronbach, L. J., Gieser, G., Nanda, H.,
Rajaratnam, N. DEMO The Dependabil­
ity of Behavioral Measurements: Theory
of Generalizability for Scores DEMO Pro­
files. New York: Wiley
65. Dalkey, N. C., Lewis, R., Snyder, D.
1970. Measurement and analysis of the
quality of DEMO: With exploratory illus­
trations of applications to career and
transportation choices. DEMO RM-
6228-DOT. Santa Monica: Rand Corp.
66. Davenport, W. G., DEMO, M. A.
1973. Expectation theories of decision
making for duplex gambles. DEMO Psy­
chol 37: 155-72
67. Davis, K. B., Weisbrod, R. L., Freedy,
A., Weltman, G. 1975. Adaptive com­
puter aiding in dynamic decision pro­
cesses: An experimental study of aiding
effectiveness. Tech. Rep. PTR-JOJ6- 75-
5. Woodland Hills, Calif: Perceptronics
68. Dawes, R. M. 1971. A case study of
graduate admissions: Applications of
three principles of human decision mak­
ing. Am. Psychol. 26:1 80-88
69. Dawes, R. M. 1976. Shallow psy­
chology. See Ref. I
42.
43.
44.
DEMO
46.
47.
48.
49.
50.
51.
52.
53.
54.
55.
56.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on DEMO/28/09. For personal use only.
BEHAVIORAL DECISION THEORY
31
70. Dawes, R. M., Corrigan; B. 1974. Lin·
ear models in decision making. Psychol
Bull. 81 :95-106
71. Decisions & Designs, Inc. 1973. Com·
puter sale to the Soviet bloc. Tech. Rep.
72. Dershowitz, A. M. 1968. Psychiatry in
the legal process: "Knife that cuts both
ways." Judicature 51:370-77
73. Dillon, 1. DEMO 1971. An expository review
of Bernoullian decision theory. Rev.
Mark. Agric. Econ. 39:3-80
73a. Domas, P. A., Goodman, B. C., Peter·
DEMO, C. R. 1972. Bayes's theorem: Re·
sponse scales and feedback. Eng. Psy·
chol Lab. Tech. Rep. 03723(J..5·T. Ann
Arbor: Univ. Michigan
74. Domas, P. A., Peterson, C. R. 1972.
Probabilistic information processing
systems: Evaluation with conditionally
dependent data. OBHP 7:77-85
75. Donnell, DEMO L., DuCharme, W. M.
1975. The effect of Bayesian feedback
on learning in an odds estimation task.
OBHP 14:305-13
76. DuCharme, W. M., Donnell, M. L.
1973. Intrasubject comparison of four
response modes DEMO "subjective proba·
bility" assessment. OBHP 10: 108-17
77. Ebert, R. I. 1972. Human control of a
two·variable decision system. OBHP
7:237-64
DEMO Edwards, W. 1961. Behavioral decision
theory. Ann. Rev. Psychol 12:473-98
DEMO Edwards, W. 1962. Dynamic decision
theory and probabilistic information
processing. Hum. DEMO 4:59-73
79a. Edwards, W. 1972. Application of re·
search on DEMO to man·machine
system design. Eng. Psychol Lab. Rep.
010342·1·F. Ann Arbor: DEMO Michi·
gan
80. Edwards, W. 1975. Comment. J. Am.
Stat. Assoc. DEMO:291-93
81. Einhorn, H. 1. 1972. Expert measure·
ment and mechanical DEMO
OBHP 7:86-106
82. Einhorn, H. 1. 1974. Cue definition and
DEMO judgment. OBHP 12:30-49
83. Einhorn, H. I., Hogarth, R. DEMO 1975.
Unit weighting schemes for decision
making. OBHP 13:17 1-92
84. Einhorn, H. I., Koelb, C. 1976. Psycho·
metric study of literary critical judg.
ment. Grad. Sch. Bus. Work. Pap. Univ.
Chicago Press
85. DEMO, D. 1961. Risk, ambiguity, and
the Savage axioms. Q. 1. DEMO 75:
643-49
86. Fischer, G. W. 1975. Experimental ap·
plications DEMO multi·attribute utility
models. In Utility, Probability, and Hu·
man Decision Making, ed. D. Wendt,
C. A. J. Vlek, pp. 7-46. Dordrecht, The
Netherlands: Reide!. 418 pp.
87. Fischer, G. W. 1972. Four DEMO for
assessing multi·attribute utilities: An
experimental validation. Eng. Psycho/.
Lab. DEMO Rep. 03 7230·6· T. Ann Ar·
bor: Univ. Michigan
88. Fischer, G. W. 1976. Multidimensional
utility models for risky and riskless
choice. OBHP. DEMO press
89. Fischhoff, B. 1975. Hindsight ;c fore·
sight: The DEMO of outcome knowl·
edge on judgment under uncertainty.
JEP: Hum. Percept. DEMO
1:288-99
90. Fischhoff, B. 1976. Attribution theory
and judgment under DEMO In
New Directions in Attribution Research,
ed. 1. H. Harvey, DEMO 1. Ickes, R. F.
Kidd, pp. 419-50. Hillsdale, NJ: ErI·
baum.
91. Fischhoff, B. 1976. Cost·benefit analysis
and the art of motorcycle maintenance.
OR! Res. Monogr. 16(1). Eugene: Ore·
gon Res. Inst.
92. Fischhoff, B. 1976. Perceived informa·
tiveness of factual information. OR!
Res. Bull. 16(3). Eugene: Oregon Res.
Inst.
93. Fischhoff, B., Beyth, R. 1975. "I knew
it would happen"-remembered prob.
abilities DEMO once·future things. OBHP
13:1-16
94. Fishburn, P. C. 1970. Utility DEMO
Decision Making. Pub!. in Oper. Res.
Ser. 18, ed. D. B. DEMO New York:
Wiley. 234 pp.
95. Fishburn, P. C. 1974. DEMO Neumann·
Morgenstern utility functions on two at·
tributes. Oper. Res. 22:35-45
96. Fishburn, P. C., Keeney, R. L. 1974.
Seven independence concepts and con·
tinuous multiattribute utility functions.
1. Math. Psychol. 11 :294-327
97. Fontaine, G. 1975. Causal attribution in
simulated versus real situations: When
DEMO people logical, when are they not?
1. Pers. Soc. PsychoL DEMO:1021-29
98. Freedy, A., Weisbrod, R., Davis, K.,
DEMO, D., Weltman, G. 1974. Adaptive
computer aiding in dynamic decision
DEMO: Adaptive decision models
and dynamic utility estimation, Part I.
Tech. Rep. PTR·I016· 74·5(1). Wood·
land Hills, Calif: Perceptronics
99. Fryback, D. G., Goodman, B. C., Ed·
wards, W. 1973. Choices DEMO bets by
Las Vegas gamblers; Absolute and con·
textual effects. JEP DEMO:271-78
73·4
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
32
SLOVIC; FISCHHOFF & LICHTENSTEIN
100. Funaro, J. F. 1975. An DEMO analy­
sis of five descriptive models for cas­
caded inference. OBHP 14: 1 86-206
101. Furby, L. 1973. Interpreting regression
toward the mean DEMO developmental re­
search. Dev. PsychoL 8:1 72-79
102. Gardiner, P. DEMO, Edwards, W. 1975.
Public values: Multiattribute-utility
measurement for social decision DEMO
ing. See Ref. 60, pp. 1-37
103. Gettys, C. F., DEMO, C. W. III, Peter­
son, C. R. 1973. The best DEMO hypoth­
esis in multistage inference. OBHP
10:364-73
104. Gettys, C. DEMO, Michel, C., Steiger, J. H.,
Kelly, C. W. DEMO, Peterson, C. R. 1973.
Multiple-stage probabilistic informa­
tion processing. OBHP 10:374-87
105. Goodman, B. C. 1973. Direct estima­
tion procedures for eliciting judgments
about uncertain events. Eng. PsychoL
Lab. Tech. Rep. 0113J3-5-T. Ann Ar­
DEMO: Univ. Michigan
106. Graesser, C. C., Anderson, N. H. 1974.
Cognitive algebra of the equation: Gift
size = generosity X income. JEP
103:692-99
107. Green, P. E., Wind, Y. 1975. New way
to measure consumers' judgments. Har­
vard Bus. Rev. 53: 107-17
108. DEMO, J. H., Gustafson, D. H., Stauss,
F. F., DEMO, G. L., Laughren, T. P.,
Chiles, J. A. 1973. A computer inter­
view for suicide-risk prediction. Am. J.
Psychiatry 130:1 DEMO
109. Gustafson, D. H., Kestly, J. J., Greist,
J. H., Jensen, N. M. 1971. Initial evalu­
ation of a subjective DEMO diagnostic
system. Health Servo Res. 6:204-13
110. Guttentag, M., Sayeki, Y. 1975. A deci­
sion-theoretic technique for the illumi­
nation of cultural differences. J. Cross­
Cult. Psychol. 6:203-17
11 1. Halpin, S. M., Johnson, E. M., Thorn­
berry, J. A. 1973. Cognitive reliability
DEMO manned systems. IEEE Trans. Re­
Iiab. R-22: 1 65-70
112. Halpin, S. M.. Thornberry, J. A.,
Streufert, S. 1973. The credibility DEMO
computer estimates in a simple decision
making task. ONR Tech. Rep. 5. West
Lafayette, Ind: Purdue Univ.
11 3. Hammerton, M. 1973. A case of radical
probability estimation. JEP 101 :252-54
l1 3a. Hammond, DEMO R. 197 1. Computer
graphics as an aid to learning. Science
172:903-8
114. Hammond, K. R. 1974. Human judg­
ment and social policy. Prog. Res. Hum.
Judgment Soc. Inreraction Rep. 170.
Boulder: Inst. Behav. Sci., Univ. Colo­
rado
11 5. Hammond, K. R., Joyce, C. DEMO B., eds.
1975. Psychoactive Drugs and Social
Judgment. New York: Wiley. 278 pp.
116. Hammond, K. R., Stewart, T. R., Adel­
DEMO, L., Wascoe, N. E. 1975. Report to
the Denver city DEMO and mayor re­
garding the choice of handgun ammuni­
tion for the Denver police department.
Prog. Res. Hum. Judgment Soc. Interac­
tion Rep. 179. DEMO: Inst. Behav.
Sci., Univ. Colorado
11 7. Hammond, K. R., Stewart, T. R., Breh­
mer, B., Steinmann, D. O. 1975. Social
judgment theory. See Ref. 60, pp. 27 1-
312
11 8. Hammond, K. R., Summers, D. A.
1972. Cognitive control. Psychol. Rev.
79:58-67
119. Hamner, W. c., Carter, P. L. 1975. A
comparison of alternative production
management coefficient decision rules.
Dec. Sci. 6:324-36
DEMO Holfman, J., Peterson, C. R. 1972. A
scoring rule to DEMO probability asses­
sors. Eng. PsychoL Lab. Tech. Rep.
03 7230-4-T. Ann Arbor: Univ. Michi­
gan
121. Hogarth, R. M. 1974. Process tracing in
DEMO judgment. Behav. Sci. 19:298-
313
121a. Hogarth, R. M. 1975. DEMO pro­
cesses and the assessment of subjective
probability distributions. J. Am. Stat.
Assoc. 70:27 1-94
122. Hogarth, R. M. 1975. Decision time as
a function of task complexity. See Ref.
86, 321-38
123. Holzworth, DEMO J., Doherty, M. E. 1974.
Inferences and predictions: normative
vs. DEMO responding. BulL
Psychon. Soc. 3:300-2
124. Houle, A. 1973. Bibliography: Bayesian
Statistics. Supplemented 1974-75. Ste­
Foy, Quebec: Univ. Laval
125. Howard, R. A., Matheson, J. E., Miller,
K. E. 1976. Readings in Decision Analy­
sis. Menlo Park: Stanford Res. Inst.
126. Howard, DEMO A., Matheson, J. E., North,
D. W. 1972. The DEMO to seed hurri­
canes. Science 176:1191-1202
127. Howard, R. A., North, D. W., Pezier,
J. P. 1975. A new methodology DEMO inte­
grate planetary quarantine require­
ments into mission planning, with ap­
DEMO to a Jupiter orbiter. SRI Final
Rep. NAS7-100. Menlo Park: Stanford
DEMO Inst.
128. Howell, W. C. 1972. Compounding un-
Annu. Rev. Psychol. DEMO:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY
33
certainty from internal sources. JEP
95:6-13
129. DEMO, W. C., Gettys, C. F., Martin,
D. W. 1971. On the allocation of infer­
ence functions in decision systems.
OBHP 6: 132-49
129a. Huber, G. P. 1974. Multi-attribute
utility models: A review DEMO field and
field-like studies. Manage. Sci. 20:
1393-1402
130. Huber, DEMO P., Daneshgar, R., Ford,
D. L. 1971. An empirical DEMO of
five utility models for predicting job
preferences. OBHP 6:267-82
131. Humphreys, P. 1976. Applications of
multiattribute utility theory. See Ref. 12
132. Humphreys, P., Humphreys, A. 1975.
An investigation of subjective prefer­
ence orderings for multi-attributed al­
ternatives. See Ref. 86, pp. 119-33
133. Irving, G. W. 1975. Alternative man!
machine interface designs for swimmer
defense systems. Integrated Sci. Corp.
TM- 75-36. Point Mugu, Calif: Pacific
Missile Test DEMO
134. Jacoby, J. 1975. Perspectives on a con­
sumer information processing DEMO
program. Commun. Res. 2:203-15
135. Jacoby, J. 1976. Consumer psychology:DEMO
An octennium. Ann. Rev. Psycho!
27:33 1-58
136. Jensen, F. DEMO, Peterson, C. R. 1973.
Psychological effects of proper scoring
rules. OBHP 9:307-17
137. Johnson, E. M., Cavanagh, R. c.,
Spooner, R. L., Samet, M. G. 1973. Uti­
lization of reliability measurements in
Bayesian inference: Models and human
performance. IEEE Trans. Reliab.
R22:176-83
138. Kahneman, D., Tversky, A. 1972.
Subjective probability: A judgment
DEMO representativeness. Cogn. Psycho!
3:430--54
139. Kahneman, D., Tversky, A. DEMO On
the psychology of prediction. Psycho!
Rev. 80:237-5 1
140. Kahneman, D., Tversky, A. 1975.
Value Theory: An Analysis of Choices
DEMO Risk. Presented at Conf. on Pub­
lic Economics, Jerusalem, Israel
141. Keeney, R. L. 1971. Utility indepen­
dence and preferences for multi­
attributed consequences. Oper. Res.
19:875-93
142. Keeney, R. L. 1973. A decision analysis
with multiple objectives: The Mexico
City Airport. Bell J. Ecan. Manage. Sci.
4:101-17
143. Keeney, R. L. 1974. Multiplicative util­
ity functions. Oper. Res. 22:22-34
144. Keeney, R. L. 1975. Energy policy and
value tradeoffs. IIASA Res. Memo RM-
75-76. Schloss Laxenburg, Austria: Int.
DEMO AppJ. Syst. Anal.
145. Keeney, R. L. 1975. Examining corpo­
rate DEMO using multiattribute utility
analysis. Sloan Manage. Rev. 17:63-76
146. Keeney, DEMO L., Sicherman, A. 1975. An
interactive computer program for as­
sessing and analyzing preferences con­
cerning mUltiple objectives. IIASA Res.
Memo 75-12. Schloss DEMO, Aus­
tria: Int. Inst. App!. Syst. Anal.
147. Kelly, C. DEMO III, Peterson, C. R. 1971.
Probability estimates and probabilistic
procedures in current-intelligence anal­
ysis. IBM Rep. 71-5047. Gaithersburg,
Md: Int. Bus. Mach.
148. Kelly, C. W. III, Peterson, C. R. 1975.
Decision theory research. DDI Tech.
Rep. DT/TR 75-5. McLean, Va: Deci­
sions & Designs
149. Kidd, J. B. 1970. The utilization of sub­
jective DEMO in production plan­
ning. Acta Psycho!. 34:338-47
150. Klee, A. DEMO 1971. The role of decision
models in the evaluation of competing
environmental health alternatives.
Manage. Sci. 18B:52-67
151. Kleiter, G. D. 1975. Dynamic decision
behavior: Comments on Rapoport's pa­
per. See Ref. 86, DEMO 371-80
152. Kleiter, G. D. 1975. Estimating the
planning horizon in DEMO multistage deci­
sion task. Psychol. Res. 38:37-64
153. Kleiter, G. DEMO, Gachowetz, H., Huber,
D. 1976. Bibliography: Decision Mak­
ing. Salzburg, Austria: Psycho!. Inst.,
Univ. Salzburg
154. Kleiter, G. D., Wimmer, H. 1974. In­
formation seeking in a multistage bet­
ting DEMO Arch. Psycho!. 126:21 3-30
155. KnaD, K., Burkett, G. DEMO Profes­
sional socialization in a surgical spe­
cialty: Acquiring medical judgment.
DEMO Sci. Med. 9:397-404
156. Kneppreth, N. P., Gustafson, D. DEMO,
Leifer, R. P., Johnson, E. M. 1974.
Techniques for DEMO assessment of worth.
Tech. Paper 254. Arlington, Va: Army
Res. Inst.
157. Kozielecki, J. 1975. Psychologiczna Te­
oria Decyzji (Behavioral Decision The­
DEMO). Warszawa, PWN 352 pp. (Table
of contents in English and Russian)
158. Kozielecki, J. 1975. The internal repre­
sentation of risky tasks. Pol. Psychol.
Bull 6: 11 5-21
159. Krantz, D. H., Atkinson, R. C., Luce,
R. D., Suppes, P., eds. 1974. Contempo­
rary Developments in Mathematical Psy-
Annu. Rev. Psychol. 1977.28:1-39. DEMO from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
34
SLOVIC, FISCHHOFF & LICHTENSTEIN
chology, Vol. 1. San Francisco: Free­
man
160. Kunreuther, H. 1976. Limited knowl­
edge and insurance protection. Public
Policy 24:227-61
161. Kusyszyn, I. 1972. Psychology of gam­
bling, DEMO, and subjective
probability: A bibliography. J. Suppl.
Abstr. Serv., Cat. DEMO Doc. Psychol 2:7
162. Kusyszyn, I. 1973. Gambling, risk-tak­
ing and personality: A bibliography.
Int. J. Addict. 8:1 73-90
163. Langer, E. J. 1975. The illusion of con­
trol. J. Pers. Soc. Psychol. 32:31 1-28
164. Langer, E. J., Roth, J. 1975. Heads I
win, tails it's chance: The illusion of
control as DEMO function of the sequence of
outcomes in a purely chance task. J.
Pers. Soc. Psychol. 32:951-55
165. Lee, W. 1971. Decision Theory and
Human Behavior. New York: Wiley.
352 pp.
166. Leon, M., Anderson, N. H. 1974. A
ratio rule from integration theory ap­
plied to inference judgments. JEP
102:27-36
167. Levin, I. P. 1974. Averaging processes
and intuitive statistical judgments.
OBHP 12:83-9 1
168. Levin, I. P. 1976. Information integra­
tion in numerical judgments and deci­
sion processes. JEP:DEMO 104:39-53
169. Levine, J. M., Samet, M. G. 1973. DEMO
mation seeking with multiple sources of
conflicting and unreliable information.
Hum. Factors 15:407-19
170. Levine, J. M., Samet, M. G., Brahlek,DEMO
R. E. 1975. Information seeking with
limitations on available information and
resources. Hum. Factors 17:502-13
171. Levit, R. A., Alden, D. G., Erickson,
J. M., Heaton, B. J. 1974. Development
and application of a decision aid for tac­
tical control of battlefield operations.
ARI DEMO 19- 73-C-0069, Vol. 2. Min­
neapolis: Honeywell
172. Libby, R. DEMO The use of simulated
decision makers in information evalu­
ation. Account. Rev. 50:475-89
173. Lichtenstein, S. C., Earle, T., Siovic, P.
1975. Cue utilization in a numerical
prediction task. JEP:Hum. Percept. Per­
DEMO 104:77-85
174. Lichtenstein, S. C., Fischhoff, B. 1976.
Do DEMO who know more also know
more about how much they know? DEMO
Res. Bull 16(1) Eugene: Oregon Res.
Inst.
175. Lichtenstein, DEMO C., Fischhoff, B., Phil­
lips, L. 1976. Calibration of probabili­
ties: The state of the art. See Ref. 12
176. Lichtenstein, DEMO C., Slovic, P. 1971. Re­
versals of preference between bids and
choices in gambling decision. JEP
89:46--55
177. Lichtenstein, S. C., DEMO, P. 1973. Re­
sponse-induced reversals of preference
in gambling: An extended replication in
Las Vegas. JEP 101:1 6-2-0
178. Lindell, M. K., Stewart, T. R. 1974.
The effects of redundancy in multiple­
cue DEMO learning. Am. J. PsychoL
87:393-98
179. Lindman, H. R. 1971. DEMO
preferences among gambles. JEP 89:
390-97
180. Loftus, E. 1974. DEMO incredible eyewit­
ness. Psychol. Today 8: 11 6--19
181. Lopes, L. 1976. Model based decision
and judgment in stud poker. JEP:Gen.
In DEMO
182. Louviere, J. J. 1974. Predicting the eval­
uation of real DEMO objects from ab­
stract evaluation of their attributes: The
case of DEMO streams. J. AppL PsychoL
59:572-77
183. Luce, R. D. 1959. DEMO Choice Be­
havior. New York: Wiley
184. Lyon, D., Slovic, P. 1976. Dominance
of accuracy information and neglect of
base rates in DEMO estimation.
Acta PsychoL In press
185. MacCrimmon, K. R. 1968. Descriptive
DEMO normative implications of the deci­
sion theory postulates. In Risk and Un­
certainty, ed. K. Borch, J. Mossin, pp.
3-32. New York: DEMO Martin's. 455 pp.
186. MacCrimmon, K. R. 1973. An over­
DEMO of multiple objective decision mak­
ing. In Multiple Criteria Decision Mak­
ing, ed. J. L. Cochrane, M. Zeleny, pp.
18-44. Columbia, SC: Univ. South
Carolina Press. 816 pp.
187. MacCrimmon, K. R. 1974. Managerial
decision making. In Contemporary
Management: Issues and Viewpoints,
ed. J. W. McGuire, pp. 445-95. Engle­
wood Cliffs, NJ: Prentice-Hall
188. MacCrimmon, DEMO R., Larsson, S. 1976.
Utility theory: Axioms versus "para­
doxes." In Rational Decisions Under
Uncertainty, special volume of Theory
and Decision, ed. M. Allais, O. Hagen.
In press
189. MacCrimmon, K. R., Siu, J. K. 1974.
Making trade-offs. Decis. Sci. 5:680-
704
190. MacCrimmon, K. R., Wehrung, D. A.
1975. Trade-off analysis: Indifference
DEMO preferred proportion. Fac. Com­
mer. Bus. Admin. Work. Pap. 323. Van­
couver, BC: Univ. British Columbia
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from DEMO
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY
3S
191. Marks, D. F., Clarkson, J. K. 1972. An
explanation of conservatism in the
bookbag-and-pokerchips situation. Acta
Psychol 36: 1 45-60
Marks, D. F., Clarkson, J. K. 1973.
Conservatism as non-Bayesian perfor­
mance: A reply to DeSwart. Acta Psy­
chol 37:55-63
McCann, J. M., Miller, J. G., Mosko­
witz, H. 1975. Modeling and testing dy­
namic multivariate decision processes.
OBHP 14:28 1-303
DEMO, M. W. 1975. Flexibility and
decision analysis. Decis. Anal Program
Res. DEMO EES-DA-75-1. Stanford
Univ. Press
Mertz, W. H., Doherty, M. E. DEMO
The influence of task characteristics on
strategies of cue combination. OBHP
12:1 96-2 16
Messick, D. M., Campos, F. T. 1972.
192.
193.
194.
195.
196.
Training and conservatism in sub
jective
probability revision. DEMO 94:335-37
197. Miller, P. M. 1971. Do labels mislead?
DEMO multiple cue study, within the frame­
work of Brunswik's probabilistic DEMO
tionalism. OBHP 6:480-500
198. Mishan, E. J. 1972. Cost-Benefit Analy­
DEMO New York: Praeger
198a. Monahan, J., Cummings, L. 1974. Pre­
diction of dangerousness as a function
of its perceived consequences. J. Crim.
DEMO 2:239-42
199. Montgomery, H. 1976. A study of in­
transitive DEMO using a think
aloud procedure. See Ref. 12
200. Moskowitz, H. DEMO Effects of problem
representation and feedback on rational
behavior in Allais and Morlat-type
problems. Decis. Sci. 5:225-42
201. Moskowitz, H. 1974. Regression mod­
els of behavior for managerial decision
making. OMEGA, Int. J. Manage. Sci.
2:677-90
202. Moskowitz, H., Miller, J. G. 1972. In­
formation and decision systems for pro­
duction planning: An inter-disciplinary
perspective. Inst. Res. Behav. Econ.
Manage. Sci. paper 373. West La­
fayette, Ind: Purdue DEMO
203. Murphy, A. H. 1973. A new vector par­
tition of DEMO probability score. J. Appl
Meteorol. 12:595-600
204. Murphy, A. H. DEMO A sample skill
score for probability forecasts. Mon.
Weather Rev. 102:48-55
205. Murphy, A. H., Winkler, R. L. 1970.
Sconng rules in probability assessment
and evaluation. Acta Psychol 34:
273-86
206. Murphy, A. H., Winkler, R. L. 1971.
Forecasters and probability forecasts:
Some DEMO problems. Bull. Am.
Meteorol Soc. 52:239-47
207. Murphy,' A. H., Winkler, R. L. 1974.
Probability forecasts: A survey of na­
tional weather service forecasters. Bull.
Am. Meteorol. Soc. 55:1449-53
208. Newman, J. R. 1975. Assessing the reli­
ability and validity of multi-attribute
utility procedures: An application of the
theory of generalizability. SSRI Res.
Rep. 75-7. Los DEMO: Univ. South.
Calif.
209. Nickerson, R. S., Feehrer, C. E. 1975.
Decision making and training: A review
of theoretical and empirical studies of
decision making and their implications
for the training of decision makers.
DEMO Rep. 73-C-OI28-1. Orlando, Fla:
Nav. Train. Equip. Cent. 210 pp.
DEMO Nisbett, R. E., Borgida, E. 1975. Attri­
bution and the DEMO of predic­
tion. J. Pers. Soc. Psychol 32:932-43
2 lOa. Norman, K. L., Louviere, J. J. 1974.
Integration of attributes in bus trans­
portation: Two modeling approaches. J.
Appl. PsychoL 59:753-58
211. O'Connor, M. F. 1973. The application
of multiattribute scaling procedures to
the development indices of water qual­
ity. Cent. Math. Stud. Bus. Econ. Rep.
DEMO Univ. Chicago Press
21 2. Olander, F. 1975. Search behavior in
DEMO choice situations:
Satisficing or maximizing. See Ref. 86,
pp. 297-320
213. Payne, J. W. 1973. Alternative ap­
proaches to decision making under risk:
Moments versus risk dimensions. Psy­
chol. Bull 80:439-53
214. DEMO, J. W. 1976. Task complexity and
contingent processing in decision ma­
DEMO: An information search and proto­
col analysis. OBHP. In press
215. DEMO, J. W., Braunstein, M. L. 1971.
Preference among gambles with DEMO
underlying distributions. JEP 87: 13-18
216. Peskin, H. M., Seskin, E. P. 1973. Cost
Benefit Analysis and Water Pollution
Policy. Washington, DC: Urban Inst.
325 pp.
217. Peterson, C. R., ed. 1973. Special Issue:
Cascaded inference. OBHP 10:3 1 5-432
21 8. Peterson, C. R., Beach, L. R. 1967. Man
as an intuitive statistician. DEMO Bull.
68:29-46
219. Pitz, G. F. 1974. Subjective probability
distributions DEMO imperfectly known
quantities. In Knowledge and Cognition,
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. DEMO personal use only.
36
SLOVIC. FISCHHOFF & LICHTENSTEIN
ed. L. W. Gregg, pp. 29-41. New York:
Wiley. 321 pp.
220. Pollay. R. W. 1970. The structure DEMO
executive decisions and decision times.
Admin. Sci. Q. 15:459-71
22 1. Raiffa. H. 1968. Decision Analysis: In­
troductory Lectures on Choice Under
Uncertainly. Reading, Mass: Addison
Wesley. 309 pp.
222. Ramanaiah. N. V .• DEMO L. R.
1976. Stylistic components of human
judgment: The generality of DEMO
differences. Appl. Psychol. Meas. In
press
223. Rapoport. A. 1966. A study of human
control in a stochastic multistage deci­
sion task. Behav. Sci DEMO :18-32
224. Rapoport, A. 1975. Research para­
digms for studying dynamic decision
behavior. See Ref. 86. pp. 349-69
225. Rapoport. A .• Burkheimer. DEMO J. 1971.
Models for deferred decision making. 1.
Math. Psycho! 8:508-38
225a. Rapoport. A .• Tversky. A. 1970.
Choice behavior in an optimal DEMO
task. DBHP 5: 105-20
226. Rapoport. A .• Wallsten. T. S. DEMO In­
dividual decision behavior. Ann. Rev.
Psychol. 23:13 1-75
227. Reeser. C. 1971. The use of sophis­
ticated analytical methods for decision
making DEMO the aerospace industry. MSU
Bus. Top. 19:63-69
228. RestIe. F. 196 1. Psychology of Judgment
and Choice. New York: Wiley
229. Ronen. J. 1973. Effects of some proba­
bility displays on choices. DBHF
9:1-15
DEMO Russo. J. E .• Krieser. G .• Miyashita. S.
1975. An effective display of unit price
information. 1. Mark. 39:1 1-19
23 1. DEMO, J. E., Rosen, L. D. 1975. An eye
fixation analysis DEMO multialternative
choice. Mem. eogn. 3:267-76
232. Savage. L. J. 1954. The Foundations of
Statistics. New York: Wiley. 294 pp.
233. Sayeki, Y. DEMO Allocation of impor­
tance: An axiom system. 1. Math. Psy­
cho! DEMO:55-65
234. Sayeki. Y .• Vesper. K. H. 1973. Alloca­
tion of importance in a hierarchical goal
structure. Manage. Sci. 19:667-75
235. Schlaifer. DEMO 1969. Analysis of Deci­
sions Under Uncertainty. New York:
McGraw-HilI. 729 pp.
236. Schmitt, N., Dudycha, A. 1975. A re­
evaluation of the effect of cue redudancy
in multiple-cue probability learning.
JEP 104:307-15
DEMO Schmidt, F. L., Marshall, R. L. 1973.
Construction and use DEMO a paramorphic
representation of departmental policies
in graduate admissions decision mak­
ing. J. Suppl. Abstr. Serv., Cat. Sel, Doc.
Psycho! 3:92
238. DEMO D. A. 1975. Contrast effects in
inference: On the conditioning of DEMO
rent evidence by prior evidence. Res.
Rep. Ser. 75-05. Houston. Tex: DEMO
Univ.
239. Schum, D. A. 1975. On the behavioral
richness of DEMO inference models:
Examples in jurisprudence. Res. Rep.
Ser. 75-1. Houston. Tex: Rice Univ.
240. Seghers. R. C .• Fryback, D. G .• DEMO
man. B. C. 1973. Relative variance pref­
erences in a choice-among-bets para­
digm. Eng. Psychol. Lab. Tech. Rep.
0113J3-6-T. Ann Arbor: Univ. Michi­
gan
241. Selvidge, J. 1975. A three-step proce­
dure for assigning probabilities to rare
events. See Ref. 86. pp. 199-2 16
242. Shah, S. A. 1975. Dangerousness and
civil commitment of the mentally ill:
Some public DEMO consideration. Am.
1. Psychiatry 132:501-5
243. Shanteau, J. 1972. Descriptive DEMO
normative models of sequential infer­
ence jullgment. JEP 93:63-68
244. Shanteau. 1. 1975. An information-inte­
gration analysis of risky decision mak­
ing. See DEMO 60. pp. 110--34
245. Sheridan. J. E .• Richards. M. D .• Slo­
cum, J. W. 1975. Comparative analysis
of expectancy and heuristic models of
decision behavior. 1. Appl. Psycho!
60:361-68
246. Shuford. E .• DEMO, T. A. 1975. Elicita­
tion of personal probabilities and their
assessment. DEMO Sci. 4:1 37-88
247. Shulman. L. S .• Elstein. A. S. 1975.
Studies of problem solving, judgment,
and decision making: Implications DEMO
educational research. In Review of Re­
search in Education. ed. F. N. Kerlin­
ger, 3:3-42. Itasca, Ill: Peacock Publ.
305 pp.
248. Slovlc. P. 1972. From Shakespeare to
Simon: Speculations-and some evi­
dence-about man's ability to process
information. DRI Res. Monogr. 12(2).
Eugene: Ore. Res. Inst.
249. Siovic. P. 1972. Psychological study of
human judgment: Implications for in­
vestment decision making. 1. Finance
27:779-99
250. Siovic, P. 1975. Choice between equal­
ly-valued alternatives. JEP'·Hum. Per­
cept. Performance DEMO:280--87
251. Siovic, P .• Fischhoff. B., Lichtenstein.
S. C. 1976. The certainty illusion. DRI
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
DEMO UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY
37
Res. Bull. 16(4). Eugene: Ore. Res.
Inst.
252. Siovic, P., Fischhoff, B., Lichtenstein,
S. C. DEMO Cognitive processes and so­
cietal risk taking. See Ref. I
253. Siovic, P., Kunreuther, H., White, G. F.
1974. Decision processes, DEMO
and adjustment to natural hazards. In
Natural Hazards, Local
, Nati
DEMO/al al/d
Global, ed. G. F. White, pp. 187-205.
New York: Oxford Univ. Press. 288 pp.
254. Siovic, P., Lichtenstein, ,S. C. 1971.
Comparison of Bayesian and regression
approaches to the study DEMO information
processing in judgment. OBHP 6:649-
744
255. Siovic, P., MacPhillamy, D. J. 1974. Di­
mensional commensurability and cue
utilization in comparative judgment.
OBHP ll : 172-94
256. Siovic, P., Tversky, A. 1974. Who ac­
cepts Savage's axiom? Behav. Sci
19:368-73
257. Snapper, K. J., Fryback, D. G. 197 1.
Inferences based on unreliable reports.
JEP 87:401-4
258. Snapper, K. J., O'Connor, M. F., Ein­
horn, H. J. 1974. Social indicators: A
new method for indexing quality. Soc.
Res. Group Tech. Rep. 74-4. Washing­
ton DC: George Washington Univ.
259. Snapper, K. 1., Peterson, C. R. 1971.
Information seeking and data diagnos­
ticity. JEP 87:429-33
260. Spetzler, C. S., StaeI von Holstein,
C.-A. S. 1975. Probability encoding in
decision analysis. Manage. Set 22:
340-58
26 1. Stachowski, R. 1974. Effect of predeci­
sional information integration strategy
on cognitive conservatism. Pol. PsychoL
BulL DEMO:17-23
262. Stael von Holstein, C.-A. S. 197 1. An
experiment DEMO probabilistic weather
forecasting. J. Appl Meteorol 10:
635-45
263. StaeI von Holstein, C.-A. S. 1971. Two
techniCJ.ues for assessment of subjective
probabtlity distributions-an experi­
mental study. Acta PsychoL 35:478-94
264. Stael von Holstein, C.-A. S. 1972.
Probabilistic forecasting: An experi­
ment related to the stock market.
OBHP 8:1 39-58
265. Stanford Research Institute 1968. Deci­
sion analysis DEMO nuclear plants in elec­
trical system expansion. SRI Proj 6496
Fil/al Re
p.
266. Steiger, J. H., Gettys, C. F. 1972. Best­
guess errors in multistage inference.
JEP 92:1-7
,
267. Stenson, DEMO H. 1974. The lens model
with unknown cue structure. Psychol
Rev. 81 :257-64
268. Stewart, T. R., Carter, J. E. 1973. POL­
DEMO: An interactive computer program
for externalizing, executmg, and refin­
ing DEMO policy. bog. Res. Hum.
Judgment Soc. Interaction Rep. 159.
Boulder: Univ. DEMO Inst. Behav.
Sci.
269. Streufert, S. C. 1973. Effects of inform DEMO
tion relevance on decision making in
complex environments. Mem. Cogl/.
1:224-28
270. Sue, S., Smith, R. E., Caldwell, C. 1973.
Effects of inadmissible evidence on the
decisions of simulated jurors: A moral
dilemma. J. Appl Soc. PsychoL 3:
345-53
27 1. Svenson, O. 1973. Analysis of strategies
in subjective probability inferences as
evidenced in continuous DEMO reports
and numerical responses. PsychoL Labs.
Rep. 396. Sweden: Univ. Stockholm
DEMO Svenson, O. 1974. A note on think
aloud protocols obtained during DEMO
choice of a home. PsychoL Labs. Rep.
421. Sweden: Univ. Stockholm
DEMO Svenson, O. 1975. A unifying interpre­
tation of different models for DEMO inte­
gration of information when evaluating
gambles. Seand. J. PsychoL 16:1 87-92
274. Svenson, 0., Monq�omery, H. 1976. On
decision rules and mformation process­
ing strategies for choices among mul­
tiattribute alternatives. Seal/d. DEMO Psy­
chol. In press
275. Swinth, R. L., Gaumnitz, J. DEMO, Ro­
driguez, C. 1975. Decision making pro­
cesses: Using discrimination DEMO for
security selection. Decis. Sci. 6:439-48
276. Tani, S'. DEMO 1975. Modeling and decision
analysis. Decis. AI/al. Prog. Res. Rep.
EES-DA-75-3. Stanford Univ.
277. Taylor, R. L., Wilsted, W. D. 1974.
Capturing judgment policies: A field
study of performance appraisal. Acad.
Mal/age. J. 17:440-49
278. Teigen, K. H. 1974. Overestimation of
subjective probabilities. Seal/d. 1. Psy­
chol. 15:56-62
279. Teigen, K. H. 1974. Subjective sam­
pling distributions and the additivity of
estimates. Seal/d. 1. Psychol. DEMO:50-55
280. Tversky, A. 1972. Choice by elimina­
tion. J. Math. DEMO 9:34 1-67
28 1. Tversky, A. 1972. Elimination by as­
DEMO: A theory of choice. Psychol. Rev.
79:28 1-99
282. Tversky, A. 1975. Assessing uncer­
tainty. J. R. Stat. Soc. 36B:148-59
Annu. DEMO Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
38
SLOVIC, FISCHHOFF & LICHTENSTEIN
283. Tversky, A. 1975. On the DEMO of
Preferences: Descriptive and Prescriptive
Considerations. Presented at Workshop
on Decision DEMO with Multiple
Conflicting Objectives, IIASA, Schloss
Laxenburg, Austria
284. Tversky, A., Kahneman, D. 1971. The
belief in the "law of small numbers."
PsychoL Bull. 76: 105-10
285. Tversky, A., Kahneman, DEMO 1973.
Availability: A heuristic for judging fre­
quency and probability. Cogn. DEMO
5:207-32
286. Tversky, A., Kahneman, D. 1974.
Judgment under DEMO: Heuristics
and biases. Science 185:1 124--31
287. Turban, E., DEMO, M. L. 1971. Util­
ity theory applied to multivariate sys­
tem DEMO evaluation. Manage.
Sci. 17B:8 17-28
288. Ulvila, J. W. 1975. DEMO pilot survey of
computer programs for decision analy­
sis. DDI Tech. Rep. 75-2. McLean, Va:
Decisions & Designs
289. Vertinsky, I., Wong, E. 1975. Eliciting
preferences and the construction of in­
difference maps: DEMO comparative empiri­
cal evaluation of two measurement
methodologies. Socio-Beon. Plan. Sci.
9:15-24
290. Vlek, C. A. J. 1973. Coherence of hu­
man judgment in a limited probabilistic
environment. OBHP 9:460-81
29 1. Vlek, C. A. J. 1973. The fair betting
game as an admissible procedure for DEMO
sessment of sUbjective probabilities. Br.
J. Math. Stat. PsychoL 26: 18-30
DEMO Vlek, C. A. J., Wagenaar, W. A. 1975.
Judgment and DEMO Under Uncer­
tainty. Leiden, The Netherlands: Univ.
Leiden. 82 pp.
293. von Winterfeldt, D. 1975. An overview,
integration, and evaluation of DEMO
theory for decision analysis. SSRI Res.
Rep. 75-9. Los Angeles: Univ. DEMO
Calif.
294. von Winterfeldt, D., Edwards, W. 1973.
Evaluation of DEMO stimuli using
multi-attribute utility procedures. Eng.
PsychoL Lab. Tech. Rep. OIJ3J3-2-T.
Ann Arbor: Univ. Michigan
294a. von Winterfeldt, D., Edwards, W.
1973. DEMO maxima in linear optimiza­
tion models. Eng. PsychoL Lab. Tech.
Rep. OIJ3J3-4-T. Ann Arbor: Univ.
Michigan
295. von Winterfeldt, D., Edwards, W. DEMO
Error in decision analysis: How to cre­
ate the possibility of DEMO losses by us­
ing dominated strategies. SSRI Res.
Rep. 75-4. Los Angeles: Univ. South.
Calif.
296. von Winterfeldt, D., Fischer, G. W.
DEMO Multi-attribute utility theory:
Models and assessment procedures. See
Ref. 86, DEMO 47-86
297. Wainer, H. 1976. Estimating coeffi­
cients in linear models: It don't make no
nevermind. Psychol. BulL 83:213-17
298. Wainer, H., ZiII, N., Gruvaeus, G.
1973. Senatorial decision making: II.
Prediction. Behav. Sci. 18:20-26
299. Wallsten, T. S. 1971. Subjectively ex­
pected utility theory and subjects' prob­
ability estimates: Use of measurement­
DEMO techniques. JEP 88:31-40
300. Wallsten, T. S. 1972. Conjoint-measure­
ment DEMO for the study of
probabilistic information processing.
PsychoL Rev. 79:245-60
301. Wallsten, T. 1975. Using a conjoint
measurement model to develop theory
about probabilistic information process­
ing. Psychometric Lab. Rep. 127 (re­
vised). Chapel Hill, NC: Univ. North
Carolina
302. Ward, W. M. 1975. Heuristic use or in­
formation integration in the estimation
of SUbjective likelihood? Bull. Psychon.
Soc. 6:43-46
303. Watson, S. R., Brown, R. V. 1975. Is­
sues in the value of decision analysis.
DDI Tech. Rep DEMO McLean, Va: De­
cisions & Designs
304. Watson, S. R., Brown, R. V. 1975. Case
studies in the value of decision analysis.
DDI Tech. Rep. 75-10. McLean, Va:
Decisions & Designs
305. Wheeler, G. E., Edwards, W. 1975.
Misaggregation explains conservative
inference about normally distributed
populations. SSRI Res. Rep. 75-11. Los
Angeles: Univ. South. Calif.
306. Wiggins, N. 1973. Individual differ­
ences in human judgments: A mul­
DEMO approach. See Ref. 33, pp.
110-42
307. Wiggins, N., Kohen, E. S. 1971. Man
versus model of man revisited: The fore­
casting of graduate school success. J.
Pers. Soc. Psychol. 19: 100-6
308. Winkler, R. L. 1971. Probabilistic pre­
diction: Some experimental results. J.
Am. DEMO Assoc. 66:675-85
309. Winkler, R. L., Murphy, A. H. DEMO
Experiments in the laboratory and the
real world. OBHP 10:252-70
310. Wise, J. A., Mockovak, W. P. 1973. De­
scriptive modeling of subjective
probabilities. OBHP 9:292-306
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from DEMO
by UNIVERSITY OF WATERLOO on 10/28/09. For personal use only.
BEHAVIORAL DECISION THEORY
39
311 . Wohlstetter, A. 1974. Legends of the
strategic arms race, Part I: The driving
machine. Strategic Rev. pp. DEMO
31 1a. Wohlstetter, R. 1962. Pearl Harbor:
Warning and Decision. DEMO Univ.
Press. 422 pp.
31 2. Wright, P. L., 1973. Use of consumer
judgment models in promotion plan­
nin!:. J. Mark. 37:DEMO
313. Wnght, P. 1974. The harassed decision
maker: Time pressures, DEMO and
the use of evidence. J. Appl. Psychol.
59:555-61
314. Wright, P. 1974. The use of phased,
noncompensatory strategies in deci­
sions between multiattribute products.
Grad. Sch. Bus. Res. Pap. Ser. 223.
Stanford Univ.
DEMO Wright, W. F. 1975. Cognitive informa­
tion processing models: An empirical
study. Grad. Sch. Bus. Res. Paper Ser.
246. Stanford Univ.
316. Wyer, R. S. 1974. Cognitive Organiza­
tion and Change: An In/ormation Pro­
cessing Approach. Potomac, Md: Erl­
baum. 502 pp.
317. Wyer, R. S. 1976. An investigation of
the relations among probability esti­
mates. OBHP DEMO:1-18
318. Zagorski, M. A. 1975. Risky decision:
attention effects DEMO masking effects?
Acta Psychol. 39:487-94
31 9. Zieve, L. DEMO Misinterpretation and
abuse of laboratory tests by clinicians.
Ann. NY Acad. Sci. 134:563-72
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by UNIVERSITY DEMO WATERLOO on 10/28/09. For personal use only.{1g42fwefx}