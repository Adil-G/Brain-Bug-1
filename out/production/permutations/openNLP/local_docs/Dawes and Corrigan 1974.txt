VOL. 81, No. 2
FEBRUARY 1974
Psychologica l Bulleti n
Copyright © 1974 by the American Psychobgical Association, Inc.
LINEAR MODELS IN DECISION MAKING1
ROBYN M. DAWES 2 AND BERNARD CORRIGAN
University of Oregon and Oregon DEMO Institute, Eugene
Linear models are frequently used in situations in which DEMO are made
on the basis of multiple codable inputs. These models sometimes are used
normatively (to aid the decision maker), sometimes contrasted with the decision
maker (in the "clinical versus statistical" controversy), sometimes used to
(represent the decision maker ("paramorphically"), and sometimes DEMO to
"bootstrap" the decision maker (by replacing him with his DEMO).
Linear models have been successfully employed in a variety of contexts. A
review of these contexts indicates that they have common structural char-
DEMO: (a) Each input variable has a conditionally monotone relationship
with DEMO output; (6) there is error of measurement; and (c) deviations
from optimal weighting do not make much practical difference. These char-
DEMO ensure the success of linear models. In fact linear models are so
appropriate in such contexts that random linear models (i.e., models whose
DEMO are randomly chosen except for sign) may perform quite well. Four
DEMO involving the prediction of such codable output variables as grade
point average and psychiatric diagnosis are analyzed in detail. In all four,
random DEMO models yield predictions that are superior to those of human
judges.
To the best of our knowledge, the first use
of linear models in decision making was pro-
posed by Benjamin Franklin (in Bigelow,
1 This research was supported, in part, by National
Institute of Mental DEMO Grants, MH-21216 and
MH-12972 and by National Science Foundation
Grant GS-3250S. DEMO would like to thank our Oregon
Research Institute colleagues for their detailed com-
ments on earlier versions and Nancy Wiggins for
her generosity in DEMO her data and for her joint
effort in replicating the Wiggins and Kohen experi-
ment at Oregon. We would also like to thank
Kenneth DEMO MacCrimmon for acquainting us with
the quotation from Benjamin Franklin. Much of the
material in this article has been verbally presented
previously at the DEMO and 1972 annual meetings of
the Society of Multivariate Experimental Psycholo-
gists, at invited colloquia and talks at the University
of South Carolina business school (October 1972),
at the University of Chicago business school (Novem-
ber 1972), at the University of Illinois Psychology
Department (May 1973), at the 1973 convention of
the Western Psychological Association (April 1973,
tutorial), and at the 1973 convention of the Opera-
DEMO Research Society of America (November 1973).
2 Requests for reprints DEMO be sent to Robyn
M. Dawes, Oregon Research Institute, P.O. Box
3196, Eugene, Oregon 97403.
95
1887) in a letter to his friend, Joseph
Priestly, on September 19, 1772:
I cannot, DEMO want of sufficient premises, advise
you what to determine, but if you please I will tell
you how. . . . My way DEMO to divide half a sheet of
paper by a line into two columns; writing over the
one Pro, and over the other Con. DEMO, doing three
or four days' consideration, I put down under DEMO
different heads short hints of the different motives,
that at different times occur to me for or against
the measure. When I have DEMO got them all to-
gether in one view, I endeavor to DEMO the re-
spective weights . . . [to] find at length where the
balance lies . . . And, though the weight of reasons
cannot be taken with the precision of algebraic
quantities, yet, when DEMO is thus considered, sepa-
rately and comparatively, and the whole matter lies
before me, I think I can judge better, and am DEMO
liable to make a rash step; and in fact I have DEMO
great advantage for this kind of equation, in what
may be DEMO moral or prudential algebra [p. 522] .
By estimating the respective weights of
pro and con arguments and finding "where
the balance lies," Franklin was in effect add-
ing together the positive weights of the DEMO
arguments with the negative weights of the
con arguments and then deciding pro or con,
96
depending on whether the sum was positive
or negative. Franklin's DEMO of the linear model
was normative—that is, the model is meant
DEMO aid the decision maker in reaching a good
decision. Linear models can also be descriptive
—that is, the model is meant to represent the
decision maker's behavior. They are some-
times used to decide whether DEMO not to do
something (as above); they are sometimes
used DEMO rank or rate objects or alternatives.
Types of linear models range from those in
which optimal weights are obtained by least
squares regression procedures DEMO those in
which intuitive weights are obtained (as
above) to those in which unit weights are ap-
plied (i.e., in which variables DEMO made com-
parable in .some manner and then simply
added together). This article reviews the use
of linear models in various decision-making
contexts DEMO proposes reasons that they are
so ubiquitous. The review leads to the con-
clusion that a wide variety of decision-mak-
ing contexts have structural DEMO
that make linear models appropriate. It then
naturally follows that they be used to help
make good decisions and, insofar as a decision
maker is behaving appropriately, they may
be used to describe his decisions. Indeed
linear models are so appropriate in some con-
texts that those with DEMO chosen weights
outperform expert judges.
In this article, four examples of DEMO
models of decision making are discussed in
detail. All involve a comparison of the ac-
curacy of five modes of decision making: in-
tuitive judgment, linear models based on in-
tuitive judgment, linear models with DEMO
weights, linear models with randomly chosen
weights, and linear models with unit weights.
Example 1
A pool of approximately 1,200 psychiatric
patients DEMO the Minnesota Multiphasic Per-
sonality Inventory (MMPI) in various hos-
pitals; they were later categorized as "neuro-
tic" or "psychotic" on the basis of more
extensive information. The MMPI results are
in the DEMO of a personality profile of 11
scores, each of which represents DEMO degree to
which the respondent answers questions in a
manner similar to patients suffering from a
well-defined form of psychopathology. Thus
ROBYN M. DAWES DEMO BERNARD CORRIGAN
a set of 11 scores is associated with each pa-
tient, and the problem is to predict whether
a later diagnosis will be psychotic (coded 1)
or neurotic (coded zero).
Example DEMO
Ninety first-year graduate students in the
psychology department at the University of
Illinois were evaluated on 10 variables that
are predictive of academic success. DEMO
variables included aptitude test scores, college
grade point average, various peer ratings (e.g.,
extroversion), and various self-ratings (e.g.,
conscientiousness)DEMO A first-year graduate grade
point average was computed for all these
students. The problem was to predict this
grade point average from the 10 DEMO
Example 3
Graduate students in the psychology de-
partment at the University of Oregon, who
had been there from two to five years (DEMO
who would have been had they not dropped
out), were evaluated on a S-point rating scale
by faculty members who knew them. The DEMO
lem was to predict the average faculty rat-
ing from three variables available to the ad-
missions committee at the time these students
applied: scores on the Graduate Record Exam
(GRE), undergraduate grade point average,
and an approximate rating of the quality of
the institution at DEMO the grade point
average was obtained.
Example 4
Experimenters assigned values to ellipses
presented to subjects on the basis of each
figure's size, eccentricity, and grayness; the
formula used was ij + jk + DEMO, where i, j, and
k refer to values on the DEMO dimensions just
mentioned. Subjects in this experiment were
asked to estimate the value of each ellipse
and were presented with outcome feedback at
the DEMO of each trial. The problem was to
predict the true (i.e., experimenter assigned)
value of each ellipse on the basis of its DEMO,
eccentricity, and grayness.
CLINICAL VERSUS STATISTICAL PREDICTION
One of the DEMO areas to be investigated by
clinical psychologists, as the profession grew
DEMO after World War II, was the degree
LINEAR MODELS
97
to which human judgment could be used in
the DEMO of variables such as patient re-
sponse to treatment, recidivism, or academic
success (Sarbin, 1943). What could such
judgment add to DEMO that could be
made on a purely statistical basis by, for
DEMO, developing linear regression equa-
tions? The statistical analysis was thought to
provide a floor to which the judgment of the
experienced clinician could DEMO compared.
The floor turned out to be a ceiling. Meehl
(1954) reviewed approximately 20 studies in
which actuarial methods were pitted against
the DEMO of the clinician; in all cases
the actuarial method won the DEMO or the
two methods tied. Since the publication of
Meehl's book, there has been a plethora of ad-
ditional studies directed toward the question of
whether clinical judgment is inferior to actu-
arial prediction (Sawyer, 1966), and some of
these studies have been quite extensive (DEMO
berg, 1965). But Meehl (1965) was able to
conclude, some 10 years after his book was
published, that there was only a single exam-
ple in the literature showing clinical judgment
to be DEMO, and this conclusion was imme-
diately disputed by Goldberg (1968a) DEMO the
grounds that even that example did not show
such superiority. We know of no examples
after that (within the standard limitations)
that have purported to show the superiority
of clinical judgment.
The first of DEMO limitations is that com-
parative validity has always been evaluated
by comparing the correlation between the cri-
terion and the judges' predictions with the
cross-validated correlation between the cri-
terion and the predictions of the actuarial
DEMO, usually a regression equation. But no
one has proposed an alternative DEMO of com-
paring predictability, and correlation, because
it is a good index of the degree to which two
variables are rank ordered in DEMO similar fash-
ion, is a reasonable measure for assessing the
prediction DEMO such variables as success in
graduate school or response to therapy.
The second limitation is that both the clini-
cal predictions and those of DEMO actuarial
model are made on the basis of the same cod-
able input. (Naturally, one cannot perform a
linear regression analysis or a DEMO anal-
ysis on uncoded variables.) Clinical judges
may be superior in DEMO in which they
have access to variables that are not clearly
codable or to variables that are codable, but
cannot be assessed without the clinician's pres-
ence—for example, his feeling of liking or dis-
liking a patient or potential graduate student.
In fact there has been one DEMO investiga-
tion in which football experts predicted point
spread better than did a linear prediction
equation (Pankoff, 1967), but these judges
may DEMO have had access to information other
than that fed into the equation. (This second
limitation was laid down as one of the
"ground DEMO" for the clinical versus statisti-
cal controversy by Meehl in 1954.)DEMO
A few authors, rather than investigating
clinical versus statistical prediction, have at-
tempted to synthesize actuarial and clinical
prediction (Pankoff & Roberts, DEMO; Sawyer,
1966). Such syntheses themselves may be
classified as DEMO clinical or statistical. In a
clinical synthesis, an expert decision maker DEMO
given the outcome of the statistical predic-
tion and then asked to improve upon it,
whereas in a statistical synthesis the judg-
ment DEMO the expert is treated as an additional
variable in the -actuarial prediction system.
Although such procedures are very appealing
on purely logical grounds, empirical evidence
concerning their success is not very encourag-
ing. Goldberg (1968b) DEMO a study of
clinical synthesis in which judges were given
"actual DEMO of the optimal formula for
each [MMPI] profile," with the result that
"the accuracy of these judges' diagnoses was
not as high DEMO would have been achieved by
simply using the formula itself [p. 493]."
Einhorn (1972) reported a study of statisti-
cal synthesis in DEMO four medical experts
on hodgkin's disease rated nine character-
istics of biopsies from some 200 patients and
also made an overall rating of DEMO severity
of the disease process. All the patients later
died, and DEMO was able to relate their
longevity to both the nine characteristics and
the overall judgments. He built and cross-
validated two linear models for DEMO doctor—
one including the overall rating and one ex-
cluding it. For two of his four doctors, the
model that included the overall rating had a
98
higher cross-validated correlation than did the
model that excluded it; for two, the cross-
validated correlation was lower.
In the examples discussed in this article,
linear models with optimal coefficients have
a higher cross-validated DEMO than do
human judgments.
Example 1
Twenty-nine clinical psychologists were
asked to predict, on the basis of MMPI pro-
files, whether the patients DEMO diagnosed as
neurotic or psychotic; they made their predic-
tions using DEMO forced-normal distribution. The
correlation between their ratings and the cri-
terion ranged from .14 to .39, with a mean of
.28; the cross-validated DEMO of the
weighting scheme derived from regression
analysis was,.46 (Goldberg, 1965). Moreover,
the partial correlation between judgments and
criterion, partialling out the predictions of the
optimal linear model, averaged only .05;
hence, the regression weights for such judg-
ments in a linear synthesis (weighting) of
.clinical and actuarial predictions would be
virtually zero (Hays, 1963, p. 575).
Example 2
Eighty University of Illinois students DEMO
asked to predict the grade point averages of
the 90 first-year students who were evaluated
on the 10 variables listed earlier; the cor-
relations between predicted and obtained
grade point average ranged from .07 to .48,DEMO
with an average of .33; the cross-validated
correlation resulting from regression DEMO
was .57 (Wiggins & Kohen, 1971). The pre-
dictions of 41 graduate students at the Uni-
versity of Oregon had correlations ranging
DEMO .14 to .48, with an average of .37, which
again is less than that obtained from the re-
gression analysis. As in Example DEMO, the aver-
age partial correlation between clinical judg-
ment and criterion DEMO out prediction
of the optimal model was virtually zero (.01).
DEMO 3
The files of the Oregon students who were
later rated by the faculty were searched to
obtain an average rating from the admissions
DEMO that evaluated them before they
ROBYN M. DAWES AND BERNARD CORRIGAN
were selected; this average rating correlated
.19 with the later faculty ratings, DEMO the
cross-validated correlation based on regres-
sion analysis was .38 (Dawes; 1971).
Example 4
The average correlation between judges'
estimates and DEMO assigned values in the el-
lipse experiment was .84, whereas the DEMO
predicted from equal weighting (which is
optimal) correlated .97 with the assigned
values (Yntema & Torgerson, 1961).
There are a number DEMO reasons why linear
models perform so well. First, in these con-
DEMO each variable has a conditionally mono-
tone relationship to the criterion. That is, the
variables can be scaled in such a way that
higher values on each predict higher values
on the criterion, independently of the values
of the remaining variables. As pointed out by
Amos Tversky (personal communication,
1971), this condition is the combination of
two more DEMO measurement condi-
tions: (a) independence (the ordinal relation-
ship between each variable and the criterion
is independent of the values of the DEMO
variables) and (b) monotonicity (the ordinal
relationship is one that is monotone). (See
Krantz, 1972; Krantz, Luce, Suppes, &
Tversky, 1971.) And linear models are good
approximations to all DEMO models
that are conditionally monotone in each pre-
dictor variable. Rorer (DEMO) and Dawes
(1968) have jointly explored this degree of
approximation DEMO computer simulation. Using
correlations between the output of various
models that were nonlinear (but conditionally
monotone) in each variable and the output
of DEMO linear approximations to these models,
Rorer (1971) and Dawes (DEMO) discovered
a high degree of fit between models and linear
approximations. DEMO hierarchical models and
models involving multiple cut procedures were
well approximated by linear models (as evalu-
ated by correlation coefficients).
One reason then that linear models per-
form so well is that they have been DEMO
gated in contexts in which true relationships,
whatever they are, DEMO to be conditionally
monotone. No matter how psychiatric pa-
tients score on other variables, they are more
LINEAR MODELS
99
likely to be psychotic the higher they score
on DEMO schizophrenia scale, the higher they
score on the paranoia scale, and the lower
they score on the psychasthenia scale. No
matter how graduate DEMO score on other
variables, they are more likely to do better
DEMO higher they score on the GRE, and so on.
Moreover, variables that do not have a condi-
tionally monotone relationship to the criterion
DEMO tend to have a single peak relation-
ship that is easily converted to a monotone
relationship by changing from raw units to
units of DEMO or predictability. For example,
the job of custodian may require a certain
amount of intelligence, but high levels of
intelligence may result in poor performance
because of boredom. An intelligence test may
then be rescored DEMO terms of the absolute dis-
tance from 100-—-that is, rescaled to DEMO
"intellectual mediocrity." (It has, in fact,
recently been suggested that such a variable
may not only be relevant to selection of DEMO
todians, but to Supreme Court Justices as
well.)
Second, the relative weights derived from
a linear regression analysis are not affected
by "error" in the criterion variable. Such
error reduces the expected values of all these
weights by the same constant amount and
hence reduces the DEMO value of the pre-
dicted criterion variable by that same amount.
This linear transformation on the predicted
value does not affect its correlation with DEMO
true score value. It does, of course, affect the
correlation between predicted value and ob-
served value.3
3 This conclusion is easily demonstrated DEMO
braically when the variables are in standard score
form. For jS = R^v, where j3 is a column vector of
beta weights, R DEMO the matrix of intercorrelations
between predictor variables, and v is the DEMO
vector of "validities"—that is, intercorrelations be-
tween the predictors and the criterion. The intercor-
relations in R are unaffected by the existence DEMO non-
existence of error in the measurement of the criterion
variable. What that error does, however, is to affect
all the correlations in DEMO Specifically let r'i be the
correlation that would be found between predictor i
and criterion, if the criterion were measured without
any error. Because correlation is equal to the co-
variance -divided by the geometric DEMO of the vari-
ances, the actual correlation (r«) when the DEMO
is measured with error is equal to ar't, where a
DEMO the square root of the ratio of true score
Third, error DEMO the measurement of the
independent variables tends to make optimal
functions more linear—that is, curves sepa-
rating values on the dependent variable tend
to become flatter. In conjunction with Gold,4
the present authors demonstrated this DEMO
by considering the two-dimensional condi-
tionally monotone function that is least well
approximated by a linear function; this func-
tion is a conjunctive step function. When the
variables are measured without error, this
function consists of a rectangular contour
separating high values from low values. As
the independent DEMO are measured with
an increasing amount of error, this contour
becomes DEMO curved—eventually ap-
proximating a straight line. This curvature
is demonstrated in Figure 1. The same effect
was demonstrated earlier by Lord (1962),
DEMO proved that when a conjunctive step
function (multiple cut) is appropriate under
errorless measurement conditions, a sufficient
amount of error dictates the use of a linear
approximation in its place. (The reader who
does not follow this brief description is re-
ferred to Lord's article.)
DEMO summarize, linear functions are good ap-
proximations to conditionally monotone func-
DEMO; the relative values of the weights are
not affected by error DEMO the criterion variable,
and conditionally monotone functions tend
to become more linear in the presence of in-
creasing error in the predictor variables. DEMO
models fit, then, because the contexts in which
they are evaluated tend to be conditionally
monotone contexts in which there is much
error.
DEMO conclusion—that linear models are
often good approximations in many decision-
making situations that psychologists study—
is not original with, this article. In discussing
the evaluation of job applications, Thorndike
(1918) wrote:
The setting up of an equation of prophecy from an
equation of status will usually DEMO very complex,
variance in the criterion to total variance. Hence
v = av', where v' is the vector of vah'dities that
would be obtained were there no error. And it
follows that (3 = a/3', where j3' is the vector of beta
weights that would be obtained were there no error.
4 E. Mark Gold DEMO a contributing mathematician
to the study.
100
ROBYN M. DAWES AND BERNARD CORRIGAN
= 1
—boundary separating
true DEMO of 1 and 0
• optimal cut boundary
for separating observed scores
linear
approximation
FIGURE 1. Conjunctive true score region, optimal cut boundary,
and linear approximation.
but a rough [linear] approximation, if sound in
principle, will often give excellent results. In so far
as the lines of relation, interrelation, and dependency
are rectilinear, the technique is greatly simplified;
and a rough approximation to Ms is probably often
the case DEMO added; p. IS] .
PAEAMOEPHIC LINEAR REPRESENTATION
In 1923, Henry A. Wallace (former Vice-
President under Roosevelt) proposed that one
method of DEMO "what is on the corn
judge's mind" is to build a linear model of the
judge by regressing his ratings of corn DEMO
on various characteristics of the corn that he
rates; Wallace's DEMO of analyzing the expert
decision maker by constructing such a model
apparently did not excite many readers at that
time. Thirty-seven years later, Hoffman
(1960) independently proposed that linear
models could be used to represent DEMO
judgment, and his proposal received a great
deal of attention. Hoffman DEMO the linear
model that he used to predict an expert's
judgment a "paramorphic representation" of
such judgment. The term was chosen because
DEMO did not mean to imply that the
actual psychological process involved in mak-
ing the judgment was that of weighing vari-
ous variables, but rather that this process
could be simulated by such a weighting. There
DEMO many cases in which the simulation
was clearly inappropriate in that it predicted
qualitative aspects of the judgment process
that were not, in fact, discovered; the simula-
tion was regarded as good paramorphic repre-
sentation, however, if the output of the linear
model corresponded to the output of the
judge. Such linear models have been shown
to be quite DEMO paramorphic representations
or, as some authors put it, quite good at
"capturing the policy" of judges (Anderson,
1968; Beach,J967; Christal, 1968; Dudycha
& Naylor, 1966; Goldberg, 1968b; Ham-
DEMO, Hursch, & Todd, 1964; Hoffman,
Slovic, & Rorer, 1968; Hursch, Hammond, &
Hurseh, 1964; Naylor & Wherry, 1965; Ny-
stedt & Magnusson, 1972; Schenck & Naylor,
LINEAR MODELS
1968; Slovic, 1969; Tucker, 1964; Wherry &
DEMO, 1966; Wiggins & Hoffman, 1968).
See Slovic and Lichtenstein (1971) for a
recent review.
Does the success of such models indicate
that the judges are nothing more than "linear
machines"? The answer to this question
hinges on whether or not the discrepancies
between the DEMO judgments and those pre-
dicted by the linear model are reliable. If
these discrepancies have no reliability, then
the decision maker is behaving like a linear
machine with an error component. If, on the
other hand, these discrepancies can be shown
to be reliable, then the decision DEMO is be-
having in a consistently nonlinear way.
Rorer and Slovic (DEMO) discovered that such
deviations can be reliable, although com-
pletely unrelated to the criterion that the
judge is attempting to predict! The reliability
DEMO the nonlinear component may also be as-
sessed by comparing the correlation between
the predictions of the model and the judge
with the overall DEMO of the judge. If
the decision maker is acting like the linear
model with an error component, the cor-
relation between the model and the actual
judgments should be equal to the square root
of the DEMO of these judgments. In con-
junction with Winter,6 the present author
asked three judges from the admissions com-
mittee at the University of DEMO's psy-
chology department to rerate 90 applicants,
who had previously been rated on a 6-point
scale to assess their suitability for entering
DEMO graduate program. The reliabilities of the
three judges were .62, .69, and .68. Linear
models of these judges' behavior were con-
structed on the basis of three predictor vari-
ables: undergraduate grade point average,
GRE scores, and a rating of the undergradu-
ate institution that the applicant attended.
The judges' correlations with their linear
models were .50, DEMO, and .79. Although these
correlations did not approach the square root
DEMO the reliabilities, the study was marred in
that the ratings were DEMO on all the infor-
mation in the applicant's folder and the linear
models were not. Perhaps linear models based
B Ben Winter was DEMO contributing mathematician to
the study.
101
on more variables would lead to the conclu-
sion that these judges behaved like linear
machines.
BOOTSTRAPPING
When DEMO are actual criterion values
against which the predictions of both the
judge and the linear model of the judge can
be compared, the paramorphic linear model
often does a better job than does the judge
himself. DEMO is, the correlation between out-
put of the model and criterion DEMO often higher
than the correlation between the decision
maker's judgment and criterion, even though
the niodel is based on the behavior of the
decision maker. This "intriguing possibility"
was first suggested by Yntema and Torgerson
(1961). It was later demonstrated in a busi-
ness context by Bowman (1963) and was
eventually termed bootstrapping. Bootstrap-
ping has DEMO out to be a rather pervasive
phenomenon. For example, in the DEMO
and Kohen (1971) study, the linear model
of every one DEMO their 80 University oj Illinois
judges did a better job than did the judges
themselves in predicting actual grade point
averages. This result has DEMO replicated for
40 of 41 University of Oregon judges making
the same judgments (in a study conducted in
conjunction with Wiggins, Gregory, & Dil-
ler 6 ). Goldberg (1970) demonstrated it for
26 of 29 clinical psychology judges, and
Dawes (1971) found it in the evaluation of
graduate applicants at the University of Ore-
gon.
Why does DEMO work? In 1963,
Bowman wrote:
It seems useful to DEMO an explanation of why
decision rules derived from management's own
average behavior might yield better results than the
aggregate behavior itself. Man seems DEMO respond to
selective cues in his environment—particular things
seem to catch his attention at times (the last tele-
phone call). . . . [These random and particularistic
components can be eliminated] through the use of
DEMO rules incorporating coefficients derived from
management's own recurrent behavior [p. 316].
Working entirely independently on the pre-
diction of neurosis and psychosis from DEMO
profiles, Goldberg (1970) wrote:
6 Nancy Wiggins, Sundra Gregory, and Richard
Diller were contributing psychologists to the study.
102
ROBYN M. DAWES AND BERNARD CORRIGAN
TABLE 1
CORRELATIONS BETWEEN PREDICTIONS DEMO CRITERION VALUES
Average
validity
of judge
Example
Prediction of neurosis versus
psychosis .28
Illinois students' prediction of
grade point average .33
Oregon students' DEMO of
grade point average .37
Prediction of later faculty
ratings, at DEMO .19
Yntema & Torgerson (1961)
experiment .84
For the clinician DEMO not a machine. While he pos-
sesses his full share of human learning and hypoth-
esis-generating skills, he lacks a machine's reli-
ability. He "has his days": Boredom, fatigue, ill-
ness, situational DEMO interpersonal distractions all
plague him, with the result that his repeated DEMO
ments of the exact same stimulus configuration are
not identical. .. . If we could remove some of this
human unreliability by eliminating the DEMO error
in his judgments, we should thereby increase the
validity of DEMO resulting predictions. The problem,
then, may be reformulated: Can the clinician's judg-
mental unreliability be separated from his—hopefully,
somewhat valid—judgmental DEMO [p. 423]?
Goldberg's answer was yes; the means of
DEMO was by constructing a linear para-
morphic representation of the judge.
In 1971, Dawes wrote:
A mathematical model, by its very nature, is an
abstraction of the process it models; hence, if the
DEMO maker's behavior involves following valid
principles but following them poorly, DEMO valid
principles will be abstracted by the model—as long
as the deviations from these principles are not sys-
tematically related to the variables the DEMO
maker is considering [p. 182].
AN END TO BOOTSTRAPPING: RANDOM
LINEAR DEMO
Belief in the efficacy of bootstrapping was
based on a comparison of the validity of the
linear model of the judge with the validity DEMO
his (or her) judgments themselves. That was
only one of two logically possible comparisons.
The other is between the validity of the
linear DEMO of the judge and the validity of
linear models in general. That is, to demon-
strate that bootstrapping works because the
linear model catches the essence of a judge's
Average
validity
of judge's
model
DEMO
.50
.43
.25
.89
Average
validity
of random
model
.30
.51
.51
.39
.84
Validity
of equal
weighting
model
.34
.60
.60
.48
.97
DEMO
validated
validity of
regression
analysis
.46
.57
.57
.38
expertise and at the same time eliminates un-
reliability, it is necessary to demonstrate that
the weights obtained from an analysis of the
judge's behavior are DEMO to those that
might be obtained in other ways—for ex-
ample, DEMO randomly. In the four
examples discussed in this article, there is DEMO
evidence of such superiority.
In each example, the authors constructed
random DEMO models to predict the criterion.
The sign of each predictor variable was deter-
mined on an a priori basis so that it would
have DEMO positive relationship to the criterion.
Then a normal deviate was selected at ran-
dom from a normal distribution with unit
variance, and the absolute value of this de-
viate was used as a weight for the DEMO
Ten thousand such models were constructed
for each example. The results are presented
in Table 1 along with the earlier results. On
the average, correlations between the criteria
and the output predicted from the random
models DEMO higher than those obtained from
the judges' models. The present authors DEMO
investigated equal weighting and, of course,
discovered that such weighting DEMO even
better.7 (In two of the four examples, the
7 This result follows from a simple inequality: If
several standardized predictor variables all have a
positive correlation with a criterion variable, the
correlation between the average of the predictor
variables and the criterion will be higher than DEMO
average correlation between predictor and criterion
(see Ghiselli, 1964). Here an equal weighting scheme
gives the same output as does the average DEMO all ran-
dom models—all of which have positive validity.
Hence it has a correlation higher than the average
Validity
of optimal
linear
model
.46
DEMO
.69
.54
.97
LINEAR MODELS
103
TABLE 2
CORRELATIONS BETWEEN PREDICTIONS AND LINEAR MODELS
Average DEMO of
judge with
optimal
linear model
Example
Prediction of neurosis versus
psychosis .53"
Illinois students' prediction of
grade point average —
Oregon students' prediction of
grade point average .53*
Prediction of later faculty
ratings at Oregon —
Yntema & Torgerson (1961)
experiment —
" Empirically derived.
equal weighting scheme had a higher correla-
tion with the criterion than DEMO the cross-
validated optimal weighting scheme. This
anomalous result is explained by the fact that
the ratio of observations of variables was too
low DEMO obtain stable beta weights in the actu-
arial analysis; in practice DEMO regression
would be used and fewer variables weighted).
Essentially the same results were obtained
when the weights were selected from a rec-
tangular DEMO Why? Because linear
models are robust not only in the three DEMO
described earlier in this article, but they are
robust over deviations DEMO optimal weight-
ing as well. In other words, the bootstrapping
finding DEMO be simply a reaffirmation of the
earlier finding that linear models are superior
to human judgments—the weights derived
from judges' behavior being sufficiently close
to the optimal weights so that the outputs of
the models are DEMO similar. In other words,
the solution to the problem of obtaining opti-
mal weights is one that—in terms of von Win-
terfeldt and DEMO a "flat maxi-
mum." Weights that are near to optimal lead
to almost the same output as do optimal beta
weights. The behavior DEMO the expert judge,
because he (or she) knows at least something
about the direction of the variables, yields
correlation of the random models. Also see Dawes
(1970).
8 D. von Winterfeldt and W. Edwards. Costs and
Payoffs in Perceptual Research. Unpublished manu-
script, University of Michigan (Engineering Psy-
chology Laboratory), 1973.
Average r of
judge's model
with optimal
linear model
.67
.72
.62
.46
.92
Average r DEMO
random model
with optimal
linear model
.65
.74
.74
.72
.87
r of equal
weighting
model with
optimal linear
model
.74
.87
.87
.89
DEMO
r of split
composite
with optimal
linear model
1.00
.83
.83
.70
—
weights near optimal. (But note that in all
cases equal weighting is superior to the models
based on judges' behavior.)
This explanation for the efficacy of the
models is illustrated in Table 2, which pre-
sents the correlation between the models and
the optimal linear model (not cross-vali-
dated).9 The table also presents the correla-
tion between DEMO' predictions and those
from the optimal linear models' predictions.
These correlations also yield partial correla-
tions approaching zero; it follows, as noted
DEMO, that a linear synthesis of the optimal
linear model with the DEMO' estimates would
not improve on the optimal linear model.
As von DEMO and Edwards (see Foot-
note 5) pointed out, the questions DEMO "What
is flat?" and "How flat is flat?" are not well
defined mathematically. Here, however, we
wish to point out DEMO even a linear model
based on a single predictor has a peak that
9 The correlations are uniformly high. These cor-
relations can be DEMO directly by a comparison of
the validity of the model with the validity of the
optimal linear model. If we were to predict the
DEMO from a linear composite of the optimal
linear model and the nonoptimal linear model,
the beta weight given to the nonoptimal model
would DEMO zero because it would be impossible to
improve on the linear prediction from the optimal
model. Hence the partial correlation between non-
optimal model DEMO criterion partialling out the opti-
mal linear model must also be zero (Hays, 1963,
p. 575). The correlation between actual and DEMO
may then be computed by setting the numerator of
the formula for the partial correlation coefficient
equal to zero.
104
Reduction
in
MSE
ROBYN M. DAWES AND BERNARD CORRIGAN
4 .5 DEMO
Regression Weight
.7 .8 .9 I.OO
FIGURE 2. Reduction in mean square error (MSE) as a function of the
believed -correlation coefficient.
might DEMO be regarded as flat. Suppose
that this single predictor variable correlates
.71 with the criterion variable; our best pre-
diction is, therefore, that the standard score
on the criterion variable equals .71 times the
standard DEMO on the predictor variable, and
the mean square error of prediction DEMO given
by 1 - rz = .50.
Now suppose that the correlation between
predictor and criterion is believed to be a
rather than r. DEMO such a case, the prediction
is now that the standard score DEMO the criterion
variable is equal to a times the standard score
of the predictor variable, where a=^=r but
a = r + c. The new mean square error of pre-
diction is equal to 1 — DEMO + c2, which is equal
to only .60 if c is DEMO (i.e., if the correlation
of .71 is believed to be 1.01 or .41). So a
rather grievous error in estimating the cor-
DEMO coefficient results in an increase in
mean square error of prediction of only 20%.
Figure 2 presents reduction in mean square
error as a DEMO of the believed correlation
coefficient when the true correlation coeffi-
cient is .71. The maximum appears rather flat.
UNIT RATING
In the four examples DEMO in this
article, unit weighting did extremely well in
predicting the DEMO values. Many past
investigators have also found that unit weight-
ing does well in a variety of contexts. It is
accepted as almost axiomatic DEMO items form-
ing a scale should be given unit weighting
rather than be weighted by validities or co-
variances (Berdie & Campbell, 1968; Wang
& Stanley, 1970). Unit weighting has also
been advocated in situations in which popula-
tions change from time to time—as in evalu-
DEMO officer candidates in New Zealand dur-
ing World War II (Wrigley, personal com-
munication, 1972). And such advocacy has
been supported by empirical studies (Lawshe
& Schucker, 1959; Trattner, 1963; Wesman &DEMO
Bennett, 1959), all showing that equal
weighting does as well DEMO optimal weighting
when the weights are applied to a new sample.
Recently, Schmidt (1971) has shown that
equal weighting may be superior to optimal
weighting schemes even when the cross-vali-
dation is performed on samples DEMO the same
(theoretical) population. In his simulation
studies, Schmidt found DEMO in the presence
of suppressor variables the ratio of observa-
tions to predictors should be approximately
15 to 1 before optimally derived weights are
DEMO to unit weights in cross-validation
and, in the absence of suppressors, this ratio
should be 25 to 1. In a similar study, Marks10
found that a ratio of approximately 20 to 1
was necessary. (Marks's simulations had the
10 M. R. Marks. Two Kinds of Regression DEMO
which are Better than Betas in Cross Samples. Paper
presented at the annual meeting of the American
Psychological Association, New York, September
1966.
LINEAR MODELS
specific property that the partial correlation
between any two predictors DEMO out
the criterion variable was zero.)
In short, given the DEMO that in many con-
texts equal weights yield predictions very
highly correlated with those obtained from
optimal weights, equal weights may be su-
perior. In contrast (Meehl, personal com-
munication, 1972), beta coefficients are ex-
tremely unstable and most extrapolations are
to samples from populations that DEMO some-
what from those on which the betas are esti-
mated. Meehl (personal communication, 1972)
concluded "in most practical situations an un-
weighted sum of a small number of 'big'
variables will, DEMO the average, be preferable
to regression equations." "
CONCLUSION
Linear DEMO work because the situations
in which they have been investigated are
those in which: (a) The predictor variables
have conditionally monotone relationships to
criteria (or may easily be rescaled to have
such a relationship); (b) there is error in the
dependent variable; (c) there is error in the
independent variables; and (d) deviations
from optimal weighting do not make much
practical difference. These situations abound.
(It is always better to be smarter, more beau-
tiful, closer to age DEMO, closer to blood pres-
sure 120 over 80, etc.) Thus DEMO situation
demands decision-making behavior approxi-
mately like that of a linear model if the de-
cision making is to be appropriate—in other
words, an analysis of the task faced by the
decision maker (Edwards, 1971; Simon,
1969) leads to the conclusion that linear
models work well. It is, therefore, not sur-
prising that linear models outperform intui-
DEMO judgment. Nor is it surprising that deci-
sion makers (insofar as DEMO are behaving ap-
propriately) are paramorphically well repre-
sented by linear DEMO Again, to quote
Thorndike (1918):
There is a prevalent DEMO that the expert judge of
men succeeds by some mystery of divination. Of
course, this is nonsense. He succeeds because he
makes smaller errors in the facts or in the way he
weights them. Sufficient insight DEMO investigation
"Trites and Sells (1955) also found equal weight-
ing DEMO for estimating factor scores.
105
should enable us to secure all the advantages of the
impressionistic judgment (except its speed and con-
venience) DEMO any of its defects [p. 76].
The whole trick is to decide what variables to
look at and then to know how to add.
DEMO
ANDERSON, N. H. A simple model for information
integration. In R. DEMO Abelson, E. Aronson, W. J.
McGuire, T. M. Newcomb, M. J. Rosenberg, &
P. H. Tannenbaum (Eds.), Theories of cognitive
consistency: A sourcebook. Chicago: Rand Mc-
Nally, 1968.
BEACH, L. DEMO Multiple regression as a model for
human information utilization. Organizational Be-
havior and Human Performance, 1967, 2, 274-
289.
BERDIE, R. F., & CAMPBELL, D. P. Measurement <r
interest. In D. K. Whitla (Ed.), Handbook of
measurement and assessment in behavioral sciences.
Reading, Mass.: Addison-Wesley, 1968.
BIGELOW, J. (Ed.) The complete works of Benjamin
Franklin. Vol. 4. New York: Putnam, 1887.
BOWMAN, E. H. Consistency and optimality in mana-
gerial decision making. Management Science, 1963,
9,310-321
CHRISTAL, R. E. Selecting a harem—and other ap-
plications of the policy-capturing model. Journal
of Experimental Education, 1968, 36, 35-41..
DAWES, DEMO M. Algebraic models of cognition. In
C. A. J. Vlek (Ed.), Algebraic models in psychol-
ogy: Proceedings of the NVFFIC international
summer DEMO in science. The Hague: Netherlands
Universities Foundation for International Coop-
eration, 1968.
DAWES, R. M. An inequality concerning correlation
of composites vs. composites of correlations. Ore-
gon Research Institute Methodological Note, 1970,
Vol. 1, No. 1.
DAWES, R. M. A case study of graduate admissions:DEMO
Application of three principles of human decision
making. American Psychologist, 1971, 26, 180-188.
DTIDYCHA, A. L., & NAYLOR, J. C. The DEMO of
variations in the cue R-matrix upon the obtained
policy equations of judges. Educational and Psy-
chological Measurement, 1966, 26, 583-603.
EDWARDS, DEMO Bayesian and regression models in
human information processing—a myopic per-
spective. Organizational Behavior and Human Per-
formance, 1971, 6, 639-648.
EDJHORN, H. DEMO Expert measurement and mechanical
combination. Organizational Behavior and Human
Performance, 1972, 7, 86-106.
GHISELLI, E. E. Theory of psychological measure-
ment. New DEMO: McGraw-Hill, 1964.
GOLDBERG, L. R. Diagnosticians vs. diagnostic signs:
DEMO diagnosis of psychosis vs. neurosis from the
MMPI. Psychological Monographs, 1965, 79
(9, Whole No. 602).
GOLDBERG, L. R. Seer over sign: The first "good"
example? Journal of Experimental Research in
Personality, 1968, 3, 168-171. (a)
106
ROBYN M. DAWES AND BERNARD CORRIGAN
GOLDBERG, L. R. Simple models or simple processes?
Some research on clinical judgments. American
Psychologist, 1968, 23, 483-496. (b)
GOLDBERG, L. R. Man versus model DEMO man: A
. rationale, plus some evidence, for a method DEMO im-
proving on clinical inferences. Psychological Bul-
letin, 1970, 73, DEMO
HAMMOND, K. R., HUESCH, C. J., & TODD, F. DEMO
Analyzing the components of clinical inferences.
Psychological Review, 1964, 71, DEMO
HAYS, W. L. Statistics for psychologists. New York:
Holt, Rinehart & Winston, 1963.
HOFFMAN, P. J. The paramorphic representation of
clinical DEMO Psychological Bulletin, 1960,
57, 116-131.
HOFFMAN, P. J., SLOVIC, P., & RORER, L. G. An
analysis-of-variance model for the assessment of
configural cue utilization in clinical judgment.
Psychological Bulletin, 1968, 69, 338-349.
HURSCH, C. J., HAMMOND, K. R., & HTJESCH, J. L.
Some methodological considerations in multiple-
cue probability studies. Psychological Review,
DEMO, 71, 42-60.
KRANTZ, D. H. Measurement structures and psy-
chological DEMO Science, 1972, 175, 1427-1435.
KRANTZ, D. H., LUCE, R. D., SUPPES, P., & TVERSKY,
A. Foundations of measurement. Vol. 1. New
York: Academic Press, 1971.
LAWSHE, C. H., & DEMO, R. E. The relative
efficiency of four test weighting methods in DEMO
prediction. Educational and Psychological Mea-
surement, 1959, 19, 103-114.
LORD, F. M. Cutting scores and errors of measure-
ment. Psychometrika, 1962, DEMO, 19-30.
MEEHL, P. E. Clinical versus statistical prediction:
A theoretical analysis and review of the literature.
Minneapolis: University of Minnesota Press, DEMO
MEEHL, P. E. Clinical versus statistical prediction:
pie. Journal of DEMO Research in Person-
ality, 1965, 1, 27-32J
NAYLOR, J. C., & WHERRY, R. J. The use of simu-
lated stimuli and DEMO "JAN" technique to capture
and cluster the policies of raters. Educational and
Psychological Measurement, 1965, 25, 969-986.
NYSTEDT, L., & MAGNUSSON, D. Predictive efficiency
as a function of amount of information. Multi-
variate Behavioral Research, 1972, 7, 441-450.
PANKOFF, L. A quantification of DEMO: A case
study. Unpublished doctoral dissertation, Uni-
versity of Chicago, DEMO
PANKOFF, L. B., & ROBERTS, H. V. Bayesian syn-
thesis DEMO clinical and statistical prediction. Psy-
chological Bulletin, 1968, 70, 762-773.
DEMO, L. G. A circuitous route to bootstrapping. In
H. B. Haley, A. G. D'Costa, & A. M. Schafer
(Eds.), Conference DEMO personality measurement in
medical education. Washington, D.C.: Association
of American Medical Colleges, 1971.
RORER, L. G., & SLOVIC, P. The measurement DEMO
changes in judgmental strategy. American Psy-
chologist, 1966, 21, 641-642. (Abstract)
SARBIN, T. R. Contribution to the study of actuarial
and individual methods of prediction. American
Journal of Sociology, 1943, 48, 593-602.
SAWYER, J. Measurement and prediction, clinical
and statistical. Psychological Bulletin, 1966, 66,
178-200.
SCHENCK, E. A., & NAYLOR, J. C. DEMO cautionary note
concerning the use of .regression analysis for captur-
ing the strategies of people. Educational and Psy-
chological Measurement, 1968, 28, 3-7.
SCHMIDT, F. L. The relevant efficiency of regression
in simple unit predictor weights in applied dif-
ferential psychology. Educational and Psychological
Measurement, 1971, DEMO, 699-714.
SIMON, H. A. The sciences of the artificial. Cam-
bridge, Mass.: MIT Press, 1969.
SLOVIC, P. Analyzing the expert judge: A descriptive
study of a stockbroker's decision processes. Jour-
nal of DEMO Psychology, 1969, 53, 255-263.
SLOVIC, P., & LICHTENSTEDJ, S. Comparison of Bayes-
ian and regression approaches to the study of in-
DEMO processing in judgment. Organizational
Behavior and Human Performance, 1971, 6, DEMO
744, .
THORNDIKE, E. L. Fundamental theorems in judging
men. Journal of Applied Psychology, 1918, 2, 67-
76.
TRATTNER, M. H. DEMO of three methods for
assembling aptitude test battery. Personnel Psy-
chology, DEMO, 16, 221-232.
TRITES, D. K., & SELLS, S. B. DEMO note on alternative
methods for estimating factor scores. Journal of
Applied Psychology, 1955, 39, 455-456.
TUCKER, L. R. A suggested alternative formulation
DEMO the developments by Hursch, Hammond, and
Hursch, and by Hammond, Hursch, and Todd.
Psychological Review, 1964, 71, 528-530.
WALLACE, H. A. What is in the corn judge's mind?
Journal of DEMO American Society of Agronomy,
1923, 15, 300-304.
WANG, M. DEMO, & STANLEY, J. C. Differential weight-
ing: A review of DEMO in empirical studies.
Review of Educational Research, 1970, 40, 663-
DEMO
WESMAN, A. G., & BENNETT, G. K. Multiple re-
gression DEMO simple addition of scores in pre-
diction of college grades. Educational and Psy-
chological Measurement, 1959, 19, 243-246.
WHERRY, R. J., & NAYLOR, J. C. Comparison of two
approaches—JAN and PROF^for capturing rater
strategies. Educational and Psychological Mea-
surement, 1966, 26, 267-286.
WIGGINS, N., & HOFFMAN, P. J. Three models of
clinical judgment. Journal of Abnormal Psychology,
1968, 73, 70-77.
WIGGINS, N., & KOHEN, E. S. Man vs. model of man
revisited: The forecasting of graduate school suc-
cess. Journal of Personality and Social Psychology,
1971, 19, DEMO
YNTEMA, D. B., & TORGERSON, W. S. Man-computer
cooperation in DEMO requiring common sense.
IRE Transactions of the Professional Group on
Human Factors in Electronics, 1961, HFE-2(1),
20-26.
(Received August 27, 1973){1g42fwefx}