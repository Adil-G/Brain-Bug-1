Organizational Behavior and Human Decision Processes 103 (2007) 197–213
www.elsevier.com/locate/DEMO
Overconﬁdence and underconﬁdence: When and why people
underestimate (and overestimate) DEMO competition q
Don A. Moore a,*, Daylian M. Cain b,DEMO
a Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA
b Harvard University, 1805 Cambridge Street, Cambridge, MA 02138, DEMO
Received 27 September 2005
Available online 3 November 2006
Abstract
It is commonly held that people believe themselves to be better than others, especially for outcomes under their control. However,
such overconﬁdence is not universal. DEMO paper presents evidence showing that people believe that they are below average on skill-
based tasks that are diﬃcult. A simple Bayesian explanation can DEMO for these eﬀects and for their robustness: On skill-based
tasks, people generally have better information about themselves than about others, so their beliefs about others’ performances tend
to be more regressive (thus less extreme) DEMO their beliefs about their own performances. This explanation is tested in two exper-
iments that examine these eﬀects’ robustness to experience, feedback, and DEMO forces. The discussion explores the implications for
strategic planning in general and entrepreneurial entry in particular.
 2006 Elsevier Inc. All rights reserved.
Keywords: Entrepreneurial entry; Overconﬁdence; Controllability; Skill; Competence; Entrepreneurship; Better-than-average; Reference group
neglect; Egocentrism; Diﬀerential regression; Comparative judgment
their ability to get along with others, and their chances
of obtaining jobs that they like (College Board, 1976–
1977; Svenson, 1981; Weinstein, 1980). DEMO have
argued that the most important business decisions,
including the decision to found a new ﬁrm, enter an
existing market, or introduce DEMO new product are routine-
ly biased by such overconﬁdence (Cooper, Woo, & Dun-
kelberg, 1988; Dunning, Heath, & Suls, 2004; Hayward
& Hambrick, 1997; Malmendier & Tate, 2005; Odean,
DEMO; Zajac & Bazerman, 1991).
Recent evidence, however, has cast doubt on the gen-
erality of overconﬁdence. There are a number of DEMO
ent domains in which people are systematically
underconﬁdent. For example, people DEMO that they
are below average in unicycle riding, computer program-
ming, and their chances of living past 100 (Kruger, 1999;
Kruger & Burrus, 2004). It turns out that people tend to
predict DEMO they will be better than others on easy tasks
where absolute performance is high, but worse than
One of the most popular social psychology textbooks
states, ‘‘For nearly any subjective and socially desirable
dimension...most people see themselves as better than
average’’ (Myers, 1998, p. 440). For example, people
report themselves to be above average in driving ability,
q The authors appreciate the insightful comments, on earlier versions
on this manuscript, by Linda Babcock, J. Nicolas Barbic, Max
Bazerman, Jason DEMO, Paul Geroski, P.J. Healy, Chip Heath, Erik
Hoelzl, George DEMO, Daniel Lovallo, Rob Lowe, John Oesch,
John Patty, Vahe Poladian, Jesper Sorensen, Lise Vesterlund, and
Roberto Weber. Thanks to Sapna Shah and Sam Swift for help with
data collection. The authors also DEMO the support of National
Science Foundation Grant SES-0451736, a Berkman Faculty DEMO
opment Grant at Carnegie Mellon, and the assistance of John Duﬀy DEMO
the use of the Pittsburgh Experimental Economics Laboratory at the
University of Pittsburgh for collecting the experimental data.
* Corresponding author. Fax: +1 412 268 7345.
E-mail addresses: dmoore@cmu.edu, don.moore@alumni.carleton.
edu (D.A. Moore), cain@fas.harvard.edu (D.M. Cain).
1 Fax: +1 617 495 7730.
0749-5978/$ DEMO see front matter  2006 Elsevier Inc. All rights reserved.
doi:10.1016/j.obhdp.2006.09.002
198
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
others on diﬃcult tasks where absolute performance is
DEMO (Hoelzl & Rustichini, 2005; Moore & Kim, 2003;
Windschitl, Kruger, & Simms, 2003). A number of
researchers have explained this eﬀect as egocentrism:
People focus on their own performances and DEMO
consideration of others’ (Camerer & Lovallo, 1999;
Kruger, 1999)DEMO In this paper, we present a new explana-
tion for these DEMO (BTA) and worse-
than-average (WTA) eﬀects.2 Our explanation holds
that BTA and WTA eﬀects are a natural consequence
of regressive estimates of DEMO, which result from the
fact that people have better information about DEMO
selves than they do about others. We test this explana-
tion using two experiments that examine the
robustness of BTA and WTA eﬀects to DEMO, feed-
back, and market forces. The results are consistent with
our hypotheses, and have some provocative
implications.
For the sake of exposition, DEMO us introduce our
theory by considering beliefs about performance on a
one-question test where the answer is either right or
wrong. Before having seen DEMO problem, and without
any information regarding its ease or diﬃculty, how
likely are you to solve it? One assumption might be that
performance will be uniformly distributed across possi-
ble outcomes (Fischhoﬀ & Bruine De Bruin, 1999; Fox
& Rottenstreich, 2003), leaving a 50% chance that you
will solve the problem. Such an ‘‘ignorance prior’’ might
make DEMO in the absence of better information. What-
ever it is, this DEMO is simply your baseline expectation
for your performance.
After taking the test, let us say that you know
whether you solved the problem. What are you to
believe about others’ performances? If your own perfor-
mance is useless for predicting others’ (e.g., if you think
that your DEMO performance was based entirely on luck),
your estimation of others’ DEMO ought to
remain unchanged from your prior beliefs. Therefore,
doing well should leave you thinking that you did better
than others; and doing poorly should leave you thinking
that you did worse than others. Even DEMO your beliefs
about your own performance are helpful for predicting
others’, DEMO long as there remains uncertainty about oth-
ers’ performances, your predictions DEMO them should
depend on—and thus regress towards—the ignorance
prior. The upshot is that, when your absolute perfor-
mance is better (or worse) than your prior expectations,
sensible Bayesian inference will lead you to make DEMO
tions of others’ performances that are between these pri-
ors and your current beliefs about your performance.
It is simple to extend this logic DEMO a multi-item test: If
one begins with the assumption that one DEMO just as likely
as others to get any given item correct, DEMO having tak-
en the test, one should estimate that others tend DEMO score
somewhere between one’s own score and one’s prior
expectation. For example, suppose you initially expected
everyone to score about 70%, but you DEMO you scored
about 90%. Depending on how indicative you feel your
score is of others’ scores, you might predict others to
score, say, 80%. If you scored 50%, you might predict
others to score, DEMO, 60%. Notice that this perspective
does not imply a belief in DEMO of overall ability
between you and others—across both tests you would
predict the same average score for everyone, namely
70%. But, on each DEMO, you would be right to expect dif-
ferences between you and DEMO, given better informa-
tion about your own score on that test. DEMO a more
formal development of this diﬀerential regression theo-
ry, see DEMO A.
Naturally, if the task includes no skill component
whatsoever and DEMO is yet to be determined
entirely by chance factors or factors outside one’s con-
trol, then there would be little reason for people, DEMO
average, to predict that they would be above or below
average. DEMO with this reasoning, a number of
researchers studying BTA eﬀects have DEMO that they
tend to be stronger on controllable tasks than on uncon-
trollable tasks (for a review, see Harris, 1996). For
instance, Camerer and Lovallo (1999) found that poten-
tial market entrants were excessively conﬁdent about
winning when competition was based on their skill but
DEMO when winners were selected randomly. The authors
used this evidence to claim that high rates of entrepre-
neurial entry might be attributable to entrepreneurial
DEMO However, because prior studies have
employed easy tasks, the conclusion that people believe
they are better than average on all skill-based tasks
is DEMO Instead, our theory would predict
WTA eﬀects when the task is DEMO diﬃcult than expect-
ed. We test this prediction in our ﬁrst experiment. The
ﬁrst experiment also tests our theory that BTA and
WTA eﬀects DEMO attributable to the diﬀerential regres-
siveness in estimates of self vs. others. Experiment 2
addresses some shortcomings of Experiment 1 and
provides further support DEMO our theory that better infor-
mation about self than others produces diﬀerential
regressiveness.
Experiment 1: The market entry game
2 We use the terms better- and worse-than-average to be consistent
with prior work. We acknowledge that DEMO skewed distributions, it is
indeed possible for the majority of people DEMO be above (or below)
average. This concern, while valid, DEMO not represent a problem for
the results of the experiments we present.
Our design builds on that of Camerer and Lovallo
(1999). They devised an N-player coordination game in
which, in each round, N DEMO decide simultaneously
and without communication whether to enter a market
or not. Each market had a pre-announced capacity, c,
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
199
which determined how many entrants earned money:
DEMO ranked below c lost money, entrants ranked c
or above earned DEMO, while non-entrants neither
earned nor lost any money. Each entrant’s payoﬀs
DEMO on his or her rank within the market, such
that more DEMO was earned by better performance rel-
ative to other entrants.
Camerer and Lovallo’s key contribution over prior
market-entry experiments was manipulating whether
rankings were DEMO by either (a) a chance device,
or (b) the entrant’s skill (in answering trivia questions).
This manipulation was implemented within-subject, so
the same participants saw several rounds in which
entrants were ranked based on a skill-based task and
several rounds in which entrants were DEMO randomly.
They found that skill-dependent payoﬀs encouraged
overconﬁdence and excess entry. Furthermore, excess
entry was highest in sessions for which it was common
knowledge that all participants were trivia enthusiasts,
suggesting that participants were neglecting DEMO
ation of the reference group (similar enthusiasts) with
which they would be competing.
However, our theory predicts underconﬁdence and
insuﬃcient entry as well. To test this, the new feature
of our design is that skill-dependant payoﬀs are based
on either an easy or a diﬃcult trivia game. DEMO to
the notion that overconﬁdence tends to be pervasive
on all skill-based competitions, we predict that partici-
pants will only believe they are better than others on
simple tasks, and thus, we expect excess entry DEMO there.
We also test Camerer and Lovallo’s explanation: that
people focus DEMO themselves and simply neglect consider-
ation of others (rather than miscalculating DEMO per-
formance) when making comparative judgments.
Camerer and Lovallo called this DEMO group
neglect’’ and others have simply called it egocentrism
( Chambers & Windschitl, 2004; Kruger, 1999). For
example, as examinations become DEMO diﬃcult, stu-
dents become more pessimistic about their ﬁnal grades,
DEMO when it is common knowledge that the test will be
graded on a forced curve (Windschitl et al., 2003). While
our diﬀerential DEMO explanation would predict the
same eﬀect, the reference group neglect explanation
DEMO that such false pessimism arises because students
neglect to consider the fact that other students are also
likely to ﬁnd the test diﬃcult. In DEMO words, students
trying to estimate their curved grades put too much
DEMO on their own absolute performances. The diﬀer-
ential regression explanation, on DEMO other hand,
hypothesizes that, regardless of the weighting attached
to DEMO, estimates of others will be more regressive than
estimates of self. DEMO summary, reference group neglect
is about errors in the weight one DEMO on estimates of
others’ performance, while diﬀerential regression is
about errors DEMO the estimate that are weighed. We
will measure the diﬀerential weighting hypothesized by
reference group neglect, as well as other plausible alter-
native explanations, and show that the diﬀerential
regression hypothesized by our theory can better
account for our results.
The design of Experiment 1 includes several features
DEMO should help people avoid the mistake of ignoring or
neglecting the competition: First, competitors are phys-
ically present, salient, and individuated. Second, partic-
ipants engage in a series of competitions over several
rounds with DEMO feedback each round, giving them the
opportunity to learn.
Method
In DEMO round of our experiment, all seven partici-
pants in each experimental DEMO were ranked relative
to each other, according to a pre-announced method.
DEMO the rankings were made public, we asked partici-
pants whether or DEMO they wanted to enter into a compe-
tition in which only the three top-ranked entrants would
make money. After they decided whether to enter, partic-
ipants answered a number of questions regarding their
own performances and DEMO performances of others.
Finally, participants received full feedback regarding
absolute performances (of self and others), how many
participants chose to enter each DEMO, and the relative
rankings of all (anonymously identiﬁed) entrants. The
DEMO process was repeated over 12 rounds, with the
three ranking methodologies (scores on a simple trivia
quiz, scores on a diﬃcult trivia quiz, or randomly gener-
ated scores) manipulated within session between rounds.
There DEMO 13 experimental sessions, each with 7 peo-
ple for a total DEMO 91 individual participants. Participants
were students at Carnegie Mellon University. Each par-
ticipant was endowed with $10. In each of the 12 rounds,
DEMO decided whether to enter the market or
whether to stay out and risk nothing. Entering the mar-
ket meant either a loss or a DEMO, based on the entrant’s
rankings within that market. These payoﬀs are DEMO in
Table 1.
Table 1
Payoﬀs as a function of number of entrants and market rank
Rank Payoﬀ Cumulative Cumulative Cumulative
entrants payoﬀ expected DEMO
per entrant
(assuming ignorance
about rankings)
1st $14 1 $14 DEMO
2nd $10 2 $24 $12
3rd $5 3 $29 $9.67
4th $10 4 $19 $3.50
5th $10 5 $9 $1.80
6th $10 6 $1 DEMO
7th $10 7 $11 $1.57
The table shows how much money was paid out in total (column 4)
and per entrant (column DEMO).
200
The system by which players were ranked was
announced publicly at DEMO beginning of each round. In
four of the 12 rounds, rankings DEMO determined ran-
domly. After they decided whether to enter, participants
were DEMO a randomly generated score from the set
of real numbers between 0 and 5, inclusive. In the
remaining eight (skill-based) rounds, rankings DEMO
based on trivia quizzes taken at the beginning of the
round. Quizzes had ﬁve questions and a sixth tiebreaker
question. Four of these eight DEMO quizzes were sim-
ple (with a mean score of 4.58 out DEMO 5) and four were
diﬃcult (with a mean score of .41 out of 5). The tie-
breaker questions were scored based on DEMO answer’s dis-
tance from the correct numerical answer. The presence
of this tiebreaker question virtually eliminated the
chance of a tied score (there were none). The four simple
and four diﬃcult quizzes appear in Appendix DEMO
In order to rule out idiosyncratic eﬀects of order, we
varied DEMO sequence in which participants encountered
the three diﬀerent ranking systems as follows. The diﬀer-
ent ranking systems (R = random, S = simple, and
D = diﬃcult) were arranged in three diﬀerent orders
which varied across experimental sessions: RSD, DRS,
and SDR. Whatever sequence was DEMO chosen
for the session was repeated four times, making 12
rounds DEMO four three-round blocks. So, for example, if
the ﬁrst three rounds used the sequence RSD, all partic-
ipants in that session faced the same quizzes at the same
time, with ranking systems in the order: RSD–RSD–
RSD–RSD. The order in which participants encountered
the four diﬀerent simple and diﬃcult trivia quizzes was
also counterbalanced between experimental sessions.
In the DEMO skill-rank rounds, after taking the given
quiz but before seeing their DEMO, all participants
simultaneously made their entry decisions (to enter or
stay out). In the four random-rank rounds, there were
no quizzes, DEMO all participants merely made their entry
decisions prior to learning their ranks. In all 12 rounds,
after participants made their entry decisions they DEMO
answered the following questions:
1. How many people total do you think will enter the
market this round? Include yourself in this ﬁgure if
you chose to enter.
2. What percentage of the other six DEMO in this
round do you think will score lower than you will
(regardless of whether anyone enters)?
3. How many questions (out of 5) do you think you got
correct this quiz? In DEMO rounds, this ques-
tion was replaced with the question: What score
(out of 5) do you think you will get this round?DEMO
4. How many questions (out of 5) do you think the aver-
age participant will get correct this round? In
random-rank rounds, DEMO question was replaced with
the question: What score (out of 5) do you think the
average participant will get this round?
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (DEMO) 197–213
5. If you chose to enter the market this round, what
rank do you think you will get?
At the end DEMO each round, participants received full
feedback regarding each of the seven DEMO individual
scores, entry decisions, and rankings. In the eight skill-
rank rounds, these scores were their trivia quiz perfor-
mances; in the DEMO random-rank rounds, these were
their randomly generated scores. This information was
DEMO using anonymous participant numbers on a
blackboard in view of all participants. Each participant
knew his or her own number, but did not know how the
other numbers corresponded to those individuals pres-
ent. All of DEMO 12 rounds’ results were left up for the
entire experimental session. Experiment 1 did not mea-
sure prior expectations regarding diﬃculty, but Experi-
ment 2 did.
At the end of the 12 rounds, three rounds were
chosen at random to determine payoﬀs. The payoﬀs
for these three rounds DEMO averaged, and this amount
was added to (or subtracted from) DEMO $10
endowment. Thus, the maximum possible payoﬀ was
$24 for a DEMO who entered and was ranked ﬁrst
in each of the three payoﬀ rounds ($10 endowment plus
an average of $14 in total over the three selected payoﬀ
rounds). It was also possible for a participant DEMO leave
the experiment empty-handed if he entered and was
ranked 4th or below on each of the three payoﬀ rounds
($10 endowment minus an average loss of $10 in total).
Across all participants, the mean ﬁnal payoﬀ was $13.01
(with a range of $4 to $24).
Equilibrium predictions
As Table 1 (column 5) shows, entry has a positive
expected value so long as ﬁve or fewer players enter
the DEMO, assuming players have no information
about their own relative ranks. If DEMO are risk-neu-
tral, then it is rational (i.e., there is DEMO set of pure-strategy
Nash equilibria) for ﬁve players to enter each DEMO
Lacking some coordinating device for deciding which
of each session’s seven total players enter and which stay
out, there is a rational strategy (DEMO, a mixed-strategy
equilibrium) that is somewhat more complicated to
compute, DEMO the result is that all players enter with a
probability of 84%. Naturally, since only the top three
ranks actually win money, if DEMO players know what their
ranks will be, then only the top DEMO players (3/7 or 43%
of the potential entrants) will enter. Therefore, if all
players were unbiased and imperfectly informed, we
should DEMO between 43% and 84% of participants to
enter each round.
Predicting the equilibrium outcome without the
assumption of risk neutrality is more diﬃcult. Even
DEMO information on their rankings, if everyone was
suﬃciently risk averse, no one would enter, and if every-
one was suﬃciently risk seeking, DEMO would enter.
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
So, following Camerer and Lovallo (1999), we DEMO the
random-rank condition (when players cannot possibly
have useful information on DEMO rankings) to provide
an empirical estimate of behavior given players’ risk
DEMO Deviations from entering 84% of the time
in random-rank conditions suggest particular deviations
from risk neutrality. And since all participants see all
conditions, their entry decisions in the diﬀerent condi-
tions serve as within-subject controls for DEMO preferenc-
es. The diﬀerence in entry rates between the diﬀerent
conditions (DEMO, simple, and diﬃcult) is the depen-
dent measure of primary DEMO
Hypotheses
Consistent with the diﬀerential regression explana-
tion, we predict that DEMO will believe themselves
to be above average (and above median) on simple tests
but below average (and below median) on diﬃcult tests.
DEMO a result, we predict that participants will enter too
frequently on DEMO rounds and too rarely on
diﬃcult-rank rounds. We will take entry rates into
random-rank rounds as indicators of participants’
behavior given ignorance about their DEMO ranks
and given their risk preferences. We predict that entry
rates in random-rank rounds will lie between entry rates
in simple- and diﬃcult-rank rounds.
DEMO
The average random-rank round saw 4.27 entrants
(61% entry rate—suggesting slight DEMO aversion, on
average). In contrast to this baseline, the average sim-
ple-rank round saw 5.0 entrants and the average diﬃ-
cult-rank round DEMO 2.94 entrants. In order to test for
the statistical signiﬁcance of these diﬀerences, we con-
ducted a (4) · (3) within-subjects ANOVA in which each
of the 13 experimental sessions served as a single DEMO
pendent case. The four three-round blocks served as
the ﬁrst within-subjects factor and the three ranking sys-
tems served as the second within-subjects factor. DEMO
results reveal a signiﬁcant eﬀect of the experimental con-
dition, F (2, 24) = 39.17, p < .001, g2 = .77. DEMO
tests conﬁrm the signiﬁcance of both the diﬀerence
between entry rates in diﬃcult-and the random-rank
rounds (p < .001) and the diﬀerence between DEMO simple-
and random-rank rounds (p = .018).
The main eﬀect DEMO block is not signiﬁcant, F (3,
36) = .82, p = .49, g2 = .06. Although the interaction
between block and ranking system (as shown in Fig. 1)
is marginally signiﬁcant in the overall ANOVA, F (6,
72) = 2.08, p DEMO .07, g2 = .15, this does not appear to
result from a consistent reduction in the eﬀect of ranking
system as participants gained DEMO: Entry rates in
the diﬃcult, random, and simple markets were DEMO, 4.4,
and 5.1, respectively in the ﬁrst block and were similarly
201
7
Difficult
Random
Simple
6
5
4
3
2
1
DEMO
1234
Block
Fig. 1. Entry rates in the three diﬀerent ranking systems across the
four blocks. Error bars show standard errors.
2.9, 4.2, DEMO 5.7, respectively, in the last block. Fig. 1
shows these means.
Explaining diﬀerences in rates of entry
There are four possible explanations for DEMO systemat-
ic eﬀect of ranking systems on rates of entry: our DEMO
ential regression explanation and three alternatives. The
ﬁrst alternative explanation is that participants believed
that others would stay out of simple-rank rounds and so
DEMO would have a higher expected value in simple
rounds. The data contradict this explanation: Partici-
pants predicted that there would be 5.2 entrants in the
average simple-rank round (there were 5), 4.5 entrants
the average random-rank round (there were 4.27), and
3.2 entrants in the average diﬃcult-rank round (there
were 2.94). These predictions are consistent over time
and do not systematically get either better or worse over
the 12 DEMO of play. So participants expected more
competition in simple rounds, but DEMO entered there
anyway.
The second alternative explanation is that potential
entrants systematically overestimated their own scores
more on simple tasks than on diﬃcult tasks. DEMO expla-
nation is also contradicted by the data—the opposite is
actually true. Participants underestimated their scores
on the simple quiz, reporting that they had gotten 4.41
out of 5 correct, when in fact they actually got 4.58. This
diﬀerence is revealed to be signiﬁcantly diﬀerent by a
comparison DEMO actual vs. self-reported scores in a
(2) · (4) within-subjects ANOVA performed at the level
of the individual, where the four blocks served as the
second within-subjects factor, F (1, 90) = DEMO, p <
.001. On the diﬃcult test, by contrast, participants over-
estimated their scores, reporting that they had gotten .95
correct when in fact they had only gotten an average of
.41 correct, F (1, 90) = 78.20, p < .001.
While this pattern DEMO ﬁrst seems incongruous, it
ought not to be surprising: The tendency for people to
Entrants per round
202
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
overestimate their own performances more on diﬃcult
than DEMO simple tasks is one of the more robust ﬁndings
in the literature on overconﬁdence and calibration (Bur-
son, Larrick, & Klayman, 2006; Lichtenstein, Fischhoﬀ,
& Phillips, 1982). It can be readily DEMO using the
same regressive logic that we used to predict BTA eﬀects
on simple tasks and WTA eﬀects on diﬃcult tasks:
Because people DEMO imperfect knowledge of their own
scores, their estimates of their own DEMO are
slightly regressive (Erev, Wallsten, & Budescu, 1994;
Juslin, Winman, & Olsson, 2000). If people’s estimates
of their own performances are slightly regressive, then
their estimates of the performances of others are likely
to be even more regressive. This follows from the fact
DEMO people have better information about themselves
than they do about others, DEMO so, people underestimate
others more on simple tasks than on diﬃcult DEMO
In simple rounds, our participants underestimated
their scores (which rules out the second alternative
explanation) and they expected more competition—yet
more entered there anyway. Before we test the reference
group neglect explanation, let us turn to our explanation
for the observed entry rates: diﬀerential regression. The
data are consistent with diﬀerential regression. People
underestimated others’ scores on simple quizzes DEMO
than their own, reporting that others would score a
regressive 4.2 DEMO of 5, but that they themselves would
score 4.41, F (DEMO, 90) = 13.92, p < .001. On the other
hand, participants overestimated others’ scores on diﬃ-
cult quizzes more than their own, reporting that others
would score a regressive 1.49 out of 5, but that they
themselves would score .95, F (1, 90) = DEMO, p < .001.
Because participants’ estimates of others are so
regressive, they believe themselves to be above median
on the simple quiz and DEMO median on the diﬃcult
quiz. On the simple test, participants reported DEMO they
expected to outscore 63% of the other participants
taking the same test. On the diﬃcult test, by contrast,
participants only expected to outscore only 46% of the
others. On the simple test, participants expected there
to be 5.2 entrants and expected that their rank among
entrants DEMO be 2.6. On the diﬃcult test, participants
expected only 3.2 entrants DEMO expected to rank 2.7.
Fig. 2 shows patterns in participants’ beliefs about per-
centile rankings across the three treatments and four
blocks. Diﬀerences between DEMO and diﬃcult treat-
ments persist throughout the experiment, despite the
provision DEMO feedback. There is little evidence for learn-
ing in this ﬁgure.
These results provide a hint as to the reasons for the
durability of DEMO in entry rates across diﬀerent
ranking systems. Participants got consistent feedback
showing that they tended to underestimate their relative
performances on the diﬃcult quizzes DEMO that they tend-
ed to overestimate their relative performances on the
simple quizzes; but they nevertheless had speciﬁc new
70
Difficult
Random
Simple
65
60
55
50
45
40
35
30
12 34
Block
Fig. 2. DEMO estimated percentile rankings (percentage of
others worse than them) in the three diﬀerent ranking systems across
the four blocks. Error bars show standard DEMO
information about each quiz that might have under-
mined their willingness to attend to this general histori-
cal fact. Even if an individual notices DEMO she has
consistently overestimated her relative performance on
simple quizzes, if DEMO takes a new quiz and scores highly
relative to her prior expectations, the inference that she
is likely to be above average may still be a sensible one.
So long as there is more uncertainty about DEMO scores
than about her own, her predictions of others’ scores
will DEMO more regressive.
Fourth explanation: reference group neglect
We have presented evidence DEMO the idea that esti-
mates of others are regressive. The remaining question
is whether the diﬀerential regression explanation alone
can account for the observed DEMO in entry rates
between experimental treatments, or whether there is
any DEMO of reference group neglect. Reference
group neglect posits that participants chose to enter on
simple rounds and stay out on diﬃcult rounds not
because DEMO actually believed that they would score
any diﬀerently from others—but because they just were
not paying enough attention to others (Klar & Giladi,
1997; Kruger, 1999; Windschitl et al., 2003). If people
DEMO to consider the group and instead focus on
themselves when estimating their relative standing, we
should observe that beliefs about own performance are
weighted more heavily than are beliefs about others.
In what follows, we test this prediction in a pair of
regression analyses (in Table 2) DEMO comparative
judgments using performance by self and others. As
the remainder of the results section details, the substan-
tial majority of the eﬀect of diﬃculty can be accounted
for by greater regressiveness in estimates of others DEMO
of self.
Model 1 in Table 2 is the optimal model, DEMO
participants’ actual percentile ranks within each round
Estimated percentile rank
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
Table 2
Actual and perceived value of participants’ own DEMO and the scores of others for estimating percentile rank
Model 1 predicting actual percentile rank Model 2 predicting self-reported percentile rank
Independent variable
B
DEMO actual score .201*
Actual average score .201*
R2
.56*
* p < .001.
SE Independent variable
B
using their own scores and actual average DEMO for the
round as independent variables. The results show, not
surprisingly, that participants’ own actual scores and
average scores have B coeﬃcients that DEMO of similar size
but opposite signs. We compare this result with partici-
pants’ self-reported beliefs, using participants’ beliefs
about their own scores and beliefs about the average
score to predict their self-reported percentile rank. The
ﬁrst DEMO diﬀerence between these two analyses is
more noise in self-reported beliefs than in actual perfor-
mance, as shown by the smaller value of R2. It ought not
to be a shock that people’s estimates of their DEMO scores
and their percentile rankings are imperfect.
The second and more important diﬀerence is that par-
ticipants’ beliefs about their own scores were weighted
DEMO heavily than were their beliefs about others’ scores.
.005 Own estimated score .111*
.006 Estimated average score .077*
R2
.27*
To be precise, the weight attached to other (jBj = .077)
is 69% the size of the weight attached to self
(B = .111), and this diﬀerence is statistically signiﬁcant,
t (1088) = 3.4, p < .001. This shows evidence of refer-
ence group neglect but raises the DEMO question:
What proportion of our primary result (the eﬀect of DEMO
ﬁculty on entry rates) can be accounted for by diﬀeren-
tial DEMO and how much can be accounted for by
reference group neglect? DEMO order to answer this ques-
tion, we ﬁrst begin by assessing DEMO experimental treat-
ment’s eﬀect on entry decisions. We did this by
regressing entry rates on experimental treatment. The
independent variable in this regression was DEMO to 1
for simple-rank rounds, 0 for random-rank rounds,
and DEMO for diﬃcult-rank rounds. When we conduct this
analysis at the level of the round, the R2 value of this
regression shows that the experimental treatment
accounts for 28% of the variation in entry rates across
all DEMO, F (1, 154) = 59.67, p < .001. However, more
useful to our purposes is this analysis performed at the
level DEMO the individual. There are two major reasons to
expect R2 to be lower in the regression conducted at
the individual level: First, participants’ DEMO decisions
are partially driven by their actual relative performance,
which is uncorrelated with the experimental treatment;
second, idiosyncratic individual-level factors such as risk
preferences aﬀect entry decisions. At the individual level,
since the DEMO variable is dichotomous (entry
or not), a logistic regression is DEMO more appropriate
203
SE
.006
.008
statistical test.3 The Nagelkerke R2 value of this logistic
regression reveals that the experimental treatment
accounts for 7.9% DEMO the variation in individual entry
decisions, and is statistically signiﬁcant, v2 (1) = 65.67,
p < .001. What this means is DEMO 7.9% is the total size
of the eﬀect of diﬃculty on entry, and we must now
determine how much of it can be accounted for by dif-
ferential regression and how much of it cannot be.
DEMO order to assess the eﬀect of diﬀerential regressive-
ness, we next DEMO entry decisions on participants’
beliefs about their relative performance, as measured
DEMO the diﬀerence between their estimated absolute scores
for self and for others. Beliefs about relative performance
account for 24.4% of the variation in entry DEMO,
v2 (1) = 218.96, p < .0001. The mere DEMO that partici-
pants’ beliefs about relative performance are predictive
of their entry decisions is neither impressive nor interest-
ing—it would be surprising if they DEMO not. The interest-
ing question is whether these beliefs about relative
performance can account for the eﬀect of the experimen-
tal manipulations on entry DEMO In order to test for
such a mediation eﬀect, we conducted DEMO third regression
that included both experimental treatment and partici-
pants’ self-reports of relative performance. The resulting
Nagelkerke R2 value indicates that these two variables
DEMO account for 26.0% of the variation in entry
decisions. The inclusion of experimental treatment pro-
vides only a 6.7% increase in variation explained (over
the 24.4% using only the relative performance). However
the B coeﬃcient DEMO with experimental condition
remains signiﬁcant (B = .34, SE = .09, p < .001). The
signiﬁcance of experimental treatment suggests that
there is an eﬀect of diﬃculty that is distinct from partic-
ipants’ beliefs DEMO their relative standing. Of the total
7.9% of variation in entry decisions accounted for by
our experimental treatment, 1.6% (or 26%  24.4%) can-
not be accounted for by participants’ self-reported beliefs
3 For the DEMO of simplicity, we present logistic regression analyses in
which each subject DEMO each round serves as the unit of analysis (91
subjects · DEMO rounds = 1092 observations). The results we present are
not appreciably diﬀerent when the same analyses are conducted using a
hierarchical linear model DEMO treats subjects as random eﬀects and
accounts for the fact that experimental treatments are nested within
trial blocks which are in turn nested within DEMO sessions.
204
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
about their own performance relative to others. This
DEMO represents 20% of the variation due to the experi-
mental treatment that remains unexplained. Reference
group neglect is the most viable alternative explanation
for DEMO unexplained 20%, but the substantial majority
of the eﬀect of diﬃculty (80%) can be accounted for by
greater regressiveness in estimates of others than of self.
Discussion
The results of the ﬁrst experiment show that DEMO
dence regarding one’s competitive performance depends
on the type of competition. Contrary to prior evidence
( Camerer & Lovallo, 1999; Harris, 1996; DEMO &
Kunda, 1994), we show that controllable tasks do not
necessarily elicit more overconﬁdence than chance tasks.
In diﬃcult-rank rounds, people avoided entering. People
overestimated others’ performances, leading them to
stay out of the competition despite the fact that they
accurately forecast few other entrants. Thus, skill-based
tasks do not always elicit overconﬁdence and entry rates
depend in DEMO on how diﬃcult potential entrants see
the task.
Participants’ prior expectations regarding diﬃculty
play an important role in our theory, but the ﬁrst exper-
iment did not measure them. Experiment 2 was designed
to address this DEMO Furthermore, our theory
posits a fundamental role for information about perfor-
DEMO own and others’. Experiment 2 allows us
to observe the eﬀect of information on participants’
beliefs as they learn ﬁrst about their own performances
DEMO then about the performances of others.
Experiment 2: The eﬀect of DEMO on comparisons
Because our diﬀerential regression explanation
describes the mechanisms by which errors in entry
occur, it also oﬀers useful insights into which interven-
tions might be useful for reducing errors and which
interventions are unlikely DEMO be eﬀective. Experiment 2
tests these interventions. Participants were ﬁrst told that
they would be taking either a diﬃcult or simple quiz and
were DEMO asked to predict the outcome (Time 1). After
taking the DEMO (Time 2), participants were invited to
revise their answers to DEMO prior estimates of absolute
and relative scores. Our theory would predict that infor-
mation about one’s own performance provided at Time
2 would produce DEMO on easy tasks and WTA on diﬃ-
cult tasks. Finally, participants DEMO given full informa-
tion about how others scored on the same quiz they
took, and they were asked to report the same compara-
tive judgments (Time 3). Our theory would not predict
BTA and WTA eﬀects at Time 3, in the presence of
excellent information about others. Previous research
has shown that information about others can reduce
BTA eﬀects (Alicke, Klotz, Breitenbecher, Yurak, &
Vredenburg, 1995). Here, we test whether it can also
reduce WTA eﬀects.
Methods
Participants
We DEMO 128 undergraduate students at Carnegie
Mellon University by oﬀering them a base payment of
$2 plus from $0 to $8 on top of that. DEMO
sessions were advertised under the name ‘‘Games of
skill’’ with the following description: ‘‘Participants will
be playing a game in which they can earn money. How
much you get paid will depend on exactly how things DEMO
out.’’
Design
The experiment had a 2 (quiz diﬃculty: simple vs. dif-
ﬁcult) · (3) (time of wager: before quiz vs. after quiz vs.
after results) mixed design. Quiz diﬃculty was manipu-
lated between subjects and time served as a within-
subjects factor.
Procedure
Participants DEMO each given $4 and invited to bet as
much as they wanted on winning a trivia competition
against a randomly chosen opponent. Participants
were DEMO told that their opponents’ scores would
be selected at random from a group of 144 students
who had previously taken these same quizzes as DEMO part
of a diﬀerent study (reported in Moore & Kim, 2003,
Experiment 3). None of the 128 participants in the
present DEMO had participated in that prior study.
The test would consist of 10 items plus an 11th tie-
breaker question that virtually eliminated the chance
DEMO a tied score. Winning participants would double
the amount they bet; DEMO who lost would keep
only the un-wagered portion of their $4. Note that
the second and third time they bet, participants were
told that the most recent bet would be the one that
counted.
Participants in DEMO simple quiz condition were told
they would take a simple trivia quiz and be shown the
following example question and answer:
What is DEMO common name for the star inside our own
solar system?
Answer: The Sun
Participants in the diﬃcult quiz condition were told
they would be taking a diﬃcult trivia quiz and shown
the following example question DEMO answer:
What is the name of the closest star outside our solar
system?
Answer: Proxima Centauri
Participants were then asked how much they wanted
to bet. After they bet, participants were given a ques-
tionnaire that asked:
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
(1)‘‘How many of the 10 questions do you think you
will get right?’’
(2)‘‘How many of the 10 questions do you think your
opponent will get right?’’
(3)‘‘What percentage of the group will have scores
below yours? (If you DEMO your score will be the
very best, then put 100. If DEMO expect your score will
be exactly in the middle, put 50. DEMO you expect your
score will be the lowest, put 0.)’’
DEMO 1 and 2 were objective measures of abso-
lute evaluation for self and for opponent. Question 3,
like the bet, was a direct measure of beliefs about rel-
ative standing. After participants had answered all
DEMO questions, they were given an actual trivia test.
The questions from DEMO diﬃcult and simple quizzes
are listed in Appendix C. Participants were then told,
‘‘Now that you have taken the quiz, you may choose to
revise your answers to these questions. Please answer
all the questions, whether or not you put the same
answers as before.’’ Then participants DEMO asked
how much they wanted to bet and were asked
the same list of questions again. These were their
Time 2 responses.
After they DEMO answered all the questions at Time 2,
participants were then given truthful feedback about
the scores of the previous test-takers from whose ranks
DEMO randomly selected opponent would be drawn. For
example, those who took DEMO simple quiz were
informed that: ‘‘The average score is 8.71 out DEMO 10,
with a standard deviation of 1.1.’’ Those who took the
diﬃcult quiz were told: ‘‘The average score is 1.48 out
of 10, with a standard deviation of 1.01.’’ Participants
were also given a breakdown of the percentage of oth-
ers who got each of the 11 DEMO scores (from 0 to
10) on the quiz. After they had a chance to review this
information, participants were told, ‘‘Now that DEMO
have seen how others did, you may choose to revise your
DEMO to these questions. Please answer all the ques-
tions, whether or DEMO you put the same answers as
before.’’ Then participants were asked how much they
wanted to bet and were asked the same list of DEMO
questions again. These were their Time 3 responses.
The bet that was counted for computing payoﬀs was
this third and ﬁnal one.
Our diﬀerential DEMO explanation holds that
BTA eﬀects and WTA eﬀects result when people have
good information about themselves but lack informa-
tion about others, such as at Time 2 after taking the
quiz. At Time 3, after getting good information about
others, these eﬀects should go away. Time 1 beliefs are
useful for assessing participants’ priors, but are based
on so little information that our theory would not make
strong predictions regarding their beliefs. DEMO shall test
both our diﬀerential regression explanation and that of
reference group neglect.
205
Results and discussion
Manipulation check
As expected, the simple quiz resulted in higher scores
(M = 8.25 out of 10, SD DEMO 2.01) than did the diﬃcult
quiz (M = 1.54 out of 10, SD = 1.34), F (1, 126) =
490.39, p < .001, g2 = .80.
Participants’ predictions at Time 1
At Time 1, participants who had seen only an easy
sample question (DEMO were about to take—but had not
yet taken—the simple test), predicted that they would
score 7.22 (SD = 1.57) and that others DEMO score
6.41 (SD = 1.79) out of 10. Those who saw only a diﬃ-
cult sample question predicted that they would score
5.22 (SD = 1.90) and that others would score 4.92
(SD = DEMO). We analyzed these predictions using a 2
(diﬃculty) · (DEMO) (target: self vs. other) mixed ANOVA.
The results reveal a main eﬀect of target, F (1, 124) =
11.97, p = .001, g2 = .09, since people predicted that
they would DEMO better than would others. The diﬀerential
regression explanation cannot account for this eﬀect; the
results suggest some basic amount of self-enhancement.
The main eﬀect of diﬃculty is, of course, also signiﬁcant,
F (1, DEMO) = 46.13, p < .001, g2 = .27. The target DEMO diﬃ-
culty interaction eﬀect does not attain statistical signiﬁ-
cance, F (1, 124) = 2.77, p = .099, g2 = .02.
DEMO of diﬀerential regression at Time 2
At Time 2, the diﬀerential DEMO explanation
would hypothesize that people predict better relative
performance (BTA) on simple tasks and (WTA) worse
relative performance on diﬃcult tasks. This DEMO man-
ifest itself in a signiﬁcant interaction between diﬃculty
(simple vs. DEMO) and target (self vs. other). Indeed,
when we subjected estimates of absolute performance
to this 2 · (2) ANOVA, the diﬃculty · target interaction
emerges as signiﬁcant, F (1, 120) DEMO 20.77, p < .001,
g2 = .15.4 At Time 2, participants reported believing
that they scored better (M = 8.30, SD DEMO 1.49) than their
opponents (M = 7.83, SD = 1.28) on the simple quiz,
t (61) = 2.94, p = .005, g2 = .12. But they also reported
believing that they scored worse (M = 2.39, SD = 1.31)
than their opponents (M = 3.30, SD = 1.61) on the dif-
2
ﬁcult DEMO, t (59) = 3.48, p = .001, g = DEMO
Consistent with our theory, the increase in BTA and
WTA eﬀects DEMO Time 1 to Time 2 is largely attribut-
able to changes in beliefs about one’s own score. On
average, participants changed their estimates of their
own scores by 2.34 points (SD = 1.77). However, DEMO
4 Naturally, the main eﬀect of diﬃculty is also signiﬁcant, since
participants predict higher scores on the simple than on the diﬃcult
test, F (1, 120) = 606.16, p < .001, g2 = .84. The main within-subjects
eﬀect of target (self vs. opponent) is DEMO signiﬁcant, F (1, 120) = 1.40,
p = .24, g2 = .01.
206
70
65
60
55
50
45
40
35
30
Difficult
Simple
DEMO 1 Time 2 Time 3
Fig. 3. Participants’ estimated percentile rankings (DEMO of
others worse than them) in the two diﬃculty conditions at DEMO
points in time. Error bars show standard errors.
only changed their estimates of others’ scores by 1.92
points (SD = 1.76), and this diﬀerence is signiﬁcant by
paired-samples t-test, t (123) = 2.34, DEMO = .02. Further-
more, these changes mediate the diﬀerence on bets
DEMO diﬃculty conditions from Time 1 to Time 2.
We included these two change measures in a regression
predicting change in participants’ bets from Time DEMO to
Time 2, along with a dummy variable for diﬃculty.
Their DEMO renders diﬃculty non-signiﬁcant,
b = .02, p = .87. As DEMO theory would predict, changes
in self-estimates were a signiﬁcant predictor of DEMO
in bets, b = .47, p < .001. However, changes DEMO other-es-
timates were not signiﬁcant, b = .13, p = .16.
Tests of diﬀerential regression at Time 3
The diﬀerential regression explanation would DEMO pre-
dict BTA and WTA eﬀects at Time 3, when participants
DEMO good information not only about themselves but
about others. Indeed, the DEMO 2 · (2) ANOVA on abso-
lute evaluations at Time 3 does not produce a signiﬁcant
target · diﬃculty interaction, F (1, 124) = .02, p = .89.5
On the simple quiz, participants predicted similar scores
for themselves (M = 8.31, SD = 1.62) and for their
opponents (M = 8.14, SD = 1.37). DEMO on the diﬃ-
cult quiz, participants predicted similar scores for them-
DEMO (M = 2.08, SD = 1.19) and for their opponents
(M = 1.90, SD = .71). Fig. 3 shows participants’ self-re-
ported percentile ranks. Furthermore, as our theory pre-
dicts estimates of others’ scores changed more from
Time 2 to Time 3 than did estimates DEMO self. Estimates
of others changed by an average of 1 point
(DEMO = 1.18), whereas estimates of self only changed by
.4 points (SD = 1.05), and these two are signiﬁcantly
5 Naturally, DEMO main eﬀect of diﬃculty remains signiﬁcant, F (1,
124) DEMO 931.98, p < .001, g2 = .88. The main eﬀect of target remains
insigniﬁcant, F (1, 124) = 2.42, p = .07, g2 = .03.
D.A. Moore, D.M. Cain / Organizational Behavior DEMO Human Decision Processes 103 (2007) 197–213
diﬀerent from one another t (123) = 4.57, p < .001.
And consistent with our theory, the reduction in BTA
and WTA eﬀects on bets is mediated by changes in peo-
ple’s beliefs about others, b = .31, p DEMO .003, not the
self, b = .16, p = .07.
DEMO of reference group neglect
The reference group neglect hypothesis predicts that
direct comparisons (like estimates of percentile rank)
will show stronger BTA and WTA eﬀects than will indi-
rect comparisons (computed by subtracting absolute
estimates of others from self) which make others’ perfor-
mances salient. The standard test is to regress compara-
tive judgment on absolute evaluations of target DEMO
referent. Using this standard test, we replicate the result
that comparative DEMO is strongly associated with
self-evaluation but more weakly predicted by absolute
evaluation of others. We regressed percentile estimates
on predictions of point scores by DEMO and other for
responses at Time 1, before participants had taken DEMO
actual test. As Table 3 shows, the b coeﬃcient for abso-
DEMO self-evaluation is .86, p < .001, indicating that abso-
lute and relative self-assessment are strongly correlated.
The b coeﬃcient for other-evaluation, however, DEMO .53,
p < .001, is only 62% the magnitude of DEMO coeﬃcient for
self. This ﬁnding is consistent with reference group
neglect.
Note that this diﬀerential weighting changes as people
gain information. At Time 2, when participants had more
information about themselves, the weight put on other-es-
timates (.49) is only 53% the size of the weight put DEMO
self-estimates. But at Time 3, when people had better
information about DEMO, other-estimates (b = 1.69) car-
ry 92% the weight placed DEMO self-estimates (b = 1.84). If
reference group neglect aﬀects how DEMO bet, then we
ought to observe some eﬀect of test diﬃculty DEMO bets, over
and above the eﬀect of diﬀerential regressiveness on esti-
DEMO of self and others’ actual performances. We tested
this as we did in Experiment 1.6 The result was that 74%
of the eﬀect of DEMO on bets at Time 2 could be
explained by diﬀerential regression. However, this test
may claim too much credit for diﬀerential regression. As
the results in Table 3 highlight, better information about
self than others appears to produce both diﬀerential
regression and diﬀerential weighting. When they are con-
DEMO, this test will give all the credit to diﬀerential
regression over DEMO weighting.
At Time 3, the eﬀect of test diﬃculty on bets DEMO
dramatically: Diﬃculty accounts for only 3.4% of the
6 First, we began with the primary eﬀect of test diﬃculty on bets. At
Time DEMO, test diﬃculty only accounted for a statistically insigniﬁcant
1.9% of the DEMO in bets, as shown by the R2 value associated with a
DEMO predicting bets using a dummy variable for experimental
condition. At Time 2, however, diﬃculty accounts for 15% of the
variance in bets.
Percentile DEMO
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
207
Table 3
Experiment 2’s results for the three DEMO measures of comparative judgment at three points in time.
Time Self-reported comparative judgment Simple vs. Diﬃcult Regression results
Eﬀect size (g2)
b (DEMO)
b (Other)
1 Bet .02 .53***
1 Percentile rank DEMO .86
***
1 Indirect comparison .03 1.07
2 Bet .15*** .92***
2 Percentile rank .16*** .93
2 Indirect comparison .15*** 1.86
3 Bet .03* DEMO
3 Percentile rank <.001 1.84
3 Indirect comparison .00 3.10
***
DEMO
***
***

*
***
**
***

***
***

.27
.53
1.0
.48
.49
1.53
1.35
1.69
3.01
The third column shows DEMO eﬀect size of the diﬀerence between simple and diﬃcult conditions, and DEMO show the signiﬁcance of the t-test
comparing diﬃculty conditions. Regression results predicting indirect comparative judgment for the three diﬀerent measures of comparative
judgment appear DEMO the fourth and ﬁfth columns.
* p < .05.
** p < .01.
*** p < .001.
 Independent variables perfectly account for dependent DEMO
variance in bets. Our theory would not predict that test
diﬃculty would aﬀect comparative judgments when
people possess complete information regarding perfor-
mance by DEMO and others. Indeed, statistically speaking,
diﬀerential regressiveness accounts for only DEMO of this
small eﬀect. The remaining 97% is most likely attribut-
able to the egocentric overweighting of self-knowledge
over other-knowledge.
General discussion
The present DEMO oﬀer two primary ﬁndings. First,
the results of the ﬁrst experiment show that conﬁdence
regarding one’s competitive performance depends on
the ease of DEMO task. Contrary to prior evidence (Camer-
er & Lovallo, 1999; DEMO, 1996; Klein & Kunda, 1994),
we show that controllable tasks do not necessarily elicit
more overconﬁdence than chance tasks. People underes-
DEMO others’ performances on simple tasks but over-
estimated them on diﬃcult tasks, leading them to enter
with conﬁdence on simple rounds despite the fact that
they accurately forecast numerous other entrants. Yet
in diﬃcult-rank rounds, people decided not to enter:
They overestimated others’ performances, leading them
to stay out of the competition despite the fact that they
accurately forecast DEMO other entrants. Thus, skill based
tasks do not always elicit overconﬁdence; instead, conﬁ-
dence and entry rates depend in part on how diﬃcult
potential entrants see the task.
The second contribution of this paper is DEMO we
identify the cause for what appear to be myopic interper-
sonal comparisons, namely, better information about
one’s own performance than about the DEMO of
others. When a task is simpler than people expect it to
be, people’s estimates of others’ performances regress
downward and a majority will conclude that they are bet-
ter than others. When a task is DEMO diﬃcult than expect-
ed, estimates of others’ performances will regress upward
DEMO a majority will conclude that they are worse than oth-
ers. Experiment 2 shows that these WTA and BTA eﬀects
are strongest when people DEMO conﬁdent regarding their
own performances but unsure of the performances of oth-
ers. This may also explain why BTA and WTA eﬀects are
stronger DEMO people compare themselves to some vague
group than when they compare themselves to a speciﬁc,
known individual (see Hoorens & Buunk, 1993; Klar,
Medding, & Sarel, 1996; Klein & Weinstein, 1997; Perloﬀ
& Fetzer, 1986; Price, 2001; Windschitl et al., 2003). It
may also help explain why BTA eﬀects have been shown
DEMO be stronger for observable performances than for tasks
or traits where people only know about themselves and
cannot observe others’ performances directly (Dunning,
Meyerowitz, & Holzberg, 1989; Suls, Lemos, & Stewart,
2002). Given that diﬀerential regression explains most
of the eﬀect of diﬃculty DEMO entry and on bets in our exper-
iments, providing decision-makers with DEMO informa-
tion about the performance of others is likely to be the
most eﬀective way to eliminate this cause of myopic
comparisons.
Our studies DEMO manipulated the informa-
tion people had, making it impossible for us DEMO measure
diﬀerences in the degree to which people seek out infor-
mation about themselves and others (for other studies
that have measured this, DEMO Moore, Oesch, & Zietsma,
in press; Radzevick & Moore, 2006). However, our
results nevertheless show that people do not always use
information as they should. When making social compar-
isons, participants ought to have given the same weight to
information about themselves as to DEMO about
others. The fact that one’s competitors are doing poorly
on some task is just as important as the fact that one is
208
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
doing poorly. Consistent with the reference group neglect
DEMO, however, our participants’ self-reported
beliefs regarding their own performance were weighted
more heavily than their beliefs regarding opponents’ per-
formance. But this egocentrism DEMO is not the driving
factor behind WTA and BTA eﬀects and their conse-
quences for behavior. Diﬀerential weighting (reference
group neglect) accounts for DEMO small proportion of the
eﬀect of diﬃculty on entry rates and bets.
We should also note that, besides reference group
neglect, there are DEMO viable explanations for why peo-
ple’s judgments would appear to weight self more heavily
than others. For example, people easily conﬂate relative
and absolute evaluation on vague subjective measures
( Baron, 1997; Biernat, Manis, & Kobrynowicz, 1997).
The conﬂation error occurs when people answer the
DEMO, ‘‘How good are you relative to others?’’ as if
they DEMO answering the question ‘‘How good are
you?’’ (Klar & Giladi, 1999). Unlike diﬀerential weight-
ing due to reference group neglect, the conﬂation
explanation is exceedingly mundane: Vague measures
facilitate confusion between relative and absolute
evaluation (Burson & Klayman, 2005; Moore, 2005).
Conﬂation DEMO make comparative evaluations appear
to overweight the self because the person does not take
herself to be making a comparative evaluation.
Although we have DEMO to distinguish the diﬀer-
ential regression explanation from reference group
neglect, DEMO should also note their fundamental compati-
bility. Both are caused by the greater accessibility and
quality of information about the self than about others.
DEMO information about others leads people to make
more regressive estimates of others but also probably
leads to further underweight of those regressive estimates
( DEMO, Windschitl, Burrus, Fessel, & Chambers, 2006).
Managerial and DEMO implications
Our results have implications for understanding entre-
preneurial entry. While we do not take a stand on the
question of whether overall rates DEMO actual entrepreneurial
entry are excessive, we instead note that rates of DEMO vary
considerably between industries. Some industries, such as
retail clothing stores, restaurants, and bars, are marked
by persistently high rates of entry DEMO high rates of subse-
quent exit (US Small Business Administration, 2003).
Indeed, one of the stylized facts to emerge is that rates
of entry and exit are highly and positively correlated
( Dunne, Roberts, & Samuelson, 1988; Geroski, 1996;
Mata & Portugal, 1994). Diﬀerences in rates of entry are
not well accounted for by DEMO size of an industry, the prof-
itability of its ﬁrms, or barriers to entry (Geroski, 1996).
So, if new ﬁrms enter an industry because of above-nor-
mal proﬁts and exit an industry because DEMO below-normal
proﬁts, then one would instead expect entry and exit to DEMO
negatively correlated such that high failure rates meant
low entry rates, DEMO least in the short term. Yet the correla-
tion between entry and exit in any given year is around .7.
The results presented in DEMO paper suggest a possible
explanation. Perhaps industries that see persistent high
rates of entry are those that potential entrants view as
‘‘easy’’ or in DEMO they feel capable (Greico & Hogarth,
2004). Such industries DEMO then likely to see more intense
competition, lower proﬁts, and higher rates of failure.
Experiment 1 shows that this might occur in spite DEMO
entrants’ correct prediction that they will have lots of
competition in ‘‘simple’’ markets. Indeed, even when they
underestimate their own absolute abilities, entrants DEMO
underestimate the abilities of their competition even
more.
However, given that DEMO experimental participants
were not actual entrepreneurs with substantial quantities
of money at stake, we must be cautious about generaliz-
ing our results from errors made in the lab. Might actual
entrepreneurs learn to avoid the biases DEMO comparative
judgment shown by participants in the present experi-
ments? While DEMO is possible that experience may allow
actual entrepreneurs to learn to overcome these errors,
it is unclear how much experience is needed for DEMO
learning to take place. Participants in the market entry
game were students at a selective university and also
experienced 12 rounds with full feedback. DEMO this
experiment included too few trials for them to learn to
solve this problem. If this is the case, however, entrepre-
neurs are DEMO to make the same mistake. After all,
even the most experienced entrepreneurs rarely get the
opportunity to start more than a handful of DEMO
Furthermore, our experimental setup was more trans-
parent, assessment of the competition was clearer, and
the causes of success were more obvious than they are
likely to be for most entrepreneurs.
We must note that DEMO our theory and our results are
bounded. We do not claim that the diﬀerential regression
explanation (a cognitive explanation) accounts for all
BTA DEMO WTA eﬀects. Motivation and bias do inﬂuence
comparative interpersonal judgments in important ways
(Kunda, 1990). It is also clear that other cognitive DEMO
nations such as reference group neglect can account for
some biases in comparative judgment and in strategic
decision making, as shown in the present ﬁndings as well
as in other work (Klar, 2002; Moore, DEMO; Rose &
Windschitl, 2006; Windschitl et al., 2003). DEMO, the
errors showcased in this paper seem to be more about
DEMO having good information about one’s competition,
as opposed to merely ignoring the competition.
Appendix A. Formalization of the diﬀerential regression
explanation
In this DEMO, we attempt to formalize our theory,
ﬁrst in general terms, then with a speciﬁc example. Our
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
209
point in this appendix is not to suggest DEMO it is possible
to predict with certainty what individuals will believe—
given a multitude of constraints that may or may not be
realistic (we let our data speak to how real people
behave)—nor do we DEMO to provide a generalized
proof or justiﬁcation of the decision process we are sug-
gesting is at work. Here, we wish only to provide insight
on why WTA/BTA eﬀects might occur in groups of rea-
DEMO people.
Let us restrict our analysis to some speciﬁc group of n
individuals who all expect to take a test together. These
people, on average, expect that their performances will
be average, relative to the DEMO in the group. It is not
necessary that everyone believe that they are exactly
average, just that beliefs are balanced within the group.
In other words, for every person (or subset of people)
who DEMO that they are better than others (or better
than some individual) there is another person (or subset
of people) who believes that DEMO are worse than others
(or worse than some individual) to the same degree, and
vice versa.
Within the group, let S be DEMO average of all individ-
uals’ estimates of the absolute performance of self; let
O = the average of all individuals’ estimates of the
absolute performance of others. To be precise:
S
¼
ðs1
þ
s2
DEMO
n
... sn
Þ
where sn is the nth person’s self-estimate.
O
¼
ðo1
þ
o2
þ
n
... on
Þ
where on is DEMO nth person’s estimate of (the average of)
others’ scores (not including self).
S

O
¼
ðs1
þ
s2
þ
... DEMO Þðo1
n
þ
o2
þ
... on
Þ
and
ðs1 o1 þs2 o2 þ ... sn onÞ
S O ¼ n
S  O DEMO equal to the average comparative judgment of
self to others. When S  O is positive, it implies a
BTA eﬀect: On average, people believe that they are
better than others. When S  O DEMO negative, it implies
a WTA eﬀect: People believe they are worse than others.
At the outset, assume that S = O (on DEMO, people
expect that their performance will be average, relative
to the others).
Let people acquire additional information about
their own (past or anticipated) performance. To the
extent that this information about self is diﬀerent
than prior information, it will justify updating beliefs
about one’s own performance (away from the prior).
To the extent that information about the self is more
useful for estimating performance by self than others,
DEMO will lead to greater updating of S than of O. There-
fore, estimates of others will tend to be closer to the
prior than will estimates of self. In other words, O
regresses to the prior more than does S. We call this
rule ‘‘Rule O’’:
Rule DEMO: Since (whenever possible) O is more regres-
sive than S, O must be closer to the prior than is S.
(When S is maximally regressive, O is equally
regressive.)
There are three possible relationships between S and
the prior:
Case 1: S > prior, meaning that, on average, people
think that they did better than they expected to do; thus
S > O (or else a DEMO follows; if we assume
S > O to be false, i.e., if O PS, and (as given) S > prior,
DEMO O PS > prior, and O would be farther from the
DEMO than S, violating Rule O), and people will, on aver-
age, believe they performed better than others.
Case 2: S < DEMO, meaning that, on average, people
think that they did worse DEMO they expected to do; thus
S < O (ELSE: O DEMO S < prior, and O would be farther
from the prior DEMO S, violating Rule O), and people
will, on average, DEMO they performed worse than
others.
Case 3: S = prior, meaning that, on average, people
think that they did as they expected DEMO do; thus S = O
(ELSE: O > S = DEMO (or O < S = prior), and O would
be DEMO regressive than S, violating Rule O), and people
will, on average, believe they performed the same as
others.
Example: Suppose there DEMO three test takers, A, B, C,
each completing a DEMO that is scored out of 100. Suppose
that, prior to taking DEMO test, the average expected
score is 50. Suppose A’s actual score DEMO 90; B’s actual
score = 65; C’s actual score = 40. The average actual
test-score = 65. On average, the test takers did better
than expected (65 > 50), even though some did worse
than expected (e.g., C scored 40). Suppose, for the sake
of simplicity, that all three know exactly how well they
themselves did, but they know their sense of others is
imperfect. Granted, speciﬁc DEMO examples of esti-
mates will depend on individual test-takers and speciﬁc
tasks. With imperfect information, however, as in
Bayesian updating, people’s best estimates (in this case
of others) will tend to fall between actual DEMO and
Table 4
(Row A, Col B) = B’s prediction DEMO A’s score
Predictor
AB C
Target A
90
B 57.5 65
C45 45
70 70
57.5
40
210
their prior expectations. Table 4 depicts reasonable esti-
mates. In keeping DEMO the idea that estimates of self are
less regressive than estimates of others, suppose that
estimates of others are computed using a somewhat
arbitrary equal weighting of the prior and actual
score: (prior + actual)/2. Since the average expected
score is 50, assume that priors of all people’s scores by
all others = 50. So, for example, DEMO A scores 90, A will
predict that B scores (90 + 50)/2 = 70.
Next we calculate S and O for the group:
S ¼ðA’s estimate of self þB’s estimate of self
þC’s DEMO of selfÞ=3
¼ð90 þ 65 þ 40Þ=3
¼ 65
O ¼½A’sðaverageÞestimate of others
þB’sðaverageÞestimate of others
þC’sðaverageÞestimate of others=3
¼½1=2ð57:5 þ 45Þþ 1=2ð70 DEMO 45Þþ 1=2ð70 þ 57:5Þ=3
¼½51:25 þ 57:5 þ 63:75=3
¼ 57:5
Result: S (65) > O (57.5)DEMO On average, relying on
sensible rules of inference, but using systematically
imperfect information (and which is known to be
imperfect), people believe that they (S) are better than
others (O).
Note that C actually does (40) worse than expected
(50) and everyone DEMO it [but C knows it best; as
shown in the preceding DEMO, where (C, C) = 40, while
(C, A) = 45, and (C, B) = 45]. Nevertheless, on average,
the group thinks it did better than expected (actu-
al = 65 = estimated > expected = 50). Our theory holds
that, when this occurs, people will (on average) think
they did better than average. The S  O calculation
bears this out: S  O = 7.5 > 0.
The logic outlined above works just the DEMO if
each person’s estimate of his or her own score is
also imperfect and known to be imperfect, and
therefore it also regresses toward the prior. The only
key requirement is that estimates of others be
DEMO regressive than estimates of self, and Rule O
holds.
Appendix B. DEMO quizzes (four simple, four diﬃcult),
experiment 1
B.1. Simple DEMO 1
1. Who was the ﬁrst president of the United States?
2. How many inches are there in a foot?
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) DEMO
3. What does MTV stand for?
4. On what continent is the country of Egypt?
5. What is the most widely spoken DEMO in the US,
after English?
Tiebreaker: What is the DEMO of the Eiﬀel Tower
(in feet)?
B.2. Simple Test 2
1. What was the ﬁrst name of the Carnegie who founded
the DEMO Institute of Technology?
2. How many states are there in the United States?
3. In which month is Thanksgiving celebrated in the
DEMO States?
4. Harrisburg is the capital of what US state?
5. On what continent is the country of France
located?
Tiebreaker: How many ﬁlms did Alfred Hitchcock
direct?
B.3. Simple Test 3
DEMO Which American civil rights leader gave a famous
speech in which he repeated the lines, ‘‘I have a
dream...’’
2. What American director was behind the movies, A.I.,
E.T., Minority Report, Saving Private Ryan, and
Jurassic Park?
3. What is the name of Pittsburgh’s professional hockey
team?
4. What Pennsylvania city is know for being at DEMO
conﬂuence of the Allegheny and Monongahela
Rivers?
5. What country lies directly north of the United States?
Tiebreaker: How many member states are there in the
United Nations?
B.4. Simple Test 4
1. DEMO American became the ﬁrst person to ever win
the Tour de France 6 times?
2. Paris is the capital of what country?
DEMO In what large US city is the famous Times Square
located?
4. Where in the human body is the cerebellum located?
5. DEMO famous act of military aggression by Japan
happened on Dec 7, DEMO that brought the United
States into World War II?
Tiebreaker: DEMO many men signed the Declaration
of Independence?
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
B.5. Diﬃcult Test 1
1. In what European city DEMO you ﬁnd the famous
Tivoli Gardens?
2. Truth or Consequences is a city in what US state?
3. What company’s research and DEMO lab was
once known as the ‘‘House of Magic?’’
4. What is the largest moon of Saturn?
5. What African country lies DEMO south of Egypt?
Tiebreaker: In the 2000 US Census, what was the
population of Walla Walla, Washington?
B.6. Diﬃcult Test 2
1. Thomas Hooker is associated with the founding of
which of the DEMO American colonies?
2. Who is the only US president to have served two non-
consecutive terms in oﬃce?
3. In Quentin Tarrantino’s DEMO Dogs, what is the
alias of the man who is revealed DEMO be an undercover
police oﬃcer?
4. In The Odyssey, who DEMO the son of Ulysses
(Odysseus)?
5. Who was voted Time magazine’s Man of the Year in
1938?
Tiebreaker: What is the land area of Morocco (in
square kilometers)?
Appendix C
Trivia DEMO used in the simple and diﬃcult trivia quizzes (Experiment 2).
DEMO Diﬃcult
1. How many inches are there in a foot? Which DEMO has the largest eyes in the world?
2. What is the name of Pittsburgh’s professional How many verses are there in the Greek DEMO
hockey team? anthem?
3. Which species of whale grows the DEMO? What company produced the ﬁrst color television
sold to the public?DEMO
4. Who is the President of the United States? How many DEMO are there in the White
House (the residence of the US DEMO)?
5. Harrisburg is the capital of what US state? Which monarch ruled Great Britain the longest?
6. What was the ﬁrst DEMO of the Carnegie who founded The word ‘‘planet’’ comes from the Greek word
the Carnegie Institute of Technology? meaning what?
7. How many states are there in the United States? What is the name of the traditional currency of
Italy (before the Euro)?
8. What DEMO is Afghanistan in? What is Avogadro’s number?
9. What country DEMO an entire continent? Who played Dorothy in ‘‘The Wizard of Oz’’?DEMO
10. Paris is the capital of what country? Who wrote the DEMO ‘‘The Yeoman
of the Guard’’?
Tiebreaker question: How many people DEMO in Pennsylvania?
Answers—Simple: (1) 12 (2) Penguins (3) Blue (4) George W. Bush (5) Pennsylvania (6) Andrew (7) 50 (8) Asia (9) Australia (10) France. DEMO:
(1) Giant squid (2) 158 (3) RCA (DEMO) 32 (5) Queen Victoria (6) wanderer (7) Lira (8) 6.02 · 1023(9) Judy Garland (10) Gilbert and DEMO Tiebreaker:
12,281,054.
211
B.7. Diﬃcult Test 3
1. Blues musician Huddie Ledbetter is better known by
what name?
2. What DEMO and model of car holds the record
for being the most widely produced car in the
world?
3. Laudanum is a form of DEMO drug?
4. Who was the president of Indonesia, as of DEMO
2002?
5. What is the capital of Nepal?
Tiebreaker: DEMO how many pieces of art
did Pablo Picasso create during his lifetime?
B.8. Diﬃcult Test 4
1. Which team won the ﬁrst NBA DEMO Lottery?
2. The Nobel Prizes are awarded in what two
cities?
3. Dr. Faustus is best known for selling what item?
DEMO What two South American countries are land-
locked?
5. Pro football announcer John Madden coached which
team to a Super Bowl victory?
DEMO: How many consecutive weeks did the
Pink Floyd album Dark Side DEMO the Moon spend on
the billboard music charts?
212
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
Appendix D. Supplementary data
Supplementary data associated with DEMO article can
be found, in the online version, at doi:10.1016/j.obhdp.
2006.09.002.
References
Alicke, M. D., Klotz, M. L., Breitenbecher, D. L., Yurak, T. J., &
Vredenburg, D. S. (DEMO). Personal contact, individuation, and the
better-than-average eﬀect. Journal of Personality and Social Psy-
chology, 68(5), 804–825.
Baron, J. (1997). Confusion of relative and absolute risk in valuation.
Journal of Risk DEMO Uncertainty, 14, 301–309.
Biernat, M., Manis, M., & Kobrynowicz, D. (1997). Simultaneous
assimilation and contrast eﬀects in judgments of DEMO and others.
Journal of Personality and Social Psychology, 73(2), DEMO
Burson, K. A., & Klayman, J. (2005). Judgments of performance: The
relative, the absolute, and the in-between. Ann Arbor, DEMO
manuscript.
Burson, K. A., Larrick, R. P., & Klayman, DEMO (2006). Skilled or
unskilled, but still unaware of it: DEMO perceptions of diﬃculty
drive miscalibration in relative comparisons. Journal of Personality
and Social Psychology, 90(1), 60–77.
Camerer, C. F., & Lovallo, D. (1999). Overconﬁdence and excess
entry: An experimental approach. American Economic Review,
89(1), 306–318.
Chambers, J. R., & DEMO, P. D. (2004). Biases in social
comparative judgments: The DEMO of nonmotivational factors in
above-average and comparative-optimism eﬀects. Psychological
Bulletin, 130(DEMO).
College Board. (1976–1977). Student descriptive questionnaire.
Princeton, NJ: DEMO Testing Service.
Cooper, A. C., Woo, C. Y., & Dunkelberg, W. C. (1988). Entrepre-
neurs’ perceived chances for success. Journal DEMO Business Venturing,
3(2), 97–109.
Dunne, T., Roberts, DEMO J., & Samuelson, L. (1988). Patterns of ﬁrm
entry DEMO exit in US manufacturing industries. Rand Journal of
Economics, 19(4), 495–515.
Dunning, D., Heath, C., & Suls, J. M. (2004). Flawed self-assessment:
Implications for health, education, and business. DEMO
Science in the Public Interest, 5(3), 69–106.
Dunning, D., Meyerowitz, J. A., & Holzberg, A. D. (1989). Ambiguity
and self-evaluation: The role of idiosyncratic trait deﬁnitions in
self-serving assessments of ability. Journal of Personality and Social
Psychology, 57(6), 1082–1090.
Erev, I., Wallsten, T. S., & Budescu, D. V. (1994)DEMO Simultaneous over-
and underconﬁdence: The role of error in judgment processes.
DEMO Review, 101(3), 519–527.
Fischhoﬀ, B., & De Bruin, Bruine (1999). Fifty-ﬁfty = 50%?. Journal of
Behavioral Decision Making 12(2), 149–163.
Fox, C. R., & Rottenstreich, Y. (DEMO). Partition priming in judgment
under uncertainty. Psychological Science, 14(3), 195–200.
Geroski, P. A. (1996). What do we know about entry? International
Journal of Industrial Organization, 13(4), 421–441.
Greico, D., & Hogarth, R. M. (2004). Excess entry, ambiguity DEMO,
and competence: An experimental investigation, unpublished
manuscript.
Harris, P. (1996). Suﬃcient grounds for optimism? The relationship
between perceived controllability and optimistic bias. Journal of
Social and Clinical Psychology, 15(1), 9–52.
Hayward, M. L. A., & Hambrick, D. C. (1997). DEMO the
premiums paid for large acquisitions: Evidence of CEO hubris.
Administrative DEMO Quarterly, 42, 103–127.
Hoelzl, E., & Rustichini, A. (2005). Overconﬁdent: Do you put your
money on it? Economic Journal, 115(503), 305–318.
Hoorens, V., & Buunk, B. P. (DEMO). Social comparison of health
risks: Locus of control, the person-positivity bias, and unreal-
istic optimism. Journal of Applied Social Psychology, 23(DEMO),
291–302.
Juslin, P., Winman, A., & Olsson, H. (2000). Naive empiricism and
dogmatism in conﬁdence research: A critical DEMO of the
hard-easy eﬀect. Psychological Review, 107(2), 384–396.
Klar, Y. (2002). Way beyond compare: Nonselective superiority and
inferiority biases DEMO judging randomly assigned group members
relative to their peers. Journal of Experimental Social Psychology,
38(4), 331–351.
Klar, Y., & Giladi, E. E. (1997). No one in my group can be below the
group’s average: A robust positivity bias in favor of anonymous
peers. Journal of Personality and Social Psychology, 73(5), 885–901.
Klar, DEMO, & Giladi, E. E. (1999). Are most people happier DEMO their
peers, or are they just happy? Personality and Social Psychology
Bulletin, 25(5), 585–594.
Klar, Y., Medding, A., & Sarel, D. (1996). Nonunique invulnerability:
Singular versus distributional probabilities DEMO unrealistic opti-
mism in comparative risk judgments. Organizational Behavior and
Human Decision Processes, 67(2), 229–245.
Klein, W. M. P., & Kunda, Z. (1994). Exaggerated self-assessments
and the preference for controllable risks. DEMO Behavior
and Human Decision Processes, 59(3), 410–427.
Klein, W. M. P., & Weinstein, N. D. (1997). Social comparison and
unrealistic optimism about personal risk. In B. P. Buunk & F. X.
DEMO (Eds.), Health, coping, and well-being: Perspectives from
social comparison theory (pp. 25–61). Mahwah, NJ: Lawrence
Erlbaum Associates.
Kruger, DEMO (1999). Lake Wobegon be gone! The ‘‘below-average
eﬀect’’ and the DEMO nature of comparative ability judg-
ments. Journal of Personality and Social Psychology, 77(2),
221–232.
Kruger, J., & Burrus, J. (DEMO). Egocentrism and focalism in unrealistic
optimism (and pessimism). Journal DEMO Experimental Social Psy-
chology, 40(3), 332–340.
Kruger, J., DEMO, P. D., Burrus, J., Fessel, F., & Chambers, DEMO R.
(2006). The rational side of egocentrism in social comparisons,DEMO
unpublished manuscript.
Kunda, Z. (1990). The case for motivated reasoning. Psychological
Bulletin, 108(3), 480–498.
Lichtenstein, S., Fischhoﬀ, B., & Phillips, L. D. (1982). Calibration of
probabilities: The state of the art in 1980. In D. Kahneman, P.
Slovic, & DEMO Tversky (Eds.), Judgment under uncertainty: Heuristics
and biases (pp. DEMO). Cambridge, England: Cambridge Uni-
versity Press.
Malmendier, U., & Tate, G. (2005). CEO overconﬁdence and
corporate investment. Journal of DEMO, (60), 6.
Mata, J., & Portugal, P. (1994). Life duration of new ﬁrms. Journal of
Industrial Economics, 42(3), 227–246.
Moore, D. A. (2004). Myopic prediction, self-destructive secrecy, and
the unexpected beneﬁts of revealing ﬁnal deadlines in negotiation.
Organizational Behavior and Human Decision Processes, 94(2),
125–139.
Moore, D. A. (2005). When good = better than average. Pittsburgh:
Tepper Working Paper 2004-E38.
Moore, D. A., & Kim, T. G. (2003)DEMO Myopic social prediction and the
solo comparison eﬀect. Journal of Personality and Social Psychol-
ogy, 85(6), 1121–1135.
Moore, D. A., Oesch, J. M., & Zietsma, C. What competition? Myopic
self-focus in DEMO entry decisions. Organization Science, in press.
Myers, D. G. (1998)DEMO Social psychology (5th ed.). New York: McGraw-
Hill.
Odean, DEMO (1998). Volume, volatility, price, and proﬁt when all traders
are above average. Journal of Finance, 53(6), 1887–1934.
D.A. Moore, D.M. Cain / Organizational Behavior and Human Decision Processes 103 (2007) 197–213
213
Perloﬀ, L. S., & Fetzer, B. K. (1986). Self-other judgments and
perceived vulnerability to victimization. Journal of Personality and
Social Psychology, 50(3), 502–510.
Price, P. C. (2001). A group size eﬀect on personal risk judgments.
Memory and Cognition, 29, 578–586.
Radzevick, J. R., & Moore, D. A. (2006). For the love of the game?
Betting, prediction, and DEMO bias in athletic competition.
Pittsburgh: Tepper Working Paper 2005-E7.
Rose, J. P., & Windschitl, P. D. (2006). How egocentric optimism
change in response to feedback in repeated competitions, unpub-
lished manuscript.
Suls, DEMO M., Lemos, K., & Stewart, H. L. (2002). DEMO, construal,
and comparisons with the self, friends, and peers. DEMO of
Personality and Social Psychology, 82(2), 252–261.
Svenson, O. (1981). Are we less risky and more skillful than our fellow
drivers? Acta Psychologica, 47, 143–151.
US Small Business Administration. (2003)DEMO Longitudinal Establish-
ment and Enterprise Microdata. Washington, DC: Oﬃce of
Advocacy (202-205-6530).
Weinstein, N. D. (1980). Unrealistic optimism about future life events.
Journal of Personality and Social Psychology, 39(5), 806–820.
Windschitl, P. D., Kruger, J., & Simms, E. (2003)DEMO The inﬂuence of
egocentrism and focalism on people’s optimism in competitions:
When what aﬀects us equally aﬀects me more. Journal of
Personality and DEMO Psychology, 85(3), 389–408.
Zajac, E. J., & Bazerman, M. H. (1991). Blind spots in industry and
competitor analysis: DEMO of interﬁrm (mis)perceptions for
strategic decisions. Academy of Management Review, 16(1), 37–56.{1g42fwefx}