<-----Page 0----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002. 53:491–517
c 2002 by Annual Reviews. All rights reserved
Copyright °

RATIONALITY
Eldar Shafir and Robyn A. LeBoeuf

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

Department of Psychology, Princeton University, Princeton, New Jersey 08544;
e-mail: Shafir@princeton.edu, RLeBoeuf@princeton.edu

Key Words judgment, choice, decision making, normative theories, cognition
■ Abstract This chapter reviews selected findings in research on reasoning, judgment, and choice and considers the systematic ways in which people violate basic
requirements of the corresponding normative analyses. Recent objections to the empirical findings are then considered; these objections question the findings’ relevance
to assumptions about rationality. These objections address the adequacy of the tasks
used in the aforementioned research and the appropriateness of the critical interpretation of participants’ responses, as well as the justifiability of some of the theoretical
assumptions made by experimenters. The objections are each found not to seriously
impinge on the general conclusion that people often violate tenets of rationality in
inadvisable ways. In the process, relevant psychological constructs, ranging from cognitive ability and need for cognition, to dual process theories and the role of incentives,
are discussed. It is proposed that the rationality critique is compelling and rightfully
gaining influence in the social sciences in general.

CONTENTS
INTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
VIOLATIONS OF NORMATIVE PRINCIPLES . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Judgment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Variants of Utility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Emotion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Dual Process Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
THE OBJECTIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Trivializations of the Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Misinterpretations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Inappropriate Tests of Rationality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
SUMMARY AND CONCLUSION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

0084-6570/02/0201-0491$14.00

492
493
493
494
495
498
498
499
500
501
503
507
509

491

<-----Page 1----->30 Nov 2001

11:29

492

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

INTRODUCTION
Assumptions about rationality occupy a central role in practically all fields of inquiry in which human behavior matters. Human rationality has been celebrated
as one of the species’ greatest achievements and is often considered a trait that
distinguishes humans from other animals. Indeed, the rationality assumption has
come to constitute perhaps the most common and pivotal assumption underlying
theoretical accounts of human behavior in various disciplines. In light of the rationality assumption’s dominant role and its comforting view of human competence,
it is not surprising that modern critiques of the rationality assumption have met
with heated resistance.
The status of the rationality assumption is ultimately an empirical question (but
see Cohen 1981, Dennett 1987). Consequently, the field of experimental psychology has been at the forefront of the modern rationality debate. Subtle distinctions
of meaning remain outside the purview of this chapter, yet it is worth mentioning
that the philosophical literature distinguishes between various senses of rationality (Harman 1995). In this chapter we review recent experimental and conceptual
work that critiques the rationality assumption. We then consider recent work that
has questioned the relevance or appropriateness of such critiques and conclude
that the rationality assumption continues to appear misguided. We propose that its
continued replacement with a behaviorally more sophisticated view promises to
contribute significantly to the success of social science theories.
It is notable that the predominant theories of rationality are predicated on notions of consistency, not of substance. A person is entitled to a wide range of
opinions, beliefs, and preferences; what is important is for these to cohere in a
normatively defensible fashion. Thus, the term “rational” conveys a more technical meaning than its general dictionary significance of “agreeable to reason; of
sound mind; sane.” These latter terms may be applicable to people whose behavior
is not well captured by normative accounts of rationality (cf. Simon 1978, Stein
1996). Conversely, one can imagine a person (say, a member of some bizarre cult)
who satisfies all the requirements of consistency yet holds beliefs that in common
parlance would be considered highly irrational.
Despite its focus on consistency, the rationality assumption remains, at least to
some degree, intuitive rather than purely technical in nature. After all, computational (as well as time, attention, memory, and similar) limitations necessitate some
failures of ideal rationality. Apart from those theories that are explicitly about idealized rationality rather than about possible human achievement (see, e.g., Stalnaker
1984, Gardenfors 1988), the requirements of rationality typically imposed are those
that we expect people, at least to a first approximation, to be able to fulfill. It turns
out that a variety of observed failures are not attributable to computational overload
but, rather, to the specific ways in which people process information and make decisions. In those instances, whether people are considered to have violated rationality
seems largely to depend on whether we had expected them to be able to perform
the task in conformity with normative criteria (Bell et al. 1988, Shafir 1993).

<-----Page 2----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY

493

For many years the predominant view in the social sciences had been that the
rationality assumption is an adequate approximation for modeling and predicting
human behavior. Normative theories pertinent to distinct tasks such as logical reasoning (Glymour 1992), probabilistic thinking (Ross 1997), and decision making
(Edwards 1961, Luce & Raiffa 1957), served as candidate paradigms of human
rationality. But then, motivated by Simon’s (1955) notions of bounded rationality
and later by Kahneman and Tversky’s heuristics and biases program (Kahneman
& Tversky 1972, 1973; Tversky & Kahneman 1973, 1974, 1983), the emphasis
shifted toward documenting the persistent inadequacy of the rationality assumption. Common to most accounts of rationality is the notion that a person is largely
entitled to his or her own views or preferences, but that these should cohere, should
adhere to basic rules of logic and probability theory, and should not be formed or
changed based on immaterial factors related to, for example, mood, context, or
mode of presentation. Many studies from the past three decades, however, have
documented numerous ways in which judgments and decisions do not cohere, do
not follow basic principles of logic and probability, and depend systematically on
just such irrelevant factors. People use intuitive strategies and simple heuristics
that are reasonably effective some of the time but that also produce biases and
lead to systematic error. In what follows, we briefly review some of the empirical
work, mostly in the areas of judgment and choice. We then consider some recent
critiques that have arisen concerning these studies’ relevance and implications for
the rationality assumption. Extensive reviews of the relevant findings can be found
in Baron (1994), Camerer (1995), Goldstein & Hogarth (1997), Hastie (2001),
Kahneman & Tversky (2000), Mellers et al. (1998), Shafir & Tversky (1995), and
Yates (1990).

VIOLATIONS OF NORMATIVE PRINCIPLES
Reasoning
Some of the earliest violations of normative principles documented by experimental psychologists involved systematic deviations from simple principles of logical
reasoning (e.g., Wason 1966; see Gilhooly 1988, Oakhill & Garnham 1993 for
reviews). Recent contributions to this research have found certain connectives easier to reason about than others; conjunctions (e.g., “and”) are easiest, followed
by conditionals (e.g., “if . . . then”), exclusive disjunctions (e.g., “A or B but not
both”), and finally, inclusive disjunctions (e.g., “A or B or both”), which cause
participants the most difficulty (Johnson-Laird et al. 1992, 2000). Research has
also been motivated by the quest to determine the mechanisms that best account
for the observed reasoning competencies and difficulties. Briefly, one view is that
people reason by applying abstract reasoning rules to a variety of reasoning tasks
(Braine & O’Brien 1998, Rips 1994), whereas the opposing view holds that reasoning is based upon mental models that are constructed to represent the situation

<-----Page 3----->30 Nov 2001

11:29

494

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

at hand (Johnson-Laird 1983, Johnson-Laird & Byrne 1991). All told, research
on reasoning has continued to document persistent and systematic shortcomings
in reasoning abilities (see Manktelow 1999, Johnson-Laird 1999 for extensive
reviews).

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

Judgment
Early work within the heuristics and biases paradigm concerned people’s intuitive probability judgments (Kahneman et al. 1982). The general finding has been
that in settings where the relevance of simple probabilistic rules is made transparent, subjects often reveal appropriate statistical intuitions (see, e.g., Tversky &
Kahneman 1986). However, in slightly richer contexts, where the applicability of
the normative rules is less immediately apparent, people tend to rely on intuitive
heuristics that often produce nonnormative judgments.
One such heuristic is the representativeness heuristic, or the tendency to evaluate
the likelihood that a target belongs to a certain class based upon the degree to which
the target resembles the prototypic class member. Whereas such a strategy may
often be reasonably effective, sample sizes, prior odds, and the basic axioms of
probability, all of which are highly relevant to likelihood, do not impinge on how
representative an observation appears and thus tend to be neglected (Kahneman
& Tversky 1972, 1973; Tversky & Kahneman 1983). In a well-known example,
respondents are presented with a personality description of a woman, Linda, who
is highly similar to a prototypical feminist, and are asked to rate the probability
that several statements about Linda are true. The majority of subjects rank the
conjunct, “Linda is a bank teller” as less probable than the conjunction, “Linda
is a bank teller and is active in the feminist movement” (Tversky & Kahneman
1983), thereby disregarding the fundamental conjunction rule of probability in
favor of a judgment based on a highly representative, yet statistically uninformative,
description. The notion that people focus on the strength of the evidence with
insufficient regard for its weight explains various systematic judgmental biases,
including the failure to appreciate regression phenomena and the fact that people
are generally overconfident (when evidence is remarkable but reliability is low)
and occasionally underconfident (when the evidence is unremarkable but highly
reliable) (Griffin & Tversky 1992).
More generally, probability judgments will have gone awry when they are
not “well calibrated.” Consider a set of propositions, each of which a person
judges to be true with a probability of 0.90. If right about 90% of these, the
person is said to be well calibrated. If right about fewer or more than 90%, the
person is said to be overconfident or underconfident, respectively. People typically
tend to be overconfident, whether judging the likelihood that their answers to
general-knowledge questions are correct (e.g., Fischhoff et al. 1977, Griffin &
Buehler 1999, Lichtenstein & Fischhoff 1977; but see Dawes & Mulford 1996) or
estimating the accuracy of predictions about future events or behaviors (Dunning
et al. 1990, Pulford & Colman 1996, Vallone et al. 1990). In a typically regressive
fashion, overconfidence is most pronounced for difficult tasks, whereas easy tasks

<-----Page 4----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY

495

occasionally yield underconfidence, in what is known as the “hard-easy effect”
(e.g., Lichtenstein & Fischhoff 1977).
Judgments often rely on sets of attributes—for example, a prospective applicant’s exam scores, relevant experience, and letters of recommendation—that need
to be combined into a single rating, for instance, likelihood of success at the job.
Because people have poor insight into how much to weight each attribute, they are
typically quite poor at combining these attributes to yield a final judgment. Much
research has been devoted to the shortcomings of intuitive (“clinical”) judgment,
and to the greater predictive success obtained by linear models of the human judge
(Dawes 1979, Dawes et al. 1989, Swets et al. 2000). In fact, it has been repeatedly shown that a linear combination of attributes, based, for example, on a judge’s
past ratings, does better in predicting future (as well as previous) instances than the
judge on whom these ratings are based (see, e.g., Swets et al. 2000). Essentially, this
“bootstrapping” method takes advantage of the person’s insights captured across
numerous ratings and improves on any single rating wherein improper weightings
of attributes may intrude. Moreover, because attributes are often highly correlated
and systematically misperceived, even a unit assignment of weights, not properly
devised for the person, can often still outperform the human judge (Dawes 1988).
Related methods have extracted from a person’s judgments a coherent core that
is maximally consistent with those judgments and at the same time comes closer
to the observed likelihoods than do the original (incoherent) judgments (Osherson
et al. 1994, Pearl 1988).
One recent attempt to model subjective probability judgments, known as support theory (Tversky & Koehler 1994), has focused on the notion that the judged
probability that some hypothesis is true will be based on the perceived strength
of evidence, or support, for the hypothesis relative to the perceived support for
alternate hypotheses. According to support theory, subjective probability is associated not with events but with descriptions of events. Unpacking the description
of an event into disjoint components generally increases its support and, hence, its
perceived likelihood. As a result, different descriptions of the same event can give
rise to different judgments (Brenner & Koehler 1999, Rottenstreich & Tversky
1997, Tversky & Koehler 1994).
As already noted, people’s judgments often violate basic normative rules, yet at
the same time, people can exhibit sensitivity to and appreciation for the normative
principles. This coexistence of fallible intuitions with an underlying appreciation
for normative judgment yields a subtle picture of probabilistic reasoning, along
with interesting possibilities for a prescriptive approach. In this vein, a large literature on expert systems has attempted to provide analyses and applications (e.g.,
Hammond et al. 1999, von Winterfeld & Edwards 1986).

Choice
Normative analyses of choice posit consistent preferences that depend on the subjective utilities of anticipated outcomes weighted by their probabilities. To be
normative, preferences must satisfy description and procedure invariance, such

<-----Page 5----->30 Nov 2001

11:29

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

496

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

that logically equivalent representations of a decision problem as well as logically
equivalent methods of elicitation yield the same preferences. Recent studies of
decision making have captured a number of psychological principles that characterize the decision making process and conflict with these most basic normative
requirements. In general, people tend not to have clear and well-ordered preferences: Instead, preferences are actually constructed, not merely revealed, in the
elicitation process, and the construction of preference is heavily influenced by the
nature and context of the decision.
A number of theories have been proposed to account for the behavioral findings in choice (e.g., Bell 1982, Edwards 1962, Fellner 1965, Luce & Fishburn
1991, Mellers et al. 1997, Shafir et al. 1993a, Tversky 1972), the most influential of which has been prospect theory (Kahneman & Tversky 1979, Tversky &
Kahneman 1992). Prospect theory posits that probabilities have nonlinear impacts
on decisions (Gonzalez & Wu 1999, Kahneman & Tversky 1979, Prelec 2000,
Tversky & Wakker 1995) and proposes an S-shaped value function with three important properties. First, the evaluation of outcomes is defined on gains and losses
rather than total wealth. Second, the value function is steeper for losses than for
gains: Thus, a loss of $X is more aversive than a gain of $X is attractive. This is
commonly referred to as loss aversion (Tversky & Kahneman 1991); one consequence of loss aversion is the “endowment effect,” wherein the mere possession
of a good can lead to higher valuation of it than if it were not in one’s possession
(Kahneman et al. 1990). Loss aversion also creates a general reluctance to trade
or depart from the status quo, because the disadvantages of departing from it loom
larger than the advantages of the alternatives (Samuelson & Zeckhauser 1988).
Finally, owing to diminishing sensitivity, prospect theory’s value function is concave for gains and convex for losses, yielding risk-averse attitudes in the domain
of gains and risk seeking in the domain of losses (except for very low probabilities,
in which case these can reverse).
The above attitudes may seem compelling and unobjectionable, yet their combination yields normatively problematic consequences. For example, because prospects can often be framed either as gains or as losses relative to some reference
point, and because risk attitudes vary depending upon whether gains or losses are
at stake, alternative frames may lead to discrepant preferences with respect to the
same final outcome (Tversky & Kahneman 1981, 1986). In one example (Tversky
& Kahneman 1986), respondents are asked to assume themselves $300 richer and
are then offered a choice between a sure gain of $100 or an equal chance to win
$200 or nothing. Alternatively, they are asked to assume themselves $500 richer,
and offered a choice between a sure loss of $100 and an equal chance to lose
$200 or nothing. Although the two problems are essentially identical with respect
to the final outcome, most subjects who choose between gains predictably prefer
the $100 for sure, whereas most subjects who choose between losses prefer the
probabilistic $200 gamble. This is known as a “framing effect”: It occurs when
alternative frames of essentially the same decision problem lead to predictably different choices. Framing effects have been replicated across a variety of domains in

<-----Page 6----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY

497

dozens of studies (for reviews, see Kühberger 1998, Levin et al. 1998; RA LeBoeuf
& E Shafir, in preparation).
Influential research has also focused on the relative weighting of options’ different dimensions. Because people are often uncertain about the relative importance
of various dimensions, the weights assigned to those dimensions are often influenced by relatively immaterial changes in the task, the description, and the nature
of the options under consideration. For example, the weight given an attribute
tends to be enhanced by its compatibility with a required response. Thus, a gamble’s potential payoff is weighted more heavily in a pricing task (in which both
the price and the payoff are expressed in the same—monetary—units) than in
choice (see Shafir 1993, 1995; Slovic et al. 1990). Consistent with this is the preference reversal phenomenon (Slovic & Lichtenstein 1983, Tversky et al. 1990),
wherein subjects choose a lottery offering a greater chance to win over another
offering a higher payoff, but then price the latter higher than the former. Preference reversals have been replicated among professional gamblers in a Las Vegas
casino (Lichtenstein & Slovic 1973) and in a context offering the equivalent of
a month’s salary to respondents in the Peoples’ Republic of China (Kachelmeier
& Shehata 1992). Preference reversals have also been documented in numerous
studies involving nonmonetary options, including choice between highway safety
programs, job candidates, and interventions intended to address environmental
problems (Kahneman & Ritov 1994, Slovic et al. 1990, Tversky et al. 1988).
A related choice pattern, referred to as an evaluability effect, emerges when
attributes are difficult to evaluate in isolation (Hsee 1996). In one example, subjects
are presented with two second-hand music dictionaries, one with 20,000 entries
and a damaged cover, the other with 10,000 entries and a cover that is like new.
When evaluating the dictionaries separately, respondents, who have little notion
of how many entries to expect, are willing to pay more for the dictionary with the
new rather than the torn cover. When these dictionaries are evaluated concurrently,
however, most people prefer the dictionary with more entries, despite its inferior
cover (Hsee 1996, Hsee et al. 1999).
In further violation of standard value maximization, decisional conflict can lead
to a greater tendency to search for alternatives when better options are available but
the decision is hard than when relatively inferior options are present and the decision is easy (Tversky & Shafir 1992a). In addition to the conflict or difficulty that
characterizes a decision (March 1978), choices have been shown to be influenced,
often nonnormatively, by the regret anticipated in cases where another option could
have been better (Bell 1982), the reasons used to justify one choice over another
(Shafir et al. 1993b, Tetlock 1992), the influence exerted by costs already suffered
(Arkes & Blumer 1985, Gourville & Soman 1998), and the effects of temporal
ordering on future decisions (Loewenstein & Elster 1992, Loewenstein & Prelec
1993). The methodology used to document the various effects in decision making
research is quite rich, including process-tracing methods, such as verbal protocols
(Ericsson & Simon 1984), information-acquisition sequences (Payne et al. 1993),
and eye-movement data (Russo & Dosher 1983).

<-----Page 7----->30 Nov 2001

11:29

498

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

Variants of Utility
Whereas discussions generally focus on the descriptive adequacy of utility maximization, recent research has explored the precise nature of utility. Kahneman
(1994) questions whether people maximize the expected experienced utility of
a decision, that is, the hedonic experience that the decision will bring, as opposed to merely the decision utility, that is, the utility perceived at the moment of
decision.
It turns out that utility mispredictions are common. The remembered hedonic
qualities of past events are subject to biased evaluations that overweigh extreme and
final moments, leading to relative “duration neglect” and the occasional preference
for events that are remembered more positively owing to an added diminishingly
painful final episode, despite the added net amount of pain overall (Kahneman
1994, Kahneman et al. 1993). In addition to misremembering their experiences,
decision makers often fail to anticipate increases in liking owing to mere exposure
(Kahneman & Snell 1992), neglect the dissipation of satiation (Simonson 1990),
misremember options previously encountered (Mather et al. 2000), and fail to foresee other factors, such as the effects of ownership on the valuation of objects (Van
Boven et al. 2000). Finally, when predicting the impact on their lives of specific
events, people tend to focus too heavily on those events, consequently overestimating the impact these events will have on their lives and their life satisfaction
(Schkade & Kahneman 1998, Wilson et al. 2000). In making such forecasts, people tend to neglect the extent to which they will be able to maintain a level of
satisfaction in the face of adversity (Gilbert et al. 1998, Kahneman et al. 1999). In
sum, expectations of experienced utility are often inaccurate, whether they stem
from biased retrospective evaluations or from misguided theories about the future.
Decisions based on expectations that are systematically inaccurate are likely to
result in courses of action that fail to maximize well-being, in violation of the
standard tenets underlying the rationality assumption.

Emotion
Whereas emotions are typically considered outside the purvue of a rational analysis, recent research has begun to explore the role of emotions in judgments and
decisions. It appears that transient moods influence choice and judgment in ways
that neither rationality assumptions nor intuition predict. For example, negative
moods increase the perceived frequency of risks and of undesirable events (such
as homicides) and decrease judged life satisfaction, while positive moods act in
the opposite direction (Johnson & Tversky 1983, Schwarz & Clore 1983). Furthermore, for those in a positive mood, the pain of a loss is heightened, leading to
attempts at “mood maintenance” through greater risk-aversion (Isen & Geva 1987,
Isen et al. 1988). Interestingly, moods with the same valence can have differential
effects on judgment; thus, anger, a negatively valenced emotion, seems to yield
optimism in judgments about future risks, whereas fear, also negatively valenced,
generates relative pessimism (Lerner & Keltner 2000).

<-----Page 8----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY

499

Furthermore, judgments are often shaped by emotionally evaluative responses
in ways not anticipated by accounts of rationality. For example, participants are
willing to pay more to insure, and are more likely to seek compensation for, an
item that is emotionally meaningful than for an emotionally neutral but equally
valuable item (Hsee & Kunreuther 2000). Similarly, the perceived risk of things
like nuclear power is related to the amount of dread that they arouse (Fischhoff
et al. 1978). The evaluative reaction engendered by stimuli plays a role in the
halo effect (Dion et al. 1972), and in the influence of vividness on perceived event
frequency (e.g., Lichtenstein et al. 1978).
Such findings have prompted attempts at integrated views of the influences of
affect on decision making. Damasio (1994) posited that good decision making
requires a somatic marker, or a visceral signal that allows the decision maker
to anticipate the pain and pleasure of outcomes. Similar proposals suggest that
images, marked by positive and negative affective feelings, often guide decisions;
because these images can be consulted more quickly and with less effort then
it would take to form a judgment through normative routes, researchers have
argued for the existence of an “affect heuristic” (Finucane et al. 2000, Slovic
et al. 2001). Findings such as the perceived negative relationship between risk
and benefit, strengthened under time pressure and purportedly mediated by affect
(Finucane et al. 2000, Fischhoff et al. 1978) and the relative insensitivity to the
probability of occurrence of emotionally powerful stimuli (Rottenstreich & Hsee
2001) are seen as further evidence for an affect heuristic. Loewenstein et al. (2001)
suggested that anticipatory emotions not only influence cognitive appraisals of
uncertain situations but compete with those appraisals in determining a response.
In summary, recent decision making research has seen an increased interest in the
role of affect: Transient emotions can produce behavioral responses that deviate
from what is otherwise seen as the “best” plan, in ways that are not subsumed by
the tenets of rationality.

Dual Process Models
People’s reasonably sophisticated normative insights, which they are able to formulate upon reflection, alongside the systematic and ubiquitous violations of normative principles in everyday decisions have led to a number of theoretical accounts that have focused on the coexistence of these two apparently discrepant
impulses. These accounts have proposed dual-process theories of reasoning and
judgment, suggesting that responses can reflect, at different times, the operation
of one system or another (Epstein 1994, Evans & Over 1996, Osherson 1995,
Sloman 1996, Stanovich 1999). For example, Epstein (1994) suggested that there
is a holistic, affective, association-driven experiential system that coexists with an
analytic, logical, and reason-oriented rational system. Sloman (1996) proposed an
associative system that makes judgments based on similarity and regularities in
the environment; this is separate from a rule-based system that operates on symbolic structures and follows explicit rules of computation. Evans & Over (1996)

<-----Page 9----->30 Nov 2001

11:29

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

500

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

distinguished habitual and tacit “type 1 rationality,” which serves to achieve everyday goals, from “type 2 rationality,” which enables people to follow explicit
normative insights. In his summary of dual-process theories, Stanovich (1999)
referred to “system 1” reasoning, which is automatic, largely unconscious, and
undemanding of capacity, versus “system 2” reasoning, which is controlled and
encompasses analytic intelligence.
Common to these theories is one process of reasoning that makes relatively
automatic inferences and judgments through mainly associative means, and another
process that makes relatively effortful inferences by following a set of explicitly
normative rules. Only when the rule-based, analytic system is engaged, and when it
cues a normative response that “overrides” the automatic, associative processing,
will people successfully avoid the “irrationalities” that can be generated by the
latter. For example, in the context of the Linda problem (Tversky & Kahneman
1983), the associative system might cue the response “Linda resembles a feminist
bank teller;” only when the rule-based system recognizes the applicability of the
conjunction rule will participants generate the normative response (cf. Epstein
1994, Sloman 1996, Stanovich 1999). It should be noted that these theories share
a basic structure with other dual-process theories of information processing, such
as Shiffrin & Schneider’s (1977) distinction between automatic and controlled
processing and Zajonc’s (1980) distinction between immediate affective responses
and more effortful cognitive responses, as well as theories of attitude change (Petty
& Wegener 1999), person perception (Trope & Gaunt 1999), and stereotyping
(Fiske et al. 1999; see Chaiken & Trope 1999, for further examples), all of which
posit at least two basic modes of processing—one in which heuristic responses
predominate and another in which more deliberate strategies take over.
Regardless of the precise account of how reasoning is performed, there seems to
be compelling evidence for systematic violations of normative principles alongside
the ability to appreciate their normative appeal. Rationality requires that judgments
and decisions be far-sighted, contemplated in the aggregate, and made from a global
perspective. Instead, research shows that they are often myopic and contemplated
from a narrow and local perspective. Nonetheless, some authors have questioned
the validity or importance of the empirical findings. It is to these objections that
we next turn.

THE OBJECTIONS
A slew of studies and replications have solidified the status of the rationality critique
over the past two decades. Perhaps not surprisingly, recent years have witnessed a
resurgence in attempts to salvage the rationality assumption. One natural path has
been to question the validity or relevance of the accumulated findings. This has been
pursued along several lines. The first trivializes the findings by denying their import
and applicability to “real” decisions. The second argues that participants are not
providing wrong answers but, rather, that the researchers misinterpret the answers

<-----Page 10----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

RATIONALITY

501

as incorrect. The third line holds that researchers’ expectations and demands of
the participants are inappropriate, unfair, or unrealistic. These arguments and the
evidence for or against them are summarized in turn (see Gilovich & Griffin 2001,
Stanovich 1999 for related reviews).

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

Trivializations of the Findings
One way to salvage the rationality assumption is by dismissing the various findings as unsystematic, unreliable, and easily correctable once participants are sufficiently motivated. The simplest version of this argument suggests that irrationalities
are nothing more than unsystematic “performance errors,” merely the result of a
“momentary . . . lapse in ancillary processes” (Stanovich & West 2000, p. 646; see
Stein 1996, pp. 9–10). Were this the case, we should expect nothing more than
error variance centered around a normative response. This version of the argument can be relatively easily dismissed. The observed deviations from rationality
are clearly not random. Errors ranging from the conjunction fallacy (Tversky &
Kahneman 1983), to framing effects (Tversky & Kahneman 1981), to preference
reversals (Lichtenstein & Slovic 1973) all arise in specific and predictable ways.
Furthermore, Stanovich & West (1998c) have found modest correlations between
an individual’s performance on a host of judgment and reasoning problems; such
correlations would not be expected were these nothing but unsystematic errors.
A related argument, however, cannot be quite so easily dismissed. According
to this argument, participants who violate basic normative principles may simply
lack sufficient motivation; were they motivated, the argument goes, they would
think more deeply about the task and obey the otherwise compelling normative
principles. This implies that rationality violations ought mostly to emerge on trivial
and inconsequential tasks. This prediction has been explored in a variety of ways.
INCENTIVES Monetary incentives have traditionally been presumed an obvious
way to increase motivation. With rare exceptions, however, incentives do not decrease the incidence of nonnormative behaviors. Camerer & Hogarth (1999) reviewed 74 studies that manipulate incentives. An occasional study has been able
to, for instance, improve performance on a probability matching task (Castellan
1969), or reduce the influence of an irrelevant anchor (Wright & Anderson 1989).
However, most inconsistencies, such as preference reversals (Grether & Plott 1979,
Lichtenstein & Slovic 1973, Kachelmeier & Shehata 1992) and framing effects
(Levin et al. 1988, Tversky & Kahneman 1981) persist in the face of incentives and
can even be exacerbated by them. Arkes et al. (1986) employed a prediction task
in which participants had the option of using an actuarial formula; the presence
of incentives led to lesser reliance on the formula and to worsened performance.
Camerer & Hogarth (1999) concluded that “there is no replicated study in which a
theory of rational choice was rejected at low stakes . . . and accepted at high stakes”
(p. 33). Note that even when incentives are successful in raising motivation, people still need to apply the correct insights for performance to improve beyond the

<-----Page 11----->30 Nov 2001

11:29

502

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

mere reduction of careless error (cf. Wilson et al. 1996). Without the appropriate
insight, increased motivation will lead to more enthusiastic application of an incorrect strategy and will have a small if not a deleterious effect (as in Arkes et al.
1986).
JUSTIFICATION PROVISION Another method of increasing participants’ involvement has been to require them to justify their responses. However, just as incentives
do not reduce the occurrence of inconsistency, neither does justification provision.
To take framing effects as an example, whereas justification has at times been
shown to reduce the incidence of framing effects (Sieck & Yates 1997, Takemura
1994), more often framing effects clearly persist even when justification is provided (Fagley & Miller 1987, Levin & Chapman 1990, Miller & Fagley 1991,
Takemura 1993; RA LeBoeuf & E Shafir, in preparation). Again, greater involvement may increase motivation, but without the right insight at the right moment
that motivation is unlikely to have a positive effect.
EXPERTISE An obvious place to look for increased involvement and sophistication
is among experts, to whom the task is highly relevant and much more familiar.
Numerous studies show that experts can violate the tenets of rationality in much
the same fashion as lay people do. For example, Redelmeier & Shafir (1995,
Redelmeier et al. 2001) found that physicians, nurses, and legislators who faced
choices in their own areas of expertise were prone to violate notions of regularity
(Tversky & Simonson 1993) and instrumentality (Bastardi & Shafir 1998) much
as nonexperts did. Similarly, McNeil et al. (1982) found that patients, graduate
students, and physicians were similarly affected by a framing manipulation of
alternative therapies’ mortality outcomes. Other studies similarly found expertise
and experience to have little impact on the incidence of decision biases (e.g.,
Benartzi & Thaler 1995, Camerer et al. 1997, Neale & Northcraft 1986, Redelmeier
& Tversky 1990).
In a slightly different vein, Dawes et al. (1989) concluded that actuarial decision
making is often far superior to expert, or clinical, judgment. Their conclusion stems
in part from studies that show that clinicians fall prey to judgmental biases, such
as overconfidence (Faust et al. 1988) and the hindsight bias (Arkes et al. 1981). It
appears that experts, for whom the tasks are meaningful and relevant, are as likely as
nonexperts to violate simple norms of rationality. This strongly suggests that such
violations cannot be attributed to lack of interest, involvement, or understanding.
NEED FOR COGNITION Despite the failure of incentives, justification, or expertise
to attenuate the observed inconsistencies and biases, one more variable that has
been investigated is participants’ inherent need for cognition (NC) (Cacioppo &
Petty 1982). NC identifies “differences among individuals in their tendency to
engage in and enjoy thinking” (Cacioppo & Petty 1982, p. 116). The NC variable
separates those who find fulfillment in intricate thought from those who do not
seek out situations that require effortful and elaborate processing (Cacioppo &

<-----Page 12----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY

503

Petty 1982). To the extent that a bias is attributable to an insufficiently serious
consideration of a problem, NC might moderate the occurrence of such bias.
Smith & Levin (1996) reported a lower impact of problem frame on highNC participants, but both Levin et al. (2001) and RA LeBoeuf & E Shafir (in
preparation) found no effect of NC on framing. Stanovich & West (1999) found
that those with higher NC scores were more likely, among other things, to recognize
the relevance of base rates in likelihood judgments and more likely to recognize
the inappropriateness of honoring sunk costs. On the other hand, they found NC
scores not to be predictive of insights in hypothesis testing or Prisoner’s Dilemma
tasks. In fact, higher NC scores did not yield an increase in the tendency to utilize
(as opposed to merely recognize the relevance of) base rates. Thus, whereas highNC participants occasionally give more normative responses than their low-NC
counterparts (especially in within-subjects contexts; see RA LeBoeuf & E Shafir,
in preparation), increased thought as indexed by NC scores does not appear to rid
respondents of observed inconsistencies and bias.
SUMMARY Deviations from the criteria of rational judgment and choice cannot
be seen as mere “performance errors.” These deviations are far too systematic,
both within and across individuals, to be considered randomly distributed. The
systematic biases persist in the face of a variety of attempts to increase incentives
as well as other motivational factors. The biases are exhibited by experts as well
as novices and cannot be dismissed as random artifacts attributable to trivial,
uninteresting, or unrepresentative tasks.

Misinterpretations
Another way to salvage the rationality assumption is to suggest that researchers
mistakenly attribute irrationality to what is in fact normative behavior. Such misinterpretation is said to arise owing to experimenters’ and participants’ purportedly
different construals of the tasks (see also Gilovich & Griffin 2001, Stanovich &
West 2000). According to this view, participants’ responses, which are rational in
light of their own construals of the task, are coded as irrational by experimenters
who fail to appreciate the participants’ construals (Hertwig & Gigerenzer 1999,
Hilton 1995, Levinson 1995, Macdonald 1986, Schwarz 1996, Slugoski & Wilson
1998). When studies are redesigned to reduce the likelihood of alternative construals and misinterpretations, purported violations should disappear or at least
be markedly reduced (Dulany & Hilton 1991, Fiedler 1988, Krosnick et al. 1990,
Politzer & Noveck 1991, Schwarz et al. 1991). We explore this in the following
sections.
CONVERSATIONAL IMPLICATIONS One critique starts with the premise that people
must make inferences about a communicator’s intent and that, in making such
inferences, people typically presume that communicators are following the maxims of relevance and nonredundancy (Grice 1975). Participants in experiments,

<-----Page 13----->30 Nov 2001

11:29

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

504

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

according to this critique, do not always realize that the experimenter may flout
a Gricean maxim, for example, by volunteering irrelevant information. Consequently, they make inferences about the experimenter’s presumed intent and base
their judgments on inferred as well as available information, whereas the experimenter expects evaluations based solely on available information (Hilton 1995,
Levinson 1995, Schwarz 1996).
Prominent targets of this critique have been violations of the conjunction rule
as exhibited by performance on the Linda problem described earlier (Tversky &
Kahneman 1983). Researchers have investigated the inferences that people draw
when presented with the conjunct (“Linda is a bank teller”) juxtaposed with the
conjunction (“Linda is a bank teller and is active in the feminist movement”).
Respondents, it is argued, may expect a cooperative communicator not to pose a
trivial question such as “Is A more or less probable than A and B?” and may thus
infer that further interpretation is necessary (Politzer & Noveck 1991), leading to
the reformulation of the conjunct as meaning “A and not B” (cf. Dulany & Hilton
1991, Levinson 1995).
Anticipating such critique, Tversky & Kahneman (1983) replaced the conjunct
with “Linda is a bank teller whether or not she is active in the feminist movement.”
Whereas the incidence of the conjunction fallacy diminished, the fallacy persisted
among the majority of participants. A number of researchers, however, remained
unconvinced and further explored potential alternative interpretations of the items.
Dulany & Hilton (1991), for example, found that they could reduce the prevalence of the conjunction fallacy to a minority of subjects (38% or fewer) by rewording the conjunct to include some helpful logical clues. Furthermore, through
interviews with participants, they ascertained that the majority who committed the
conjunction fallacy did not interpret the conjunct in its extensional, or normative,
form. Politzer & Noveck (1991) similarly found that explicit, as opposed to implicit, conjunctions indeed encouraged alternate interpretations of the conjunct.
In a related vein, Slugoski & Wilson (1998) found that the tendency to commit
the conjunction fallacy was correlated with a person’s conversational skill and
proposed that the fallacy is due to a process of interpretation, not necessarily an
inability to reason.
Despite these observations, it appears unlikely that the conjunction fallacy can
be relegated to a flouting of Gricean conventions. First, Tversky & Kahneman
(1983) observed the conjunction fallacy across a wide variety of problems, including some for which implicatures are not easily invited (e.g., the “Bjorn Borg”
problem). Second, Tversky & Kahneman observed the conjunction effect in a
between-subjects design in which the conjunct was rated as less probable than
the conjunction even though the two were seen by different participants (but see
Hertwig & Gigerenzer 1999, Politzer & Noveck 1991 for questions about the relevance of between-subjects findings). Agnoli & Krantz (1989) found that instruction
in set theory could diminish the incidence of the conjunction fallacy, which would
not be expected if participants reinterpreted the conjunct to mean that the conjunction was not its subset. Agnoli & Krantz also noted that replacing the conjunct

<-----Page 14----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY

505

with its purported reinterpretation (A and not B) increased the difference between
the likelihood assigned the replacement statement and the original conjunction, a
pattern that would not be expected under the spontaneous reinterpretation notion.
Finally, Morier & Borgida (1984) included the conjunct, the original conjunction,
as well as the purported reinterpretation among the response alternatives. This
should have obviated the purported need to reinterpret, yet 77% of participants
committed the conjunction fallacy on the Linda problem.
Findings of insufficient reliance on base-rate information in likelihood judgments (Kahneman & Tversky 1973) sparked similar discussions regarding possible
conversational inferences (see Schwarz 1996). In a typical experiment, participants
are presented with a vignette drawn randomly from some population (consisting,
e.g., of 70 lawyers and 30 engineers) and asked the likelihood that the description
belongs to a particular member of that population (e.g., a lawyer). Estimates are
typically under-influenced by the base rate, and over-influenced by the representativeness of the description (Kahneman & Tversky 1973). It was suggested that
perhaps participants are led to infer that the description is important, and that it
is this inference, not a general reluctance to rely on base rates, that underlies the
apparent error (Schwarz 1996, Schwarz et al. 1991).
In the original studies (Kahneman & Tversky 1973), base rates were given
first and then the individuating description was added; this order of presentation,
some have proposed, may have suggested that base rates were insufficient for
the task. Krosnick et al. (1990) varied the order in which the information was
presented and, indeed, found that reliance on base rates increased when baserate information was presented after the description. Also, in the original studies,
in which the personality description was purportedly compiled by psychologists,
participants may have inferred that it was carefully constructed and perhaps valid.
When the description was said to have been randomly sampled, unreliable, or
informative to “statistical” experts, reliance on base rates increased significantly
(Ginossar & Trope 1987, Schwarz et al. 1991). Finally, when base rates were
made to vary, reliance on base rates increased (Fischhoff et al. 1979, Schwarz
et al. 1991). Whereas some instances of base rate neglect may be attributable
to conversational factors, as suggested above, the data continue to suggest that
an under-reliance on base rates, perhaps less extreme than occasionally observed,
nevertheless characterizes people’s judgments (Fischhoff et al. 1979, Schwarz et al.
1991).
Conversational considerations have also been invoked with regard to framing
effects. In the context of the Asian Disease problem (Tversky & Kahneman 1981),
for example, researchers have suggested that the two (purportedly isomorphic)
frames presented could be construed as nonisomorphic (Berkeley & Humphreys
1982, Macdonald 1986). However, Stanovich & West (1998b), using a withinsubjects design, showed that most participants, especially those of higher cognitive
ability, recognize the two frames as extensionally identical. Violations of normative criteria are often overdetermined; many factors can combine to produce such
violations, and conversational misinterpretations may be one, but are unlikely to be

<-----Page 15----->30 Nov 2001

11:29

506

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

a major, contributor to the observed effects (cf. Gilovich & Griffin 2001, Schwarz
1996).
ALTERNATIVE INTERPRETATIONS OF TERMS AND TASKS Some attempts to dismiss
the observed findings have focused on the possibility that respondents’ interpretations of the terms or tasks are different from those assumed by the experimenters
who present them. One such line of criticism hinges on the use of the term “probability.” There are at least two distinct philosophical conceptions of probability
(Howson & Urbach 1989, Keynes 1921, von Mises 1957). According to one, probabilities refer to the relative frequencies of objective physical events in repeated
trials; according to the other, probabilities are epistemic in nature, expressing
degrees of belief in specific hypotheses. Note, though, that these different conceptions of probability are arguably constrained by the same mathematical axioms.
Adherence to the axioms suffices to insure that probability judgment is coherent.
Nonetheless, this distinction is at the core of an ongoing debate concerning the
status and interpretation of some experimental findings (see, e.g., Cosmides &
Tooby 1996; Fiedler 1988; Gigerenzer 1994, 1996a; Kahneman & Tversky 1996).
For example, Gigerenzer (1994; see also Macdonald 1986) noted that the conjunction fallacy, observed when asking for the probability of single events, violates
some theories of probability but does not violate the frequentist conception of probability. Furthermore, Hertwig & Gigerenzer (1999) argued that participants who
commit the fallacy generally do not interpret “probability” mathematically. They
showed that preceding probability judgments with typicality judgments reduces
the incidence of the conjunction fallacy, suggesting that participants can interpret
probability mathematically but tend not to do so spontaneously. The conjunction fallacy, however, has also been shown in frequentistic formats (Tversky &
Kahneman 1983, Kahneman & Tversky 1996). Furthermore, most respondents
do not subscribe to a frequentistic interpretation, because they appear to find the
notion of a single event probability natural and clear (Kahneman & Tversky 1996).
In fact, it appears that the standard conception of probability endorsed by experimenters is also endorsed by participants with greater cognitive ability (Stanovich &
West 1998b).
A similar objection concerns the possible reinterpretation of task instructions.
For example, incorrect responses on the Wason selection task (Wason 1966) are
typically seen as indicative of errors in deductive reasoning. However, Oaksford &
Chater (1996) suggested that participants might see their task as involving optimal
data selection for inductive hypothesis testing, which would explain the supposed
incorrect responses when the task has abstract or otherwise nondeontic content, as
opposed to the improved performance with deontic content. By this account, variations from the modal responses should merely constitute error variance. However,
Stanovich & West (1998a) found a larger-than-expected set of participants who
gave either the correct or the incorrect response in both the nondeontic and deontic
versions, suggesting a frequent construal of the task as one involving deductive
reasoning.

<-----Page 16----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY

507

A review of the findings suggests that observed violations of the requirements of
rationality cannot be explained away by attributing to respondents alternative construals of problems. Of course, understanding participants’ construals of situations
has been very important, particularly in social psychology (Griffin & Ross 1991).
Various considerations that enter into peoples’ construals of decision situations
have been explored, including fairness (Kahneman et al. 1986), anticipated regret
(Bell 1982, Tversky 1975), wishful thinking (Quattrone & Tversky 1984), and
impression management (Sen 1993), among others. However, not all construals of
every problem can be considered legitimate lest the theory of rational choice be
stripped of any normative impact (see Margolis 1987). In fact, some misconstruals
may be at the very heart of the counter-normative behaviors they help generate.
Stanovich & West (2000, Stanovich 1999) attempted to find an “expert wide reflective equilibrium” such that normative principles, philosophical considerations,
intuition, and expert opinion come into balance in regards to whether alternative
interpretations are seen as potentially normative; they conclude that the standard
normative construals are, for the most part, appropriate.

Inappropriate Tests of Rationality
Other objections to the documented violations of rational choice and judgment
focus not on the results as much as on the appropriateness of the tests used to
obtain them.
COMPUTATIONAL LIMITATIONS A fundamental challenge questions whether the
observed biases and errors emerge simply because the normative responses are
out of reach for people. Clearly, rationality should not be defined in a manner that
renders it unattainable by most people (Harman 1995, Stich 1990). If the tasks are
unfairly demanding, we learn little from observing participants’ inability to solve
them.
For many of the findings that form the core of the rationality critique this
argument simply does not apply. Simple violations of well-ordering in choice,
for example, such as standard framing effects (Tversky & Kahneman 1981), the
asymmetric dominance effect (Huber et al. 1982, Simonson & Tversky 1992), the
effects of noninstrumental searches (Bastardi & Shafir 1998), and the variety of
preference reversals discussed earlier all impose remarkably simple demands; the
difficulties appear to reside not in any computational demands, but in the fact that
preferences are malleable and thus prone to systematic violations of well-ordering.
Demonstrated, albeit imperfect, improvements in statistical reasoning following
instruction also suggest that the difficulties are often not computational but rather
conceptual in nature (see, e.g., Agnoli & Krantz 1989, Fong & Nisbett 1991, Frank
et al. 1993). Furthermore, various errors and inconsistencies that are systematically
exhibited when the applicability of a relevant principle goes undetected are easily
avoided once it is transparent (e.g., Fiedler 1988, Tversky & Kahneman 1986,
Tversky & Shafir 1992b). As before, the difficulty appears to reside not in the

<-----Page 17----->30 Nov 2001

11:29

508

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

required computation, but in the intuitive heuristic procedures that are used unless
their possible inappropriateness is made salient.
INAPPROPRIATE PROBLEM FORMATS The nature of the particular problems used
has also been questioned, particularly in light of findings suggesting that performance can be improved if the problems are altered. Researchers approaching the
question of rationality from an evolutionary perspective, for example, have argued that the tasks provided are typically not the tasks that participants’ cognitive
mechanisms have evolved to be good at. When evolutionarily more appropriate tasks are employed, the argument holds, performance improves (Cosmides &
Tooby 1996, Gigerenzer 1996b). For example, it is known that performance can
be improved when problems are posed in terms of frequencies rather than likelihood judgments (Cosmides & Tooby 1996, Fiedler 1988, Gigerenzer et al. 1991,
Hertwig & Gigerenzer 1999, Tversky & Kahneman 1983), although performance
can also be hurt by frequency formats (see Griffin & Buehler 1999). Evolutionary
psychologists have proposed that the ability to encode frequencies was useful in
the Pleistocene age, and the corresponding cognitive mechanisms were thus selected for, whereas the ability to determine the likelihood of single events was not
(Cosmides & Tooby 1996). Similarly, improved performance on the Wason selection task when the content requires participants to check for violations of social
contracts is attributed to a “cheater-detection” module that was ostensibly selected
for through evolution (Cosmides & Tooby 1992, Gigerenzer & Hug 1992).
Even if these arguments were correct, the fact remains that many problems
encountered in everyday life are not presented in evolutionarily advantageous
ways and may thus generate incorrect responses. In fact, the successful elicitation
of improved performance with certain formats suggests that people do indeed
have the required competence and that they tend to agree about the correct norms
(Stanovich 1999, Stein 1996). Of course, the fact that some biases are more or
less easy to avoid depending on question format is not surprising or inconsistent
with nonevolutionary accounts of problem solving and judgment (Gick & Holyoak
1980, Reed 1993). For example, it has been suggested that frequency formats may
make extensional considerations easier to bring to mind (Tversky & Kahneman
1983; but see Hertwig & Gigerenzer 1999).
INAPPROPRIATE NORMS Yet another argument regarding the appropriateness of
studies of rationality centers on whether the appropriate normative standards are
being used (cf. Gigerenzer 1996a, Gigerenzer et al. 1991, Lopes & Oden 1991,
Wetherick 1971). Several economists tried to effect a compromise between normative accounts and descriptive findings by retaining some of the more normatively
appealing principles, such as dominance and invariance, while relaxing others,
such as independence and transitivity (see Camerer 1990, 1995; Machina 1982).
In a similar fashion some researchers have attempted to address the rationality
critique by changing some normative criteria so that the normative and descriptive
may be more in line (Stein 1996).

<-----Page 18----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY

509

Allowing departures from otherwise appealing normative criteria is problematic. For one thing, incoherent judgment entails the possible holding of contradictory beliefs and likelihood judgments that, when translated into bets that the
person deems fair, create a set of bets that the person is bound to lose no matter how things turn out (Osherson 1995, Resnik 1987, Stein 1996). Not only do
individuals who violate the simple laws of probability or preference leave themselves exposed to situations in which they are bound to lose, but the normative
principles are, in fact, typically endorsed by those who occasionally violate them.
Stanovich & West (1999) presented participants with normative as well as nonnormative arguments, and found that participants who changed their responses
were often more likely to do so in the normative direction (see also Tversky &
Kahneman 1983). Furthermore, in many of the tasks that these investigators studied, those who respond normatively score higher on the SAT as well as other
cognitive ability measures (Stanovich & West 1998a,b,c). It appears that greater
awareness of the normative principles, indexed by cognitive ability, presentation
formats, or through explicit explication, is often associated with greater support
for their normative appeal (but see Dawes & Mulford 1996, Hoch 1987, Stanovich
& West 1998c for instances in which standard normative principles might not be
appropriate).
Perhaps the most extreme argument has suggested that rationality is not to be
settled empirically, because evolution will have necessarily produced organisms
that form true beliefs and that reason rationally (e.g., Dennett 1987, Fodor 1975;
see Stanovich 1999, Stein 1996, Stich 1990 for reviews). As others have written,
these arguments misconstrue the function of evolution and of natural selection
(Lewontin 1990, Stein 1996). There is no basis for assuming that evolution will
have produced creatures whose behavior conforms to the rational principles that
they have endorsed, and there is, therefore, no reason to question the appropriateness of studies that try to gauge these principles’ empirical status.

SUMMARY AND CONCLUSION
Various arguments have been made disputing the accumulation of findings that
show people systematically violating fundamental normative principles of reasoning, judgment, and decision. This review suggests that the violations cannot
be dismissed as either random or trivial, nor can they be attributed to experimenters’ misinterpretation of answers that are actually appropriate to alternative,
valid interpretations of the problems. The systematic and well-documented findings cannot be attributed to simple computational limitations, nor does it appear
that inappropriate types of questions are being asked or inappropriate norms applied. The compelling nature of the rationality critique is having an ever greater
impact on work in neighboring disciplines, most notably in the increasing popularity of behavioral economics (Rabin 1998, Sunstein 2000, Thaler 1992, 1993).
It may eventually help alter the social sciences’ view of the human agent.

<-----Page 19----->30 Nov 2001

11:29

510

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

Visit the Annual Reviews home page at www.AnnualReviews.org

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

LITERATURE CITED
Agnoli F, Krantz DH. 1989. Suppressing natural heuristics by formal instruction: the case
of the conjunction fallacy. Cogn. Psychol.
21:515–50
Arkes HR, Blumer C. 1985. The psychology of
sunk cost. Org. Behav. Hum. Decis. Process.
35:124–40
Arkes HR, Dawes RM, Christensen C. 1986.
Factors influencing the use of a decision rule
in a probabilistic task. Org. Behav. Hum. Decis. Process. 37:93–110
Arkes HR, Wortmann RL, Saville PD, Harkness AR. 1981. Hindsight bias among physicians weighing the likelihood of diagnoses.
J. Appl. Psychol. 66:252–54
Baron J. 1994. Thinking and Deciding. New
York: Cambridge Univ. Press. 2nd ed.
Bastardi A, Shafir E. 1998. On the pursuit and
misuse of useless information. J. Pers. Soc.
Psychol. 75:19–32
Bell DE. 1982. Regret in decision making under
uncertainty. Oper. Res. 30:961–81
Bell DE, Raiffa H, Tversky A, eds. 1988. Decision Making: Descriptive, Normative, and
Prescriptive Interactions. New York: Cambridge Univ. Press
Benartzi S, Thaler R. 1995. Myopic loss aversion and the equity premium puzzle. Q. J.
Econ. 110:73–92
Berkeley D, Humphreys P. 1982. Structuring
decision problems and the “bias heuristic.”
Acta Psychol. (Amst.). 50:201–52
Braine MDS, O’Brien DP, eds. 1998. Mental
Logic. Mahwah, NJ: Erlbaum
Brenner LA, Koehler DJ. 1999. Subjective
probability of disjunctive hypotheses: local–
weight models for decomposition of evidential support. Cogn. Psychol. 38:16–47
Cacioppo JT, Petty RE. 1982. The need for
cognition. J. Pers. Soc. Psychol. 42:116–31
Camerer CF. 1990. Behavioral game theory. In
Insights in Decision Making: A Tribute to
Hillel J. Einhorn, ed. RM Hogarth, pp. 311–
36. Chicago: Univ. Chicago Press

Camerer CF. 1995. Individual decision making.
In Handbook of Experimental Economics,
ed. JH Kagel, A Roth, pp. 587–703. Princeton, NJ: Princeton Univ. Press
Camerer CF, Babcock L, Loewenstein G,
Thaler R. 1997. Labor supply of New York
City cab drivers: one day at a time. Q. J. Econ.
112:407–441
Camerer CF, Hogarth RM. 1999. The effects of
financial incentives in experiments: a review
and capital-labor-production framework. J.
Risk Uncertain. 19:7–42
Castellan NJ. 1969. Effect of change of payoff in probability learning. J. Exp. Psychol.
79:178–82
Chaiken S, Trope Y. 1999. Dual-Process Theories in Social Psychology. New York: Guilford
Cohen LJ. 1981. Can human irrationality be
experimentally demonstrated? Behav. Brain
Sci. 4:317–70
Cosmides L, Tooby J. 1992. Cognitive adaptations for social exchange. In The Adapted
Mind: Evolutionary Psychology and the Generation of Culture, ed. J Barkow, L Cosmides,
J Tooby, pp. 163–228. New York: Oxford
Univ. Press
Cosmides L, Tooby J. 1996. Are humans
good intuitive statisticians after all? Rethinking some conclusions from the literature on
judgment under uncertainty. Cognition 58:1–
73
Damasio AR. 1994. Descartes’ Error: Emotion, Reason, and the Human Brain. New
York: Avon
Dawes RM. 1979. The robust beauty of improper linear models in decision making. Am.
Psychol. 34:571–82
Dawes RM. 1988. Rational Choice in an Uncertain World. New York: Harcourt Brace Jovanovich
Dawes RM, Faust D, Meehl PE. 1989. Clinical versus actuarial judgment. Science 243:
1668–74

<-----Page 20----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY
Dawes RM, Mulford M. 1996. The false consensus effect and overconfidence: flaws in
judgment or flaws in how we study judgment? Org. Behav. Hum. Decis. Process.
65:201–11
Dennett DC. 1987. The Intentional Stance.
Cambridge, MA: MIT Press
Dion K, Berscheid E, Walster E. 1972. What
is beautiful is good. J. Pers. Soc. Psychol.
24:285–90
Dulany DE, Hilton DJ. 1991. Conversational
implicature, conscious representation, and
the conjunction fallacy. Soc. Cogn. 9:85–110
Dunning D, Griffin DW, Milojkovic JD, Ross
L. 1990. The overconfidence effect in social
prediction. J. Pers. Soc. Psychol. 58:568–81
Edwards W. 1961. Behavioral decision theory.
Annu. Rev. Psychol. 12:473–98
Edwards W. 1962. Subjective probabilities inferred from decisions. Psychol. Rev. 69:109–
35
Epstein S. 1994. Integration of the cognitive and
the psychodynamic unconscious. Am. Psychol. 49:709–24
Ericsson KA, Simon HA. 1984. Protocol Analysis: Verbal Reports as Data. Cambridge,
MA: MIT Press
Evans JStBT, Over DE. 1996. Rationality and
Reasoning. Hove, UK: Psychology Press
Fagley NS, Miller PM. 1987. The effects of decision framing on choice of risky vs. certain
options. Org. Behav. Hum. Decis. Process.
39:264–77
Faust D, Hart KJ, Guilmette TJ. 1988. Pediatric malingering: the capacity of children to
fake believable deficits on neuropsychological testing. J. Consult. Clin. Psychol. 56:578–
82
Fellner W. 1965. Probability and Profit: A Study
of Economic Behavior along Bayesian Lines.
Homewood, IL: Irwin
Fiedler K. 1988. The dependence of the conjunction fallacy on subtle linguistic factors.
Psychol. Res. 50:123–29
Finucane ML, Alhakami A, Slovic P, Johnson
SM. 2000. The affect heuristic in judgments
of risks and benefits. J. Behav. Decis. Mak.
13:1–17

511

Fischhoff B, Slovic P, Lichtenstein S. 1977.
Knowing with certainty: the appropriateness
of extreme confidence. J. Exp. Psychol. Hum.
Percept. Perform. 3:552–64
Fischhoff B, Slovic P, Lichtenstein S. 1979.
Subjective sensitivity analysis. Org. Behav.
Hum. Perform. 23:339–59
Fischhoff B, Slovic P, Lichtenstein S, Reid S,
Combs B. 1978. How safe is safe enough?
A psychometric study of attitudes towards
technological risks and benefits. Policy Sci.
9:127–52
Fiske ST, Lin M, Neuberg SK. 1999. The continuum model: ten years later. See Chaiken
& Trope 1999, pp. 231–54
Fodor J. 1975. The Language of Thought. New
York: Crowell
Fong GT, Nisbett RE. 1991. Immediate and
delayed transfer of training effects in statistical reasoning. J. Exp. Psychol.: Gen. 120:34–
45
Frank RH, Gilovich T, Regan DT. 1993. Does
studying economics inhibit cooperation? J.
Econ. Perspect. 7:159–71
Gardenfors P. 1988. Knowledge in Flux. Cambridge, MA: MIT Press
Gick M, Holyoak K. 1980. Analogical problem
solving. Cogn. Psychol. 12:306–55
Gigerenzer G. 1994. Why the distinction
between single-event probabilities and frequencies is important for psychology (and
vice versa). In Subjective Probability, ed. G
Wright, P Ayton, pp. 129–61. New York:
Wiley
Gigerenzer G. 1996a. On narrow norms and
vague heuristics: a reply to Kahneman and
Tversky. Psychol. Rev. 103:592–96
Gigerenzer G. 1996b. Rationality: why social
context matters. In Interactive Minds: LifeSpan Perspectives on the Social Foundation
of Cognition, ed. PB Baltes, U Staudinger,
pp. 319–46. Cambridge: Cambridge Univ.
Press
Gigerenzer G, Hoffrage U, Kleinbolting H.
1991. Probabilistic mental models: a Brunswickian theory of confidence. Psychol. Rev.
98:506–28
Gigerenzer G, Hug K. 1992. Domain-specific

<-----Page 21----->30 Nov 2001

11:29

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

512

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

reasoning: social contracts, cheating and perspective change. Cognition 43:127–71
Gilbert DT, Pinel EC, Wilson TD, Blumberg
SJ, Wheatley TP. 1998. Immune neglect: a
source of durability bias in affective forecasting. J. Pers. Soc. Psychol. 75:617–38
Gilhooly K. 1988. Thinking: Directed, Undirected and Creative. New York: Academic.
2nd ed.
Gilovich TD, Griffin DW. 2001. Heuristics
and biases: then and now. See Gilovich et al.
2001. In press
Gilovich TD, Griffin DW, Kahneman D, eds.
2001. Heuristics and Biases: The Psychology of Intuitive Judgment. Cambridge: Cambridge Univ. Press. In press
Ginossar Z, Trope Y. 1987. Problem solving
in judgment under uncertainty. J. Pers. Soc.
Psychol. 52: 464–74
Glymour CN. 1992. Thinking Things Through:
An Introduction to Philosophical Issues and
Achievements. Cambridge, MA: MIT Press
Goldstein WM, Hogarth RM. 1997. Research
on Judgment and Decision Making: Currents, Connections, and Controversies. Cambridge: Cambridge Univ. Press
Gonzalez R, Wu G. 1999. On the shape of the
probability weighting function. Cogn. Psychol. 38:129–66
Gourville JT, Soman D. 1998. Payment depreciation: the behavioral effects of temporally
separating payments from consumption. J.
Consum. Res. 25:160–74
Grether D, Plott C. 1979. Economic theory
of choice and the preference reversal phenomenon. Am. Econ. Rev. 69:623–38
Grice HP. 1975. Logic and conversation. In The
Logic of Grammar, ed. D Davidson, G Harman, pp. 64–75. Encino, CA: Dickenson
Griffin DW, Buehler R. 1999. Frequency,
probability, and prediction: easy solutions to
cognitive illusions? Cogn. Psychol. 38:48–
78
Griffin DW, Ross L. 1991. Subjective construal,
social inference, and human misunderstanding. In Advances in Experimental Social Psychology, ed. L Berkowitz, 24:319–59. San
Diego, CA: Academic

Griffin DW, Tversky A. 1992. The weighing of
evidence and the determinants of confidence.
Cogn. Psychol. 24:411–35
Hammond J, Keeney R, Raiffa H. 1999. Smart
Choices: A Practical Guide to Making Better
Decisions. Boston: Harvard Bus. Sch. Press
Harman G. 1995. Rationality. See Smith & Osherson 1995, pp. 175–211
Hastie R. 2001. Problems for judgment and decision making. Annu. Rev. Psychol. 52:653–
83
Hertwig R, Gigerenzer G. 1999. The “conjunction fallacy” revisited: how intelligent inferences look like reasoning errors. J. Behav.
Decis. Mak. 12:275–305
Hilton DJ. 1995. The social context of reasoning: conversational inference and rational
judgment. Psychol. Bull. 118:248–71
Hoch SJ. 1987. Perceived consensus and predictive accuracy: the pros and cons of projection. J. Pers. Soc. Psychol. 53:221–34
Howson C, Urbach P. 1989. Scientific Reasoning: The Bayesian Approach. La Salle, IL:
Open Court
Hsee CK. 1996. The evaluability hypothesis: an
explanation of preference reversals between
joint and separate evaluations of alternatives.
Org. Behav. Hum. Decis. Process. 67:247–
57
Hsee CK, Kunreuther H. 2000. The affection
effect in insurance decisions. J. Risk Uncertain. 20:141–59
Hsee CK, Blount S, Loewenstein G, Bazerman
M. 1999. Preference reversals between joint
and separate evaluations: a review and theoretical analysis. Psychol. Bull. 125:576–
90
Huber J, Payne JW, Puto C. 1982. Adding
asymmetrically dominated alternatives: violations of regularity and the similarity hypothesis. J. Consum. Res. 9:90–98
Isen AM, Geva N. 1987. The influence of positive affect on acceptable level of risk: the
person with a large canoe has a large worry.
Org. Behav. Hum. Decis. Process. 39:145–
54
Isen AM, Nygren TE, Ashby FG. 1988. Influence of positive affect on the subjective

<-----Page 22----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY
utility of gains and losses: It is just not worth
the risk. J. Pers. Soc. Psychol. 55:710–17
Johnson EJ, Tversky A. 1983. Affect, generalization, and the perception of risk. J. Pers.
Soc. Psychol. 45:20–31
Johnson-Laird PN. 1983. Mental Models: Towards a Cognitive Science of Language,
Inference, and Consciousness. Cambridge,
MA: Harvard Univ. Press
Johnson-Laird PN. 1999. Deductive reasoning.
Annu. Rev. Psychol. 50:109–35
Johnson-Laird PN, Byrne RMJ. 1991. Deduction. Hillsdale, NJ: Erlbaum
Johnson-Laird PN, Byrne RMJ, Schaeken
WS. 1992. Propositional reasoning by model.
Psychol. Rev. 99:418–39
Johnson-Laird PN, Legrenzi P, Girotto V,
Legrenzi MS. 2000. Illusions in reasoning
about consistency. Science 288:531–32
Kachelmeier SJ, Shehata M. 1992. Examining evidence from the People’s Republic of
China. Am. Econ. Rev. 82:1120–41
Kahneman D. 1994. New challenges to the rationality assumption. J. Inst. Theor. Econ.
150:18–36
Kahneman D, Diener E, Schwarz N, eds.
1999. Well-Being: The Foundations of Hedonic Psychology. New York: Russell Sage
Found.
Kahneman D, Fredrickson BL, Schreiber CA,
Redelmeier DA. 1993. When more pain is
preferred to less: adding a better end. Psychol. Sci. 4:401–5
Kahneman D, Knetsch JL, Thaler RH. 1986.
Fairness and the assumptions of economics.
J. Bus. 59(Suppl.):285–300
Kahneman D, Knetsch JL, Thaler R. 1990. Experimental tests of the endowment effect and
the Coase theorem. J. Polit. Econ. 98:1325–
48
Kahneman D, Ritov I. 1994. Determinants of
stated willingness to pay for public goods: a
study in the headline method. J. Risk Uncertain. 9:5–38
Kahneman D, Slovic P, Tversky A, eds. 1982.
Judgment Under Uncertainty: Heuristics
and Biases. Cambridge: Cambridge Univ.
Press

513

Kahneman D, Snell J. 1992. Predicting a changing taste: do people know what they will like?
J. Behav. Decis. Mak. 5:187–200
Kahneman D, Tversky A. 1972. Subjective
probability: a judgment of representativeness. Cogn. Psychol. 3:430–54
Kahneman D, Tversky A. 1973. On the psychology of prediction. Psychol. Rev. 80:237–
51
Kahneman D, Tversky A. 1979. Prospect
theory: an analysis of decision under risk.
Econometrica 47:263–91
Kahneman D, Tversky A. 1996. On the reality of cognitive illusions. Psychol. Rev.
103:582–91
Kahneman D, Tversky A, eds. 2000. Choices,
Values, and Frames. New York: Cambridge
Univ. Press/Russell Sage Found.
Keynes JM. 1921. A Treatise on Probability.
London: Macmillan
Krosnick JA, Li F, Lehman DR. 1990. Conversational conventions, order of information acquisition, and the effect of base rates
and individuating information on social judgments. J. Pers. Soc. Psychol. 59:1140–52
Kühberger A. 1998. The influence of framing
on risky decisions: a meta-analysis. Org. Behav. Hum. Decis. Process. 75:23–55
Lerner JS, Keltner D. 2000. Beyond valence:
toward a model of emotion-specific influences on judgment and choice. Cogn. Emot.
14:473–93
Levin IP, Chapman DP. 1990. Risk taking,
frame of reference, and characterization of
victim groups in AIDS treatment decisions.
J. Exp. Soc. Psychol. 26:421–34
Levin IP, Chapman DP, Johnson RD. 1988.
Confidence in judgments based on incomplete information: an investigation using both
hypothetical and real gambles. J. Behav. Decis. Mak. 1:29–41
Levin IP, Gaeth GJ, Schreiber J, Lauriola M.
2001. A new look at framing effects: distribution of effect sizes, individual differences,
and independence of types of effects. Org.
Behav. Hum. Decis. Process. In press
Levin IP, Schneider SL, Gaeth GJ. 1998. All
frames are not created equal: a typology and

<-----Page 23----->30 Nov 2001

11:29

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

514

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

critical analysis of framing effects. Org. Behav. Hum. Decis. Process. 76:149–88
Levinson SC. 1995. Interactional biases in human thinking. In Social Intelligence and Interaction, ed. E Goody, pp. 221–60. Cambridge: Cambridge Univ. Press
Lewontin R. 1990. The evolution of cognition.
In An Invitation to Cognitive Science, ed. EE
Smith, DN Osherson, 3:229–46. Cambridge,
MA: MIT Press. 1st ed.
Lichtenstein S, Fischhoff B. 1977. Do those
who know more also know more about how
much they know? The calibration of probability judgments. Org. Behav. Hum. Perform.
16:1–12
Lichtenstein S, Slovic P. 1973. Responseinduced reversals of preferences in gambling:
an extended replication in Las Vegas. J. Exp.
Psychol. 101:16–20
Lichtenstein S, Slovic P, Fischhoff B, Layman M, Combs B. 1978. Judged frequency
of lethal events. J. Exp. Psychol. Hum. Learn.
Mem. 4:551–78
Loewenstein G, Elster J, eds. 1992. Choice
Over Time. New York: Russell Sage Found.
Loewenstein GF, Prelec D. 1993. Preferences
for sequences of outcomes. Psychol. Rev.
100:91–108
Loewenstein GF, Weber E, Hsee CK, Welch
N. 2001. Risk as feelings. Psychol. Bull.
127:267–86
Lopes LL, Oden GC. 1991. The rationality
of intelligence. In Probability and Rationality: Studies on L. Jonathan Cohen’s Philosophy of Science, ed. E Eels, T Maruszewski,
pp. 199–223. Amsterdam: Editions Rodopi
Luce RD, Fishburn PC. 1991. Rank- and
sign-dependent linear utility models for finite
first-order gambles. J. Risk Uncertain. 4:29–
59
Luce RD, Raiffa H. 1957. Games and Decisions. New York: Wiley
Macdonald RR. 1986. Credible conceptions
and implausible probabilities. Br. J. Math.
Stat. Psychol. 39:15–27
Machina M. 1982. “Expected utility” analysis
without the independence axiom. Econometrica 50:227–324

Manktelow K. 1999. Reasoning and Thinking.
Hove, UK: Psychology Press
March J. 1978. Bounded rationality, ambiguity
and the engineering of choice. Bell J. Econ.
9:587–608
Margolis H. 1987. Patterns, Thinking, and Cognition: A Theory of Judgment. Chicago: Univ.
Chicago Press
Mather M, Shafir E, Johnson MK. 2000. Misremembrance of options past: source monitoring and choice. Psychol. Sci. 11:132–
38
McNeil BJ, Pauker SG, Sox HC, Tversky
A. 1982. On the elicitation of preferences
for alternative therapies. N. Engl. J. Med.
306:1259–62
Mellers BA, Schwartz A, Cooke ADJ. 1998.
Judgment and decision making. Annu. Rev.
Psychol. 49:447–77
Mellers BA, Schwartz A, Ho K, Ritov I. 1997.
Decision affect theory: emotional reactions
to the outcomes of risky options. Psychol.
Sci. 8:423–29
Miller PM, Fagley NS. 1991. The effects of
framing, problem variations, and providing
rationale on choice. Pers. Soc. Psychol. Bull.
17:517–22
Morier DM, Borgida E. 1984. The conjunction
fallacy: a task specific phenomenon? Pers.
Soc. Psychol. Bull. 10:243–52
Neale MA, Northcraft GB. 1986. Experts, amateurs, and refrigerators: comparing expert
and amateur negotiators in a novel task. Org.
Behav. Hum. Decis. Process. 38:305–17
Oakhill J, Garnham A. 1993. On theories of belief bias in syllogistic reasoning. Cognition
46:87–92
Oaksford M, Chater N. 1996. Rational explanation of the selection task. Psychol. Rev.
103:381–91
Osherson DN. 1995. Probability judgment. See
Smith & Osherson 1995, pp. 35–75
Osherson DN, Shafir E, Smith EE. 1994. Extracting the coherent core of human probability judgment. Cognition 50:299–313
Payne JW, Bettman JR, Johnson EJ. 1993. The
Adaptive Decision Maker. Cambridge: Cambridge Univ. Press

<-----Page 24----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY
Pearl J. 1988. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. San Mateo, CA: Morgan Kaufman
Petty RE, Wegener DT. 1999. The elaboration
likelihood model: current status and controversies. See Chaiken & Trope 1999, pp. 37–
72
Politzer G, Noveck IA. 1991. Are conjunction rule violations the result of conversational rule violations? J. Psycholinguist. Res.
20:83–103
Prelec D. 2000. Compound invariant weighting
functions in prospect theory. See Kahneman
& Tversky 2000, pp. 67–92
Pulford BD, Colman AM. 1996. Overconfidence, base rates and outcome positivity/
negativity of predicted events. Br. J. Psychol.
87:431–45
Quattrone G, Tversky A. 1984. Causal versus
diagnostic contingencies: On self-deception
and on the voter’s illusion. J. Pers. Soc. Psychol. 46:237–48
Rabin M. 1998. Psychology and economics. J.
Econ. Lit. 36:11–46
Redelmeier DA, Shafir E. 1995. Medical decision making in situations that offer multiple
alternatives. JAMA 273:302–5
Redelmeier DA, Shafir E, Aujla P. 2001. The
beguiling pursuit of more information. Med.
Decis. Mak. In press
Redelmeier DA, Tversky A. 1990. Discrepancy between medical decisions for individual patients and for groups. N. Engl. J. Med.
322:1162–64
Reed S. 1993. Imagery and discovery. In Imagery, Creativity, and Discovery: A Cognitive Perspective, ed. B Roskos-Ewoldson, MJ
Intons-Peterson, R Anderson, pp. 287–312.
New York: North-Holland
Resnik MD. 1987. Choices: An Introduction to
Decision Theory. Minneapolis: Univ. Minn.
Press
Rips LJ. 1994. The Psychology of Proof. Cambridge, MA: MIT Press
Ross SM. 1997. A First Course in Probability.
Upper Saddle River, NJ: Prentice Hall. 5th
ed.
Rottenstreich Y, Hsee CK. 2001. Money, kis-

515

ses, and electric shocks: on the affective
psychology of risk. Psychol. Sci. 12:185–
90
Rottenstreich Y, Tversky A. 1997. Unpacking,
repacking, and anchoring: advances in support theory. Psychol. Rev. 104:406–15
Russo JE, Dosher BA. 1983. Strategies for
multiattribute binary choice. J. Exp. Psychol.
Learn. Mem. Cogn. 9:676–96
Samuelson W, Zeckhauser R. 1988. Status quo
bias in decision making. J. Risk Uncertain.
1:7–59
Schkade DA, Kahneman D. 1998. Does living
in California make people happy? A focusing illusion in judgments of life satisfaction.
Psychol. Sci. 9:340–46
Schwarz N. 1996. Cognition and Communication: Judgmental Biases, Research Methods,
and the Logic of Conversation. Mahwah, NJ:
Erlbaum
Schwarz N, Clore GL. 1983. Mood, misattribution, and judgments of well-being: informative and directive functions of affective states.
J. Pers. Soc. Psychol. 45:513–23
Schwarz N, Strack F, Hilton D, Naderer G.
1991. Base rates, representativeness, and the
logic of conversation: the contextual relevance of “irrelevant” information. Soc. Cogn.
9:67–84
Sen A. 1993. Internal consistency of choice.
Econometrica 61:495–521
Shafir E. 1993. Intuitions about rationality and
cognition. In Rationality: Psychological and
Philosophical Perspectives, ed. KI Manktelow, DE Over, pp. 260–83. Florence, KY:
Taylor & Francis
Shafir E. 1995. Compatibility in cognition
and decision making. Psychol. Learn. Motiv.
32:247–74
Shafir E, Osherson DN, Smith EE. 1993a. The
advantage model: a comparative theory of
evaluation and choice under risk. Org. Behav. Hum. Decis. Process. 55:325–78
Shafir E, Simonson I, Tversky A. 1993b.
Reason-based choice. Cognition 49:11–36
Shafir E, Tversky A. 1995. Decision making.
See Smith & Osherson 1995, pp. 77–100
Shiffrin RM, Schneider W. 1977. Controlled

<-----Page 25----->30 Nov 2001

11:29

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

516

AR

SHAFIR

AR146-18.tex

¥

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

LeBOEUF

and automatic human information processing: II. Perceptual learning, automatic attending and a general theory. Psychol. Rev.
84:127–90
Sieck W, Yates JF. 1997. Exposition effects
on decision making: choice and confidence
in choice. Org. Behav. Hum. Decis. Process.
70:207–19
Simon HA. 1955. A behavioral model of rational choice. Q. J. Econ. 69:99–118
Simon HA. 1978. Rationality as process and
as product of thought. J. Am. Econ. Assoc.
68:1–16
Simonson I. 1990. The effect of purchase quantity and timing on variety seeking behavior.
J. Mark. Res. 27:150–62
Simonson I, Tversky A. 1992. Choice in context: tradeoff contrast and extremeness aversion. J. Mark. Res. 29:281–95
Sloman SA. 1996. The empirical case for two
systems of reasoning. Psychol. Bull. 119:3–
22
Slovic P, Finucane M, Peters E, MacGregor
DG. 2001. The affect heuristic. See Gilovich
et al. 2001. In press
Slovic P, Griffin D, Tversky A. 1990. Compatibility effects in judgment and choice. In
Insights in Decision Making: Theory and Applications, ed. R Hogarth, pp. 5–27. Chicago:
Univ. Chicago Press
Slovic P, Lichtenstein S. 1983. Preference reversals: a broader perspective. Am. Econ.
Rev. 73:596–605
Slugoski BR, Wilson AE. 1998. Contribution of
conversation skills to the production of judgmental errors. Eur. J. Soc. Psychol. 28:575–
601
Smith EE, Osherson DN, eds. 1995. Thinking:
An Invitation to Cognitive Science, Vol. 3.
Cambridge, MA: MIT Press. 2nd ed.
Smith SM, Levin IP. 1996. Need for cognition
and choice framing effects. J. Behav. Decis.
Mak. 9:283–90
Stalnaker RC. 1984. Inquiry. Cambridge, MA:
MIT Press
Stanovich KE. 1999. Who is Rational? Studies of Individual Differences in Reasoning.
Mahwah, NJ: Erlbaum

Stanovich KE, West RF. 1998a. Cognitive ability and variation in selection task performance. Think. Reasoning 4:193–230
Stanovich KE, West RF. 1998b. Individual differences in framing and conjunction effects.
Think. Reasoning 4:289–317
Stanovich KE, West RF. 1998c. Individual differences in rational thought. J. Exp. Psychol.
Gen. 127:161–88
Stanovich KE, West RF. 1999. Discrepancies
between normative and descriptive models
of decision making and the understanding/
acceptance principle. Cogn. Psychol. 38:
349–85
Stanovich KE, West RF. 2000. Individual differences in reasoning: implications for the
rationality debate? Behav. Brain Sci. 23:645–
726
Stein E. 1996. Without Good Reason: The Rationality Debate in Philosophy and Cognitive
Science. New York: Oxford Univ. Press
Stich SP. 1990. The Fragmentation of Reason:
Preface to a Pragmatic Theory of Cognitive
Evaluation. Cambridge, MA: MIT Press
Sunstein CR, ed. 2000. Behavioral Law and
Economics. Cambridge: Cambridge Univ.
Press
Swets JA, Dawes RM, Monahan J. 2000. Psychological science can improve diagnostic
decisions. Psychol. Sci. Public Interest 1:1–
26
Takemura K. 1993. The effect of decision frame
and decision justification on risky choice.
Jpn. Psychol. Res. 35:36–40
Takemura K. 1994. Influence of elaboration on
the framing of decisions. J. Psychol. 128:33–
39
Tetlock PE. 1992. The impact of accountability on judgment and choice: toward a social
contingency model. In Advances in Experimental Social Psychology, ed. MP Zanna,
25:331–76. New York: Academic
Thaler RH. 1992. The Winner’s Curse: Paradoxes and Anomalies of Economic Life. New
York: Free Press
Thaler RH. 1993. Advances in Behavioral Finance. New York: Russell Sage Found.
Trope Y, Gaunt R. 1999. A dual-process model

<-----Page 26----->30 Nov 2001

11:29

AR

AR146-18.tex

AR146-18.SGM

LaTeX2e(2001/05/10)

P1: GSR

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

RATIONALITY
of overconfident attributional inferences. See
Chaiken & Trope 1999, pp. 161–78
Tversky A. 1972. Elimination by aspects: a theory of choice. Psychol. Rev. 79:281–99
Tversky A. 1975. A critique of expected utility
theory: descriptive and normative considerations. Erkenntnis 9:163–73
Tversky A, Kahneman D. 1973. Availability:
a heuristic for judging frequency and probability. Cogn. Psychol. 5:207–32
Tversky A, Kahneman D. 1974. Judgment under uncertainty: heuristics and biases. Science 185:1124–31
Tversky A, Kahneman D. 1981. The framing of
decisions and psychology of choice. Science
211:453–58
Tversky A, Kahneman D. 1983. Extensional
vs. intuitive reasoning: the conjunction fallacy in probability judgment. Psychol. Rev.
90:293–315
Tversky A, Kahneman D. 1986. Rational
choice and the framing of decisions. J. Bus.
59:251–78
Tversky A, Kahneman D. 1991. Loss aversion in riskless choice: a reference dependent
model. Q. J. Econ. 106:1039–61
Tversky A, Kahneman D. 1992. Advances in
prospect theory: cumulative representation
of uncertainty. J. Risk Uncertain. 5:297–323
Tversky A, Koehler DJ. 1994. Support theory:
a nonextensional representation of subjective
probability. Psychol. Rev. 101:547–67
Tversky A, Sattath S, Slovic P. 1988. Contingent weighting in judgment and choice.
Psychol. Rev. 95:371–84
Tversky A, Shafir E. 1992a. Choice under conflict: the dynamics of deferred decision. Psychol. Sci. 3:358–61
Tversky A, Shafir E. 1992b. The disjunction
effect in choice under uncertainty. Psychol.
Sci. 3:305–9
Tversky A, Simonson I. 1993. Context dependent preferences: the relative advantage
model. Manage. Sci. 39:1179–89

517

Tversky A, Slovic P, Kahneman D. 1990. The
causes of preference reversal. Am. Econ. Rev.
80:204–17
Tversky A, Wakker P. 1995. Risk attitudes and
decision weights. Econometrica 63:1255–
80
Vallone RP, Griffin DW, Lin S, Ross L. 1990.
Overconfident prediction of future actions
and outcomes by self and others. J. Pers. Soc.
Psychol. 58:568–81
Van Boven L, Dunning D, Loewenstein
G. 2000. Egocentric empathy gaps between
owners and buyers: misperceptions of the endowment effect. J. Pers. Soc. Psychol. 79:66–
76
von Mises R. 1957. Probability, Statistics, and
Truth. New York: Dover
von Winterfeld D, Edwards W. 1986. Decision Analysis and Behavioral Research.
Cambridge: Cambridge Univ. Press
Wason PC. 1966. Reasoning. In New Horizons
in Psychology 1, ed. B Foss, pp. 135–51. Harmondsworth, UK: Penguin
Wetherick NE. 1971. Representativeness in a
reasoning problem: a reply to Shapiro. Bull.
Br. Psychol. Soc. 24:213–14
Wilson TD, Houston CE, Etling KM, Brekke
N. 1996. A new look at anchoring effects:
basic anchoring and its antecedents. J. Exp.
Psychol. Gen. 125:387–402
Wilson TD, Wheatley T, Meyers JM, Gilbert
DT, Axsom D. 2000. Focalism: a source
of durability bias in affective forecasting. J.
Pers. Soc. Psychol. 78:821–36
Wright WF, Anderson U. 1989. Effects of situation familiarity and financial incentives on
use of the anchoring and adjustment heuristic for probability assessment. Org. Behav.
Hum. Decis. Process. 44:68–82
Yates JF. 1990. Judgment and Decision Making.
Englewood Cliffs, NJ: Prentice-Hall
Zajonc RB. 1980. Feeling and thinking: preferences need no inferences. Am. Psychol.
35:151–75

<-----Page 27----->P1: FDS

December 4, 2001

14:39

Annual Reviews

AR146-FM

Annual Review of Psychology
Volume 53, 2002

CONTENTS
Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

Frontispiece—Endel Tulving
PREFATORY
Episodic Memory: From Mind to Brain, Endel Tulving
GENETICS OF BEHAVIOR
Genetic Contributions to Addiction, John C. Crabbe

xvi
1
435

BRAIN IMAGING/COGNITIVE NEUROSCIENCE
Child-Clinical/Pediatric Neuropsychology: Some Recent Advances,
Byron P. Rourke, S. A. Ahmad, D. W. Collins, B. A. Hayman-Abello,
S. E. Hayman-Abello, and E. M. Warriner

AUDITION AND ITS BIOLOGICAL BASES
Change Detection, Ronald A. Rensink
MEMORY
Remembering Over the Short-Term: The Case Against the Standard
Model, James S. Nairne

309
245

53

JUDGMENT AND DECISION MAKING
Rationality, Eldar Shafir and Robyn A. LeBoeuf

491

BIOLOGICAL AND GENETIC PROCESSES IN DEVELOPMENT
Gene-Environment Interplay in Relation to Emotional and
Behavioral Disturbance, Michael Rutter and Judy Silberg

463

DEVELOPMENT IN SOCIETAL CONTEXT
Socioeconomic Status and Child Development, Robert H. Bradley
and Robert F. Corwyn

371

MOOD DISORDERS
Depression: Perspectives from Affective Neuroscience, Richard J.
Davidson, Diego Pizzagalli, Jack B. Nitschke, and Katherine Putnam

PSYCHOPATHOLOGY: VARIOUS DISORDERS
Causes of Eating Disorders, Janet Polivy and C. Peter Herman
vi

545
187

<-----Page 28----->P1: FDS

December 4, 2001

14:39

Annual Reviews

AR146-FM

CONTENTS

Insomnia: Conceptual Issues in the Development, Maintenance
and Treatment of Sleep Disorder in Adults, Colin A. Espie

vii

215

CLINICAL ASSESSMENT
Clinical Assessment, James M. Wood, Howard N. Garb,
Scott O. Lilienfeld, and M. Teresa Nezworski

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

ADULT CLINICAL NEUROPSYCHOLOGY
Adult Clinical Neuropsychology: Lessons from Studies of the
Frontal Lobes, Donald T. Stuss and Brian Levine

519

401

SELF AND IDENTITY
Self and Social Identity, Naomi Ellemers, Russell Spears,
and Bertjan Doosje

ALTRUISM AND AGGRESSION
Human Aggression, Craig A. Anderson and Brad J. Bushman
INTERGROUP RELATIONS, STIGMA, STEREOTYPING, PREJUDICE,
DISCRIMINATION
Intergroup Bias, Miles Hewstone, Mark Rubin, and Hazel Willis

161
27

575

CULTURAL INFLUENCES
Cultural Influences on Personality, Harry C. Triandis
and Eunkook M. Suh

133

ORGANIZATIONAL PSYCHOLOGY OR ORGANIZATIONAL BEHAVIOR
Organizational Behavior: Affect in the Workplace, Arthur Brief
and Howard Weiss

279

LEARNING AND PERFORMANCE IN EDUCATIONAL SETTINGS
Motivational Beliefs, Values, and Goals, Jacquelynne S. Eccles
and Allan Wigfield

109

PSYCHOBIOLOGICAL FACTORS IN HEALTH
Emotions, Morbidity, and Mortality: New Perspectives from
Psychoneuroimmunology, Janice K. Kiecolt-Glaser, Lynanne
McGuire, Theodore F. Robles, and Ronald Glaser

83

PSYCHOPHYSIOLOGICAL DISORDERS AND PSYCHOLOGICAL EFFECTS
ON MEDICAL DISORDERS
Effects of Psychological and Social Factors on Organic Disease:
A Critical Assessment of Research on Coronary Heart Disease,
David S. Krantz and Melissa K. McCeney

341

<-----Page 29----->P1: FDS

December 4, 2001

viii

14:39

Annual Reviews

AR146-FM

CONTENTS

ANALYSIS OF LATENT VARIABLES
Latent Variables in Psychology and the Social Sciences,
Kenneth A. Bollen

605

INDEXES

Annu. Rev. Psychol. 2002.53:491-517. Downloaded from www.annualreviews.org
by University of Waterloo on 05/06/11. For personal use only.

Author Index
Subject Index
Cumulative Index of Contributing Authors, Volumes 43–53
Cumulative Index of Chapter Titles, Volumes 43–53

ERRATA
Online log of corrections to the Annual Review of Psychology corrections:
Steven Regeser López and Peter J. Guarnaccia
Cultural Psychopathology: Uncovering the Social World
of Mental Illness
Annu. Rev. Psychol. 2000, Vol. 51: 571–598.
http://psych.annualreviews.org/errata.shtml

635
679
705
709

