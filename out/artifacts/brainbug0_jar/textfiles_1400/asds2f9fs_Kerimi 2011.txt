<-----Page 0----->Decision Strategies
Something Old, Something New, and Something Borrowed
Neda Kerimi
Doctoral Thesis in Psychology at Stockholm University, Sweden 2011

<-----Page 1-----><-----Page 2----->Decision Strategies
S o m e t h i n g O l d , S o m e t h i n g N e w, a n d
Something Borrowed

Neda Kerimi

<-----Page 3----->©Neda Kerimi, Stockholm 2011
ISBN 978-91-7447-294-3
Printed in Sweden by US-AB, Stockholm 2011
Distributor: The Department of Psychology, Stockholm University, Sweden

<-----Page 4----->To life and those who make
it enjoyable....

<-----Page 5-----><-----Page 6----->Abstract

In this thesis, some old decision strategies are investigated and a new one
that furthers our understanding of how decisions are made is introduced.
Three studies are presented. In Study I and II, strategies are investigated in
terms of inferences and in Study III, strategies are investigated in terms of
preferences. Inferences refer to decisions regarding facts, e.g., whether a
patient has a heart disease or not. Preferences refer to decision makers’ personal preferences between different choice alternatives, e.g., which flat out
of many to choose. In all three studies, both non-compensatory strategies and
compensatory strategies were investigated. In compensatory strategies, a
high value in one attribute cannot compensate for a low value in another,
while in non-compensatory strategies such compensation is possible. Results
from Study I showed that both compensatory (logistic regression) and noncompensatory (fast and frugal) strategies make inferences equally well, but
logistic regression strategies are more frugal (i.e., use fewer cues) than the
fast and frugal strategies. Study II showed that the results were independent
of the degree of expertise. The good inferential ability of both noncompensatory and compensatory strategies suggests there might be room for
a strategy that can combine the strengths of the two. Study III introduces
such a strategy, the Concordant-ranks (CR) strategy. Results from Study III
showed that choices and attractiveness evaluations followed this new strategy. This strategy dictates a choice of an alternative with concordant ranks
between attribute values and attribute weights when alternatives are about
equally attractive. CR also serves as a proxy for finding the alternative with
the shortest distance to an ideal. The CR strategy combines the computational simplicity of non-compensatory strategies with the superior information
integration ability of compensatory strategies.

<-----Page 7-----><-----Page 8----->Acknowledgements

Don’t count the days, make the
days count.
~Mohammed Ali

It is common conception that writing the final thesis (kappa) is the most
difficult and emaciating part of the PhD process. Maybe I am an outlier, but
writing this thesis has been the most gratifying part of my time as a PhD
student. Mostly, because As Frank Sinatra said “I did I my way”. I planned it
my way, wrote it my way, using my words and my way of telling things and
I have never been so satisfied. The second most gratifying part was the discussions, idea exchanges, stimulating talks, and collaborations that I have
had the privilege to have with those people who have supported and encouraged me in my pursue as a researcher. I would like to show my gratitude to
some of them.
A special gratitude goes to my supervisors, which I admire in so many ways.
Prof. Henry Montgomery, my academic father, you are one of the most intelligent and humble human beings I know. You accepted me as I was and let
me be who I am. You taught me to speak with my data and understand what
is saying, you thought me the language of research. You are the definition of
a true researcher. Thank you Prof. Peter Juslin for giving me inspiration and
motivation in dark days and making me feel welcome. Your humbleness
despite your high intelligence is a true inspiration. My respect for you has
only grown. Thank you Dr. Fredrik Jönsson for treating me as a peer and
giving me the strength and courage to continue. You were one of the few
people that I felt I could talk to. You understood my language even though I
sometimes spoke jiddisch. Thank you for making me fall in love with research again.
A warm gratitude goes to my colleagues who took the time to read and
comment on this dissertation: Håkan Nillson, Ebba Elwin, Maria Henriksson, Markus Lindskog, Anders Winman, Marianne Jakobson, and Gustav
Törngren. In addition, I want to thank my co-authors Lars Backlund, Ylva
Skånér, Lars-Erik Strender, and Dan Zakay. Working with you has been
rewarding.
I also want to thank some of the people at the department of psychology.
Emma Bäck, you were there for me when everybody else failed, something
that I will always remember. Anna Lindquist, you are a true ray of light.
Thank you for encouraging me to continue being me and giving me pep talks

<-----Page 9----->when the path felt so steep. Emma and Anna, I don’t know what I would
have done without our fika moments. My time as a doctoral student had not
been bearable without you two and I hope that I will always have you in my
life.
Tonya Pixton, my academic twin, during the writing of this thesis, you have
given me courage and energy to continue. What is so special with you is that
you did not even need to push yourself to do that. You were just being you.
Dr. Mats Englund, you actually know more (sometimes but not always)
about computers than I do, even though I pretend otherwise. Caroline Cederström, you are the most down-to-earth human being I know. Hope to
have you as a travel companion again; Shiraz next? Dr. Farah Moniri, you
are one of the most altruistic human beings I know. Don’t ever change. Dr.
Mats Nilsson. The encounters I have had with you have been very inspirational and guiding. I really enjoy talking research with you. All my respects
to you. Shahin Foladi, I am so glad that we have you. You are a philanthrope. Always ready to help.
Moreover, I would like to thank the following people in no special order:
Hans Fornlind (the sweetest man in the department), Dr. Henrik Olsson (can
just say wow, I wish I was as smart as you), Munnever Malgir (a person
defining strength and cherish), Margareta Hedner (a youth full of energy),
Martin Arvidsson (the know-it-all who actually knows a lot), Prof. Birgitta
Berglund (genuine researcher), Britth Sandin (sweet and motherly), Dr. Ola
Sternäng (the skåning with wearing a t-shirt of Timbuktu!!!), Artin Arshamian (movie enthusiast!!!), Ninni Persson (a fair fighter). and Henrik Duner
(always ready to help). Other I would like to thank are Dr. Heidi Selenius ,
Dr. Nathalie Peire, Dr. Johan Willander, Dr. Elisabeth Borg, Jesper Alvarsson, Håkan Andersson, Ewa Sjöqvist, Kristina Danilov, Niclas Hansen, Dr.
Lars Häsänen, and Malena Ivarsson. You were the fun part in this trip. I
hope to have you as the fun part also in my future trips.
A special thank goes to my mentor Prof. Maria Larsson, you have no idea
how much of a guiding star you have been for me. Moreover, many thanks
to Prof. Torun Lindholm for encouragement and a shoulder to cry on. Prof.
Ola Svenson, all my respects and gratitude to you. Your advises kept me on
track when the road was slippery.
I also want to take this opportunity to thank Prof. Jay Russo, Anne-Sophie
Chaxel, Prof. Tom Gilovich, Sara Larsson, Karin Lilja, and Maria Asseily
who all made my visit at Cornell so much more pleasant. I had the time of
my life.
A special thank and gratitude goes to my beloved family. First and foremost,
my parents Zara and Nasrollah, the struggles that you have dealt with has

<-----Page 10----->given me the strength to rise up, and above. I hope I have made you proud.
Second, my sisters and brothers, Afsaneh, Reza, Nahid, Mohammad, and
Pejman. I am still dreaming of seeing you soon in a “for-the-first-timefamily-re-union”. The love and cherish you have shown me are invaluable.
We are spread all over the world but I think of you every day. I hope you all
know the love and cherish I feel for you is immeasurable. Third, I also want
to take the opportunity to thank Javad Ghodsi and Nahid Tahmasby, who
helped me more than they probably know during the writing of this thesis.
Shukri Omar, Anoshé Ghodsi, and Mina Taghivand, thank you. Ali, you are
my best friend and nobody has been there for me the way you have (you
didn’t have much choice). When I was down you lifted me up but you also
made sure to keep me on ground. You mentored me and showed me the way.
I am who I am and where I am because of your guidance, support and endless love.
A very special and warm gratitude to you. You know who you are and I will
never forget you.
Finally, a very special gratitude goes to Jane, which patiently let me use and
abuse her in my thesis. I hope that the decision situations I have put you
through have not traumatized you for life. However if they have made it
more difficult for you to make decisions, then my advice to you is to use the
CR strategy. It will probably make your life easier.
I want to add a final note regarding writing this acknowledgment. Writing a
acknowledgment is harder than many think. When I finally managed finishing it (actually, I don’t think you ever finish writing an acknowledgment) I
realized that I have many names in it. For a long time, I thought that the
more names you have the more diluted will their impact become. However,
caught by a moment of sanity I realized that I am so lucky to have so many
names. Because this means I have been fortunate to have many people companying me on this journey. Having many people does not mean that they
are less important, but that my trip as a PhD student has been so much richer
and so much more fun. Thank you all.

<-----Page 11-----><-----Page 12----->List of Studies

The present doctorial thesis is based on the following studies:
I.

Kerimi, N., Backlund, G. L., Skånér, Y., Strender, L-E., Montgomery,
H. (submitted). Judgment Analysis in the Medical Domain: Making a
Fair Comparison Between Logistic Regression and Fast & Frugal
Models.

II.

Kerimi, N., Backlund, G. L., Skånér, Y., Strender, L-E., Montgomery,
H. (submitted). Do We Really Need Medical Experts when Modeling
in Judgment Analysis? Lack of Difference Between Experts and NonExperts in Judgment Analysis.

III.

Kerimi, N., Montgomery, H., Zakay, D. (2011). Coming Close to The
Ideal Alternative: The Concordant-Ranks Strategy. Judgment and
Decision Making, 6, 196-210.

<-----Page 13-----><-----Page 14----->Contents

Abstract ....................................................................................................... vii
Acknowledgements .................................................................................... ix
List of Studies.............................................................................................xiii
Contents ...................................................................................................... xv
Introduction ................................................................................................ 17
Rationality ................................................................................................................. 18
Classical and bounded rationality ................................................................... 18
Coherence and correspondence ...................................................................... 19
Models of decision making ..................................................................................... 20
Decision strategies .................................................................................................. 21
Information processing in decision strategies .................................................... 21
Limited cognitive capacity ................................................................................ 21
Beyond limited cognitive capacity ................................................................... 22
Compensatory decision strategies .................................................................. 23
Non-compensatory decision strategies .......................................................... 24
Compensatory vs. non-compensatory decision strategies ......................... 24
Decision strategies in a nutshell...................................................................... 25
Information processing by experts ...................................................................... 25
Expertise and different types of decisions ..................................................... 26
Examples of decision strategies and related theories....................................... 27
Multiattribute utility rule ................................................................................... 27
Prospect theory .................................................................................................. 28
Distances ............................................................................................................. 28
Heuristics ............................................................................................................. 30
Examples of decision strategies and related theories in a nutshell .......... 32
Judgment Analysis .................................................................................................. 33
Regression models in judgment analysis....................................................... 34
Fast and frugal models in judgment analysis ............................................... 35
Regression vs. Fast and frugal models .......................................................... 35
Judgment analysis in a nutshell ...................................................................... 36

<-----Page 15----->Research objectives .................................................................................. 37
Empirical Studies ....................................................................................... 39
Study I - Comparison of decision strategies using judgment analysis .......... 39
Aim ....................................................................................................................... 39
Method ................................................................................................................. 40
Results and discussion ...................................................................................... 41
Conclusion ........................................................................................................... 48
Study II - Comparing decision strategies while controlling for expertise ..... 48
Aim ....................................................................................................................... 48
Method ................................................................................................................. 49
Results and discussion ...................................................................................... 49
Conclusion ........................................................................................................... 50
Study III – The “New” Concordant-ranks Strategy........................................... 51
Aim ....................................................................................................................... 51
What is “The Concordant-Ranks Strategy”?.................................................. 52
Method ................................................................................................................. 53
Results and discussion – Experiment 1.......................................................... 55
Results and discussion – Experiment 2.......................................................... 56
Conclusion ........................................................................................................... 56

Discussion ................................................................................................... 57
Main Findings ........................................................................................................... 57
Something old..................................................................................................... 57
Something new................................................................................................... 61
Something borrowed ......................................................................................... 64
Something to remember................................................................................... 65
Points of caution ...................................................................................................... 66
Future Research....................................................................................................... 67

References .................................................................................................. 69
Appendix...................................................................................................... 79
Appendix A – Experiment procedure in Study III.............................................. 79

<-----Page 16----->Introduction

As soon as questions of will or decision or reason or choice of action
arise, human science is at a loss.
~Noam Chomsky

Making decisions is a part of everyday life that we cannot ignore. For example, a bride, let us call her Jane, about to get married has to make a multitude
of decisions. Some of these decisions are based on an old saying “Something
Old, Something New, Something Borrowed…”1, where she has to find something in each of these categories to have a happy marriage. This saying is
also applicable in research where you can study “old” theories, come up with
a “new” theory that can be “borrowed” or built on the “old” theories. In this
thesis, I will present some “old” decision strategies (Study I, II, and III). I
will afterwards present a “new” strategy (Study III), explain how this “new”
strategy relates to and how it might have “borrowed” some of the strengths
of the “old” strategies.
Before I get into “Something Old, Something New, and Something Borrowed”, I will present different views on rationality underlying research in
decision making. These different views on human rationality have led to the
identification of different models and strategies in decision making, which I
will describe. One thing that differentiates decision strategies from each
other is how they utilize information. I will focus on how individuals process
information in these different decision strategies. Which decision strategies
humans use and how they utilize information is also dependent on degrees of
expertise. Therefore, I will also give a short review of the different views on
expertise in decision making.
Finally, before I present results from three studies, I will describe judgment
analysis, which is a commonly used method in decision making research
when decisions concern inferences of possible facts, for example, whether a
patient has a heart disease or not. Studies I and II use judgment analysis and
are, hence, focused on inferential decisions. By contrast, Study III concerns
decisions involving preferences. Preferences refer to decision makers’ personal preferences between different choice alternatives, for example which
flat out of many to choose.
Before starting, it is necessary to find a proper definition of what decision
making is. In this thesis, I will depart from the following definition of deci1

This is a saying dating back to the Victorian era. It is supposed to bring good luck if the
bride ensures that she has something of each category in her wedding outfit.
17

<-----Page 17----->sion making: “a choice set of options or courses of action, a background of
controllable and uncontrollable events that determine the outcome of the
action-event combination that occurs, and subjective satisfaction that is a
consequence of the objective outcome.” (Hastie & Pennington, 1995, p. 1).
It is also necessary to clarify the differences between decision-making and
judgment. In connection to a decision, individuals make several judgments,
such as judgments of probabilities and values of aspects characterizing the
choice alternatives. Judgments may also be holistic and integrate several
more specific judgments, but still differ from decisions in that they do not
designate the choice of a particular alternative. Thus, decision making and
judgment are closely intertwined, but not synonymous. Therefore, the research field in psychology is labeled judgment and decision making (Koehler & Harvey, 2004). In this thesis, I focus mostly on decision making, both
in inferential decisions (Study I and II), and in preferential decisions (Study
III). In Study III, I will also present data on holistic evaluative judgments of
choice alternatives.
It is difficult to talk about judgment and decision making without mentioning
and describing rationality. Assumptions of rationality underlie most of the
research conducted in decision making (e.g., Gigerenzer, 2007; Hammond,
2007). Next, I will give an account for rationality and how it is defined in
psychology.

Rationality
Classical and bounded rationality
Decision making is evaluated as being a more or less rational process depending on how it is defined. The definitions of rationality differ depending
on two views: classical rationality and bounded rationality. According to
classical rationality, decision makers such as Jane follow a rational decision
process and know exactly which and what information she needs in order to
make an optimal decision (Bicchieri, 1993). According to bounded rationality, Jane has limited access to information and limited cognitive capacity that
limits her decision making. Simon (1982; 1991) argued bounded rationality
is like a pair of scissors in which one blade represents the computational
capacities of Jane, and the other blade represents the environment in which
Jane uses her capacity. The scissor will only work if the two blades fit and
work together. Moreover, Simon (1982; 1991) argued that Jane has adapted
to the environment and as a result, based on the information she has, she will
try to make satisfying rather than optimal, decisions. Because decision makers, such as Jane, have time constrains and limited cognitive capacity, they
18

<-----Page 18----->use heuristics rather than rigid and utility maximizing computations (Augier,
2000).
Related to bounded rationality is Brunswick’s lens model (Brunswick, 1952;
Wolf, 2000). The lens model describes the difference between the environment (e.g., a disease) and how an individual observes the environment. In
addition, this model describes how the individual adapts and reacts to the
difference in the two based on cues or information (e.g., symptoms of a disease) in the environment. Brunswick argued that to understand human decision making or cognition in general, the environment in which the decision
making is taking place should also be studied.

Coherence and correspondence
Rationality is associated with the notions of coherence and correspondence.
According to coherence theories, Jane is rational when her decisions are
coherent with logic or statistical norms. According to correspondence theories, Jane is rational if her decision works well or is fitted to the environment. Hammond (1990, 1996) argued that those who look for coherence will
find human beings as irrational while those who look for correspondence
will find human beings as adaptive.
The research of Kahneman and Tversky (1973) used the coherence approach
as a background for identifying biases in judgment and decision making.
They suggested that to overcome the limitations of classical rationality, researchers have to understand the heuristics and biases in people’s decision
making. It is only when these heuristics and biases are understood that researchers can provide guidelines to improve decision making. Gigerenzer
and colleagues (2002), using the correspondence approach to study judgment
and decision making, argue that Simon’s (1982) bounded rationality is misinterpreted. For instance, they argue that some decision strategies do not
explain or consider how and when the information search should stop (Gigerenzer, Todd & The ABC research group, 1999). Gigerenzer suggested an
“adaptive toolbox”, consisting of simple heuristics that decision makers use
and which lead to better decisions than most of the utility-optimization theories (Gigerenzer & Selten, 2002; Gigerenzer et al., 1999). This view came
later to be called ecological rationality (Gigerenzer et al., 1999). Hammond
argues that the study of human judgment and decision making cannot go
forward without the use of both coherence and correspondence approaches
(Hammond, 2007).
Similar to most psychological scientists, I do not believe that humans are
perfectly rational. Instead, they are boundedly rational because of, among
other things, limited cognitive capacity. In this thesis, I will investigate different decision strategies, which either fall into the group of classical ratio19

<-----Page 19----->nality (e.g., MAU) or bounded rationality (e.g., elimination by aspects, EBA
and fast and frugal heuristics).

Models of decision making
Baron (2008) divides the decision models into three categories: descriptive,
normative, and prescriptive. The aim of descriptive models is to describe
how decision makers, such as Jane, actually make decisions. Heuristics,
which are rules of thumbs, can provide such descriptions. Here the description of how Jane makes a decision is usually compared with some ideal way
of making decisions. This leads us to normative models.
The aim of normative models is to provide policies or axioms that can aid
Jane to make an optimal and rational decision in a certain decision situation.
Note that Jane cannot use normative models as such because they are often
too computation demanding or time-consuming (Baron, 2008), which leads
us to prescriptive models.
The aim of prescriptive models is to model or create prescriptions of how
humans should make decisions. Similar to the descriptive models, the prescriptive models can be different heuristics or rules of thumb. Because of the
complex nature of decision making, there is not only one prescriptive model
for all situations.
Jane’s choice of a wedding ring will provide us with an example of the differences between descriptive, normative, and prescriptive models. Most
normative models postulate that if Jane prefers sapphire rings (A) to diamond rings (B), and diamond rings (B) to emerald rings (C), then she
should also prefer sapphire rings (A) to emerald rings (C). However, in a
descriptive model (i.e., how decision makers actually made decisions), decision makers can be intransitive. For instance, Jane might prefer sapphire
rings (A) to diamond rings (B), diamond rings (B) to emerald rings (C), but
prefer emerald rings (C) to sapphire rings (A). One reason for this intransitivity can be that when Jane compares sapphire rings (A) with diamond rings
(B), certain attributes are emphasized, while when sapphire rings (A) are
compared to emerald rings (C), other attributes are emphasized. So, from a
normative point of view, Jane should be transitive and choose sapphire rings
(A) while from a descriptive point of view, she will choose emerald rings
(C). A prescriptive point of view could be that Jane should choose the stone
ring that gives her highest satisfaction but this can be ring A (from a normative point of view) or ring C (from a descriptive point of view). Therefore,
the prescriptive models provide Jane with a guideline of how to find, for
example, a balance between normative and descriptive models. For instance,
a guideline of how to evaluate different attributes of the rings (for example
20

<-----Page 20----->color) so that eventually the differences between the rings become transitive
(i.e., sapphire rings are more beautiful than diamond rings, diamond rings
are more beautiful than emerald rings. Therefore, sapphire rings should also
be more beautiful than emerald rings).
In this thesis, I will investigate decision strategies in all three types of models: descriptive (e.g., EBA and Lexicographic), prescriptive (e.g., fast and
frugal models), and normative (e.g., Maximin and MAU). Some of these
decision strategies can be categorized into two of the models (e.g., MAU,
which can be both prescriptive and normative), but only one strategy, the CR
strategy, which will be introduced and explained in Study III, can be categorized in into all three models.

Decision strategies
Payne, Bettman, and Johnson (1995) defines a decision strategy as ”a sequence of mental and effector (actions on the environment) operations that
transform some initial state of knowledge into a final knowledge state so that
the decision maker perceives that the particular decision problem is solved.”
(p. 140).
Usually decision makers have a repertoire of decision strategies, acquired by
experience or prior exposure to those strategies (e.g., Larrick, Morgan, &
Nisbett, 1990). The majority of the times, decision makers want to use the
strategy that requires a minimum effort while at the same time leads to the
choice of the best alternative (Beach & Mitchell, 1978; Klayman, 1983; Russo & Dosher, 1983; Shugan, 1980). One important, if not the most important,
component in decision strategies is how decision makers process information.

Information processing in decision strategies
Limited cognitive capacity
The way information is processed while making decisions has drawn much
attention (e.g., Fischhoff, Slovic, & Lichtenstein, 1978; Griffin, Dunning, &
Ross, 1990; Ross, 1987, 1989; Slovic & MacPhillamy, 1974; Yates, Jagacinski, & Faber, 1978). Newell and Simon (1972) coined the term information processing theory, which describes how individuals process information
when they make decisions. Specifically, the theory describes the cognitive
system and the environment in which information is processed. Proponents
argue that when researchers study the cognitive limitations of decision mak21

<-----Page 21----->ers, they must also study how decision makers search and process information in complex environments (Newell & Simon, 1972). The information
processing limitations are compatible with the notion that humans are selective in which information they attend to (Simon, 1978). For example, Russo,
Medvec, and Meloy (1996) found that existing preferences could lead to
distortion of new information in support of a chosen alternative. This, they
explained, is because individuals desire to maintain a consistency in their
beliefs and reduce the effort of making a decision by confirming already setup preferences and rejecting information that goes against the chosen alternative. Using related theoretical perspectives, other researchers have reported similar findings (e.g., Backlund, Skånér, Montgomery, Bring, &
Strender, 2003; Dahlstrand & Montgomery, 1984; Holyoak & Simon, 1999;
Kuhl, 1984).

Beyond limited cognitive capacity
The sequential sampling process (Busemeyer & Johnson, 2004) gives another view on how a decision maker deals with limited cognitive capacity. In a
sequential sampling process, different alternatives and different pieces of
information are taken in and processed until one alternative or piece of information exceeds a certain threshold (Newell, 2005). Newell and Bröder
(2008) argue that the study of how humans process information should consider not only (i) the limited cognitive capacity, but also (ii) the dual nature
of information processing, (iii) the learning ability, and (iv) the regulation
capacity or metacognition.
The dual nature of information processing
As for the dual nature of information processing, many theories have been
formulated through the years (e.g., Kahneman & Frederick, 2002; Newell &
Simon, 1972; Sloman, 1996; Slovic, Finucane, Peter, & McGregor, 2002).
The view of the information processing as a dual system has drawn much
attention, received many names, and gone through several modifications (for
reviews see Baumeister, 2005; Paivio, 2007; Sun, 2002). However, most of
these theories share the common view that there are two types of information
processes - automatic processes that are unconscious, fast, and associative,
and controlled processes that are conscious, slower, and limited by the capacity of the working memory.
Glöckner and Betsch (2008) argued that researchers have focused too much
on the controlled processes and that the automatic processes might be more
involved in decision making than earlier stated. They presented data confirming that decision makers use associative and integrated information that
is stored in the memory and activated as a connected network. This in its
turn allows for an additive or multiplicative type of information integration
(Glöckner & Betsch, 2008; Juslin, Jones, Olsson, & Winman, 2003). This
22

<-----Page 22----->network connects the information in such a way that one alternative is perceived as superior and finally chosen (Glöckner & Betsch, 2008).
The learning ability
Several studies have shown that learning is important for how we process
information and that learning can help to develop and improve decisions (for
examples see Barron & Erev, 2003; Erev & Barron, 2005; Newell & Rakow,
2007; Newell, Lagnado & Shanks, 2007). An example of theories adapting
this view is categorization theories, which I will describe in more detail later
in this thesis.
The regulation capacity
There is a large body of research on how thinking and attentive regulation
impacts what information individuals search and utilize to make decisions
(Jönsson & Kerimi, 2010; Metcalfe & Finn, 2008). Regulation capacity refers to judgments of how to decide and therefore, how to allocate a piece of
the limited capacity to produce the best decision (Newell & Bröder, 2008).
The study of compensatory and non-compensatory decision strategies can
also shed light on how information is processed in decision making situations. Next, I will explain compensatory and non-compensatory strategies in
more detail.

Compensatory decision strategies
In compensatory decision strategies, an attractive or high value on one
attribute in an alternative can compensate an unattractive or low value on
another attribute (Montgomery & Svenson, 1976; Svenson, 1979). Compensatory decision strategies require the decision maker to identify all possible
attributes that can influence the decision. For instance, if Jane needs to
choose between which catering firms out of different alternatives to hire,
then she must identify all the attributes that have an impact on her final decision. She will then calculate an overall value based on the impact each
attribute (i.e., how important the food quality is) has on her final decision,
and then choose the catering firm with the highest value. Because there is an
overall value for each catering firm, attractive attribute values (e.g., high
food quality) can compensate unattractive attribute values (e.g., expensive).
Compensatory decision strategies are more analytical (Beach & Mitchell,
1978) and applicable in more situations, but may be more difficult to use.
These strategies are typically seen as complex and require much information
processing, which can be problematic for decision makers (Chater, Oaksford, Nakisa, & Reddington, 2003).

23

<-----Page 23----->Non-compensatory decision strategies
By contrast, in non-compensatory decision strategies, attractive attribute
values cannot compensate unattractive attribute values (Elrod, Johnson &
White, 2004). This puts less cognitive load on the decision maker, for instance, in the catering firm example, Jane might prefer the catering firm
which offers higher food quality. This firm might be more expensive but she
cannot compensate an unattractive attribute value (low food quality) with an
attractive attribute value (cheaper). Non-compensatory strategies are less
analytic and easier to use (Beach & Mitchell, 1978) because they do not
require the decision maker to compare one attribute to a completely different
attribute. However, they are not optimal because they can lead to missing
important information. One example of a non-compensatory strategy is the
Lexicographic strategy where the alternative that is best on the most important attribute is chosen (Gigerenzer & Goldstein, 1996; Gigerenzer et al.,
1999) In Study I, II, and III, I study and compare both compensatory and
non-compensatory decision strategies.

Compensatory vs. non-compensatory decision strategies
There are studies showing that compensatory strategies are not as difficult or
demanding to use as previously stated. In addition, recent research suggests
that the experimental design of previous studies, which have presented evidence for non-compensatory strategies, might have forced decision makers
to think in a non-compensatory manner (e.g., Bröder, 2000, 2003; Bröder &
Schiffer, 2003; Glöckner & Betsch, 2008). Furthermore, compensatory decision strategies might be preferred because decision makers want to have
access to all the available information (for a review see Newell & Shanks,
2007). For example, Lindeman and Markman (1996) found that individuals
prefer comparable attributes more than non-comparable, which may make it
natural to use compensatory rather than non-compensatory decision strategies in situations where attributes are comparable. In their study, they provided students with important non-comparable information and lessimportant comparable information about different colleges. They found that
the students preferred the comparable information even though it was less
important. Because of the traditional view that non-compensatory decisions
require less effort (Gigerenzer et al., 1999), Bröder and Schiffer (2003) reasoned that more cognitive capacity should result in using more advanced and
compensatory strategies. Therefore, they limited participants’ cognitive capacity by putting a high cognitive load on them. Their results showed that
decision makers use compensatory strategies even under greater cognitive
load and the difference was between the choices of a strategy rather than
how decision makers executed a strategy. In Study III, I will adapt this view
and suggest a decision strategy that, similar to compensatory decision strate-

24

<-----Page 24----->gies, search more information while at the same time, similar to noncompensatory decision strategies, is easier to use.

Decision strategies in a nutshell
In a nutshell, strategies differ from each other in the way information is utilized. Newell and Bröder (2008) define information processing consisting of
four interplaying parts: the cognitive capacity of humans, the dual nature of
information processing, the learning ability, and metacognition. Another way
of viewing how information is processed in different decision strategies is
provided by the compensatory (an attribute compensating a different
attribute) and non-compensatory (an attribute cannot compensate for other
attributes) view. I believe that many situations require the use of compensatory decision strategies compared to non-compensatory decision strategies.
In this thesis, I will show that, similar to recent research (e.g., Glöckner &
Betsch, 2008), decision makers can use strategies that require the integration
of different pieces of information in a more nuanced way (Study I, II, and
III).

Information processing by experts
How individuals search information, and which decision strategies they use
can be related to expertise. There is a large body of research on what makes
an expert (e.g., Elstein, Shulman & Sprafka, 1978; Ericsson, Charness, Feltovich, & Hoffman, 2006; Ericsson, Roaring, & Nandagopal, 2007; Patel,
Arocha, & Kaufman, 1999; Posner, 1988; Shanteau, 1991; 1992; Wineburg,
1998). Meyer and Booker (2001) defined an expert as “a person who has
background in the subject area and is recognized by his or her peers or
those conducting the study as qualified to answer questions” (p. 3). Similarly, Shanteau argues that those in the domain of the expert should be the ones
defining expertise (Shanteau, 1987, 1988, 1991).
Experts can have different degrees of expertise and several classification
systems of levels of expertise have been proposed (e.g., Brehmer & Brehmer, 1988; Ericsson & Lehman, 1996; Shanteau, 1988). Shanteau (1988)
suggests three expertise levels. Naïve decision makers are at the lowest level
of expertise and have little skill in their field of expertise. For example, in
the medical domain, medical students who have acquired knowledge in the
field but not practiced or applied the knowledge yet can exemplify naïve
decision makers. Novice decision makers are at the medium level of expertise. They have more knowledge and experience than the naïve decision
makers. In the medical domain, general practitioners can be an example of
novice decision makers for certain types of problems, where advanced expert
knowledge is valuable. At the top level are expert decision makers who have
25

<-----Page 25----->reached the highest point of expertise in their field. In the medical domain,
specialized doctors such as cardiologists can be an example of expert decision makers.
Another more general way of grouping experts is by the way they search for
and utilize information. According to the Information-Use Hypothesis, experts use more information because they can better utilize it (Jacoby et al.,
2001). However, other studies have shown the opposite, experts might
search and utilize less information than non-experts because they can ignore
irrelevant information (for examples see Einhorn, 1974; Goldberg, 1970).
Another view of the difference between experts and non-experts is how they
handle information and not how much. It might be that decision makers with
different degrees of expertise use equal amounts of information, but they
weigh and utilize the information differently (for examples see Ettenson,
Shanteau, & Krogstad, 1987; Shanteau, 1991). Non-experts do not have the
ability to ignore irrelevant information. Consequently, when both experts
and non-experts might search the same amount of information, they utilize
or ignore the information differently. This difference arises from contextdependence. For instance, a piece of information might be important in one
situation while unimportant in another. Experts, in contrast to non-experts,
have acquired experience and domain knowledge and can therefore, determine if a piece of information is relevant for a given decision situation
(Shanteau, 1992).

Expertise and different types of decisions
It may seem self-evident that individuals regarded as experts make better
decisions compared to non-experts. However, the evidence for this statement
is mixed. This depends partially on the type of decision (Ericsson, Krampe,
& Tesch-Romer, 1993). In some domains, such as in physics, experts make
decisions using static stimuli. Static stimuli refers to stimuli that are constant
and do not change. In other domains, such as medical domain, the stimuli are
dynamic, mostly because of human behavior. In domains where expert
judgments have been based on tasks involving predictions of human behavior, experts do not necessarily perform better compared to non-experts and
these experts are less predictable (Shanteau, 1992). In addition, in some domains, experts make estimations in uncertain areas (e.g., how much fuel a
certain engine needs; Krupka, Peaslee, & Laquer, 1983). In other domains,
experts make predictions of future events (e. g, how much weapons US
might need for future use; Meyer, Booker, Cullingford, & Peaslee, 1982). In
estimations in uncertain areas, or in predictions, research has shown that
experts are not necessarily better decision makers compared to non-experts
(Bennell, Bloomfield, Snook, Taylor, & Barnes, 2010; Faust & Ziskin,
1988; Tetlock, 2005). One reason for this can be due to the response-mode.
For example, in predictions experts, and non-experts for that matter, usually
26

<-----Page 26----->provide probabilities of an outcome (e.g., the probability of a patient having
heart failure or the probability of rain tomorrow). However, people in general, being an expert or not, are often unable to reason in probabilities
(Kahneman & Tversky, 1973). In domains in which experts do better decisions compared to non-experts (e.g., in medical decision making), expert
judgments are used to improve and aid decisions (e.g., by modeling the way
doctors make medical judgments; Gafni & Charles, 1998).
In this thesis, I will investigate how individuals search and utilize information depending on the different decision strategies they use. However, expertise is domain specific and how much and how information is searched is
dependent on how the degrees of expertise are identified (Shanteau, 1991).
In this thesis, I will use the expertise levels definition by Shanteau (1988)
and investigate the predictability of compensatory and non-compensatory
decision strategies for doctors’ judgments and decisions.

Examples of decision strategies and related theories
In the following, I will describe several decision strategies in which information is searched and utilized in different ways.

Multiattribute utility rule
One of the most commonly mentioned decision strategy in the literature is
the Multiattribute utility (MAU) rule. MAU is a normative method of how
difficult decisions should be made, but it also serves as a prescriptive method
or guideline for how decisions can be made. The idea behind MAU is to help
decision makers to formalize what is important to them and make a decision
based on those attributes that are important (Fischer, 1975; Keeney & Raiffa,
1993a, 1993b). Some researchers argue that using MAU is an effective and
objective way of choosing the best alternative (Edwards, Guttentag, & Snapper, 1975). If Jane made decisions in line with MAU, in order to choose the
best venue for her wedding, she would first identify all the venue alternatives. Second, she would identify all the important attributes in each venue.
Third, she would quantify the attribute values in terms of utility. Fourth, she
would give each attribute an importance weight, and then calculate an overall utility by summing the product of attribute values and weights (Edwards
& Newman, 1982; Gardiner & Edwards, 1975). Last, Jane would choose the
venue with the highest overall utility (Edwards et al., 1975; Keeney & Raiffa, 1993a, 1993b). In Study III, MAU will be included in the repertoire of
tested strategies.
Many researchers have criticized MAU by referring to bounded rationality
(Kahneman, 2003; Simon, 1991). It has been shown that decision makers do
27

<-----Page 27----->not search information in the manner MAU describes (Russo & Dosher,
1983; Tversky, 1972). Additionally, proponents of MAU presume that decision makers have stable and unchangeable attribute preferences while research show that this is not the case. Instead, preferences are constructive in
the sense that they are changed and shaped depending on the decision situation (Hsee, Loewenstein, Blount, & Bazerman, 1999; Lichtenstein & Slovic,
1971; 2006; Miyamoto & Eraker, 1988). Another theory that is similar to
MAU is the Subjective Expected Utility (SEU), which claims that decisions
can be made by weighing the utility by the probability of its occurrence
(Wallsten, 1971). Thus, the difference between MAU and SEU is that SEU
is a theory of decisions among uncertain alternatives while MAU is a theory
of decisions with more or less certain outcomes (Luce, 1992).

Prospect theory
As stressed in SEU theory, risks, or the uncertain outcome that comes with
decisions play an important role in decisions. This is an essential ingredient
in Prospect Theory (PT). PT, which is a more descriptive variant of SEU,
was developed as a critic to the more normative expected utility (EU) model.
EU does not consider the limitations in the uncertainty and probability
judgments individuals actually make while PT does. PT replaces the utility
concept in EU, which refers to absolute values, with relative values defined
in terms of their relationship to certain reference values, meaning that the
subjective value of a given value will change across situations and individuals. Value in PT refers to gains and losses rather than to absolute levels. According to PT, individuals weigh gains and losses differently and this, in
turn, will have a huge impact on decisions (Tversky & Kahneman, 1980).
More specifically, the value function of losses is steeper than it is for gains,
implying that a loss of an x amount of money feels much stronger than the
gain of the exact same amount of money. This asymmetry is called loss
aversion. Further, according to PT, the same decision outcomes will be different depending on how the decision situation is framed. If a decision situation is framed as a loss, then decision makers will be risk seeking while if
the decision situation is framed as a gain, then decision makers will be risk
aversive (Kahneman, Knetsch, & Thaler, 1990). Moreover, PT considers
probabilities differently than SEU does. PT assumes that small probabilities
will be over-weighted while high probabilities will be under-weighted
(Tversky & Kahneman, 1981). Finally, PT predicts the so-called certainty
effect. According to certainty effect, sure gains are favored to less sure gains
even though the less sure gain is better in terms of expected value.

Distances
How decision makers process information is dependent on their memory,
which is demonstrated in categorization theories (e.g., Murphy & Medin,
28

<-----Page 28----->1985). According to these theories, when an individual observes an object,
such as a cat, the object’s distance to a prototype or exemplars, which are
associated with a certain category (e.g., the category of cats) in the individual’s memory, is estimated in order to decide whether the object can be put
into the category in question. In exemplar models, instances of events or
objects are stored and represented as points in an n-dimensional psychological space in memory. For example, when Jane observes a new dress (i.e., a
new object), she compares the observed dress to all the exemplars of dresses
that she has stored in her memory. The newly observed dress is then saved in
Jane’s memory in the exemplar the dress has shortest distance to, for instance, the exemplar of wedding dresses (Erickson & Kruschke, 1998; Juslin, Olsson & Olsson, 2003; Nosofsky, 1986; Nosofsky & Johansen, 2000;
Nosofsky & Palmeri, 1997; Smith, Patalano & Jonides, 1998). Distance estimations are typically assumed to be based on similarity judgments or correlations between stimulus judgments (Yushi, 2006). A Euclidean distance is
the length of the straight line between two points (Goldstone & Son, 2005;
Tenenbaum, 1999; Tversky, 1977; Yushi, 2006). There are many distance
functions; of interest in this thesis is the Euclidean distance (ED) and
weighted Euclidean distance (WED). The difference between ED and WED
is that in ED individuals are assumed to share the same psychological
weightings and that these weightings are equal to each other while in WED it
is assumed that these weightings differ between individuals (Carroll &
Chang, 1970; Horan, 1969). Rubinstein and Zhou (2000) derived a mathematical model showing that when the given alternatives are part of a Euclidean space, an individual will choose the alternative with the shortest Euclidean distance to a reference point within this space. This model, however,
was not tested psychologically or empirically and therefore, we cannot know
if it is psychologically plausible or not.
Theories of distance have, however, been criticized for being too general and
hence failing to consider the impact of the environment, for instance, by not
considering that preferences can be constructive (Lichtenstein & Slovic,
1971; 2006). Besides, humans need to make sense of their choices, and it has
been asserted that using distance functions cannot provide such sense
(Tversky, 1977).
Ideal alternative
Closely related to distances and categorization theories is the concept of
ideal alternatives. For instance, a category, according to categorization models, consists of a centroid (i.e., a prototype) or a group of exemplars Nosofsky, 1986; Nosofsky & Johansen, 2000; Nosofsky & Palmeri, 1997). This
centroid or group of exemplars can sometimes be an ideal alternative (e.g.,
the ideal wedding dress). Similarly, Klein (1993), in his recognition primed
decision making model, suggested that decision makers do not compare al-

29

<-----Page 29----->ternatives to one another, rather to a mental simulation, which tests that the
alternative fulfills the requirements of an ideal alternative.
The idea of ideal alternatives is not new. Long before Zeleny (1976), Thurstone (1926, referred to in De Soete, Carroll, & DeSarbo, 1986) developed
the ideal point model (IPM). According to IPM, the closer an alternative is to
an ideal point, the higher preference will it receive (Bockenholt, 1998; De
Soete, Carroll, & DeSarbo, 1986; MacKay, Easley, & Zinnes, 1995). Similarly, Zeleny (1976) argued that alternatives close to some anchor (ideal)
should be preferred. For instance, Jane might find two wedding dresses to
both have satisfactory fit and look. However, the dress that is most similar to
Jane’s ideal wedding dress (e.g., because it reminds Jane of her mother’s
dress) will be preferred and appeal as more satisfactory. Zakay and Dil
(1984) tested Zeleny’s notion of ideal alternative and found that participants
chose the alternative that was closest to an ideal alternative. In another study,
they found that this strategy had a high predictive ability in actual choices
(Zakay & Barak, 1984). In both studies, distance was calculated by summing
the importance weights across those attributes where the attribute values of
an offered alternative and the ideal alternative differed, thus not accounting
for how much the attribute values of the offered alternatives differed from
the attribute values of the ideal alternative. Also in consumer research, researchers have found that consumers have different ideals that they try to
choose in line with (Desarbo, Atalay, Lebaron, & Blanchard, 2008).
In Study III, I will build on the notion of ideal alternatives and test this strategy against other more established strategies mentioned above.

Heuristics
Researchers in cognitive psychology have found vast evidence that decision
makers use heuristics to make decisions (e.g. see Gigerenzer, 2006; Gigerenzer & Selten, 2002; Gigerenzer et al., 1999; Gilovich, Grifﬁn, & Kahneman, 2002; Kahneman & Frederick, 2002). Heuristics are simplified strategies or rules of thumb, which help individuals to make decisions. Even
though many of the heuristics have been found to violate axioms of rationality (one such violation is intransitive preferences; Tversky, 1969), these violations are regarded as acceptable. This is because these heuristics work for
the greater good, that is, they help decision makers to make decisions even
though they might be somewhat disabled because of their limited processing
capacity (Tversky & Kahneman, 1974).
There are at least three reasons why individuals such as Jane would use heuristics: first, because of limited cognitive capacity, she might not have other
possibilities, second, she might not have the time or resources, and third,
because these heuristics have worked satisfactory earlier, she might find
30

<-----Page 30----->them suitable for future decisions as well (Payne & Bettman, 2004). Heuristics differ from sequential sampling process described earlier in the sense
that what and how much information to process is pre-determined.
There are many heuristics, most of them non-compensatory. Some of interest
for this thesis is: The Dominance rule, often used when people look for justifying their choice, implies the choice of an alternative that is better than all
other alternatives on at least one attribute and not worse on other attributes.
In his dominance structuring theory, Montgomery (1983) suggested that if
Jane cannot find a dominating alternative, she will change the structuring of
the alternatives so that one of the alternatives will eventually become dominant. Dahlstrand and Montgomery (1984) found that individuals, in their
search for a dominance structure, applied the Lexicographic heuristic explained earlier (Gigerenzer & Goldstein, 1996; Gigerenzer et al., 1999) and
the Maximin heuristic, choice of an alternative that has the best worst outcome (Dahlstrand & Montgomery, 1984). Another heuristic is Tversky’s
(1972) Elimination by aspects (EBA) heuristic. Here Jane assigns each
attribute in an alternative an importance weight and a threshold value. Jane
starts by investigating the most important attribute and eliminates alternatives that do not meet the threshold value of that attribute. Jane continues to
the second most important attribute value and repeats the same procedure.
She continues this procedure until there is only one alternative left.
Fast and frugal heuristics
Alongside the mentioned heuristics, there is a full body of research on heuristics called fast and frugal (F&F) heuristics, which are seen as serving ecological rationality (Gigerenzer et al., 1999; Gigerenzer, 2000). Except for
being fast and frugal, what differentiates F&F heuristics from the heuristics
mentioned in previous paragraph is that the F&F heuristics are inferential
while the above-mentioned ones are preferential (Gigerenzer, 2007). According to Gigerenzer (2007), there are no criteria to evaluate how successful for instance the Lexicographic rule is and therefore the usage of this rule
only shows if the decision maker has a preference for using it or not. In contrast, for the F&F heuristics, there are criteria that individuals and researchers can use to make inferences about how well these heuristics work.
The core of F&F heuristics is that they do not require search or integration of
all the information (i.e. the attributes). Instead, decision makers using F&F
heuristics base their decisions on one attribute, hence the name frugal (Dhami & Harries, 2001; Gigerenzer & Goldstein, 1996; Gigerenzer et al., 1999;
Gigerenzer, Hoffrage, & Kleinbölting, 1991). Proponents of F&F heuristics
argue that it is more plausible to use these heuristics because they cope with
the limited cognitive ability by only searching a limited amount of information (Todd & Gigerenzer, 2003).

31

<-----Page 31----->One of the most well-known F&F heuristics is the Take the best heuristic in
which attributes are searched in order of their importance until one discriminates, and then the search stops and all other attributes are ignored (Gigerenzer & Goldstein, 1996). Other examples of F&F heuristics are the Recognition heuristic and the Tallying heuristic. In the Recognition heuristic, the
one out of two alternatives that is recognized by the decision maker is chosen (Goldstein & Gigerenzer, 2002). In the Tallying heuristic, the number of
favoring attributes is counted and the alternative with the highest number of
favored attributes is chosen (Gigerenzer & Goldstein, 1996). Some of the
F&F heuristics could be characterized as F&F trees. Here more than one cue
can be considered. However, this does not mean that all the cues will de
facto be considered, instead if a decision is not reached with only one cue,
then the next cue in the tree is considered and so forth (Fischer et al., 2002).
Studies have shown that sometimes F&F heuristics are more valid and accurate than, for example, regression models (e.g., by having better predictive
accuracy of human judgment than the more complex and cognitive demanding heuristics; Gigerenzer and Goldstein, 1996). On the other hand, there are
arguments and studies showing that these simple heuristics might not be as
simple as claimed. For instance, in order to decide which cue or piece of
information to attend to, complex computations are needed (Dougherty,
Franco-Watkins, & Thomas, 2008; Juslin & Persson, 2002).

Examples of decision strategies and related theories in a nutshell
Decision makers have a repertoire of decision strategies that they can use in
different situations (Payne et al., 1995). Different theories and decision strategies focus in different aspects. In MAU, the focus is to choose the alternative with the highest utility (Keeney & Raiffa, 1993a). Prospect theory,
stresses the importance of risks and uncertainty in decisions (Tversky &
Kahneman, 1980). Decision strategies based on distances focus on how
memory and how distance functions play a role in decision making (Murphy
& Medin, 1985). Theories of ideal alternatives, closely related to distance
theories, focus on how individual’s ideals guide the decision making process
(Zakay & Dil, 1984). Heuristics focus on how humans have developed simple rules of thumb in order to cope with the limited cognitive capacity
(Dahlstrand & Montgomery, 1984; Gigerenzer & Goldstein, 1999). In this
thesis, I will investigate and compare several decisions strategies and theories against each other. In particular, I will investigate and compare MAU,
distance functions, a strategy based on an ideal alternative, different heuristics and, regression models. I will also introduce a new strategy that can
better account for human decision making compared to these strategies.

32

<-----Page 32----->Judgment Analysis
One method that makes it possible to study decision strategies and how individuals search and utilize information is judgment analysis (Cooksey, 1996).
In order to understand judgment analysis, a short description of its origins is
needed. Judgment analysis is a method originating from the social judgment
theory (SJT), which in turn originates from a Brunswickian approach
(Brunswick, 1952). SJT is a framework for studying human judgments and
the decision environment. Put differently, SJT concerns people’s ability to
make inferences about facts in the environment. According to SJT, a judgment process is defined by the integration of information (i.e., cues) from
multiple sources. As an example, consider Jane, who is a doctor examining a
patient in order to diagnose heart failure. According to SJT, the first step for
Jane is to define the cues, in this case the symptoms (e.g., age and gender),
that might affect the final diagnosis. The second step is to define the relationship and the importance of the identified symptoms (e.g., how age and
gender together can increase or decrease the risk of heart failure). Finally,
Jane’s diagnosis (i.e., the presence of heart failure or not) is studied and explained with the relation between the different symptoms, and how Jane
interpreted the symptoms (for a review see Brehmer & Joyce, 1988). SJT
focuses on not only the decision maker and the decision environment but
also on how the judgment of one decision maker agrees to the judgment of
another.
Judgment analysis is a method for fulfilling the goals of SJT. In judgment
analysis, decision makers are asked to make a decision or judgment based on
a number of cues. The decision maker’s decision policy is then inferred from
the way s/he made the decision based on the provided cues (for instance,
Jane’s way of judging based on the symptoms). This policy or model is then
used to predict judgments and decisions without the actual help of the original decision maker (i.e., without the help of Jane). Traditionally, SJT theorists have worked on the supposition that judgments are a product of linear
and compensatory integration of cues (Brehmer & Brehmer, 1988). Therefore, in judgment analysis, it is a common practice to use different regression
models such as logistic regression (LR) or multiple regression to model and
predict judgments and decisions (for overviews see Cooksey, 1996; Engel,
Wigton, LaDuca, & Blacklow, 1990; Wigton, 1988, 1996).
In judgment analysis, researchers have relied on the notion that experts have
adapted to their task environment and are, hence, superior to novices in their
decision-making (for reviews see Dhami, Hertwig, & Hoffrage, 2004).
Therefore, most of the judgment and decision data for building models on
decision strategies has come from experts. However, as demonstrated by
Kee et al. (2003), different degrees of expertise, model, and methods might
provide different results. In the study by Kee and colleagues (2003), train33

<-----Page 33----->ing-grade pediatricians, consultants, and junior and senior doctors decided,
based on 60 patient vignettes, whether to admit a patient because of asthma.
Kee and colleagues then used two judgment analysis models, a regression
and a F&F one, in order to model the different doctors’ decisions. Kee and
colleagues found that the regression models’ ability to predict decisions was
lower for consultants than for training-grade pediatricians. The F&F model
did not find such difference. It was concluded that models built on logistic
regression are better at capturing decision behavior than the matching heuristic (the F&F strategy they used).

Regression models in judgment analysis
Regression models have proven to be good at modeling experts’ decision
making (Cooksey, 1996; Dawes & Corrigan, 1974; Goldberg, 1970), especially in policy capturing studies (For examples see Backlund, Bring,
Skånér, Strender, & Montgomery, 2009; Dhami & Harries, 2001). Policy
capturing, or bootstrapping as it is sometimes called, is a special method in
judgment analysis for gaining insight of how decision makers weigh and
integrate information in order to make a decision (Zedeck, 1977). Regression
models are compensatory models that give a statistical description of a decision (Brehmer & Brehmer, 1998; Wigton, 1988). As an example of regression models in judgment analysis, medical doctors are presented with madeup patient cases where the doctor’s task is to make a clinical judgment or
decision, which is considered as the dependent variable. Each patient case
can consist of a number of cues (e.g., age, gender, blood pressure and so
forth), which are considered as the independent variables. The doctors’ decisions are then regressed on the provided cues that give a judgment policy or
model of how the cues are weighted and integrated. The outcome of the regression model is different weightings of the cues (that is, the weights of the
information provided in the cases) and the regression model consists of the
cues with the highest weightings (Cooksey, 1996). The model or policy can
then be compared with the decision maker’s own statement of the judgment
in order to see how well it predicts the decision of the decision maker.
Judgment analysis is not used only in the medical domain but also in other
domains such as accounting and education (Heald, 1991; Waller, 1988).
One of the main critics against regression models is that they are not psychologically plausible because the cognitive ability of the human mind is limited
and regression models require extensive calculations (e.g., Kahneman,
2003). Several studies have shown that people are not good at reasoning in a
statistical manner, and instead reason in line with a heuristic manner (for
examples see Kahneman & Tversky, 1972, 1973, 1982; Tversky & Kahneman, 1974). However, there are situations where people might reason in a
statistical manner, especially in situations where the decision maker has expertise (Nisbett, Krantz, Jepson, & Kunda, 1983).
34

<-----Page 34----->Fast and frugal models in judgment analysis
Lately, many studies in judgment analysis have tested simple heuristics such
as F&F models in order to investigate their predictive accuracy. An example
of F&F trees used in judgment analysis is the Matching heuristic (Dhami &
Ayton, 2001; Dhami & Harries, 2001). Similar to regression models, in the
Matching heuristic the judgments provided by the doctors are the dependent
variable, and the cues are the independent variables. In order to determine
the number of cues (independent variables) in the model based on the
Matching heuristic, first a critical value for each cue is identified. The critical value is identified as the cue value that has the highest frequency of hits
(in heart failure this would be patients diagnosed with heart failure). For
example, if out of 100 patients, 70 male patients (the cue here being gender)
are diagnosed as having a heart failure (hits) while only 30 patients are diagnosed as not having heart failure (non-hits), then the critical value for gender
is the value that has the highest number of heart failure diagnoses, in this
case male patients. If the number of diagnoses is the same for both males and
females, then the critical value is based on the cue value with the lowest
number of “non-hits”. When these were also the same, the critical value is
chosen randomly. Second, cue validity is identified as the proportion of cases with the critical value that is associated with a diagnosis. For example, if
the critical value had 70 hits and 30 non-hits, then 70 is divided by 100 (total
number of judgments). Third, the cue validities are ordered by their validity
as defined in the preceding step, and this order indicates the order the cues
are searched by the model. Finally, in order to calculate how many cues
should be included in the model, a fit is calculated by adding each of the
cues in the model. The number of cues that lead to the highest fit is chosen
as the number of cues in the model. This model is then fitted to the data.

Regression vs. Fast and frugal models
The results from studies that have compared regression models against
F&F models point to different directions (e.g., Backlund et al., 2009; Czerlinski, Goldstein & Gigerenzer, 1999; Dhami & Harries, 2001, Gigerenzer &
Goldstein, 1999; Kee et al., 2003; Martignon, Kastikopoulos, & Woike,
2008; Smith & Gilhooly, 2006). Some studies show that F&F heuristics have
better predictive accuracy of human judgments and decisions compared to
regression models (Czerlinski et al., 1999; Gigerenzer & Goldstein, 1996)
while other studies show that regression models better predict human judgment and decision (Backlund et al., 2009; Kee et al., 2003). There are good
reasons to be cautious in drawing conclusions from the results of the previous studies. For instance, in some of the studies (e.g., Backlund et al.,
2009, Dhami & Harries, 2001) the validity of the models has not been measured by using cross-validation. This does not automatically indicate the
model’s predictive ability, applied on other data sets. In fact, fitting and pre-

35

<-----Page 35----->dicting the same data set can lead to over-fitting (Plutowski, Sakata, &
White; 1994; Roberts, & Pashler, 2000). Czerlinski et al. (1999) investigated
the predictive accuracy and frugality of F&F and LR strategies by applying
cross-validation. They found that the data were over-fitted, especially for the
regression models. Other studies show the same results (Martignon, 2001;
Martignon & Hoffrage, 2002). In studies where cross-validation has been
used, the data have concerned factual relations such as cities being a state
capital or not depending on having a soccer team (Czerlinski et al., 1999;
Gigerenzer & Goldstein, 1996; Martignon, Kastikopoulos, & Woike, 2008).
Consequently, the dependent variables in these studies have concerned ecological facts instead of human decisions or judgments hence having high
ecological validity but maybe lower psychological validity. Furthermore, the
regression models have often included all the information (i.e., cues). This
can led to over-fit in the regression models (Pitt, Myung, Shaobo, 2002).

Judgment analysis in a nutshell
Judgment analysis origins from social judgment theory that is a framework
for studying how, for example, information is utilized and how well a decision strategy predicts human judgments. Some common models to capture
judgment policies are regression models (Brehmer & Brehmer, 1988) and
F&F models (e.g., Dhami & Harries, 2001). However, previous studies have
shown conflicting results in whether regression models or F&F models are
better at capturing human judgments (for different results see e.g., Backlund
et al., 2009; Czerlinski et al., 1999; Dhami & Harries, 2001, Kee et al., 2003;
Martignon, Kastikopoulos, & Woike, 2008). I have identified three weaknesses from the previous studies, which might explain why the different
results are conflicting. In some studies cross-validation has not been used
(e.g., Backlund et al., 2009), or only ecological facts has been used as the
dependent variable (e.g., Czerlinski et al., 1999), while in other studies the
regression models have used all the available information (Gigerenzer &
Goldstein, 1996). Because of the above-mentioned shortcomings of the previous studies, the question of which strategy that can better predict and model for human judgment is still unanswered. In Study I and II, I aim to answer
this question by overbuilding the found weaknesses. In Study II, I will also
add expertise as a dependent variable.

36

<-----Page 36----->Research objectives

After all, the ultimate goal of all
research is not objectivity, but
truth.
~Helene Deutsch

Even though the research on decision making has been interdisciplinary with
a long history, there are gaps of knowledge that need to be filled. In this
thesis, I aim to pay more attention to a few of these gaps. I will start by investigating some “old” decision strategies that individuals might use and that
might best describe human decision making. With old, I refer to the strategies that have been subject of research. I will use judgment analysis to compare the inferential ability of these strategies. The data to build models based
on the decision strategies will be ecological data in terms of actual diagnoses
and human judgments of medical professionals. The investigated strategies
in Study I are two “old” strategies, one compensatory (logistic regression),
and one non-compensatory (F&F). However, in judgment analysis most of
the times, the judgment and decision data come from experts. As discussed
earlier decisions made by experts may differ in many ways compared to
decisions made by non-experts (for instance, because experts might, depending on the type of decision, produce better decisions). Therefore, in order to
be able to generalize the results to non-experts as well, I will test decision
strategies where participants with different degrees of expertise (Study II)
make the judgments.
Judgment analysis establishes the inferential ability of different strategies,
but not which decision strategy individuals actually prefer or use. Besides,
there are many more “old” decision strategies than those tested in Study I
and II. Therefore, in Study III I will investigate other compensatory and noncompensatory decision strategies. I will use an experimental setting to investigate the choices and preferences of decision makers. As mentioned earlier,
both compensatory and non-compensatory decision strategies have advantages and disadvantages. For instance, a disadvantage of most noncompensatory decision strategies is that they are too simple to represent human decision making. I believe, in line with recent research (Glöckner &
Betsch, 2008) that humans search and integrate more information than stated
in those simple strategies. In Study III, I will present a “new” decision making strategy that goes beyond the compensatory versus non-compensatory
perspective by incorporating the strengths of the two (Study III). This “new”
strategy, the Concordant-Ranks strategy, integrates and searches more information (similar to compensatory decision strategies) while being simple
and therefore not overloading the human brain (similar to non-compensatory

37

<-----Page 37----->decision strategies). The CR strategy manifests itself by choosing the alternative that is closest to an ideal alternative in terms of distance in a multiattribute decision space. This alternative will also present a pattern (concordant ranks between attribute weights and attribute values in the alternative
that is at hand for the decision maker when choosing) when the MAU is the
same for the different alternatives. In order to test the superiority of this
strategy, I will compare the CR strategy with other commonly used strategies, such as MAU, EBA, distance strategies, and “one reason strategies”
such as the Lexicographic and Maximin strategy.

38

<-----Page 38----->Empirical Studies

To finish it, it took me five
years, little did I know I had
been doing it all my life.
~Anonymous

Study I - Comparison of decision strategies using judgment
analysis
Aim
The aim of this study was to compare, and test the inferential ability of different compensatory (logistic regression) and non-compensatory (F&F)
strategies. For this aim, judgment analysis was used. One benefit of using
judgment analysis is that the policies it produces are not sensitive to memory
recall biases, for example, biased because participants cannot correctly recall
how they made a decision (Wilson, Laser, & Stone, 1982). In addition, using
judgment analysis has shown to produce reliable models (e.g., Brehmer &
Brehmer, 1988). However, there are a few methodological weaknesses in
previous studies that have used judgment analysis; (i) low generalizability,(ii) lack of cross-validation, and (iii) inappropriate criteria for inclusion of
cues in the models. Some studies have adjusted for some, but not all, of these
weaknesses. For instance, concerning low generalizability, some studies, to
build models, have used ecological facts and not human judgment as dependent variables. Therefore, the predictability of these models cannot be
trusted when they are applied on human judgments. Studies that have used
human judgments have not used cross-validation, and studies that have used
human judgments or/and cross-validation, have not used proper cue inclusion in the regression models. In the present study, all three mentioned
weaknesses were avoided in order to more properly compare different decision strategies. In order to increase the generalizability, the data used in order to model the strategies were based on participant judgments on two different medical decisions, one about prescription of medicine (Hyperlipidemia study), and one about diagnose of heart failure (Heart failure). In the
heart failure data, also actual diagnoses of the same patient cases based on a
thorough investigation at a heart clinic were used. Moreover, crossvalidation was carried out when building the different models. Lastly, in
order to build models based on logistic regression, different significant levels
for including cues in the model were used.
The five investigated models (two F&F models and three logistic regression
models) were tested and compared in terms of:
39

<-----Page 39----->-

Predictive accuracy: how well a model built according to the tested
strategies can predict judgments on a new set of data.
Frugality: amount of information (i.e., cues) that a model consists of
and amount of information the model actually utilizes for predicting.

Method
Participants
In order to collect judgments of whether to prescribe or not prescribe a cholesterol-lowering drug (Hyperlipidemia2), 38 general practitioners from
Stockholm, Sweden, were randomly selected. In order to collect human
judgments regarding heart failure diagnose, 68 doctors from Stockholm,
Sweden were selected.
Patient cases
In both Hyperlipidemia and Heart failure study, each participating doctor
judged 40 actual patient cases. In both studies, participants marked, on a
scale from 0-100%, their willingness to prescribe medicine (Hyperlipidemia
study) or marked the probability that the patient suffered from heart failure
(Heart failure study). The patient cases in the Hyperlipidemia study consisted of seven cues (age, sex, cholesterol value, triglyceride value, diabetes,
hypertension, and history of coronary heart disease). The patient cases in the
Heart failure study consisted of 10 cues (age, sex, history of myocardial infarction, dyspnea, atrial fibrillation, leg edema, rales, systolic blood pressure,
cardiac volume, and signs of pulmonary congestion on lung X-ray). In both
studies, participant judgments were coded as 1 if the response was equal or
greater than 50%, and coded as 0 if it was 50% or below.
Case sampling
In order to decide which cases to include in the fitting set (i.e., which cases
to use in order to build a model) and to use in the prediction set, Monte Carlo
simulations were used. For each participant the simulations were repeated
100 times and the participant model consisted of the average value of the
100 simulations. In addition, four fitting sample sizes were used in order to
build a model; 25% of the total dataset (10 cases), 37.5% of the total dataset
(15 cases), 50% of the total dataset (20), and 75% of the total dataset (30
cases).

2

Hyperlipidemia is the condition of high cholesterol.

40

<-----Page 40----->Model building
The strategies, which the models were built according to, were two fast and
frugal models (F&F 1 and F&F 2) and three logistic regression models (LR
5, LR 10, and LR Enter) where each regression model used different significance levels (5%, 10%, and 100%) of how many cues to include in the
regression model. Below, I will describe each model in more detail.
Fast and frugal model 1(F&F 1)
This model was based on the matching heuristic described by Dhami and
Harries (2001). This procedure is identical to the one described earlier in the
fast and frugal section of judgment analysis. In short, first, a critical value of
each cue is determined. Second, a validity of each cue is calculated. Third,
the cue validities are rank-ordered and the fit is calculated by adding one cue
at a time, starting with the cue with the highest validity, until the fit does not
improve anymore. The model is then established as the model with the number of cues that lead to the highest fit value.
Fast and frugal model 2 (F&F 2)
The simulation of F&F 2 was based on the model described by Backlund et
al. (2009). This model is identical to F&F 1 except that in this model the
critical value is identified differently. While in F&F 1, the critical value is
identified by the cue value that has the highest frequency of hits, in F&F 2
the critical value is identified by the cue value that has the highest frequency
of hits and true rejections.
Logistic Regression (LR)
For modeling according to logistic regression, the cues (7 in Hyperlipidemia
and 10 in Heart failure) were used as the independent variables and the participant responses were used as the dependent variable. Actual diagnoses
from the Heart failure study were also used as dependent variable. In logistic
regression, different significance levels can be used in order to determine
which cues to include in a model. In this study, three different significance
levels were used: 5% (LR 5), 10% (LR 10), and 100% (LR Enter).

Results and discussion
Predictive accuracy
Each of the five models were compared with one another in terms of how
accurately they predicted new set of data (predictive accuracy).
Hyperlipidemia
Figure 1 shows the different predictive accuracy values for the different
models and different samples. The predictive accuracy of the models was
compared by using ANOVA followed by post hoc analysis. The analysis
41

<-----Page 41----->showed that LR Enter had significantly lower predictive accuracy than all
the other models. LR Enter had the lowest predictive accuracy in all the
sample sizes as well. However, this pattern was only significant in the fitting
set using 75% of the total data set.

95

Hyperlipidemia - Judgments

Predictive accuracy

85
81
80

77 78

78

F&F 1
F&F 2
LR5
LR10
LR Enter

70 70 70
67
65

65

65 65

66

67 67

68

64

67
65

68

67 66 66
62

53
50
Fit

75 % in fit

50 % in fit

37.5 % in fit

25 % in fit

% of the data that was in the fitting set

Figure 1. Percentage of fit and predictive accuracy for the different models and
different fitting set sizes in the Hyperlipidemia study.

Heart Failure
In the heart failure study, building a model using only 25% of the data
(which was equal to 10 cases), meant using the same number of cases as the
number of independent variables in the LR Enter model. Therefore, two
ANOVA analyses were conducted, one without LR Enter but with fitting set
25% (4 models x 4 samples) and one with LR Enter but without fitting set
25% (5 models x 3 samples). For levels of predictive accuracy for the different models and fitting sample sizes, see Figure 2. The analysis without LR
Enter showed no significant main effect of model, meaning that the predictive accuracy for the models did not differ significantly between F&F 1,
F&F 2, LR 5, and LR 10. There was also a main effect of sample size, where
the greater fitting samples provided higher predictive accuracy. There was a
significant interaction effect of model and sample size where LR 5 and LR
10 did slightly better than the other models in all samples except for the fitting set 75%.

42

<-----Page 42----->In the analysis with LR Enter but without fitting set 25%, there was a main
effect of model. There was also a main effect of sample size where further
analysis showed that the differences were significant between all sample
sizes. Remember that in the analysis where LR Enter was excluded there was
no main effect, however when LR Enter was included but fitting set 25%
was excluded, there was no main effect. This indicates that LR Enter must
have caused the main effect where the predictive accuracy of LR Enter decreased the most compared to the other models, while the predictive accuracy of the other models (F&F 1, F&F 2, LR 5, and LR 10) did not differ significantly.

95
90

Heart Failure - Judgments

92

Predictive accuracy

87
82 83
80

77

78 78
76
74

74 74 75

76

75
73 73

74

77 77
75

73

F&F 1
F&F 2
LR5
LR10
LR Enter

69
67
65

50
Fit

75 % in fit

50 % in fit

37.5 % in fit

25 % in fit

% of the data that was in the fitting set

Figure 2. Percentage of fit and predictive accuracy for the different models and
different fitting set sizes in the Heart failure study using participant judgments.

43

<-----Page 43----->The models were also built using actual diagnoses as dependent variables. In
contrast to participant judgments, which were given by the participants, actual diagnoses were based on a thorough investigation at a heart clinic. As
illustrated in Figure 3, LR Enter provided the highest predictive accuracy
when it was not cross-validated but when cross-validated, instead F&F 1
provided the highest predictive accuracy (in all sample sizes except for fitting set 37.5% where it did equally well as F&F 2 and LR 10). However,
notice that this difference was very small.
Heart Failure - Actual Diagnosis
95
90

Predictive accuracy

85 85
80

80 80
F&F 1
F&F 2

LR5
LR10

64

65

63
60 60

61

62
59

60

61

61 61
58

60

62

61
58

LR Enter

61
59 59

50
Fit

75 % in fit

50 % in fit

37.5 % in fit

25 % in fit

% of the data that was in the fitting set

Figure 3. Percentage of fit and predictive accuracy for the different models and the
different fitting set sizes in the Heart failure study, using actual diagnoses.

In models based on both participant judgments and actual diagnoses, the
trend was the same with regard to the predictive accuracy of LR Enter.
However, after cross-validation the predictive accuracy of all the models
decreased markedly more when the models were built using actual diagnoses
compared to when participant judgments were the dependent variable.
In sum, results show in terms of predictive accuracy fitting set sample size
mattered more in the Heart failure study while mattered only in one of the
fitting sample sizes (the greatest one) in the Hyperlipidemia study. However,
not considering the sample size, it seems that in both studies when crossvalidation is used, LR Enter provides the lowest predictive accuracy compared to the other models.

44

<-----Page 44----->Frugality
As mentioned earlier, in contrast to previous studies, which have measured
frugality in terms of the number of cues in the model, in this study frugality
was measured on two dimensions. One dimension was the number of cues in
the model (cues in model). Another dimension was the number of cues actually utilized for predicting (cues actually utilized).
Hyperlipidemia – Cues in Model
In terms of cues in model, ANOVA showed a significant main effect of
model, and an interaction effect between model and fitting sample. In all
sample sizes, the LR 5 model consisted of fewer cues than any other model
(see Table 1). Post hoc analysis on models showed that the differences were
significant between all models, except for the difference between F&F 1 and
LR 10.
Turning to the different fitting samples, the smaller the fitting set sample
was, the more cues in the model for the F&F models while the opposite was
true for LR 5 and LR 10. That is, in the smaller the fitting set sample was,
the fewer cues in LR 5 and LR 10. Additionally, for the smallest fitting samples, LR 5 (1.18, 1.45) used fewer cues than F&F 1 (2.53, 2.40) and F&F 2
(3.19, 3.03).
Table 1. Frugality in Terms of Cues in Models and Cues Actually Utilized for the
Different Models and Different Fitting Sets in the Hyperlipidemia Study.

F&F 1
F&F 2
LR 5
LR 10
LR Enter

Fit
2.37
2.32
1.74
2.63
7.00

Number of Cues in the Model
75% in fit
50% in fit
37.5% in fit
2.34
2.37
2.40
2.39
2.56
3.03
1.76
1.56
1.45
2.41
2.19
2.06
7.00
7.00
7.00

F&F 1
F&F 2
LR 5
LR 10
LR Enter

Fit
1.61
1.68
1.74
2.63
7.00

Number of Cues Actually Utilized
75% in fit
50% in fit
37.5% in fit
1.69
1.27
1.61
1.77
1.36
2.05
1.76
1.56
1.45
2.41
2.19
2.06
7.00
7.00
7.00

25% in fit
2.53
3.19
1.18
1.63
7.00

25% in fit
1.31
2.10
1.18
1.63
7.00

45

<-----Page 45----->Hyperlipidemia – Cues Utilized by Model
In terms of number of cues actually utilized, ANOVA showed a significant
main effect of model, significant main effect of fitting sample, and an interaction effect between model and fitting sample. As seen in Table 1, regarding cues actually utilized by the model, the F&F 1 model utilized the fewest
number of cues in the greater fitting samples sizes. The differences were
significant between all models except for between F&F 1 versus LR 5 and
between F&F 2 versus LR 5 and LR 10 when the fitting set was small
(75%). Further, there were significant differences between fitting set sample
25% and both 37.5% and 75%, between 37.5% and 50%, and between 50%
and 75%. Results showed also an interaction effect between sample size and
model. Number of cues in F&F 1 decreased when the fitting set sample got
smaller, while in F&F 2 number of cues increased.
The regression models use the same number of cues in model and cues actually utilized. However, this is different for the F&F models. The F&F
models did not use all the cues that the model consisted of in order to predict.
Heart Failure – Cues in Model
In terms of number of cues in model, ANOVA showed a significant main
effect of model, a significant main effect of fitting sample, and an interaction
effect between model and fitting sample. As seen in Table 2, LR 5 used fewest cues in a majority of the fitting sets samples (except for fitting sample
75%). LR 10 used fewer cues compared to the F&F models in the smaller
fitting sample sizes. Number of cues in the LR models decreased due to fitting set sample size while the number of cues in the F&F models increased.
The differences were significant between all fitting sets. In addition, in the
smallest fitting set sample the mean number of cues in model was lower for
LR 5 (1.21, 1.58) than for F&F 1 (2.83, 2.65) and F&F 2 (3.18, 3.23).

46

<-----Page 46----->Turning to actual diagnoses, as seen in Table 2, LR 5, followed by LR 10,
used fewest numbers of cues in model while F&F 2 model had more cues
than any other model.
Table 2. Frugality in Terms of Cues in Models and Cues Actually Utilized for the
Different Models and Different Fitting Sets in the Heart failure Study.

Fit

Number of Cues in the Model
75% in fit 50% in fit 37.5% in fit 25% in fit

Participant Judgments
F&F 1
F&F 2
LR 5
LR 10
LR Enter

2.07
2.93
2.48
3.33
10.00

2.39
2.95
2.43
3.44
10.00

2.53
2.99
1.90
2.85
10.00

2.65
3.23
1.58
2.34
10.00

2.83
3.18
1.21
1.73
10.00

Actual Diagnosis
F&F 1
F&F 2
LR 5
LR 10
LR Enter

3.00
4.00
2.00
2.00
10.00

2.73
3.19
1.65
2.36
10.00

2.56
2.96
1.78
2.48
10.00

2.59
3.12
1.41
2.34
10.00

2.75
3.15
1.19
1.77
10.00

Fit

Number of Cues Actually Utilized
75% in fit 50% in fit 37.5% in fit 25% in fit

Participant Judgments
F&F 1
F&F 2
LR 5
LR 10
LR Enter

1.55
1.99
2.48
3.33
10.00

1.39
1.56
2.43
3.44
10.00

1.78
1.35
1.90
2.85
10.00

1.58
1.78
1.58
2.34
10.00

1.72
2.01
1.21
1.73
10.00

Actual Diagnosis
F&F 1
F&F 2
LR 5
LR 10
LR Enter

2.36
2.88
2.00
2.00
10.00

2.10
2.35
1.65
2.36
10.00

1.97
1.49
1.78
2.48
10.00

2.00
2.34
1.41
2.34
10.00

2.05
2.33
1.19
1.77
10.00

Heart Failure – Cues Utilized by Model
In terms of number of cues actually utilized, ANOVA showed a significant
main effect of model, a significant main effect of fitting sample, and an interaction effect between model and fitting sample. As seen in Table 2, in the
bigger fitting samples F&F 1 utilized least number of cues compared to the
other models. Furthermore, in the F&F models the number of cues utilized

47

<-----Page 47----->increased in the smaller fitting samples. Post hoc analysis showed that while
all the models differed significantly, regarding fitting sample size, differences were significant between fitting set 75% and both 37.5% and 50%, between 37.5.5% and 75%, and 50% and 75%. Regarding actual diagnoses, LR
5 utilized fewest numbers of cues followed by F&F 1.
In sum, it seems that also the LR models are as frugal, if not more, than the
F&F models. In addition, there seem to be a linear relation between frugality
and fitting set sample size while such linearity was not found in the F&F
models. However, this relationship requires that the amount of information
in the model can be limited, which has not been the case in previous studies
such as those by Gigerenzer and Goldstein (1996).

Conclusion
Overall, our data suggest that also when cross-validation is used, the regression models (or compensatory strategies) predict as efficiently as the socalled F&F heuristics, if only significant cues are included in the model. In
fact, because the models built on logistic regression also used very few cues,
they also can be considered as frugal. In addition, because the regression
models use the same number of cues in model as number of cues actually
utilized, they can be considered as more frugal than the F&F models. In sum,
it can be noted that the compensatory strategy, in this case logistic regression, had equally high predictive accuracy while being more frugal than the
F&F strategies.

Study II - Comparing decision strategies while controlling
for expertise
Aim
In Study I, it was found that if the studies are carried out properly then regression models are as good as, if not better, than the F&F models in terms
of predictive accuracy and frugality. However, earlier studies have shown
that the degree of expertise of participants lead to different decisions, especially in the case where expertise and knowledge matters (e.g., Shanteau,
1991; 1992; Jacoby et al., 2001). Consequently, the results from Study I can
only be generalized to those with the same level of expertise as our participants in Study I. Therefore, in order to increase the generalizability of the
results from Study I, Study II was conducted.
The main aim of Study II was to investigate whether different decision strategies are differently suitable when the judgments come from individuals
48

<-----Page 48----->with different degrees of expertise. For this aim, different strategies: F&F
strategies (F&F 1 and F&F 2) and logistic regression strategies (LR 5, LR
10, and LR Enter) were cross-validated and tested. The judgments came
from individual doctors with three different degrees of expertise: students,
general practitioners, and cardiologists. These different experts differ both in
terms of knowledge (more knowledge in the higher degree of expertise) and
in terms of experience (longer practice in the higher degree of expertise).

Method
Participants
The participants in this study were 21 medical students (14 women) from
two courses in family medicine, 27 general practitioners (13 women) randomly selected from a list of specialists in family medicine, and 20 cardiologists (5 women) from two cardiology clinics. The medical students were in
their last semester (11 semesters) in medical school. The general practitioners had practiced for 9.8 years in average. The cardiologist, which had practiced as general practitioners for some years before becoming cardiologists,
had practiced as cardiologists for 11 years in average. The same data set was
also used in Study I.
Procedure and model building
The procedure of getting participant judgments, presentation of the patient
cases, and model building was identical to the Heart Failure study in Study I.
Similar to Study I, the models were two fast and frugal strategies (F&F 1 and
F&F 2) and three logistic regression strategies (LR 5, LR 10, and LR Enter).
However, because in Study I, sample size was of little importance for the
predictive accuracy, only one sample size consisting of 75% in the fitting set
(30 cases) and 25% in the prediction set (10 cases) was used.

Results and discussion
Fit and prediction
Table 3 shows the predictive accuracy for each model and expertise level.
Even though ANOVA analyses showed a significant main effect of model,
there was no significant interaction effect between the predictive accuracy of
the five models and participants with different degrees of expertise. Post hoc
analysis showed that in fit the differences were significant between all models except for Original and LR10, and Extended and LR10. In prediction,
only LR 5 and LR 10 provided significantly higher predictive accuracy as
compared to LR Enter.

49

<-----Page 49----->Table 3. Mean and (Standard Deviation) of Fit and Prediction (in Percent) of Different Models for Participants with Different Degrees of Expertise.
Model

% Fit

% Prediction

F&F 1
F&F 2
LR 5%
LR 10%
LR Enter

Students
83.18 (6.56)
75.14 (10.03)
84.20 (6.37)
74.19 (9.90)
88.12 (6.07)
76.43 (9.75)
91.09 (5.79)
76.19 (9.22)
95.69 (5.11)
72.43 (6.28)
General Practitioners
85.63 (6.03)
77.22 (9.14)
86.33 (5.75)
76.33 (9.00)
89.56 (6.39)
78.93 (10.17)
92.41 (6.09)
79.00 (9.48)
96.78 (4.24)
76.00 (8.31)

F&F 1
F&F 2
LR 5%
LR 10%
LR Enter

Cardiologists
84.76 (6.03)
77.82 (8.50)
85.46 (5.70)
77.15 (9.23)
87.35 (4.77)
78.51(6.98)
85.71(20.79)
78.43 (6.35)
89.85 (21.60)
73.60 (7.33)

F&F 1
F&F 2
LR 5%
LR 10%
LR Enter

Number of cues in Strategy
As seen in Table 4, LR 5 used fewer number of cues. ANOVA analyses,
however, showed no significant main effect of expertise or interaction effect
of expertise and model.
Table 4. Frugality of the Models in Terms of Number of Cues in Model.
Model

Students

Original
Extended
LR 5%
LR 10%
LR Enter

2.60 (0.77)
3.12 (0.55)
2.16 (0.82)
3.07 (1.05)
10.00

General
Practitioners
2.43 (0.70)
2.98 (0.68)
2.35 (0.69)
3.39 (0.93)
10.00

Cardiologists
2.57 (0.70)
3.11 (0.52)
2.24 (0.85)
3.19 (1.06)
10.00

Conclusion
To sum up, similar differences in the models, which were found in Study I,
was also found in Study II. However, even though there were differences
50

<-----Page 50----->between the models dependent on different degrees of expertise in terms
prediction and frugality, these differences were not significant. Therefore, it
is plausible to conclude that no matter expertise level, compensatory decision strategies are about equally good as the non-compensatory F&F decision strategies in terms of predictive accuracy and frugality.

Study III – The “New” Concordant-ranks Strategy
Aim
In Study I and II, it was found that compensatory strategies provided equally
high predictive accuracy than the non-compensatory decision strategies.
However, even though the results from Study I and II reveal how adapted
decisions are to the environment, they were not focused on how decision
makers actually make decisions. Therefore, the aim of this study was to investigate which decision strategies decision makers actually use and whether
the differences between the strategies are similar to those in Study I and II.
Because both the compensatory and non-compensatory strategies provided
high predictive accuracy, the results from Study I and II suggest that maybe
a strategy that combines the strengths of both compensatory and noncompensatory decision strategies might better account for human decision
making. Therefore, another aim of this study was to test a strategy that combines some of the strengths of both compensatory and non-compensatory
decision strategies.
In Study III participants had to, choose the most promising alternative, out of
five alternatives. The alternatives in a choice set were equally attractive in
terms of having equal MAU but differed in terms of being in line to a specific decision strategy. Therefore, participants’ choice would reveal the strategy
they used. One of the strategies was a “new” strategy, the Concordant-Ranks
strategy (CR), which I describe in more detail in the next section. The other
tested strategies were: Lexicographic, Maximin, EBA, MAU, Euclidean
distance, or some other arbitrary strategy.
Using the CR strategy means choosing the alternative that is closest to an
ideal alternative. As I will later show, such an alternative will also have the
same rank-order within its attribute values as the attribute importance
weights, given that all alternatives are equally attractive in terms of MAU.
However, even if the CR alternative is chosen in a majority of the times, and
this alternative is proven to be closer to an ideal alternative than other alternatives, it can be argued that the CR alternative was chosen as a tiebreaker
and not because it was closer to the ideal alternative. Therefore, in an additional task participant had to evaluate the attractiveness of the different alter51

<-----Page 51----->natives one by one. That is, in contrast to the decision task where participants had to choose one alternative out of five, in this task participant only
saw one alternative at a time while evaluating it. Because in the other tested
strategies attributes are compared with one another among the different alternatives, in the attractiveness evaluation task, these alternatives should not
be evaluated as more attractive. CR does not require comparison between
other alternatives; instead, the evaluated alternative is compared with an
ideal alternative. Therefore, if it is true that CR is used as a proxy for minimizing the distance to an ideal alternative, then the CR alternative should
receive higher attractiveness evaluations.
To increase the validity of the results, the alternatives were individually tailored by using attributes that the participants themselves provided. In Experiment 1, two different procedures were used for identifying attributes: inferring attributes from thinking aloud (Thinking-aloud) about an imagined decision or directly stating (Direct-stating) relevant attributes. This precaution is
in line with previous research showing that different procedures for getting
data on decision processes (e.g., think aloud data or retrospective reports)
may influence the decision process (Russo, Johnson, & Stephens, 1989).
Similarly, in order to be sure that the procedure for constructing alternatives
did not favor any of the tested strategies, in Experiment 2, the constraints for
constructing alternatives were relaxed. In Experiment 2, one alternative was
in line with the CR strategy while the other alternatives consisted of arbitrary
attribute values.

What is “The Concordant-Ranks Strategy”?
In order to explain the rationale behind CR an example is needed. Jane, the
bride to be, has an idea of what kind of venue she wants for her wedding.
She knows that the attributes location, size, and environment are the most
important attributes where the importance weights are 3, 2, 1, respectively).
Using the same measuring scale for all the attributes (from 0 to 100), her
ideal alternative would have maximally perfect values (i.e., 100) on these
attributes. She has already eliminated those venues that are far away from
her ideal venue (in Study III, this is achieved by eliminating alternatives with
low MAU), and ended up with two venues. Still, the venues that she is looking at are not 100 on all the attributes because such venue would be outside
the price budget. Jane assigns the following points to the two venues on each
attribute: Venue A: 65 (location), 60 (size), 50 (environment); Venue B: 70
(location), 30 (size), 95 (environment). Because both venues have the same
overall attractiveness (if we use MAU as an attractiveness scale then both
venues would have the same MAU equal to 365), Jane cannot choose between the two. Therefore, she starts investigating the two venues on each of
her important attributes in a non-compensatory manner, starting with the
most important attribute location. Looking at location, she realizes that Ve52

<-----Page 52----->nue B is superior (70 vs. 65). However, she does not want to base her decision only on location because the other attribute values might be unattractive
(if she would have stopped her information search now, her decision strategy
would have been similar to F&F or lexicographic heuristics). Thus, she also
investigates the value on her second most important attribute, size. She finds
that the leading venue, Venue B, is unattractive regarding size (value equal
to 30) and Venue A has a better value on size (60). She then continues to the
third most important attribute and finds that Venue B (value equal to 95) is
superior compared to Venue A (value equal to 50) on environment. However, because different attribute values favor different venues, she cannot
choose one. Therefore, she decides to choose the venue that is most similar
to her ideal venue (the one with maximal values on each attribute). Jane sees
that Venue A has an appealing pattern where the rank order of attribute importance weights and attribute values coincide, whereas this is not true for
Venue B and therefore, she finds Venue A as more similar to her ideal venue.
What she might not know is that in Venue A, all the weighted distances to
her ideal alternative on each attribute (attribute weight x (100 – attribute
value)) are relatively short for all attributes. This is shown in a mathematical
proof in appendix A in Study III. This is because the rank-order of the
attribute values coincides with the rank-order of the attribute importance
weights. The choice process of Jane gives a rationale behind the processes of
the CR strategy, where weights of the underlying attributes are taken in consideration when trying to find an alternative that is proximate to an ideal
alternative.

Method
Participants
In Experiment 1, 61 (42 women) participants and in Experiment 2, 31 (21
women) participants took part in the study. Participants could choose to receive either course credits or a movie ticket as reimbursement for their participation.
Procedure
Both experiments in this study followed the same 5-step procedure:
1. Presentation of experiment and the think-aloud task. In Experiment 1,
one group of participants were only informed about the purpose of the
experiment (Direct-stating group) while the other group were also introduced to the think-aloud method, because they were going to think
aloud in some parts of the experiment (Think-aloud group). In Experiment 2, only the Direct-stating procedure was used.

53

<-----Page 53----->2.

3.

4.

5.

54

Identification of attributes. In the Direct-stating group, participants
were asked to state their most important attributes when choosing a
house/car. In the Think-aloud group, participants were asked to imagine they were going to buy a house/car and think aloud while doing
so. Attributes provided by the Think-aloud group were identified by
rerunning think-aloud recordings. In both groups and both experiments, some attributes were relabeled. For instance, if the participant
had said that it was important for him/her to have a big apartment, this
attribute was relabeled as an attribute called size. After re-labeling, the
attributes were written in the computer program (see Figure A1 in
Appendix A)
Review and ranking of attributes. Participants were asked to distribute
100 points between the attributes they had provided, in a manner so
that the points would reflect how important each attribute was (see
Figure A2 in Appendix A). Further, participants were not allowed to
give zero or equal points to two different attributes.
Presentation and choice of alternatives. Participants were instructed
to choose the most promising alternative out of five alternatives. This
was repeated 10 times, each time with five new alternatives. Each alternative consisted of the attributes the participant had provided earlier. Each of the five alternatives was constructed according to the
tested decision strategies: Lexicographic, Maximin, Euclidean,
weighted Concordant-ranks, and an alternative consisting of arbitrary
values. For an example of how the alternatives were presented see
Figure A3 in Appendix A.
Attractiveness evaluations. Participants were shown one alternative
and were asked to rate the alternative according to how attractive it
was perceived on a scale from 0 to 100(see Figure A4 in Appendix A).
This was done for 10 different alternatives.

<-----Page 54----->Results and discussion – Experiment 1
Choices
As seen in Table 5, the CR alternative was chosen (significantly) more often
than the other alternatives. The lexicographic alternative was chosen significantly more often than the arbitrary alternative, and the maximin alternative
was chosen significantly more often than the lexicographic and the arbitrary
alternative.
Table 5. Choice Frequency for Each of the Five Types of Alternatives.
Think aloud
Chosen alternative
Lexicographic
Maximin
CR
Euclidean
Arbitrary

Direct stating

Frequency

%

Frequency

%

77
80
187
59
47

17.1
17.8
41.5
13.1
10.4

24
36
65
18
17

15.0
22.5
40.6
11.3
10.6

The method for getting attribute weights (step 3 in the procedure) could result in more equal weights than is true for other weight elicitation methods.
For instance, this method could lead to two attributes having the importance
relationship 55:45 while other methods could lead to for example 70:30 for
the same attributes (Wedell & Parducci, 1988). Too equal weights could lead
to MAUs that in fact were not equal, which in turn could mean that the
choices were not based on CR but maybe MAU calculated . Therefore, a
new MAU calculation was tested, where the weights were stretched out. The
CR alternative and highest “new” MAU alternative coincided in 52% of the
cases. However, choices of the CR-alternative were significantly more
common (42% of the choices) than choices with highest new MAU-value
(32% of the choices). It can be concluded that the predominance of CRchoices in line with CR, seen in Table 5, does not seem to result from an
equal weighting bias.
Attractiveness evaluations
As seen in Table 6, the CR alternatives were evaluated as significantly more
attractive compared to all the other alternatives and the maximin alternatives
were evaluated as significantly more attractive than the Euclidean and arbitrary alternatives. The CR alternative had the lowest WED followed by the
maximin, lexicographic, arbitrary, and Euclidean alternative in that order,
meaning that the CR alternative had the shortest WED to an ideal (85.6 % of
the times).

55

<-----Page 55----->Table 6. Means, Standard Deviations (SD) for the Attractiveness Evaluations, Mean
WEDa Values of Each of the Five Alternative Types and Percent of Alternative Type
With the Lowest WED.
Think aloud
Type of
alternative
Lexicographic
Maximin
CR
Euclidean
Arbitrary
a

M

56.0
59.3
65.0
50.4
53.8

SD

17.0
17.1
12.4
18.7
14.9

Direct stating
WED

a

1052
1024
949
1121
1065

Both groups

M

SD

WED

% lowest
WED

64.9
66.8
72.3
60.9
61.6

17.7
18.2
18.2
21.4
18.9

1026
1024
934
1134
1058

8.0
3.3
85.6
0.2
3.1

Weighted Euclidean distance

Results and discussion – Experiment 2
Choices
Similar to Experiment 1, the CR alternative was significantly more chosen
(29.4%) compared to the arbitrary alternatives (17.7%).
Attractiveness evaluations
The CR alternative was rated as significantly more attractive (70.23) than the
arbitrary alternatives (65.15).

Conclusion
The results of Study III show that concordance between the rank order of the
attribute values and attribute weights of an alternative seems to play an important role when choosing the most promising alternative. This concordance is important also in attractiveness judgments of the alternatives. The
CR strategy was shown to be superior compared to MAU, EBA, Euclidean
and other “old” commonly used strategies. Furthermore, the alternative consistent with the CR strategy had also the shortest weighted Euclidean distance to an ideal (for proof, see Appendix A in Study III).

56

<-----Page 56----->Discussion

A scientist's aim in a discussion
with his colleagues is not to
persuade, but to clarify.
~Leo Szilard

Below I will first discuss Study I and II combined, and then discuss Study
III. Afterwards I will give a general discussion of all three studies.

Main Findings
Something old
Investigation of some existing decision strategies
In Study I and II, the tested strategies were two F&F models, which fall into
the category of non-compensatory decision strategies, and logistic regression
models, which fall into the category of compensatory decision strategies.
Results showed that logistic regression, when the information inclusion level
was limited, provided equally high predictive accuracy as the tested F&F
models. Additionally, the logistic regression models with limited information used less information in the models and sometimes utilized fewer cues
than the F&F models. Because logistic regression models combine and compensate information, one would expect them to use more information than
the tested F&F models. However, this was not the case, at least when only
significant cues were considered. Important here is also the difference between the numbers of cues a model consists of and number of cues actually
utilized by the model. If this difference is small then it implies that the model
is better at actually utilizing the information in a saturated way. However,
results showed that in the F&F models, the number of cues actually utilized
was 26-48% less than the number of cues in the model.
In Study I, the different models (built according to five different strategies)
were tested on participant judgments as the dependent variable, but also on
actual diagnoses. Both the actual diagnoses and participant judgments gave
the same fit in all the models when not cross-validated. However, when the
data was cross-validated, the predictive accuracy in actual diagnoses decreased markedly more than the participant judgments.
When modeling using actual diagnoses as the dependent variable, the F&F
models used more information than models using participant judgments as
57

<-----Page 57----->the dependent variable. This was also the case in terms of the amount of
information actually utilized. However, in the logistic regression models the
opposite was the case. Here LR 5 and LR 10 used fewer cues in models using actual diagnoses as the dependent variable compared to models using
participant judgments as the dependent variable. Considering that actual
diagnoses, as compared to participant judgments, provided lower predictive
accuracy, it is plausible to assume that the realism of the judgmental task
used for building models is important when comparing different decision
strategies.
An interesting finding from Study I and II is that in both studies the compensatory decision strategies used a limited portion of information in the model
(even though compensatory) and still were comparable with F&F models in
terms of predictive accuracy. This makes the compensatory decision strategies (logistic regression in this study) equally or even more frugal than noncompensatory decision strategies (F&F strategies in this study). Therefore, it
makes sense to conclude that compensatory decision strategies can better
predict human decision making in the studied tasks.
As mentioned earlier, previous studies have shown conflicting results on
whether F&F or regression models are better for predicting judgments. For
instance, in one study Dhami and Harries (2001) found that both regression
and F&F models were equally good at predicting judgments while in another
study (2001), they found that the F&F models were better. One can wonder
who is right. In study I and II, the methodological strengths from previous
studies were retained, whereas the found methodological weaknesses were
avoided. These weaknesses have made the comparison and testing of different decision strategies unfair and biased the results in favor of F&F strategies. Therefore, it is plausible to assume that the results from studies I and II
are more accurate than previous studies.
So what were the found weaknesses in earlier research? The first avoided
weakness regarded cross-validation. In cross-validation, a subset of the data
is used for building a model and the rest is used to test the validity of the
built model, by letting the model predict the judgments in the remaining
data. When cross-validation is not used, fitting and predicting is based on the
same data. When the data is not cross-validated the predictions will be better
than they actually are and hence overemphasizing the superiority of the
model. In study I and II, it was indeed found that not cross-validating leads
to biased results.
The second weakness regarded the dependent variable. Most of the strategy
comparisons involving F&F versus logistic regression have used ecological
facts rather than judgments as the dependent variable (i.e., Gigerenzer &
Goldstein, 1996). This is not necessarily a weakness, but rather restricts the
58

<-----Page 58----->generalizability of the results. In Study I and II both actual diagnoses and
participant judgment were used as the dependent variable. The difference
between actual diagnoses and participant judgments is that in actual diagnoses, both dependent (the actual judgment) and independent variables (the
cues) are ecological facts while in participant judgments, the judgments are
more subjective (i.e., weaker related to actual disease in our case). Models
built on one of the two sources of dependent variable can give different outcomes and therefore, using both types of data makes the results more generalized. Results from Study I and II showed that indeed the source of the
judgments influence the results.
The third weakness regarded the amount of information included in the regression models. Building models on all available cues or information means
including also information that does not contribute to the prediction and
hence might lead to over-fit, resulting in lower predictive accuracy. For instance, when the logistic regression models consisted of only the significant
information or cues, logistic regression provided equally high predictive
accuracy of decision behavior. This is something that, for some unknown
reason, has been overlooked in previous studies where the compensatory
decision strategies have used all the available information (e.g., Gigerenzer
& Goldstein, 1996; Martignon et al., 2008). It is therefore, reasonable to
assume that indeed, the weaknesses now discussed sometimes have lead to
biased results in previous studies in favor of the F&F strategies.
A matter of expertise
It is common belief that experts make better decisions; therefore, usually the
judgment data used in judgment analysis in order to model decisions has
been judgments from experts. This was the case in Study I. However, because in Study I, the aim was to compare different strategies, independent of
expertise, we cannot be sure that the results can actually be generalized to
individuals with less expertise. The different decision strategies and the way
experts utilize information might not be the same as non-experts. Thus, in
Study II, the judgments were from three groups of doctors, each with different degrees of expertise. The groups were formed according to Shanteau’s
(1988) definition of different degrees or levels of expertise; naïve decision
makers, novice decision makers, and expert decision makers.
Some studies have shown that experienced decision makers make better
decisions (e.g., Jacoby et al., 2001). If this is also true in judgment analysis,
the models built using judgment data from participants with higher degrees
of expertise (cardiologists) should provide higher predictive accuracy than
models based on novice decision makers (general practitioners) and naïve
decision makers (medical students) in that order. When the same decision
strategies tested in Study I also were tested in Study II, but now adding expertise as an independent variable, it was again found that the compensatory
59

<-----Page 59----->strategies (logistic regression) provided equally high predictive accuracy of
judgments than the non-compensatory heuristics (F&F), however, independent of degrees of expertise. This does not necessarily mean that Jacoby et
al. (2001) are wrong but that other factors than expertise can be important
when creating models in judgment analysis. Concerning frugality and expertise, Shanteau argues that experts are more frugal than non-experts are
(Shanteau, 1991; 1992). If this is also true in judgment analysis, then models
based on those with higher degrees of expertise should be more frugal because they can ignore unimportant information. In contrast, Jacoby et al.
(2001) argued decision makers with higher degrees of expertise should use
more information compared to non-experts because experts have the capacity. If this is also the case in judgment analysis, then models based on those
with lower expertise should be more frugal. There was, however, no overall
significant difference in frugality for different levels of expertise. Two explanations to the non-differences are possible. One is there is actually no
difference, at least not in decisions that are similar to the one in Study II, and
the definitions of Jacoby et al. (2001) and Shanteau (1991, 1992) do not
apply in the tested setting. Another explanation is that it is possible the differences would have been significant if degrees of expertise had been established differently. For instance, Kee and colleagues (2003) found that there
were differences between the models (regression versus F&F) and levels of
expertise but they defined expertise differently than how expertise was defined in Study II. Another reason for the difference between their results and
the results in Study II can be due to the discussed weaknesses. For example,
Kee and colleagues did use neither cross-validation nor different levels of
information inclusion in their regression model.
Shanteau and colleagues (Shanteau, Weiss, Thomas, & Pounds, 2002) argued that the nature of the decision task also can affect expert decision making. In Study II, the task of diagnosing heart failure can be seen as a dynamic
task (i.e., involving human behavior). As mentioned by Shanteau (1992), in
situations involving dynamic decision tasks, experts are not necessarily better or more predictable. This can explain why in Study II the predictive accuracy of the models based on expert judgments did not differ from models
based on non-expert judgments. Expertise is very domain specific (Ericsson
et al., 1993; Shanteau, 1992) and can vary, not only between domains but
also, between different type of decisions in the same domain (i.e., different
diagnoses with different task difficulty). For instance, it has been shown that
people, being expert or not, have difficulties thinking in terms of probabilities (Kahneman & Tversky, 1974), which was the response-mode used in
Study I and II. In addition, the participants with different degrees of expertise could have been differently certain of their judgment. The responses
given in probability were coded as either zero or one. However, perhaps
more coding categories or using the probabilities themselves could have
better differentiated between levels of expertise. For instance, those with
60

<-----Page 60----->higher degrees of expertise can be more confident (Mahajan, 1992) with
their response and hence give a probability that is closer to either diagnose or
non-diagnose. Those with lower degree of expertise might give probabilities
that depending on coding schema lead to different judgments.
In sum, the results of Study II strengthens the results from Study I, suggesting that even though both compensatory and non-compensatory strategies
had equally good predictive accuracy, the compensatory strategies are
slightly better at predicting human decision behavior, independent of degrees
of expertise, because they are more frugal.

Something new
The introduction of a new decision strategy
In Study I and II, while the non-compensatory strategies (i.e., F&F) sometimes used more information compared to the compensatory strategies (i.e.,
logistic regression), they still predicted rather well. One reason for both
strategies doing well could be that each strategy has strengths and weaknesses. Compensatory decision strategies integrate information, for example
by compensating one attribute with another, and are hence more nuanced.
The judgment of some patient cases might require the decision maker to
compensate or integrate different pieces of information while in other patient
cases, non-compensatory strategies might do equally well or even better
because in these cases, there is no need for integrating and combining the
information. In addition, regression models might describe the decision policy of some participants better than F&F and vice versa. Nevertheless, the
results from Study I and II speak more about the inferential ability of decision strategies, and less about decision makers’ preferences of these strategies. Recent research shows that decision makers integrate the information,
use compensatory strategies (e.g., Newell & Bröder, 2008), and are capable
of handling computation-demanding decision strategies (Juslin & Persson,
2002). Therefore, it is plausible to hypothesize that the results from Study I
and II can also be extended to how decision makers actually make decisions.
In Study III, some of the advantages of both compensatory and noncompensatory strategies were combined and a new strategy– The concordant
ranks strategy (CR) – was investigated. CR shares the simplicity noncompensatory decision strategies provide (when the attribute value of each
attribute is investigated and compared to the importance weight of the same
attribute in the ideal alternative) while at the same time integrate the information (when holistic pattern of the alternatives are compared to an ideal).
Note that CR does not require that one attribute can be compensated by
another attribute, as is in compensatory strategies, but integrates information
in order to check whether a certain holistic pattern can be found in the alternative.
61

<-----Page 61----->Furthermore, compared to the other tested strategies, CR is the only strategy
that is descriptive, prescriptive, and normative. Remember that descriptive
models describe how decision makers actually make decisions. This is true
in CR that empirically gave account for how decision makers go about in
order to make a decision. Normative models are theoretical descriptions of
how decision makers should make decisions. Because CR implies choosing
an alternative with shortest WED to the ideal alternative, it can be seen as a
normative model. Prescriptive models are links between the descriptive and
normative models. Therefore, CR can also be seen as a prescriptive model
where how decision makers actually make decisions is in line with a theoretical rationale. In contrast, the other tested strategies corresponded to only
one of the three types of models or at best to two of the models. For example, MAU is a normative model that can also act as a prescriptive model or
F&F models are prescriptive models that can also be descriptive.
The concordant-ranks strategy put to the test
Introducing a new strategy is not particularly special; this is why there is a
large body of different strategies. However, what validates a new strategy is
that, when it is put to the test against other “old” and established strategies, it
shows to be superior or equally legitimate to exist in the ecology because in
some situations it provides better decision outcome or account for decisions.
In Study III, in two experiments, CR competed with a normative linear model (MAU), two simple heuristics (Lexicographic and Maximin), a heuristic
that searched more information than the simple heuristics (EBA), and a mathematical descriptive strategy (Euclidean distance). Results showed consistently that the most frequently chosen alternative was the CR alternative, that
is, the alternative that had the same rank-order within the attribute values as
the importance order within the attributes in the ideal alternative.
The runner-up chosen alternatives in Experiment 1 and 2 was the simple
heuristics Lexicographic and Maximin, suggesting that heuristic-based strategies seem to be preferred by some individuals (Dahlstrand & Montgomery,
1984) while majority might prefer, similar to compensatory decision strategies, more information search and integration than the simple heuristics allow. This is coherent with the results from Study I and II where the compensatory and non-compensatory strategies did well, in terms of their predictive
accuracy.
Similar to CR, EBA provides the opportunity to use more information than
the simple heuristics typically do. EBA is a special case of the more general
Selection by Aspects (SBA) model (Barthélemy & Mullet, 1992), which includes both the elimination and selection of alternatives depending on
whether they pass or do not pass certain threshold values on an attribute or
several attributes simultaneously. Using a deterministic version of EBA (see
62

<-----Page 62----->Gati, 1986; Svenson, 1979), Jane starts by inspecting the most important
attribute and then eliminates alternatives falling below a threshold value
associated with the most important attribute. Jane continues to the second
most important and so forth until one alternative remains and, hence is chosen by Jane. If the rank-order of attribute values within an alternative is in
accordance with the rank-order of the threshold values for the corresponding
attributes, EBA will coincide more or less closely with the CR strategy. The
degree of correspondence depends on the number of attributes used in the
elimination procedure and on the distribution of attribute values above the
threshold values of each attribute. Turning to the SBA model, it can be noted
that agreement between the rank-order of weights and attribute values in a
particular alternative may be used as a criterion for selecting an alternative
as the promising alternative. However, this would require SBA to include
ranking patterns as a basis for selection of a promising alternative. In addition, in the attractiveness judgments participants rated the CR alternative as
more attractive, something that is not possible if they had used EBA or SBA.
This is because if participants used EBA they would need to search the information across the alternatives and that was not possible in the attractiveness ratings. Therefore, it is plausible to assume that choices and attractiveness judgments could not have arisen from EBA or SBA, but rather CR.
It is not only the fact that both choice and judgment data clearly favored the
CR strategy that strengthen the support for the CR strategy. Another one is
that CR has a clear theoretical rationale, as shown by the mathematical proof
(see Appendix A) in Study III. Additionally, the CR alternatives had in a
large majority of the choice situations shorter WED to the ideal than was
true for the other choice alternatives.
Some might argue that holding MAU constant for all the alternatives is not
how alternatives appear in the ecology. However, in experimental settings,
there are some trade-offs that must be made in order to control for confounding variables. I believe that these trade-offs are justified because otherwise it
would not have been possible to test the different strategies. In addition,
MAU was only a tool for eliminating less attractive alternatives, which also
happens in the ecology or decision maker’s environment. For instance, Jane
would exclude wedding venues that are too expensive for her. She would
only consider alternatives that are attractive to her (i.e., being in her budget
range) but which cannot be easily differentiated. In our study, less attractive
alternatives were excluded by letting the alternatives have high and equal
MAU. Jane might (in fact probably do) use other procedures or methods in
order to exclude unattractive alternatives, but they lead to the same outcome;
the choice set will consist of attractive alternatives that the decision maker
cannot easily differentiate. However, one can still argue that CR is used secondary to MAU. That is, participants would have used MAU, but because
the alternatives were equal in terms of MAU, they could not apply MAU and
63

<-----Page 63----->hence used CR. However, two different methods of calculating MAU was
tested (by changing the ways attribute weights were established) and both
methods favored the use of the CR strategy also when the alternative MAUmethod predicted the choice of another alternative than the CR alternative.
In summary, when CR was put to the test against some “old” and established
strategies, it was shown that CR was superior. CR is not only theoretically
(shown in the mathematical proof in Appendix A in Study III, and because
CR had the shortest WED compared to the other strategies) superior but also
empirically (shown by the strong choice and attractiveness judgments data
from Experiment 1 and 2). It was found that in line with CR, participants
search for more information (for instance, more than one attribute) than
stated in other strategies and that CR combines simplicity that noncompensatory heuristics provide while still considering all the information,
something that was believed to take place only in the complex and demanding compensatory strategies.

Something borrowed
The common denominator of the “old” and the “new” decision strategy
The ideas behind CR are not completely new. As discussed earlier, it borrows and combines some of the advantages of both compensatory and noncompensatory strategies. Furthermore, in CR, some of the ideas are “borrowed” from the prominence effect (Slovic, 1975; Tversky, Sattah, & Slovic,
1988). According to the prominence effect, Jane would, out of two alternatives, choose the alternative that is better on the more important attribute but
worse on less important attribute, although the two alternatives have been
matched to be equal in attractiveness. Similarly, Montgomery and colleagues
found that the prominence effect takes place not only in choices but also in
attractiveness evaluations (Montgomery, Selart, Gärling, & Lindberg, 1994;
Selart, Gärling, & Montgomery, 1998; Selart, Montgomery, Romanus, &
Gärling, 1994). The prominence effect implies that the more important
attributes will loom larger in both choices and attractiveness evaluations
compared to matching tasks. The prominence effect might take place in
choices in line with choosing the CR alternative; because in both the prominence effect and CR strategy attributes that are more important loom larger
in choice and attractiveness evaluations than is expected from MAU estimates. However, what differentiates CR from the prominence effect is that
the prominence effect is used as a tiebreaker when alternatives are equal.
Moreover, the prominence effect is at hand when the choice is made between
alternatives. Because CR was rated as more attractive independent of other
alternatives, participants cannot have used it as a tiebreaker or for comparing
between alternatives.

64

<-----Page 64----->In CR, some of the ideas of pattern recognition and categorization theories,
where the attributes weights are considered in comparisons (Nosofsky, 1986;
Juslin, Jones, Olsson, & Winman, 2003), have also been “borrowed”. CR
differs from categorization theories in the sense that there is not a prototype
or a group of exemplars serving as the ideal alternative. Instead, there is an
idea of what is maximally good on all the important attributes (which would
correspond to an imagined ideal alternative that may not actually exist) and
that decision makers try to choose an alternative that is proximate to this
ideal. In fact, prototypes and exemplars can advantage from replacing their
definitions with the concept of ideal alternatives. CR offers a simple pattern
matching without actually requiring participants to calculate the weighted
Euclidean distance to the exemplar. Thus, CR offers Jane a strategy that
combines simplicity with the seemingly complex notion of minimizing
weighted multidimensional distance (WED) to an ideal alternative.
CR has also “borrowed” some of the assumptions of the dual process theories. Some claim decision-making is a controlled process where rules and
strategies are used; others claim that it is an automatic process where exemplars in the memory lead the way to a decision (Murphey & Medin, 1985).
In this thesis, I claim that in decision making both controlled and automatic
processes interplay and aid each other in the decision-making process. The
minimization of WED and pattern matching to an ideal alternative that CR
uses is similar to automatic processes. The rank ordering of the attributes is
similar to controlled and conscious processes. What strengthens the psychological validity of CR is that it does not go against the view of human beings
as a creature with limited capacity. Using the CR strategy means finding a
shortcut (by using concordance in ranks) in order to find the alternative with
shortest WED, which otherwise would have been a demanding process.

Something to remember
The main focus of this thesis was to investigate the validity of different decision strategies. Several strategies were compared against each other (Study I
and II) and it was found that even though compensatory strategies and noncompensatory strategies provided equally high predictive accuracy, they
were more frugal. One explanation to why both compensatory and noncompensatory strategies were good as accounting for decision behavior
could be that there are intra-individual differences and different situations
promote different strategies. Another explanation could be that the underlying processes of both strategies are valid and interplaying. Therefore, in
Study III, a new decision strategy – CR –when it is at hand and which better
account for human decision making compared to other existing and established decision strategies was suggested.

65

<-----Page 65----->Finally, to sum up, if there is something to remember from this thesis let it
be two things. First, decision makers can use the simplicity of the noncompensatory strategies while also using the superior complexity that compensatory decision strategies offer. Second, there might be more room for
ideal alternatives as guide-lines for decision making than has been investigated and choosing according to the ideal alternative (which in our case manifested itself in the CR strategy) can also be explained in terms of weighted
Euclidean distance.

Points of caution
A few notes of caution should be made concerning the studies in this thesis. I
will give some notes of caution for each study.
The analysis and conclusion drawn from Study I and II are based on means
calculated over all the participating doctors, and the models are built using
the means. It is possible that some individuals consistently use simple heuristics as seen in Skånér and colleagues (2000). In fact, they might even be
using heuristics other than those investigated in this study. However, the aim
of Study I and II was neither to re-produce the doctors’ decisions nor to reproduce the decision process itself. The aim was to investigate which strategies make better inferences.
When I speak of “no difference in expertise” regarding frugality, I only
speak in terms of how the different models searched or utilized data. In fact,
there might be differences between degrees of expertise that Study I and II
do not account for. Judgment analyses do not fully reflect the cognitive
processes that, in fact, might differ depending on degrees of expertise.
Therefore, I can only speak of no differences in a judgment analysis study.
Related to expertise, there are other ways to group expertise. As Brehmer
and Brehmer (1988) pointed out, experience is not the only variable to group
expertise. Other variables such as information search, personality, type of
education, type of decision task can be used (Ericsson & Lehman, 1996;
Shanteau, 1992). In addition, experts might be using other types of information for their decisions than those given in the patient cases. For instance,
when a doctor reviews a patient vignette, s/he might see the cue age but ignore it because it not relevant in combination with the other cues. However,
when s/he sees the patient in person, the patient’s age might become more
important.
Turning to Study III, previous studies have shown that the experimental design can promote the use of certain strategies (Glöckner & Betsch, 2008).
Therefore presenting the alternatives as pie-diagrams can have promoted the
usage of CR. In addition, even though participants chose the alternative ac66

<-----Page 66----->cording to the CR strategy, they could have used other strategies not tested
in Study III.

Future Research
One issue for future research concerns the method for including information
in the regression model. For instance, information can be included in the
order they are presented to the decision maker, because this might be the
order decision makers process the information. One way to see if this is actually the case, the order of the different cues in a patient case can be counterbalanced. Another method for including information in the regression
model can be based on theory. For example, if according to guidelines and
previous research, age is more determining than gender for the presence of
heart failure. Therefore, age should be included in the model first or presented to the decision maker as the first piece of information.
The comparison of different strategies should include other domains than
just the medical domain and also other diagnoses than those tested in this
thesis. For instance, diagnoses of heart failure are one of the more difficult
diagnoses, and doctors differ in their definition and diagnoses based on the
cues. Asthma, on the other hand, is more straightforward. As Skånér et al.
(2000) pointed out, in heart failure; the difference might be more on individual differences rather on expertise level differences. This point to an important aspect of judgment analysis, that different conditions require different
methods and models as well as a deeper investigation on whose judgment
and decision data to use in order to model decision making.
Regarding Study III, it would be of interest to design experiments where
MAU and WED would predict different choices independently of whether
the rank order of attribute values and importance weights agree or not for a
given alternative. Furthermore, I suggest investigating whether participants
use an alternative based on WED, rank, or both. In Study III, results showed
participants chose the alternative that had the same rank-order within its
attributes as an ideal alternative and this also implied shortest WED. However, what happens if we present participants with alternatives that have the
shortest WED but have not the right rank-order? Alternatively, what happens
if an alternative has the right rank-order but does not have the shortest
WED? In relation to this, different strategies are differently time-consuming.
Because WED is considered as an automatic process, it should require less
time than an alternative with concordance in ranks, which is a controlled
process. Therefore, response times should shed more light on this issue,
Additionally, the inferential ability of CR should also be tested in a judgment
analysis as well as the more general idea that judgments are based on close67

<-----Page 67----->ness to an ideal. In Study I and II, both compensatory and non-compensatory
models were about equally (with logistic regression being more frugal) good
at predicting human behavior. As mentioned earlier, both compensatory and
non-compensatory strategies have advantages and disadvantages. One and
same decision situation can consist of different pieces of information. Some
of the information might better be accounted for by compensatory strategies
while some other information might better be accounted for by noncompensatory strategies. Because CR is a strategy that combines the
strengths of both compensatory and non-compensatory strategies, it ought to
be much better at predicting human behavior and maybe better at accounting
for the information. Note, however, using the CR strategy requires that there
is a CR alternative in the choice set but minimizing the distance to an ideal
alternative may always be a possibility. Therefore, the roles of ideal alternatives should be further investigated in future studies.

68

<-----Page 68----->References

Augier, M. (2000). Models of Herbert A. Simon. Perspectives on Science, 8(4). 407443.
Backlund, L., Bring, J., Skånér, Y., Strender, L-E., & Montgomery, H. (2009). Improving fast and frugal modeling in relation to regression analysis: Test of
three models for medical decision making. Medical Decision Making, 29. 140148.
Backlund, L., Skånér, Y., Montgomery, H., Bring, J., & Strender, L.-E. (2003).
Doctors' decision processes in a drug-prescription task: The validity of rating
scales and think-aloud reports. Organizational Behavior & Human Decision
Processes, 91, 108-117.
Baron, J. (2008). Development of normative models. In Baron. J (Eds.), Thinking
and deciding. (pp. 50-58). Cambridge: Cambridge University Press.
Barron, G., & Erev, I. (2003). Small feedback based decisions and their limited
correspondence to description-based decisions. Journal of Behavioral Decision
Making, 16, 215–233.
Barthélemy, J. P., & Mullet, E. (1992). A model of selection by aspects. Acta Psychologica, 79, 1-19.
Baumeister, R. (2005). The human psych at work. In The cultural animal (pp. 7481). New York: Oxford University Press.
Beach, L. R., & Mitchell, T. R. (1978). A contingency model for the selection of
decision strategies. Academy of Management Review, 3, 439-449.
Bennell, C., Bloomfield, S., Snook, B., Taylor, P., & Barnes, C. (2010). Linkage
analysis in cases of serial burglary: comparing the performance of university
students, police professionals, and a logistic regression model. Psychology,
Crime & Law, 16(6), 507 – 524.
Bicchieri, C. (1993). Rationality and predictability. in Rationality and Coordination
(pp. 1-22). Cambridge: Cambridge University Press.
Bockenholt, U. (1998). Modeling time-dependent preference: Drifts in ideal points.
In M. Greenacre & J. Blasius (Eds.), Visualization of categorical data (pp.
461–476). Hillsdale, NJ: Erlbaum.
Brehmer, B., Joyce C. R. B. (1988). Human Judgment: The SJT View. New York:
North Holland.
Brehmer, A,. & Brehmer, B. (1988). What have we learned about human judgment
from thirty years of policy capturing? In: Brehmer B, Joyce CRB, eds. Human
Judgment: The SJT View (pp. 75-114). New York: North Holland.
Brunswick, E. (1952). The conceptual framework of psychology. (International
Encyclopedia of Unified Science, Volume 1, Number 10.) Chicago: The University of Chicago Press.

69

<-----Page 69----->Busemeyer, J. R., & Johnson, J. G. (2004). Computational models of decision making. In D. J. Koehler & N. Harvey (Eds.), The Blackwell handbook of judgment
and decision making (pp. 133–154). Malden, MA: Blackwell.
Bröder, A. (2000). Assessing the empirical validity of the “Take The Best”-heuristic
as a model of human probabilistic inference. Journal of Experimental Psychology: Learning, Memory, and Cognition, 26, 1332–1346.
Bröder, A. (2003). Decision making with the “adaptivetoolbox”: Inﬂuence of environmental structure, intelligence, and working memory load. Journal of Experimental Psychology:Learning Memory, and Cognition, 29, 611–625.
Bröder, A., & Schiffer, S. (2003). Bayesian strategy as assessment in multi-attribute
decision research. Journal of Behavioral Decision Making, 16, 193–213.
Carroll, J. & Chang, J. (1970). Analysis of individual differences in multidimensional scaling via an N-way generalization of Eckart-Young decomposition. Psychometrika, 35, 283-319.
Chater, N., Oasksford, M., Nakisa, R., & Redington, M. (2003). Fast, frugal, and
rational: How rational norms explain behavior. Organizational Behavior and
Human Decision Processes, 90, 63–86.
Cooksey, R.W. (1996). Judgment Analysis: Theory, Methods and Applications.
Academic Press, New York.
Czerlinski, J., Gigerenzer, G., & Goldstein, D. G. (1999). How good are simple
heuristics? In G. Gigerenzer, P. M. Todd, & the ABC Research Group, Simple
heuristics that make us smart (pp. 97–118). New York: Oxford University
Press.
Dahlstrand, U., & Montgomery, H. (1984). Information search and evaluation
processes in decision making: A computer based process tracing study. Acta
Psychologica, 56, 113-123.
Dawes, R. M., & Corrigan, B. (1974). Linear models in decision making. Psychological Bulletin, 81, 95-106.
Desarbo, W.S., Atalay, A. S., Lebaron, D., & Blanchard, S, J. (2008). Estimating
multiple consumer segment ideal points from context-dependent survey data.
Journal of Consumer Research. 35(1), pp. 142-153.
De Soete, G., Carroll, J. D., & DeSarbo, W. S. (1986). The wandering ideal point
model: A probabilistic multidimensional unfolding model for paired comparison data. Journal of Mathematical Psychology, 30, 28-41.
Dhami, M. K. & Ayton, P. (2001). Bailing and jailing the fast and frugal
way. Journal of Behavioral Decision Making, 14, 141-168.
Dhami, M., & Harries, C. (2001). Fast and frugal versus regression models of human judgment. Thinking and Reasoning, 7, 5-27.
Dhami, M., Hertwig, R., & Hoffrage, U. (2004). The role of representative design in
an ecological approach to cognition. Psychological Bulletin, 130, 959–988.
Dougherty, M. R., Franco-Watkins, A. M., & Thomas, R. (2008). Psychological
plausibility of the theory of probabilistic mental models and the
fast and frugal heuristics. Psychological Review, 115, 199 –213.
Edwards, W., Guttentag, M., & Snapper, K. (1975). A decision-theoretic approach
to evaluation research. In E. L. Struening and M. Guttentag (eds.), Handbook
of Evaluation Research (vol. 1, pp. 139-81). Beverly Hills, CA: Sage.
Edwards, W., & Newman, J. R. (1982). Multiattribute Evaluation. Beverly Hills,
CA: Sage.

70

<-----Page 70----->Einhorn, H. (1974). Expert judgment: Some necessary conditions and an example.
Journal of Applied Psychology, 59, 562-571.
Elrod, T., Johnson, R. D., & White, J. (2004). A new integrated model of noncompensatory and compensatory decision strategies. Organizational Behavior and
Human Decision Process, 95, 1–19.
Elstein, A. S., Shulman, L. S., & Sprafka, S. A. (1978). Medical problem solving:
An analysis of clinical reasoning. Cambridge, MA: Harvard University Press.
Engel, J.D., Wigton, R.S., LaDuca, A, & Blacklow, R.S. (1990). A social judgment
theory perspective on clinical problem solving. Evaluation and the Health Professions, 13, 63-78.
Erev, I., & Barron, G. (2005). On adaptation, maximization, and reinforcement
learning among cognitive strategies. Psychological Review, 112, 912–931.
Ericsson K. A, Charness N., Feltovich, P., & Hoffman, R. R. (2006). Cambridge
Handbook of Expertise and Expert Performance. Cambridge: Cambridge University Press.
Ericsson, K. A., Krampe, R. T., & Tesch-Romer, C. (1993). The role of deliberate
practice in the acquisition of expert performance. Psychological Review,
100(3), 363–406.
Ericsson, K. A., & Lehmann, A. C. (1996). Expert and exceptional performance: Evidence on maximal adaptations on task constraints. Annual Review of Psychology, 47, 273-305.
Ericsson, K. A., Roaring, R. W., & Nandagopal, K. (2007). Giftedness and evidence
for reproducibly superior performance, High Ability Studies, 18, 3-56
Erickson, M. A., & Kruschke, J. K. (1998). Rules and exemplars in category learning. Journal of Experimental Psychology: General, 127, 107–140.
Ettenson, R., J. Shanteau, J,. & Krogstad, J. (1987). Expert judgment: Is more information better?. Psychological Reports 60, 227-238.
Faust, D., & Ziskin, J. (1988). The expert witness in psychology and psychiatry.
Science, 241, 31-35.
Fischer, G. W. (1975). Experimental applications of multi-attribute utility models. In
D. Wendt and C. Vlek (eds.), Utility, Probability, and Human Decision Making
(pp. 7-46). Dordrecht, Holland: D. Reidel Publishing Company.
Fischer, J.E., Steiner, F., Zucol, F., Berger, C., Martignon, L., Bossart, W., et al.
(2002). Using simple heuristics to target macrolide prescription in children
with community-acquired pneumonia. Archives of Pediatrics, 156, 1005–1008.
Fischhoff, B., Slovic, P., & Lichtenstein, S. (1978). Fault trees: Sensitivity of estimated failure probabilities to problem representations. Journal of Experimental
Psychology: Human Perception and Performance, 4, 330-344.
Gafni, A., & Charles, C. (1998). The physician–patient encounter: The physician as
a perfect agent for the patient versus the informed treatment decision-making
model. Social Science & Medicine, 47 (3), 347-354.
Gardiner, P. C., & Edwards, W. (1975). Public values: Multiattribute-utility measurement for social decision making. In M. F. Kaplan & S. Schwartz (Eds.),
Human judgment and decision processes (pp. 1-37). NY: Academic Press.
Gati, I. (1986). Making career decisions: A sequential elimination approach. Journal
of Counseling Psychology, 33, 408–417.
Gigerenzer, G. (2000). Ecological Rationality. In: G Gigerencer. Adaptive thinking:
Rationality in the real world (pp 58-59). Oxford, UK: Oxford University Press.

71

<-----Page 71----->Gigerenzer, G. (2006). Heuristics. In G. Gigerenzer & E. Engel (Eds.). Heuristics
and the law (pp. 17-45). Cambridge, MA: MIT Press.
Gigerenzer, G., (2007). Fast and Frugal Heuristics: The tools of bounded rationality.
In D. J. Koehler & N. Harvey (Eds.), Blackwell Handbook of Judgment & Decision Making (pp. 62-88). Oxford: Blackwell Publishing.
Gigerenzer, G., & Goldstein, D. (1996). Reasoning the fast and frugal way: Models
of bounded rationality. Psychological Review, 103, 650–669.
Gigerenzer, G., Hoffrage, U., & Kleinbölting, H. (1991). Probabilistic mental models: A Brunswickian theory of confidence. Psychological Review, 98, 506-528.
Gigerenzer, G., & Selten, R. (2002). Bounded rationality: The adaptive toolbox.
Cambridge, Massachusetts: MIT Press.
Gigerenzer, G., Todd, P. M., & The ABC Research Group. (1999). Simple heuristics
that make us smart. Oxford: Oxford University Press.
Gilovich, T., Grifﬁn, D., & Kahneman, D. (2002). Heuristics and biases: The psychology of intuitive Judgment. Cambridge, UK: Cambridge University Press.
Glöckner, A., & Betsch, T. (2008). Multiple-reason decision making based on automatic processing. Journal of Experimental Psychology: Learning, Memory,
and Cognition, 34, 1055-1075.
Goldberg, L. R. (1970). Man versus model of man: A rationale, plus some evidence
for a method of improving on clinical inferences. Psychological Bulletin, 73,
422-432.
Goldstein, D. G., & Gigerenzer, G. (2002). Models of ecological rationality: The
recognition heuristic. Psychological Review, 109, 75–90
Goldstone, R. L., & Son, J. (2005). Similarity. In K. Holyoak & R. Morrison
(Eds.), Cambridge handbook of thinking and reasoning, (pp. 13-36). Cambridge: Cambridge University Press.
Griffin, D. W., Dunning, D., & Ross, L. (1990). The role of construal processes in
overconfident predictions about the self and others. Journal of Personality and
Social Psychology, 59, 1128-1139.
Hammond, K. R. (1990). Functionalism and illusionism: Can integration be usefully
achieved? In R. M. Hogarth (Ed.), Insights in decision making: A tribute to
Hillel J. Einhorn (pp. 227-261). Chicago: University of Chicago Press.
Hammond, K. R. (1996). Human judgment and social policy: Irreducible uncertainty, inevitable error, unavailable injustice. New York: Oxford University Press.
Hammond, K. R. (2007). Beyond rationality: The search for wisdom in a troubled
time. New York: Oxford University Press.
Hastie, R., & Pennington, N. (1995). Cognitive approaches to judgment and decision
making. In J, Busemeyer. D, L, Medin, & R, Hastie (Eds), Decision making
from a cognitive perspective, (pp, 1-31), San Diego: Academic Press.
Heald, J. E. (1991). Social judgment theory: Applications to educational decision
making. Educational Administration Quarterly, 27, 343-357.
Holyoak, K. J., & Simon, D. (1999). Bidirectional reasoning in decision making by
constraint satisfaction. Journal of Experimental Psychology: General, 128, 331.
Horan, C. B. (1969). Multidimensional scaling: Combining observa- tions when
individuals have different perceptual structures. Psychometrika, 34, 139-165.
Hsee, C. K., Loewenstein, G. F., Blount, S. & Bazerman, M. H. (1999). Preference
reversals between joint and separate evaluations of options: A review and theoretical analysis. Psychological Bulletin, 125, 576-590.

72

<-----Page 72----->Jacoby, J., Morin, M., Johar, G., Gurhan, Z., Kuss, A., & Mazursky, D. (2001).
Training novice investors to become more expert: The role of information accessing strategy. Journal of Psychology and Financial Markets, 2, 69-79.
Juslin, P., Jones, S., Olsson, H., & Winman, A. (2003). Cue abstraction and exemplar memory in categorization. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 29, 924-941.
Juslin, P., Olsson, H., & Olsson, A-C. (2003). Exemplar effects in categorization
and multiple-cue judgment. Journal of Experimental Psychology: General,
132, 133-156.
Juslin, P., & Persson, M. (2002). PROBabilities from EXemplars: A “lazy” algorithm for probabilistic inference from generic knowledge. Cognitive
Science, 26, 563-607.
Jönsson, F. U., & Kerimi, N. (2010). An Investigation of Students’ Knowledge of
the Delayed Judgments of Learning Effect. Journal of Cognitive Psychology.
Kahneman, D. (2003). A perspective on judgment and choice: Mapping bounded
rationality. American Psychologist, 58, 697-720.
Kahneman, D., & Frederick, S. (2002). Representativeness revisited: Attribute substitution in intuitive judgment. In T. Gilovich, D. Griffin & D. Kahneman
(Eds.), Heuristics and biases: The psychology of intuitive judgment (49-81).
New York: Cambridge University Press.
Kahneman, D., Knetsch, J., & Thaler, R. (1990). Experimental Test of the endowment effect and the Coase Theorem. Journal of Political Economy 98(6), 13251348.
Kahneman, D., & Tversky, A. (1972). Subjective Probability: A Judgment of Representativeness. Cognitive Psychology, 3, 430-54.
Kahneman, D., & Tversky, A. (1973). On the psychology of prediction. Psychological Review, 80, 237-251.
Kahneman, D., & Tversky, A. (1982). On the study of statistical intuition. Cognition, 12, 325-326.
Kee, F., Jenkins, J., McIIwaine, S., Patterson, C., Harper, S., & Shields, M. (2003).
Fast and frugal models of clinical judgment in novice and expert physicians.
Medical Decision Making, 23, 293-300.
Keeney, R. L., & Raiffa, H. (1993a). Tradeoffs under certainty. In R. L. Keeney, &
H. Raiffa (Eds). Decisions with multiple objectives: Preference and value tradeoffs (66-129). New York: Wiley.
Keeney, R. L., & Raiffa, H. (1993b). Multiattribute preferences under uncertainity:
The two-attribute case. In R. L. Keeney, & H. Raiffa (Eds). Decisions with
multiple objectives: Preference and value tradeoffs (219-273). New York: Wiley.
Klayman, J. (1983). Analysis of predecisional search patterns. In P. Humphreys, O.
Svenson, & A. Vari (Eds.), Analyzing and aiding decision processes (pp. 400414). Amsterdam: North Holland.
Klein, G. A. (1993). A recognition primed decision (RPD) model of rapid decision
making. In G. A. Klein, J. Orasanu, R. Calderwood, & C. E. Zsambok (Eds.),
Decision-making in action: Models and methods (pp. 138–147). Norwood, NJ:
Ablex.
Koehler, D.J., & Harvey, N. (2004). (Eds.), Blackwell handbook of judgment and
decision making. Oxford, UK: Blackwell.

73

<-----Page 73----->Krupka, M. C., Peaslee, A. T., & Laquer, H. L. (1983). Gaseous Fuel Safety Assessment for Light-Duty Automotive Vehicles. Los Alamos National Laboratory. Technical Report.
Kuhl, J. (1984). Volitional aspects of achievement motivation and learned helplessness: Toward a comprehensive theory of action-control. In B. A. Maher (Ed.),
Progress in experimental personality research (pp. 99-171). New York: Academic Press.
Larrick, R. P., Morgan, J. N., & Nisbett, R. E. (1990). Teaching the use of costbenefit reasoning in everyday life. Psychological Science, 1, 362-370.
Lichtenstein, S., & Slovic, P. (1971). Reversals of preference between bids and
choices in gambling decisions. Journal of Experimental Psychology, 89, 46-55.
Lichtenstein, S., & Slovic, P. (2006). The construction of preferences: An overview.
In S. Lichtenstein & P. Slovic (Eds.), The construction of preference (pp. 140). New York, NY: Cambridge University Press.
Lindemann, P. C., & Markman, A. B. (1996). Alignability and attribute importance
in choice. In C. Cottrell (Eds.), Proceedings of the Eighteenth Annual. meeting
of the Cognitive Sciencec Society. Mahwah, NJ: Erlbaurn.
Luce, R. D. (1992). Where does subjective expected utility fail descriptively. Journal of Risk and Uncertainty, 5, 5-27.
MacKay, D.B., Easley, R.F., & Zinnes, J.L. (1995). A single ideal point model for
market structure analysis. Journal of Marketing Research, 32, 433–443.
Mahajan, J. (1992). The Overconfidence Effect in Marketing Management Predictions. Journal of Marketing Research, 29, 329-42.
Martignon, L. (2001). Comparing fast and frugal heuristics and optimal models. In
G. Gigerenzer & R. Selten (Eds.), Bounded rationality: The adaptive toolbox
(pp. 147-171). Cambridge, MA: MIT Press.
Martignon, L., & Hoffrage, U. (2002). Fast, frugal, and fit: Simple heuristics for
paired comparison. Theory and Decision, 52, 29–71
Martignon, L., Katsikopoulos, K. V., & Woike, J. K. (2008). Categorization with
limited resources: A family of simple heuristics. Journal of Mathematical Psychology, 52, 352-361.
Metcalfe, J., & Finn, B. (2008). Evidence that judgments of learning are causally
related to study choice. Psychonomic Bulletin & Review. Vol 15(1), 174-179.
Meyer, M. A., & Booker, J. M. (2001). Eliciting and analyzing expert judgment: A
practical guide (p. 3). Philadelphia, PA: ASA-SIAM.
Meyer, M. A., Booker, J. M., Cullingford, H. S., & Peaslee, A. T., JR. (1982). A
Data-Gathering Method for Use in Modeling Energy Research, Development
and Demonstration Programs, in T. N. Veziroglu (Ed.) Energy Programs, Policy, and Economics: Alternative Energy Sources (p. 421-430). Ann Arbor, MI:
Ann Arbor Science.
Miyamoto, J. M., & Eraker, S. A. (1988). A multiplicative model of the utility of
survival duration and health quality. Journal of Experimental Psychology:
General, 117, 3-20.
Montgomery, H. (1983). Decision rules and the search for a dominance structure:
Towards a process model of decision making. In P. Humphreys, O. Svenson, &
A. Vari (Eds.), Analyzing and aiding decision processes (pp. 471-483). Amsterdam: North-Holland.

74

<-----Page 74----->Montgomery, H., & Svenson, O. (1976). On decision rules and information
processing strategies in multiattribute decision making, Scandinavian Journal
of Psychology, 17, 283-291.
Montgomery, H., Selart, M., Gärling, T., & Lindberg, E. (1994).The judgmentchoice discrepancy: Noncompatibility or restructuring? Journal of Behavioral
Decision Making, 7, 145-155.
Murphy. G,. & Medin. D. L. (1985). The role of theories in conceptual coherence, Psychological Review, 92, 289–316.
Newell, A., & Simon, H. A. (1972). Human problem solving. Englewood Cliffs, NJ:
Prentice Hall.
Newell, B. R. (2005). Re-visions of rationality. Trends in Cognitive Sciences, 9, 11–
15. Newell, B. R., Lagnado, D. A, & Shanks, D. R. (2007). Straight Choices:
The psychology of decision making. Hove, UK: Psychology Press.
Newell, B. R., & Bröder, A. (2008). Cognitive processes, models and metaphors in
decision research. Judgment and Decision Making, 3, 195–204.
Newell, B. R., Lagnado, D. A., & Shanks, D. R. (2007). Stages of judgment I: Discovering, acquiring and combining information. In Benjamin R., David A.,
David R. (Eds.), Straight Choices The Psychology of Decision Making (pp 2545). UK: Psychology Press.
Newell, B. R., & Rakow, T. (2007). The role of experience in decisions from description. Psychonomic Bulletin and Review, 14, 1133–1139.
Newell, B.R., & Shanks, D.R. (2007). Recognizing what you like: examining the
relation between the mere-exposure effect and recognition. European Journal
of Cognitive Psychology, 19, 103-118.
Nisbett, R. E., Krantz, D. H., Jepson, C., & Kunda, Z. (1983). The use of statistical
heuristics in everyday inductive reasoning. Psychological Review, 90, 339-363
10.
Nosofsky, R.M. (1986). Attention, similarity, and the identification
categorization relationship. Journal of Experimental Psychology: General, 115,
39-57.
Nosofsky, R. M., & Johansen, M. K. (2000). Exemplar-based accounts of “multiplesystem” phenomena in perceptual categorization. Psychonomic Bulletin & Review, 7, 375–402.
Nosofsky, R. M., & Palmeri, T. J. (1997). An exemplar-based random walk model
of speeded classification. Psychological Review, 104, 266–300.
Paivio, A. (2007). Mind and its evolution: A dual coding theoretical approach.
Mahwah, NJ: Erlbaum.
Patel, V. L., Arocha, J. F., & Kaufman, D. R. (1999). Expertise and tacit knowledge
in medicine. In R. J. Sternberg & J. A. Horvath (Eds.), Tacit knowledge in professional practice: Researcher and practitioner perspectives (pp. 75-99).
Mahwah, N.J: Erlbaum.
Payne, J. W., & Bettman, J. R. (2004). Walking the scarecrow: The informationprocessing approach to decision research. In D. J. Koehler & N. Harvey (Eds.),
Blackwell handbook of judgment & decision making (pp. 110-132). New York:
Blackwell Publishing
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1995). An information processing
perspective on choice, in Busemeyer, J., Medin, D.L. and Hastie, R. (Eds), Decision Making from a Cognitive Perspective (pp.137-75). San Diego, CA: Academic Press.

75

<-----Page 75----->Pitt, M. A., Myung, I. J., & Zhang, S. (2002). Toward a method of selecting among
computational models of cognition. Psychological Review, 109, 472-491.
Plutowski, M., Sakata, S., & White, H. (1994). Cross-validation estimates IMSE. in
Cowan, J.D., Tesauro, G., and Alspector, J. (Eds.) Advances in Neural Information Processing Systems (pp. 391-398). San Mateo, CA: Morgan Kaufman.
Posner, M. (1988). Introduction: What is it to be an expert? In Chi, M. T. H., Claser,
R., & Farr, M.J. (Eds.), The Nature of expertise (pp. xxix-xxxvi). NJ: Erlbaum.
Roberts, S., & Pashler, H. (2000). How persuasive is a good ﬁt? A comment on
theory testing. Psychological Review, 107, 358–367.
Ross, B. H. (1987). This is like that: The use of earlier problems and the separation
of similarity effects. Journal of Experimental Psychology: Learning, Memory,
and Cognition, 13, 629-639.
Ross, B. H. (1989). Distinguishing types of superficial similarities: Different effects
on the access and use of earlier examples. Journal of Experimental Psychology: Learning, Memory, and Cognition, 15, 456-468.
Rubinstein, R., & Zhou, Y. (2000), Phys. Lett. A, 267, 379.
Russo, J. E., & Dosher, B. A. (1983). Strategies for multiattribute binary choices. Journal of Experimental Psychology: Learning, Memory, and Cognition, 9,
676-696.
Russo, J. E., Johnson, E. J., & Stephens, D. L. (1989). The validity of verbal protocols. Memory & Cognition, 17, 759-769.
Russo, J. E., Medvec, V. H., & Meloy, M. G. (1996). The distortion of information
during decisions. Organizational Behavior and Human Decision Processes, 66,
102-110.
Selart, M., Gärling, T., & Montgomery, H. (1998). Compatibility and use of information processing strategies. Journal of Behavioral Decision Making, 11, 5972.
Selart, M., Montgomery, H., Romanus, J., & Gärling, T. (1994). Violation of procedure invariance in preference measurement: Cognitive explanations. European
Journal of Cognitive Psychology, 6, 417-436.
Shanteau, J. (1987). Psychological characteristics of expert decision makers. In J. L.
Mumpower, O. Renn, L. D. Phillips, & V. R. R. Uppuluri (Eds.), Expert judgment and expert systems (pp. 289-304). Berlin: Springer-Verlag.
Shanteau, J. (1988). Psychological characteristics and strategies of expert decision
makers. Acta Psychologica, 68, 203-21.
Shanteau, J. (1991). Psychological characteristics and strategies of experts. In: G.
Wright and F. Bolger (eds.), Expertise and decision support (pp. 16-19). New
York: Plenum.
Shanteau, J. (1992). How much information does an expert use? Is it relevant. Acta
Psychologica, 81, 75-86.
Shanteau, J., Weiss, D. J., Thomas, R. P., Pounds, J. C. (2002). Performance based
assessment of expertise: how to decide if someone is an expert or not. Eur J
Operational Res, 63, 136-253.
Shugan, S. M. (1980). The cost of thinking. Journal of Consumer Research, 7, 99111.
Simon, H. A. (1978). Rationality as process and as product of thought. American
Economic Review, 68, 1-6.
Simon, H. A. (1982). Models of Bounded Rationality. Cambridge, Mass: MIT Press.

76

<-----Page 76----->Simon, H. A. (1991). Bounded Rationality and Organizational Learning. Organization Science, 2(1), 125–134.
Skånér, Y., Bring, J., Ullman, B., & Strender, L-E. (2000). The use of clinical information in diagnosing chronic heart failure: A comparison between general
practitioners, cardiologists, and students. J Clin Epidemiol. 53,1081–1088.
Sloman, S. A. (1996). The empirical case for two systems of reasoning. Psychological Bulletin, 119, 3-22.
Slovic, P. (1975). Choice between equally valued alternatives. Journal of Experimental Psychology: Human Perception and Performance, 1, 280-287.
Slovic, P., Finucane, M., Peters, E. R., & MacGregor, D. G. (2002). The aﬀect heuristic. In T. Gilovich, D. Griﬃn, & D. Kahneman (Eds.), Heuristics and biases:
The psychology of intuitive judgment (pp. 397–420). New York: Cambridge
University Press.
Slovic, P., & MacPhillamy, D. (1974). Dimensional commensurability and cue utilization in comparative judgment. Organizational Behavior and Human Performance, 11, 172-194.
Smith, L., & Gilhooly, K. (2006). Regression versus fast and frugal models of decision-making: The case of prescribing for depression. Applied Cognitive Psychology, 20, 265-274
Smith, E. E., Patalano, A. L., & Jonides, J. (1998). Alternative strategies of categorization. Cognition, 65, 167–196.
Sun, R. (2002). Duality of the Mind. Mahwah, NJ: Lawrence Erlbaum Associates.
Svenson, O. (1979). Process descriptions of decision making, Organizational Behavior and Human Performance, 23, 86-112.
Tenenbaum, J. B. (1999). Bayesian modelling of human concept learning. In M. S.
Kearns, S.A. Solla, & D.A. Cohn, (Eds.), Advances in neural information
processing systems (pp. 59-65). Cambridge, MA: MIT Press.
Tetlock, Ph. E. (2005), Expert olitical judgment: How good is it? How Can we
know? Princeton University Press, Princeton, NJ.
Todd, P. M., & Gigerenzer, G. (2003). Bounding rationality to the world. Journal of
Economic Psychology, 24, 143–165.
Troutman, C. M., & Shanteau, J. (1976). Do consumers evaluate products by adding
or averaging attribute information. Journal of Consumer Research, 3, 101-106.
Tversky, A. (1969). Intransitivity of preferences. Psychological Review, 76, 31–48.
Tversky, A. (1972). Elimination by aspects: A theory of choice. Psychological Review, 79, 281–299.
Tversky, A. (1977). Features of similarity. Psychological Review, 84, 327–352.
Tversky, A., & Kahneman, D. (1974). Judgment under uncertainty: Heuristics and
biases. Science,185. pages
Tversky, A., & Kahneman, D. (1980). Causal schemas in judgments under uncertainty. In M. Fishbein (Ed.), Progress in social psychology(Vol. 1, pp. 49-72).
Hillsdale, NJ: Erlbaum.
Tversky, A., & Kahneman, D. (1981). The framing of decisions and psychology of
choice. Science, 211, 453-458.
Tversky, A., Sattah, S., & Slovic, P. (1988). Contingent weighting in judgment and
choice. Psychological Review, 95 , 371-384.
Waller, W. S. (1988). Brunswickian research in accounting and auditing. In B.
Brehmer & C. R. B. Joyce (Eds.), Human judgment: The SJT view (pp. 247272). New York: North-Holland.

77

<-----Page 77----->Wallsten, T. S. (1971). Subjectively expected utility theory and subjects' probability
estimates: Use of measurement-free techniques. Journal of Experimental Psychology, 88, 31-40.
Wedell, D. H., & Parducci, A. (1988). The category effect in social judgment: Experimental ratings of happines. Journal of Personality and Social Psychology, 55,
341-356.
Wigton, R. S. (1988). Use of linear models to analyze physicians' decisions. Medical
Decision Making, 8, 241-252.
Wigton, R. S. (1996). Social Judgment Theory and Medical Judgment. Thinking and
Reasoning, 2,175-190.
Wilson, T.D., Laser, P.S., & Stone, J.I. (1982). Judging the predictors of one's own
mood: Accuracy and the use of shared theories. Journal of Experimental Social
Psychology, 18, 537–556.
Wineburg, S. (1998). Reading Abraham Lincoln: An expert-expert study in the interpretation of historical texts. Cognitive Science. 22(3). 319-346.
Wolf, B. (2000). The structure of the human world: Brunswick’s organismenvironment-model. http://www.Brunswick.org. Notes and essays.
Yates, J. F., Jagacinski, C. M., & Faber, M. D. (1978). Evaluation of partially described multiattribute options. Organizational Behavior and Human Performance, 21, 240-251.
Yushi, G. (2006). Differentiation, coherence, and similarity: A theory of choice in
context, Dissertation Abstracts International: Section B: The Sciences and Engineering, 66, 7-B, 39-67.
Zakay, D., & Barak, A. (1984). Meaning and career decision making. Journal of
Vocational Behavior, 24, 1-14.
Zakay, D., & Dil, D. (1984). Degree of post-decisional confidence as a function of
the distances of the offered alternatives from an "ideal" alternative. Archiv für
Psychologie, 136, 293-300.
Zedeck, S. (1977). An information processing model and approach to the study of
motivation. Organizational Behavior and Human Performance, 18, 47-77.
Zeleny, M., (1976). The attribute-dynamic attitude model. Management
Sciences, 23, 12–25.

78

<-----Page 78----->Appendix

Appendix A – Experiment procedure in Study III

Figure A1. Corresponding to step two in procedure of Study III, where participants had were presented with their identified attributes.

Figure A2. Corresponding to step three in procedure of Study III, where
participants were asked to distribute 100 points between the attributes.

79

<-----Page 79----->Figure A3. Corresponding to step four in procedure of Study III, where participants had to choose the most promising alternative. Each alternative consisted of the attributes identified earlier. Each alternative was presented in a
unique color. This procedure was repeated 10 times, each time with five new
alternatives.

Figure A4. Corresponding to step five in procedure of Study III, where participants were asked to rate each alternative according to how attractive it
was perceived on a scale from 0 (not attractive at all) to 100 (most attractive). This was done for 10 different alternatives.

80

