<-----Page 0----->Distinguishing Control from Learning in Total Quality Management: A Contingency
Perspective
Author(s): Sim B. Sitkin, Kathleen M. Sutcliffe and Roger G. Schroeder
Reviewed work(s):
Source: The Academy of Management Review, Vol. 19, No. 3, Special Issue: "Total Quality"
(Jul., 1994), pp. 537-564
Published by: Academy of Management
Stable URL: http://www.jstor.org/stable/258938 .
Accessed: 18/10/2012 12:19
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at .
http://www.jstor.org/page/info/about/policies/terms.jsp

.
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of
content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms
of scholarship. For more information about JSTOR, please contact support@jstor.org.

.

Academy of Management is collaborating with JSTOR to digitize, preserve and extend access to The Academy
of Management Review.

http://www.jstor.org

<-----Page 1----->?

Academy of Management Review
1994, Vol. 19, No. 3, 537-564.

DISTINGUISHINGCONTROLFROMLEARNING
IN TOTALQUALITYMANAGEMENT:
A CONTINGENCYPERSPECTIVE
SIM B SITKIN
Duke University
KATHLEENM. SUTCLIFFE
University of Minnesota
ROGER G. SCHROEDER
University of Minnesota
The singular emphasis on control that has characterized traditional
approaches to total quality management (TQM) implementation are
not well suited to conditions of high task uncertainty, a limitation that
has not been recognized in the popular TQM movement. Although the
fundamental precepts advocated by founders of the quality movement
can accommodate conditions of high uncertainty, the way that these
basic TQM precepts have been articulated, extended, and applied
has not reflected the distinct, learning-oriented requirements associated with higher levels of uncertainty. A broader, more theory-driven
perspective on TQM is proposed to clearly distinguish control from
learning goals and, thus, to begin to address limitations in the way
TQM has been conceptualized and applied in the past.

Throughout the past century, change movements in management often have been sold as near-universal remedies for a wide range of organizational problems. Scientific management,
human relations, and
T-groups are examples of change movements that failed to live up to their
original promises. Even though scholars have acknowledged for years the
idea that there is no one best way to organize, the idea that high performance is a consequence of the extent to which organizational systems are
attuned to contextual requirements has not always been salient to proponents of change. In part, this can be explained by the observation that,
as the momentum of popular change movements builds, the temperance
implied by contingency theory can be swept aside by the sheer enthusiasm of change advocates.
We would like to express our appreciation for helpful feedback concerning earlier drafts
of this article to John Seely Brown, Erhard Bruderer, Margaret Graham, Steve Lutze, Elizabeth Pierson, David Robson, Denise Rousseau, and Andrew Van de Ven. The thoughtful
comments of the Special Issue Editors, David Bowen and James Dean, and two anonymous
reviewers were also extremely helpful in sharpening our ideas, and we wish to acknowledge their constructive assistance.
537

<-----Page 2----->538

Academy of Management Review

July

Total quality management (TQM) has taken on many of the characteristics of earlier management fads (Main, 1991; Tetzeli, 1992). Although
concerns for quality surfaced early in the century (e.g., Shewhart, 1931)
and began to diffuse following World War II, it is only within the last
decade that corporations, consumers, and government agencies in the
United States have become broadly aware of-and
increasingly enamored with-the
TQM concept (Lawler, Mohrman, & Ledford, 1992; Port,
Carey, Kelly, & Forest, 1992; Seymour & Collett, 1991). Snell and Dean
(1992: 470) succinctly captured the core features of TQM as it has come to
be practiced: "total quality is characterized by a few basic principlesdoing things right the first time, striving for continuous improvement, and
fulfilling customer needs-as
well as a number of associated practices."
As this conception of TQM has diffused, many of the familiar problems
associated with undiscriminating acceptance have surfaced (McLagan,
1991).
TQM has been advocated as universally applicable to organizations
and organizational activities (Crosby, 1979; Deming, 1986; Juran, 1986)
with virtually no attention to the nature of the uncertainty faced by the
organization. As a result, TQM is in danger of being "oversold," inappropriately implemented, and ineffective. Indeed, this may explain some of
the failures of TQM that have received attention in the popular press (The
Economist, 1992; Fuchsberg, 1991a; Hospitals, 1992; Peters, 1992; Training
& Development, 1992).
We are motivated by a concern that the potential contributions of
TQM could be lost if its theoretical underpinnings and boundary conditions are not critically assessed. We examine the basic precepts, principles, and practices underlying TQM in order to propose a contingency
approach to conceptualizing TQM that provides a basis for predicting the
conditions under which the use of different aspects of TQM should be
more or less effective. The overall patterns that emerge from our analysis
suggest that TQM is not a panacea that can be unthinkingly used, but that
it must be implemented with a clear sense of the degree to which the
context is characterized by uncertainty, nonroutineness, and/or instability.
This article builds on the familiar contingency theory catechism that
when systems are poorly attuned to contextual requirements, a number of
problems may ensue. Although a contingency perspective implies that
TQM principles and associated practices should be matched appropriately to situational requirements, the TQM literature has not developed
an adequate conceptual foundation upon which to base such a matching
process. Though contingency theory is hardly novel to organizational researchers, it has not been reflected in the work on TQM to date and, thus,
presents an opportunity for those with an interest in TQM to conceptualize
more precisely what TQM is and to theorize about how TQM has an impact on organizational effectiveness. We can draw directly from the work
of contingency theorists (e.g., Lawrence & Lorsch, 1967; Perrow, 1967;

<-----Page 3----->1994

Sitkin, Sutcliffe, and Schroeder

539

Thompson, 1967; Woodward, 1965), who not only established the general
importance of matching an organization's structure and processes to situational requirements, but also focused especially on uncertainty as a
critical situational feature. Specifically, these theorists stressed that organizational effectiveness is contingent upon how well organizations
adapt to the distinct requirements associated with well understood versus
poorly understood task, organizational, or environmental conditions (i.e.,
uncertainty).
Definitions of uncertainty in the organizational literature have taken
a wide variety of foci, including the nature of the organization's environment (Duncan, 1972), rates of environmental change (Lawrence & Lorsch,
1967), and task variability (Perrow, 1967). Regardless of their specific referent, at the core of most definitions of uncertainty is the idea that information is incomplete concerning the attributes, causes, or effects of the
phenomenon of interest. In this article, we have adopted this emphasis on
the inadequacy of information, but we use the term uncertainty to cut
across the referent phenomena addressed in the literature because TQM
can take on a variety of focal concerns (ranging from an external focus on
the customer to an internal focus on efficiency in task performance).
The remainder of the article is separated into four major sections. In
the first section, we examine the idea that key aspects of the TQM approach may be contingent on the level of situational uncertainty and
propose that TQM be separated into two conceptually distinct approaches, which we label total quality control (TQC) and total quality
learning (TQL). In the second section, we review the sources of uncertainty that can affect the applicability of TQC and TQL approaches. In the
third section, we assess more specifically the contingent appropriateness
of TQC and TQL by proposing several hypotheses concerning their implementation under varying conditions of uncertainty. We conclude with
a discussion of the implications of our ideas for future research and the
implementation of TQM in organizations.

TOWARDA THEORYOF THEAPPLICABILITY
OF TOTALQUALITY
MANAGEMENT
UNDERDIFFERENT
ORGANIZATIONAL
CONDITIONS
Universalism in the Conceptualization and Diffusion of TQM
Although some TQM scholars have acknowledged that the application of TQM differs from one situation to the next, most either have advocated that TQM can be applied uniformly to all organizations (e.g.,
Juran, 1986) or have failed to articulate specific contingencies that may
affect the implementation of TQM (e.g., Langevin, 1977).
The quality movement resurrects and expands many engineering and group process tools invented or refined in the
1950s ... but the quality movement goes beyond.... It encourages every organization, unit, team and individual to

<-----Page 4----->540

Academy of Management Review

July

examine the processes involved in doing the work. Unfortunately people interpret this to mean that all work processes
should be routinized. (McLagan, 1991:31-32)
In their zeal, proponents of TQM have failed to recognize the importance of identifying ill-fitting concepts or applications in developing a
richer understanding of how TQM works and when it can be helpful. In
fact, the marketing of TQM as a commodity has taken on a life of its own
that has led increasingly toward highly rational techniques and prepackaged approaches (Hospitals, 1992: 30; Training & Development, 1992: 11)
and away from selectively incorporating TQM as it fits the specific situational requirements of the organization. The recent enthusiasm for transferring the lessons learned from manufacturing-based TQM to service
organizations illustrates this point, as a number of authors have asserted
that traditional TQM approaches can be directly transferred without modification (e.g., Deming, 1986: 183; Schonberger, 1992).
Although there are a number of identifiable perspectives represented
in the literature on the management of quality in organizations (e.g.,
Crosby, 1979; Deming, 1986; Feigenbaum, 1983; Juran, 1986), nearly all of
the past work has been descriptive or prescriptive in nature, with very
little emphasis on theory development or testing. Even though this is a
common characteristic of new research areas, a more fully developed
basis for understanding the causes underlying TQM-related outcomes is
essential both for linking this important new organizational development
to mainstream organizational theory and also for the further development
of TQM concepts and practices.
The suggestion that TQM lacks a well-developed theoretical foundation need not imply that there is no basis for outlining such a framework.
To the contrary, an assessment of the literature on quality reveals several
promising conceptual similarities across the otherwise differing perspectives on quality. To begin to articulate such a set of conceptual underpinnings, we first identify a set of precepts common to the various TQM
approaches. Because these shared precepts provide a common conceptual basis for quite distinct approaches to TQM, a monolithic set of principles and practices has come to be identified with TQM. Yet such a
monolithic notion of what TQM is tends to convolute two fundamentally
different sets of goals and assumptions.
Our contention that TQM comprises two fundamentally different
goals (control and learning) (Tamuz, 1987, 1988) should not be taken to
imply that organizations or their managers have the luxury of pursuing
one or the other in blissful isolation. To the contrary, because organizational survival in today's highly competitive and rapidly changing world
depends on both reliable performance and adaptability (March, 1991; Sitkin, 1992), organizational effectiveness hinges on the capacity to balance
the conflicting goals of stability and reliability with those of exploration
and innovation. Managers can gain competitive advantage from this apparent paradox if they are able to recognize that the everyday situations

<-----Page 5----->1994

Sitkin, Sutcliffe, and Schroeder

541

they confront almost inevitably involve both the exercise of control and
the capacity to learn. This reality manifests our notion that these two
epistemologically
incompatible approaches can coexist synergistically
(e.g., Leonard-Barton, 1992). Further, the effectiveness of TQM requires
that managers overcome this apparent paradox by tailoring their organization's balance between learning and control so as to match the situational uncertainty they face. This is what Cameron (1986: 539) referred to
as "the paradoxical nature of effectiveness."
It is important to surface the theoretical problems associated with
universalistic approaches for two reasons. First, disentangling the assumptions underlying the components of TQM will enhance the development of TQM theory. Second, more clearly understanding the degree to
which each situation meets the assumptions underlying specific principles and practices associated with control versus learning will enhance
the organization's ability to balance appropriately the two approaches
during the implementation of TQM.
Common guiding TQM precepts. Despite their distinctions, TQM's
otherwise dissimilar approaches share fundamental guiding precepts
(e.g., Dean & Snell, 1991; Ernst & Young, 1992a; March & Garvin, 1986;
Seymour & Collett, 1991). Different authors have clustered these precepts
in a variety of ways; however, these precepts can be conceptually distinguished into three clusters: (a) focusing on customer satisfaction, (b)
stressing continuous improvement, and (c) treating the organization as a
total system.
The core philosophy of TQM is reflected in these basic precepts. Specifically, the common ground that supports a wide array of TQM approaches is based on the notion that organizations can most fully enhance
their performance by recognizing that customers' expectations are likely
to rise as organizational performance improves and, thus, if an organization is to remain competitive, it needs to attempt to achieve concomitantly continuous improvements in its own processes and outcomes. Simple, piecemeal, or shortsighted solutions will not take the organization
very far. Thus, problems need to be addressed through solutions that go
"beyond the box" by crossing boundaries and seeing the various components of the organization, its suppliers, and its customers as a seamless
whole that contributes to the pursuit of better "total quality." Viewed in
this way, the three precepts-customer
satisfaction, continuous improvement, and an integrated system perspective-are
the distinguishable but
intertwined threads that jointly give TQM its strength.
Customer satisfaction. TQM often is defined as the continuous improvement of processes by all employees in the organization to better
meet the needs of internal and external customers. According to this definition, everyone in the organization has a customer, and a critical role of
effective TQM is to ensure that incentive systems clearly hold everyone accountable to either an internal or external customer (Schonberger, 1990). Nearly all management of quality approaches requires the

<-----Page 6----->542

Academy of Management Review

July

generation of objective data ("facts") that can be used systematically to
improve work processes and products. In TQM programs, "facts" are generated through the use of a variety of quantitative analysis techniques.
These tools are used to facilitate the recognition of causes of variance in
production and administrative processes, and they are prerequisites for
taking the actions necessary to reduce variance or errors in order to more
effectively meet customer needs. The tools cited in the literature and used
in industry are numerous and include such analytical techniques as statistical process control charts, quality function deployment, experimental
design, cause-and-effect diagrams, and Pareto charts.
Continuous improvement. The precept of continuous improvement
captures the desire of TQM proponents to enhance the reliability and
control of performance (e.g., "doing things right the first time") and simultaneously reflects the pursuit of enhanced learning and experimentation (e.g., "continuous learning") in order for organizations to continue
to develop new skills and capabilities. In practice, most quality programs
focus on enhancing organizational performance through "continuous
quality improvement," in which there is an effort to surface and systematically reduce or eliminate sources of customer dissatisfaction (including
errors). TQM involves extensive data collection, analysis, and feedback
systems that help to surface and isolate problems and direct the attention
of employees toward the problems that have been identified.
A typical approach is to focus on a few key problem areas that are
encountered repeatedly and can be analyzed systematically. Because
these problems are selected to be both routine (i.e., to avoid getting distracted by isolated or idiosyncratic problems) and low in uncertainty (i.e.,
the problem is analyzable), dramatic enhancements in efficiency are
sometimes reported (Juran, 1986; Juran & Gryna, 1980). Such efforts can be
quite effective for well-understood problems in which it is clear what
needs to be measured and what the focus of corrective action should be
(e.g., in automotive production processes, statistical process control is
used to focus on well-established key indicators).
The organization as a total system. The typical TQM focus on the
organization as a total system has a number of implications, including
the involvement of the individual employee as a critical part of a problemsolving team and a recognition that quality enhancement involves a fundamental cultural shift toward honestly assessing and responding to customer-driven concerns (Bowen & Lawler, 1992). At its core, a focus on the
organization as a total system suggests that complex production and service problems cannot be addressed with simple, patchwork solutions, but
instead require a hard-nosed assessment of how the entire "chain of production" might contribute to the problem-and
to its solution (Dean &
Snell, 1991; Snell & Dean, 1992).
As TQM has diffused, the passion for and focus on these fundamental
TQM precepts has masked attention to the duality inherent in the underlying goals of TQM: the desire for control and the desire for learning. In

<-----Page 7----->1994

Sitkin, Sutcliffe, and Schroeder

543

fact, early quality efforts, referred to as quality control (QC), were initiated specifically as a way to improve or control the efficiency of manufacturing processes to enhance "conformance quality." Later, quality efforts expanded the narrow, formal, and measurement-oriented
QC
approach to incorporate more qualitative, emergent, and systemic issues
that currently are reflected in TQM efforts. More specifically, the move to
TQM was motivated in part by the recognition that QC approaches
needed to embrace rather than ignore insights about the social system
drawn from research on human relations and sociotechnical systems and
by the recognition that knowledge and learning were crucial mechanisms
for sustaining a competitive advantage, especially during periods of
rapid change (Deming, 1982). As Steel and Jennings (1992: 6) observed,
TQM was "developed as a means of filtering responsibility for quality
improvement to all parts of an organization. Total corporate quality control was to be an end product of this process."
By emphasizing customer satisfaction, continuous learning, and the
organization as a total system, the quality movement was able to take a
giant step forward by going beyond its insights about control over stable
and familiar processes. By incorporating new insights about learning,
knowledge creation, and process innovation, the quality movement was
able to address the potential adaptability of the organization to highly
changing and uncertain circumstances. Paradoxically, this substantial
advance has carried with it the hidden seeds of the problem noted previously: As TQM has diffused, a myopic focus on the common TQM axioms that cut across control and learning has to some extent blurred the
distinctions between these elemental goals. Thus, we propose that a focus on the precepts fostered a premature sense of resolution in that TQM
advocates hastily concluded that the quality process was not only well
understood but also could be addressed through a singular set of principles. As we have pointed out, the problem with this assumption is that it
ignores the fundamental incompatibilities in the principles and practices
associated with the pursuit of control and the pursuit of learning (Tamuz,
1987) and, therefore, underestimates the importance of attaining a balance that matches situational requirements.
Surfacing the Duality Implicit in TQM: Total Quality Control Versus
Total Quality Learning
Total quality control (TQC). Before TQM, earlier QC efforts focused
much more narrowly on enhancing discreet clusters of tasks or, if they
focused on the organization more systemically, ignored the role of the
customer in defining standards to be achieved. Henry Ford's vaunted
assembly line efficiency was, after all, equally well known for disdaining
any customer requests concerning color (Ford is often quoted [e.g., Baida,
1990: 205] for saying, "Any customer can have a car painted any color that
he wants, so long as it is black.") By broadening their purview to include

<-----Page 8----->544

Academy of Management Review

July

both employees and customers as essential elements of the organizational system, modern quality approaches (i.e., TQM) have been more truly
focused on effective quality control by recognizing that earlier QC approaches omitted critical aspects of the system they were attempting to
bring under "control." Thus, it is entirely appropriate to have added the
term total-to reflect the shift away from the narrowness of earlier QC
efforts.
It is easy to lose sight of the essential control-oriented focus of TQM,
yet the core focus of TQM on meeting customer requirements, continuous
improvement, and the total organizational system meets quite precisely
the requirements for a cybernetic control system. Cybernetic control involves "a process in which a feedback loop is represented by using standards of performance, measuring system performance, comparing that
performance with standards, feeding back information about unwanted
variances in the system, and modifying the system" (Green & Welsh, 1988:
289).
Cybernetic theories of control highlight the theoretical boundary conditions that are likely to apply to the total quality control (TQC) approach
that is typical of today's TQM. Specifically, the "cybernetic validity"
(Green & Welsh, 1988) of a system must be demonstrated. Two critical
requirements are the need for a regulatory standard and the need for
activities that are sufficiently routine to be well understood. According to
Green and Welsh (1988: 289), control "derives its distinction from the organization's need for an activity to be done repeatedly in some standard
fashion." This emphasis on repetition and standardization implies a certain degree of task routineness and a moderate to high amount of certainty to understand cause-effect relationships. Further, it also implies
that cybernetic control systems are less appropriate in situations of high
uncertainty, which fail to meet the standards of cybernetic validity.
As exemplars of cybernetic control systems, current approaches to
TQM (i.e., TQC) also are subject to these boundary conditions. Thus,
researchers must look beyond current approaches to TQM for an approach
to quality that can work under conditions characterized by high uncertainty and nonroutineness. Although cybernetic control clearly involves
learning, it represents first-order rather than second-order learning (Argyris & Schon, 1978) in that it involves more effectively exploiting familiar
skills in addressing known problems. This distinction between first-order
and second-order learning implies that approaches that meet the precepts of quality and also foster second-order learning might be better
suited to uncertain and nonroutine conditions.
Total quality learning (TQL). The three guiding TQM precepts also
can accommodate an effort to enhance an organization's ability to uncover new problems or develop solutions independent of current problems. Focusing on this exploration-oriented aspect of TQM, a secondorder definition of learning in the TQM context would highlight
increasing an organization's ability to explore the unknown and to

<-----Page 9----->1994

Sitkin, Sutcliffe, and Schroeder

545

identify and pursue novel solutions (Garvin, 1993: 80). For example, instead of maintaining a continued focus on enhanced reliability with current production, the strategic focus of a firm may swing toward discovering new product domains for which novelty rather than reliability is the
key to competitiveness.
Rather than relying on customers to articulate
needs for products or services that they cannot yet imagine, a firm's strategy might emphasize improving the firm's ability to educate customers.
To illustrate, in the computer industry, the product life cycle is so short
that production techniques frequently become outmoded before they have
had the chance to settle into a well-understood routine that would be
amenable to the use of routine-oriented TQM practices. In settings in
which the task is poorly understood, it may not only be impossible to
specify appropriate measures, but it also may be impossible to conduct
the necessary exploratory, high-risk work without making an irreducibly
large number of errors-what
Purser and Pasmore (1992: 43) refer to as
"unique and nonrepetitive variance."
In these fundamentally uncertain contexts, continuous improvement
should focus on enhancing experimentation rather than on decreasing
error rates. For example, pharmaceutical research on "new chemical entities" that are the basis for proprietary drug patents are unavoidably
uncertain-and
highly successful pharmaceutical firms like Merck or
Johnson & Johnson have been described as places where "a mistake can
be a badge of honor" (Business Week, 1988) to reflect that a focus on the
elimination of errors is as essential in the manufacturing of drugs as it is
a seductive delusion in the development of fundamentally new drugs.
Recognizing Different Principles Emanating From a Common Set
of Precepts
If conditions of high uncertainty require an alternative to standard
TQM approaches, then matching different forms of TQM to situational
requirements should enhance effectiveness of TQM. As shown in Table 1,
we propose that the two complementary forms of TQM-labeled
total
quality control (TQC) and total quality learning (TQL)-share the same
underlying precepts fundamental to TQM but translate those basic precepts into very different-even
antithetical-sets
of operating principles
that are more appropriately attuned to the specific requirements of the
distinct situations that they are suited to addressing.
The first precept-customer
satisfaction-manifests
divergent principles when associated with control versus learning. Control-oriented
customer satisfaction stresses developing a better understanding of the
needs of known customers (including providers and internal customers)
and responding to those needs. In contrast, a learning-oriented approach
to customer satisfaction stresses the need to see new pools of relevant
customers as emerging as new issues or products are developed by an
organization. In addition, a learning-oriented
approach implies that

<-----Page 10----->Academy of Management Review

546

July

TABLE 1
Linking the Distinctive Principles Associated With TQC and TQL to
Common Underlying TQM Precepts
Shared TQM
Precepts

Principles Derived From Common Precepts
Control-Oriented
Learning-Oriented
Principles (TQC)

Customer
Satisf action

Principles (TQL)

Monitor and assess known
customer needs
Benchmark to better
understand existing
customer needs
Respond to customer needs

Scan for new customers,
needs, or issues
Test customer need definitions

Continuous
Improvement

Exploit existing skills and
resources
Increase control and reliability

Explore new skills and
resources
Increase learning and
resilience

Treating the
Organization as a
Total System

First-order learning (cybernetic
feedback)
Participation enhancement
focus

Second-order learning

Stimulate new customer need
definitions and levels

Diversity enhancement

focus

customers may not appreciate learning-oriented organizational efforts
and, thus, a TQL approach might not only fail to be guided by customers'
expressions of needs, but it might also include active "educational efforts" aimed at trying to alter their perceptions of their needs. For example, Cringely (1992) reported that shopping carts-like
early microcomputers-were
initially rejected by consumers, until these "customers"
were tricked (i.e., educated) into believing that the shopping carts were
both useful and socially acceptable.
Continuous improvement -the second precept -also
illustrates how
a single precept can take the form of distinct quality principles depending
upon whether quality is being pursued to enhance control or learning.
The control-oriented focus underlying TQC stresses continually enhancing the degree to which an organization is able to efficiently and effectively exploit a firm's existing capabilities and resources-where
the key
is to enhance control. In contrast with TQC's emphasis on cybernetic
control, total quality learning (TQL) stresses improvement in learning
capability-which
includes effectively identifying new skills and resources to pursue, the ability to explore these new arenas, the capacity to
learn from that exploration, and the resilience to withstand the inevitable
failures associated with such exploration.
Distinct principles also emanate from the final precept-treating
the
organization as a total system-and
can be seen most directly in TQC's
emphasis on first-order learning and TQL's emphasis on second-order

<-----Page 11----->1994

Sitkin, Sutcliffe, and Schroeder

547

learning. Learning how to deliver better quality given a set of clear parameters is the focus of TQM. As Krishnan, Shani, Grant, and Baer (1993:
18) put it, "Targets must be attainable within specifiable time periods and
objectively measurable so that participants know when they have met
their goals." In contrast, clearly defined basic goals and criteria for measuring the achievement of standards are more appropriately viewed as
the intended outcome for a TQL effort, rather than a prerequisite, as in the
case of TQC.
In addition, TQC programs recognize that quality improvement requires changes throughout a more broadly defined system, and, thus,
they stress the increased involvement of suppliers, employees, and customers. Although it is easy to mistake this increased involvement for an
open systems view of the organization because it includes customers and
suppliers, the traditional TQC approach may be more accurately thought
of as an expanded closed system because it retains a focus on operations
within its more broadly defined boundaries, rather than stressing challenges to those boundaries from the outside. In contrast, TQL reflects an
open systems view and focuses on keeping boundaries as permeable as
possible to facilitate second-order learning. This view implies that the
existing population of participants, even if broadly defined, usually
needs to be made more diverse if existing assumptions are to be adequately challenged.
Contrasting the Practices of TQC with Those of TQL
The TQC and TQL perspectives share underlying precepts but differ
in the guiding principles that each derives from those
significantly
shared precepts. Operating practices associated with implementing each
of the approaches also diverge and can be categorized in three broad
groups (see Table 2): practices aimed at enhancing capabilities, practices
focused on information collection and dissemination,
and practices
aimed at motivating employees (i.e., providing incentives for implementation).
We have highlighted that core TQM goals are fundamentally different, depending on the uncertainty of the situation, and have proposed
that in routine situations the goal is control and in nonroutine situations
the goal is learning. It follows that the management practices must be
adapted to the requirements of the situation in order to effectively achieve
desired outcomes.
In Table 2, we have distinguished practices based on whether they fit
the principles governing a TQC or a TQL approach. The stark contrast
between the practices identified here supports the notion that the pursuit
of control and learning represent distinct organizational goals that require special managerial attention if they are to coexist fruitfully.

<-----Page 12----->548

Academy of Management Review

July

TABLE 2
Practices Associated with Total Quality Control
and Total Quality Learning
Management
Practices
Capability
Enhancement

Total Quality Control
Enhanced exploitation of
existing skills
Increased efficiency in use of
existing resources
Increased effectiveness in
control over processes,
products, and services
Increased performance
reliability
Doing things right the first time

Training for specific skill
improvement
Information
Collection,
Analysis, &
Dissemination

Ongoing assessment of
customer/supplier perceptions
of needs and concerns
Fulfill known needs
Benchmarking against
satisfaction standards and
practices by competitors and
in other industries
Use of standardized statistical
control information

Incentives for
Implementation

Incentives for error reduction
Role models, mentoring, and
emphasis on constructive
conformity
Performance feedback
Participation/teamwork
emphasis
Evaluation through precise
standards

Total Quality Learning
Enhanced exploration of new
skills
Increased availability of slack
resources
Increased effectiveness in
learning and capacity
enhancement
Increased resilience in the face
of new and/or unexpected
changes or requirements
Doing things that are likely to
provide insight, but only have
a moderate probability of
succeeding
General training and exposure
Address previously
unrecognized customer groups
Identify new needs for current
customers
Test (rather than accept)
customer definitions of needs
and constraints
Self-designed, changing,
nonstandardized diagnostic
information
Incentives for innovation
Leadership support for
independent thinking and
calculated risks
Learning-related feedback
Autonomy
Evaluation through general
values and judgment

Capability enhancement. TQC's traditional emphasis on eliminating
defects has been treated as a turnkey approach for which measurement
and evaluation systems can simply be imported without a great deal of
tailoring to the specifics of the organization's situation.'
1

Surgery is often cited as a model for industry to follow in overcoming the tendency to
accept high error rates, because surgery is supposedly a situation in which mistakes are not
tolerated. Yet this analogy is an oversimplified and misleading characterization (Bosk,

<-----Page 13----->1994

Sitkin, Sutcliffe, and Schroeder

549

Consider the automobile production process. Auto production is characterized by high volume runs, stable production processes, well-known
technology, and routine tasks. Processes are highly automated and, in
some cases, include statistical monitoring and control of the process itself. Tight statistical process controls include many measurements made
at various points in the process concerning the degree to which cars are
being assembled according to technical specifications. The underlying
system of production is stable and repetitive, with approximately 500 cars
being produced per eight-hour shift, and successful implementation of
TQC-like practices have led to low variance and high quality (Ernst &
Young, 1992b). In fact, failures have become so rare for some automobile
components (e.g., measured in defects per million parts) that when a
failure does occur it is in fact treated as a "treasure." Indeed, in this
industry, the processes used are so well understood that failures can be
readily identified and causes can be traced to specific internal or external
aspects of the production process, and, thus, the process can be relatively
easily maintained in a state of statistical control. If the processes were not
so well understood, the adoption of TQM ideas among U.S. auto manufacturers could not have led to recent dramatic product and service improvements.
In contrast to the broad applicability of TQC principles in the case of
automobile manufacturing, consider the situation in the computer industry, where even relatively stable products are subject to rapidly evolving
process engineering advances. Under these conditions, the capacity of
organizations to effectively utilize the routine aspects of TQC systems is
diminished because the firms may never achieve the stable process that
is prerequisite to cybernetic validity. For example, portable computers
are rapidly changing, as new models are introduced every 6 to 12 months.
In this environment, quality yields may be as low as 60 percent when the
product is first put into production, and quality is maintained by discarding the defective parts. Even when quality improvements lead to process
yields as high as 90-99 percent, these higher yield ranges barely become
available in time as new products come on line and yield rates drop
to the lower range once again. The learning associated with the process
of enhancing yield rates may be beneficial,
even if the yield-rate
1979). A closer examination suggests that it is easy to gloss over the distinction between
experimental procedures that may take many years to achieve even modest success levels.
Although these procedures may subsequently achieve remarkable levels of reliability, once
the procedure is more fully understood (e.g., eye surgery), the quality-enhancement
processes used at the experimental versus the routine operation stages are quite different. An
implication of this observation is that control versus learning-oriented approaches may be
used at different stages of the life cycle of an organization, a department, or a process. In
early stages, a TQL approach may be more appropriate. In middle stages, as the process
begins to become more fully understood, a transition period will require a more balanced
approach. Finally, as knowledge becomes more complete, a heavier emphasis on TQC may
become more appropriate.

<-----Page 14----->550

Academy of Management Review

July

improvements cannot actually be put into use. However, under conditions
of such rapid change, the adoption of prepackaged, stringent systemssuch as those that stress the pursuit of zero defects (e.g., Crosby, 1979)can undermine the experimentation essential to the pursuit of innovation
at the heart of industry competitiveness.
Illustrating the TQL approach to capability enhancement, Chaparral
Steel has been characterized as an organization that operates its factory
operations as a learning laboratory. Although at this firm TQ principles
have infused organizational activities so pervasively that they are no
longer conspicuous (Francis, 1992), Chaparral does not view its advantage over its competitors in terms of either its products or its production
processes. Instead, it views its competitive advantage as resting on its
ability to "outlearn competitors" (Leonard-Barton, 1992: 32). Because of its
focus on TQL, Chaparral has stressed the importance of focusing attention on uncertain, cutting-edge innovations within its factory operations.
When dealing with highly uncertain, innovative activities it relaxes the
typical TQC focus on error reduction that pervades its routine manufacturing operations.
TQM training to enhance employees' knowledge of and commitment
to a quality initiative is often beneficial for employees (Ernst & Young,
1992a). However, educational efforts (e.g., specific technical training in
the use of teamwork or statistical tools such as control charts) have been
predicted to be most beneficial for employees working in highly or moderately routine situations and less beneficial for employees working in
nonroutine situations where task analyzability, variety, and predictability are low. Under conditions of high uncertainty, educational programs
targeting general "human capital" (i.e., employee) enhancement are
likely to be beneficial in the long run (Snell & Dean, 1992). The simpler the
task, the more abbreviated the training would need to be, just as the less
stressful the performance conditions, the less the training would have to
provide the opportunity for what Weick (1985) referred to as overlearned
behaviors. More generally, even standardized training programs (including methods, tools, and practices) may require attention to the customization, balancing, and sequencing of training experiences to match the
specific situational uncertainty levels involved.
Information collection, analysis, and dissemination. The contingent
applicability argument applies to information collection, analysis, and
dissemination involving employees, customers, and suppliers (Tamuz &
Sitkin, 1993). When tasks are routine, criteria for monitoring and feedback
can be more easily established, agreed upon, and measured. Thus, when
tasks and expectations are clear, employee performance and motivation
are aided by increased feedback (Hackman & Oldham, 1980).
The situation, however, is quite different for conditions of high uncertainty. According to the vice president for petroleum and synthetic
fuels research at Exxon Research and Engineering Company (Eidt, 1992:
26), "It is not at all clear that the basic processes through which major

<-----Page 15----->1994

Sitkin, Sutcliffe, and Schroeder

551

innovations occur are very well understood." Thus, it is not clear what
information should be collected or disseminated. In assessing the applicability of typical TQM practices for Exxon's efforts, he drew upon Exxon's
experience in using quality techniques for managing research activities
and concluded that the "application of quality tools and techniques to
work processes in this area [R&D] is considerably less straightforward,
especially in the early invention stage."
Even though the input of the customer or supplier is a crucial driver
of quality improvements when highly routine tasks are involved, uncertain or nonroutine activities may even be detrimentally affected by such
input. According to Ernst & Young (1992a: 36), to the extent that there is a
focus "on innovative new products in higher-performing organizations,
direct customer participation can limit the development effort if it does
not represent a broad enough view of the potential marketplace." Even
when input is broadly representative, it can nonetheless dampen innovation because it may not reflect the hard-to-imagine possibilities scientific innovation can sometimes offer. In a "technology push" environment,
effort is focused on "building a better mousetrap," regardless of customers' needs at the time. This idea is reflected by the computer scientist who
expressed frustration in applying "customer-based tests" to his futuristic
R&D efforts by stating: "I can't ask my customers what they want. They
haven't been born yet" (Sitkin, In press). Ultimately, such technology push
efforts can lead to new products and even new customers. In contrast,
when the technology is well known and adaptations are being considered, then a customer-driven approach may be more appropriate to define
what is needed.
When customers' definitions of need differ from current product or
service conceptions, TQC and TQL imply very different responses. TQC
focuses on benchmarking as a means of examining processes and standards used by other companies to establish expectations of achievable
excellence and provides a source of ideas for potential changes. Similar
firms can be drawn from inside an organization's industry or by identifying other firms using similar suppliers, customers, or processes. In addition, nontraditional firms can be used for benchmarking when the goal is
to leapfrog the competition or to gain a radically different perspective on
familiar problems. For example, the Square D Company corporate technology center has been experimenting with adapting the quality paradigm to its own R&D needs since 1990. According to the corporate vice
president and chief technical officer (Francis, 1992), the key to Square D's
approach is the adaptation of what he refers to as quality tenets to match
R&D task requirements. At Square D, the control-oriented focus on benchmarking and the establishment of baselines have been replaced by a
broader perspective on R&D investments and long-range payoffs, technology road maps, and technology transfer.
When the goal is to learn, as in TQL, practices should not be aimed
at meeting current standards because new products or services may not

<-----Page 16----->552

Academy of Management Review

July

yet be imaginable to customers. In addition, if the focus is on that which
is truly new, reliability standards that make sense for well-honed TQC
tasks are likely to be unrealistic for TQL activities, but they may well be
"required" by customers who are basing their judgments on less experimental goods. Thus, practices for TQL may need to focus on shifting the
customer's perceptions, rather than on finding new ways to meet these
perceptions.
Like the other quality practices, in-process feedback does not take the
same form for control-oriented and learning-oriented
quality efforts
three
must
be
met
for statistical
(Tamuz, 1988). For example,
requirements
in
and
control charts to be useful
controlling
improving organizational
processes. First, at least one measurable quality characteristic is needed
that is of importance to the customer. Second, the use of control charts
requires a stable underlying system of production. In other words, the
statistical distribution of the underlying quality characteristics) that is
(are) being sampled must not vary over time. Third, the use of control
charts rests on the assumption that a repetitive process or product is
being analyzed and, thus, is useful in mass production systems (e.g.,
automobile assembly factories) where these requirements are met. Automobile production has many measurable quality characteristics related
to the function and fit of the product, and it utilizes a stable process based
on high volume, repetitive assembly lines.
In contrast, control charts are not useful to the same extent in custom
production systems, R&D, and service systems where some or all of the
previous requirements are not met. In some custom production, the product or process is not repetitive. In R&D contexts and service contexts,
some or all three requirements often are violated. For example, research
organizations lack measurable quality characteristics in the initial stages
of research, when underlying scientific knowledge is being discovered.
Also, because spontaneous and creative discovery (rather than process
stability) is being encouraged in such research processes, the research
process lacks stability or consistency (McGrath, Martin, & Kukla, 1982)basic requirements for the use of control charts.
Implementation incentives. The applicability of TQM-related rewards and incentives also are hypothesized to be contingent on the extent
of situational uncertainty. More specifically, it is the target of the incentive that would vary in these situations-with
error-reduction incentives
matching more certain situations and experimentation and innovation
incentives matching less certain ones. Under more certain conditions, for
example, performance improvements and learning occur through incentives that stress the reduction of errors and variance and "small wins"
(Weick, 1984). In contrast, in more uncertain situations, learning occurs
through error-induced discoveries and incentive systems that reward
thoughtfully planned, well-executed, but inherently risky failures, which
are more likely to foster both learning and innovation (Sitkin, 1992;
Tamuz, 1994). For example, in basic research, high quality "products"

<-----Page 17----->1994

Sitkin, Sutcliffe, and Schroeder

often can only be produced through unpredictable
ing.

553

trial-and-error learn-

It is one thing to exhort an assembly line crew to "do it right
the first time" but quite another to give the same signal to an
exploratory researcher whose work inevitably involves learning from failed experiments. (Eidt, 1992:28)
In such situations, where the nature of the task is not well understood, a high tolerance for errors is necessary because the state of knowledge is not well understood (Wildavsky, 1988) and must be continuously
discovered (rather than continuously improved). Whereas in novel situations (e.g., research) defects and errors are not well defined in advance,
more certain activities (e.g., production) occur in a context that is better
understood and in which knowledge has become more codified. As we
noted previously, because few situations are likely to represent pure
types, even in situations that require a substantial emphasis on reliability, some learning-oriented mechanisms will need to be developed. The
recognition that pure types are rare suggests that it is the complementarity of and balance between control and learning that constitutes the
critical design factor for TQM designers and managers.
Unfortunately, the TQM literature does not reflect a sensitivity to this
issue. For example, Berry and Parasuraman (1992: 9) rebuffed the mere
suggestion of the appropriateness of errors: They noted that "we sometimes hear managers say that it is not practical to try to eliminate mistakes" and unequivocally reject such complaints as excuses to let managers "off the hook," which they see as an easy avoidance of "boldness
and creativity." Given the focus of TQM on continuous improvement, it is
ironic that objections to TQM seem to reinforce rather than mitigate the
faith of TQM adherents. Such a response typifies the "self-sealing" logic
described by Argyris (1985) and Janis (1972), in which individuals (or
groups) who believe strongly in a particular way of doing things can come
to see contrary information as erroneous and challenges as defensivethus creating a belief system that is virtually immune to refutation.
Turnkey TQM systems represent well-established ways of enhancing
processes through which employees can be reasonably expected to reduce errors, and, therefore, they also can be expected to reap rewards for
diligently pursuing zero error rates. However, turnkey TQM systems are
not only ineffective for handling novel and emergent situations, but they
can actually exacerbate problems in accountability if they fail to realistically reflect the uncertainty associated with the tasks being performed
(Beer, Eisenstadt, & Spector, 1990; Tamuz, 1988). A question raised by this
research is: When rewards are keyed to the elimination of errors, how can
individual employees or subunits be expected to actively pursue risky
innovations, which will (by definition) increase rather than decrease errors?
Team rewards may be more applicable in highly or moderately

<-----Page 18----->554

Academy of Management Review

July

certain situations (e.g., many manufacturing, custom production, or development settings). In contrast, teams are hypothesized to be less useful
in nonroutine situations, such as basic research projects, which are not
only more ill-defined, but also frequently involve disjunctive tasks more
suited to individual rather than group problem solving (Thibaut & Kelley,
1959). For example, there is still a role in research for the lone inventor or
single entrepreneur (Van de Ven, Angle, & Poole, 1989). Further, as Van de
Ven and Polley (1992) noted, a team approach may adversely affect innovation by obstructing learning.
In this section, we have suggested how two distinct approaches to
implementing TQM share three guiding precepts but differ fundamentally
in how those precepts are manifest under varying conditions of uncertainty and vary in the way they are translated into operating principles
and practices. In the next section, we discuss how situational uncertainty
is the crucial causal variable that determines the contingent appropriateness of the TQC versus TQL approaches to the implementation of TQM.
An Uncertainty-Based

Contingency Perspective on TQM Effectiveness

If we are to begin to develop a theoretical model of the control!
learning distinction, it is essential to make explicit the underlying situational difference that drives the contingent appropriateness of the assumptions and needs underlying TQC and TQL. We have suggested that
the theoretical basis for that divergence rests on the level of uncertainty
with the situation in which TQM is being applied. That is, when uncertainty is low, control is cybernetically valid (Green & Welsh, 1988), and
the assumptions and practices associated with a TQC approach make
sense. In contrast, when uncertainty is high (e.g., because the organization is engaged in novel or complex efforts), the only reasonable goal may
be to try to do a good job of exploration and learning (March, 1991; Sitkin,
1992; Tamuz, 1988) through the use of a TQL approach. Finally, we have
noted that most situations include mixtures of subtasks that vary in their
level of certainty and, thus, mandate that the two distinct approaches be
used simultaneously in some appropriately balanced way.
The contingency perspective we have outlined contrasts with the universalistic perspective on TQM effectiveness that has typified most past
work on quality. As we have suggested, proponents of the universalistic
approach have implicitly assumed that the diligent implementation of
standard TQM prescriptions (usually operationalized in terms of what we
have referred to here as TQC) is sufficient to ensure effectiveness. In
contrast, a contingency perspective stresses the importance not only of
the shared precepts that bind different TQM approaches together, but
also the fundamentally different principles and practices that distinguish
TQC and TQL and make them complementary.
According to the contingency-based model of TQM we propose (see
Figure 1), the principles and practices adopted by an organization will

<-----Page 19----->Sitkin, Sutcliffe, and Schroeder

1994

555

FIGURE 1
Contingency Model Of TQM Effectivenessa
Sources of
Uncertainty

Task Uncertainty
Product/Process
Uncertainty
Organizational
Uncertainty

Effectiveness

TQM Implementation

TQM Principles
(Control vs. Learning)

TQM Practices
a The dashed line in this figure depicts previously hypothesized direct effects, which we
have challenged. The solid lines represent the interaction effect that we have proposed.

enhance effectiveness only to the extent that they match the level of situational uncertainty. That is, we have argued that the effectiveness of
TQC or TQL is fully contingent on the degree of situational uncertainty for
which it is being used. Thus, we are arguing that the implementation of
TQM will not exhibit a main effect on indicators of outcome effectiveness.
We do not hypothesize the existence of a simple, noncontingent effect on
effectiveness because excessive reliance on either form of quality (TQC or
TQL) would, we suggest, turn from having a beneficial impact on outcomes to having a negative effect once reliance on that aspect of quality
exceeded situational requirements. These arguments can be specified in
the form of the following hypotheses and associated corollaries.
Hypothesis 1: When task, product/process, or organizational uncertainty is low, practices associated with
the implementation
of TQC will increase outcome

<-----Page 20----->Academy of Management Review

556

July

effectiveness. [Corollary: Outcome effectiveness will decrease when practices associated with TQL are implemented under highly certain conditions.]
Hypothesis 2: When task, product/process, or organizational uncertainty is high, practices associated with the
implementation of TQL will increase outcome effectiveness. [Corollary: Outcome effectiveness will decrease
when practices associated with TQC are implemented
under highly uncertain conditions.]
To illustrate these propositions, consider the current singular reliance on TQC. We have noted that TQC appears to be highly beneficial
when applied to conditions of low uncertainty. Thus, it has a positive
relationship with outcome effectiveness. However, we also have suggested that when TQC is emphasized under highly uncertain conditions,
the effectiveness of the outcome is affected negatively. This example fits
our more general hypothesis because the effect of TQC is purely contingent: It is positive up to a situationally determined level and then turns
negative. A parallel case can be made for an excessive reliance on TQL
under conditions that require control.

DISCUSSION
Much of the TQM research to date has been broadly focused on descriptions of practice rather than on the development of a coherent middle-range theory of use to managers and scholars. This may explain some
of the TQM failures reported in the popular press in recent years (The
Economist, 1992; Fuchsberg, 1992a, 1992b; Mathews & Katel, 1992). Perhaps if TQM had been implemented first in more nonroutine situations
(e.g., uncertain environments such as R&D) rather than in more routine
ones (e.g., manufacturing), the movement may have encountered difficulties early in its history rather than diffusing as it has. Although the idea
of a universally applicable TQM approach may have been instrumental
in fostering its acceptance, it also may be a root cause of many of today's
TQM problems. We offer a theoretical basis for examining these problems, and, thus, the contingency approach discussed in this article provides a framework for understanding the effectiveness of TQM in different
situations. In addition, the approach proposed here provides theoretical
and practical links to several existing streams of organizational research.
These links are discussed more fully in the following sections.
Links to Organizational

Theory

Organizational learning. We have focused explicitly on the conception of TQM as a strategy for enhancing both organizational learning and
control. One direction for future work that builds on our analysis is to
more explicitly examine the competency, investment, and performance

<-----Page 21----->1994

Sitkin, Sutcliffe, and Schroeder

557

trade-offs suggested by a control versus a learning approach. For example, under stable contextual conditions, rapid learning (associated with
learning-curve advantages) can lead to a strategic advantage for firms
further along the learning curve. Also, TQC's emphasis on refining existing competencies is well suited for such conditions because TQC practices should accelerate first-order learning. However, under conditions of
more rapid change, the tendency of TQC to exploit existing strengths
rather than develop new ones can put the fast-learning firm at a disadvantage by foreclosing "the experimentation necessary for discovering
good alternatives" (Levinthal & March, 1981; March, 1988: 10). That is,
while reliance on existing competencies certainly leads to more reliable
short-term performance, it does so by underinvesting in the development
of new competencies for the future.
Organization design and requisite variety. Research on TQM also
may be linked to research on organization design and requisite variety. In
fact, the major theme underlying this article, that TQM elements be
matched to the situational requirements, is supported by existing theory
on the concept of requisite variety. The concept of requisite variety (Conant & Ashby, 1970), put succinctly, is that "only variety can regulate
variety" (Buckley, 1968: 495). This idea is supported by Weick (1979: 189),
who suggests that "organizational processes that are applied to equivocal inputs must themselves be equivocal." The implication of requisite
variety for TQM is that organizations be flexible in their adoption of TQM
methods by tailoring TQM to match the distinct design requirements of
each organizational subunit.
Tailoring TQM to subunit requirements in more traditional vertically
integrated firms may be relatively easy, as control over TQM implementation is likely to be relatively centralized. However, the tailoring of TQM
methods to the requirements imposed by network organizations (e.g.,
Snow, Miles, & Coleman, 1992) or firms that use temporary or contract
workers (e.g., Pfeffer & Baron, 1991) may present a set of different challenges. For example, in network organizations control is more diffuse,
because networks generally spread asset ownership and risk across several independent firms. A potentially interesting question to be answered
by future research is whether firms operating in networks are embracing
TQM, and if they are, to what extent is TQM adopted differentially by
different members of the network? Furthermore, to the extent that firms
operating in networks have adopted TQM programs, how are the dual
goals of control and learning addressed (and with what degree of success)
in network systems? Though the use of temporary or contract workers may
provide benefits from diverse perspectives and new ideas, such fluid
organizational participation may pose roadblocks not only to enhancing
quality control, but especially for quality learning because fluid participation incurs severe process costs and contributes to losses of organizational memory (Van de Ven & Polley, 1992).
High reliability organizations in fast velocity environments. A rising

<-----Page 22----->558

Academy of Management Review

July

area of interest among organizational scholars concerns the capacity of
organizations to function with remarkable reliability in highly uncertain
situations (see Roberts, 1993). For example, researchers with this focus
have examined how organizations confronting complex or rapidly changing technologies (e.g., nuclear power plants, aircraft carriers, air transportation systems) are able to sustain almost failure-free operations when
they have little experience or information and compressed time within
which to make high-consequence
decisions (March, Sproull, & Tamuz,
1991; Roberts, 1990; Tamuz, 1987; Weick, 1987). One interesting avenue for
future research could be to systematically compare the similarities and
differences between TQM approaches and the effective approaches used
by these "high-reliability" organizations.
Eisenhardt (1993) has extended this line of work by focusing on situations in which situational uncertainty is derived from high rates of contextual change (e.g., due to rapid product life cycles or to the highly
interdependent and shifting strategies of competitors) rather than task
complexity. Even though Eisenhardt focused on "contextual factors" that
we were only able to touch upon, it is interesting to note that in her work
on the computer industry (which we refer to as an exemplar of our hypothesis), she identified a set of effectiveness-enhancing
conditionsincluding decentralization, allowing mistakes and actively "processing"
these errors, allowing for practice in anticipating, recognizing and resolving problems-that
are quite similar to those we proposed for uncertain
settings. Future work could examine the degree to which what she identified as effectiveness-enhancing
activity patterns (e.g., rapid recognition
of contextual change, speedy decisions, and learning over time) become
synonymous with practices that facilitate learning-oriented quality in organizations.
Implications for Future Research
This article points to the general importance of considering the conditions under which TQC or TQL approaches are more or less applicable
and highlights the need for empirical research on the ideas proposed
here. Specifically, it would be beneficial to conduct field research that
more systematically investigates the extent to which TQM practices and
success vary as a consequence of differing levels of task uncertainty.
Such a study could be done not only within the same firm (as it is likely
that task uncertainty varies across departments), but also across different
firms and different industries. For example, a natural follow-up study is
to more systematically investigate TQM practices being used in different
situations such as research, development, custom production, and repetitive production. The research could verify, or refute, the theory proposed
here and might suggest more precisely how TQM practices vary depending upon the nature of the task and other situational variables. Such
empirical work could provide fruitful insights about the contingent

<-----Page 23----->1994

Sitkin, Sutcliffe, and Schroeder

559

appropriateness of TQM and may help to clarify and refine the ideas
presented here.
Second, our approach also could be extended based on the recent
findings reported in Ernst & Young's study (1992a), which highlight how
firms at different stages of TQM adoption benefit differentially from the
use of various elements of TQM. Thus, our contingency analysis and Ernst
& Young's analysis could be combined to examine the joint effects of task
characteristics and the firm's place on the TQM learning curve.
A third research implication highlights the value of inductively reviewing the rich body of literature on TQM practices to extract the theories
that might be implicit. As part of this effort, longitudinal research examining the effects of TQM interventions on organizational outcomes is
sorely needed (Steele & Jennings, 1992).
In summary, we have described a three-pronged research approach.
One approach is to conduct empirical research guided by existing theory.
The second approach is to use theory from existing organization literature
and to translate TQM approaches into that literature. The third approach
is to develop theories more inductively from TQM practices or from existing prescriptions about TQM.
Implications for Practice
Our analysis of TQM elements provides a starting point for managers
who wish to "unbundle" and critically examine prepackaged TQM programs, so that the most applicable parts of these approaches are used
reflectively in each situation. Different TQM approaches in various combinations can be used within different industries, within different parts of
an organization, and for different functions within a small unit, although
there are likely to be some common elements that cut across the entire
organization.
In short, there is no substitute for managerial analysis and judgment.
Practitioners should not presume that uncertainty is always high in R&D
(Graham & Pruitt, 1990) and low in production (Leonard-Barton, 1992).
Instead, organizational members should examine each situation for its
particular tasks and contextual requirements before deciding which specific TQM approach is most appropriate. The most important implication
for practitioners is the idea that the effectiveness of TQM can be enhanced
by tailoring the particular type of TQM approach to the requirements of
the task and context.
One implication of our separate examination of each feature of the
typically integrated TQM program is that a "turnkey" approach to the
adoption of TQM is likely to be problematic. Those who implement TQM
packagese" that represent any single approach should expect pockets of
resistance from managers and staff who find that the specifics of the
approach simply do not fit their local requirements.
As we have noted previously, though proponents of TQM historically
have dismissed the validity of such resistance (because TQM was

<-----Page 24----->560

Academy of Management Review

July

presumed to be universally applicable), one implication of the ideas discussed here is that, in this regard, TQM proponents are wrong. To the
contrary, the absence of such resistance, rather than its presence, should
be viewed as problematic for three reasons. First, it may suggest that
employees are being less than honest. Second, it may suggest that employees are being uncritical in their acceptance of TQM. Third, it could
suggest that the TQM program is not being pushed far enough. That is, if
TQM is actually being taken seriously, experimental implementation will
be tried even in situations in which its applicability is unclear, and sometimes the result will be failure when it turns out to have crossed the
applicability limits of TQM; If there are no failures or resistance to bring
these misapplications to light, TQM has not been pushed as far as it could
be. Thus, we are making a seemingly counterintuitive argument: that
unless the limits of TQM are recognized, the use of TQM cannot begin to
reach those limits.
As TQM has spread, its adoption has begun to be driven increasingly
by concerns for managerial and firm legitimacy, rather than by instrumental task requirements. Even though this scenario is quite typical of
the later stages of the diffusion of any innovation (Rogers & Shoemaker,
1971), it also is likely to lead to the rapid erosion of support for the basically sound ideas represented by TQM. In this article, we have argued
that it is necessary to avoid the "faddish" elements of TQM and to think
through the primary purpose for which TQM is being adopted. This is true
before implementing TQM, and it is also true in adjusting the approach
used as the organization changes and matures. By carefully analyzing the
task and context and then adapting the particular TQM approaches used,
researchers should improve the effectiveness of TQM. Put differently, by
allowing organizational theory to guide and ground managerial practice,
researchers may enhance the effectiveness of TQM practices. Thus, the
more qualified and tentative endorsement of TQM implicit in a contingency approach is likely to foster the persistence of TQM rather than to
hasten its demise.

REFERENCES
Argyris, C. 1985. Strategy. change, and defensive routines. Marshfield, MA: Pitman.
Argyris, C., & Schon, D. A. 1978. Organizational learning: A theory of action perspective.
Reading, MA: Addison-Wesley.
Baida, P. 1990. Poor Richard's legacy: American business values from Ben Franklin to
Michael Milken. New York: Morrow.
Beer, M., Eisenstat, R. A., & Spector, B. 1990. The critical path to corporate renewal. Boston:
Harvard Business School Press.
Berry, L. L., & Parasuraman, A. 1992. Prescriptions for a service quality revolution in America. Organizational Dynamics, 20(Spring): 5-15.
Bosk, C. L. 1979. Forgive and remember: Managing medical failure. Chicago: University of
Chicago Press.
Bowen, D. E., & Lawler, E. E. III 1992. Total quality-oriented human resources management.
Organizational Dynamics. 20(Spring): 29-41.

<-----Page 25----->1994

Sitkin, Sutcliffe, and Schroeder

561

Buckley, W. F. 1968. Society as a complex adaptive system. In W. Buckley (Ed.), Modern
systems research for the behavioral scientist: 490-513. Chicago: Aldine.
Business Week. 1988. Johnson & Johnson: A mistake can be a badge of honor. September 26:
126.
Cameron, K. S. 1986. Effectiveness as paradox: Consensus and conflict in conceptions
organizational effectiveness. Management Science, 32: 539-553.

of

Conant, R. C.. & Ashby, R. W. 1970. Every good regulator of a system must be a model of that
system. International Journal of Systems Science, 1(2): 89-97.
Cringely. R. X. 1992. Accidental empires. Reading, MA: Addison-Wesley.
Crosby, P. B. 1979. Quality is free. New York: McGraw-Hill.
Dean. J. W., & Snell. S. A. 1991. Integrated manufacturing and job design: Moderating effects of organizational inertia. Academy of Management Journal, 34: 776-804.
Deming, W. E. 1982. Quality, productivity, and competitive position. Cambridge: Massachusetts Institute of Technology, Center for Advanced Engineering Study.
Deming, W. E. 1986. Out of the crisis. Cambridge: Massachusetts
Center for Advanced Engineering Study.

Institute of Technology,

Duncan, R. B. 1972. Characteristics of organizational environments and perceived environmental uncertainty. Administrative Science Quarterly, 17: 313-327.
The Economist. 1992. The cracks in quality. April 18: 67-68.
Eidt, C. M. 1992. Applying quality to R&D means "learn-as-you-go." Research * Technology
Management, 35(4): 24-31.
Eisenhardt, K. M. 1993. High reliability organizations meet high velocity environments:
Common dilemmas in nuclear power plants, aircraft carriers, and microcomputer firms.
In K. H. Roberts (Ed.). New challenges to understanding organizations: 117-135. New
York: Macmillan.
Ernst & Young. 1992a. International quality study: Best practices report. New York: American
Quality Foundation.
Ernst & Young. 1992b. International quality study: Automotive industry report. New York:
American Quality Foundation.
Feigenbaum, A. V. 1983. Total quality control: Engineering an'1 management
York: McGraw-Hill.

(3rd ed.). New

Fortune. 1992. Making quality more than a fad. May 18: 12-13.
Francis, P. H. 1992. Putting quality into the R&D process. Research * Technology Management, 35(4): 16-23.
Fuchsberg, G. 1992a. Quality programs show shoddy results. Wall Street Journal, May 14:
B1.
Fuchsberg, G. 1992b. "Total quality" is termed only partial success.
October 1: B 1.

Wall Street Journal,

Garvin. D. A. 1993. Building a learning organization. Harvard Business Review, 71(4): 78-91.
Graham, M. B. W.. & Pruitt, B. H. 1990. R&D for industry: A century of technological
at ALCOA. Cambridge. England: Cambridge University Press.
Green. S. G.. & Welsh, M. A. 1988. Cybernetics and dependence:
concept. Academy of Management Review, 13: 287-301.

change

Reframing the control

Hackman, J. R., & Oldham, G. R. 1980. Work redesign. Reading, MA: Addison-Wesley.
Hospitals. 1992. TQM backlash prompts questions. June 5: 30.
Janis, I. L. 1972. Victims of groupthink. Boston: Houghton Mifflin.

<-----Page 26----->562

Academy of Management Review

July

Juran, J. M. 1986. The quality trilogy: A universal approach to managing for quality. Quality
Progress, 19(8): 19-24.
Juran, J. M., & Gryna, F. M. 1980. Quality planning and analysis. New York: McGraw-Hill.
Krishnan, R., Shani, A. B., Grant, R. M., & Baer, R. 1993. In search of quality improvement:
Problems of design and implementation. Academy of Management Executive, 7(4): 7-20.
Langevin, R. L. 1977. Quality control in service industries. New York: American Management
Association.
Lawler, E. E. III, Morhman, S., & Ledford, G., Jr. 1992. Employee involvement and total
quality management: Practices and results in Fortune 1,000 companies. San Francisco:
Jossey-Bass.
Lawrence, P. R., & Lorsch, J. W. 1967. Organization and environment. Cambridge: Harvard
University Press.
Leonard-Barton, D. 1992. The factory as a learning laboratory. Sloan Management Review,
34(1): 23-38.
Levinthal, D., & March, J. G. 1981. A model of adaptive organizational
Economic Behavior and Organization, 2: 307-333.

search. Journal of

Lewin, K. 1951. Field theory in social science: Selected theoretical papers. New York: Harper
Brothers.
Main, J. 1991. Is the Baldridge overblown? Fortune, July 1: 62-65.
March, A., & Garvin, D. A. 1986. A note on quality: The views of Deming, Juran, and Crosby.
Boston: Harvard Business School.
March, J. G. 1988. Decisions and organizations.
March, J. G. 1991. Exploration and exploitation
Science, 2(1): 71-87.

New York: Blackwell.
in organizational

learning. Organization

March, J. G., Sproull, L. S., & Tamuz, M. 1991. Learning from samples
Organization Science, 2(1): 1-13.

of one or fewer.

Mathews, J., & Katel, P. 1992. The cost of quality. Newsweek, September 7: 48-49.
McGrath, J. E., Martin, J., & Kukla, R. A. 1982. Judgment calls in research. Beverly Hills, CA:
Sage.
McLagan, P. 1991. The dark side of quality. Training, 28(11): 31-33.
Perrow, C. 1967. A framework for the comparative
Sociological Review, 32: 194-208.
Peters, T. 1992. There's more to a successful
News, July 20: 2F.

analysis

of organizations.

American

company than zero defects. San Jose Mercury

Pfeffer, J., & Baron, J. N. 1991. Taking the workers back out: Recent trends in the structuring
of employment. In B. M. Staw & L. L. Cummings (Eds.), Research in organizational
behavior, vol. 10: 257-303. Greenwich, CT: JAI Press.
Port, O., Carey, J., Kelly, K., & Forest, S. A. 1992. Quality: Small and midsize companies
seize the challenge-not
a moment too soon. Business Week, November 30: 66-72.
Purser, R. E., & Pasmore, W. A. 1992. Organizing for learning. Research in organizational
change and development, vol. 6: 37-114. Greenwich, CT: JAI Press.
Roberts, K. H. 1990. Some characteristics of one type of high reliability organization. Organization Science, 1(2): 160-176.
Roberts, K. H. (Ed.). 1993. New challenges to understanding organizations. New York: Macmillan.
Rogers, E. M., & Shoemaker, F. F. 1971. Communication
approach. New York: Free Press.

of innovations: A cross-cultural

<-----Page 27----->1994

Sitkin, Sutcliffe, and Schroeder

563

Schonberger, R. J. 1990. Building a chain of customers: Linking business functions to create
the world class company. New York: Free Press.
Schonberger, R. J. 1992. Total quality management cuts a broad swath-through
turing and beyond. Organizational Dynamics. 20(Spring): 16-28.

manufac-

Seymour, D., & Collett, C. 1991. Total quality management in higher education: A critical
assessment (Application Report 91-01). Methuen, MA: GOALIQPC.
Shewhart, W. Q. 1931. Economic control of quality of manufactured product. Princeton, NJ:
Van Nostrand. [Reprinted by ASQC, Milwaukee, WI.]
Sitkin, S. B 1992. Learning through failure: The strategy of small losses. In B. M. Staw & L. L.
Cummings (Eds.), Research in organizational behavior, vol. 14: 231- 266. Greenwich, CT:
JAI Press.
Sitkin, S. B In press. Mismatches between control systems and task requirements as determinants of trust: The dynamics of distrust in an era of quality. In R. M. Kramer & T. R.
Tyler (Eds.), Trust in Organizations. Newbury Park, CA: Sage.
Snell, S. A., & Dean, J. W. 1992. Integrated manufacturing and human resource management: A human capital perspective. Academy of Management Journal, 35: 467-504.
Snow, C. C., Miles, R. E., & Coleman, H. J. 1992. Managing 21st century network organizations. Organizational Dynamics, 20(Winter): 5-20.
Steel, R. P., & Jennings, K. R. 1992. Quality improvement technologies for the 90s: New
directions for research and theory. In R. Woodman & W. Pasmore (Eds.), Research in
organizational change and development, vol. 6: 1-36. Greenwich, CT: JAI Press.
Tamuz, M. 1987. The impact of computer surveillance
World Journal of Business, 22(1): 69-77.

on air safety reporting. Columbia

Tamuz, M. 1988. Monitoring dangers in the air: Studies in information and ambiguity. Unpublished doctoral dissertation, Stanford University, Stanford, CA.
Tamuz, M. 1994. Developing organizational safety information systems for monitoring potential dangers. In G. E. Apostolakis & T. S. Win (Eds.), Proceedings of PSAM II, vol 2
(Section 71): 7-12. Los Angeles: University of California.
Tamuz, M., & Sitkin, S. B 1993. The invisible muzzle: Organizational and legal constraints on
the disclosure of information about health and safety hazards. Unpublished manuscript,
School of Public Health, University of Texas, Houston, TX.
Tetzeli, R. 1992. Making quality more than a fad. Fortune, May 18: 12-13.
Thibaut, J. W., & Kelley, H. H. 1959. The social psychology of groups. New York: Wiley.
Thompson, J. D. 1967. Organizations in action. New York: McGraw-Hill.
Training & Development.

1992. The downside of quality. March: 11.

Weick, K. E. 1979. The social psychology of organizing. Reading, MA: Addison-Wesley.
Weick, K. E. 1984. Small wins: Redefining the scale of social problems. American Psychologist, 39(1): 40-49.
Weick, K. E. 1985. A stress analysis of future battlefields. In J. G. Hunt & J. D. Blair (Eds.),
Leadership on the future battlefield: 32-46. McLean, VA: Pergamon Press.
Weick, K. E. 1987. Organizational culture as a source of high reliability.
agement Review, 29(2): 112-127.

California Man-

Wildavsky, A. 1988. Searching for safety. New Brunswick, NJ: Transaction Press.
Woodward, J. 1965. Industrial organization: Theory and practice. London: Oxford University

Press.

<-----Page 28----->564

Academy of Management Review

Van de Ven, A. H., Angle, H. L., & Poole, M. S. 1989. Research on the management
vation. New York: Harper & Row.

July
of inno-

Van de Ven, A. H., & Polley, D. 1992. Learning while innovating. Organization Science, 3(1):
92-116.
Sim B Sitkin is associate professor of management at the Fuqua School of Business,
Duke University. He received his Ph.D. in organizational behavior from the Graduate School of Business, Stanford University. His research focuses on the effect of
formal and informal organizational control systems on risk taking, accountability,
trust, learning, and innovation.
Kathleen M. Sutcliffe is assistant professor of organizational behavior and human
resource management, School of Business Administration, University of Michigan.
She received her Ph.D. from the University of Texas at Austin and was on the faculty
of the Carlson School of Management, University of Minnesota when this paper was
written. Her research interests include top-management team perception, interpretation, and sensemaking processes, organizational learning and adaptation, and
organizational responsiveness to environmental change.
Roger G. Schroeder is professor of operations management and Co-Director of the
Quality Leadership Center, Carlson School of Management, University of Minnesota. He received his Ph.D. from Northwestern University. His current research interests are in quality management, world class manufacturing, manufacturing strategy, and technology management.

