<-----Page 0----->Preprints of the
Max Planck Institute for
Research on Collective Goods
Bonn 2008/12

Multiple-Reason Decision
Making Based on
Automatic Processing

Andreas Glöckner / Tilmann Betsch

MAX PLANCK SOCIETY

<-----Page 1----->Preprints of the
Max Planck Institute
for Research on Collective Goods

Bonn 2008/12

Multiple-Reason Decision Making Based on
Automatic Processing

Andreas Glöckner / Tilmann Betsch

April 2008

Max Planck Institute for Research on Collective Goods, Kurt-Schumacher-Str. 10, D-53113 Bonn
http://www.coll.mpg.de

<-----Page 2----->Multiple-Reason Decision Making Based on Automatic Processing∗

Andreas Glöckner / Tilmann Betsch

Abstract
It has been repeatedly shown that in decisions under time constraints, individuals predominantly use noncompensatory strategies rather than complex compensatory ones. We argue that
these findings might be due not to limitations of cognitive capacity but instead to limitations
of information search imposed by the commonly used experimental tool Mouselab (Payne et
al., 1988). We tested this assumption in three experiments. In the first experiment, information was openly presented, whereas in the second experiment the standard Mouselab program
was used under different time limits. The results indicate that individuals are able to compute
weighted additive decision strategies extremely quickly if information search is not restricted
by the experimental procedure. In a third experiment, these results were replicated using more
complex decision tasks, and the major alternative explanations that individuals use more
complex heuristics or merely encode the constellation of cues were ruled out. In sum, the
findings challenge the fundaments of bounded rationality and highlight the importance of
automatic processes in decision making.
Keywords: Automatic Information Integration, One Reason Decision Making, Mouselab,
Probabilistic Inferences, Process Tracing, Time Limits, Intuition

∗

Andreas Glöckner, Max Planck Institute for Research on Collective Goods, Bonn and Tilmann Betsch,
University of Erfurt, Germany. The first two studies were conducted as a part of the diploma thesis of the
first author at the University of Heidelberg, Germany. We thank Stephan Dickert, Christoph Engel, Martin Beckenkamp, Peter Ayton, Edward Wisniewski and three anonymous reviewers for helpful comments
on earlier drafts of this article which helped to improve it considerably. Correspondence concerning this
article should be addressed to Andreas Glöckner, Max Planck Institute for Research on Collective Goods,
Kurt-Schumacher-Str. 10, D-53113 Bonn, Germany. E-Mail: gloeckner@coll.mpg.de.

1

<-----Page 3----->Multiple-Reason Decision Making Based on Automatic Processing
In process tracing studies in decision research, evidence has accumulated that individuals often employ simple strategies that minimize the amount of information considered and the
mental effort invested in a decision (e.g., Payne, Bettman, & Johnson, 1988). These strategies,
such as the lexicographic rule (LEX, Fishburn, 1974), elimination-by-aspects (EBA, Tversky,
1972), or the equal weight rule (EQW, Fishburn, 1974) involve considerably less computational steps than the weighted additive rule (WADD) of utility theory. Scholars now take it for
granted that time and capacity constraints provoke strategy shifts from complex, compensatory strategies towards simple noncompensatory ones (Ariely & Zakay, 2001; Bettman, Luce,
& Payne, 1998; Payne et al., 1988; Payne, Bettman, & Johnson, 1992; Rieskamp & Hoffrage,
1999). In this paper we question the external validity of the findings underlying this conclusion. Specifically, we argue that the predominantly used research methods in behavioral decision research encourage participants to deliberate and hinder the activation of automatic decision-making processes. We aim to demonstrate that automatic processes driven by the “intuitive system” (Kahneman & Frederick, 2002) enable individuals to quickly integrate multiple
reasons in their decisions in a compensatory way. In two of the three experiments reported in
this paper, we applied a research method in which the intuitive system could demonstrate its
powers. Results indicate that the majority of individuals use automatic processes to integrate
multiple reasons in a weighted additive manner if information acquisition is not constrained
by the experimental setting.

Bounded Rationality and the Focus on Deliberate Decision Strategies
In line with the dual-processing framework suggested by Kahneman and Frederick (2002), we
define deliberate decision strategies as strategies that are based on controlled cognitive operations. Here, information is integrated in a serial manner, processing is cognitively demanding
and rather slow, and individuals using these strategies are aware of most of the underlying
processes and can even verbalize them. Research in the tradition of the bounded rationality
approach (Simon, 1955) has focused on the functioning of such deliberate decision strategies
(cf. Frederick, 2002). The fundamental tenet of the bounded rationality approach is that, because of their limited cognitive capacities, individuals employ shortcut strategies (commonly
called heuristics1).
A prominent decision problem that has been repeatedly used in this research is the city-size
decision task (Gigerenzer, Hoffrage, & Kleinbölting, 1991; Gigerenzer, Todd, & the ABC
Group, 1999). In this task, an individual has to decide which of two cities (options) has more
inhabitants based on conflicting pieces of evidence (cues). Cues (e.g., whether a city is a state
capital) vary as predictors for city size, which means that they differ in the conditional likeli1

Note that in research on human judgments, the term heuristics refers to strategies that are based on automatic processes (cf. Kahneman & Frederick, 2002).

2

<-----Page 4----->hood (cue validity) that city A is larger than city B given a positive cue value. Assume that the
individual is informed by the experimenter that city A is a state capital and city B is not, and
that city B has a university and a major league sports team whereas city A has neither. A very
simple strategy would be to base the decision on only the most valid cue. If, for instance, the
person presumes that the state capital cue is the most valid one, he or she could consider only
this information, ignore the other cues, and decide that city A is larger. Such a strategy relies
on one reason only. This example describes the application of the Take-The-Best heuristic
(TTB, Gigerenzer & Goldstein, 1996), which belongs to the class of LEX rules. Only if the
most valid cue does not differentiate between options would the next cue be used, and so on.
Such a strategy seems to be simple enough for laypersons to apply deliberately in everyday
settings.
A strategy in which all the validities of all cue values are considered would be much more
complicated. This could be realized by a weighted additive rule (WADD) in which cue values
are multiplied by the validities of the respective cues and summed up. The option with the
highest weighted sum (total evidence) is chosen. WADD considers all relevant pieces of information, integrates cue values and their validities for each option, and thus provides an ideal
example of a compensatory strategy (i.e., a strategy in which negative values on one cue can
be compensated for by positive values on other cues). It has been repeatedly stated by proponents of the bounded rationality approach that humans might be often incapable of applying
such extensional strategies because these strategies overtax their computational capacities
(e.g., Gigerenzer et al., 1999).
As will be pointed out in more detail later, we question this assumption and argue that individuals may indeed carry out a WADD strategy, albeit not by deliberately calculating
weighted sums but instead by relying on automatic processes.

Mouselab – A Method for Process Tracing and Strategy Classification
One of the major challenges in behavioral decision research is to empirically identify application of different decision strategies on the individual level, as the underlying cognitive processes cannot be directly observed. Hence, a multitude of methods have been developed to infer decision strategies from proximal parameters such as choice patterns (e.g., Bröder &
Schiffer, 2003b), information search parameters (e.g., Johnson, Payne, Schkade, & Bettman,
1986; Sundstroem, 1987), decision times (e.g., Bergert & Nosofsky, 2007; Glöckner, 2006;
Glöckner, 2007), confidence judgments (Glöckner & Hodges, 2006), eye movements (e.g.,
Russo & Dosher, 1983), self-reports and think-aloud protocols based on introspection (e.g.,
Montgomery & Svenson, 1983; Svenson, 1989), or combinations of these.
One of the standard tools for strategy classification is the computer-based information board
called Mouselab (Johnson et al., 1986). In Mouselab, information about options is presented
in a covered information matrix. Participants have to move the mouse cursor onto boxes to
3

<-----Page 5----->uncover the outcomes of choice options. Steps of information search are recorded and are
subsequently used to identify decision strategies (see Figure 3 for an example).
The introduction of Mouselab was an important breakthrough. By providing an easy-tohandle tool for process tracing and strategy classification, this research method opened the
door to a process view in decision research; hence, it might actually be considered a revolution (Beach & Potter, 1992). Regardless of its undisputed merits, the method entails some difficulties. The fundamental problem is that it imposes restrictions on information search that
might, in turn, influence strategy selection. Note, for instance, that in the standard Mouselab
program, only one piece of information can be inspected at a time. This procedure promotes a
serial mode of information search and hampers the possibility of making quick comparisons
between multiple pieces of information as well as of detecting specific cue constellations.
Thus, Mouselab fosters application of deliberate, step-by-step decision strategies and hinders
the activation of automatic processes. Therefore, findings from Mouselab studies are likely to
underestimate humans’ total cognitive capacity, which is based on the usage of both types of
processes. Furthermore, Mouselab confounds the sources of constraints. Accordingly, the use
of simple strategies may reflect both the constraints on overt search behavior imposed by the
properties of the research tool and the constraints on the processing system imposed by capacity limitations of the cognitive system.
In Mouselab experiments, it has been consistently observed that participants change decision
strategies under severe time pressure from more complex, compensatory strategies to simple,
noncompensatory ones (e.g., from WADD to LEX; Payne et al., 1988; Rieskamp & Hoffrage,
1999; for further discussions, see Ariely & Zakay, 2001; Broadbent, 1971; Zakay, 1993). We
do not want to claim that these findings are always and entirely produced by Mouselab, particularly because there is converging evidence from studies which used other methods (Edland & Svenson, 1993). However, we would like to highlight the problem that these strategy
shifts may only apply to deliberate decision strategies. Mouselab is likely to support the application of these strategies and to hamper the application of automatic processes. The relatively
high decision times usually observed in Mouselab experiments clearly indicate that decision
strategies are based on elaborated deliberation (e.g., the average time for individuals’ decisions was for instance 44 seconds in Payne et al., 1988, Experiment 1, no time pressure condition). Thus, a critical scrutiny of the procedure reveals that the results cannot serve as conclusive evidence for the view that the strategy shift is always caused by a limited capacity for
information integration. Neither can they rule out the alternative explanation that time pressure simply constrains the information search operations (i.e., movements of the computer
mouse) necessary for gaining access to the information and thus also hampers automatic decision processes.
Findings by Lohse and Johnson (1996) lend support for this alternative interpretation. The
authors investigated the influence of different types of process tracing methods on decision
behavior and identified, apart from a significant amount of convergence, substantial differences between information search behavior and choices when the same decision tasks were
4

<-----Page 6----->presented in Mouselab, where information had to be looked up serially, or presented openly
so that information was instantly accessible; in the latter case, information search was recorded using an eye tracking method. Lohse and Johnson found that the Mouselab method
significantly increased the amount of time needed to acquire information compared with the
second method. In the Mouselab condition, individuals also showed a more systematic information acquisition behavior. Finally, in the condition containing richer contextual information
(i.e., decisions between apartments as compared to decisions between gambles), almost one
third of the individual choices changed as a function of the manipulation of the process tracing method (see also Billings & Marcus, 1983; Maule, 1994).
Taken together, findings indicate that Mouselab forces decision makers to engage in a serial
consideration of information. In turn, this method induces a deliberate rule-based integration
of information. These processes are slow and consume both task and mental resources. Automatic processes that could draw on a parallel consideration of information are systematically
constrained in this paradigm. Unsurprisingly, individuals reduce the depth of serial processing
in Mouselab, especially when time and cognitive resources become scarce. When time pressure conditions do not allow all information to be inspected, the Mouselab method invites the
application of noncompensatory strategies (e.g., LEX/TTB). We cannot rule out the possibility that the presumed increased prevalence of noncompensatory strategies under time pressure
mainly applies to situations that resemble Mouselab. Thus, the general claim that individuals
always use this kind of strategy more often under time pressure is not warranted.

The Neglected Role of Automatic Processes in Research on Decision Strategies
Although the importance of automatic processes has been repeatedly highlighted (Bargh &
Chartrand, 1999; Bargh & Williams, 2006; Doherty & Kurz, 1996; Hasher & Zacks, 1984;
Hintzman, 1988; Kahneman, Slovic, & Tversky, 1982; Kahneman & Frederick, 2002;
Schneider & Shiffrin, 1977; Shiffrin & Schneider, 1977; Wegner, 1994; Zajonc, 1980), they
were largely ignored in research on multiple-strategy decision making (Frederick, 2002).
Elaborating on the notion of a dual-processing approach (see Chaiken & Trope, 1999, for an
overview), Kahneman and Frederick (2002) put forward a two-system framework that distinguishes between intuitive/automatic processes (system 1) and reflective/deliberate processes
(system 2). It is usually assumed that shortcut strategies like EQW or LEX/TTB are executed
by the deliberate system since they draw upon controlled processes.
Beyond this general framework, several models have been proposed that specify the functioning of automatic processes (e.g., Beach & Mitchell, 1996; Betsch, 2007; Busemeyer & Townsend, 1993; Dougherty, Gettys, & Ogden, 1999; Epstein, 1990; Frederick, 2002; Glöckner,
2006; Glöckner & Betsch, 2008; Hogarth, 2001; Lieberman, 2000; Simon, Snow, & Read,
2004; Sloman, 2002). It is beyond the scope of this paper to discuss and compare these models. For simplicity, we base our research on one fundamental assumption raised by Hammond
et al., (1987):
5

<-----Page 7----->General Hypothesis: Automatic processes should enable individuals to quickly integrate information in a weighted additive manner.
This would mean that individuals apply a WADD rule without deliberately calculating
weighted sums.

Methodological Preliminaries
Notation. We use the abbreviation WADD to refer to a strategy that integrates cue values and
cue validities in weighted additive (linear) fashion. On a general level, we use WADD in a
paramorphic sense (Hoffman, 1960). Accordingly, WADD is said to be applied if the output
of a decision (the choice) accords to the choice predictions derived from a linear aggregation
of all the given pieces of information available. If we wish to address the level of processes
(i.e., what individuals really do when they make a decision), we add suffixes specifying the
type of processes. Specifically, we use the notation WADDdel for a strategy that is based on a
deliberate calculation of weighted sums and the notation WADDauto for a strategy that performs the integration operations automatically. LEX/TTB describes noncompensatory onereason decision strategies that search cues in the order given by cue validities. EQW describes
equal weight strategies in which cue validities are ignored and the option with more positive
cue values is selected.
Analysis of Choices in Diagnostic Decision Tasks. Strategy classification in our experiments
is primarily based on the analysis of choices. Decision tasks were systematically selected as
diagnostic for different decision strategies (cf. Glöckner & Betsch, in press). Specifically, decision tasks were based on cue patterns (constellations of cue information) so that the considered strategies LEX/TTB, EQW, and WADD make different predictions for substantial subsets of tasks. To allow for a classification of decision strategies on an individual level as compared to an analysis across all participants, decision tasks were presented repeatedly by holding constant the structural cue patterns underlying the decision tasks (cf. Bröder & Schiffer,
2003b). Note that it is obviously impossible to differentiate between WADDdel and WADDauto
based on choices because choice predictions are equal; therefore, we have to consider other
process-related variables, such as decision time.
Analysis of Decision Time Patterns. The process of information integration will be further
investigated by analyzing individual decision time patterns (cf. Bergert & Nosofsky, 2007).
Strategies differ considerably with respect to the time their performance expends. For individuals who use a LEX/TTB strategy, decision times should depend on the number of cues
required for differentiating between the options. Thus, people should decide faster in decision
tasks in which the first cue differentiates between options as compared to decision tasks in
which two or more cues have to be considered (Bröder & Gaissmaier, in press). Individuals
who use an EQW strategy should not show any differences in decision times as long as the
number of cue values is held constant and the sum of cue values differentiates between op6

<-----Page 8----->tions. The same prediction holds for a WADDdel strategy that is based on a deliberate calculation of weighted sums (Payne et al., 1988). In contrast, some of the decision strategies based
on automatic processes (e.g., WADDauto) facilitate deriving the prediction that decision times
increase with rising evidence that points against the preferred option, and decrease with rising
evidence in favor of the preferred option (Busemeyer & Townsend, 1993; Cartwright &
Festinger, 1943; Glöckner, 2006; cf. Holyoak & Simon, 1999; for empirical evidence in favor
of this claim, see Festinger, 1943; Glöckner, 2007). The general version of the rational model
(Bergert & Nosofsky, 2007) specifically predicts that decision time decreases with increasing
difference between the total evidence for two options. Furthermore, it can be predicted that
the overall level of decision time is much higher for a WADDdel strategy than a WADDauto
strategy. Thus, besides providing converging evidence for the choice-based strategy classification method, decision time analysis can be used to test whether individuals applied a
WADDdel or a WADDauto strategy. In our experiments, decision times were analyzed to further differentiate between decision strategies and to learn more about the underlying processes.
Analysis of Confidence Judgments. Other data that depend on the applied decision strategies
and thus could be used to learn more about the processes of decision making are subjective
judgments of the confidence in choices (Christensen-Szalanski, 1978). According to simple
LEX/TTB rules, confidence should depend on the validity of the most valid cue only (Gigerenzer et al., 1991), whereas some of the WADD models predict that confidence is dependent
on the differences in the weighted cue values for the options (Cartwright & Festinger, 1943;
Glöckner, 2006). Bergert and Nosofsky (2007) refer to decisions with a low (vs. high) difference in the total evidence for the options as hard (vs. easy) decisions. Assuming that hard decisions lead to lower confidence judgments than easy decisions do, the same prediction could
be derived from Bergert and Nosofsky’s generalized version of the rational model. In the third
experiment, we therefore investigated confidence judgments. Table 1 summarizes the differential predictions of the decision strategies that were used to identify strategies in the three
experiments reported in this paper.
In the first experiment reported below, we tested whether individuals are able to quickly integrate information in a weighted additive manner (application of a WADDauto strategy) if information search is not restricted by the research tool. In the second experiment, the decision
tasks of Experiment 1 were presented in a classical Mouselab format under different time
limit conditions in order to further investigate whether strategy shifts are due to limitations of
cognitive capacity or to limitations of information search induced by the Mouselab method
itself. In the third experiment, more complex decision tasks and a manipulation of cue validities were used that enabled further investigation of information integration processes.

7

<-----Page 9----->Table 1
Predictions of Decision Strategies
Decision Strategies
LEX/TTB

EQW

WADDdel

WADDauto

Yes

No

No

No

No

Yes

No

No

No

No

Yes

Yes

Choices
1,2,3

1. Less valid cues are ignored

1,2,3

2. Cue validities are ignored

1,2,3

3. Weighted additive information integration

Decision Times
1. Time dependent on the cues necessary for differentiating with a LEX strategy1

Yes

No

No

No

2. Time equal for all cue patterns1,3

No

Yes

Yes

No

3. Time decreases with increasing differences
between the options1,3

No

No

No

Yes

Confidence Judgments
1. Confidence dependent on the validity of the
differentiating cue with LEX3

Yes

No

No

No

2. Confidence increases with increasing differences between the options3

No

No

Yes

Yes

Note. Hypotheses are stated in the left-hand column. Exponents indicate the experiment(s) in which each hypothesis was tested. The predictions of the decision strategies are presented in the columns to the right with the
values yes–no indicating that the respective hypothesis should or should not hold if the strategy is applied.

Experiment 1
In Experiment 1 information was presented in an “open” matrix (no covered information) to
assure that the information search was not artificially constrained. All participants were put
under time pressure by the instructions. According to the bounded rationality approach, individuals should use simple deliberate strategies (i.e., LEX/TTB) under such conditions because
they are assumed to lack the cognitive capacity to perform complex calculations when decision time is limited. The alternative hypothesis states that even under time pressure, participants use a WADDauto strategy because the automatic system is able to simultaneously process a multitude of information (e.g., in a parallel and holistic fashion, Glöckner & Betsch,
2008).
The experimental tasks required the participants to assume the role of a manager of a company. In repeated decision trials, participants were instructed to select the best of three different products (options). They were provided with information from three testers (cues) with
different predictive validity (cue validity), which provided dichotomous quality ratings (i.e.,
good–bad) for each product.
8

<-----Page 10----->Method
Participants and design. Participants in the first experiment were 15 University of Heidelberg
students (11 female, 4 male). The experiment lasted approximately 30 minutes. Participation
was either compensated for by course credit or a flat fee amounting to 4 euros. Decision tasks
were varied as a within-participants factor, resulting in a 6 (VERSION) x 23 (CUE PATTERN) design with the following factors nested under the latter: CUE (number of cues necessary to differentiate according to a LEX/TTB rule), PRO_OPTION1 (number of positive cue
values in favor of option 1), and PRO_OPTION2/3 (number of positive cue values in favor of
option 2 or 3). The factor VERSION represented six different versions of each cue pattern, in
which the order of options was permutated. Table 2 shows the 23 cue patterns used in the experiment. C1 to C3 refer to cues in order of validity with cue 1 being the most valid cue. The
cue validities (in this case given as probabilities of correct predictions) were .80, .70, and .50.
O1 to O3 represent the eligible options. Cue values are represented by the symbols “+” (positive) and “-” (negative).
The 23 cue patterns can be separated into three sets that correspond to the manipulation of the
factors CUE. In the first set (CUE PATTERNS 1 to 15; CUE=1), the most valid cue has only
one positive cue value in favor of option 1. Within set 1, the number of cues with a positive
cue value for option 1 (PRO_OPTION1) varies from 1 to 3 (cf. main rows in Table 2). This
variation is completely crossed with a variation of the number of positive cue values for options 2 and 3 (PRO_OPTION2/3) from 0 to 4 (cf. main columns in Table 2), resulting in a
total of 15 stimuli for set 1. In the second set (CUE PATTERNS 16 to 21; CUE=2), cue 1 has
more than one positive cue value but cue 2 has only one. In the third set (CUE PATTERNS
22 and 23; CUE=3), cue 1 has entirely positive cue values, cue 2 has two positive cue values,
and cue 3 has one or two.
Cue Patterns and Strategy Classification. Individuals who use a LEX/TTB strategy should
show increasing decision times from set 1 to set 3 but constant decision times within each
given set because a constant number of cues need to be considered to arrive at a decision. Individuals who use a WADDauto strategy should show increasing decision times with increasing evidence for options 2 and 3 (PRO_OPTION2/3) and decreasing decision times with increasing evidence for option 1 (PRO_OPTION1). Individuals that use a WADDdel rule should
show equal decision times for all cue patterns. The 23 cue patterns also allowed for classification of the decision strategies LEX/TTB, EQW and WADD based solely on the choice analysis. The LEX/TTB strategy predicts choices of option 1 in all 23 cue patterns, because the
most valid differentiating cue (i.e., cue 1 for cue patterns 1 to 15; cue 2 for cue patterns 16 to
21; cue 3 for cue patterns 22 and 23) always points towards this option. The EQW and
WADD strategies predict choices of option 2 in cue patterns 7 and 10, and choices of options
2 or 3 in cue pattern 13, because in these patterns both the unweighted and the weighted sum
of the cue values are higher for these options. Note that for a WADD strategy, this prediction
is only valid if the sum of the subjective cue validities for cues 2 and 3 is higher than the cue
validity of cue 1 (see also Footnote 3 below).
9

<-----Page 11----->Table 2
Cue Patterns Experiment 1 and 2
Cue Patterns Set 1 (CUE=1)
Positive O2 and O3
Positive O1

1

2

3

0

1

2

3

4

Pattern 1

Pattern 4

Pattern 7

Pattern 10

Pattern 13

O1 O2 O3

O1 O2 O3

O1 O2 O3

O1 O2 O3

O1 O2 O3

C1

+

-

-

+

-

-

+

-

-

+

-

-

+

-

-

C2

-

-

-

-

+

-

-

+

-

-

+

+

-

+

+

C3

-

-

-

-

-

-

-

+

-

-

+

-

-

+

+

Pattern 2

Pattern 5

Pattern 8

Pattern 11

Pattern 14

O1 O2 O3

O1 O2 O3

O1 O2 O3

O1 O2 O3

O1 O2 O3

C1

+

-

-

+

-

-

+

-

-

+

-

-

+

-

-

C2

+

-

-

+

+

-

+

+

-

+

+

+

+

+

+

C3

-

-

-

-

-

-

-

+

-

-

+

-

-

+

+

Pattern 3

Pattern 6

Pattern 9

Pattern 12

Pattern 15

O1 O2 O3

O1 O2 O3

O1 O2 O3

O1 O2 O3

O1 O2 O3

C1

+

-

-

+

-

-

+

-

-

+

-

-

+

-

-

C2

+

-

-

+

+

-

+

+

-

+

+

+

+

+

+

C3

+

-

-

+

-

-

+

+

-

+

+

-

+

+

+

Cue Patterns Set 2 (CUE=2)
Pattern 16

Pattern 17

Pattern 18

Pattern 19

Pattern 20

Pattern 21

O1 O2 O3

O1 O2 O3

O1 O2 O3

O1 O2 O3

O1 O2 O3

O1 O2 O3

C1

+

+

-

+

+

+

+

+

-

+

+

+

+

+

-

+

+

+

C2

+

-

-

+

-

-

+

-

-

+

-

-

+

-

-

+

-

-

C3

-

-

-

-

-

-

-

+

-

-

+

+

+

+

-

+

-

-

Cue Patterns Set 3 (CUE=3)
Pattern 22

Pattern 23

O1 O2 O3

O1 O2 O3

C1

+

+

+

+

+

+

C2

+

+

-

+

+

-

C3

+

-

-

+

-

+

Note. The 23 cue patterns used in Experiment 1 and 2 are depicted in a matrix format. C1 to C3 represent cues 1
to 3, with cue 1 being the most valid and cue 3 the least valid cue. O1 to O3 represent options. Cue patterns are
categorized in three sets for which the number of cues increases. Set 1 consists of cue patterns 1 to 15, set 2
consists of cue patterns 16 to 21, and set 3 consists of cue patterns 22 and 23. Within set 1, the number of positive cue values for option 1 is varied from 1 to 3 (cf. main rows). This variation is fully crossed with a variation of
the number of positive cue values for options 2 and 3 (0 to 4; cf. main columns).

10

<-----Page 12----->Individuals who choose option 1 in all cue patterns can be classified as LEX/TTB users,
whereas individuals who mainly choose option 2 or 3 in cue patterns 7, 10, and 13 could have
used EQW or WADD. The latter participants were further differentiated based on an examination of cue patterns 4, 8, 11, and 18. The EQW strategy predicts an equal distribution of
choices of options 1 and 2 for these patterns because the number of cues is equal for both options, whereas WADD predicts choices of option 1 because the more valid cues speak for this
option. In summary, people who choose option 1 in all cue patterns ignore less valid cues and
should be classified as LEX/TTB users; individuals who mainly choose option 2 or 3 in cue
patterns 7, 10, and 13 and about equally often choose option 1 and 2 in cue patterns 4, 8, 11,
and 18 look at all cue values but ignore cue validities, and should be classified as EQW users;
and finally, individuals who choose option 2 or 3 in cue patterns 7, 10, and 13 and mainly
choose option 1 in cue patterns 4, 8, 11, and 18 take into account all the cue values as well as
their validities, and should be classified as WADD users (as mentioned above, the notion is
used in a paramorphic sense, not implying that weighted sums are calculated in a serial manner).
Materials and Procedure. A computer program written in MEL2 (Multiple Experimental
Language 2) was used to run the experiment. The complete experimental instructions can be
found in Appendix A. Participants were instructed to repeatedly select the vendor who provides the best quality product. They were informed about the testers’ cue validities in a frequency format to facilitate their understanding and processing of the information (Gigerenzer
& Hoffrage, 1995). Note that from a normative perspective, participants should ignore the
information of tester 3 (i.e., 50 percent correct predictions) since the validity of this information reaches only the level of chance, which should in turn encourage the application of
LEX/TTB strategies. Moreover, participants were asked to make high quality decisions and to
be as fast as possible in deciding (Fazio, 1990). All nine pieces of information for each decision task were presented simultaneously in an information matrix with cues displayed in rows
and options in columns. Information was presented in the middle of a black screen using ASCII characters as depicted in Appendix A. The information remained on the screen until the
participants chose one option by hitting one of three adjacent keys that were marked on the
keyboard (i.e., “f”, “g”, “h”). Choices and decision times were recorded.
Eight warm-up decision trials were used to familiarize participants with the material and the
procedure. These were followed by 138 target trials, which were presented in six randomized
presentation blocks, each consisting of one of the six versions of the 23 choice patterns. Two
1-minute breaks were embedded to minimize the effects of decreasing concentration. After
having completed all tasks, participants were asked to recall the cue validities in order to ensure that they had remained aware of them over the entire course of the experiment.

11

<-----Page 13----->Results
Strategy Classification Based on Choices. Choice proportions for option 1 in cue patterns 1 to
23 aggregated across VERSIONS are depicted in Figure 1. On an aggregated level of analysis, choices of option 1 were most frequently observed, except in the critical patterns 7, 10,
and 13. Thus, the majority of aggregated choices are in line with the predictions of WADD,
indicating that a considerable portion of participants used this strategy. In order to determine
the size of this portion precisely, further analyses were conducted on the individual level. To
identify participants who used a LEX/TTB strategy, choices in cue patterns 7, 10, and 13 were
compared with choices in the remaining cue patterns. As mentioned above, in an error-free
application of a LEX/TTB strategy, option 1 should always be selected. Taking into account
that individuals may not be able to apply a decision strategy without error, one might decide
to determine a proper error rate. Given that this is methodologically problematic, however,
one can alternatively test whether the observed individual rate of error is the same for different cue patterns (cf. Bröder & Schiffer, 2003b). Thus, if a LEX/TTB strategy is applied, the
portion of choices of option 1 should be equal in the critical cue patterns compared to in the
remaining ones. This hypothesis was tested using individual χ2-tests of independence. For
each participant, it was tested whether the proportion of choices of option 1 were independent
of cue patterns. Here, cue patterns 7, 10, and 13 (critical cue patterns) were compared with
the remaining cue patterns. Eleven participants chose option 1 significantly less often in the
critical patterns than in the remaining patterns (p < .05). This indicates that the information
provided by the less valid cues systematically influenced their choices, even though the most
valid cue already discriminates between the options (cf. Table 2). Thus, it is unlikely that
these participants used a LEX/TTB strategy. Two of the 15 participants made their choices in
line with the predictions of a LEX/TTB strategy and were classified respectively. Two further
participants distributed their choices equally among options 1, 2, and 3 across all cue patterns,
which no systematic decision strategy would predict. These participants were therefore classified as using a random choice strategy (RAND).

12

<-----Page 14----->Figure 1

Set 2

Set 1

1

Set 3

0.9

Choices for Option 1

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1

2

3

4

5

6 7

8

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

Cue Pattern

Figure 1. Percentage of choices of option 1 in Experiment 1. The “Positive O1” manipulation
within set 1 is indicated by different grayscales. Error bars indicate 95 percent confidence
intervals.

Based on this analysis, it can be concluded that at least 11 participants did not concentrate on
the most valid cue only, but instead used information from all three cues, which might be explained by EQW or WADD strategies. However, an EQW strategy further predicts that in cue
patterns 4, 8, 11, and 18, an equal distribution of choices of options 1 and the other options
should be observed, whereas WADD predicts choices of option 1 only. For the 11 participants
yet to be classified, the distribution of choices in these cue patterns was examined using χ2tests. Specifically, observed choices were tested against an equal distribution of choices of
option 1, compared with the sum of choices of the other options (i.e., 50:50 choices of option
1 vs. choices of options 2 + 3). There was a precisely equal distribution for one person, who
was accordingly classified as an EQW user. For the remaining 10 participants, choices significantly deviated from an equal distribution; these participants clearly preferred option 1 (p
< .05). Having apparently used information from all three cues and also taking into account
the cue validities, they were classified as WADD users. The results of the strategy classification are summarized in the top row of Table 3. It can be seen that about two thirds of the participants used a WADD strategy, whereas only a few individuals used EQW or LEX/TTB
strategies and ignored information. Thus, in contrast to earlier findings, simple LEX/TTB
strategies were not predominantly used under time pressure.

13

<-----Page 15----->Table 3
Results of Choice-Based Strategy Classification
Decision Strategies
LEX/TTB

EQW

WADD

RAND

Experiment 1
Time Pressure

2 (13%)

1 (7%)

10 (67%)

2 (13%)

Experiment 2
Lenient Time Limit

4 (27%)

1 (7%)

10 (67%)

0

Medium Time Limit

5 (33%)

3 (20%)

7 (46%)

0

Severe Time Limit

14 (93%)

0

1 (7%)

0

Experiment 3
Time Pressure in Complex
Decision Tasks

13 (21%)

0

50 (79%)

0

Strategy Classification Based on Decision Times. The median decision time was found to be
very low: Half of the decisions were made in less than 1.1 seconds (MD = 1.07s, M = 1.53s,
SD = 1.51s, skew = 6.19, kurtosis = 65.11). Thus, it can be concluded that participants actually followed the time limit instructions. The short decision time makes it fairly unlikely that
individuals were able to deliberately integrate cue values and cue validities (WADDdel). To
strengthen this argument, we carried out a study in which participants were instructed to deliberately apply a WADDdel strategy to similar decision tasks with two options and three cues
(Glöckner, 2006). The observed average decision time was 20.5 seconds (SE = 2.2s), which
lies far above the decision times observed in this experiment. Lohse and Johnson (1996) report comparable decision time predictions for the application of WADDdel in an open Mouselab. For decisions with two options but two or seven attributes, the partially empirically derived decision time predictions were 7.7 and 29.1 seconds.
Decision time data were log-transformed to the basis of 10 to reduce the influence of outliers
and the skewness and kurtosis of the distribution (Glass & Hopkins, 1996). The transformed
data points were fairly normally distributed (MD = 3.03, M = 3.09, SD = 0.26, skew = 1.05,
kurtosis = 1.27). To analyze decision times, a 23 (CUE PATTERN) x 6 (ORDER) repeated
measurement ANOVA was conducted, with log-transformed decision time as the dependent
variable. CUE PATTERN and ORDER were used as within-subject factors. Each cue pattern
was presented in six different versions, which were presented in a random order. Thus, the
factor ORDER ranged from first (1) to last (6) repetition of the cue pattern (and replaced the
factor VERSION in the analysis). A Greenhouse-Geisser correction was used because
Mauchly’s test turned out to be significant, indicating that the assumption of sphericity was
violated. The same correction was also used in all following analyses, where indicated. The
main effect for CUE PATTERN was highly significant, F(4.9, 68.2) = 24.04, p < .001, η2 =

14

<-----Page 16----->.63.2 Thus, it can be concluded that decision times differ systematically between cue patterns
(Figure 2), which speaks against the sole application of a WADDdel strategy.
As expected, there was also a significant main effect for the factor ORDER, F(1.6, 22.8) =
7.47, p = .006, η2 = .35. Although the time needed for the decision was already very low in
the first presentation of each cue pattern, decision times further decreased in later repetitions,
indicating learning effects. For this factor, the mean values for log-transformed decision
times, starting with the first presentation (with SE in parentheses), were 3.17 (0.037), 3.08
(0.039), 3.08 (0.039), 3.07 (0.045), 3.05 (0.042), and 3.06 (0.041).
The effect of the factor CUE on decision times was analyzed using a repeated-measurement
ANOVA with CUE as a within-participants factor. The main effect for CUE turned out to be
significant, F(2, 28) = 4.45, p = .021, η2 = .24. However, in contrast to the predictions derived
from a LEX/TTB strategy, decision times significantly decreased with the increasing number
of cues needed to differentiate according to a LEX/TTB strategy (M1 = 3.097, SE = 0.006; M2
= 3.070, SE = 0.009; M3 = 3.056, SE = 0.016). Thus, decision time data converge with choice
data in indicating that participants did not predominantly use a LEX/TTB strategy.
Figure 2
3.6

Set 2

Set 1

Set 3

3.5

Log(Decision Time)

3.4
3.3
3.2
3.1
3.0
2.9
2.8
2.7
2.6
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

Cue Pattern

Figure 2. Log-transformed decision times in Experiment 1. The “Positive O1” manipulation within set 1 is
indicated by different grayscales. Error bars indicate 95 percent confidence intervals.

2

The effect-size measures reported in this paper are all partial η2-values. Therefore, values do not add up to 1.

15

<-----Page 17----->The effects of the factors PRO_OPTION1 and PRO_OPTION2/3 were investigated using a 3
(PRO_OPTION1) x 5 (PRO_OPTION2/3) repeated measurement ANOVA with logtransformed decision times as the dependent variable. The analysis was run for set 1 only because there was no systematic manipulation of the factors in the remaining sets (cf. Table 2).
There were highly significant main effects for PRO_OPTION1, F(1.3, 17.9) = 31.8, p < .001,
η2 = .69, and PRO_OPTION2/3, F(2.9, 41.1) = 15.0, p < .001, η2 = .52, and a significant interaction between both factors, F(2.2, 30.4) = 36.9, p < .001, η2 = .73. As predicted by
WADDauto (but contrary to the predictions of WADDdel, LEX/TTB, and EQW), decision
times decreased with an increasing number of cues favoring option 1 and increased with an
increasing number of cue values favoring options 2 and 3 (Figure 2). Decision times were
particularly high for the critical cue patterns (7, 10, 13), accounting for the interaction effect.

Discussion
Our results indicate that the majority of the participants (67%) considered information on all
three cues as well as cue validities. Their choices were in line with a WADD strategy. Most
importantly, individuals were capable of successfully applying this strategy within less than
1.5 seconds on average (MD = 1.07 s). Although set under time pressure, participants refrained from using simple deliberate strategies like LEX/TTB or EQW. Consequently, the
major findings from Mouselab studies could not be replicated when individuals had unconstrained access to relevant information. Our results suggest that individuals can capitalize on
remarkable abilities for complex information integration and multiple-reason decision making. Considering the decision times observed in the above-mentioned study, in which participants were instructed to deliberately calculate weighted sums (Glöckner, 2006), it is unlikely
that individuals deliberately computed a WADDdel strategy, because the median decision time
of less than 1.1 seconds is far below the time necessary for calculating WADDdel or similar
weighted additive strategies.
We argue that these results emphasize the importance of automatic processes in decision making. As proposed by different authors (e.g., Hammond et al., 1987; Kahneman & Frederick,
2002), individuals seem to possess the ability not only to use simple deliberate heuristics but
also to apply decision strategies based on automatic processes that lead to choices according
to a weighted additive information integration (i.e., WADDauto). Even under time pressure,
these automatic strategies appear to have guided the decisions of the majority of participants
in our studies. By disentangling the limitations of information search and information integration, we were able to demonstrate that the cognitive capacity for information integration is not
as limited as generally assumed by proponents of the bounded rationality approach (e.g., Gigerenzer, 2004).
The results of Experiment 1 conflict with the well-established findings from Mouselab studies
showing that when there is severe time pressure, simple LEX/TTB strategies are usually employed (e.g., Payne et al., 1988). As argued above, Mouselab fosters the application of
16

<-----Page 18----->LEX/TTB strategies, because information search consumes considerable resources (e.g., time
required to perform the appropriate mouse movements). We remedied this problem by using
an open information display and a choice-based strategy classification method.3 Our findings
indicate that limitations of their information integration capacity is not always the major reason for individuals adopting simple strategies when subjected to time pressure. There is instead a straightforward alternative interpretation: Lacking the time to look up all information,
individuals concentrate on the most important pieces. Our results converge with several recent
findings showing that people tend to use WADD strategies instead of simple heuristics if information can be directly accessed in the environment (Bröder, 2000a; 2003; Glöckner, 2006).
Results on decision times further strengthen our point and provide converging evidence with
the choice analysis. The decision times clearly speak against the application of a deliberative
compensatory strategy (WADDdel) and instead support the assumption that weighted additive
procedures are performed by the automatic system (WADDauto). It might be argued that individuals could have used the following heuristic: “Choose the option favored by cue 1 unless
consensually outvoted by cues 2 and 3.”4 Obviously, this is also a multiple-reason strategy
because it takes into account all cue values and at least ordinal information about cue validities; nevertheless, it would be easier to apply than a WADDdel strategy. However, the observed systematic variations of decisions times clearly rule out its application. Specifically,
this heuristic could not explain the significant main effects for the number of positive cue values for option 1 (pro_option1) and the number of positive cue values for options 2 and 3
(pro_option2/3). Overall, it seems unlikely that simple heuristics can account for the differentiated findings concerning decision times.

Experiment 2
In Mouselab studies, it is a well documented finding that individuals switch to simple, noncompensatory strategies if task constraints (e.g., time) become severe (e.g., Rieskamp & Hoffrage, 1999). We argued that this finding might only apply to situations in which individuals
use deliberate decision strategies and Mouselab might induce the application of such strategies. In Mouselab studies, time pressure manipulations, for instance, might simply constrain
the depth of information search, because the motor activity needed to move the mouse to the
appropriate boxes is time consuming. The first experiment provided compelling evidence in
favor of this claim. As a caveat, however, we used a decision problem that has never been
3

4

From a methodological perspective, it needs to be kept in mind that choice-based strategy classification
entails the problem that WADD predictions dovetail with predictions from LEX/TTB and EQW strategies
(Bergert & Nosofsky, 2007; Bröder, 2000b; Glöckner, 2006; Glöckner, in press). This is because the latter are submodels of the former (e.g., persons who have equal cue validities for all cues but use a WADD
strategy are misclassified as EQW users that ignore cue weights per se). Thus, the proportions of WADD
users reported in this and the following studies have to be considered a conservative estimate of the real
proportions, and it is highly possible that more participants used a WADD strategy. Note, however, that
this only strengthens our argument.
We thank Peter Ayton for suggesting this alternative heuristic.

17

<-----Page 19----->employed in Mouselab studies before. To rule out that results are specific to our problem domain, we ran a second experiment that used the same types of problems but employed the
classic Mouselab tool. If the above reasoning is correct, we should be able to replicate those
findings documented in the literature. Specifically, in a Mouselab with hidden information,
participants should switch to simple, noncompensatory strategies if time limits become severe.
We manipulated time limits on three levels. A lenient time limit condition was designed to
allow for the repeated inspection of all the information. A medium time limit condition provided just enough time to look up each piece of information once. A severe time limit condition did not allow all pieces of information to be looked up, but it provided approximately the
self-selected average decision time that individuals used in Experiment 1. We expected that
the majority of individuals would apply a WADD strategy under the lenient and medium time
limit conditions but adopt a LEX/TTB strategy under the severe time limit condition.
In the classic Mouselab program, information search parameters can be recorded. We considered two important parameters of information search: the number of information boxes
opened per cue and the direction of search. We use the PATTERN index to measure direction
of search (also called SI-index; Payne et al., 1988; for a critical view, see Böckenholt & Hynan, 1994; see also Footnote 6 below). PATTERN indexes the relative proportion of cuebased and option-based transitions between information boxes. Given the acquisition of a particular piece of information, a cue-based transition means that the next acquisition involves
the same cue but a different option; an option-based transition means that the next acquisition
involves the same option but a different cue. PATTERN is calculated by subtracting the number of cue-based transitions from the number of option-based transitions and dividing this difference by the sum of both transitions. Thus, PATTERN indicates whether individuals’ search
for information is more cue-based or option-based. It ranges from -1 to 1. Negative values
indicate more cue-based and positive values more option-based search. Hence, negative
scores are usually interpreted as evidence for noncompensatory decision strategies like
LEX/TTB, whereas positive scores are taken as evidence for compensatory decision strategies
like WADD (although it has to be acknowledged that the score only measures the direction of
information search, not information integration itself).

Method
Participants and Design. Fifteen students (9 female, 6 male) from the University of Heidelberg participated in a 30-minute study and were compensated for participation either by
course credit or a flat fee of 4 euros. Again, decision tasks were manipulated within participants by using 23 different cue patterns in six different versions (see Table 2). Time limit was
manipulated on three levels as a further within-participants factor (lenient: 8s, medium: 3s,
severe: 1.5s). The six versions of each cue pattern were equally assigned to one of the time
limit conditions using a random procedure. Thus, the factor VERSION was nested within the
18

<-----Page 20----->factor TIME LIMIT, resulting in a 23 (CUE PATTERN) x 3 (TIME LIMIT) x 6 (VERSION)
nested within-participants design.
Materials and Procedure. We used the same cover story, instructions, and materials as in Experiment 1. Again, cue information was presented in an information matrix with options displayed in columns and cues in rows (Figure 3). In contrast to the previous study, information
was hidden in boxes. Each information box opened automatically when hit by the mouse cursor. First, participants were introduced to the task and informed about the cue validities. After
becoming familiarized with Mouselab, they completed eight test trials. The following 138
target decision tasks were presented in three blocks, each with a different time limit. Time
limits increased over the three blocks of trials. Blocks were separated by 1-minute breaks
(black screen). For each decision task, participants could move the mouse to access information. A piece of information was visible only as long as the cursor was held on the information box. A time bar was shown at the top of the screen to inform participants of time limits.
The length of the bar decreased in proportion to the elapsed time. Immediately after the decision task was presented, the bar began counting down time.
Figure 3
Search for information and select a vendor by clicking on it.

Option 1

Tester 1

Option 2

Option 3

+

Tester 2

Tester 3

Figure 3. Mouselab presentation used in Experiment 2.

Again, participants were asked to make accurate decisions and to proceed as quickly as possible. Furthermore, they had to make their choices within the time limit; after the allotted time
had elapsed, no further information search was possible. Nevertheless, participants were
forced to make a decision and were subsequently reminded to keep within time limits.
Choices, decision times, and information-search parameters (opened information boxes and

19

<-----Page 21----->time for opening) were recorded.5 Decision times were measured from the onset of the decision task to the selection of the option. Options were selected by mouse click; the mouse cursor was initially positioned in the upper left-hand corner of the screen. Each decision task was
started by clicking a button on an introductory screen. The Mouselab software was programmed in Visual Basic 6.0 and was run on IBM-compatible computers.

Results
Strategy Classification Based on Choices. The same method as in the previous experiment
was used to classify strategies. Each time limit block was analyzed separately. Note that the
reduced number of analyzed choices reduced the statistical power and thereby increased the
probability of LEX/TTB and EQW classifications. As explained in the results section of Experiment 1, two individual χ2-tests had to turn out significant for one participant to be classified as WADD user. With only one third of the number of observations, it becomes less likely
that existing effects will be detected at a specified alpha level (i.e., the beta error increases).
Accordingly, the likelihood that a WADD user is mistakenly classified as an EQW or
LEX/TTB user increases substantially. In compensation, we used an increased alpha level of
α = .10 in both tests. First, we analyzed whether the proportion of choices of option 1 (vs.
choices of options 2 + 3) in cue patterns 7, 10, and 13 differed from the proportion of choices
of option 1 in the remaining cue patterns, using individual χ2-tests of independence. Second,
we tested the observed proportions across options (i.e., option 1 vs. options 2 + 3) in patterns
4, 8, 11, and 18 against an equal distribution. It turned out that under the lenient time limit
condition, the majority of participants used a WADD strategy (Table 3). Under the medium
condition, participants mainly retained their decision strategy. Three former WADD users
switched to the EQW and LEX/TTB strategies. When the time limits were severe, almost all
the participants turned to a LEX/TTB strategy. Thus, choice data are in line with our expectation that decision strategies only change if time pressure prevents all pieces of information
from being inspected (i.e., under severe time limits).
Manipulation Check for the Factor TIME LIMIT. A 23 (CUE PATTERN) x 3 (TIME LIMIT)
x 2 (REPEAT) repeated measurement ANOVA, with log-transformed decision times as dependent variables, revealed a significant effect for TIME LIMIT, F(1.3, 18.4) = 457.4, p <
.001, η2 = .97. This indicates that our time limit manipulation was successful. With decreasing
time limits, actual decision times decreased. The median decision times for the lenient, medium, and severe time limit conditions in seconds were 4.28, 2.56, and 1.49 respectively. Furthermore, CUE PATTERN was found to have a significant main effect, F(3.1, 44.0) = 5.80, p
< .001, η2 = .29. For the critical patterns 7, 10, and 13, the decision times were again particularly high. Similarly high decision times were found for cue patterns 4, 17, 18, 19, and 23. A

5

For pragmatic reasons, information-search data were recorded only for the first 20 inspected information
boxes per decision task.

20

<-----Page 22----->considerable portion of decisions (22% vs. 49%) under the medium and severe time limit
conditions was made after the time limit allotted for the information search had elapsed.
Strategy Classification Based on Information Search. The distribution of inspected information boxes per cue was analyzed using a 3 (CUE) x 3 (TIME LIMIT) repeated measurement
ANOVA, with the numbers of viewed information boxes as a dependent variable. The main
effect for CUE was highly significant, F(1.9, 26.0) = 45.52, p < .001, η2 = .76, indicating that
participants looked up more pieces of information for more valid cues (Table 4). There was
also a significant main effect for TIME LIMIT, F(1.4, 19.3) = 92.6, p < .001, η2 = .87. The
number of opened information boxes also decreased parallel to decreases in the time limit. As
indicated by the information box index in Table 4 (which is calculated by dividing the number
of opened information boxes by the number of available ones), under lenient time limits, participants inspected each information box more than once; under medium time limits, each information box was opened once on average; under severe time limits, only 61 percent of the
information boxes were inspected. The interaction between the factors CUE and TIME LIMIT
was also significant, F(2.1, 29.8) = 18.7, p < .001, η2 = .57. It was found that participants focused their information search on the most valid cue even more when time limits decreased.
Table 4
Information-Search Parameters Experiment 2
Information-Search Parameters
Information Box Index

PATTERN

Cue 1

Cue 2

Cue 3

M

M

SE

Lenient Time Limit

1.51

1.49

1.01

1.34

.05

.10

Medium Time Limit

1.31

1.16

0.60

1.02

.08

.11

Severe Time Limit

1.16

.49

0.16

0.61

-.42

.09

Note. The information box index is a measure of the number of information boxes opened divided by the number
of boxes available. A value of 1 indicates that the number of opened information boxes was equal to the number
of available information boxes; lower values indicate that fewer boxes were opened than available. Higher values
indicate that boxes have been opened repeatedly. The PATTERN index indicates whether information searches
were predominantly cue-based (negative values) or option-based (positive values).

To further investigate search strategies, the information search index PATTERN was computed (Payne et al., 1988).6 We conducted a repeated measurement ANOVA with the differ6

Note that transitions in which the acquisition involves both another cue and another option are not considered in the index and that the PATTERN index for each participant was computed using the total number of cue-based and option-based transitions for the 46 decision trials in each time limit condition. It has
been argued that the former could lead to biased strategy classification results if the number of options
and the number of cues (or dimensions) in the Mouselab matrix differ (Böckenholt & Hynan, 1994). This
was not the case in our experiment. Nevertheless, we additionally calculated the unstandarized SM* index
that also takes into account all other transitions (Böckenholt & Hynan, 1994). As expected, this did not
change our results substantially (SM*lenient TP = .06, SM*medium TP = .07, SM*sever TP = -.30).

21

<-----Page 23----->ent PATTERN scores for the time limit conditions as dependent variables. There was a significant effect for TIME LIMIT, F(1.3, 18.6) = 14.0, p = .001, η2 = .50. Under the first two
conditions, there was a slight preference for option-based searches. Under the severe time limits, in contrast, individuals showed a strong preference for cue-based searches (Table 4; right
column). Two contrasts were computed to further pinpoint this effect. It turned out that there
was no difference in the PATTERN scores between the lenient and the medium time limit
conditions, F(1, 14) = .16, p = .70, η2 = .01. However, the difference between the severe time
limit condition and medium/lenient time limit conditions was highly significant, F(1, 14) =
16.32, p < .01, η2 = .54. Thus, as expected, patterns of information search changed only when
decision time was too short to investigate all pieces of information.
For each person and each time limit block, we further analyzed whether results on the PATTERN index dovetail with those of strategy classification based on choices. In 73% percent of
the 45 comparisons (each comparison was computed for three time limit conditions per person), results of both measures converged.

Discussion
The second experiment examined whether changes in decision strategies in Mouselab experiments under time pressure (e.g. Payne et al., 1988) are due to limitations in information search
instead of limitations in cognitive capacity, as is generally assumed. It was found that when
sufficient time to inspect all of the information was allotted, choices were in line with a
WADD strategy. Under the severe time limit of 1.5 seconds, it was no longer possible to inspect all the information boxes; participants then used a LEX/TTB strategy, inspecting only
the information on the most valid cue. Together, the results of Experiment 1 and 2 provide
evidence that at least in some experimental settings the use of simple, noncompensatory
strategies (e.g., LEX/TTB) is indeed caused by constraints of information search rather than
by limitations of cognitive capacity.
In the two experiments, choices and decision time patterns were shown to be in line with our
hypothesis that individuals are able to quickly integrate multiple pieces of evidence in a
weighted additive manner. There is conclusive evidence that the majority of individuals takes
available pieces of information into account and considers them according to their validity.
Thus, our results are difficult to explain with fast and frugal heuristics (Gigerenzer et al.,
1999) that ignore either cue values or cue validities. The applied decision strategies appear not
to be based on one or a few reasons but instead capitalize on the wealth of the information
given.
Nevertheless, the findings could still be challenged in two ways. First, it might be questioned
whether the results generalize to more complex decision tasks. One possible hypothesis is that
individuals encode the array of information as a constellation. This constellation could be
compared with different prototypes or exemplars (Juslin, Olsson, & Olsson, 2003; Olsson,
22

<-----Page 24----->Enkvist, & Juslin, 2006), or mere perceptual pattern recognition processes could be used to
reach a decision quickly (e.g., by identifying a specific series of + and -). This might be particularly the case in simple tasks in which cues are always presented in the same order. Second, one might speculate whether the results evidence application of “complex heuristics”
such as TTB-CONFIGURAL (Garcia-Retamero, Wallin, & Dieckmann, 2007): Participants
could have used fast and frugal heuristics that were not based on single cues but rather on
complex ones, such as configurations of cue values (which are then applied in the order of
their validity). Individuals could have learned to react appropriately to certain cue patterns by
identifying the complete constellations of the three cues (e.g., the most important cue points
towards A, all others point towards B) or parts of them (but see discussion of Experiment 1).
Findings by Nosofsky and Bergert (2007) lend initial support for the application of TTBCONFIGURAL in multiple cue decision tasks. To critically test these alternative interpretations, we conducted a third experiment.

Experiment 3
In this study, we kept the constellation of cue information constant and manipulated the validity of only one cue without changing the constellation (i.e., without changing the order of cues
in the cue hierarchy). If decisions are based solely on the conceptual constellation of cue information, this manipulation should not influence decisions. Furthermore, the presentation
order of cues in the information matrix was randomized to prevent mere perceptual pattern
recognition processes. More complex decision problems with six cues and two options were
used. Confidence judgments were measured as an additional dependent variable. According to
a LEX/TTB strategy, confidence judgments should depend on the validity of the differentiating cue only. According to a WADDauto strategy, confidence judgments should depend on the
difference between the weighted sums of cue values and cue validities for the available options.

Method
Participants and Design. Sixty-three students (55 female, 8 male) from the University of Erfurt participated in a 20-minute-long experiment, which was part of a one-hour experimental
battery of thematically unrelated studies. Students received 6 Euros for their participation in
the entire hour. Decision tasks were again manipulated within participants, resulting in a 6
(CUE PATTERN) x 4 (CUE VALIDITY) x 3 (REPETITION) design.

23

<-----Page 25----->Table 5
Cue Patterns Experiment 3
Cue Pattern
1

2

3

4

5

6

A

B

A

B

A

B

A

B

A

B

A

B

Cue 1(p = .80 to .95)

+

-

+

-

+

-

+

-

+

-

+

-

Cue 2 (p = .75)

-

+

-

-

-

+

-

-

-

+

+

-

Cue 3 (p = .70)

-

-

-

-

-

+

-

-

-

+

-

-

Cue 4 (p = .65)

-

-

-

-

-

-

-

-

-

+

-

-

Cue 5 (p = .60)

-

-

-

-

-

-

-

+

-

+

-

+

Cue 6 (p = .55)

-

-

-

+

-

-

-

+

-

+

-

+

Note. The six cue patterns used in Experiment 3 are depicted in a matrix format. Cues are shown in the left-hand
column. The percentage of correct predictions p of each cue is given in parentheses. A and B represent options.

Materials and procedure. Six cue patterns were used (Table 5). In cue patterns 1, 2, and 6, an
equal number of cues had positive cue values for both options. In cue patterns 3, 4, and 5, the
most valid cue made a prediction contrary to at least two other cues. Cue patterns were repeated three times with randomized orders of options and cues (REPETITION). Again, we
provided individuals with explicit information about the probability of correct predictions
made by each cue. This probability was varied for the most valid cue from .80 to .95 in steps
of .05 (CUE VALIDITY). The probabilities were constant for the remaining cues 2 to 6 at
levels of .75, .70, .65, .60, and .55.
Independent of the cue validity manipulation, the LEX/TTB strategy predicts choices of option A in all six cue patterns, because the most valid cue always points towards this option.
The EQW strategy predicts choices of options B in cue patterns 3, 4, and 5 and a random selection of options in the remaining ones. Independent of the manipulation of the validity of
cue 1, the WADD strategy predicts choices of option A in cue patterns 1, 2, and 6.
Choices in WADD strategies crucially depend on individuals’ transformation of given accuracy probabilities of cues into cue weights. The simplest possibility is to follow an ignorant
WADD strategy and to use probabilities as cue weights without any transformation (e.g., .55
for cue 6). In cue patterns 3, 4, and 5 such an ignorant WADD strategy would make predictions for option B only. Note that such a strategy could easily be misleading because it does
not take into account that cues with a probability of .50 are uninformative and should be ignored (cf. Experiment 1). It would be more appropriate for participants to transform provided
probabilities into cue weights so that information about cues with a probability of .50 is
weighted 0. Individuals who use an ignorant WADD strategy would select option B in cue
patterns 3, 4, and 5, independent of the cue validity manipulation. Individuals who take into
24

<-----Page 26----->account the problem and correct their decision weights should show decreasing choices of
option B with increasing validity of cue 1.
The cue validity manipulation should only influence choices if participants use decision
strategies that are based on processes that integrate information in a weighted additive manner; no influence of the manipulation on choices would be predicted if individuals base their
decision simply on the constellation of cues. Thus, the manipulation of cue validities was used
for testing the (second) alternative explanation raised above.
Participants made their choices via mouse click on the option (Figure 4). After each choice,
individuals were asked to indicate their confidence in their decision on a continuous horizontal scale: “Please indicate how certain you are of your decision!” The endpoints of the scale
were labeled “very uncertain” and “very certain.” The scrollbar was presented below the information matrix, which remained visible until the judgment was made. After each decision,
an instruction screen was shown. Clicking a “continue” button ensured that the cursor was
always positioned in the middle of the screen when the individual started to work on the next
decision task.
Figure 4

Oranges A

Oranges B

Choose

Choose

Tester 1
(90% correct)

+

-

Tester 2
(60% correct)

-

-

Tester 3
(70% correct)

-

+

Tester 4
(75% correct)

-

+

Tester 5
(65% correct)

-

-

Tester 6
(55% correct)

-

-

Figure 4. Presentation format of decision tasks used in Experiment 3.

After a learning trial, individuals were presented with 72 decision tasks comprising different
versions of the six cue patterns presented in Table 5. Each CUE PATTERN was realized for
all four CUE VALIDITY conditions and each of the resulting decision tasks was repeated
three times. Decision tasks were presented in individually randomized order. The order of the
options and the order of the cues in each decision were also individually randomized for each
trial.
25

<-----Page 27----->Results
Strategy Classification Based on Aggregate Choices. Proportions of choices of option B in the
six CUE PATTERNS and the four CUE VALIDITY conditions are depicted in Figure 5.
There were very few decisions for option B in cue patterns 1, 2, and 6, but a considerable proportion of choices of option B in cue patterns 3, 4, and 5, with choice proportions for option B
decreasing with increasing validity of the first cue. To test whether choices differ significantly
between the six cue patterns, a χ2- test against an equal distribution of choices of option B
across the six cue patterns was conducted. This analysis produced a highly significant effect, χ
(5; N = 789) = 1176.6, p < .001. Thus, contrary to the predictions of a LEX/TTB strategy,
aggregated choices differ significantly between cue patterns, indicating that individuals based
their decisions on multiple pieces of information rather than on the most valid cue. To test
whether choices differ between levels of CUE VALIDITY for cue 1, a χ2- test against an
equal distribution of choices of option B in the four CUE VALIDITY conditions was conducted. The test turned out to be highly significant, χ (3; N = 789) = 86.5, p < .001. Thus,
against the predictions of the EQW strategy, choices were influenced by the cue validity manipulation, indicating that cue information was considered according to its validity. The significant effects of the CUE VALIDITY manipulation rules out the hypothesis that individuals
simply react to constellations of cues because the constellation was held constant and only
validities of the most valid cue varied.
Figure 5

Choices for Option B (in percent)

0.80
Pattern 1
Pattern 2
Pattern 3
Pattern 4
Pattern 5
Pattern 6

0.70
0.60
0.50
0.40
0.30
0.20
0.10
0.00
0.80

0.85

0.90

0.95

Validity of Cue 1
Figure 5. Percentage of choices of option 2 in Experiment 3.

26

<-----Page 28----->Strategy Classification Based on Individual Choices. To investigate decision strategies more
closely, individual choice patterns were analyzed in the same way as in the previous experiments. For each individual, two χ2- tests were conducted to test against the predictions of the
LEX/TTB and the EQW strategies. First we tested whether the proportion of choices of option
A or B were the same in the cue patterns 1, 2, and 6 as compared to the cue patterns 3, 4, and
5 using a χ2- test of independence. A significant difference would indicate that individuals did
not use a LEX/TTB strategy. Second we tested whether the choices of option A and B were
equally distributed in cue patterns 1, 2, and 6. A significant deviation from the equal distribution would indicate that individuals did not use an EQW strategy but instead acknowledged
cue validities. A significance level of α = .05 was applied in both clusters of tests. If one of
the tests failed to reach this level of significance, an individual was classified as LEX/TTB or
EQW user, respectively. The results of the strategy classification are shown in Table 3 (last
row). In line with the results on the aggregate level, the majority of individuals decided in
accordance with a WADD strategy. Only a minority of individuals seemed to use a LEX/TTB
strategy.
A 6 (CUE PATTERN) x 4 (CUE VALIDITY) x 3 (REPETITION) x 2 (DECISION TIME
VS. CONFIDENCE) MANOVA was conducted to investigate the simultaneous effect of the
within-participants manipulations on decision times and confidence judgments. The relevant
factors CUE PATTERN and CUE VALIDITY showed significant main effects, a significant
interaction with each other and significant interactions with DECISION TIME VS. CONFIDENCE.7 Thus, in line with our expectations, the factors influenced decision time and confidence in opposing directions. Univariate analyses of decision times and confidence judgments
were run to further explore these effects.
Decision Times. The median of decision times was 3.71 seconds, indicating that individuals
followed the time pressure instruction (SD = 4.29, skew = 8.26, kurtosis = 127.7). Note that
the increase in decision times as compared to the previous experiments is likely because six
rather than three cues were provided and that, unlike in Experiments 1 and 2, the presentation
order of cues was randomized. For the further analyses, decision times were again logtransformed to reduce the influence of outliers and to account for deviations from normal distribution. We conducted a 6 (CUE PATTERN) x 4 (CUE VALIDITY) x 3 (REPETITION)
repeated measurement ANOVA with log-transformed decision times as dependent variables.
The main effects for CUE PATTERN turned out to be significant, F(2.8, 170.8) = 56.8, p <
.001, η2 = .48. The longest decision times were observed for cue pattern 5 and the lowest deci7

The omnibus tests revealed significant main effects for the factors CUE PATTERN, Pillais V = .67, F(5,
58) = 28.9, p < .001, η2 = .67, CUE VALIDITY, Pillais V = .46, F(3, 60) = 16.8, p < .001, η2 = .46, and
DECISION TIME VS. CONFIDENCE, Pillais V = .67, F(1, 62) = 125.3, p < .001, η2 = .67. Furthermore, the following two-way interactions were significant: DECISION TIME VS. CONFIDENCE by
CUE VALIDITY, Pillais V = .46, F(3, 60) = 17.1, p < .001, η2 = .46, DECISION TIME VS. CONFIDENCE by CUE PATTERN, Pillais V = .67, F(5, 58) = 23.9, p < .001, η2 = .67, and CUE VALIDITY
by CUE PATTERN, Pillais V = .49, F(15, 48) = 3.1, p < .01, η2 = .49. Moreover we obtained a significant three-way interaction between DECISION TIME VS. CONFIDENCE, CUE VALIDITY, and CUE
PATTERN, Pillais V = .50, F(15, 48) = 3.1, p < .01, η2 = .50.

27

<-----Page 29----->sion times were found for cue patterns 1 and 2 (Figure 6; SE ranged from 0.014 to 0.027).
Thus, the finding that decision times are particularly long in decisions with conflicting cue
information (i.e., cue patterns 3, 4, and 5) could be replicated. There was also a significant
main effect for CUE VALIDITY, F(2.6, 163.3) = 22.5, p < .001, η2 = .27. Decision times decreased with increasing validity of cue 1 (see Figure 6). In addition, there was a significant
main effect for REPETITION, indicating learning effects, F(1.4, 84.6) = 128.1, p < .001, η2 =
.67. The means of the log-transformed decision times for the three repetitions (with SE in parentheses) were 3.68 (0.016), 3.59 (0.012), and 3.54 (0.012). The interaction between CUE
VALIDITY and CUE PATTERN also turned out to be significant, F(10.1, 623.3) = 3.1, p <
.01, η2 = .05.
Figure 6

Log-Transformed Decision Times

3.8

3.7

3.6

3.5

3.4

Pattern 1
Pattern 2
Pattern 3
Pattern 4
Pattern 5
Pattern 6

3.3
0.80

0.85

0.90

0.95

Validity of Cue 1
Figure 6. Log-transformed decision times in Experiment 3.

To explore whether decision times differ between LEX/TTB users and WADD users, we
added another factor to the ANOVA. Specifically, we considered the result of the individual
strategy classification as an additional factor. In this 4-factorial ANOVA, the factor DECISION STRATEGY had no main effect on decision time, F(1, 61) = 0.36, p = .55, η2 = .01.
Both the two-way interaction between DECISION STRATEGY and CUE VALIDITY and the
three-way interaction between DECISION STRATEGY, CUE VALIDITY, and CUE PATTERN turned out to be significant, F(2.6, 160.2) = 3.0, p < .05, η2 = .05, F(10.1, 617.4) = 2.6,
p < .01, η2 = .04. Given the null effect of DECISION STRATEGY, we can conclude that participants were able to integrate all pieces of evidence according to a WADD rule in approxi28

<-----Page 30----->mately the same time that (other) participants needed to apply a simple LEX/TTB rule. However, the substantial interactions indicate that different decision strategies led to different patterns of decision time (cf. Table 1), although it should be noted that the effect sizes for these
interactions are relatively low. WADD users showed patterns that could mainly be explained
by the application of WADDauto, whereas LEX/TTB users showed considerable differences in
decision times – a finding that could hardly be explained by LEX/TTB. This could indicate
that a considerable proportion of WADD users were still misclassified as LEX/TTB users (see
Footnote 3).
Confidence Judgments. Confidence judgments were analyzed using a 6 (CUE PATTERN) x 4
(CUE VALIDITY) x 3 (REPETITION) repeated measurement ANOVA. The CUE PATTERN produced a significant main effect, F(2.5, 152.4) = 48.4, p < .001, η2 = .44. Confidence
ratings were higher for cue patterns 1, 2, and 6 than for the remaining cue patterns (Figure 7;
SE ranged from 3.2 to 6.0). We also obtained a significant main effect for CUE VALIDITY,
F(2.0, 125.0) = 34.7, p < .001, η2 = .36. Confidence increased with increasing validity of cue
1 (see Figure 7). There was a significant interaction between CUE VALIDITY and CUE
PATTERN, F(8.3, 516.1) = 7.3, p < .001, η2 = .11. The cue validity manipulation led to a
general increase in confidence in all cue patterns except cue pattern 5, in which a decrease
was observed.
Figure 7

100

Confidence Judgments

90
80
70

Pattern 1
Pattern 2
Pattern 3
Pattern 4
Pattern 5
Pattern 6

60
50
40
30
20
10
0
0.80

0.85

0.90

0.95

Validity of Cue 1
Figure 7. Confidence judgments in Experiment 3 with high values indicating a high level of confidence. Ratings could range from -100 to 100.

29

<-----Page 31----->To test more specifically the hypothesis that confidence judgments increase with increasing
differences between the weighted cue values of options, we computed correlations between
difference scores D (i.e., difference between total evidence for options) and confidence judgO
O
O
O
O
ments. Difference scores were computed by D = ∑ ci 1 wi 1 − ∑ ci 2 wi 2 in which ci 1 and
O
ci O2 are cue values of cue i for options A and B (i.e., -1 or 1); wi 1 and wi O2 are decision
weights for options A and B. Decision weights were calculated in two different ways. First,
according to an ignorant WADD strategy, accuracy probabilities (e.g., .75 for cue 2) were
directly used as decision weights (wcue = pcue); second, difference scores were calculated by
correcting for the fact that cues with an accuracy probability of .50 only (wcue = pcue - .50) are
uninformative. Correlations were calculated between confidence judgments and difference
scores D based on ignorant WADD and corrected WADD. There was a significantly negative
correlation for difference scores based on ignorant WADD, r = -.51, t(70) = -5.01, p < .001
(two-tailed), but a significantly positive correlation for corrected difference scores, r = .35,
t(70) = 3.16, p = .002 (two-tailed). We did not expect a positive correlation for ignorant
WADD because choice data already indicated that individuals corrected their decision
weights. For the corrected difference scores, we obtained a substantial positive correlation.
This supports the hypothesis derived from WADD strategies that the difference of the
weighted cue values between options influences confidence judgments. Thus, the findings
lend further support to our general hypothesis that individuals integrate information in a
weighted additive manner. If cue validities or cue values were ignored, no correlation would
be expected.

Discussion
In the third experiment, the general findings of the previous experiments could be replicated
and strengthened by additional evidence. The majority of individuals took into account cue
values and cue validities. Choices and confidence judgments indicate that the information was
integrated in a weighted additive manner. The low overall decision times make it likely that
individuals thereby relied on automatic processes; the systematic variations of decision time
between cue patterns in line with the predictions of WADDauto further corroborate this hypothesis. Note that the observed decision time of 3.7 seconds is not per se evidence for automatic processes. There are many cognitive tasks in which such a decision time would indicate
the application of deliberate processes (e.g., simple Stroop tasks or categorization tasks as
used in the implicit association test; Greenwald, McGhee, & Schwarz, 1998). However, in
decision tasks of the complexity used in our experiment, in which 12 cue values and 6 cue
validities had to be considered, a decision time of 3.7 seconds substantially decreases the likelihood that WADDdel strategies were applied.8

8

As mentioned above, Lohse and Johnson (1996) estimated the time for applying such a strategy in an
open Mouselab in decision tasks of similar complexity (i.e., 2 options and 7 attributes) to be 29.1 seconds.

30

<-----Page 32----->It could be shown that individuals are sensitive to minor manipulations of cue validities that
do not change the general constellation of cue values. This clearly speaks against the idea that
cue information is merely encoded as a constellation and compared with prototypes. Individuals integrate information in a weighted additive manner that is sensitive to minor changes in
cue validities. Note that this observation also rules out alternative fast and frugal heuristics
that are all based on ignorance or only ordinal considerations of cue validities (like the one
discussed as an alternative explanation for the findings in Experiment 1). Finally, the findings
cannot be explained by the recently proposed “complex heuristics” like TTB-CONFIGURAL
(Garcia-Retamero et al., 2007) because, according to the heuristic, the minor manipulation of
cue validities should not influence choices. Thus, our findings differ from that of Nosofsky
and Bergert (2007), which found data in line with TTB-CONFIGURAL. It is highly likely
that the many differences in materials and procedures (among other things, Nosofsky and Bergert used materials with interacting cue structures and provided feedback for decisions) might
have caused the differences. Further research will be necessary to investigate the reasons for
these differences more closely.
The analysis of confidence judgments lends additional support for WADDauto strategies. In
particular, the substantial correlation between confidence judgments and difference scores
makes it unlikely that cue values or validities are ignored in the decision, although we cannot
rule out that confidence judgments might have been based on other information than choices
alone.

General Discussion
Process tracing studies have repeatedly shown that individuals employ simple strategies that
minimize the amount of considered information and the mental effort invested in the decision
(e.g., Payne et al., 1988). Although the question of strategy selection is still subject to theoretical debate (e.g., Glöckner & Betsch, 2008; Lee & Cummins, 2004; Newell, 2005; Rieskamp & Otto, 2006), a few models converge in assuming that time and capacity constraints
provoke strategy shifts towards a LEX/TTB rule (e.g., Bettman, Luce, & Payne, 1998; Rieskamp & Hoffrage, 1999). Moreover, joint evidence from simulations and empirical research
suggests that LEX/TTB rules can lead to quite accurate decisions (Czerlinski, Gigerenzer, &
Goldstein, 1999), especially under time pressure (Payne et al., 1988). Taken together, these
findings seem to corroborate the cornerstone assumptions of the bounded rationality approach
that has been directing and inspiring psychological decision research over the last decades.
One of these is that humans commonly lack the cognitive resources to apply extensional,
compensatory strategies such as the WADD rule, particularly under time pressure. We hypothesized that this assumption does not hold if decision strategies are considered that capitalize on automatic processes for information integration and choice.When introducing the notion of bounded rationality, Herbert Simon (1955) already anticipated that the boundaries he
described might only pertain to the deliberate side of the cognitive system: “My first empiri31

<-----Page 33----->cal proposition is that there is a complete lack of evidence that, in actual choice situations of
any complexity, these [EU] computations can be, or are in fact, performed… but we cannot,
of course, rule out the possibility that the unconscious is a better decision-maker than the
conscious” (p. 104, italics added). Unfortunately, the research method regularly used in studying strategy application, Mouselab, hinders both the operation and the observation of automatic processes. It forces decision makers to engage in a step-by-step consideration of information, the units of observation being the steps represented by the movements of a computer
mouse. The underlying assumption of this method is that overt information search behavior
mimics hidden cognitive processes. We call this assumption into question, asserting instead
that by directing individuals to uncover information one piece at a time, Mouselab binds task
resources such that decision makers expend most of their time and effort on gathering information and thus cannot unfold their processing potential. Especially under time constraints,
they are not able to collect as much information as they could process and therefore might
work below their computational capacity. If this reasoning is true, the conclusions drawn from
Mouselab studies would have to be reconsidered. Accordingly, the prevalence of shortcut
strategies under Mouselab conditions might not provide evidence of limitations in the cognitive apparatus but simply show limitations in information search (i.e., uncovering hidden information in a matrix). Hence, we suspected that the predominance of LEX/TTB strategies
under time constraints found in the majority of Mouselab studies was partially induced by the
experimental procedure.
We tested this assumption in three experiments using choice-based strategy classification with
open information presentation and compared the results with conditions using a standard
Mouselab under different time pressure conditions. The results indicate that individuals are
able to apply WADD rules within an astoundingly narrow time frame if information search is
not restricted by environmental conditions. We were able to replicate prior findings in Experiment 2, where we employed the standard Mouselab program. In such an environment,
participants searched for information in accordance with the LEX/TTB rule when time limits
were too tight to inspect all pieces of information. In a third experiment, we investigated the
cognitive processes that allowed individuals to quickly integrate information according to a
WADD rule. Here we showed that choices were sensitive to even small changes in cue validities. By keeping the ordinal structure of the cue hierarchy constant in the latter experiment,
we could rule out the explanation that individuals only encode constellations of information
and compare them to prototypes, exemplars or use heuristics which are based on complex
configural cues. Taken together, the studies provide evidence that the predominance of simple, noncompensatory strategies documented in Mouselab studies may well have been caused
by the experimental method and not by cognitive limitations. As demonstrated, Mouselab is
likely to induce the application of deliberate processes and thereby hinder the application of
automatic processes. Consequently, the total cognitive capacity of human decision makers is
substantially underestimated. Testing the potential of the human mind in Mouselab is like
testing the power of a Ferrari's engine in a parking lot. Obviously, the Ferrari cannot unfold its

32

<-----Page 34----->powers in such a constrained environment. Rather, we need to run it on a speedway before
making a verdict about its performance.
Our results indicate that individuals are capable of performing decision strategies involving
complex information integration in an astonishingly short time period. Thus, the assumption
that limitations of the cognitive capacity for information integration cause the application of
simple serial strategies – as proposed by proponents of the bounded rationality approach – has
to be revised. As anticipated by Herbert Simon, there may be another possibility for relieving
humans from the burden of endless, complex mathematical computations. Evolution may
have equipped humans with very powerful cognitive tools that capitalize on the automatic
integration of information (Glöckner, in press). It has been shown that even sticklebacks select mating partners by a weighted consideration of multiple pieces of evidence (Künzler &
Bakker, 2001) and that monkeys react to stimuli by considering probabilities and values in a
weighted additive way (Glimcher, Dorris, & Bayer, 2005). Thus, from an evolutionary perspective, it seems rather unlikely that humans lack the cognitive capacity for such operations.
Our conclusions concerning the differential influence of time pressure on automatic and deliberate decision strategies converge nicely with recent findings by Beilock and DeCaro
(2007), who investigated the influence of working memory capacity, time pressure and structure of the environment on individuals’ strategies and performance in solving complex
mathematical problems. Individuals’ problem-solving strategies were measured by analyzing
self-reports. Statements were categorized to indicate rule-based strategies or estimations based
on previous associations with problem operands. The former are deliberate strategies, the latter (at least) contain what we call automatic strategies. In environments in which rule-based
strategies lead to good performance, rule-based deciders showed a worse performance under
high as compared to low time pressure, whereas the inverse effect was observed for persons
who relied on more automatic strategies. Thus, time pressure hampers deliberate processes
but does not necessarily have a negative effect on automatic processes.
According to our experiments, automatic strategies are likely to be used if a quick inspection
of information is possible. At the same time, Glöckner and Hodges (2006) also found evidence for automatic strategies in experiments in which information had to be retrieved from
memory (but see Bröder & Schiffer, 2003a). However, further research will be needed to investigate the application of automatic strategies under different context conditions, including
monetary multi-attributive decisions, which have often been used in classic Mouselab studies.
Based on our data it is not possible to conclusively differentiate between the automatic processing models proposed by different authors (e.g., Beach & Mitchell, 1996; Busemeyer &
Townsend, 1993; Dougherty et al., 1999). Nevertheless, only such models that predict choices
based on weighted additive information integration and systematic differences in decision
times and confidence judgments can account for our findings. Particularly, the results nicely
fit predictions derived from connectionist models of decision making (Betsch, 2005; Thagard
& Millgram, 1995; Simon et al., 2004; Glöckner, 2006; Glöckner & Betsch, 2008). They are
33

<-----Page 35----->also in line with some evidence accumulation models (e.g., Busemeyer & Townsend, 1993;
Usher & McClelland, 2004).
Although Mouselab may not be an appropriate method for studying the limitations of the cognitive system, it has its undisputable merits as a tool for studying search processes in environments that only allow for serial and effortful acquisition of information. Such situations
can of course be found under natural conditions as well. For instance, consider a first-year law
student who checks legal cases by looking up relevant aspects piece by piece in the literature.
Customers who intend to buy a product without any prior knowledge about it will probably
behave in a similar way. For these situations, findings from Mouselab studies are likely to be
valid. However, generalizations about results based on this specific research paradigm should
be made with caution. Observations and case studies on decision making in natural setting
(e.g., Klein, 1999) indicate that experienced decision makers are capable of considering a
huge amount of information even under severe time constraints. For instance, experienced
chess players (e.g., Ferrari, Didierjean, & Marmeche, 2006) or experienced judges (Glöckner,
in press) base their decisions on complex constellations of information rather than selectively
focusing on single cues or reasons.
An important lesson to be learned from the multiple strategy approach is that properties of the
decision task influence decision-making processes (e.g., Beach & Mitchell, 1978; Payne et al.,
1992). Taking the present findings, it is important to differentiate decision tasks in which information is instantly available from those in which it is not. If information is not instantly
available, it has to be looked up in a serial manner. If task constraints obstruct the depth of
information search (e.g., time pressure) it is reasonable to assume that decision makers will
order their search by the importance of information and may apply simple, noncompensatory
strategies for choice (e.g., TTB/LEX, cf. Experiment 2; Payne et al., 1988). Similarly, in
situations in which expected gains from the information search are estimated to be lower than
its costs, only the most important information may be inspected (cf. Beach & Mitchell, 1978;
Newell & Shanks, 2003). In contrast, if the task enables relevant information to be accessed
immediately, as it was the case in our open Mouselab, individuals are likely to employ complex strategies for choice (e.g., WADDauto), even under time constraints.
As already mentioned before, in several other studies, strategy shifts to noncompensatory
strategies under time pressure were observed without relying on Mouselab procedure (for an
overview, see Edland & Svenson, 1993). Thus, we do not argue that all findings concerning
strategy shifts under time pressure can be explained by information search constraints induced
by Mouselab or other methods. However, according to our findings it should be acknowledged that humans’ total cognitive capacity for information integration is higher than usually
estimated.
To conclude, more research is needed that aims at exploring and disentangling the effects of
the research method and other context variables. From our point of view, it is important to be
aware of the limitations of a particular research method. Some methods (i.e., Mouselab; think34

<-----Page 36----->aloud protocols) appear unsuitable for identifying an important class of decision strategies,
namely, strategies that capitalize on automatic processing of information. Relying more
strongly on nonobtrusive methods of process tracing (e.g., eye tracking) and considering multiple correlates of internal processes (e.g., decision times, confidence judgments) might help
to improve our understanding of automatic processes in decision making.

35

<-----Page 37----->References
Ariely, D, & Zakay, D. (2001). A timely account of the role of duration in decision making.
Acta Psychological, 108, 187–207.
Bargh, J. A., & Chartrand, T. L. (1999). The unbearable automaticity of being. American Psychologist, 54, 462–479.
Bargh, J. A., & Williams, E. L. (2006). The automaticity of social life. Current Directions in
Psychological Research, 15, 2–4.
Beach, L. R., & Mitchell, T. R. (1978). A contingency model for the selection of decision
strategies. Academy of Management Review, 3, 439–449.
Beach, L. R., & Mitchell, T. R. (1996). Image theory, the unifying perspective. In L. R. Beach
(Ed.), Decision making in the workplace: A unified perspective (pp. 1–20). Mahwah,
NJ: Lawrence Erlbaum.
Beach, L. R., & Potter, R.E. (1992). The pre-choice screening of options. Acta Psychologica,
81, 115–126.
Bergert, F. B., & Nosofsky, R. M. (2007). A response-time approach to comparing generalized rational and take-the-best models of decision making. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 33, 107–129.
Betsch, T. (2005). Preference theory: An affect-based approach to recurrent decision making.
In T. Betsch & S. Haberstroh (Eds.), The routines of decision making (pp. 39–66).
Mahwah, NJ: Lawrence Erlbaum.
Betsch, T. (2007). The nature of intuition and its neglect in research on judgment and decision
making. In H. Plessner, C. Betsch & T. Betsch (Eds.), Intuition in judgment and decision making (pp. 3–22). Mahwah, NJ: Lawrence Erlbaum.
Bettman, J. R., Luce, M. F., & Payne, J. W. (1998). Constructive consumer choices. The
Journal of Consumer Research, 25, 187–217.
Billings, R. S., & Marcus, S. A. (1983). Measures of compensatory and noncompensatory
models of behaviour: Process tracing versus policy capturing. Organizational Behavior
and Human Performance, 31, 331–352.
Böckenholt, U., & Hynan, L. S. (1994). Caveats on a process-tracing measure and a remedy.
Journal of Behavioral Decision Making, 7, 103–117.
Broadbent, D. E. (1971). Decision and stress. London: Academic Press.

36

<-----Page 38----->Bröder, A. (2000a). Assessing the empirical validity of the “take-the-best” heuristic as a
model of human probabilistic inference. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 26, 1332–1346.
Bröder, A. (2000b). “Take The Best – Ignore The Rest”. Wann entscheiden Menschen begrenzt rational? [When do people make boundedly rational decisions?]. Lengerich,
Germany: Pabst Science Publishers.
Bröder, A. (2003). Decision making with the “Adaptive Toolbox”: Influence of environmental structure, intelligence, and working memory load. Journal of Experimental Psychology: Learning, Memory, and Cognition, 29, 611–625.
Bröder, A., & Schiffer, S. (2003a). Take the best versus simultaneous feature matching: Probabilistic inferences from memory and effects of representation format. Journal of Experimental Psychology: General, 132, 277–293.
Bröder, A., & Schiffer, S. (2003b). Bayesian strategy assessment in multi-attributive decision
making. Journal of Behavioral Decision Making, 16, 193–213.
Bröder, A., & Gaissmaier, W. (in press). Sequential processing of cues in memory-based
multi-attribute decisions. Psychonomic Bulletin and Review.
Busemeyer, J. R., & Townsend, J. T. (1993). Decision field theory: A dynamic cognitive approach to decision making in an uncertain environment. Psychological Review, 100,
432–459.
Cartwright, D. & Festinger, L. (1943). A quantitative theory of decision. Psychological Review, 50, 595–621.
Chaiken, S., & Trope, Y. (Eds.). (1999). Dual-process theories in social psychology. New
York: Guilford Press.
Christensen-Szalanski, J. J. (1978). Problem solving strategies: A selection mechanism, some
implications and some data. Organisational Behavior and Human Performance, 22,
307–323.
Czerlinski, J., Gigerenzer, G., & Goldstein, D. G. (1999). How good are simple heuristics? In
Simple heuristics that make us smart (pp. 97–118). New York: Oxford University Press.
Beilock, S. L., & DeCaro, M. S. (2007). From poor performance to success under stress:
Working memory, strategy selection, and mathematical problem solving under pressure.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 33, 983-998.
Doherty, M. E., & Kurz, E. M. (1996). Social judgement theory. Thinking and Reasoning, 2,
109–140.
37

<-----Page 39----->Dougherty, M. R. P., Gettys, C. F., & Ogden, E. E. (1999). MINERVA-DM: A memory process model for judgements of likelihood. Psychological Review, 106, 108–209.
Edland, A., & Svenson, O. (1993). Judgment and decision making under time pressure: Studies and findings. In O. Svenson & A. J. Maule (Eds.), Time pressure and stress in human judgment and decision making (pp. 27–40). New York: Plenum Press.
Epstein, S. (1990). Cognitive-experiential self-theory. In L. Pervin (Ed.), Handbook of personality: Theory and research (pp. 165–192). New York: Guilford.
Fazio, R. H. (1990). A practical guide to the use of response latency in social psychological
research. In C. Hendrick & M. S. Clark (Eds.), Research methods in personality and social psychology (pp. 74–97). Thousand Oaks, CA: Sage Publications.
Ferrari, V., Didierjean, A., & Marmeche, E. (2006). Dynamic perception in chess. The Quarterly Journal of Experimental Psychology, 59, 397–410.
Festinger, L. (1943). Studies in decision: I. Decision-time, relative frequency of judgment and
subjective confidence as related to physical stimulus difference. Journal of Experimental Psychology, 32, 291–306.
Fishburn, P. C. (1974). Lexicographic orders, utilities, and decision rules: A survey. Management Science, 20, 1442–1472.
Frederick, S. (2002). Automated choice heuristics. In D. Griffin, T. Gilovich & D. Kahneman
(Eds.), Heuristics and biases: The psychology of intuitive judgment (pp. 548–558). New
York: Cambridge University Press.
Garcia-Retamero, R., Hoffrage, U., & Dieckmann, A. (2007). When one cue is not enough:
Combining fast and frugal heuristics with compound cue processing. The Quarterly
Journal of Experimental Psychology, 60(9), 1197-1215.
Gigerenzer, G., Hoffrage, U., & Kleinbölting, H. (1991). Probabilistic mental models: A
Brunswikian theory of confidence. Psychological Review, 98, 506–528.
Gigerenzer, G., & Hoffrage, U. (1995). How to improve Bayesian reasoning without instruction: Frequency formats. Psychological Review, 102, 684–704.
Gigerenzer, G., & Goldstein, D. G. (1996). Reasoning the fast and frugal way: Models of
bounded rationality. Psychological Review, 103, 650–669.
Gigerenzer, G., Todd, P. M., & the ABC Group (1999). Simple heuristics that make us smart.
New York: Oxford University Press.

38

<-----Page 40----->Gigerenzer, G. (2004). Fast and frugal heuristics: The tools of bounded rationality. In D.
Koehler & N. Harvey (Eds.), Handbook of judgment and decision making (pp. 62–88).
Oxford, UK: Blackwell.
Glass, G. V., & Hopkins, K. D. (1996). Statistical methods in education and psychology.
Boston, MA: Allyn and Bacon.
Glimcher, P. W., Dorris, M. C., & Bayer, H. M. (2005). Physiological utility theory and the
neuroeconomics of choice. Games and Economic Behavior, 52, 213–256.
Glöckner, A. (2006). Automatische Prozesse bei Entscheidungen [Automatic processes in decision making]. Hamburg: Kovac.
Glöckner, A., & Hodges, S. D. (2006). Strategy selection in memory based decisions: Simplifying fast and frugal heuristics versus weighted compensatory strategies based on
automatic information integration. Manuscript submitted for publication.
Glöckner, A., & Betsch, T. (in press). Do people make decisions under risk based on ignorance? An empirical test of the priority heuristic against cumulative prospect theory.
Organizational Behavior and Human Decision Processes.
Glöckner, A. & Betsch, T. (2008). Modeling option and strategy choices with connectionist
networks: Towards an integrative model of automatic and deliberate decision making.
Judgment and Decision Making, 3(3), 215–228.
Glöckner, A. (2007). Does intuition beat fast and frugal heuristics? A systematic empirical
analysis. In H. Plessner, C. Betsch, and T. Betsch (Eds.), Intuition in judgment and decision making (pp. 309–325). Mahwah, NJ: Lawrence Erlbaum.
Glöckner, A. (in press). How evolution outwits bounded rationality: The efficient interaction
of automatic and deliberate processes in decision making and implications for institutions. In C. Engel and W. Singer (Eds.), Better than conscious. FIAS Workshop Report.
Cambridge, MA: MIT Press.
Greenwald, A. G., McGhee, D. E., & Schwartz, J. L. K. (1998). Measuring individual differences in implicit cognition: the implicit association test. Journal of Personality and Social Psychology, 74, 1464–1480.
Hammond, K. R., Hamm, R. M., Grassia, J., & Pearson, T. (1987). Direct comparison of the
relative efficiency on intuitive and analytical cognition. IEEE Transactions on Systems,
Man and Cybernetics, 17, 753–770.
Hasher, L., & Zacks, R. T. (1984). Automatic processing of fundamental information: The
case of frequency of occurrence. American Psychologist, 12, 1372–1388.

39

<-----Page 41----->Hintzman, D. L. (1988). Judgments of frequency and recognition memory in a multiple-trace
memory model. Psychological Review, 95, 528–551.
Hoffman, P. J. (1960). The paramorphic representation of clinical judgment. Psychological
Bulletin, 57, 116–131.
Hogarth, R. (2001). Educating intuition. Chicago: University of Chicago Press.
Holyoak, K. J., & Simon, D. (1999). Bidirectional reasoning in decision making by constraint
satisfaction. Journal of Experimental Psychology: General, 128, 3–31.
Johnson, E. J., Payne, J. W., Schkade, D. A., & Bettman, J. R. (1986). Monitoring information processing and decisions: The Mouselab system. Unpublished manuscript, Center
for Decision Studies, Fuqua School of Business, Duke University.
Juslin, P., Olsson, H., & Olsson, A.-C. (2003). Exemplar effects in categorization and multiple-cue judgment. Journal of Experimental Psychology: General, 132, 133–156.
Kahneman, D., Slovic, P., & Tversky, A. (Eds.) (1982). Judgement under uncertainty: Heuristics and biases. Cambridge, UK: Cambridge University Press.
Kahneman, D. & Frederick, S. (2002). Representativeness revisited: Attribute substitution in
intuitive judgment. In T. Gilovich, D. Griffin & D. Kahneman (Eds.), Heuristics and
biases: The psychology of intuitive judgment (pp. 49–81). New York: Cambridge University Press.
Klein, G. (1999). Applied decision making. In P. A. Hancock (Ed.), Human performance and
ergonomics (pp. 87-107). San Diego, CA: Academic Press.
Künzler, R., & Bakker, C. M. (2001). Female preferences for single and combined traits in
computer animated stickleback males. Behavioral Ecology, 12, 681–685.
Lee, M. D., & Cummins, T. D. R. (2004). Evidence accumulation in decision making: Unifying the “take the best” and the “rational” models. Psychonomic Bulletin & Review, 11,
343–352.
Lieberman, M. D. (2000). Intuition: A social cognition neuroscience approach. Psychological
Review, 126, 109–137.
Lohse, G. L., & Johnson, E. J. (1996). A comparison of two process tracing methods for
choice tasks. Organizational Behavior and Human Decision Processes, 68, 28–43.
Maule, A. J. (1994). A componential investigation of the relation between structural modelling and cognitive accounts of human judgement. Acta Psychologica, 87, 199-216.

40

<-----Page 42----->Montgomery, H., & Svenson, O. (1983). A think-aloud study of dominance structuring in decision making. In R. Tietz (Ed.), Aspiration levels in bargaining and economic decision
making (pp. 366–383). Berlin: Springer.
Newell, B. R., & Shanks, D. R. (2003). Take the best or look at the rest? Factors influencing
“One-Reason” decision making. Journal of Experimental Psychology: Learning, Memory, and Cognition, 29, 53–65.
Newell, B. R. (2005). Re-visions of rationality? Trends in Cognitive Science, 9, 11–15.
Nosofsky, R. M., & Bergert, F. B. (2007). Limitations of exemplar models of multi-attribute
probabilistic inference. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 33, 999-1019.
Olsson, A.-C., Enkvist, T., & Juslin, P. (2006). Go with the flow: How to master a nonlinear
multiple-cue judgment task. Journal of Experimental Psychology: Learning, Memory,
and Cognition, 32, 1371–1384.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1988). Adaptive strategy selection in decision
making. Journal of Experimental Psychology: Learning, Memory, & Cognition, 14,
534–552.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1992). Behavioral decision research: A constructive processing perspective. Annual Reviews of Psychology, 43, 87–131.
Rieskamp, J., & Hoffrage, U. (1999). When do people use simple heuristics and how can we
tell? In G. Gigerenzer, P. M. Todd & the ABC Research Group, Simple heuristics that
make us smart (pp. 141–167). New York: Oxford University Press.
Rieskamp, J., & Otto, P. E. (2006). SSL: A theory of how people learn to select strategies.
Journal of Experimental Psychology: General, 135, 207–236.
Russo, J. E., & Dosher, B. A. (1983). Strategies for multiattribute binary choices. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 9, 676–696.
Schneider, W., & Shiffrin, R. M. (1977). Controlled and automatic human information processing: I. Detection, search, and attention. Psychological Review, 84, 1–66.
Shiffrin, R. M., & Schneider, W. (1977). Controlled and automatic human information processing: II. Perceptual learning, automatic attending, and a general theory. Psychological
Review, 84, 127–190.
Simon, D., Snow, C. J., & Read, S .J. (2004). The redux of cognitive consistency theories:
Evidence judgments by constraint satisfaction. Journal of Personality and Social Psychology, 86, 814–837.
41

<-----Page 43----->Simon, H. A. (1955). A behavioral model of rational choice. The Quarterly Journal of Economics, 69, 99–118.
Sloman, S. A. (2002). Two systems of reasoning. In T. Gilovich, D. Griffin & D. Kahneman
(Eds.), Heuristics and biases: The psychology of intuitive judgment (pp. 379–396). New
York: Cambridge University Press.
Sundstroem, G.A. (1987). Information search and decision making: the effects of Information
display. Acta Psychologica, 65, 165–179.
Svenson, O. (1989). Eliciting and analysing verbal protocols in process studies of judgement
and decision making. In H. Montgomery & O. Svenson (Eds.), Process and structure in
human decision making (pp. 65–81). New York: Wiley.
Thagard, P. & Millgram, E. (1995). Inference to the best plan: A coherence theory of decision. In A. Ram & D. B. Leake (Eds.), Goal-driven learning (pp. 439–454). Cambridge,
MA: MIT Press.
Tversky, A. (1972). Elimination by aspect: A theory of choice. Psychological Review, 79,
281–299.
Usher, M., & McClelland, J. L. (2004). Loss aversion and inhibition in dynamical models of
multialternative choice. Psychological Review, 111, 757–769.
Wegner, D. (1994). Ironic processes of mental control. Psychological Review, 101, 34–52.
Zajonc, B. (1980). Feeling and thinking: Preferences need no inferences. American Psychologist, 35, 151–175.
Zakay, M. P. (1993). The impact of time perception processes on decision making under time
stress. In O. Svenson & A. J. Maule (Eds.), Time pressure and stress in human judgement and decision making (pp. 59–72). New York: Plenum Press.

42

<-----Page 44----->Appendix A: Instructions used in Experiment 1
Imagine that you are the head of a company that produces orange juice. You receive offers
from different orange vendors and have to decide which vendor to select. You have three testers A, B, and C, who check each vendor’s oranges for their quality. They give you information about each vendor: “+” means the vendor’s oranges are of good quality, “-” means the
vendor’s oranges are of poor quality. [pagebreak] You know from experience that the testers’
information varies in reliability: Tester A’s information is correct in 8 out of 10 cases, tester
B’s information is correct in 6 out of 10 cases, and tester C’s information is correct in 5 out of
10 cases. [pagebreak] In the experiment you will be repeatedly presented with offers from
three different vendors and information from the testers A, B, and C in the following format:
Orange Vendors
1

2

3

A

+

+

-

B

-

+

-

C

+

-

+

Your task is to select the vendor with the best-quality oranges. Please try to make good decisions and to proceed as quickly as possible. [pagebreak] Three keys are marked on the keyboard for use in selecting the vendors. Please lay three fingers of one hand on the three keys
to avoid unnecessary errors. Hit the left key to select vendor 1, hit the middle key to select
vendor 2, and hit the right key to select vendor 3.

<-----Page 45----->Appendix B: Additional Instructions used in Experiment 3

Explanations for the Information on Testers’ Reliability
The values for the reliability of the testers’ predictions range from 50 percent to 100 percent.
Fifty percent correct predictions mean that 5 of 10 of the tester’s predictions are wrong. Because there are only two possible predictions (good–bad), this equates to random probability.
This means that testers’ whose predictions are 50 percent correct can be ignored because they
provide no information about the quality of oranges. In contrast, the information of a tester
who makes 100 percent correct predictions is always correct. The testers in the study will
have different reliability values that are between 50 and 100 percent.

44

