<-----Page 0----->THE POTENTIAL OF
ACTUARIAL DECISION
MODELS: CAN THEY
IMPROVE THE VENTURE
CAPITAL INVESTMENT
DECISION?
ANDREW L. ZACHARAKIS
Babson College, Babson Park, Massachusetts

G. DALE MEYER
University of Colorado, Boulder, Colorado

Venture capitalists (VCs) are considered experts in identifying high-potential
new ventures—gazelles. VC-backed ventures survive at a much higher rate
than those ventures backed by other sources (Kunkel and Hofer 1991; Sandberg 1986; Timmons 1994). Thus, the VC decision process has received tremendous attention within the entrepreneurship literature. Nonetheless, VCbacked firms still fail at a surprisingly high rate (20%). Moreover, another
20% of the VC’s portfolio fails to provide any return to the VC. Therefore, there is room for improvement
in the VC investment process.
The three staged investment process often begins with venture screening. First, VCs screen the hundreds of proposals they receive to assess which deserve further consideration. Those ventures that survive
the initial stage are then subjected to extensive due diligence. Finally, the VC and entrepreneur negotiate
terms of the investment. Considering the amount of time that due diligence and negotiation of terms may
take, it is imperative that VCs minimize their efforts during screening so that only those ventures with
the most potential proceed to the next stage. Yet, at the same time, the screening process should also be
careful not to eliminate gazelles prematurely. VCs are in a quandary. How can they efficiently screen

EXECUTIVE
SUMMARY

Address correspondence to Andrew L. Zacharakis, Arthur M. Blank Center for Entrepreneurship, Babson College, Babson Park, MA 02457-0310, (781) 239-4497, E-mail: Zacharakis@Babson.edu
An earlier version of this paper was presented at the 1996 Academy of Management Meetings in Cincinnati. The authors would like to acknowledge the contributions of Roger Smith, Julio DeCastro, Charlene
Nicholls-Nixon, Reid Hastie, Gary McClelland, Dale Jasinski, Harry Sapienza, Anne Huff, Robert Keeley,
and Don Sexton for their advise and insight on this research project. This research was funded in part by
the Center for Entrepreneurial Leadership, Inc. and the Ewing Marion Kauffman Foundation. The contents
of this publication are solely the responsibility of the authors.
Journal of Business Venturing 15, 323–346
 2000 Elsevier Science Inc. All rights reserved.
655 Avenue of the Americas, New York, NY 10010

0883-9026/00/$–see front matter
PII S0883-9026(98)00016-0

<-----Page 1----->324

A.L. ZACHARAKIS AND G.D. MEYER

venture proposals without unduly rejecting high potential investments? The answer may be to use actuarial decision aides to assist in the screening process.
Actuarial decision aides are models that decompose a decision into component parts (or cues) and
recombine those cues to predict the potential outcome. For example, an actuarial model about the VC
decision might decompose a venture proposal into decisions about the entrepreneurial team, the product,
the market, etc. The sub-component decisions are than recombined to reach an overall assessment of
the venture’s potential. Such models have been developed in a number of decision domains (e.g., bank
lending, psychological evaluations, etc.) and been found to be very robust. Specifically, these models often
outperform the very experts that they are meant to mimic.
The current study had 53 practicing VCs participate in a policy capturing experiment. The participants examined 50 ventures and judged each venture’s success potential; would the venture ultimately
succeed or fail. Likewise, identical information about each venture was input into two different types
of actuarial models. One actuarial model—a bootstrap model—used information factors that VCs had
identified as being most important to making a good investment decision. The second actuarial model
was derived by Roure and Keeley (1990). The Roure and Keeley model best distinguished between success
and failure in a study of 36 high-technology ventures. The bootstrap model outperformed all but one
participating VC (he achieved the same accuracy rate as the bootstrap model). The Roure and Keely
model, although less successful than the bootstrap model, outperformed over half of the participating VCs.
The implications of this study are that properly developed actuarial models may be successful
screening decision aides. The success of the actuarial models may be attributed to their consistency across
different proposals and time. The models always weight the information cues the same. VCs, as are all
human decision makers, may often be biased by differing salient information cues that cause them to
misinterpret or ignore other important cues. For example, a VC may overlook product weaknesses if
(s)he is familiar with the entrepreneur putting forth a particular proposal. Although the current study
developed a generalized actuarial model, each VC firm could create screening models that fit it’s particular
decision criteria. The models could then be used by junior associates or lower level employees to perform
an initial screen of received venture proposals thereby freeing senior associates’ time.  2000 Elsevier
Science Inc.

INTRODUCTION
New venture survival is tenuous at best, but those backed by Venture Capitalists (VCs)
tend to achieve a higher survival rate than non-VC-backed businesses (Kunkel and
Hofer 1991; Sandberg 1986; Timmons 1994). Studies find that survival for VC-backed
ventures range from around 65% (Sahlman 1990) to 85% of the VC’s portfolio (Dorsey
1979). Of those startups that survive, 20% fail to provide an adequate return to the
VC (Ruhnka, Feldman, and Dean 1992). In effect, combining data from various failure
studies results in a failure rate (from the VC’s perspective) ranging from 35% to 55%.
Dean and Giglierano (1990) suggest that only 42% of VC-backed firms achieve an Return on Investment (ROI) of 15% which suggests a failure rate of nearly 60%. John
Hill, a prominent VC in Colorado, says that out of every 10 investments, a VC hopes
to hit one “home run” which often salvages the portfolio’s return (Hill 1993). Regardless
of what numbers the reader chooses to believe, the data indicate that the VC investment
decision has ample room for improvement. Thus, this paper asks the question of how
can VCs improve their “hit-rate” of successfully funded ventures thereby improving
their rate of return?
Using Social Judgment Theory (SJT) as a basis, this paper employs real time policy
capturing methods common in cognitive psychology to capture the VC’s actual decision
process, compare the VC’s decision process to that of an actuarial model (a decision aide

<-----Page 2----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

325

FIGURE 1 VC Decision.

which weights information factors in such a manner as to distinguish between expected
success and/or failure among new venture proposals) and determine the potential of
actuarial models to improve VC decision-making. The paper proceeds as follows: First,
the VC decision process is investigated. Second, the paper looks at how biases and heuristics hinder the decision. Third, the paper discusses the potential for actuarial models
to improve the decision by reviewing decision domains where such models have been
successful. This section builds a series of testable hypotheses. Finally, the paper discusses the results of the current study.

VENTURE CAPITALIST DECISION-MAKING
VC firms can be defined as “those organizations whose predominant mission is to finance the founding or early growth of new companies that do not yet have access to
the public securities market or to institutional lenders” (Gupta and Sapienza 1992:349;
Perez 1986; Pratt 1987). As such, Gupta and Sapienza (1992) suggest that VCs add
value by:
•

bringing investors and entrepreneurs together in an efficient manner,

•

making superior investment decisions than limited partners would make, and

•

providing non-financial assistance which in turn enhances survival.

All other things equal, a VC firm’s performance is a function of how well it makes
the investment decision and how effective its management advice and services are after
the investment decision has been made. In fact, Roure and Keeley (1990) assert that
success can be predicted from information contained in the business plan. Therefore,
improving the investment decision can improve the VC’s performance.
Decisions can be decomposed into three basic components, (1) consequences, (2)
alternatives/options, and (3) uncertainty of action (Behn and Vaupel 1982). The VC
investment decision and its basic components are diagrammed in Figure 1. The consequences associated with investment decisions boil down to ROI. If the VC invests in
a startup idea, ROI is a function of the new venture’s performance. Successful ventures
provide a high return, “living dead” (Ruhnka et al. 1992) and failed ventures result in
a loss of all or part of the investment. The basic alternatives or options that the VC
has in this decision are to invest or not invest. The invest alternative can be further
subdivided into an amount invested. For example, a VC can form a syndicate to spread
the risk. However, Figure 1 shows the invest decision without these subdivisions. Finally,

<-----Page 3----->326

A.L. ZACHARAKIS AND G.D. MEYER

the uncertainty of any investment translates into probabilities or likelihood of the possible outcomes which cannot be perfectly known a priori.
VCs attempt to assess the probability of success or failure by evaluating information
surrounding the particular venture. To receive funding, new ventures must past an initial
screening (typically a review of the business plan) followed by months of due diligence.
A number of researchers have examined what information is critical to the VC’s decision
(Table 1). A review of this literature suggests that there are four main categories on
which VCs base their decision. The four categories can be summarized as (1) entrepreneur/team capabilities, (2) product/service attractiveness, (3) market/competitive conditions, and (4) potential returns if venture is successful (Wells 1974; Poindexter 1976;
Tyebjee and Bruno 1984; MacMillan, Seigel, and Subba Narasimha 1985; MacMillan,
Zeman, and Subba Narasimha 1987; Robinson 1987; Timmons, Muzyka, Stevenson, and
Bygrave 1987).

IMPEDIMENTS TO OPTIMAL DECISION MAKING
It is well recognized in the decision-making literature that decision makers are not perfectly rational, but boundedly rational (Cyert and March 1963; Newell and Simon 1972;
Simon 1955). Biases and heuristics inhibit optimal decisions (e.g., Tversky and Khaneman 1974; Hogarth and Makridakis 1981). The availability bias, for example, may encourage decision makers to recall past successes rather than failures (Dawes 1988;
Dawes, Faust, and Meehl 1989). Therefore, a VC is apt to assess the success of a current
venture prospect by how similar the current prospect is to a past success. If the venture
under consideration uses the same technology, or has the same lead entrepreneur, such
available information may bias the VC to overlook other information that suggests the
current venture is likely to fail. Likewise, a VC utilizing a satisficing heuristic might
reject new venture proposals that fail to meet any one minimum requirement on the
VC’s list of decision factors, even if all other remaining factors are substantially higher
than the minimum requirements. As such, the VC may eliminate potentially profitable
investments from further consideration because of a heuristic rule (s)he is using to keep
the task manageable. However, considering the number of proposals that VCs review,
such time saving tradeoffs may be more cost effective in the long run.
Biases and heuristics are more prevalent in certain tasks than others (Shanteau
1992). Some aspects of the VC task make it more difficult and susceptible to sub-optimal
decision making. First, much of the information is constantly changing. The proverbial
“window of opportunity” is typically closing or opening, but always fast moving. Second,
feedback on the quality of the VC’s decision is slow in coming. It generally takes 7 years
to identify the portfolio winners, and 2 to 3 years to identify the losers (Timmons 1994).
Slow feedback makes it difficult for VCs to adjust their decision processes. Finally, VCs
rely on intuitive processes (Dominguez 1974; Khan 1987). As such, the use of decision
aids may be rare.
Biases, heuristics, and a number of difficult task characteristics result in sub-optimal
decisions. The decision effectiveness problem sums down to low intra-judge reliability
and low inter-judge reliability. VCs are apt to consider each prospective venture as
unique thereby recalling differing available information factors from memory resulting
in low intra-judge reliability. The salience of certain factors surrounding a decision may
unduly bias VCs by encouraging them to pay more attention to certain information fac-

<-----Page 4----->Entrepreneur/team characteristics
Mgmt skills and experience
Venture team
Mgmt stake in firm
Personal motivation
Entr personality
Product/service characteristics
Product attributes
Product differentiation
Proprietary
Growth potential
Mkt acceptance
Prototype
Market characteristics
Mkt size
Mkt growth
Barriers to entry
Competitive threat
Venture creates new mkt
Financial characteristics
Cash-out method
Expected ROR
Expected risk
Percentage of equity
Investor provisions
Size of investment
Liquidity
Other
References
Venture development stage
VC investment criteria
X

X

X

X

X

X
X

X

X

X
X
X

X
X
X
X

X

X

X
X

X

X

X

X
X

X

X
X

X

X

X

X
X

100

46 (Study 1)
41 (Study 2)

X

97

questionnaire

phone survey &
questionnaire

X

X

X

X

X
X

67

questionnaire

Tyebjee & Bruno MacMillan et al. MacMillan et al.
(1984)
(1984)
(1987)

X
X

X

X

X

X

8

questionnaire

personal
interviews

Method

Sample Size

Poindexter
(1976)

Wells (1974)

Study

TABLE 1 Information Factors used in VC Decision

X

X

X

X

X
X

53

questionnaire

Robinson
(1987)

X

X
X
X
X

X

X

X

47

unstructured
interviews

Timmons et al.
(1987)

X

X

X

X
X

16

verbal protocol

Hall & Hofer
(1993)

THE POTENTIAL OF ACTUARIAL DECISION MODELS

327

<-----Page 5----->328

A.L. ZACHARAKIS AND G.D. MEYER

tors than is warranted. Thus, VCs are likely to inconsistently apply their own decision
criteria, resulting in low intra-judge reliability.
Low inter-judge reliability can be attributed to differences between VCs, such as
experience, education, and other demographic factors. These differences influence the
VC’s perceptions of the prospective venture (Barr, Stimpert, and Huff 1992). JohnsonLaird notes:
We seem to perceive the world directly, not a representation of it. Yet this phenomenology is illusory: what we perceive depends on what is in our heads—on what evolution has “wired” into our nervous systems and what we know as a result of experience.
The limits of our models are the limits of our world (1989:470–471).

The fact that each individual perceives the world differently leads to different decisions.
Therefore, consistency between decision makers within the same domain may be affected; low inter-judge reliability. The problems with consistency raise the question of
whether more consistent decisions would improve the VC’s prediction of successful ventures? If so, how can decision consistency be improved?

ACTUARIAL MODELS
Elstein and Bordage state that “actuarial (statistical) models refer to the use of any
formal quantitative techniques or formulas, such as regression analysis, for . . . [deciding] clinical tasks” (1988:123). An actuarial model optimally combines decision cues
(relevant information) to derive an answer. Thus, actuarial models decompose decisions
into component parts. Just as an insurance actuary statistically derives the payoff risk
associated with different groups of people (i.e., age, gender, etc.), actuarial models can
assess the probability of certain outcomes based upon information available to the decision.
Actuarial models have received a lot of attention within cognitive psychology
(Dawes and Corrigan 1974; Dawes et al. 1989; Duda and Shortliffe 1983; Fischhoff 1988;
Goldberg 1968; Slovic 1972). Social Judgment Theory (Brunswik 1956) from cognitive
psychology provides a framework for understanding actuarial models. SJT’s underlying
assumption is that decision makers do not have access to “real” information, but instead
perceive that information through proximal cues (Strong 1992). These cues quantitatively describe the relationship between someone’s judgment and the information used
to make that judgment (Stewart 1988). As such, SJT also provides a theoretical reference to much of the past research on VC decision criteria (Wells 1974; Poindexter 1976;
Tyebjee and Bruno 1984; MacMillan, Seigel and Subba Narasimha 1985; MacMillan,
Zeman, and Subba Narasimha 1987; Robinson 1987; Timmons, Muzyka, Stevenson, and
Bygrave 1987; Sandberg, Schweiger and Hofer 1988; Hall and Hofer 1993). SJT illustrates how these criteria are decomposed and recombined to reach a decision. Hence,
SJT allows the capture of ‘theories in use’ as opposed to ‘espoused theories’ of action
(Hitt and Tyler 1991). Within SJT, human judgments are formally modeled via the
lens model.
The lens model (Brunswik 1956; Hammond 1977) illustrates the VC investment
decision (using the four major categories mentioned earlier) (Figure 2). The information
factors link the objective environment (left side of Figure 2) and the assessment of that
environment (right side of Figure 2). Specifically, the criterion variable (actual outcome)
is linked to the information factors by what decision the VC makes, typically invest or

<-----Page 6----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

329

FIGURE 2 VC Investment Decision.

not invest. Regardless of how optimal the VC’s decision, the information factors are
correlated to the ultimate decision. The judgment variable (expected venture outcome)
on the right side of the model represents the VC’s assessment of the venture’s potential.
For example, if the VC views the entrepreneur as a fatal flaw for a particular venture,
then the VC would likely expect the venture to fail and not invest in it. Again, the expected outcome is correlated to the information factors. In sum, the actual outcome
is linked to the expected outcome via a series of information cues.
Using the lens model framework, two types of actuarial models can be derived,
a bootstrap and an environmental model. Bootstrapping (Dawes and Corrigan 1974;
Fischhoff 1988; Slovic 1972) is a method of modeling the information cues that actual
judges use. In other words, experts are queried about what information is important
to the decision and then that information is used to build a model (this relationship is
represented on the right side of Figure 2). As contrasted with the bootstrap model, an
environmental actuarial model of the VC investment decision (see the left side of Figure
2) identifies how cues fit the environment. Discriminant or regression analysis (AbdelKhalik and EI-Sheshai 1980; Dawes, et al. 1989) identifies the optimal correlation between the available information factors (cues) and the ultimate venture outcome. Discriminant analysis basically determines which information factors from the environment
distinguish between success and failure.

Past Studies of Actuarial Models
Actuarial models have been developed in a number of decision domains and then compared to the intuitive or “clinical” decisions of experts within those domains. Goldberg
(1968) extended Meehl’s (1959) groundbreaking study on actuarial models. In Goldberg’s study, 29 psychologists judged patient psychosis by using information from the
Minnesota Multiphasic Personality Inventory (MMPI). Each psychologist had varying
experience with the MMPI. An actuarial model derived from the MMPI instrument

<-----Page 7----->330

A.L. ZACHARAKIS AND G.D. MEYER

predicted patient psychosis correctly about 70% of the time. The best psychologist, in
terms of correct diagnosis, achieved a 67% accuracy rating. The average for all the psychologists was 62%.
Actuarial models have also been tested within the domains of business decision
making (e.g. Wright 1979; Abdel-Khalik and El-Sheshai 1980; Lewis, Patton, and Green
1988). In Wright’s (1979) study, 47 MBA’s from Stanford predicted the percentage
change in security prices for 50 common stocks. Second year students achieved an accuracy of r ⫽ 0.31 vs. r ⫽ 0.20 for first year students. In addition, students evidenced low
inter-judge reliability. An environmental actuarial model, on the other hand, achieved
an accuracy rating of r ⫽ 0.59.
Abdel-Khalik and El-Sheshai (1980) tested the ability of commercial lenders to
predict loan defaults. Twenty-eight commercial lenders judged the likelihood of default
of 46 firms and achieved an accuracy rating of 62%. In comparison, an environmental
actuarial model was 90% accurate and a bootstrap model was 67% accurate. The authors contend that the primary difference in accuracy is a function of cue choice, because
the bootstrap model is not statistically different than the lenders. It is possible that the
non-statistical difference is a function of the strong theoretical base (i.e., ratios) that
lenders use in making loan decisions. In other words, once the lender has chosen which
ratios to use in making the loan decision, it is unlikely that the expert lender will misjudge such quantitative information factors.
In another development of the actuarial model process, Lewis et al. (1988) examined the ability of 47 municipal financial analysts to determine the change in municipal
bond ratings. Using 12 information factors derived from previous studies, the analysts
achieved an accuracy rating of approximately 45%. An environmental model achieved
60% accuracy, however bootstrap models did not statistically differ from the experts
in accuracy. Again, the fact that bootstrap models did not outperform experts may be
a function of the decision and the fact that quantifiable numbers and ratios are readily
available to the analyst. In decisions that use more subjective information, a bootstrap
model may perform better than the expert which it is modeling.

The potential of actuarial models for VC decision making
It is interesting to note that many of the prior studies into VC decision criteria that
rely on surveys and questionnaires essentially derive the criteria that the experts would
include in a bootstrap model (Wells 1974; Poindexter 1976; Tyebjee and Bruno 1984;
MacMillan, Seigel, and Subba Narasimha 1985; MacMillan, Zeman, and Subba Narasimha 1987; Robinson 1987; Timmons, Muzyka, Stevenson, and Bygrave 1987). In essence, the questionnaires and surveys yield the cues that experts believe are most important to the decision to accept or reject investing. In other words, a bootstrap model
reaches the same conclusion as an expert since it uses the same information as the expert.
However, past research finds that bootstrap models perform better than experts because
the models:
•

are consistent (experts are subject to random fluctuations);

•

are not biased by a non-random sample; and

•

optimally weigh information factors (Dawes et al. 1989; Fischhoff 1988; Slovic
and Lichtenstein 1971; Slovic 1972).

<-----Page 8----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

331

Given the forgoing reasoning, Hypothesis 1 suggests that a bootstrap actuarial
model (one based upon the information that VCs deem most important to the investment decision) outperforms the VCs themselves:
H1: A bootstrap actuarial model of the VC’s decision process better predicts actual
outcomes than the VC’s own intuitive decision process.

Past research also shows that environmental actuarial models perform better than
experts for the same reasons that bootstrap models outperform experts. Additionally,
environmental models use only predictive variables and disregard non-predictive ones
(Dawes et al. 1989). Unlike human experts, environmental actuarial models don’t develop distorted beliefs about variable relationships. Therefore, environmental actuarial
models should achieve the highest accuracy rate in selecting successful ventures.
Roure and Keeley (1990) developed an environmental actuarial model for venture
capital decision making. Examining business plans from 36 high tech enterprises, Roure
and Keeley identified four factors that best distinguished between venture success and
failure (team completeness, technical superiority of product, expected time for product
development, and buyer concentration) for the firms in their sample. The researchers
suggest that their model can be used to screen for successful ventures (Roure and Keeley
1990). Based upon the findings from other decision domains and Roure and Keeley’s
environmental model, Hypothesis 2 states:
H2: An environmental actuarial model of the decision process better predicts actual
outcomes than the VC’s intuitive prediction.

In a perfectly rational ideal world where the VC would use valid cues as determined
by accurate statistical analyses of the environment and where the VC weighed the cues
correctly, the correlations on the task (left) and cognitive (right) sides of the lens model
(see Figure 2) would be equivalent. However, the probability of this perfectly correlated
scenario is unrealistic. Instead, an environmental actuarial model using the task cue factors is more likely to predict the correct outcome than a bootstrap actuarial model using
cognitive cue factors. As such, an environmental model should better predict venture
outcome than a bootstrap model. Thus, Hypothesis 3 suggests:
H3: An environmental model of the decision process better predicts actual outcomes
than a bootstrap model.

Oskamp (1982) finds that experts have greater confidence in their decisions when
more information is available for analysis. In other words, VCs exposed to more information are apt to believe that they make better predictions than either of the two actuarial models or their peers who have less information with which to make the decision.
But, Oskamp argues that the expert’s increased confidence is unfounded. With more
information, the accuracy of their decision remains unchanged (Castellan 1977; Elstein
and Bordage 1988; Oskamp 1982) and may even decrease (Arkes 1981). Part of the
reason that VC accuracy is not greatly improved with more information is that experts,
despite their beliefs, use relatively few available cues (Brehmer and Brehmer 1988).
Therefore, VC’s tend to mistakenly believe that they are making a more informed decision with a greater amount of information even though they are likely ignoring the additional information or using it inappropriately. More information leads not to improved
decision accuracy, just increased confidence. Given the foregoing reasoning, Hypothesis
4a is derived:

<-----Page 9----->332

A.L. ZACHARAKIS AND G.D. MEYER

H4a: The VC’s intuitive prediction of success does not improve even if (s)he has
more decision factors to consider.

If, as Hypothesis 4a posits, more information does not lead to improved decision
accuracy, both the bootstrap and environmental actuarial models should still outperform those VCs who have access to more information.
H4b: A bootstrap model outperforms VC’s who have access to more decision
factors.
H4c: An environmental model outperforms VC’s who have access to more decision factors.

Actuarial models have proven to be robust. In a meta-analysis, only 6 of 117 studies
found that clinical or intuitive decision making equaled or outperformed actuarial models (Grove 1986). Therefore, it appears that actuarial models may be useful tools for
improving VC decision making.

METHOD
The main hypotheses propose that VC decisions are less accurate then those of bootstrap or environmental actuarial models. In this study, therefore, the VCs’ decisions
are compared to the predictions of the actuarial models on 25 actual ventures that have
subsequently achieved some outcome—either success or failure. The VCs receive several pieces of information about each potential investment. The actuarial models (regression equations) use the same information cues as the VCs. The exercise requests
that the participants evaluate the ventures as they would during the initial screening
stage of an actual decision and judge whether the venture will likely succeed or fail.
Thus, the VCs were asked to rate on a seven point Likert Scale, the potential of each
venture to succeed of fail. Coding of the VC response to success or failure was conducted
as follows: 5 to 7 (success probability is high), 4 (VC is unsure or doesn’t know), 1 to
3 (failure probability is high). The hit-rate—number of correct decisions as compared
to the actual outcome of the venture—is recorded for both the VCs and each actuarial
model. Additionally, VCs participated in one of three treatments that varied the amount
and type of information that they could use to make the decision. The hit-rate of VCs
is compared across treatments.

Decision Experiment
The experiment was administered on a notebook PC brought to the VC’s office; such
convenience likely increased participation. Policy capturing experiments enable control
and are conducive to quantitative statistical tests (i.e., Regression and ANOVA).

Sample
The sample for this experiment was 53 practicing VCs from two entrepreneurial “hotbeds,” (1) the Colorado Front Range (primarily the Denver/Boulder metro area) and
(2) the Silicon Valley in California. Two of the 53 participants were removed (one because the PC crashed during the exercise and the other because he did not wish to con-

<-----Page 10----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

333

TABLE 2 VC Demographics
VC Firm Level Demographics
Variable
Stage of
investment

Size of VC firm
Age of firm
Number of
associates
Industry
requirements
Geographic
focus
Average funding
per venture
Type of VC firm
Average number
of investors
per venture

Description

Range

Mean

Standard
Deviation

Percentage Seed
Start-up
Early growth
Expansion
Decline
Dollars under investment control (in millions)
Years since founding
FT equivalents actively involved in venture
funding decisions
Percentage of portfolio in high technology
versus low technology
State (1); regional (2); national (3)
international (4); none (5)
Dollar amount (in thousands)

0–100
0–100
0–60
0–60
0–40
1–2000
1–32
1–35

21.6
35.7
22.8
18.5
1.5
202.9
14.0
5.4

21.214
21.926
15.324
17.809
6.136
316.196
7.890
5.033

0–100

81.4

24.977

2.4

0.753

3304.6

7031.198

Independent/private, bank affiliated
corporation affiliated, non-affiliated SBIC
0, 1–3, 4–5, ⬎5

1–4
50–50,000

All Independent
0–⬎5

2.5

1.525

29–72

46.5

10.366

50 males
3 females
14–22

17.8

0.977

44
23
17
8
1–25
0–19

8.7
2.3

6.104
4.239

5–49

22.5

10.341

Individual VC Demographics
Age

Measured in years

Gender
Education level

Education type
(number of VCs
with degree in
field)
Tenure with firm
Other VC
experience
Other relevant
experience

Years of education with a high school
graduate ⫽ 12; 4 yr college degree ⫽ 16,
etc.; college, graduate, etc.
Business
Engineering
Liberal Arts
Science
Number of years with current firm
Years
Number of years working (including years
as VC)

tinue past the first few decisions). Table 2 further delineates the demographics of
the sample.

Procedure
The experiment follows a two step creation process; (1) identify information cues (decision variables) that are valuable to the investment decision and (2) create decision scenarios for the VC to judge. The number of scenarios and cues is interrelated (Stewart
1988). The more scenarios each participant completes, the higher the validity of the
captured judgment policy. Unfortunately, too many scenarios may tire the judge and

<-----Page 11----->334

A.L. ZACHARAKIS AND G.D. MEYER

limit participation. Stewart (1988) suggests that 35 scenarios is typically sufficient to
accurately capture the subject’s decision policy. Another rule of thumb is to have a minimum of five scenarios for every cue that is being tested (Stewart 1991).
A policy capturing exercise that uses all the identified information factors from
previous research would be untenable (see Table 1, approximately 25 cues in aggregate
form). To achieve an appropriate scenario-to-cue ratio, the VCs would have to evaluate
over 100 scenarios (5 cases/cue * 25 cues ⫽ 125). Evaluating 100 scenarios would increase the required time to complete the exercise, might reduce participation, or tire
each participant, thereby reducing the experiment’s validity. Additionally, such an increased time requirement might discourage VCs from participating in the exercise altogether. Furthermore, several of the identified cues are probably highly correlated with
each other. High multicolinearity adversely affects policy capturing experiments (Stewart 1988). Finally, most people, including experts, typically use only three to seven information cues (Stewart 1988), so a smaller set of cues is valid. For the above reasons, the
number of cues used in the exercise in a subset of all possible cues.
Before scenarios can be constructed, relevant information cues must be identified.
In order to use a manageable set of cues, cue frequency across studies and reported
importance within each study are used as a criterion for the inclusion of a particular
cue in the experiment. Additionally, cues that are highly correlated with other cues are
removed (Lewis, Patton, and Green 1988) retaining the cue that is deemed most important in the literature. A consulting expert VC also verified that the retained cue was
valid and important. Although the list is not exhaustive, it is more probable that the
identified cues in this study include unimportant factors rather than exclude important
factors. This outcome is due to the fact that experts typically identify far more cues than
they actually use (Stewart 1988).
Decision scenarios were created once the pertinent cues had been identified. Cooperative VCs outside the sample of the study (primarily VCs based in Chicago and the
East Coast) provided actual investment decision scenarios. A stipulation for using the
actual cases was that the entrepreneur, venture, and any associated firms or individuals
remain unidentified. Such a provision does not impede this study in any way. In fact,
identifying the venture or entrepreneur might bias the participant’s decisions. For example, personal knowledge of an entrepreneur’s reputation might lead the subjects to judge
that case without fully evaluating other supplied information. Products also are not identified, because many of the actual ventures included products identified with unique
firms. Moreover, identifying the product might also narrow the available sample size.
A VC may be hesitant to make a decision about a biotechnology firm if (s)he specializes
in computer disk storage. Although a proposed venture may not fit a particular VC
firm’s investment criteria, VCs within those firms often screen such ventures and, if they
have potential, refer them to an more suitable VC. For the same reasons, financial cues
are not included in this experiment. Different VCs use different hurdle rates. This experiment focuses on the screening stage, therefore, it is appropriate to minimize any preset
biases regarding unique firm investment criteria (i.e., industry, etc.).
Value ranges given to each cue allow it to be compared across scenarios (Stewart
1988). Concrete values are used (e.g., market size) for cue values when possible, but
purely representative distributions are appropriate for subjective cues (Stewart 1988).
A uniform coding system for subjective information factors allows consistent coding
across the business plans used in building the experiment. For instance, the subjective
information factors within the Cognitive Cue Treatments were rated on a five-point

<-----Page 12----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

335

TABLE 3 MANOVA Results between Actual and Generated Cases
Variable
Market familiarity
Leadership ability
Start-up record
Team completeness
Proprietary protection
Product superiority
Time to development
Market size
Market growth
Direct competitors
Competitor strength
Buyer’s concentration

Cochran’s C
p
p
p
p
p
p
p
p
p
p
p
p

⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽

0.173
0.813
0.154
0.854
0.945
0.817
0.762
0.123
0.813
0.369
0.274
0.499

Multivariate tests of significance

Pillais
0.731
Hotellings 0.731
Wilks
0.731

Multivariate tests of homogeneity

Box’s M
Wilks

Bartlett-Box F
p
p
p
p
p
p
p
p
p
p
p
p

⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽
⫽

0.182
0.817
0.152
0.857
0.946
0.821
0.774
0.142
0.817
0.382
0.287
0.509

0.367
0.353

scale. For example, the proprietary product cue value rated from 1 (lowest protection)
to 5 (highest protection). Likewise, competitor strength was also rated on a five-point
scale. Within the Task Cue Treatment, Roure and Keeley’s (1990) subjective rating scale
was used.
The lead researcher pulled information factors from the business plans of the actual
cases. Although there is a potential threat that the information included in the plan is
inaccurate (which would carry over into the experiment), Roure and Keeley (1990) find
that VCs rarely need to make “intense” corrections. Thus, it is reasonable to assume that
the business plans are accurate enough for this study. To insure inter-judge reliability, a
colleague unfamiliar with the business plans or their outcomes also coded all appropriate cues. The lead researcher provided the second coder with the entire list and description of the information factors of interest. Overall inter-judge reliability equates
to 87.5%. Berelson (1952) reports that inter-judge reliability typically ranges from 66%
to 95%. As such, the coding is deemed fairly reliable.
A technique to further decrease multicolinearity while maintaining strong external
validity is to combine actual and statistically derived cases. A random case generator
from Policy PC software package (Stewart 1991) creates a manageable number of statistically derived cases. MANOVA verifies that the statistical cases are from the same population as the actual cases (see Table 3). The IVs have equal variance between real and
generated cases and the multivariate means are equivalent. Furthermore, a consulting
expert VC identified those cases that were not feasible (i.e., combination of cue values
that rarely occurs in reality). Unfeasible scenarios were dropped from the sample of
potential candidates.
The final design allowed the VCs to use four to eight cues (depending upon the
treatment) and judge 50 cases. The independent variables are the decision cues available
within each treatment. The dependent variable is the VCs assessment of how likely the
venture is to succeed as measured on a seven point Likert Scale. The participants are
divided into three groups (see Table 4). Group one uses the information cues associated
with a base cognitive model as derived from the literature reviewed (see Table 4). The

<-----Page 13----->336

A.L. ZACHARAKIS AND G.D. MEYER

TABLE 4 Experiment Treatment Variables
Base Cognitive Cues
(Treatment 1)
1. Market familiarity—average
number of years of experience in market/industry for
team
2. Leadership ability—average
number of years of management experience for team
3. Proprietary protection—
level of protection provided
because product/service or
process to deliver product/
service is unique and
difficult to imitate

Additional Cognitive Cues
(Treatment 2)
Same five cues as base
cognitive cues treatment plus:
6. Relevant track record—
number of past start-up
experiences for team

Task Cues
(Treatment 3)
1. Completeness of team—
percentage of key positions
which were filled at the time
of the first major (over
$300,000) outside funding

7. Competitors—number of
direct competitors

2. Product superiority—how
product compares to existing
product

8. Competitor strength—fivepoint scale from high
strength (large relative
market share) to low
(numerous small market
share competitors)

3. Time to development—
number of months from
initiation of development to
the initial sale as forecast in
business plan

4. Market size—market
revenues for most current
year
5. Market growth—% over last
several years

4. Buyers concentration—
measures the number of
potential customers in the
target market during the first
two years of sales

cues are from studies (primarily Tyebjee and Bruno 1984; MacMillan et al. 1985, 1987;
Robinson 1987; Timmons et al. 1987) which rely on post hoc methods. Thus, these studies basically rely on introspection by the VC as to what are the most important decision
factors. Group two uses more cues than either the first or third groups to assess whether
more information changes the decision process (see Table 4). Specifically, group two
cues include the five used by group one VCs plus three more commonly cited from the
literature. Groups one and two use cues corresponding to the cognitive side of the lens
model (see Figure 2). Group three uses the information factors that best distinguish
between successful and failed new ventures; these cues correspond to the task side of
the lens model (see Figure 2). The group 3 treatment uses task cues derived by Roure
and Keeley (1990). The regression equation for each of the three possible treatments
is as follows:

Base Cognitive Cues Model
Y ⫽ a ⫹ b1 (mktfam) ⫹ b2 (lead) ⫹ b3 (proprietary) ⫹ b4 (mktsize)
⫹ b5 (mktgrw)

Additional Cognitive Cues Model
Y ⫽ a ⫹ b1 (mktfam) ⫹ b2 (lead) ⫹ b3 (proprietary) ⫹ b4 (mktsize)
⫹ b5 (mktgrw) ⫹ b6 (start-up) ⫹ b7 (competitor) ⫹ b8 (strength)

Task Cues Model
Y ⫽ a ⫹ b1 (complete) ⫹ b2 (product) ⫹ b3 (devtime) ⫹ b4 (buyer)
The VC decisions were compared to the predictions of two different actuarial mod-

<-----Page 14----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

337

TABLE 5 Percentages Correct Based on Actual Performance Data
Hit-Rate for
Bootstrap
Model
Mean
Std. Dev.
Range
n

60%

H1:
supported

60%

Treatment 1:
Treatment 2:
Treatment 3:
Hit-Rate for
Hit-Rate for
Hit-Rate for VCs
Hit-Rate for
Environmental
VCs using
using Bootstrap ⫹
VCs using
Model
Bootstrap Cues Additional Cues Environmental Cues
40%

H2:
mixed

40%

H3: not
⬍60%
supported not supported

40%

H4a:
supported
H4b:
supported
H4c:
supported

39.5%
0.1050
20 to 60%
n ⫽ 20

30.9%
0.0844
15 to 45%
n ⫽ 17

17.1%
0.0972
5 to 30%
n ⫽ 14

⬎39.5%
supported

⬎30.9%
supported

⬎17.1%
supported

⫽ 39.5%
not supported

⬎30.9%
supported

⬎17.1%
supported

39.5%

⬎30.9%
supported
⬎30.9%
supported

60%
40%

30.9%
supported

els. The bootstrap actuarial model used the eight decision cues that VCs in the Additional Cognitive Cues Treatment used. The bootstrap actuarial model equally weighted
the eight cues. The environmental actuarial model used the four cues and respective
weights identified by Roure and Keeley (1990).
The appendix provides a visual representation of a sample case within each treatment that the VCs examined. Note that each information factor is labeled. There is a
numeric representation of the cue value as well as a visual bar chart of how that cue
in the presented scenario relates to its respective cue in all the other scenarios.

RESULTS
Before launching into the results related to the hypotheses, we note that VCs within
the three treatments achieved different accuracy rates (see Table 5). The next section
discusses these results further as they relate to each of the hypotheses.
Hypothesis 1, which posits that an equal weighted bootstrap actuarial model (one
that uses the same cues that VCs believe to be important) better predicts actual outcome
than the VC, receives support. The standardized bootstrap equal weighted actuarial
model1 is as follows:
zY ⫽ (mktfam) ⫹ (lead) ⫹ (proprietary) ⫹ (mktsize) ⫹ (mktgrw) ⫹ (start-up)
⫺ (competitor) ⫺ (strength)
where:
zY ⫽ standardized prediction of success
other variables are standardized cue values for each scenario.
1

The model is equal weighted, therefore, there is no associated beta weights with each cue.

<-----Page 15----->338

A.L. ZACHARAKIS AND G.D. MEYER

The bootstrap actuarial model achieved a hit-rate of 60% whereas VCs hit-rates
were significantly lower (39.5% in the bootstrap cues treatment, 30.9% in the additional
cues treatment, and 17.1% in the environmental cues treatment [see Table 5]). One of
the 20 VCs in the bootstrap cues treatment achieved a hit-rate of 60% which suggests
that (s)he performed as well as the bootstrap actuarial model. None of the VCs in either
the additional cues treatment (n ⫽ 17) or environmental cues treatment (n ⫽ 14)
matched the success of the bootstrap actuarial model. Thus, Hypothesis 1 is supported;
a bootstrap model better predicts outcome than the expert VC.
Hypothesis 2, which posits that an environmental actuarial model will outperform
expert VCs, receives mixed support. The current study uses Roure and Keeley’s (1990)
environmental actuarial model as follows:
IRR ⫽ ⫺486.27 ⫹ 2.91(complete) ⫹ 24.63(product) ⫹ 183.96(buyer)
⫺32.30 (buyer)2 ⫹ 15.88 (devtime) ⫺ 0.78 (devtime)
where:
IRR
complete
product
devtime
buyer

⫽
⫽
⫽
⫽
⫽

Internal Rate of Return expected from investment
degree of team completeness
product’s superiority over existing offerings
months from funding until product is ready to go
number of potential customers for the product.

Roure and Keeley’s model achieved a hit-rate of 40% (see Table 5) which is approximately equal to those VCs in the bootstrap cues scenario (39.5%). However, the environmental actuarial model beat the mean hit-rate of those VCs in the additional cues
scenario (30.9%) and those in the environmental cues scenario (17.1% [see Table 5]).
Thus, Hypothesis 2 receives mixed support.
Hypothesis 3, which suggests that an environmental model will outperform a bootstrap model, does not receive support. The Roure and Keeley (1990) environmental
model achieved a hit-rate of 40%, whereas the equal weighted bootstrap model
achieved a hit-rate of 60%.
Hypothesis 4a, which asserts that VC prediction success does not improve with additional information, receives support. Decision accuracy decreased the more information that the VC had available to make the decision—from 39.5% in the bootstrap cues
treatment to 30.9% in the additional cues treatment (see Table 5). Additionally, VCs
who had more information were more likely to reject a proposal (44% rejections to
40.5% in bootstrap cues treatment) or be unsure (i.e., select “don’t know”—19.3% to
16.5% in bootstrap cues treatment). As such, VCs in the additional cues treatment selected 36.7% of the cases as likely successes, whereas VCs in the bootstrap cues treatment selected 43% as likely successes.
Hypothesis 4b, which suggests that the bootstrap model will outperform even those
VCs with additional information, receives support. The equal weighted bootstrap model
achieved a hit-rate of 60% whereas VCs in the additional information scenario achieved
a mean rate of 30.9% (see Table 5). Moreover, no VCs in the additional cues treatment
(n ⫽ 17) matched or beat the bootstrap model. The best VCs in this treatment achieved
a 45% correct classification rate.
Hypothesis 4c, which posits that an environmental actuarial model will outperform
VCs with additional information, also receives support. The Roure and Keeley (1990)

<-----Page 16----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

339

environmental actuarial model achieved a hit-rate of 40% whereas the VCs within the
additional cues treatment achieved a hit-rate of 30.9% (see Table 5). However, in this
case, 4 out of 17 VCs equaled the environmental model and 1 of 17 beat (45% correct)
the environmental model.
The results of the hypotheses support most of the relationships proposed in
this study.

DISCUSSION
In general, the results indicate that more information appears to hinder the VC’s decision process, even though most people prefer more information when making complex
decisions. This study also demonstrates that VC decision making can be improved
through the aid of actuarial models, especially in information laden environments. Even
though this experiment used a generic bootstrap and environmental actuarial models,
these aids had significantly higher hit rates than the participating VCs across all treatments. Although the expert VC’s intuition is valuable, it often is biased resulting in suboptimal decisions, especially when more information surrounds the decision. Furthermore, the results imply that as more information is available to the decision, the VCs’
predictive accuracy substantially decreases. Even though the experiment dramatically
reduces the information surrounding an actual situation, an increase in the available
information (from five to eight information factors) results in a decrease in prediction
accuracy of almost 9% (from 39.5% correct to 30.9% correct). The decreased decision
efficiency has several potential explanations, including cognitive overload and “story”
incoherence (Pennington and Hastie 1986). As more information becomes available,
it is more difficult for the decision maker to interpret each piece of information, let alone
how that information impacts other factors. Thus, it is cognitively harder to create a story
or scenario where the venture will succeed. Story incoherence usually results in a negative
interpretation of a situation (Pennington and Hastie 1986). Therefore, identifying the most
important criteria, and removing the noise caused by all the other information surrounding the decision may improve the decision process. Actuarial models remove VC
biases by ignoring salient information surrounding a particular venture decision. Thus,
VCs become more consistent in their decision making (improved intra-judge reliability).
Additionally, if VCs within the same organization use the same actuarial model, consistency across VCs within the firm also increases (improved inter-judge reliability).
More information also appears to affect whether VCs judge a venture as potentially
successful or not. It seems that VCs with more information are less likely to view a venture as potentially successful (37% vs. 43% within the base treatment). Such a failure
bias may suggest that VCs are employing a “satisficing” heuristic in their decision making (Simon 1955) where the plan must meet a minimum level on each criteria or be
rejected. With additional information, there is an increased likelihood that a venture
will fail on one information factor and be eliminated from further consideration. Poor
standing on one criteria may become salient and bias the VC. The critical question is
whether weakness on one criteria negates an otherwise sound investment? The answer
is likely dependent upon the relative importance of that criteria. Actuarial models can
eliminate the noise by isolating those factors that are most central to the decision. Thus,
actuarial models may potentially improve the VC’s successful “hit-rate”.
If actuarial models can improve decision consistency, the implications for practicing
VCs are obvious. Such models may improve the hit-rate of successful ventures, thereby

<-----Page 17----->340

A.L. ZACHARAKIS AND G.D. MEYER

improving the VC’s return. These decision aids appear under used in this industry, however VCs are particularly well suited to develop such aids. In follow-up interviews, it
was found that only 24% of the participating VCs use some sort of factor checklist (a
document or tool where the VC identifies how each venture proposal measures up to
key criteria). Checklists provide a basis for VCs within the firm to evaluate the lead
VCs analysis and by extension, examine whether the VC is biased by certain salient
factors. Over time as certain funded ventures succeed and others fail, checklists allow
VCs to assess the validity of their decision criteria and make corrections. In fact, several
of those VCs that use a checklist did so after they made an investment decision. In other
words, the VC made the decision on an intuitive basis and then after the firm was funded,
the VC went back and completed the checklist. Such a history of investment decisions
allows VCs to learn what works and what doesn’t. However, if the VC never formalizes
the decision process, it is much more difficult to discern the critical factors, especially
considering post hoc recall and rationalization biases.
Second, VCs face a plethora of information when making an investment decision
(i.e., business plan, outside consultants, due diligence, etc.). It may be difficult for VCs
to truly understand their intuitive decision because of all the noise caused by this information overload. This lack of systematic understanding impedes learning. VCs cannot
make accurate adjustments to their evaluation process if they do not truly understand
it. Therefore, VCs may suffer from a systematic bias that impedes the performance of
their investment portfolio. The method used in this experiment can be modified and
used as a training tool to assist active VCs in understanding their intuitive process.
The basic conclusion of this paper is that actuarial models can improve VC decision
making and by extension, VC returns. Improving the return enhances the VC’s ability to
solicit investors into his/her next investment portfolio. Developing a successful actuarial
model may provide VC’s with a competitive advantage. However, actuarial models
aren’t panaceas.
The use of actuarial models, as with any information processing device (i.e., computer), can be hazardous. The old saying “garbage in, garbage out” applies to actuarial
models as well. Therefore, VCs must assess the quality of the information going into the
model. For example, if the VC believes that start-up experience is a crucial component of
the model, (s)he would be well advised to assess the quality of those start-up experiences.
Were the prior start-ups successful? If not, what were the problems? If not, was it still
a valuable learning experience? Why did the entrepreneur leave the successful start-up?,
etc. On the basis of such questions, the VC can assess the quantitative value of start-up
experience and determine the best way to input it into the actuarial model.
Although VCs should be wary of the information input into the model, there is
a very real danger that VCs will over analyze such information and possibly invalidate
the results. In a classic study, Goldberg (1968) finds that experts (clinical psychologists
judging psychosis) who use actuarial models as one more input into the decision process
often override the model’s conclusion. They identify “broken legs” or exceptions
(Meehl 1954) that invalidate the model’s conclusion, or so they believe. However, Goldberg finds that the model achieves higher accuracy in isolation than those experts who
use the model as one more source of analysis. Therefore, VCs should exercise caution
interpreting the model’s prediction, as well as modifying data going into the model.
Although actuarial models have been shown to improve expert decision making,
the models have not been widely adopted by experts. There is an underlying distrust
of “machine” that inhibits adoption of such techniques across a wider array of fields

<-----Page 18----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

341

(Holt 1986). A common explanation of this reluctance is that actuarial models remove
responsibility for the decision (Hastie 1994). Although a model might be able to predict
psychosis, does the psychologist want to take responsibility if the model is wrong? Or
would the psychologist feel better if (s)he made that final decision even if there is potential for more mistakes? In today’s litigious society, one has to wonder if malpractice
insurance would cover the misdiagnosis of an actuarial model. Such questions pose an
interesting quandary that may explain the low usage of such models and the tendency
to identify “broken legs” or exceptions that invalidate the model.
Recognizing the reluctance to use such models, it seems that the most appropriate
place within the VC decision process would be at the initial plan screening process. The
actuarial model quickly focuses attention on the critical issues thereby saving the VCs
time and reducing the possibility that “high potential” plans are prematurely discarded
and that “low potential” plans are needlessly passed on to the next level of analysis.
Such use of the actuarial model also does not remove the VC’s control or responsibility
over the decision. The VC can still look for exceptions if (s)he disagrees with the model,
but the VC should be cognizant of Goldberg’s (1968) findings.

INTERPRETING RESULTS OF POLICY
CAPTURING EXPERIMENTS
Although policy capturing allows real time, unbiased capture of VC decisions, it does
have some short-falls. As with any experiment, the issue of reductionism must be considered. The subjects are exposed to a decision situation which does not perfectly mirror the
“real-life” decision. Such “paper tests” affect the external validity of many lens model
experiments (Brehmer and Brehmer 1988; Strong 1992). Nevertheless, policy capturing
experiments are a valid method for deriving what information decision makers actually
use (Stewart 1993). Although such “paper” experiments have been criticized, Brown
(1972) finds that under even the most contrived cases, the decisions reflect actual decisions. Moreover, since the VC decision has a large “paper” component in the real world
(i.e., much of the VC’s information comes from business plans), correlation between
the experimental task and the “real world” decision should be even higher.
The 40% hit-rate for the environmental actuarial model causes concern. Ideally,
an environmental cue set is the optimal set of factors for distinguishing between successes and failures. Unfortunately, the Roure and Keeley (1990) model is not optimal
for the cases within this experiment. Therefore, it appears that there may not be a universal set of predictor variables, or that the case set used to derive Roure and Keeley’s
(n ⫽ 36), is not large enough to derive a universal environmental model2. In all likelihood, there is not a universal model, but it is likely that each individual firm can benefit
by developing a model that is suited to its investment criteria.
It was surprising that the VCs in the environmental cue treatment performed so
poorly. An obvious explanation may be that the predictor cues are not the optimal predictors. A second explanation may be the nature of the cues. To an even greater extent
than cues in the other treatments, the environmental cues are very condensed and quantitative. For example, instead of describing entrepreneur and team qualifications, the
environmental cue of team completeness provides the percentage of filled key positions
2
The actual cases used in both the Roure and Keeley (1990) and the current study consist primarily
of high tech firms (i.e., biotechnology, semiconductors, computers, peripherals, etc.).

<-----Page 19----->342

A.L. ZACHARAKIS AND G.D. MEYER

at the time of funding. Although such a cue is undoubtedly correlated with team quality
and ability, VCs view the cues as intuitively unappealing; the cues are condensing too
many key elements. Likewise, buyer concentration seems to be a poor intuitive proxy
for market potential. As such, VCs may be unsure of how to interpret these cues which,
in turn, makes them more likely to predict venture failure than VCs in the other treatments (56 vs. 44% for VCs in additional cues treatment and 41% for VCs in bootstrap
cues treatment).
Another limitation is a history effect on the cases used in the study. It typically
takes 5 to 7 years for a VC to realize a return on a new venture investment (Timmons
1994). During that time, many things can change which ultimately influence the venture’s success. Some examples include new team members, a revised product/service,
changing technology, and shift in market demand. Steier and Greenwood’s (1995) indepth case study of one new venture funded by a network of VCs suggests that the firm’s
ultimate demise was a function of poor coordination and a lack of timely follow-up funding by the VCs, not any inherent weakness in the business concept. Although one may
question Steier and Greenwood’s conclusion, the point is that anyone of these changes
can either positively or negatively affect the venture’s success. Therefore, VCs in the
experiment (as well as in reality), are making decisions about a venture that may be
substantially different in a short matter of time. Moreover, it is unclear what leads to
the ultimate success/failure of the included cases. When asked, VCs providing the cases
were vague. Typically, they asserted the success/failure to a good/bad decision, strong/
weak management, good/poor understanding of the marketplace, etc. Thus, it would
not appear that any large history effects are occurring. However, it is probable that a
certain degree of history did help or hinder the firms used as cases. Such an effect not
only hinders the VC’s decision, but also the prediction ability of an actuarial model.
Nevertheless, Roure and Keeley (1990) assert that initial actions and strategies have
the largest impact on ultimate outcome. As such, the plans used as cases in this study
are valid. These strategies are likely contained in the business plan, therefore, the business plan is a valid tool to make the decision.
The experiment also forces VCs to make decisions based upon the presented cues.
In reality, VCs would (1) have access to a multitude of possible information cues and
(2) use interactive due diligence and other methods to clarify and assess reliability of
chosen cues. A common theme in the follow up interviews is that VCs prefer to reserve
final judgment until they have a chance to meet with the lead entrepreneur. VCs want
a chance to “see if they can work with the guy.” In essence, meeting with the entrepreneur adds more data points. If, however, meeting with the entrepreneur and other interactive processes add more information, it is not necessarily going to improve the decision
(Oskamp 1982). Such meetings might add to the information overload that affects information use and leads to sub-optimal decisions as illustrated in the experiment. Moreover, meeting the entrepreneur adds a number of new biases that might impede the
overall decision, such as “first impression” biases (Borman 1991) or “personal appearance” biases (Borman 1991). However, if interaction improves the reliability of the cues,
then it should improve the decision.

FUTURE RESEARCH
There are a number of possible extensions to the current study. In follow-up interviews,
the participating VCs suggested that their decision style was much less formal than their

<-----Page 20----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

343

East Coast peers. An interesting question is whether there is a difference and does it
lead to different decisions? Another question is how do VCs compare to Angels and
other new venture investors? New samples might address these questions.
Although the current study finds that actuarial models outperform experts, the accuracy of the model is substandard (60% correct). It appears that actuarial models need
to be geared towards a firm’s specific criteria (i.e., stage, industry, etc.). Thus, a longitudinal relationship with a few VCs could lead to firm specific bootstrap actuarial models
based upon the needs and beliefs of the VCs within that firm. After several iterations,
it would be interesting to see if the model agrees with the assessment of the VC evaluating the various plans that the firm receives. Over a number of years, a quality bootstrap
model would ideally be developed and incorporated into the firm’s decision process.
At that point in time, it would be interesting to see how the VCs use the tool: Do they
frequently override its prediction? How much is the information input into the model
modified? and a number of other questions surrounding its use. In sum, actuarial models
have the potential of increasing the efficiency of the VC investment market, and it is
hoped that this study will spur efforts to create such decision aids.

REFERENCES
Abdel-Khalik, A.R., and El-Sheshai, K.M. 1980. Information choice and utilization in an experiment on default prediction. Journal of Accounting Research 18(2):325–342.
Arkes, H.R. 1981. Impediments to accurate clinical judgment and possible ways to minimize their
impact. Journal of Consulting and Clinical Psychology 49:323–330.
Barr, P.S., Stimpert, J.L., and Huff, A.S. 1992. Cognitive change, strategic action, and organizational renewal. Strategic Management Journal 13:15–36.
Behn, R.D., and Vaupel, J.W. 1982. The basic decision dilemma: The angina/bypass surgery decision. In Quick Analysis For Busy Decision Makers. New York: Basic Books.
Berelson, B. 1952. Content analysis in communications research. Glencoe, IL: Free Press.
Borman, W. 1991. Job behavior, performance and effectiveness. In M. Dunnette and L. Hough,
eds., Handbook of Industrial and Organizational Psychology. Palo Alto: Consulting Psychologist Press.
Brehmer, A., and Brehmer, B. 1988. What have we learned about human judgment from thirty
years of policy capturing. In B. Brehmer and C. Joyce, eds., Human Judgment: The SJT
View. North Holland: Elsevier.
Brown, T.R. 1972. A comparison of judgmental policy equations obtained from human judges
under natural and contrived conditions. Mathematics Bioscience 15:205–230.
Brunswik, E. 1956. Perception and the representative design of experiments. Berkeley: University
of California Press.
Castellan, N.J. 1977. Decision making with multiple probabilistic cues. In N. Castellan, J. Pisoni,
and M. Potts, eds., Cognitive Theory, Volume 2. Hillsdale, NJ: Erlbaum.
Cyert, R.M., and March, J.G. 1963. A behavioral theory of the firm. Engelwood Cliffs: Prentice Hall.
Dawes, R.M. 1988. Rational choice in an uncertain world. Fort Worth: Harcourt Brace Jovanovich.
Dawes, R.M., Faust, D., and Meehl, P.E. 1989. Clinical versus actuarial judgment. Science
243:1668–1674.
Dawes, R.M., and Corrigan, B. 1974. Linear models in decision making. Psychological Bulletin 81(2):95–106.
Dean, B.V., and Giglierano, J.J. 1990. Multistage financing of technical start-up companies in
Silicon Valley. Journal of Business Venturing 5:375–389.

<-----Page 21----->344

A.L. ZACHARAKIS AND G.D. MEYER

Dominguez, J.R. 1974. Venture capital. Lexington, MA: Lexington.
Dorsey, T. 1979. Operating guidelines for effective venture capital funds management. Austin: University of Texas.
Duda, R.O., and Shortliffe, E.H. 1983. Expert systems research. Science 220:261–268.
Elstein, A.S., and Bordage, G. 1988. Psychology of clinic reasoning. In J. Dowie and A.S. Elstein,
eds., Professional Judgment: a reader in clinical decision making. Cambridge: Cambridge
University Press.
Fischhoff, B. 1988. Judgment and decision making. In R. Sternberg and E. Smith, eds., The Psychology of Human Thought. Cambridge: Cambridge University Press.
Goldberg, L.R. 1968. Simple models or simple processes? Some research on clinical judgments.
American Psychologist 23(7):483–496.
Grove, W.M. 1986. Presentation at Annual Meeting of Psychological Association, Minneapolis.
Gupta, A.K., and Sapienza, H.J. 1992. Determinants of venture capital firms’ preferences regarding the industry diversity and geographic scope of their investments. Journal of Business
Venturing 7:347–362.
Hall, J., and Hofer, C.W. 1993. Venture capitalists’ decision criteria and new venture evaluation.
Journal of Business Venturing 8(1):25–42.
Hammond, K.R. 1977. Social judgment theory: Application in policy formation. In M. Kaplan
and S. Schwartz, eds., Human Judgments and Decision Processes in Applied Settings. New
York: Academic Press.
Hastie, R. 1994. Seminar at University of Colorado, Boulder.
Hill, J. 1993. Presentation at the University of Colorado, Boulder, Colorado.
Hitt, M.A., and Tyler, B.B. 1991. Strategic decision models: Integrating different perspectives.
Strategic Management Journal 12:327–351.
Hogarth, R.M., Makridakis, S. 1981. Forecasting and planning: An evolution. Management Science 27(2):115–138.
Holt, R.R. 1986. Clinical and statistical prediction: A retrospective and would-be integrative perspective. Journal of Personality Assessment 50(3):376–386.
Johnson-Laird, P.N. 1989. Mental models. In M. Posner, ed., Foundations of Cognitive Science.
Cambridge, MA: The MIT Press.
Khan, A.M. 1987. Assessing venture capital investments with non compensatory behavioral decision models. Journal of Business Venturing 2:193–205.
Kunkel, S.W., and Hofer, C.W. 1991. Why study the determinants of new venture performance:
A literature review and rationale. Presentation at Academy of Management meetings, Miami, FL.
Lewis, B.L., Patton, J.M., Green, S.L. 1988. The effects of information choice and information
use on analysts; predictions of municipal bond rating changes. The Accounting Review
63(2):270–282.
MacMillan, I.C., Zeman, L., and Subba Narasimha, P.N. 1987. Criteria distinguishing unsuccessful
ventures in the venture screening process. Journal of Business Venturing 2:123–137.
MacMillan, I.C., Seigel, R., and Subba Narasimha, P.N. 1985. Criteria used by venture capitalist
to evaluate new venture proposals. Journal of Business Venturing 1:119–128.
Meehl, P. 1959. A comparison of clinicians with five statistical methods of identifying psychotic
MMPI profiles. Journal of Counseling Psychology 6:102–109.
Meehl, P. 1954. Clinical versus statistical predictions: A theoretical analysis and review of the evidence. Minneapolis: University of Minnesota Press.
Newell, A., and Simon, H.A. 1972. Human problem solving. Engelwood Cliffs, NJ: Prentice-Hall.
Oskamp, S. 1982. Overconfidence in case-study judgments. In D. Khaneman, P. Slovic and A.
Tversky, eds., Judgment Under Uncertainty: Heuristics and Biases. Cambridge: Cambridge
University Press.
Pennington, N., and Hastie, R. 1986. Evidence evaluation in complex decision making. Journal
of Personality and Social Psychology 51(2):242–258.

<-----Page 22----->THE POTENTIAL OF ACTUARIAL DECISION MODELS

345

Perez, R.C. 1986. Inside venture capital: Past. present and future. New York: Praeger.
Poindexter, E.A. 1976. The efficiency of financial markets: The venture capital case. Unpublished
doctoral dissertation: New York University, New York.
Pratt, S.E. 1987. Overview and introduction to the venture capital industry. In S. Pratt and J.
Morris, eds., Pratt’s Guide to Venture Capital Sources, 11th edition. Wellesley, MA: Venture Economics.
Robinson, R.B. 1987. Emerging strategies in the venture capital industry. Journal of Business
Venturing 2:53–77.
Roure, J.B., and Keeley, R.H. 1990. Predictors of success in new technology based ventures. Journal of Business Venturing 5:201–220.
Ruhnka, J.C., Feldman, H.D., and Dean, T.J. 1992. The “living dead” phenomena in venture
capital investments. Journal of Business Venturing 7(2):137–155.
Sahlman, W.A. 1990. Structure of venture capital organizations. Journal of Financial Economics 27:483.
Sandberg, W.R. 1986. New venture performance. Lexington, MA: Lexington.
Sandberg, W.R., Schweiger, D.M., and Hofer, C.W. 1988. The use of verbal protocols in determining venture capitalists’ decision processes. Entrepreneurship Theory and Practice (Winter): 8–20.
Shanteau, J. 1992. Competence in experts: The role of task characteristics. Organizational Behavior and Human Decision Processes 53:252–266.
Simon, H.A. 1955. A behavioral model of rational choice. Quarterly Journal of Economics
69:99–118.
Slovic, P. 1972. Psychological study of human judgment: Implications for investment decision
making. Journal of Finance 27(4):779–799.
Slovic, P., and Lichtenstein, S. 1971. Comparison of bayesian and regression approaches to the
study of information processing judgment. Organizational Behavior and Human Performance 6:649–744.
Steier, L., and Greenwood, R. 1995. Venture capitalist relationships in the deal structuring and
post-investment stages of new firm creation. Journal of Management Studies 32(3):337–357.
Stewart, T.R. 1993. Notes on the validity of judgment analysis. Working paper.
Stewart, T.R. 1991. Policy PC: Judgment analysis software reference manual. Albany: Executive
Decision Services.
Stewart, T.R. 1988. Judgment analysis procedures. In B. Brehmer and C. Joyce, eds., Human
Judgment: The SJT View. North Holland: Elsevier.
Strong, K.C. 1992. A cognitive model of downstructuring strategy. Unpublished doctoral dissertation: University of Colorado, Boulder.
Timmons, J.A. 1994. New venture creation: Entrepreneurship for the 21st century. Homewood,
IL: Irwin.
Timmons, J.A., Muzyka, D.F., Stevenson, H.H., and Bygrave, W.D. 1987. Opportunity recognition: The core of entrepreneurship. Frontiers Of Entrepreneurship Research 109–123.
Tversky, A., and Khaneman, D. 1974. Judgment under uncertainty: Heuristics and biases. Science 185:1124–1131.
Tyebjee, T.T., and Bruno, A.V. 1984. A model of venture capitalist investment activity. Management Science 30(9):1051–1056.
Wells, W.A. 1974. Venture capital decision-making. Unpublished doctoral dissertation, CarnegieMellon University, Pittsburgh.
Wright, W.F. 1979. Properties of judgment models in a financial setting. Organizational Behavior
and Human Decision Processes. 23:73–85.

<-----Page 23----->346

A.L. ZACHARAKIS AND G.D. MEYER

APPENDIX Sample Scenario for Each Treatment.

