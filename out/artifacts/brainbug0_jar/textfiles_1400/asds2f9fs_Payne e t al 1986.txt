<-----Page 0----->AD-A178 858
UNCLASSIFIED

DUKE
86-1
AL DECISION
31 JUL 86AKING(U)
NC J IdPAYNE ET IN
UNIV DURHAM
ADAPTIVE STRATEGY SELECTION
F/G 5/10

1/1
ML

mhhmhEohEEEohE
EhhhEEEEmhhhhE
I......

<-----Page 1----->JI~fL
Lim'~11125
1.1 L"L
11111L2

MICROCOPY

RESOW~TION TESTCHART

NATIONALBUREAUOF STANDARDS1963-A

<-----Page 2----->ONR CONTRACT NUMBER:
WORK UNIT NUMBER:

N00014-80-C-0114

R & T 4425063

0o
LJ
0DISTRIBUTION

APPROVED FOR PUBLIC RELEASE,
UNLIMITED.

0
I

ADAPTIVE STRATEGY SELECTION IN DECISION MAKING

DTIC

JOHN W. PAYNE

L.CT E

DUKE UNIVERSITY

AUG 13

JAMES R. BETTMAN
DUKE. UNIVERSITY
ERIC J. JOHNSON
CARNEGIE-MELLON UNIVERSITY

!,.

THIS WORK WAS SUPPORTED BY THE ENGINEERING PSYCHOLOGY
PROGRAMS FROM THE OFFICE OF NAVAL RESEARCH. REPRODUCTION IN
WHOLE OR IN PART IS PERMITTED FOR ANY PURPOSE OF THE UNITED
STATES GOVERNMENT.

86

8

13

096

<-----Page 3----->SECURITY CLASSIFICATION OF THIS PAGE (Whion Des EnIer_

_

REPORT DOCUMENTATION PAGE
. REPORT NUMBER

2. GOVT ACCESSION NO. I

'

V4L_

86-1
4.

'4

__)

____s__uc

_

_N__S

SEFORE COMLZTM[G FORM

RECIP ENT*S CATALOG NUMUER

6
S.

TITLE (and Subltl)e.

ADAPTIVE STRATEGY SELECTION IN DECISION MAKING

TYPE OF REPORT & PERIOD COVERED

Research
6. PERFORMING ORO. REPORT NUMSER

e. CONTRACT ON GRANT NUMSER1()

7. AUTNORfe)

John W. Payne, Duke University
James R. Bettman, Duke University
Eric J. Johnson, Carnegie-Mellon University

N00014-80-C-0114
10. PROGRAM ELEMENT PROJECT. TASK

9. PERFORMING ORGANIZATION NAME AND ADDRESS

AREA I WORK UNIT NUMBERS

Duke University
It.

RT 4425063

CONTROLLING OFFICE NAME AND ADDRESS

REPORT DATE

12.

July 31, 1986
ONR, Arlington, VA

.4-.

22217-5000

13. NUMBER OF PAGES

_64
14. MONITORING AGENCY NAME & AOORESS(If different Ina Controlling Office)

SECURITY CLASS. (of thle eporl)

IS.

Unclassified
Ia.
S.
.:
*

DECLASSIFICATION/DOWNGRADING
SCHEDULE

I.

-F..

DISTRIBUTION STATEMENT (ofhis RepPrt)

Approved for public release; distribution unlimited.

17.

DISTRIBUTION STATEMENT (of the ebelrcac

entered In Steoc k".

If difforent hem RAped)

S1. SUPPLEMENTARY NOTES

19.

KEY WORDS (Continue on .evere

. "ifnece.erya

identity by block nubo,)

Decision Making, Strategies Adaptive, Cognitive Effort
Time Pressure, Process Tracing

-

-'4

.J2.

AST ACT (Continueaon revere side If necessayn

diddentify by block nunber)

examine the role of effort and accuracy in the adaptive use of decision
processes. A computer simulation study that used the concept of elementary
information processes identified heuristic choice strategies which approximate
the accuracy of normative procedures while requiring substantially less effort.
However, no single heuristic did well across all task and context conditions.
Of particular interest was the finding that under time constraints, several
heuristics were clearly more accurate than a normative procedure. Two process
tracing studies showed a significant degree of correspondence between the
..
IAN

7. 1473

EDITION OF i NOV 65 IS OBSOLETE
S/N 0102- LF- 014. 6601

SECURITY CLASSIFICATION OF THIS PAGE (Mhen

bets fntard)

<-----Page 4----->efficient strategies for a given decision problem identified by the simulation
and actual decision behavior. People vere highly adaptive to changes in the
nature of the alternatives available to them and to the presence of time
pressure.

Ja

,
if

-, -

<-----Page 5----->Adaptive Decisions
3
Much research has been devoted to describing the information processing
strategies people use for making choices (Bettman, 1979; Svenson, 1979).
Initially, this research focused on strategies that implied a complete search
of all relevant information about the alternatives and that also allowed the
good and bad aspects of each alternative to compensate for one another.
*Examples

of such decision rules are the various expectation models of risky
choice and the additive utility model of multiattribute choice.

Simon (1955),

however, suggested that decision strategies like additive utility were
incompatible with our knowledge of human cognition.
*failed

Furthermore, such models

to account for important empirical findings, such as intransitivity in
preferences (Tversky, 1969).

Consequently, a number of simplified decision

rules, or choice heuristics, have been proposed.

Such heuristics reduce

information processing demands by ignoring some potentially relevant problem
information and by avoiding tradeoffs among values.

For example, the

lexicographic heuristic (Tversky, 1969) chooses the alternative which is best
on the most important attribute, ignoring all other information.

While

heuristics can reduce information processing demands, they can also lead to
decision errors such as intransitivities.
One of the major empirical findings of recent decision research is that
an individual will use a variety of strategies for making a choice.
a person will use a compensatory type of strategy.
person will use a noncompensatory decision strategy.

\S

Sometimes

At other times, the same
The use of a particular

strategy appears to be contingent on a number of task and context variables

[]

El
(Payne, 1982).

Task variables are general characteristics of the decision

problem, such as number of alternatives and time pressure, which are not
dependent on the particular values of the alternatives in the decision set.
,

Codes

Context variables, in contrast, are associated with the particular values of
-" - 1IJ1

~~'5~

...

d.

W-

-r

4.

e

.

%1

~.

*~

*.

'.** W

5-

<-----Page 6----->Adaptive Decisions
4
the choice objects, such as the correlation between attributes.

One example

of a contingency effect is the increase in the use of simplifying heuristics
as the number of alternatives increases (Payne, 1976).
Evidence of contingent information processing in decisions'has raised
the question of why certain decision strategies are applied to solve certain
decision problems.
choose?

In other words, what determines the decision on how to

One general perspective in trying to answer that question looks at

strategy selection as a function of both its costs, primarily the effort
required to use a rule, and its benefits, primarily the ability of a strategy
to select the best alternative (Beach & Mitchell, 1978; Russo & Dosher, 1983).
The advantage of a cost-benefit approach to strategy selection is the ability
to maintain the concept of calculated rationality (March, 1978), once the
costs of executing the decision process are included in the assessment of
rationality.

Furthermore, because the costs and benefits of various decision

strategies will vary across different problems, the cost-benefit perspective
provides the potential for explaining a variety of empirical results
concerning situation specific decision behavior.
The goal of this paper is to examine the role of effort and accuracy
considerations in the adaptive use of different information processing
strategies for making a choice.

First, an approach to understanding

V

contingent decision behavior using the concept of elementary information

./

processes and the method of computer simulation is introduced, and some prior
work by Johnson and Payne (1985) using that approach is briefly discussed.
Next, a Monte-Carlo simulation study of the effort and accuracy of choice
heuristics in a variety of choice environments which extends the prior work by
Johnson and Payne (1985) in several directions is reported.

Of particular

interest is the impact of time constraints on the relative accuracy of

<-----Page 7----->-_ PI P

- -

Adaptive Decisions
5
decision strategies.

Finally, two experimental studies of task and context

effects on decision behavior are reported.

As in the simulation, the task

variable of interest is the degree of time pressure confronting the decision
maker.

These studies utilize a new computer-based process-tracing technique

to examine the adaptiveness of human choice processes.

The degree of

correspondence between the efficient strategies-identified by the computer
-:

simulation for a given type of decision problem and the actual information
processing strategies people use is then addressed.
Hence, the major purposes of the paper are threefold:

1) To provide a

conceptual approach for modeling effort and accuracy tradeoffs in choice; 2)
To report both simulation-based and empirical evidence regarding- patterns of
adaptivity in strategy selection in different choice environments; and 3) To
examine the extent to which the, empirical evidence on adaptivity validates the
conceptual approach used.

As a secondary purpose, the empirical work provides

some of the most detailed process-tracing evidence to date regarding responses
to time pressure in decision making.
Effort and Accuracy in Choice
One major difficulty in examining strategy selection from a cost-benefit
perspective has been the lack of a conceptually appropriate measure of effort
that is easy to calculate.

A closely related problem is the lack of a common

language which could be used to describe the process level similarities and
differences among the various choice models that have been proposed.

This is

important if strategy selection is to be investigated at an information
processing level rather than at a more general level of analysis, such as
analytic vs. nonanalytic (Beach and Mitchell, 1978) or analytic vs. intuitive
(Hammond, 1986).

A second area of concern with the cost-benefit approach has

<-----Page 8----->Adaptive Decisions
6
been the lack of agreement on how to measure accuracy of choice.

Johnson and

Payne (1985) have proposed solutions to these problems.
Measuring Strategy Effort.

Building on earlier work by 0. Huber (1980),

Johnson (1979), and the ideas of Newell and Simon (1972), Johnson and Payne
(1985) suggest that decision strategies can be decomposed into elementary
information processes (EIP's).

A decision strategy or rule could then be

thought of as a sequence of events, such as reading the values of two
alternatives on an attribute, comparing them, and so forth.

A possible set of

EIP's for decision making, similar to those suggested by Huber (1980) and
Johnson (1979), is listed in Table 1. One advantage of this approach is that
the EIP's provide a common language for describing seemingly diverse decision
strategies in terms of their underlying components.
Insert Table 1 about here
A second advantage of this approach is that a count of the total number
of elementary information processes required by a given strategy to reach a
decision in a particular choice task environment can be used as a measure of
th effort associated with the use of that decision strategy in that task
environment (Johnson and Payne, 1985).

Examples of the use of EIP counts to

measure processing load can be found in a number of studies of cognition
(e.g., Card, Moran, & Newell, 1983; Carpenter & Just, 19750.
Measuring Accuracy.

Accuracy of choice can be defined in many ways.

At

a very general level, quality of choice can be defined by basic principles
such as consistency in preference.

For example, maintaining transitivity, or

the avoidance of errors such as selecting a dominated alternative, are often
suggested as normative decision principles.

However, more specific criteria

for decision quality can be developed in certain choice environments.

In the

<-----Page 9----->Adaptive Decisions
7
area of risky choice, for instance, the expected utility model, which can be
derived from certain principles of consistency, is often suggested as a
normative decision procedure.

N

A special case of the EU model, the

maximization of expected value, has been used as a criterion to investigate
the accuracy of decision heuristics through computer simulation (Thorngate,
In the domain of nonrisky choice, the compensatory multi-attribute

1980).

utility (MAU) rule is often used as a criterion for decision effectiveness
(e.g., Zakay & Wooler, 1984).
Examining Accuracy and Effort in Choice.

Johnson and Payne (1985)

examined both the effort and the accuracy of six decision rules for risky
choice.
* -in

Effort was measured in terms of EIP's, and accuracy was measured both

terms of consistency in choice and EV maximization.

The six decision rules

examined by Johnson and Payne differed markedly in the amount of the available
information they considered.

A priori, this was expected to be an important

determinant of both the accuracy and the effort resulting from their use.

The

expected value (EV) rule, which is based on complete search of the available
information, was at one extreme.

The equiprobable heuristic is similar to the

EV rule in that it examines all the alternatives and all outcomes.

However,

it ignores one of the two attributes of a gamble's outcomes, probability,
explicitly treating all events as equally likely.

The most-likely heuristic,

in contrast, examines only one outcome for each alternative, the outcome with
the highest probability of occurrence, and selects the alternative with the
largest payoff for this outcome.

The maximin heuristic ignores probabilities-

entirely and selects the alternative with the largest minimum payoff.
Elimination by aspects (EBA) is a choice rule proposed by Tversky (1972).

A

special version of EBA investigated by Thorngate (1980) that attends only to
payoff information was also examined by Johnson and Payne.

.

~4.~

"LS

Each payoff of a

V,

<-----Page 10----->Adaptive Decisions
8
gamble is compared to a cutoff equal to the mean payoff.

If a payoff is less

than the cutoff, the gamble is eliminated from further consideration.
i~.

The

rule terminates when either (a) one alternative remains, or (b) all attributes
have been considered, and one must choose randomly from the remaining
alternatives.

Finally, the random choice rule served as a baseline, simply

choosing an alternative at random with no search.
Johnson and Payne conducted a series of Monte Carlo studies that varied
several aspects of the choice environment.

The task variables

-

number of

risky alternatives and number of outcomes- were varied at levels of 2, 4, and
8.

Another aspect of the choice environment varied was a context variable,

the amount of variance in probabilities within each gamble.

This variable was

chosen because Thorngate (1980), using a simulation approach, had suggested
siT..that probability information may be relatively unimportant in making accurate
risky choices.

C'..'that
a

However, Thorngate's method for constructing gambles ensured

the variance in the probability distribution would be small relative to

the variance in payoffs.

Hence, Johnson and Payne implemented an additional

method of probability generation that produced larger variances in the
probability distributions.
V.

Finally, the presence or absence of dominated

alternatives in a choice set was the second context variable examined.
The Johnson and Payne simulations identified choice rules that appeared
to provide approximately the accuracy of normative procedures while requiring
substantially less effort.

*

The results, however, were highly contingent upon

characteristics of the choice environments.

In the environment that closely

resembled Thorngate's, for example, the equiprobable rule appeared quite
accurate.

It was also a rule that maintained roughly the same accuracy as the

number of outcomes was increased.

In contrast, when the variance of the

probabilities was increased, the most-likely heuristic became the most

a.V

<-----Page 11----->Adaptive Decisions
9
accurate, whereas the equiprobable heuristic displayed a marked decrease in
accuracy.

Furthermore, the most-likely rule was the only one to maintain

accuracy as the number of outcomes increased in the high-variance environment.
*

Thorngate's earlier statement about the importance of probability information,
therefore, was found to be of limited generality.
Another interesting result was the effect of the presence or absence of

*

dominated alternatives.

The removal of dominated alternatives reduced the

accuracy of some heuristics to almost chance levels.. Finally, Johnson and
Payne also found that task effects tended to have a greater influence on the
efotrequired by strategies, while context effects tended to have a greater
influence on accuracy.
Johnson and Payne concluded that heuristics could be highly accurate,
but that no single heuristic would do well across all contexts.

Instead, if a

decision maker wanted to maintain a high level of accuracy with a minimum of
%

effort, he or she would have to choose among a repertoire of strategies,
contingent upon situational demands.

In other words, a decision maker

striving to minimize both errors and effort would have to be highly adaptive
in the use of decision processes.
Thus, the Johnson and Payne simulations, using EIP's to measure effort
and various criteria for assessing accuracy, were able to yield interesting
and important conclusions about adaptivity in choice.
raised two very important issues.
*

However, this work also

First, the original Johnson and Payne

(1985) work investigated a few decision rules in one particular type of risky.
decision environment.

Hence, one issue is whether these results generalize to

other rules and different types of choice settings.

Second, the simulation

work helps to identify adaptive strategies for decision makers, assuming that
they wish to minimize either errors, effort, or some combination of the two.

<-----Page 12----->Adaptive Decisions
10
A major unanswered empirical question is the degree to which human decision
makers actually display such adaptivity to either errors or effort.

The

remaining sections of the paper examine these two issues, utilizing further
computer simulation for the first and two experiments for the second.
Study 1:

A Monte-Carlo Simulation of Effort

and Accuracy in Choice
The purpose of this study was to investigate the generality of the

Johnson and Payne (1985) simulations by extending both the range of decision
strategies and choice environments studied.

This study examined a set of ten

decision strategies, four more than investigated by Johnson and Payne (1985).
Forms of the lexicographic and elimination-by-aspects strategies are included

that are more consistent with those originally described by Tversky (1969;
1972).

In addition, several strategies not considered in the earlier

simulation and two strategies are that are combinations of other strategies

(e.g., an EBA rule plus an additive rule) are examined.

The specific

strategies used are described in more detail below.
A second major change involves the decision task.

In contrast to the

earlier simulations, the choice alternatives are constructed to have a set of
outcomes which have the same probability for each alternative.

In other

words, each of the alternatives may have a different value for each outcome,
but the probability of receiving each outcome is the same for all the
alternatives.

This allows us to also interpret the current decision task as a

riskless choice task, in which the probabilities function as attribute weights
that apply across alternatives.
at a probability of

Under a riskless interpretation, one can look

.25, for example, as the weight given to a particular

attribute across all alternatives.

Alternately, under a risky choice

scenario, the .25 is the probability of obtaining that outcome.

-N.6

In previous

<-----Page 13----->Adaptive Decisions

simulation work (Thorngate 1980, Johnson and Payne, 1985), the probabilities
varied across alternatives, preventing the extension of the results to
riskless choice.

This relationship between risky choice problems and multi-

attribute decision problems is discussed more fully in Keeney and Raiffa
(1976).
Finally, in addition to the task and context variables studied in the
earlier simulation, the present study investigates the impact of time
pressures upon decision strategies.
most significant task variables.

4

Time pressure is potentially one of the

Under time constraints, a heuristic like EBA

(Tversky, 1972) might be more accurate than a strategy such as maximization of
expected value.

The reason is that the rate at which a heuristic's accuracy

degrades under increasing time pressure may be slower than the rate at which a
more comprehensive processing rule, e.g., EV., degrades.

One possible reason

for this is that heuristics require fewer operations and will generally be
"further along" when time runs out.

Furthermore: time pressure relates to the

extent to which people use heuristics because they have no other choice
(Simon, 1981).

A more normative decision strategy like expected utility

maximization may exceed the information processing capabilities of a decision
maker, given any "reasonable" time limit for making the decision.

If use of a

more normative rule is effectively impossible, then the task of deciding how
to choose becomes a selection of the "best" among a set of available
heuristics, not a decision on whether to use some heuristic or the more
normative rule.
Decision Strategies
The ten decision strategies were implemented using the EIPs and
The

production system representation proposed by Johnson and Payne (1985).

ten decision strategies varied substantially in the amount of the available

4.4t!

A ;

.

<-----Page 14----->Adaptive Decisions
12
information used to make a choice.

The most information intensive was a

version of a Weighted Additive (WADD) compensatory process.

This strategy

considers the values of each alternative on all the relevant attributes
(outcomes) and all the relative importances (weights or probabilities) of the
different attributes (outcomes) to the decision maker.

The rule develops a

weighted value for each attribute by multiplying the weight times the value
and sums over all attributes to arrive at an overall evaluation of an
alternative.
°,

Then the alternative with the highest evaluation is selected.

Thus, the weighted additive rule selects an alternative based on an exhaustive

search of the available information.

Such a process is often suggested as a

normative procedure for multiattribute choices (Ulvila & Brown, 1982).

In

contrast, the Random (RAN) choice rule chooses an alternative at random with
no search of the available information.

Hence, the Random rule serves as a

minimum baseline for measuring both accuracy and effort.
In addition to these two baseline rules, six individual heuristics for
multiattribute choice were implemented, along with two combination strategies.
The Equalweight (EQW) rule examines all alternatives and all attribute values
for each alternative.

However, the rule ignores information about the

relative importance of each attribute.

Instead, the equalweight rule operates

by summing the attribute values for each alternative to get an overall value,
and the alternative with the highest total is selected.

In some contexts, the

equal weight rule has been advocated as a highly accurate simplificaton of the
choice process (Dawes, 1979; Einhorn and Hogarth, 1975).

The equal weight

rule is identical to the equiprobable rule for risky choice investigated by
Thorngate (1980) and Johnson and Payne (1985).

The Elimination by Aspects

(EBA) rule (Tversky, 1972) begins by determining the most important attribute
(the outcome with the highest weight (probability)).

%

Then, the cutoff value

%

<-----Page 15----->Adaptive Decisions
13
for that attribute is retrieved, and all alternatives with values for that
attribute below the cutoff are eliminated.

This process continues with the

second most important attribute, then the third, and so on, until one
alternative remains.

This version of EBA differs from that examined by

Thorngate (1980) and Johnson and Payne (1985).

The present version of EBA

does order search by attribute importance, so it more closely resembles the
EBA model originally proposed by Tversky (1972).
The Majority of Confirming Dimensions (MCD) rule has been suggested by
Russo and Dosher (1983).

This rule involves processing pairs of alternatives.

The values for each of the two alternatives are compared on each attribute,
and a running score is kept of how many times each alternative has a better
value on an attribute.
values is selected.

The alternative with a majority of winning attribute

In the case of an equal number of winning values for the

two alternatives, we implemented a version of this rule where the alternative
winning the comparison on the last attribute is retained.

The retained

(winning) alternative is then compared to the next alternative among the set
of alternatives.

The process of pairwise comparison repeats until all

alternatives have been evaluated and the final winning alternative identified.
The Satisficing (SAT) rule (Simon, 1955) does not necessary examine all the
alternatives in a set.

Instead, alternatives are considered one at a time.

For each attribute of an alternative, it is determined whether the attribute
value exceeds a cutoff value.

If any attribute value is below the cutoff

value, that alternative is rejected.

The first alternative in a set which has

values which pass the cutoffs for all attributes is chosen.
can be made before all alternatives have been evaluated.

That is, a choice

In the case where no

alternative passes all the cutoffs, a random selection is made among the
alternatives.

<-----Page 16----->Adaptive Decisions
14
For

We also implemented two versions of the lexicographic choice rule.
the strict Lexicographic (LEX) rule, the most important attribute is

determined, and the values of all the alternatives on that attribute are then
examined.

The alternative with the highest value on that attribute is

selected.

If there are ties, the second most important attribute is examined,

and so on until the tie is broken.

However, because the attributes in the

simulation are generated as continuous random variates, ties almost never
Thus, this rule is essentially the same as the most likely heuristic

occur.

for risky choice investigated in Thorngate (1980) and Johnson and Payne
(1985).

We also examined a Lexicographic Semi-Order (LEXSEMI) rule (Tversky,
This rule is similar to the strict lexicographic rule, but introduces

1969).

the notion of a just-noticeable difference (JND).

If several alternatives are

-S..

within a JND difference of the best alternative on the most important
attribute, they are considered to be tied.

These alternatives are compared on

the next most important attribute, and the process continues until one option
*

remains.

The potential advantage of the Lexicographic semi-order rule is that

it ensures that an option which is marginally better on the most important
attribute but much worse on other attributes will not necessarily be selected.
Finally, two combined strategies were implemented.

The first was an

plus Weighted Additive (EBA+ADD) rule.

*Elimination-by-Aspects

This rule used

an EBA process until the number of available alternatives remaining was three
or less, and than used a weighted additive rule to evaluate the remaining
and select the best.

*alternatives

The other combined strategy used

Elimination-by-Aspects plus Majority of Confirming Dimensions (EBA+MCD).

This

-

rule again used an elimination-by-aspects process to reduce the problem size
to three alternatives or less, and then a majority of confirming dimensions
heuristic is used to select the winning alternative from the reduced set.

A:K'

A-

7

-A

.

.

'

<-----Page 17----->Adaptive Decisions
15
These combinations were used because they had been observed in several
previous choice process studies (e.g., Payne, 1976; Bettman and Park, 1980).
V"

In addition to the amount of information utilized, these heuristics
differ in how information about the alternatives and attributes of a decision
problem is likely to be processed.
based form of processing.

Some of the rules imply an alternative-

That is, information is processed regarding the

multiple attribute values of a single alternative before information about a
second alternative is processed.

Examples of such rules are the weighted

additive rule, the equalweight rule, and satisficing.
imply an attribute-based form of processing.

Other decision rules

That is, information is

processed regarding the values of several alternatives on a single attribute
before information about a second attribute is processed.

Examples of

attribute-based processing strategies are the EBA rule and the lexicographic
choice rules.

The distinction between alternative-based (also called

"holistic processing") and attribute-based decision strategies has played a
*major

role in numerous discussions of decision models (e.g., Bettman, 1979;
Goldstein, 1986; Svenson, 1979), and has implications for the robustness of
the various strategies under time constraints.

In particular, it can be

argued that under increasingly severe time pressure, it becomes more and more
-

important to examine all alternatives, even if on a limited set of attributes.
Thus, attribute-based strategies may have an advantage (i.e., degrade more
slowly) under time pressure.
Task and Context Variables
For purposes of comparison with Johnson and Payne (1985), we included
essentially the same set of task and context variables.

We manipulated task

complexity through variations in the number of alternatives and number of

<-----Page 18----->Adaptive Decisions
16
attributes.

The numbers of alternatives were 2, 5, and 8; the numbers of

attributes were also 2, 5, and 8.
One context variable was the presence or absence of dominated
alternatives.

Removing dominated alternatives produces efficient or Pareto-

optimal choice sets.

The other context variable was the variance in the

relative weights assigned to the attributes.

As noted earlier, Johnson and

Payne (1985) found that the variance of the probabilities impacted on which
heuristics were most efficient in risky choice.

As before, we examined both

low variance and high variance sets of weights.

The generation of the weights

paralleled the two procedures used in Johnson and Payne (1985) for generating
the probabilities of outcomes, with the difference that only one set of
weights were generated for a given choice problem.
Time Constraints
One new task variable was added, time pressure.
constraint were investigated.

Four levels of time

One level involved no time pressure.

rule could use as many operations as needed.

A given

The three other levels of time

constraint were a maximum of (1) 50 EIP's (severe time pressure), (2) 100
EIP's (moderate pressure), and (3) 150 EIP's (low pressure).

These time (EIP)

constraint values were selected on the basis of an analysis of the maximum
2
number of EIP's associated with the most effortful rule (weighted additive).

Note that the total number of EIP's was used to operationalize time pressure.
This implicitly assumes that each EIP takes a similar amount of time.

While

this is clearly an oversimplification, equal weighting of EIP's was felt to be
a useful initial approximation.
A key issue in dealing with the time or effort constraints is how rules
should select among alternatives if they run out of time.

For those rules

where one alternative which is best so far is available (i.e., the WADD, EQW,

<-----Page 19----->"

.1

Adaptive Decisions
17
and MCD rules), that alternative was selected.

The EBA, lexicographic, and

satisficing rules all picked an option randomly from those alternatives that
had not yet been eliminated.

For the two combined strategies, the selection

was either made at random from the alternatives not yet eliminated, if the
combined strategy was still in the EBA phase, or the best so far if in the
9.

WADD or MCD phase.

JNDs and Cutoff Values
Three of the rules, elimination-by-aspects, satisficing, and the
lexicographic-semiorder rule, involve parameters that affect the potential
effort and accuracy of the rules.

For EBA and satisficing , this is the

cutoff value used to eliminate alternatives.
rule, it is the value of the JND.

For the lexicographic-semiorder

While these parameters are, in some sense,

under the control of the decision maker for each decision, we wanted to
establish a priori values which would be the same for all decisions made by
the simulation.

Other alternatives, such as finding an optimal level of the

cutoff or JND for each decision or decision environment, would themselves
require effort on the part of the decision-maker, and would have to be
captured in the simulation.
time constraints.

Instead, we ran a pilot simulation without any

All attributes in the simulation were drawn from a uniform

distribution bounded by 0 and 1000.

We manipulated both cutoffs (100, 300 and

500) and JNDs (1, 50, and 100) and selected values which represented the most
efficient accuracy-effort tradeoffs across the entire set of decisions.

We

found that values of the cutoff of 500 and 300 were most efficient for
elimination-by-aspects and satisficing, respectively, and that a JND of 50
p'

gave the best performance for the lexicographic-semiorder rule.

We therefore

set the JND value at 50, and included cutoffs set at 300 and 500 as a factor
in the experimental design.
in

Since this cutoff effect is small, compared to

<-----Page 20----->Adaptive Decisions
18
other factors, we shall not discuss it further.

When the results for the EBA

and satisficing rules are presented, they are for the most efficient cutoff
values for each rule.
Method
Each of the ten decision rules was applied to 200 randomly generated
decision problems in each of the 288 conditions defined by a 3 (number of
alternatives) by 3 (number of attributes) by 2 (low or high variance of
weights) by 2 (presence or absence or dominated alternatives) by 2 (cutoff
V'

values) by 4 (time constraints) factorial.

After each trial, the alternative

selected was recorded, along with a tally for each elementary operation used
by the decision rule.

Johnson and Payne (1985), for comparison, investigated

only 36 possible task and context combinations.

For further details of the

simulation methodology, see Johnson and Payne (1985).
Results
The measure of accuracy used compares the relative performance of
strategies to the two baseline strategies:
value, and (2) random choice.

(1) the weighted additive (WADD)

The measure is defined by the following

equation:

Relative

WADDheuristic rule choice - WADDrandom rule choice

Accuracy

WADDadditive rule choice - WADDrandom rule choice

--------------------------------------------------

That is, we determined the maximum weighted additive (WADD) value possible in
a particular choice set,
selection.

and the WADD value associated with a random

The WADD value of the alternative selected by a decision heuristic

is then compared to these two baseline values.

This measure of performance is

bounded by a value of 1.00 for the WADD rule itself, and 0.0 for random

V

A-5

A.

-.

<-----Page 21----->Adaptive Decisions
19
selection.

It thus provides a measure of the relative improvement over random

selection (Johnson and Payne, 1985).
Effort was measured by first summing the total number of elementary
operations used by a decision rule to make a selection from a particular set
of alternatives.

This measure assumes that each elementary operation requires

essentially the same level of time or mental effort.

This assumption was used

by Johnson and Payne (1985) in their principal analyses.
Table 2 presents the relative accuracy scores and the unweighted effort
scores for each of the ten decision strategies, in each of the four variance.
in weights (low, high) by dominance (present or absent) context conditions.
These scores are for the no time pressure conditions.

The results are

averaged over number of alternatives and attributes and cutoffs, except that
the results for the EBA and satisficing rule are for each rule with its "best"
cutoff value.
Table 3 presents the relative accuracy of each decision strategy in the
four context conditions under the three levels of time pressure.

Effort

measures are not included, because they are constrained by the time pressure
cutoff values.

3

No Time Pressure Results
The simulation results for choice among multiattribute alternatives
without time pressure, shown in Table 2, are similar to those found by Johnson
and Payne (1985).

In some environments, heuristics for multiattribute choice

can approximate the accuracy of a normative strategy (WADD), with substantial.

*

savings in effort.

A decision maker using an equal weighted version of the

additive model (EQW), for example, can achieve 89% of the relative performance
of the normative model, with only about half the effort, in the low-variance,
dominance-possible task environment.

V.1
a,,iL
'it

Even more impressive is the performance

<-----Page 22----->Adaptive Decisions
20
of the strict lexicographic rule in the high-variance task environments.

The

lexicographic rule achieves 90. relative accuracy, with only about 40 percent
of the effort, on average.

Note that the lexicographic-semiorder rule is

slightly better than the simpler lexicographic rule in only one of the four
decision environments.

The extra effort needed to take into account just-

noticeable differences may only be of value for a limited set of decision
situations.
As was found in Johnson and Payne (1985), it is clear from Table 2 that
the most efficient heuristic varies across decision environments.

It is also

clear that some heuristics (e.g., MCD and Satisficing) perform reasonably in
the dominance-possible environments, but are very poor choice rules in tasks
where all dominated alternatives have been screened out.

Insert Table 2 about here

One interesting result from Table 2 is the relatively efficient

4-"

performance of the elimination-by-aspects rule.

In the earlier work by

Thorngate (1980) and Johnson and Payne (1985), the version of EBA investigated
did not show much accuracy (30% on average).

In the present simulation, the

EBA rule provided an average relative accuracy value of 65

over all task

environments, with an effort score of 85 versus 160 for the WADD rule.
Obviously, allowing the EBA rule to search as a function of the relative
importance of attributes (one main difference between the current
implementation and the previous studies) makes a major difference in the
accuracy of an EBA rule.
Another interesting set of results concerns the performance of the two
combined decision strategies.

The combination of an elimination process with

a weighted adding model (EBA+ADD) performed well across all task conditions.

L

<-----Page 23----->Adaptive Decisions
21
That rule appears to offer a good combination of accuracy and reasonable
levels of effort.

The EBA+MCD rule, on the other hand, does not appear to be

an efficient combination strategy.

On the basis of the overall simulation

results, it appears that the EMA rule alone is superior to the EBA+MCD rule.
Time Pressure Results
From the time pressure results, shown in Table 3, it is clear that time
constraints have different effects on the various rules.

The weighted

additive rule, for example, shows a marked reduction in accuracy from the
baseline value of 1.0 for the no time pressure condition to an average
accuracy of only .2 under the most severe time constraint in the no dominancelow variance condition.

In contrast, the elimination-by-aspects heuristic

shows relatively little effect of time pressure.

The average accuracy is

reduced from .69 (no time pressure) to .56 (severe time pressure).
Interestingly, the EBA rule is actually the most accurate decision strategy
for three of the four choice environments for severe time pressure.

Another

rule that appears to hold up well under time pressure is the lexicographic
rule.

In general, it appears that strategies involving an initial processing

of all alternatives across a limited set of attributes do well under time
pressure.

On the basis of the simulations, what seems to be important in time

pressured decision environments is to use a choice strategy that involves the
processing of at least some information about all alternatives as soon as
possible.

However, note that at least in one decision environment (dominance-

possible, variance in weights-low), the alternative simplification strategy
provided by the equalweight rule does well under even the most severe time
constraint studied.
--

-

-

--

-

-

-

--

-

-

-

Insert Table 3 about here

>.WV.~:
~9*,~?-------------------------S4

4

<-----Page 24----->Adaptive Decisions
22
Note also the effects of time pressure on the relative performance of
the EBA and the EBA plus weighted additive rules.
combined strategy is more accurate.
strict EBA rule does better.

Under most conditions, the

However, under severe time pressure, the

We speculate again that under severe time

pressure, the processing of at least some information about all alternatives
is important.

With the combined rule, some alternatives may not be processed

when the initial number of alternatives is small.

With a small number of

alternatives, the rule becomes essentially a weighted additive rule.
-~

Overall, the results show that some decision strategies are much more
sensitive to time constraints than others.

What appears important under

severe time pressure is to do at least a quick, if dirty, evaluation of all
the alternatives.

This type of strategy seems superior to one that evaluates

some alternatives more completely, but may not evaluate some other
alternatives at all within the time constraint.

A related finding is that

those strategies which involve attribute-based processing (e.g., LEX & EBA)
appear to hold up better under time pressure than alternative-based processing
strategies, e.g., WADD and EQW.
Study 2:

Time Pressure and Context Effects
on Decision Processes

Taken together, the simulation results from Study 1 and the earlier work
of Johnson and Payne (1985) indicate what a decision maker might do to adapt
to a decision environment.

Specifically, this work suggests the possibility

that a decision maker might be able to maintain a high level of accuracy and
minimize effort by using a diverse set of heuristics, changing rules as
contexts and time pressure change.
In this and the following study, we examine the degree of correspondence
between the actual adaptivity shown by human decision makers and the adaptive

".

N

%

<-----Page 25----->Adaptive Decisions
23
strategies indicated by the simulation results.

Specifically, we ask:

(1) To

what extent do people change strategies as a function of task effects such as
time pressure and context effects such as the variance in probabilities?; and
(2) Are these changes in strategy adaptive in the directions suggested by the
simulation?

Two empirical studies which monitor subjects' decison processes

as we manipulate both time pressure and the variance in probabilities were
carried out to answer these questions.
The simulation results provide a fairly clear picture of an adaptive
-:

decision maker.

Consider the context manipulation of the variance in

probabilities, and assume that dominated alternatives are possible.

Then, if

decision makers are adaptive in the way the simulations suggest, we would
expect to see a relationship between the variance in probabilities and the
amount of alternative-based versus attribute-based processing.

The simulation

indicates that an alternative-based processing strategy, the equalweight rule,
is a very accurate heuristic for low-variance decision environments.

On the

other hand, a more attribute-based processing strategy, the lexicographic
rule, is more accurate in high variance in probabilities decision
Note that a shift in the form of processing as a function of

*

environments.

A

context would indicate that people are sensitive to changes in choice
environments due to a concern for accuracy and not due to task complexity or
information processing demands.

The reason is that the accuracy of these

rules varies across contexts (variance conditions), but the effort required by
the rules does not.

Studies showing contingent processing due to task

complexity (e.g., changes in numbers of alternatives and attributes) are
4.

common; studies showing processing changes due to changes in context
variables, and hence implicitly a concern for accuracy, are rare (cf. Payne,
1982).

,6z.

<-----Page 26----->Adaptive Decisions
24
The task variable examined is the presence or absence of time pressure.
We also expect strategy changes at severe levels of time pressure.

As the

simulation results indicate, the most accurate decision rule, the weighted
additive rule, becomes less accurate than several choice heuristics when there
is severe time pressure.

Consequently, the presence of an explicit time

constraint should emphasize the adaptive use of choice heuristics.
-

In

particular, the simulation results indicate that attribute-based forms of
processing, and specifically the EBA strategy, maintain relatively high levels
of accuracy under time pressure, particularly in the high variance context.

vThis

suggests that the frequency with which attribute-based processing occurs
should increase with time pressure.

*"..

Time pressure is interesting for other reasons as well.

Many real-world

decisions are made under conditions of moderate to severe time constraints.
Given the potential importance of time pressure to decision making, it is
surprising how few empirical studies have directly examined the influence of
time constraints on judgments and choices (see Svenson, Eckland, & Karlson, in
press).
.Nj

The best known work in this area is by Peter Wright (Wright, 1974;

Wright & Weitz, 1977).

Wright (1974) contains many of the theoretical

concepts that have driven most subsequent time pressure research; he equated
variations in time pressure with other ways one might vary task complexity and
then argued that increased time pressure would lead to efforts by the decision
4.

maker to simplify the task.
Ben Zur and Breznitz (1981)
simplification could occur.
/%

identified at least three ways in which this

One way to cope with time pressure is to process

only a subset of the most important information.
to as "filtration" (Miller, 1960).

This idea has been referred

Another way to cope with time pressure is

the "acceleration" of processing (Ben Zur & Breznitz, 1981; Miller, 1960).

'.4.'

<-----Page 27----->Adaptive Decisions
25
That is, one tries to process the same information, but at a faster rate.
*

Finally, one could shift processing strategies.

At the extreme, this could

involve random choice, or what has been called "avoidance" (Ben Zur &
Breznitz, 1981; Miller, 1960).

A less extreme form of contingent processing

would involve a shift from a more effortful rule, like the additive rule, to a
-

less effortful rule, like EBA.

The simulation results presented earlier

indicate that such a shift in strategy could maintain relatively high levels
of accuracy even under severe time pressure.
The hypothesis of filtration is supported in the literature.
example, Wright (1974),

For

Wright and Weitz (1977), and Svenson et. al. (in

press) all report that the most important information in a judgment task was
given more weight under time pressure.

Ben Zur and Breznitz (1981),

in the

only process tracing study of time pressure effects on choice, also report
some shifting to the use of more important information under time pressure.
Furthermore, Ben Zur and Breznitz found that subjects spent less time looking

"-

at individual items of information under time pressure.

They concluded that

the combination of filtration and limited acceleration "can be viewed as the
44
44

optimal decision making strategy when the DM is confronted with information

%:

overload while pressured by deadlines (p. 102)".
The question of optimality of choice under time pressure was directly
They found that under

addressed by Zakay and Wooler (1984) and Zakay (1985).
"

time pressure a smaller proportion of the observed choices consisted of the

G

alternative that had been measured as having the greatest additive value.
In much of the work on time pressure effects, a hypothesis is that time

.

pressure will cause people to shift toward "simpler" decision strategies.
-However,

almost all of the prior studies of time pressure have used inputoutput analyses.

.4,

-

As Wright (1974) correctly points out, the use of

*

.-

..

.4

,

.

.

.

..

.

.

.

.

.

.....

'

<-----Page 28----->Adaptive Decisions

4

26

correlational techniques based on inputs and outputs by themselves is
generally not adequate to demonstrate a shift in processing strategy.

To our

knowledge, there is no process evidence for strategy shifts under time
pressure.

Consequently, the present study uses the process tracing technique

of monitoring information acquisition to test the adaptiveness of actual
decision processes to different time constraints.

The study also examines the

adaptiveness of decision processing to the context variable associated with
the distribution of probabilities (weights) defining the options in a choice
set.

While the major purpose of the study is to study adaptivity of decision

making, the specific results for time pressure are also of great interest in
and of themselves.
Method
Subjects.

Sixteen undergraduates at Duke University served as subjects

in this experiment.

Participation in the experiment earned credit toward

fulfillment of a course requirement.

In addition, the subjects had a

possibility of winning as much as $9.99, depending on their actual choices.
Stimuli.
four options.

The stimuli were sets of risky options.

Each set contained

Each option in a set offered four possible outcomes.

outcomes involved possible payoffs ranging from $.Ol to $9.99.

The

Every option

in a set was defined in terms of the same four outcome probabilities.

That

is, each choice alternative was defined in terms of the same four possible
states of the world.

The probabilities for any given state of the world

ranged from .01 to .96, with the constraint that the sum of the four outcome
probabilities equaled 1.0.
The values of the options were generated using the techniques contained
in the simulation program described in Johnson and Payne (1985) and used in
Study 1.

Ten sets of high variance in probabilities (weights) options and 10

<-----Page 29----->Adaptive Decisions
27

S

sets of low variance options were generated.
in all sets.

Dominated options were allowed

In terms of the design used for Study 1, we sampled sets of

options from the low-variance, dominance-possible, and high-variance,
dominance-possible conditions.

The probability (weight) and payoff values for

a sample of three sets of low variance options and three sets of high variance
options used in this study are provided in Table 4.
*

Overall, the sets of

options in the Low and High variance conditions were similar in terms of their
average expected vlaues.
As noted above, these decision environments are ones where heuristics
can be highly efficient, but which heuristic is best differs across decision
environments.

The equiprobable or equal weighted additive rule, characterized

by an alternative-based form of processing, does well in the low variance
condition.

In contrast, the lexicographic rule, characterized by an

attribute-based form of processing, does better than the equalweight rule in

4

the high variance condition.

We expect in general that adaptive information

processing by an individual would involve a shift from more alternative-based
processing to more attribute-based processing as the variance in probabilities
or weights that characterize the options in a choice set increases.
- - - - - - - - - --

- - -

Insert Table 4 about here

The 20 sets of options (10 low variance, 10 high variance) were
presented under two time pressure conditions.
pressure at all.

The first was no explicit time

Subjects were told that they could take as much time as they

wished to acquire information about probabilities and payoffs and make a
decision.

The other condition involved a 15 second time constraint. 4

In this

condition, a clock was shown in the upper left-hand corner of the display
showing the information about the gambles (described more fully below).

As

<-----Page 30----->Adaptive Decisions
28
the 15 seconds passed, the clock slowly disappeared.

At 15 seconds, a beep

sounded, the subject could not acquire additional information, and he or she
was instructed to make a choice.
There were 40 decision problems (2 context conditions x 2 time pressure
conditions x 10 replications), presented to each subject in a random order.
The use of a complete within-subjects design was motivated by the desire to
provide the strongest possible test of adaptive decision making (i.e.,

that

the same subject would be expected to switch strategies from one trial to the
next).

s

A complete experimental session took from 30-45 minutes for each

subject.'
The Mouselab methodology.

Information acquisitons, response times, and

choices were monitored using a new software system called Mouselab (Johnson,
Payne, Schkade, & Bettman, 1986).

This system uses an IBM personal computer,

or equivalent, equipped with a "mouse".

A mouse is a hand-controlled pointing

device that can be used to move a cursor around the display screen of the
computer.

The stimuli are presented on the display in the form of a matrix of

available information.

The first row of boxes contained information about the

probabilities of the four outcomes.

The next four rows of boxes contained

information-about the payoffs associated with the different outcomes for each
alternative, respectively.

At the bottom of the screen were four boxes that

were used to indicate which alternative was most preferred.

Figure 1 is an

example of a stimulus display with one box opened, and with the time pressure
clock part way through the countdown.

Insert Figure 1 about here

When a set of options first appears on the screen, the values of the
payoffs and probabilities are "hidden" behind the labeled boxes.

To open a

<-----Page 31----->Adaptive Decisions
29
particular box and examine the information, all a subject has to do is move
the cursor into the box.

The box immediately opens and remains open until the

cursor is moved out of the box.

Only one box can be open at a time.

The Mouselab program records the order in which boxes are opened, and
the amount of time boxes are open.

When the subject is ready to make a

choice, he or she just moves the cursor into the choice box representing the
preferred alternative and pushes one of the buttons on the mouse.

After the

program verifies that the subject has indeed selected his or her preferred
alternative, the response is recorded, along with the total elapsed time since
the display first appeared on the screen.

Response times are recorded to an

accuracy of 1/60th of a second.
The Mouselab methodology comes close to the recording of eye movements
in terms of speed and ease of acquisitions, while minimizing instrumentation
cost and difficulty of use for both subject and experimenter.

An analysis of

the time necessary to move the mouse between boxes in our displays using Fitts
Law indicates that one could move between boxes in less than 100 milliseconds.
This suggests that the time to acquire information using the Mouselab system
is limited mainly by the time it takes to think where to point, rather than by
the time it takes to move the mouse.

More details on the Mouselab system can

be found in Johnson, Payne, Schkade, and Bettman (1986).

By using the data

collected with the Mouselab system, numerous summary measures describing the
subject's decision process can be developed.

Several such measures are

outlined in the results section.
Procedure.

Each subject was told that the purpose of the experiment was

to understand how people make decisions.
''right'

They were told that there were no

or "rn"answers.

w

m

~~

P

~

**

~

**

,***

<-----Page 32----->Adaptive Decisions
30
The subjects then were instructed on the use of the Mouselab information
acquisition system and allowed to practice its use.

Next they were told that

they would be presented with a series of decisions involving choices among
risky options.

They were told that some decisions would involve an explicit

time constraint, while for other decision problems they could take as long to
respond as they wished.
To increase motivation, the subjects were told that at the end of the
experiment a decision problem would be selected at random,

and the option they

had chosen would be played by randomly generating an outcome according to the
probabilities for that option.

They would be allowed to keep whatever money

they won.
-

-j

Results

Overview.

Our main focus in the results is how people adapt to the task

manipulation, time pressure, and the context manipulation, variance in
probabilities.

We consider effects on how subjects processed information,

relative accuracy levels, and the relationship between processing strategy and
accuracy.

Before considering these results, we first introduce measures used

to characterize the form of information processing.

Then these measures are

examined in terms of both time press'ire and context effects.

Next, the impact

of time pressure and context on the relative accuracy of decisions will be
discussed.

Finally, the relationship between processing measures and accuracy

will be examined to see how it varies over

both the time pressure and context

conditions.
A key hypothesis of this study is that people will adapt their behavior
to the demands of the decision environment in a fashion consistent with the
results of the simulations.

As noted, to provide the strongest possible test

of adaptiveness, we utilized a within-subjects experimental design.

~

.~

.

~

.'

Subjects,

<-----Page 33----->Adaptive Decisions
31
however, may have to experience several examples of different types of
decision problems before settling on a preferred decision strategy for a
particular type of problem.

Consequently, we present the results calculated

both for the block of 20 decision problems seen first by the decision maker,
and the block of the last 20 decisions (Recall that the sets of options
representing the four combinations of time pressure and context were presented
in a random order to the subjects, so that problems corresponding to each of
the four time pressure-variance combinations were distributed essentially
equally over the two blocks).
Process measures.

Information acquisition behavior can be characterized

in a wide variety of ways.

One can examine the amount of information

acquired, the sequence of information acquired, and the time spent acquiring
information (See Klayman (1983) for a discussion of various information
acquisition measures).

For the purposes of this paper, we adopt eight

measures of decision processes.

The first measure is the total number of

times information boxes were opened for a particular decision.

This is one

measure of the total amount of search, denoted acquisitions (ACQ).

A second

measure of total amount of search is the total time spent looking at
information in all the opened boxes (BOX TIME).

A third measure, which is

directly relevant to the acceleration of processing, is the time spent per
item of information acquired (TPERACQ).
The fourth and fifth measures reflect the relative attention devoted to
specific types of information in the decision environment.

One measure,

denoted (PTMI), reflects the proportion of the total box time that was spent
in boxes involving the most important attribute of a particular decision
problem.

We defined the attribute (outcome) with the largest weight

(probability of occurrence) as the most important attribute.

The other

<-----Page 34----->Adaptive Decisions
32
*

measure, denoted (PTPROB), is the proportion of time spent on probability
information as opposed to information about payoff values.
The sixth measure is based on the sequence of information acquisitions.
Given the acquisition of a particular piece of information, the next piece of
information acquired might involve the same alternative but different
attribute (an alternative, holistic, or a Type 1 transition), or the same
attribute but a different alternative (an attribute, dimensional, or Type 2
transition).5

A simple measure of the relative amount of alternative-based

(Type 1) and attribute-based (Type 2) transitions isprovided by calculating
the number of Type 1 transitions minus the number of Type 2 transitions
divided by the sum of Type 1 and Type 2 transitions (Payne, 1976).

This

measure of the relative use of alternative-based versus attribute-based
processing ranges from a value of -1.0 to +1.0.

A more positive number

indicates relatively more alternative-based processing, while a more negative
number indicates relatively more attribute-based processing.

This measure of

sequence of search is denoted (PATTERN).
Finally, the last two measures reflect the variances in the proportions
of time spent on each alternative (VAR-ALTER) and each attribute (VAR-ATTRIB),
respectively.

Note that more compensatory decision rules, e.g., WADD, EQW,

and MCD, imply a pattern of information acquisition that is constant (low in
variance) across alternatives and attributes.

In contrast, heuristic

strategies, like EBA, lexicographic, and satisficing, imply more variance in
processing across alternatives and attributes.
Table 5 presents the means for each of the eight process measures as a
function of time pressure (No Time Pressure vs. 15 sec.), decision context
(Low variance vs. High variance), and block of decision problems (1st half vs.
2nd half.).

U'2.

The data were analyzed with three within-subjects factor (time

<-----Page 35----->Adaptive Decisions

33
pressure, context, and block) analyses of variance.

The results presented in

Table 5 will be discussed first in terms of time pressure effects, then
context effects, and finally the relationships among time pressure, context,
and decision processing will be examined.

Insert Table 5 about here

Time pressure and processing.

As would be expected, the subjects

acquired fewer items of information (ACQ) in the time constrained choice
environments (M - 35.0 vs. M
*

16.7, F -378.44,

p < .01).6

Subjects also

spent less overall time looking at information (BOXTIME) in the time pressured
problems (M
vs. MH

*

=

-

25.7 vs. M 8.1 sec., F

-

324.22, p < .01).

Both ACQ (M

23.8, F - 24.39, p < .01) and BOXTIME (m - 18.7 VS. m

-

28.9

-

15.1, f

22.05, P < .01) were also smaller for the last block of 20 decision problems
compared to the first block of 20 decision problems.

This finding was

qualified by block by time pressure interactions for both ACQ (F -20.15,
.01) and BOXTIME (F

p <

19.31, p < .01), which simply show that the amount of

=

information acquisition did not vary much over blocks in the high time
pressure condition, but that less information was acquired in the second block
*

with no time pressure.
One major hypothesis regarding time pressure and decision making is that

*

people will adapt to time constraints by accelerating their processing of
items of information.

The results for the time per acquisition variable

(TPERACQ) indicate that people did process information significantly faster
under time pressure (M

-

.67 vs. M -. 49 sec., F -217.36,

p < .01).

In

addition, time per acquisition was smaller CM -. 60 vs. M - .57 sec., F
7.51,-p < .01) for the second block of trialIs than the first, although this
was qualified by a block by time pressure interaction (F -3.87,

p < .05)

<-----Page 36----->Adaptive Decisions
34
shoving that the decrease over blocks only occurred in the no time pressure
condition.

Thus, our results are consistent with those of Ben Zur and

Breznitz (1981) concerning the acceleration of processing.
Another hypothesis regarding time pressure, examined by many
researchers, concerns the filtration of information.

That is, do people focus

more on the most important information under time pressure?

The proportion of

time spent examining items of information involving the most likely outcome
(PTMI) in this study was significantly greater under time pressure (M
vs. M

=

.40, F

9.83, p < .01).

=

interactions involving block.

.37

-

There were no effects of block or

Note also that the proportion of time spent on

probabilities (PTPROB) was greater for the time pressured problems CM - .25
vs. M - .29, F

18.14, p < .01).

=

The proportion of time spent on

probabilities also increased slightly from the first block to the second CM=
.26 vs. M

.28), and there were no interactions involving block.

These

results clearly support the filtration hypothesis.
Beyond evidence for acceleration and filtration of processing, our
results also suggest a shift in information processing strategies as a
'V.

function of time pressure.

Such a shift is crucial evidence for adaptivity.

The PATTERN variable, which depicts the extent to which ccquisitions are
alternative-based or attribute-based, showed an effect of time pressure, with
processing becoming more attribute-based under higher ti me pressure CM
vs. M -

-

.28, F

-

=

-.22

3.55, p < .059) (Recall that more negative values of this

variable correspond to more attribute-based processing).

There were no main

effects or interactions involving block on this variable.

The variance in the

proportion of time spent processing the various alternatives (VAR-ALTER)
showed no effects due to time pressure, although there was a tendency for this
variance to increase from the first block to the second (M

.29 vs. M

=.32,

<-----Page 37----->Adaptive Decisions
35

F

4.57, p < .05).

Finally, the variance in the proportion of time spent

processing the attributes (VAR-ATTRIB) showed an effect due to time pressure,
with greater variance under nigh time pressure (H
p < .05).
h.

*

.32 vs. H

.31 vs. HM

-

.38, F

-

5.98,

This proportion also rose from the first block to the second (H
-

.38, F

-

-

12.83, p < .01) and shoved a three way interaction

between time pressure, block, and variance that is not easily interpretable (F
5.57, p < .05).

However, the time pressure results are the most crucial

here, and it is important to note that the shift in information processing
behavior is in a direction that is consistent with greater use of attributebased heuristic rules under time pressure.

There is more attribute-based

processing and more variance in processing in the time constrained decision
problems.
To summarize, we found evidence that people adapted to time pressure by
accelerating processing, focusing processing, and by changing the pattern
(strategy) of processing toward more attribute-based heuristics.
Context effects on processing.

The context variable (Low variance in

probabilities versus High variance in probabilities) also had a significant
effect on a variety of process measures.
31.02, p < .01), ACQ (M

=

28.9 vs. HM

acquisition (M -. 60 vs. M - .57, F

BOXTIME (H

23.8, F

-7.21,

=

=

19.2 vs. M

=

14.6,

F

36.39, p < .01), and time per

p < .01) were all significantly

less for problems involving a higher degree of variance in probabilities.
These effects were all qualified by significant variance by time pressure
interactions, showing that the decrease due to higher variance in
probabilities was manifested only in the low time pressure condition (F
21.36, p < .01, F -12.91,

p < .01, and F - 12.56, p < .01 respectively).

In

addition, there was more focus on the largest probability (PTMI) when there
was high variance in probabilities CM - .34 vs. M

-

.44,

F

-

92.34, p < .01),

<-----Page 38----->Adaptive Decisions
36
although there was no significant difference in the proportion of time spent
on probabilities (F

-

1.34, n.s.).

There were also no interactions involving

variance for the latter two variables.
*

The largest impact of the context manipulation was on the processing

variables:

PATTERN, VAR-ATTRIB, and to a lesser extent VAR-ALTER.

The

predominant pattern of processing became significantly more attribute-based
for the high variance gamble sets (M

-

-.12 vs. H

-

.37, F - 54.60, p < .01).

The variance in the proportion of time spent on attributes was also much
greater for the high variance option sets (M
.01).

=

.22 vs. M .49, F

=

119.13, p <

Finally, there was more variance in processing across alternatives when

the decision problems involved probabilities that differed greatly (M -. 28
vs. M =.33, F
.1

=

6.83, p < .01).

There were no two-way interactions involving

the context manipulation for these three dependent variables.
As noted earlier, the simulations suggest that changes in a context
variable, such as the variance of the probabilities associated with the
options in a choice set, do not alter the effort levels of decision
strategies.

On the other hand, the accuracy of strategies is strongly

affected by context in these simulations.

Prior work investigating contingent

decision processing has demonstrated that decision makers are influenced by
task variables that impact effort (e.g., number of alternatives).

The present

results clearly demonstrate that people will also shift processing strategies
with variations in context variables that impact on the potential relative
accuracy of heuristics, but not on their relative effort.

Such context

effects have rarely been shown.
In sum, the results for both the time pressure (task) manipulation and
the variance (context) manipulation indicate that people adapt their decision

<-----Page 39----->Adaptive Decisions
37
processes to changes in the decision environment impacting on both the
relative effort and the relative accuracy of choice heuristics.
Accuracy of choice.

As noted in our discussion of the Monte-Carlo

simulation experiment, there are a number of ways in which accuracy or quality
of choice can be measured.

For consistency with the prior simulation work on

accuracy of heuristics Cmhorngate, 1980; Johnson & Payne, 1985), we used a
measure of accuracy based on the maximization of expected value (EV).

The

main advantage of EV as an accuracy measure is that values from individual
decision makers are not required to operationalize the rule.

Of course, a

maximization of EV criterion is at best only a first approximation to the

a'

optimal choice, since it does not reflect individual differences.
*

The primary measure of accuracy we used is essentially the same as the

.

relative performance peasure of accuracy used in Study 1.

That is, as above

we defined a measure that is a measure of the proportion of the maximum
possible improvement in EV obtained over that which would be expected based on
The closer the value of relative accuracy is to 1.0,

a random choice rule.

the nearer the responses are to a strict maximization of expected value rule.
The average relative accuracy scores for the 16 subjects as a function
of time pressure, variance in probabilities, and decision block are presented
in Table 6.

While the relative accuracy scores are higher under no time

pressure (M - .62 vs. M
.48 vs. M,-

.62, F

-

=

.48, F

=

8.32, p < .01) and in the second block CM

7.23, p < .01), it is clear from Table 6 that the

decrement in performance is concentrated in the responses to the earlier
(first block) problems involving time pressure.

By the latter block, people

had adapted to time pressure and had improved their performance to levels
similar to those obtained in the no time pressure condition.
by the significant block by time pressure interaction (F

*1Lo

-

This is verified

10.73, p (.01).

<-----Page 40----->Adaptive Decisions
38
- -

-

- -

-

- -

-

- -

-

- -

-

Insert Table 6 about here

Relationship of Process to Accuracy.

A major conclusion reached from

the Monte-Carlo simulations of effort and accuracy in choice was that a
decision maker who used heuristics would have to adaptively choose among
decision strategies, depending upon the specific choice environment.

The

prior results for process measures and accuracy measures indicate that
subjects in this experiment were influenced by both the task and context
variables.

A major question is whether the adaptiveness in terms of process

is related to improvements in accuracy.
that question. 7

Table 7 presents results that address

The process variable used in Table 7 was the relative amount

of alternative-based versus attribute-based processing (i.e., PATTERN).
Recall that higher values of that variable correspond to more alternativebased processing.

The accuracy measure was the relative accuracy score.

It

is clear from Table 7 that the relationship between pattern of processing and
performance was stronger for the second block decision problems.

It is also

clear that under no time pressure, there is a significant relationship between
relative accuracy and the use of relatively more alternative-based processing.
That result might be expected, given that the relative accuracy score uses EV
maximization, which is an alternative-based decision rule, as a criterion for
accuracy.
The result of the greatest interest, however, is that the relationship
between processing a id accuracy changes sign for those decision problems.
involving both time pressure and high variance in the probabilities.

Note

that it is exactly the combination of high time pressure and high variance in
probabilities where the Monte-Carlo simulation indicated that attribute-based
forms of processing, e.g., the EBA strategy and lexicographic rule, were

<-----Page 41----->Adaptive Decisions
39
better than either one of the alternative-based strategies, i.e., the weighted
additive or equalweight additive rules (See Table 3, Dominance Yes, Variance
High, Time Pressure Severe).
*

In other words, a person striving to maintain

accuracy in a severely time pressured, high variance decision environment
should, according to the simulation results, utilize more attribute-based
processing.

Our results show that the use of relatively more attribute-based

processing led to better relative accuracy for exactly those time pressured,
high variance decision problems (a negative correlation implies that lower
values for PATTERN, signifying more attribute-based processing, are associated
with higher relative accuracy).
Insert Table 7 about here

Discussion
The central result from Study 2 is that people exhibit a surprising
degree of adaptivity in their decision behavior.
*

Decision processes were

sensitive to a context variable that influences the relative accuracy of
heuristics, without impacting on relative effort.

Decision processes were

also sensitive to the important task variable of time pressure.

These

findings of adaptivity are particularly strong in that they were exhibited by
the same subjects on different trials.

Moreover, there was a relationship

between processing strategy and the relative accuracy of choice as a function
*of

changes in the task environment.

Finally, the general pattern of adaptive

behavior was in a direction consistent with the simulation results.
The results dealing with time pressure and decision processes were also
*

of interest.

Support was found for the hypotheses that increased time

pressure would result in (1) acceleration of information processing, (2)
"

filtration of information to be processed, and (3) changes in the choice

*%

,% %

<-----Page 42----->Adaptive Decisions

N.

40

heuristics used to make a decision.

As noted earlier,

supported the acceleration and filtration hypotheses.

prior research has
The present study is

the first to demonstrate clear changes in choice processing strategies as a
function of time pressure.
The fact that there appear to be at least three ways in which people can
adapt to time pressure leads to the following question:

Is there an ordering

to the adaptive strategies people use to deal with time pressures?

That is,

do people first try to deal with time constraints through acceleration and
perhaps filtration of processing?

Selecting an alternative decision process

in response to time pressure may only occur if the first two responses are not
adequate.

The purpose of the third study is to investigate that possibility

by examining a case of less severe time pressure
.-.

~

3:

%Study

Effects of Moderate Time Pressure on Choice

This study examines the extent and direction of adaptive decision
when the amount of time pressure is less severe than that

Pip.,processing

N

investigated in Study 2.

This study also examines the effects of the context

variable dealing with the variance in probabilities.
Method
Subjects.

Ten undergraduates at Duke University served as subjects.

Subjects participated in return for course credit and the chance to win up to

$9.99.
Stimuli and Procedures.

The stimuli and procedures used in this

experiment were the same as those used in Study 2.

The only difference was

that the amount of time available in those decision problems with a time.
constraint was increased to 25 seconds, as opposed to the 15 seconds used in
Study 2.

<-----Page 43----->Adaptive Decisions
41
Results
The measures of process and accuracy used in this study were the same as
those in Study 2.

A summary of both the process and accuracy results for

Study 3 can be found in Table 8.
The results for Study 3 parallel those for Study 2 with respect to items
of information acquired (ACQ) and BOXTIME.

There is a main effect of time

pressure for each, with fewer items of information acquired (M
23.2, F

-

118.6, p.< .01) and less time spent (M

-

37.3 vs. M-

26.2 vs. M - 12.8, F

-

8
124.8, p < .01) under greater time pressure.

The results also support acceleration, in that there is a main effect of
time pressure on time per acquisition (TPERACQ).
more quickly under time pressure CM -. 65 vs. M

People process information
-

.56, F - 71.48, p < .01).

There is some evidence for filtration, although weaker than in Study 2.
There is a marginal main effect of time pressure on proportion of time spent
on the most likely outcome (PTMI), with this proportion greater under time
pressure CM

=

.31 vs. M

=

.33, F =3.36, p -. 067).

There is no effect of

time pressure on the proportion of time spent on probability information,
however.
Finally, there is very little evidence of time pressure effects on the
pattern of processing.

There is no main effect on the PATTERN measure (F

.03, n.s.) or variance in the proportion of time spent on the various
attributes (F

-

1.89, n.s.).

There is a marginal effect of time pressure on

the proportion of time spent on the various alternatives (VAR-ALTER), with
greater variance under lower time pressure, opposite to the predicted effect
(M

-

.25 vs. M = .22, p = .069).

Hence, unlike the results for Study 2, there

is no evidence in Study 3 that a shift in processing strategies occurred under
time pressure.

This conclusion is reinforced when the correlations between

<-----Page 44----->Adaptive Decisions
42
the relative amount of alternative-based processing (PATTERN) and relative
accuracy are examined across the various time pressure, block, and variance
conditions. 9

As shown in the last row of Table 8, the correlations are all

positive, showing that more alternative-based processing is consistently
associated with greater relative accuracy.

This contrasts to the shift in the

sign of the correlations found in Study 2.
The overall results for the relative accuracy measure also show no main
effect for time pressure (F = .42, n.s.).

However, there is a significant

time pressure by block interaction, again showing that accuracy was only low

in the first block under time pressure (F - 5.05, p < .05).
Although the results for adaptivity of strategy to time pressure are not
-

.

significant, the context variable had similar effects to those of Study 2.
There were main effects of context on acquisitions (ACQ) (F = 14.35, p < .01)
and boxtime (F = 13.47, p < .01) , with lower values in the high variance
There were also effects of context on the process variables.

conditions.

The

predominant pattern of processing becomes more attribute-based (M = .12 vs. M
= -. 13, F

=

45.01, p < .01); there is a greater variance in the proportion of

time spent on the various alternatives (VAR-ALTER) (M = .20 vs. M = .27, F =
10.49, p < .01); and there is greater variance in the proportion of time spent

V .:.

on the various attributes (VAR-ATTRIB) (M

=

.20 vs. M = .34, F = 14.25, p <

.01) for the greater variance condition.

These results are important, for

they show that the subjects in the experiment did show adaptivity to the

variance manipulation by changing strategies.

Hence, the failure to show such

an effect for time pressure is not due to a total failure to obtain
'J

adaptivity.10
To summarize, the results for the no time pressure problems versus
decision problems involving a time pressure of 25 seconds indicated strong

'pk

<-----Page 45----->Adaptive Decisions
43
evidence of acceleration of processing, marginally significant evidence for
filtration of information to be processed, and no evidence of changes in
decision heuristics.

A comparison of the results for Study 3 with those of

Study 2 suggests the hypothesis that people adapt to time pressure in a
ordered sequence of ways.
processing.

First, they try to speed up their rate of

Next they will selectively process information.

Finally, they

will select a different decision or evaluation strategy.
The effects of the context variable replicate those reported for Study
2, and support the conclusion that people will adapt decision processes to
changes in the decision environment that impact the relative accuracy of
heuristics without affecting the relative effort.
General Discussion

N

Past research has shown that the same individual will often employ
diverse strategies in making a decision, contingent on task demands (Payne,
1982).

The use of multiple decision strategies extends to children, as well

as adults (Klayman, 1985).

Similarly, a growing amount of evidence from the

study of human performance in several other cognitive tasks indicates that an
individual may use many different cognitive processes (strategies) to reason
and solve problems (Reder, 1982; Siegler, 1986).
As Siegler (1986) has argued, "children (and adults) have good reasons
to use multiple strategies.

Strategies differ in their accuracy, in how long

they take to execute, in their demands on processing resources, and in the
range of problems to which they apply (p. 1)".

A major problem for current

cognitive research is to be able to better understand and predict when a.
particular strategy will be employed.
This paper has examined the role of effort and accuracy considerations
in the selection of information processing strategies for making a choice.

<-----Page 46----->Adaptive Decisions
44
The general hypothesis is that the selection among strategies is adaptive, in
the sense that a decision maker will choose strategies that are relatively
efficient in terms of effort and accuracy as task and context demands are
varied.

The first part of the paper outlined an approach to modelling the

inpact of task and context variables on decision strategies.

The approach is

based on the use of elementary information processes to measure effort and use
of computer simulation models to examine accuracy and effort tradeoffs.

Study

1 used Monte-Carlo simulation techniques to examine the impact of variations
in several aspects of the choice environment, including the presence or
absence of time pressure, variance in weights, presence or absence of
dominated alternatives, and different problem sizes, on the accuracy and
effort of a variety of choice heuristics.

This simulation identified

strategies which approximate the accuracy of normative procedures while
requiring substantially less effort.

However, no single heuristic did well

across all task and context conditions.

A decision maker striving to maintain

a high level of accuracy with a minimum of effort would have to adaptively
choose from a repertoire of heuristics.
*

Of particular interest was the

finding that under time constraints, several attribute-based heuristics (e.g.,
Elimination-by-aspects) were clearly superior in terms of accuracy to a
normative procedure such as expected value maximization.
Studies 2 and 3 directly tested the degree of correspondence between the
efficient strategies for a given decision problem identified by the
simulations and the actual information processing strategies people use to
make a choice.

People were shown to be highly adaptive in their responses to

changes in the nature of the alternatives available to them, and to the
presence or absence of time pressure.

%

The results for actual decision

<-----Page 47----->Adaptive Decisions

45
behavior tended to validate the models of decision strategies and the
simulation estimates of accuracy and effort in various choice environments.
More specifically, subjects were shown to use several approaches in
adapting to different decision environments.

Subjects acquired less

information, spent less time overall and less time per acquisition, used more
attribute-based processing, and displayed greater variance in the proportion
of time spent on the various alternatives and attributes in situations where
the context variable of variance in the weights (probabilities) was high
rather than low.

Such adaptivity in strategy usage in response to a context

variable demonstrates that people are sensitive to a change in the task
environment that impacts on the relative accuracy of heuristics without
affecting relative effort.
In addition, several effects of time pressure were demonstrated.

Under

moderate time pressure, subjects were shown to accelerate their processing
and, to a lesser extent, to focus on a subset of the available information.
Under severe time pressure, people accelerated their processing, focused on a
subset of the information, and changed their decision strategies.

There was

slightly more attribute-based processing and more variance in the proportion
of time spent on various attributes as time pressure increased.

In addition,

these changes appeared to be appropriate in terms of accuracy, as more
attribute-based processing was associated with higher gains in high time
pressure, high variance in weights environments.

Also interesting is the fact

that the adaptive use of heuristics was greater for the second block of
decision problems.

This suggests that people may learn appropriate heuristics

.4

*.

to use with experience in solving certain types of decision problems.
There are several important aspects of the time pressure results.
First, they provide one of the clearest demonstrations in the literature to

<-----Page 48----->Adaptive Decisions
46
date of adaptivity of processing strategies to time pressure.

Second, the

results of Studies 2 and 3, taken together, imply that there may be a
hierarchy of responses to time pressure.

People may first attempt to simply

accelerate, or speed up their processing.
the same things faster.

That is, they may first try to do

If the time pressure is too great for acceleration to

suffice, individuals may next engage in filtration, focusing on a subset of
the available information.
pressures become extreme.

Finally, people may change strategies when time
The evidence also suggests that such strategy

changes are in the appropriate direction in terms of preserving accuracy while
minimizing effort.
Taken as a whole, the results provide very strong evidence for
adaptivity in decision making.

Individuals change strategies from one choice

problem to the next depending upon the structure of the choice environment for
each problem.

The current studies are the only ones of which we are aware

which provide such extensive within-individual evidence of adaptivity.

This

variability in approach from one problem to the next implies that humans
possess abilities for assessing choice environment properties; characterizing
such abilities would be a fruitful area for study.
The results also provide impressive validation for the conceptual and
simulation approaches outlined in Johnson and Payne (1985).

Subjects not only

change strategies in response to changes in choice environments, but they
appear to change in directions predicted by the simulation.

This implies that

such simulations may be useful in understanding adaptive responses to other
aspects of choice environments, such as the intercorrelation structure of the
attributes (Johnson, Meyer, & Goshe, 1986).

However, certain environmental

properties may be more easily noticed, and hence more adapted to, then others.

*1".g

_!

!

<-----Page 49----->Adaptive Decisions
47
The evidence for adaptive use of heuristics obtained in this study
suggests a picture of the human decision maker that is fairly optimistic in
terms of rational behavior.

People clearly do use choice heuristics that may

lead to violations of certain principles of rationality (Tversky, 1969).

The

use of heuristics may reflect a tradeoff of effort and accuracy, or reflect
the fact that the decision maker has no other choice in some decision
environments than the use of a heuristic (Simon,

1981).

However,

our results

suggest that people can adaptively select from a repertoire of processing
strategies.

That is, people use heuristics that are often appropriate given

task and context factors.

<-----Page 50----->Adaptive Decisions
48
References
Beach, L. R., & Mitchell, T. R. (1978).
of decision strategies.

Academy of Management Review, 3, 439-449.

Ben Zur, H., & Breznitz, S. J.
choice behavior.
Bettman, J. R.

A contingency model for the selection

(1981). The effects of time pressure on risky

Acta Psychologica, 47, 89-104.

(1979). An information processing theory of consumer choice.

Reading, Mass:

Addison-Wesley.

Bettman, J. R., & Park, C. W.

(1980). Effects of prior knowledge and

experience and phase of the choice process on consumer decision processes:
A protocol analysis.

Journal of Consumer Research, 7, 234-249.

Card, S. K., Moran, T. P., & Newell, A. (1983). The psychology of humancomputer interaction. Hillsdale, NJ: Lawrence Erlbaum.
Carpenter, P. A., & Just, M. A.

(1975). Sentence comprehension:

psycholinguistic processing model of verification.

A

Psychological Review,

82, 45-73.
Dawes, R. M.
making.

(1979). The robust beauty of inproper linear models in decision
American Psychologist, 34, 571-582.

Einhorn, H. J., & Hogarth, R. M.
making.

Organizational Behavior and Human Performance, 13, 171-192.

Goldstein, W. M.
5,

choice.

(1975). Unit weighting schemes for decision

(1986). Dimensional strategies for multiattribute binary

Unpublished paper, Center for Decision Research, University of

Chicago.
Hammond, K. R.

(1986). A theoretically based review of theory and research in

judgment and decision making.

Report 260, Center for Research on Judgment

and Policy, Institute of Cognitive Science, University of Colorado.
'5

<-----Page 51----->Adaptive Decisions

49
Huber, 0.

(1980). The influence of some task variables on cognitive

operations in an information-processing decision model.

Acta

Psychologica, 45, 187-196.
Johnson, E. J.
decision.

(1979). Deciding how to decide:

The effort of making a

Unpublished manuscript, University of Chicago.

Johnson, E. J.,

Meyer, R. M., & Goshe, S.

(1986). When choice models fail:

Compensatory representations in efficient sets.

Unpublished manuscript,

Graduate School of Industrial Administration, Carnegie-Mellon University.
Johnson, E. J.,

& Payne, J. W.

(1985). Effort and accuracy in choice.

Management Science, 31, 395-414.
Johnson, E. J.,

Payne, J. W.,

Schkade, D. A.,

& Bettman, J. R.

Monitoring information processing and decisions:

(1986).

The mouselab system.

Unpublished manuscript, Center for Decision Studies, Fuqua School of
Business, Duke University.
Keeney, R. L., & Raiffa, H.

(1976).

Preferences and value tradeoffs.
Klayman, J.

Decisions with multiple objectives:
New York:

Wiley.

(1983). Analysis of predecisional information search patterns.

In P. C. Humphreys, 0. Svenson, & A. Vari (Eds.), Analyzing and aiding
decision processes.
March, J. G.
choice.

(1978).

Amsterdam:

North Holland.

Bounded rationality, ambiguity, and the engineering of

Bell Journal of Economics, 9, 587-608.

Miller, J. G.

(1960). Information input overload and psychopathology.

American Journal of Psychiatry, 116, 695-704.
Payne, J. W.

(1976).

Task complexity and contingent processing in decision

An information search and protocol analysis.

0making:

Behavior and Human Performance,

--

*8Z

Organizational

16, 366-387.

%

<-----Page 52----->Adaptive Decisions
50
Payne, J. W.

(1982). Contingent decision behavior.

Psychological Bulletin,

92, 382-402.
Reder, L. M.

(1982). Plausibility judgments versus fact retrieval:

Alternative strategies for sentence verification.

Psychological Review,

89, 250-280.
Russo, J. E.,
choice.

& Dosher, B. A.

(1983). Strategies for multiattribute binary

Journal of Experimental Psychology:

Learning, Memory, and

Cognition, 9, 676-696.
Siegler, R.

(1986).

Strategy choice procedures and the development of

multiplication skill.
Simon, H. A.

Unpublished manuscript, Carnegie-Mellon University.

(1955). A behavioral model of rational choice.

Quarterly

Journal of Economics, 69, 99-118.
Simon, H. A.
Mass:

(1981). The sciences of the artificial

(2nd Ed.).

Cambridge,

MIT Press.

Svenson, 0.

(1979).

Process descriptions of decision making.

Organizational

Behavioral Human Performance, 23, 86-112.
Svenson, 0.,

Edland, A.,

& Karlson, G.

(In press). The effect of numerical

and verbal information and time stress on judgments of the attractiveness
of decision alternatives.

In L. B. Methlie & R. Sprangue (Eds.),

Proceedings of the Working Conference on Knowledge Representation for

Decision Support Systems.
Thorngate, W.

Amsterdam:

North Holland.

(1980). Efficient decision heuristics.

Behavioral Science, 25,

219-225.
Tversky, A.

(1969). Intransitivity of preferences.

Psychological Review, 76,

31-48.
Tversky, A.

(1972). Elimination by aspects:

Psychological Review, 79, 281-299.

A theory of choice.

<-----Page 53----->Adaptive Decisions

51
*.

Ulvila, J. W.,

& Brown, R. V.

(1982). Decision analysis comes of age.

Harvard Business Review, 60, 130-141.
Wright, P. L.

(1974). The harassed decision maker:

distraction, and the use of evidence.

Time pressures,

Journal of Applied Psychology, 59,

555-561.
Wright, P. L., & Weitz, B.
strategies.
Zakay, D.

Time horizon effects on product evaluation

Journal of Marketing Research, 14, 429-443.

(1985).

choice process.
Zakay, D.,

(1977).

Post-decision confidence and conflict experienced in a
Acta Psychologica, 58, 75-80.

& Wooler, S.

effectiveness.

(1984).

Time pressure, training and decision

Ergonomics, 27, 273-284.

t!

9'Z

Si

-.

.*.*I4* **~

<-----Page 54----->Adaptive Decisions
52
Authors' Notes
The research reported in this paper was supported by a contract from the
Engineering Psychology Program of the Office of Naval Research.
authorship is arbitrary.

The order of

Each author contributed equally to all phases of

this project.
Requests for reprints should be sent to John W. Payne, Center for
Decision Studies, Fuqua School of Business, Duke University, Durham, North
Carolina 27706.

<-----Page 55----->Adaptive Decisions

.r.
.Footnotes

53
1

EIP's can also be used as components in production system models of

decision strategies.

Productions are (condition) --> (action) pairs, where

the action is performed only if the condition is matched.

EIP's could be used

as the actions, and the results of earlier actions could be used as parts of
conditions (e.g., if A and B have been read, then add A and B).
2

To provide insight into the ranges of values possible, the average

number of EIP's required for the weighted additive rule to run to completion
ranged from 28 for the two alternative, two attribute case to 400 for the
eight alternative, eight attribute case.

Comparable figures for the

lexicographic strategy are 21.3 (2 x 2) and 172.5 (8 x 8).
3

*"

The standard error for the effort values in Table 2 is +2.75, and for

the accuracy values in Tables 2 and 3 it is +.029,
4

Subjects took about 50 seconds, on average, when under no time pressure

in the pilot studies.
*represented

Those pilot studies revealed that 15 seconds

substantial time pressure for the subjects.
5

.

p < .05.

1n addition, one could have same alternative, same attribute

transitions (reacquisitions) or different alternative, different attribute
transitions.

These two cases are not particularly germane to our major

hypotheses, however.
6

The degrees of freedom for all of the F-values reported for this study

are 1 and 617.
7

The cell-sizes for the correlations in Table 7 ranged from 64 to 96.

8

For all F-values reported for Study 3, the degrees of freedom are 1 and

9

The cell-sizes for these correlations ranged from 40 to 60.

400.

<-----Page 56----->-.

Adaptive Decisions

.

54
10

Although there were other significant results that paralleled those of

Study 2, they are not reported in detail here.

These were effects of block on

BOXTIME (F = 34.2, p < .01), ACQ (F - 21.86, p < .01), time per acquisition (F
- 20.71, p < .01), and PTMI (F - 5.66, p < .05).

There were block by time

pressure interactions for BOXTIME (F = 22.82, p < .01), ACQ (F
.01), and time per acquisition (F = 11.69, p < .01).
pressure by variance interactions for BOXTIME (F

U

8.47, p < .01) and ACQ (F

4N

v-s

4,.

. ,.A

,SA4N

11.18, p <

Finally, there were time

7.58, p < .01).

r,

=

1

U

<-----Page 57----->Adaptive Decisions
55
Table 1
Elementary Information Processing Operations (EIPs) used by Johnson and Payne
(1985)

READ

Read an alternative's value on an attribute into 5Th

COMPARE

Compare two alternatives on an attribute

DIFFERENCE

Calculate the size of the difference of two alternatives for
an attribute

--

ADD

Add the values of an attribute in STh

PRODUCT

Weight one value by another (multiply)

ELIMINATE

Remove an alternative from consideration

MOVE

Go to next element of external environment

CHOOSE

Announce preferred alternative and stop process

~A6

L

-

a

<-----Page 58----->Adaptive Decisions
56
Table 2
Simulation Results for Accuracy and Effort of Heuristics in the No Time
Pressure Decision Problems

Task Environments

WADD

EQW

LEX

LEXSEMI

EBA

MCD

SAT

EBA+ADD

EBA+MCD

Low

High

Low

High

1.01

1.0

1.0

1.0

(160)2

(160)

(160)

(160)

.89

.67

.41

.27

(85)

(85)

(85)

.69

.90

.67

.90

(60)

(60)

(60)

(60)

.71

.87

.64

.77

(79)

(78)

(79)

.67

.66

.54

(87)

(88)

(82)

.62

.48

.07

.09

(148)

(148)

(141)

(140)

.32

.31

.03

.07

(49)

(49)

(61)

.84

.79

.69

.66

(104)

(106)

(102)

(102)

.69

.59

.29

.31

(89)

(89)

(86)

(86)

0

RAND
iRelative Accuracy.
2

Unweighted operations count.

7

No

Yes

Dominance Possible:
Variance in Probs:

Decision
Strategy

.-

0

0

(85)

(81)
.56
(82)

(61)

0

<-----Page 59----->Adaptive Decisions

57
Table 3
Simulation Results for Accuracy of Heuristics under Time Pressure

Task Environments

*

NO

YES

Dominance Possible:

Decision

Variance in Probs:

LOW

Strategy

Time Pressure

Low

Mod.

HIGH

LOW

HIGH
Sev.

Low

Mod.

Sev.

Low

Mod.

Sev.

Low

Mod.

Sev.

WADD

.911 .80

.28

.91

.80

.28

.90

.77

.12

.92

.82

.24

EQW

.88

.82

.72

.66

.65

.55

.41

.34

.26

.24

.25

.18

LEX

.70

.69

.47

.90

.90

.59

.69

.68

.48

.90

.90

.60

LEXSEMI

.71

.66

.40

.87

.83

.49

.63

.59

.43

.76

.75

.51

EBA

.70

.68

.49

.76

.73

.65

.63

.60

.48

.67

.67

.61

MCD

.58

.49

.23

.44

.35

.17

.03 -. 01

-. 02

.04

.03

.02

SAT

.38

.34

.30

.32

.34

.23

.03

.04

.06

.07

.05

.04

EBA+ADD

.86

.79

.43

.86

.82

.48

.73

.66

.27

.75

.74

.43

EBA+MCD

.74

.65

.44

.67

.60

.49

.35

.32

.27

.40

.41

.36

0

0

0

0

0

0

0

0

0

0

0

0

SRAD

iAccuracy is measured relative to the performance of the WADD rule in the no time pressure
condition.

SJ,1

<-----Page 60----->Adaptive Decisions
58
Table 4
Sample of Stimulus Sets Used in Study 2

LOW VARIANCE SETS

I..

p.

Set 1:

Probs:

Gl:

HIGH VARIANCE SETS

.22

.26

.24

.28

Amts:

8.73

7.83

1.74

G2:

Amts:

7.54

4.64

G3:

Amts:

5.37

G4:

Amts:

Set 5:

Probs:

G:

Set 1:

Probs:

.03

.02

.09

.86

8.91

Gl:

Amts:

5.41

8.39

7.43

7.76

5.11

6.73

G2:

Amts:

8.99

7.29

2.05

7.78

5.41

6.03

3.55

G3:

Amts:

1.48

3.53

1.79

7.06

5.07

7.51

5.12

2.50

G4:

Amts:

1.21

2.09

0.81

7.88

.20

.31

.20

.29

Set 5:

Probs:

.20

.04

.07

.69

Amts:

4.39

5.59

3.20

9.90

Gl:

Amts:

6.86

1.18

4.96

0.84

G2:

Amts:

8.33

3.40

3.29

6.99

G2:

Amts:

1.38

3.34

8.49

2.91

G3:

Amts:

5.50

7.10

0.28

9.07

G3:

Amts:

8.04

1.07

0.54

6.85

G4:

Amts:

3.67

3.10

2.29

6.56

G4:

Amts:

1.00

0.72

0.71

8.47

Set 9:

Probs:

.27

.15

.31

.27

Set 9:

Probs:

.02

.56

.01

.41

Gl:

Amts:

7.21

9.83

4.00

7.18

Gl:

Amts:

1.89

6.77

2.92

5.62

G2:

Amts:

1.36

1.64

0.87

2.38

G2:

Amts:

4.31

2.77

7.13

2.46

G3:

Amts:

1.06

1.58

9.77

9.70

G3:

Amts:

3.24

8.10

4.94

1.83

G4:

Amts:

3.52

5.96

8.27

9.85

G4:

Amts:

9.07

7.00

1.00

4.21

<-----Page 61----->Adaptive Decisions
59
Table 5
Process Measures as a Function of Time Pressure, Context, and Decision Block

Time Pressure:

1st

2nd

st

ACQ

46.6

35.3

BOXTIME

37.2

TPERACQ

LOW

"p

LOW

HIGH

1st

2nd

35.1

27.6

18.3

17.6

15.6

25.0

23.9

18.0

8.7

8.4

7.8

7.4

.754

.668

.650

.622

.492

.487

.507

.493

PTMI

.322

.335

.419

.417

.347

.352

.446

.480

PTPROB

.232

.252

.245

.285

.283

.297

.281

.289

-. 111

-. 107

-. 319

-. 329

-. 103

-. 164

-.446

-.408

VAR-ALTER

.015

.015

.018

.022

.020

.015

.020

.019

VAR-ATTRIB

.181

.200

.343

.559

.210

.281

.495

.534

1st

2nd
15.4

ACQ

=

Number of information boxes examined.

BOXTIME

f

Average time spent examining information boxes.

TPERACQ

f

Time per information acquisition.

PTMI

f

Proportion of time on the most important attribute.

PTPROB

f

Proportion of time on the probability information.

PATTERN

=

Index reflecting relative amount of attribute-based (-) and
alternative-based (+) processing.

VAR-ALTER

=

Variance in the proportion of time spent on each alternative.

VAR-ATTRIB -

"p

15 sec

HIGH

2nd

PATTERN

*

No Time Pressure

Variance:
Block:

Variance in the proportion of time spent on each attribute
(including both payoff and probability information).

<-----Page 62----->Adaptive Decisions
60
Table 6
Mean Relative Accuracy as a Function of Time Pressure, Context, and Decision
Order

Time Pressure:
Variance%

15 seconds
LOW
HIGH

No Time Pressure
LOW
HIGH

MEAN

MEAN
Relative Accuracy (1st half)

.694

.585

.628

.269

.398

.333

Relative Accuracy (2nd half)

.609

.611

.610

.616

.643

.629

Relative Accuracy (Total)

.643

.595

.442

.520

MEAN

.619

MEAN

=.481

<-----Page 63----->Adaptive Decisions
61
Table 7
Correlation between Pattern of Processing and Relative Accuracy as a Function
of Time Pressure, Context, and Decision Block

Time Pressure:

Variance:

No Time Pressure

15 Seconds

LOW

HIGH

LOW

HIGH

1st half

.10

.06

.20

.10

2nd half

.41*

.30*

.31*

Decision Order

*Significant, p < .05.
V.

I

,.

-.20( .08)

<-----Page 64----->Adaptive Decisions

62
Table 8
Summary of Process and Accuracy Results for Study 3

No Time Pressure
LOW
HIGH
1st
2nd
1st
2nd

1st

2nd

HIGH
lst
2nd

ACQ

45.3

36.6

38.5

27.6

24.9

22.9

23.3

21.9

BOXTIME

37.9

22.9

27.9

16.9

13.9

12.6

13.0

11.6

TPERACQ

.768

.643

.724

.607

.567

.559

.565

.538

PTMI

.283

.282

.325

.351

.260

.322

.361

.384

PTPROB

.235

.214

.251

.253

.233

.237

.244

.238

PATTERN

.089

.135

-.136 -.079

.087

.175

VAR-ALTER

.011

.013

.017

.018

.012

.013

.013

.016

VAR-ATTRIB

.205

.198

.253

.338

.187

.225

.342

.445

Relative Accuracy

.541

.474

.508

.450

.381

.664

.252

.490

Correlation Of

.18

.49*

.12

.29

.30*

.42*

.09

.33*

Process
.,

Time Pressure:
Variance:
Decision Block:

25 Sec.
LOW

-.148 -.133

Accuracy

Relative Accuracy & Pattern

*

h9

P < .05

<-----Page 65----->Adaptive Decisions
63
Figure Caption
Figure 1.

Example of stimulus display with time pressure clock.

<-----Page 66----->P,!.

W _1

.

._

..

'4'

N,.b

-A

...

..

,w

r

a. 'U-

W

-1,

, rv

r

w

Jwr

t

l w.

an

uL"u = -

...

-.

.

.

-

-.

jr-'

't.,,l

-

<-----Page 67----->January 1986

OFFICE OF NAVAL RESEARCH
Engineering Psychology Program
TECHNICAL REPORTS DISTRIBUTION LIST
OSD

V

CAPT Paul R. Chatelier
Office of the Deputy Under Secretary
of Defense
OUSDRE (E&LS)
Pentagon, Room 3D129
Washington, D. C. 20301

J. Randy Simpson
Statistics Program Code 1111SP
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000
Dr. Lyle D. Broemeling

Department of the Navy
Engineering Psychology Program
Office of Naval Research
Code 1142EP
800 North Quincy Street
Arlington, VA 22217-5000 (3 copies)

Code 1111SP
Office of Naval Research
800 N. Quincy Street
Arlington, VA 22217-5000
Information Sciences Division
Code 1133
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000

Aviation & Aerospace Technology
Programs
Code 121
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000

CAPT William M. Houk
Commanding Officer
Naval Medical R&D Command
Bethesda, MD 20814-5055

Physiology and Neurobiology Program
Office of Naval Research
Code 1141NP
800 North Quincy Street
Arlington, VA 22217-5000

Dr. Randall P. Schumaker
NRL A. I. Center
Code 7510ical R&D Command
Naval Research Laboratory
Washington, D.C. 20375-5000

CAPT. P. M. Curran
Code 125
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000
Dr. Charles Holland
Office of Naval Research
Code 1133
800 N. Quincy Street
Arlington, VA 22217-5000

i'%v

-

~-

*%

<-----Page 68----->JANUARY 1986

Department of the Navy
Special Assistant for Marine
Corps Matters
Code OOMC
Office of Naval Research
800 North Quincy StreetWahntD.C
Arlington, VA 22217-5000Wahntn
Mr. R. Lawson
ONR Detachment
1030 East Green Street
Pasadena, CA 91106-2485

Dr. James McMichael
Office of the Chief of Naval
Operations, 0P987H
Technology Assessment Division
205
0.C 235
Mr. John Davis
Combat Control Systems Department
Code 35
Naval Underwater Systems Center
Newport, RI 02840

CDR James Offutt
Office of the Secretary of Defense
Strategic Defense Initiative Organization
Washington, D.C. 20301-7100

Human Factors Department
Code N-71
Naval Training Systems Center
Orlando, FL 32813

Director
Technical Information Division
Code 2627
Naval Research Laboratory
Washington, D.C. 20375-5000

Mr. Norm Beck
Combat Control Systems Department
Code 35
Naval Underwater Systems Center
Newport, RI 02840

Dr. Michael Melich
Conmmunications Sciences Division
Code 7500
Naval Research Laboratory
Washington, D.C. 23075-5000

Human Factors Engineering
Code 441
Naval Ocean Systems Center
San Diego, CA 92152

Dr. J. S. Lawson, Jr.
4773-C Kahala Avenue
Honolulu, HI 96816
Dr. Neil McAlister
Office of Chief of Naval Operations
Commnand and Control
OP-094H
Washington, D. C. 20350
Dr. A. F. Norcio
Computer Sciences & Systems
Code 7592
Naval Research Laboratory
Washington, DC 20375-5000-

Dr. Gary Poock
Operations Research Department
Naval Postgraduate School
Monterey, CA 93940
Mr. H. Talkington
Engineering & Computer Science
Code 09
Naval Ocean Systems Center
San Diego, CA 92152
CDR Paul Girard
Commnand & Control Technology
Department, Code 40
Naval Ocean Systems Center
San Diego, CA 92152

<-----Page 69----->-.

~~~~~~

-

-

-IYT~
-Vf
f -u- -

-

-

.

JANUARY 1986

Department of the Navy
Commander
Naval Air Systems Command
Crew Station Design
NAVAIR 5313
Washington, D. C. 20361

Mr. Paul Heckman
Naval Ocean Systems Center
San Diego, CA 92152
Dr. William Uttal
Naval Ocean Systems Center
Hawaii Laboratory
P. 0. Box 997
Kailua, HI 96734

Mr. Philip Andrews
Naval Sea Systems Command
NAVSEA 61R
Washington, D. C. 20362

Dr. A. L. Slafkosky
Scientific Advisor
Commandant of the Marine Corps
Washington, D. C. 20380

Aircrew Systems Branch
Systems Engineering Test
Directorate
U.S. Naval Test Center
Patuxent River, MD 20670

Dr. L. Chmura
Computer Sciences & Systems
Code 7592
Naval Research Laboratory
Washington, D.C. 20375-5000

Mr. Milton Essoglou
Naval Facilities Engineering
Command
R&D Plans and Programs

Dr. Michael Letsky

Code 03T

Office of the Chief of Naval
Operations (OP-O1B7)
Washington, D.C. 20350

Hoffman Building II
Alexandria, VA 22332
CAPT Robert Biersner
Naval Biodynamics Laboratory
Michoud Station
Box 29407
New Orleans, LA 70189

Professor Douglas E. Hunter
Defense Intelligence College
Washington, D.C. 20374
CDR C. Hutchins
Code 55
Naval Postgraduate School
Monterey, CA 93940

Dr. Arthur Bachrach
Behavioral Sciences Department
Naval Medical Research Institute
Bethesda, MD

Dr. Stanley Collyer
Office of Naval Technology
Code 222
800 North Quincy Street
Arlington, VA 22217-5000

Dr. George Moeller
Human Factors Engineering Branch
Naval Submarine Base
Submarine Medical Research Lab.
Groton, CT 06340

Professor Michael Sovereign
Joint Command, Control &
Communications Curriculum
Code 74
Naval Postgraduate School
Monterey, CA 93943

3

<-----Page 70----->JANUARY 1986

Department of the Navy
Head
Aerospace Psychology Department
Naval Aerospace Medical Research Lab
Pensacola, FL 32508
Commanding Officer
Naval Health Research Center
San Diego,.CA 92152

Dean of the Academic Departments
U.S. Naval Academy
Annapolis, MD 21402
CDR W. Moroney
Naval Air Development Center
Code 602
Warminster, PA 18974

Dr. Harry Crisp
Dr. Jerry Tobias
Auditory Research Branch
Submarine Medical Research Lab
Naval Submarine Base
Groton, CT 06340
Dr. Robert Blanchard
Code 71
Navy Personnel Research and
Development Center
San Diego, CA 92152-6800
LCDR T. Singer
Human Factors Engineering Division
Naval Air Development Center
Warminster, PA 18974
Mr. Jeff Grossman
Human Factors Division, Code 71
Navy Personnel R&D Center
San Diego, CA 92152-6800
LT. Dennis McBride
Human Factors Branch
Pacific Missle Test Center
Point Mugu, CA 93042
Dr. Kenneth L. Davis
Code 1114
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000
LCDR R. Carter
Office of Chief on Naval Operations
(OP-OlB)
Washington, D.C. 20350

Code N 51
Combat Systems Department
Naval Surface Weapons Center
Dahlgren, VA 22448
Mr. John Quirk
Naval Coastal Systems Laboratory
Code 712
Panama City, FL 32401
Human Factors Branch
Code 3152
Naval Weapons Center
China Lake, CA 93555
CDR Kent S. Hull
MS 239-21
NASA/Ames Research Center
Moffett Field, CA 94035
Dr. Rabinder N. Madan
Code 1114SE
Office of Naval Research
800 North Quincy Street
Arlington, VA 22217-5000
Dr. Eugene E. Gloye
ONR Detachment
1030 East Green Street
Pasadena, CA 91106-2485

<-----Page 71----->JANUARY 1986

Dr. Glen A1lgaler
Artificial Intelligence Branch
Code 444
Naval Electronics Ocean System Center
San Diego, CA 921525

Department of the Air Force

Dr. Steve Sacks
Naval Electronics Systems Command
Code 61R
Washington, D.C.. 20363-5100

Dr. A. Fregly
U.S. Air Force Office of
Scientific Research
Life Science Directorate, NL
Bolling Air Force Base
Washington, D.C. 20332-6448

Dr. Kenneth R. Boff
AF AMRL/HE
Wright-Patterson AFB, OH 45433

Dr. Sherman Gee
Command and Control Technology, (Code 221)
Office of Naval Technology,
800 N. Quincy Street
Arlington, VA 22217-5000
Dr. Robert A. Fleming
Human Factors Support Group
Naval Personnel Research & Development Ctr.
1411 South Fern Street
Arlington, VA 22202

Mr. Charles Bates, Director
Human Engineering Division
USAF AJRL/HES
Wright-Patterson AFB, OH 45433
Dr. Earl Alluisi
Chief Scientist
AFHRL/CCN
Brooks Air Force Base, TX 78235
Dr. J. Tangney
Directorate Life Sciences
AFSOR
Bolling AFB
Washington, D.C. 20032-6448

Department of the Army
Dr. Edgar M. Johnson
Technical Director
U.S. Army Research Institute
Alexandria, VA 22333-5600

Mr. Yale Smith
Rome Air Development
Center, RADC/COAD
Grifflss AFB
New York 13441-5700

Technical Director
U.S. Army Human Engineering Laboratory
Aberdeen Proving Ground, MD 21005
Director, Organizations and Systems
Research Laboratory
U.S. Army Research Institute
5001 Eisenhower Avenue
Alexandria, VA 22333-5600

Dr. A. D. Baddeley
Director, Applied Psychology
Unit
Medical Research Council
15 Chaucer Road
Cambridge, CB2 2EF England

Dr. Milton S. Katz
Director, Basic Research
Army Research Institute
5001 Eisenhower Avenue
Alexandria, VA 22333-5600

Dr. Kenneth Gardner
Applied Psychology Unit
Admiralty Marine Tech. Estab.
Teddington, Middlesex
TW11 OLN
England

S

<-----Page 72----->JANUARY 1986

.Other Government Agencies
Dr. H. C. Montemerlo
Information Sciences &
Human Factors Code RC
NASA HQS
Washington, D.C. 20546

Dr. Donald D. Hoffman
University of California
(Irvine)
School of Social Sciences
Irvine, CA 92717

Dr. Alan Leshner
Deputy Division Director
Division of Behavioral and
Neural Sciences
National Science Foundation
1800 G. Street, N.W.
Washington, D.C. 20550

Dr. T. B. Sheridan
Dept. of Mechanical
Engineering
Massachusetts Institute of
Technology
Cambridge, MA 02139
Dr. Daniel Kahneman
The University of British
Department of Psychology
#154-2053 Main Mall
Vancouver, British Columbia
Canada V6T 1Y7

Defense Technical Information
Center
Cameron Station, Bldg. 5
Alexandria, VA 22314 (2 copies)
Dr. Clinton Kelly
Defense Advanced Research
Projects Agency
1400 Wilson Blvd.
Arlington, VA 22209

Dr. Stanley Deutsch
NAS-National Research Council
(COHF)
2101 Constitution Avenue, N.W.
Washington, D.C. 20418

other Organizations
Dr. Harry Snyder
Dept. of Industrial Engineering
Virginia Polytechnic Institute
and State University
Blacksburg, VA 24061

Dr. Meredith P. Crawford
American Psychological
Association
Office of Educational Affairs
1200 17th Street N.W.
Washington, D.C. 20036

Dr. Amos Tversky
Dept. of Psychology
Stanford University
Stanford, CA 94305
Dr. Amos Freedy
Perceptronlcs, Inc.
6271 Vartel Avenue
Woodland Hills, CA 91364

Dr. Deborah Boehm-Davis
Department of Psychology
George Mason University
4400 University Drive
Fairfax, VA 22030

Dr. Jesse Orlansky
Institute for Defense Analyses
1801 N. Beauregard Street
Alexandria, VA 22311

,

*.--

* *

<-----Page 73----->JANUARY 1986

Other Organizations
Dr. David Van Essen
California Institute of Tech.
Division of Biology
Pasadena, CA 91125

Dr.
New
Box
Las

Dr. James H. Howard, Jr.
Department of Psychology
Catholic University
Washington, D.C. 20064

Mr. Joseph G. Wohl
Alphatech, Inc.
3 New England Executive Park
Burlington, MA 10803

Dr. William Howell .
Department of Psychology
Rice University
Houston, TX .77001

Dr. Marvin Cohen
Decision Science Consortium, Inc.
Suite 721
7700 Leesburg Pike
Falls Church, VA 22043

Dr. Christopher Wickens
Department of Psychology
University of Illinois
Urbana, IL 61801

Dr. Scott Robertson,
Catholic University
Department of Psychology
Washington, D.C. 20064

Dr. Robert Wherry
Analytics, Inc.
2500 Maryland Road
Willow Grove, PA 19090
Dr. Edward R. Jones
Chief, Human Factors Engineering
McDonnell-Douglas Astronautics Co.
St. Louis Division
Box 516
St. Louis, MO 63166

Stanley N. Roscoe
Mexico State University
5095
Cruces, NM 88003

Dr. William B. Rouse
School of Industrial and Systems
Engineering
Georgia Institute of Technology
Atlanta, GA 30332

*

Dr. Lola 1. Lopes
Department of Psychology
University of Wisconsin
Madison, WI 53706
Dr. Joaquin FusterFarxV203
University of California at
Los Angeles
760 Westwood Plaza
Los AneeCA 904Washington,

Ms. Denise Benel
Essex Corporation
333 N. Fairfax Street
Alexandria, VA 22314
Dr. Andrew P. Sage
Assoc. V. P. for Academic Affairs
George Mason University
4400 University Drive
Dr. James Ballas
Georgetown University
Department of Psychology
D.C. 20057

7

<-----Page 74----->JANUARY 1986

Other Organizations
Dr. Richard Pew
Bolt Beranek & Newman, Inc.
50 Moulton Street
Cambridge, MA 02238
Dr. Hillel Elnhorn
Graduate School of Business
University of Chicago
1101 E. 58th Street
Chicago, IL 60637

I

Dr. Robert A. Hummel
New York University
Courant Inst. of Mathematical
Sciences
251 Mercer Street
New York, New York 10012
Dr. H. Mcl. Parsons
Essex Corporation
333 N. Fairfax Street
Alexandria, VA 22314

Dr. Douglas Towne
University of Southern California
Behavioral Technology Lab
1845 South Elena Avenue, Fourth Floor
Redondo Beach, CA 90277

Dr. Paul
Decision
1201 Oak
Eugene,

Dr. James T. Todd
Brandeis University
Waltham, MA 02254

Dr. Kent A. Stevens
University of Oregon
Dept. of Computer.& Info Sc.
Eugene, OR 97403

Dr. John Payne
Graduate School of Business
Administration
Duke University
Durham, NC 27706

Dr. Donald A. Glaser
U. of California, Berkeley
Department of Molecular Biology
Berkeley, CA 94720

Dr. Dana Yoerger
Deep Submergence Laboratory
Woods Hole Oceanographic
Institution
Woods Hole, MA 02543
Dr. Azad Madni
Perceptronlcs, Inc.
6271 Variel Avenue
Woodland Hills, CA

91364

Dr. Tomaso Poggio
Massachusetts Institute of Tech.
Center for Biological Information
Processing
Cambridge, MA 02139
Dr. Whitman Richards
Massachusettes Ins. of Tech
Department of Psychology
Cambridge, MA 02139

Slovic
Research
Street
OR 97401

<-----Page 75----->JANUARY 1986

Other Organizations
Dr. Leonard Adelman
PAR Technology Corp.
Building A
1220 Sunset Hills Road, Suite 310
McLean, VA 22090

Dr. Alexander Levis
Massachusetts Institute of
Technology
Lab Information & Decision Systems
Cambridge, MA 02139

Dr. Michael Athans
Massachusetts Inst. of Technology
Lab Information & Decision Systems
Cambridge, MA 02139

Dr. D. McGregor
Perceptronics Inc.
1201 Oak Street
Eugene, OR 97401

Dr. David Castanon
ALPHATECH, Inc.
111 Middlesex Turnpike
Burlington, MA "01803

Dr. David Noble
Engineering Research Assoc.
8616 Westwood Center Dr.
McLean, VA 22180

Dr. A. Ephremides
University of Maryland
Electrical Engineering Dept.
College Park, MD 20742

Dr. P. Papantoni-Kazakos
University of Connecticut
Department of Electrical Engin.
and Computer Science (U-157)
Storrs, CT 06268

Dr. Baruch Fischhoff
Perceptronics, Inc.
6271 Variel Ave.
Woodland Hills, CA 91367

Professor Wayne F. Stark
University of Michigan
Department of Electrical Eng.
and Computer Science
Ann Arbor, MI 48109

Dr. Bruce Hamill
The Johns Hopkins Univ.
Applied Physics Lab
Laurel, MD 20707

Mr. Robert L. Stewart
The Johns Hopkins University
Applied Physics Laboratory
Laurel, MD 20707

Barry Hughes
Space and Naval Warfare Systems
Code 611
Washington, D.C. 20363-5100

Dr. Kepi Wu
Space and Naval Warfare Systems
Code 611
Washington, D.C. 20363-5100

Dr. E. Douglas Jensen
Carnegie-Mellon University
Computer Science Dept.
Pittsburgh, PA 15213
Dr. David L. Kleinman
Electrical Engineering &
Computer Science Dept.
University of Connecticut
Storrs, CT 06268

0

<-----Page 76----->IN

ilu

