<-----Page 0----->MANAGEMENT SCIENCE

informs

Vol. 52, No. 3, March 2006, pp. 395–409
issn 0025-1909  eissn 1526-5501  06  5203  0395

®

doi 10.1287/mnsc.1050.0468
© 2006 INFORMS

The Effectiveness of Simple Decision Heuristics:
Forecasting Commercial Success for
Early-Stage Ventures
Thomas Åstebro

Joseph L. Rotman School of Management, University of Toronto, 105 St. George Street,
Toronto, Ontario M5S 3E6, Canada, astebro@rotman.utoronto.ca

Samir Elhedhli

Department of Management Sciences, University of Waterloo,
Waterloo, Ontario N2L 3G1, Canada, elhedhli@engmail.uwaterloo.ca

W

e investigate the decision heuristics used by experts to forecast that early-stage ventures are subsequently
commercialized. Experts evaluate 37 project characteristics and subjectively combine data on all cues by
examining both critical ﬂaws and positive factors to arrive at a forecast. A conjunctive model is used to describe
their process, which sums “good” and “bad” cue counts separately. This model achieves a 91.8% forecasting
accuracy of the experts’ correct forecasts. The model correctly predicts 86.0% of outcomes in out-of-sample,
out-of-time tests. Results indicate that reasonably simple decision heuristics can perform well in a natural and
very difﬁcult decision-making context.
Key words: judgment; heuristic; forecast; decision making; statistical prediction; early-stage ventures
History: Accepted by Detlof von Winterfeldt, decision analysis; received September 30, 2004. This paper was
with the authors 3 months for 2 revisions.

1.

Introduction

information feedback on outcomes, where there is a
large number of cues to consider, or where there are
selection effects that bias the ability to observe all outcomes (Goldberg 1968).
Analysts at the Canadian Invention Assistance Program (IAP) are continually faced with the task of
judging the commercial quality of inventions submitted to the program by independent inventors;
this pool represents a particularly difﬁcult decisionmaking context. We were therefore surprised to ﬁnd
that, contrary to expectations based on a large number of studies, IAP analysts could correctly forecast
the likelihood that an invention would reach the market as often as or more often than a linear additive
statistical model (Åstebro and Koehler 2004).
This paper takes these results as its starting point
and seeks to ﬁnd the reasons behind the success of the
IAP experts. Are the decision heuristics they use simple and robust or very complicated? What are those
decision rules, and can we explain why these heuristics perform so well?
We explore the decision heuristics typically employed by the IAP analysts through interviews with
their main analyst, who has close to 20 years of
experience with the organization. We formalize this
heuristic with a conjunctive model that sums a subset of all “good” and “bad” cue counts separately.

Linear additive statistical models of the form 1 X1 +
2 X2 + · · · + n Xn have been shown to better predict outcomes than experts’ implicit decision rules
across many different decision environments, raising the issue of whether “experts” are experts at all
(Dawes et al. 1989). The increased professionalization
of decision making, however, has made people more
reliant on expert opinion in areas such as law, science,
accounting, and health care. To a large extent, experts
in these areas still rely on decision heuristics. Therefore, understanding just how experts make decisions
in deliberate, thoughtful decision-making contexts is
useful.
While most people use heuristics to simplify decision making (Tversky and Kahneman 1974), these
methods have caused decision makers to deviate
signiﬁcantly from optimal decisions (Kahneman and
Tversky 1979). However, others argue that heuristics
might provide fast and reasonably accurate decisions
(Holte 1993, Gigerenzer and Goldstein 1996). Research
on the accuracy of heuristics has implications for the
amount and type of training received by students and
decision makers. On a more fundamental level, the
research also impacts our understanding of how people make calculated decisions. For example, individuals tend to do poorly in situations with little or no
395

<-----Page 1----->396

Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures
Management Science 52(3), pp. 395–409, © 2006 INFORMS

We ﬁrst test the ability of the heuristic to replicate the
analysts’ forecasts. Secondly, we examine how well
this model predicts project outcomes. Although we
capture the apparent heuristics used by the decision
makers through an optimization procedure, we do not
claim to capture their actual thought processes.
Our study differs from many reports of memorychoice or choices made from a menu of information in
laboratory experiments in two ways: (1) We use real
experts as subjects and analyze their actual decisions,
and (2) Considerable deliberation over each judgment
occurs in the decision-making context.

2.

Decision Heuristics and Statistical
Prediction

Using Heuristics
Most decision makers use heuristics to simplify decisions (Tversky and Kahneman 1974) because heuristics lessen complexity by decreasing the number of
choices and cues, thus reducing the computational
effort involved. The degree to which heuristics are
used depends on the decision-making context. People
often use heuristics when there are many alternatives (Payne et al. 1993). When faced with decisions
involving just two or three alternatives and a limited
number of cues, people often process all information
and look at trade-offs between different cue values
(Keeney and Raiffa 1976).1 While heuristics typically
lead to deviations from optimal decisions (Tversky
and Kahneman 1974), they may still be efﬁcient under
the assumption that there are multiple objectives,
including both the desire to be accurate and the desire
to conserve cognitive processing (Payne et al. 1993).2
Experts seem to use heuristics differently than lay
people and may therefore have higher forecasting
accuracy.3 Shanteau (1988) argued that experts break
down larger problems into smaller parts, solve them,
and then put together the partial solutions. Laboratory studies have found that experts, while using
the same amount of cues as students, utilize information much better than students (Ettenson et al.
1987, Shanteau et al. 1991). Shanteau (1992) reported
that expert auditors are not inﬂuenced by irrelevant
information while more inexperienced auditors are.
1

We focus the review on deliberate thoughtful decision-making
contexts rather than social or affective contexts.
2
Herbert Simon termed such a decision-making strategy “satisﬁcing,” thereby combining two goals: that of satisfying a predeﬁned
level of accuracy and that of using sufﬁcient mental computational
processing for a rational decision maker (Simon 1956, 1982).
3
In our setting, the decision maker can accurately be described
as an “expert” in the meaning ascribed by Webster’s Dictionary
(1979): “having, involving, or displaying special skills or knowledge derived from training or experience.”

On the other hand, many studies have shown that
experts, while better than novices, are less able to
forecast/diagnose than simple linear additive models
(for reviews, see Goldberg 1968, Dawes et al. 1989,
Grove and Meehl 1996). Goldberg summarized a host
of studies showing that the amount of professional
training and experience does not generally relate to
judgment accuracy and that the information available
to the decision maker is not related to the accuracy
of resulting inferences. Additional research demonstrated that experts and lay people alike suffer from
the same judgmental biases (Ben-Shakhar et al. 1998,
Chapman and Chapman 1982, Einhorn and Hogarth
1978).
Using Statistical Models
While heuristics can be efﬁcient, a vast body of literature nevertheless has shown that statistical (actuarial) models are at least equal and mostly superior
to judgmental decision making (Dawes et al. 1989,
Grove and Meehl 1996). This conclusion holds true
across a number of decision-making contexts in both
real and experimental settings and for both experts
and less-experienced decision makers. There are several reasons for this common human failure, including the difﬁculties of processing large amounts of data
in parallel, distinguishing between valid and invalid
information, and dealing with sample selection bias
and data truncation. Other reasons are the tendencies to let judgments be affected by recent events and
hindsight bias, to seek only conﬁrmatory data, to not
apply internal models consistently, and to be overconﬁdent (e.g., Chapman and Chapman 1967, Faust 1984,
Fischhoff 1975, Fischhoff and Beyth 1975, Tversky
and Kahneman 1974, Skov and Sherman 1986). Therefore, past evidence has not generally supported the
claim that judgmental decision heuristics have superior value.
Hammond and Summers (1965) summarized research showing that for a considerable number of
decision situations, a simple linear additive model
replicates quite adequately judgments made—despite
reports that decision makers were using highly complex, nonlinear, and interactive rules. Hoffman (1960),
Goldberg (1968), and Camerer (1981) argued that
being able to capture someone’s choices this way does
not mean capturing their actual thought processes—
only that for prediction purposes such thought processes can in most cases be reduced to a linear additive
model.
Characterizing Decision Heuristics
A number of decision heuristics have been reported
on and investigated in cases where people make
deliberate choices (Payne et al. 1993). We brieﬂy
review the most commonly described and note that
they may be combined.

<-----Page 2----->Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures
Management Science 52(3), pp. 395–409, © 2006 INFORMS

The most complex rules are those that combine
a large number of cues interactively and nonlinearly. Goldberg (1968) found that, when prodded,
experts often claim to use such rules to make decisions. The second most complex rule in terms of
information use and processing complexity uses statistically optimized cue weights. While deriving the
rules involves complex optimization, their application is rather straightforward, involving the multiplication of a vector of cue weights with a vector
of cue values. However, Dawes (1979) reported that
equal weights are often as accurate as statistically
derived weights. The reason is that the likelihood
function is often relatively ﬂat over many different
combinations of weights. Other rules similar to equal
weights are those that sum counts (e.g., Alba and
Marmorstein 1987, Russo and Dosher 1983). (Sums of
counts imply equal weights across cues and cue values of either zero or one.) In one study of the accuracy
of equal versus statistically derived weights, Dawes
and Corrigan (1974, p. 105) concluded, “The whole
trick is to decide what variables to look at and then to
know how to add.” Although this might sound simple, ﬁnding which cues are most important involves
some kind of optimization across the cues. If such
methods are possible, then it appears inefﬁcient not to
also compute the weights using optimization. Nevertheless, even if statistically derived weights are available, they might not be used in practice because they
require a greater cognitive burden compared to summing counts of cues.
The next class of heuristics is those that use only
the most important cue, possibly followed by the next
most important, and so on. Some of these heuristics include “elimination-by-aspects,” “take-the-best,”
“lexiographic,” or “1-rule” (Holte 1993, Payne et al.
1993, Tversky 1972). Gigerenzer and Goldstein (1996)
claimed that using only the best classifying cue saves
tremendously on information processing. The ﬁnal
class of rules is that which follows some random rule,
i.e., uses a random cue or selects the choice most
favored.
Simulations have shown that simple heuristics have
accuracies close to more complex rules (Czerlinski
et al. 1999, Gigerenzer and Goldstein 1996, Holte 1993,
Makridakis and Hibon 2000, Thorngate 1980, Weiss
et al. 1990). However, they do not show how decision
makers actually use these rules—if at all—and how
the rules perform in natural settings.

3.

The Decision-Making Context

A Canadian IAP using the system originally developed by Gerald G. Udell was launched at the
Canadian Innovation Centre (CIC) in Waterloo in 1976
(Åstebro and Bernhardt 1999, Åstebro and Gerchak

397

2001). Since 1982, the IAP has used full-time, in-house
analysts and continuously revised and improved its
evaluation methods. The IAP evaluated more than
13,000 projects between 1976 and 2000.
The IAP evaluates potential entrepreneurs and their
projects on 37 different cues and provides a recommendation. The cues and their deﬁnitions employed
during the study period are described in Appendix A.
To have a project evaluated, the entrepreneur ﬁlls out
a questionnaire and pays a fee. In addition to background information about the entrepreneur, the questionnaire asks for a brief description of the idea and
supplementary documentation such as patent applications, sketches, and test reports. The in-house analyst compares the project with similar projects in
their library of previous reviews and collects various relevant information. He or she avoids personal
contact with the entrepreneur beyond the provided
documentation. A particular salient feature is the use
of the vast library of past reviews to do case-based
comparisons. The analyst uses this method of casebased comparison to sort the inventions into ordinal rankings without considering class-based data
such as base rates. Similar decision-making rules that
focus on the case at hand rather than on class-based
data have been shown to produce biased choices in
experiments (Kahneman and Tversky 1973, Tversky
and Kahneman 1983). Edwards and von Winterfeldt
(1986), however, argued that such case comparisons
might work well. For example, diamond evaluators
reduce the decision problem to assessing similarities
and differences with other remembered or currently
available diamonds on key criteria, a way of using
anchoring and adjustment.
The analyst uses these data to subjectively rate the
project on 37 cues. There are three scores for the
37 cues: A—very good, B—average, and C—a critical ﬂaw. The analyst determines an overall score
for the project using intuitive summary judgment.
Because the method of assessing the joint effect of
the cues is judgmental, the overall assessment might
differ across evaluations and evaluators even though
data are identical. The ﬁve possible overall scores are
reported in Table 1. Note that the judgment is one of
ordinal rankings, not a probabilistic forecast. Further,
the analyst conducts the forecast without any knowledge of the base rate probability of success.4 The judgment can be completely ignored by the client, and
the review does not necessarily provide any particular beneﬁt in terms of preferred treatment from third
parties.
4
Data on the base rates were ﬁrst presented to the IAP in 1997
(Åstebro 1997). However, the senior analyst reported that the success rate was considered to be “less than 10%.”

<-----Page 3----->398

Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures

Interviews with the senior analyst at the IAP indicated that the overall assessment is a mixture of two
decision rules. If a project is critically ﬂawed on one
or more cues, either the lowest or next-to-lowest overall score is provided: D or E (i.e., noncompensatory
weighting).5 If, however, there are no (or few) critical ﬂaws, then the scores on the cues are usually
assessed in some additive fashion.6 In addition to the
review by a single expert, a group meeting is conducted where the evaluating expert presents a summary, and a ﬁnal overall score is agreed upon. The
evaluation process typically takes 5–7 hours and can
stretch over several weeks as the analyst collects information from various sources. A report is delivered to
the entrepreneur consisting of scores on the 37 cues,
a verbal representation of the overall score, and a recommendation on commercialization options.
The decision situation contains a large number of
cues that can only be qualitatively assessed, and
the outcome to be predicted is extremely uncertain,
suggesting that accuracy will be low. Furthermore,
decision-relevant information is uncertain and cannot
easily be quantiﬁed. Many of the cues have to be forecasted, for example, “New Competition.” The average
time-to-event outcome, if successful, is approximately
1.5 years indicating a long forecasting horizon and
associated larger error than for shorter horizons such
as weather forecasting (Murphy and Winkler 1984).
The IAP collects information about ventures that have
gone through the review by clipping out newspaper
articles that they might ﬁnd. Feedback on the prediction is therefore biased and spotty. All these conditions suggest large difﬁculties in making accurate
predictions (Goldberg 1968).
On the other hand, there seem to be many conditions and processes in place that are suggested by
researchers to promote good decision making (Fischhoff 1982). First, there is ample time to form an
opinion. Also, the IAP uses a highly structured and
standardized procedure involving problem decomposition where all cues are individually scored and a
record is kept of all scores. Furthermore, the IAP
employed the same senior analyst between 1981 and
2000, and all evaluators were trained by that person in the evaluation procedure; the initial training
took about two days followed by close supervision
over two weeks. The group meeting at the end of
each review might also mitigate potential erroneous
classiﬁcations. In addition, the IAP is paid signiﬁcant
amounts enforcing considerable deliberations. Finally,
5
The overall score D is typically assigned to projects that have little
or no novelty value (i.e., where similar products are already available on the market). The score E is reserved for those with obvious
technical ﬂaws that the IAP believe cannot be corrected.
6

The senior analyst could not provide any further general rules.

Management Science 52(3), pp. 395–409, © 2006 INFORMS

Baker and Albaum (1986) test the reliability of the
instrument used by the IAP across 86 judges and six
products and ﬁnd Cronbach alphas ranging from 0.84
to 0.96, implying high reliability for IAP personnel.

4.

Sampling and Data

4.1. Sampling
The sample frame consisted of all 8,797 valid records
of inventions submitted to the IAP for evaluation during 1976 to 1994. We obtained 1,091 usable responses
from 1,465 randomly sampled entrepreneurs who
could be reached by telephone and asked to participate in the survey, representing an adjusted response
rate of 75%. (For details on sampling plan and sampling bias tests, see Åstebro 2004.) We further added
52 projects to the sample that had gone through the
IAP program and, in addition, had been identiﬁed by
the IAP through newspaper clippings as potentially
successful. We added these because we were concerned that the number of successful ventures would
be too small to estimate meaningful models. Thirtythree of these projects were reported by the inventors as successfully reaching the market. The addition
of the choice-based observations increases the sample mean probability of commercialization from 0.07
to 0.11. We, however, ﬁnd no changes in the underlying distribution of data with the addition of the
choice-based observations. Therefore, there is no bias
in parameter estimates or classiﬁcation accuracy, only
a change in the intercept. We nevertheless examine
the impact of these added observations on estimates
in sensitivity analyses. The data set for analysis was
ultimately reduced to 561 projects containing 499 failures and 62 commercial successes spanning the period
1989 to 1994.7
4.2. Data
The telephone interview script contained 11 questions,
one of which is used in this study: “Did you ever start
to sell NAME or a later, revised, or improved version
of this invention?” Responses deﬁne a binary variable
that takes unity if an invention ever obtained sales
revenue, and 0 otherwise. We refer to this outcome as
7
Twenty observations were dropped for the regression analysis
because they had no data on the predictors. Data spanned two submission periods with somewhat different evaluation procedures,
with the ﬁrst period from 1976 to early July 1989 and the second
from July 21, 1989, to January 1994. Because both evaluation criteria and scales differed substantially across the two periods, we
decided to use only data from July 1989 onward. The addition of
the 52 choice-based observations did not change the distribution of
observations across ratings for the 1989 to 1994 subsample ( 2 =
634, d.f. = 4, n.s.). In addition, the change in period covered and
the inclusion of the choice-based sample did not have a signiﬁcant
effect on the distribution of the probability of commercialization.

<-----Page 4----->Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures

399

Management Science 52(3), pp. 395–409, © 2006 INFORMS

Table 1

Base Rates of the Overall Scores and the Probability of Commercial Success
1989–1994 Sample
Frequency
(2)

Percent (%)
(3)

Percent
commercial (%)
(4)

Rate of return
for commercial (%)
(5)

A—recommended for development
B—may go forward, but need to collect more data
C—recommended to go forward, returns likely modest
D—doubtful, further development not recommended
E—strongly recommend to stop further development

28
39
83
341
70

5
7
15
61
12

71
26
20
4
1

260
260
−132
−285
N/A

Total

561

100

11

−73

Overall score
(1)

Note. Data in columns 2–4 are from Åstebro (2004), and data in column 5 are from Åstebro (2003).

the probability of commercialization. This is the variable against which the decision rules and the statistical
model will be calibrated.
Evaluation information in the CIC record included
ratings for each of the 37 cues as well as the venture’s
overall rating. Data on the independent variables
were consequently collected before outcomes were
observed and are independent of this study. We therefore avoid any potential methods bias (Campbell and
Fiske 1959, Fischhoff 1975). We convert the scores on
the 37 cues into numerical data according to the following: A = 1 (positive); B = 0 (neutral); and C = −1
(negative).
Table 1 (columns 2 and 3) reports the frequency
distribution of the responses over the IAP’s overall
rating. A large majority (73%) of ventures (rating D
and E) were advised to terminate efforts. Five percent received the most favorable overall score (A),
7% were advised to collect additional market or technical analysis (B), and 15% were advised that the
project was suitable to launch as a limited (i.e., parttime) effort (C). Table 1 (column 4) also reports the
probability of commercialization for each of the different overall scores. As seen, the probability of commercialization increases with the IAP overall score.
Åstebro (2003) computed the median internal rate of
return (IRR), conditional on successful commercialization for the ﬁve classes of inventions. These data are
reported in Table 1 (column 5). As shown, the IRR is
also correlated with the IAP overall judgment.
To measure the predictive accuracy of the overall
forecast we convert the overall rating into the following scheme: A, B, and C are assumed to be a forecast
of “success,” while D and E are assumed to be a forecast of “failure.” This allows us to compare the forecast against the actual outcome in a 2-by-2 matrix and
to compute the classiﬁcation accuracy of the forecasts.
The sample mean probability of reaching the market while excluding the nonrandom sample is 0.07.
In comparison, the probability of commercial success
of conducting R&D in established ﬁrms is approximately 0.37 (Mansﬁeld et al. 1977). The average

development time in calendar years is 1.5 years for
successful inventions and 0.5 years for unsuccessful
inventions (Åstebro 1998). The average development
costs for successful versus unsuccessful inventions
are $87,553 and $5,798, respectively (Åstebro 2003).
A conservative estimate of the mean yearly sales is
CDN$257,500 (1995 values), with the median located
between CDN$5,000 and $24,999 (Åstebro 1998). The
expected survival time for the inventions that reach
the market is approximately 11 years (Gerchak and
Åstebro 2000). The average pretax IRR on a portfolio investment in these inventions is 11.4% (Åstebro
2003). This is higher than the contemporary risk-free
rate of 4.2% but lower than the long-run return on
high-risk securities, which is approximately 18%–23%.
Nevertheless, the median IRR conditional on commercialization is negative, indicating a skew distribution.
Spearman rank-order correlations and percentage
high scores (“A”s) are shown in Table 2. The forecast
of successful commercialization is most strongly correlated with the cue “proﬁtability” r = 064 p < 001.
This cue is also most strongly correlated with the
likelihood of commercialization r = 031 p < 001.
Cues measuring “payback period,” “potential sales,”
“size of investment,” “development risk,” “function,”
and “functional performance” all have correlations
with the forecast between 0.41 and 0.55 and correlations with commercialization likelihood between 0.19
and 0.25. The IAP therefore seems to use roughly the
same cues for their forecasts as those that indeed are
predictive of future commercial success. The bottom
four cues are used in a much more discriminating
way than most other cues. Only 2% receive the highest “A” rating on “proﬁtability.” Few also are expected
to have short payback period (3%), large potential
sales (5%), and a small-sized investment (6%).

5.

Analysis and Results

Our approach to modeling the decision-making process by the analysts is based on the ideas that decision
makers tend to use simple rules and tend to focus on

<-----Page 5----->Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures

400

Management Science 52(3), pp. 395–409, © 2006 INFORMS

Table 2

Bivariate Spearman Rank-Order Correlations and Percentage High Scores

Variable
Probability of commercialization
Overall judged commercialization quality
Technical feasibility
Functional performance
Research and development
Technology signiﬁcance
Safety
Environmental impact
Technology of production
Tooling cost
Cost of production
Need
Potential market
Trend of demand
Duration of demand
Demand predictability
Product line potential
Societal beneﬁts
Compatibility
Learning
Visibility
Appearance
Function
Durability
Service
Price
Existing competition
New competition
Marketing research
Promotion cost
Distribution
Legality
Development risk
Dependence
Protection
Size of investment
Potential sales
Payback period
Proﬁtability

Legend

Proportion of
observations
receiving highest
rating (A)

Correlation with
probability of
commercialization

Correlation with
judged
commercialization
quality

p(A)

q1

score

1.00
0.39

1.00

0.15
0.19
0.19
0.08
0.01
0.05
0.13
0.12
0.17
0.16
0.01
0.15
0.09
0.12
0.12
0.08
0.15
0.02
0.07
0.18
0.23
0.14
0.10
0.18
0.09
0.06
0.16
0.12
0.13
0.09
0.24
0.08
0.18
0.21
0.25
0.23
0.31

0.34
0.41
0.35
0.28
0.10
0.11
0.24
0.28
0.30
0.32
0.12
0.23
0.16
0.16
0.19
0.21
0.31
0.12
0.24
0.39
0.45
0.23
0.18
0.32
0.24
0.09
0.22
0.30
0.24
0.14
0.47
0.19
0.36
0.50
0.54
0.55
0.64

q1
score
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37

0.72
0.57
0.37
0.08
0.30
0.28
0.65
0.18
0.11
0.18
0.27
0.20
0.37
0.08
0.06
0.77
0.40
0.45
0.34
0.28
0.29
0.17
0.06
0.09
0.06
0.08
0.11
0.02
0.08
0.52
0.17
0.30
0.07
0.06
0.05
0.03
0.02

Notes. Correlations larger than 0.082 are signiﬁcant at least at p < 005, correlations larger than 0.115 are signiﬁcant
at least at p < 001, n = 561.
q1 = 1 if invention reach market, else 0.
Overall score = [A = 5, B = 4, C = 3, D = 2, E = 1] = forecast.

a subset of cues. The extreme approach would be to
focus on a single criterion, as in the “take-the-best”
heuristic (Todd 1999). The idea of narrowing down
the cue space is also used in the categorization-byelimination heuristic (Berretty et al. 1997) and in the
elimination-by-aspects heuristic (Tversky 1972). Narrowing down the cues is an integral part of our proposed heuristic. We do not, however, employ it for
the sake of analyzing the efﬁciency of an a priori
preferred rule as in Czerlinski et al. (1999). Rather, we
use the data to eliminate cues that do not systemati-

cally agree with the decisions of the analysts and/or
the actual outcomes.
Our approach starts with a description of the rules
used by the analysts in order to formulate a general data analysis approach. Analysts indicated that
if a project is critically ﬂawed on one or more cues,
either the lowest or next-to-lowest overall score is
typically provided. If no critical ﬂaws exist, however,
then the scores on the cues are usually assessed in
some unknown subjective additive fashion. To derive
a model of these rules, we use a conjunctive decision

<-----Page 6----->Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures
Management Science 52(3), pp. 395–409, © 2006 INFORMS

rule that counts the number of positive and negative
cues to make a forecast based on these two counts.
The rule takes this form: If the number of positives is
greater than or equal to p and the number of negatives
is less than or equal to n, we classify the projects as
having future commercial success. The best values for
n and p and the best selection of cues are those that
maximize a certain objective. We pursue two objectives: (1) We try to match the analysts’ forecasts, and
(2) we try to predict the actual commercial outcomes.
Suppose that the possible values for n and p are
0 1 2 3 4 and 5 6 7 8 9 10, respectively. Given
37 cues, the number of possible combinations is in the
order of four billion.8 Going through all of the combinations would be very time-consuming. Instead, we
use an iterative nested procedure that starts with the
generation of all possible combinations of a prespeciﬁed length (say 35 or 36 cues). We then evaluate each
against the objective for all possible n p values. The
combination that achieves the highest objective value
for that subset of cues is retained and used to generate further combinations of smaller sizes (say, 33
or 32). The procedure continues until the total number of remaining cues is less than a prespeciﬁed value
(e.g., 20). For a technical step-by-step description, see
Appendix B.9
Following the goal of the IAP to provide accurate
forecasts to all clients, it seems reasonable to minimize the total cost of misclassiﬁcation. This general
objective can be described with
max1 P1 V1 + 2 P2 V2 

(1)

where 1 is the sample proportion of successes, P1 is
the probability of correctly classifying a success, V1
is the value of classifying a success correctly, 2 is
the sample proportion of failures, P2 is the probability
of correctly classifying a failure, and V2 is the value
of correctly classifying a failure. We choose a relative value of correct classiﬁcation of 10 to 1 between
V2 and V1 , meaning that it is 10 times as valuable
to classify a success correctly compared to classifying
a failure correctly. This implies that the objective to be
maximized is
max10S1 + S2 
(1.1)
8

The number of possible subsets, excluding the empty set, is 237 − 1,
so the number of possible combinations is 5 × 6 × 237 − 1 =
412 × 1012 .

9
For example, suppose we start the procedure by looking at combinations of size 35. This leads to a total of 666 combinations, each of
which is tested against each of the 30 n p possibilities. The best
combination is retained. The procedure is then restarted on those
35 retained cues. Suppose we generate all possible combinations of
length 33. This results in a total of 595 new combinations, each of
which is tested against every n p possibility. The best combination is again identiﬁed, and the procedure is restarted.

401

where S1 is the number of successes classiﬁed correctly and S2 is the number of failures classiﬁed
correctly. This goal seems commensurate with the
behavior of the analysts at the IAP. It also seems to
match the goals of similar actors in this area. For
example, venture capitalists (VCs) are more interested
in whether or not the venture they invest in will
obtain spectacular returns. They are not as concerned
with what happens to those they reject.
Replicating the Analysts’ Forecasts
Analysts at the Canadian IAP made 150 forecasts of
success and 411 forecasts of failure between 1989 and
1994. With these forecasts, the IAP could correctly
classify 47 out of 62 true successes (75.8% accuracy),
and 396 out of 499 true failures (79.4% accuracy) for
an overall forecasting accuracy of 443/561 (79.0%),
indicating that analysts are approximately equal in
their ability to identify successes and failures. As we
later split the sample into an estimation sample and
a prediction sample, we report the classiﬁcation accuracy of the IAP for these two subsamples in Table 3,
column 1.
The analysts are, however, poorer at making correct
forecasts than applying much simpler rules. An alternative would be to forecast all projects to be failures.
The overall classiﬁcation accuracy of this rule is high:
499/561 (88.9%). However, the percentage of correctly
classiﬁed successes is low: 0% (0 out of 62). Inventors
would not be interested in paying for a service that
provides the stock response “you will fail,” so we discount this as an irrelevant rule. Another simple rule
would be to use the base rate of 11% success to forecast 62 randomly chosen projects to be successes (the
probability matching rule). This rule correctly classiﬁes 444 of 499 failures (90.0%) and 7 out of 62 successes (11%) for an overall classiﬁcation accuracy of
80.3%. However, while the overall classiﬁcation accuracy is strong, this rule also fails to correctly classify
successful projects.
In describing their decision rules, we aim to replicate only the experts’ correct forecasts. We focus on
these because there is random variation in the ability of decision makers to forecast outcomes (Goldberg
1968). Trying to capture the incorrect forecasts with
a model might make some sense if one is interested
in explaining poor performance, but in this case our
objective is the reverse. Also, the number of incorrect
forecasts is too small on which to apply optimization techniques. To test the robustness of results, we
split the sample into two groups. The ﬁrst covers the
period from 1989 to 1992 and is used as an estimation sample. The second covers the period from 1993
to 1994 and is used for making out-of-sample predictions. There are 383 observations in the 1989 to 1992

<-----Page 7----->Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures

402

Management Science 52(3), pp. 395–409, © 2006 INFORMS

Table 3

Replicating the Analysts’ Correct Forecasts
Heuristics based only on correct
IAP forecasts
Conjunctive model with cues
1 2 3 4 5 6 7 8 10 11
12 13 14 16 17 18 19 20 21
22 23 24 25 26 27 29 30 31
32 34 35 36 37
included
n = 2 p = 6
(2)

IAP forecasts
(1)
# correct

% correct (%)

# correct

% correct (%)

Estimation sample (1989 to 1992)
Total
Predicted to be a success
Predicted to be a failure

296 out of 383
30 out of 39
266 out of 344

778
7692
7733

277 out of 296
28 out of 30
249 out of 266

936
933
936

Prediction sample (1993 to 1994)
Total
Predicted to be a success
Predicted to be a failure

147 out of 178
17 out of 23
130 out of 155

8258
7391
8387

135 out of 147
14 out of 17
121 out of 130

918
824
931

Notes. Column (1) contains data on the ability of the IAP analysts to correctly forecast whether a project reaches
the market or not during two time periods: 1989–1992 and 1993–1994. For example, during 1989 to 1992, they
correctly predicted 30 out of 39 actual successes correctly.
Column (2) contains an estimation based on the subset of all 561 observations where the IAP made correct
forecasts. The 1989–1992 time period is used to calibrate n, p, and the cues to use, and the 1993–1994 time period
is used to test the forecasting accuracy of the heuristic using the previously calibrated values of n, p, and the cues
to use. For example, in the prediction sample, the model correctly predicts 14 out of 17 actual successes that were
correctly classiﬁed by the IAP analysts.
n: threshold value for the number of negatives ≤n.
p: threshold value for the number of positives (≥p.
For concordance between cue numbers and names, see Table 2.

pool (39 successes and 344 failures), and 178 observations in the 1993 to 1994 pool (23 successes and 155
failures). Results are displayed in Table 3, column 2.
As shown in column 2 of Table 3, the heuristic
that keeps 33 and ignores 4 cues with n p = 2 6
replicates 30 out of their 39 correct forecasts of successes (93.3%) and 266 out of their 344 correct forecasts of failures (93.6%), reaching an overall accuracy
of 93.6% (277 out of 296) in the estimation sample.10
This replication accuracy is well over what is expected
as reasonable (about 90%) using linear additive models (Goldberg 1968). Indeed, an ordinal probit with
linear additive terms had a replication accuracy of
91.6%, suggesting that the conjunctive model with
equal weights better describes the decision-making
process than a model with linear terms of unequal
weights. In terms of forecasting ability of the analysts’ judgments, the conjunctive heuristic correctly
predicts 14 out of their 17 correct forecasts of successes (82.3%) and 121 out of their 130 correct forecasts of failures (93.1%), reaching an overall accuracy
of 91.8% (135 out of 147) in the prediction sample
(Table 3, column 2)
10

To save space in Tables 3 and 4, we write out legends rather than
cue names. See Table 2 for their concordance.

The best conjunctive heuristic that replicates their
forecasts eliminates 4 of the 37 cues (Table 3, column 2). That is, approximately 33 cues appear to be
used by the analysts when forming their decisions.
This is far from using a single criterion as in the simulations by Todd (1999) or Czerlinski et al. (1999). In
fact, our replication analysis appears to conﬁrm our
interviews with the senior analyst as well as the work
by Goldberg (1968). But a single criterion heuristic
may perform approximately equal to the more complex heuristic apparently employed by the IAP’s analysts. It might be that even a randomly chosen cue
will perform well. We examine these questions in the
next section where we explore the accuracy of various
heuristics in predicting project outcomes.
Predicting Commercial Success
Under this objective, we seek a decision rule that
correctly predicts the commercial success of projects.
To test the robustness of results we split the sample
as in the previous analysis. Consistent with the previous analysis, we calibrate the optimization on the
goal described in Equation (1.1). Table 4 displays the
predictions by the IAP (column 2), a heuristic that
considers all 37 cues (column 3), the best conjunctive
heuristic (column 4), and two log-linear (logit) regression model (columns 5 and 6).

<-----Page 8----->Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures

403

Management Science 52(3), pp. 395–409, © 2006 INFORMS

Table 4

Within and Out-of-Sample Classiﬁcation Accuracy for Analysts and Decision Rules
Conjunctive heuristic

All cues;
n = 4 p = 6
(3)

IAP
(2)

Cue
2 6 8 10 11
13 16 17 18
19 20 21 24
25 27 31 32
33 34 35 37
included;
n = 2 p = 5
(4)

Log-linear regression model
Cue
12 15 18 21
27 31 36 37
included;
(5)

All cues
(6)

Total
(1)

#

%

#

%

#

%

#

%

#

%

Estimation sample (1989 to 1992)
Overall predictive accuracy
Correctly predicts success
Correctly predicts failure

383
39
344

296
30
266

773
769
773

275
29
246

718
744
715

296
32
264

773
820
767

293
31
262

765
795
762

296
28
268

773
718
779

Prediction sample (1993 to 1994)
Overall predictive accuracy
Correctly predicts success
Correctly predicts failure

178
23
155

147
17
130

826
739
839

143
20
123

803
870
793

153
19
134

860
826
865

140
15
125

786
652
806

125
15
110

772
652
710

Notes. Column (1): Total number of projects split by two time periods: 383 + 178 = 561. The totals for each time period are further split by successes and
failures (e.g., 39 successes and 344 failures = 383 projects during 1989–1992).
Columns (2)–(6): #: the number of projects classiﬁed correctly, %: the percentage of column (1).
Column (2) repeats from Table 1 data on the ability of the IAP analysts to correctly forecast whether a project reaches the market or not during two time
periods: 1989–1992 and 1993–1994.
Columns (3)–(6) contain model estimations on all 561 observations. The 1989–1992 time period is used to calibrate the various models, and the 1993–1994
time period is used to test the forecasting accuracy of the various models. Since the estimation sample contains all observations (not just the correctly
forecasted observations by the IAP as in Table 3) and the objective is now to try to predict the actual commercial outcomes (rather than the IAP decisions) the
results on optimal n, p, and cues are different from those reported in Table 3.
Column (3) reports estimation and prediction results where we did not eliminate any cues but simply calibrated the most optimal values of n and p.
Column (4) reports estimation and prediction results where we calibrated the most optimal values of n, p, and cues included.
Column (5) reports estimation and prediction results of a log-linear regression model where cues were selected using backwards variable elimination with
a p-value of 0.10.
Column (5) reports estimation and prediction results of a log-linear regression model where all cues were retained.
n: threshold value for the number of negatives ≤n.
p: threshold value for the number of positives ≥p.
For concordance between cue numbers and names, see Table 2.

The best heuristic is that which keeps 21 and
ignores 16 cues with n = 2, p = 5 (column 4). The
heuristic has an overall out-of-sample predictive accuracy of 86.0%. Note that the best heuristic, the regression model with all cues, and the IAP all make
the same overall number of correct classiﬁcations
(296) in the estimation sample. However, the conjunctive heuristic correctly classiﬁes two more successes (32 versus 30), while the IAP correctly classiﬁes
two more failures (266 versus 264) and the regression
model correctly classiﬁes four more failures (268 versus 264).11 These differences are not signiﬁcant in a
statistical sense. But it is notable that the conjunctive
11

The conjunctive model could easily exceed the 296 correctly classiﬁed projects at the expense of making very few correct classiﬁcations of successes. For example, if n and p are set to 0 and 15,
respectively, then the heuristic will correctly classify 347 projects,
correctly predicting all the failures but only 3 successes (of 39). We
reiterate that such a calibration is not a reasonable objective as it
defeats the purpose of the service provided by the IAP.

heuristic accurately predicts more successes because
the value of correctly classifying successes is approximately 10 times higher than the value of correctly
classifying failures, as noted above.12
The IAP experts, on the other hand, correctly predicted 17 successes (73.9%) and 130 failures (83.9%)
for an overall forecasting accuracy of 82.6%, lower
than the best heuristic we found. However, the difference of proportions between the conjunctive heuristic and the IAP experts is not signiﬁcant z = 0873
p > 010 n = 178.
Notice that the cues used to forecast outcomes are
different than the cues used to replicate the analysts’
forecasts. To replicate the analysts’ forecasts as closely
as possible, the procedure included 33 out of 37 cues.
However, only 21 cues are included when forecasting
future successes and failures. The conjunctive forecasting rule eliminates 12 cues and includes 1 cue to
12

That the overall accuracy for the IAP, the decision heuristic, and
the full regression model is the same is pure coincidence.

<-----Page 9----->404

Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures

the set that the analysts seem to use. That is, commensurate with laboratory ﬁndings, the analysts are
likely to use too much invalid information in comparison with the optimal conjunctive rule that forecasts
successes.
While we follow a “minimalist” strategy of eliminating cues that are not useful because of their low
consistency with the forecasts, it is possible that these
cues are still occasionally meaningful. One can envision cues that are typically identical across a number of projects but in a few cases contain important
“broken-leg” cues.13 In column 3 of Table 4, we therefore test the forecasting accuracy of a decision heuristic that uses all 37 variables, with n and p being 4
and 6, respectively. This heuristic predicts one more
success but 11 less failures than the best heuristic that
uses a reduced set of cues. It appears that a fullinformation heuristic does not predict as well as a
heuristic that takes into account the important, but
not all, cues. Many of the cues eliminated are those
that tend to make analysts provide incorrect forecasts. The cues eliminated also tend to degrade the
classiﬁcation accuracy of the best conjunctive rule if
included.
We now illustrate the difference between the conjunctive model and a typical benchmark used in
similar studies: a linear additive statistical model. A
logistic regression model is ﬁtted on the estimation
sample (Table 4, top three data rows of column 5).14
We narrow down the cues by using backward variable elimination with a p-value of 0.10 to determine
inclusion of the statistically most important cues. The
resulting model contains eight of the 37 cues. As
before, we calibrate forecasts on the prediction sample
using Equation (1.1). In the out-of-sample test (bottom
three data rows of column 5), the regression model
correctly forecasts 15 of the 23 successes (65.2%) and
125 of the 155 failures (80.6%), reaching an overall
accuracy of 78.6%. Inconsistent with previous results
(Dawes et al. 1989) and thus surprisingly, analysts
at the IAP are better at forecasting outcomes than a
log-linear additive regression model. The difference of
proportions between the IAP experts (82.6%) and the
regression model (78.6%) is, however, not signiﬁcant
z = 0939 p > 010 n = 178. The regression model
also performs worse than the conjunctive decision
13

This term comes from Paul Meehl who argued that a regression
model will not recognize an infrequent event such as a broken leg,
but the analyst will be able to predict with high certainty that the
professor won’t go to the movies if his leg is broken.

14

Even though we decided to use the logistic speciﬁcation, a number of link functions are available when outcomes are discrete.
Rather than arbitrarily selecting one function, three alternative link
functions were explored: logit, normit (also called probit), and gompit (also called complementary log-log). Regressions showed that
all three types generated the same cues as signiﬁcant.

Management Science 52(3), pp. 395–409, © 2006 INFORMS

heuristic. The difference of proportions between the
conjunctive model (86.0%) and the regression model
(78.6%) is signiﬁcant z = 1805 p < 005 n = 178.
Apparently there are predictive nonlinear decision
rules captured by the conjunctive model but not captured by the linear additive regression model.
As a ﬁnal comparison, we investigate the model ﬁt
and the out-of-sample accuracy of a regression model
with all variables (see Table 4, column 6). Compared
to the regression model with a reduced set of cues, the
out-of-sample prediction accuracy goes down indicating overﬁtting on the estimation sample and supporting the idea that narrowing down the cue space is
effective.
We also test the sensitivity of the best conjunctive
heuristic against deviations in the choices of n and p
by altering the values of n and p. The analysis reveals
that the conjunctive decision rule is more sensitive
to changes in n than to changes in p, reﬂecting the
nature of the decision environment as primarily an
elimination process based on the number of negative cues. We further test the sensitivity of results to
the exclusion of 52 observations that were included
because of information collected by the IAP that these
projects might be successful. The conclusions do not
change using this alternative and smaller set of observations. In addition, we analyze how accurate the
take-the-best cue heuristics perform in this context.
The best single cue is “proﬁtability.” The most effective take-the-best heuristic is that which classiﬁes an
observation as a success if it receives either an A
or B rating on this cue with an overall classiﬁcation
accuracy of 88.6%. However, this result is deceptive
because the heuristic can correctly identify only 5 out
of 62 successes. The reason is the very low granularity of the cue—it simply uses too little information
and so cannot be accurately calibrated on both successes and failures simultaneously (details available
from the author).
A ﬁnal concern is that the data might be affected
by a self-fulﬁlling prophecy that might affect estimation results. The advice provided by the IAP may
affect inventors’ efforts. If the cues are completely
uninformative of commercialization likelihood while
the recommendation turns out to be highly correlated
with commercialization efforts (for example, due to
affectation), we would observe positive and biased
correlations between cues and the likelihood of commercialization. The self-fulﬁlling prophecy, however,
does not bias results on the relationship between cues
and judgments. That is, our analysis that derives the
experts’ decision rules is unaffected.
Åstebro and Chen (2004) followed the work by
Manski (1995) and Angrist (2000) to estimate the
average treatment effect, deﬁned as the average effect

<-----Page 10----->Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures
Management Science 52(3), pp. 395–409, © 2006 INFORMS

of the judgment on the probability of commercialization, controlling for the expected commercial quality
of the invention. The expected quality of the invention is estimated econometrically by an index measuring the likelihood of reaching the market, while
controlling for the selection bias. A more colloquial
way of saying this (and a restricted case) is that they
estimate the degree to which there is a bias in the
relationship between cues and outcomes if the outcomes are 100% determined by the IAP recommendation, and not at all by the underlying quality of their
inventions. The authors ﬁnd that most of the inventors’ efforts are driven by the underlying quality of
their inventions and that the IAP advice accurately
reﬂects this quality. The most likely bias is a rather
small increase (decrease) in the inventor’s expectation
of the probability of success as a function of a positive
(negative) review by the IAP, while controlling for the
expected quality of the invention. The detected bias
is not large enough to invalidate the conclusion that
the statistically estimated log-linear model describing the relation between the cues and the probability
of commercialization is relatively unbiased for most
inventions.

6.

Concluding Remarks

Summary
Most decision makers use simplifying heuristics when
making judgments. These heuristics have been found
to cause decision makers to deviate from optimal
decisions (Tversky and Kahneman 1974, Dawes et al.
1989). However, simpliﬁed decision rules may provide fast and reasonably accurate decisions that might
not deviate much from what is optimal (Gigerenzer
and Goldstein 1996). Previous studies of both claims
have been mostly lab- or simulation-based, raising
the question of how decision makers actually use
heuristics and how observed heuristics perform in
real settings.
We investigate the type and efﬁcacy of simpledecision heuristics used by experts in a natural setting
to forecast that early-stage R&D projects are commercialized. The decision situation contains a large number of cues (37), and the outcome to be predicted
is extremely uncertain. At the same time, feedback
on the prediction is biased and spotty, and decisionrelevant information is uncertain and not easily quantiﬁed. However, there is ample time to form an
opinion, for which the experts are highly paid.
In a previous paper (Åstebro and Koehler 2004), it
was found that the experts had a forecasting accuracy equal to or surpassing a linear statistical model,
something that is rarely supported by the literature
(Dawes et al. 1989). Contrary to most other results, the

405

experts have a high forecasting accuracy, in particular of the successful projects and especially considering the difﬁcult decision-making environment. Given
this ﬁnding, it seems important to understand their
decision-making rules. Are they simple and robust
or complicated? Can we explain why their heuristics
perform so well?
Through interviews, we discovered that to arrive at
a forecast, the experts ﬁrst use a consistent (although
subjective) method of scoring a ﬁxed set of cues. They
then tend to follow a heuristic where they subjectively combine data on all cues by examining both
critical ﬂaws as well as positive factors. We formalize this heuristic with a conjunctive model that sums
a subset of all “good” and “bad” cue counts separately and achieves a 91.8% forecasting accuracy of
the experts’ correct forecasts. We then compare predictions derived from the conjunctive model and the
analysts’ forecasts as well as a log-linear additive statistical model with future R&D project commercializations. The conjunctive model predicts 86.0% and
experts correctly predict 82.6%, a close second, while
a log-linear additive statistical model correctly predicts 78.6% in out-of-sample, out-of-time tests. The
difference in proportions between the conjunctive
model and the statistical model was signiﬁcant at less
than 5%.
The conjunctive model that replicates the experts’
forecasting rules uses 33 out of 37 possible cues.
The model forecasting project successes, however, use
21 cues. These results point to experts who appear
to use considerably more information than what we
found optimal and allow this to incorrectly affect their
forecasts. Indeed, those models that use all cues do
not perform as well as those that use a selected set of
cues. Nor is a “take-the-best” rule as effective at predicting as a rule that considers a selected set of cues.
Outcome data are potentially affected by the judgments and therefore require adjustments or at least
analysis of potential treatment effects. This “treatment effect” might lead to a self-fulﬁlling prophecy
of judgments. It could bias upward the estimated predictive ability of the judges. It could also cause a positive bias in regressions between cues and outcomes.
The self-fulﬁlling prophecy, however, does not bias
the reported results on the relationship between cues
and judgments. Our analysis that derives the experts’
decision rules remains unaffected.
We refer to work by Åstebro and Chen (2004), who
used the same data to estimate the treatment effect.
They found that the most likely treatment bias is a
small increase (decrease) in the entrepreneur’s expectation of the probability of success as a function of a
positive (negative) review by the IAP, while controlling for the expected quality of the invention. This
bias was not large enough to invalidate the conclusion

<-----Page 11----->406

Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures

that the estimated statistical model is relatively unbiased for most inventions. We assume that because the
bias of the log-linear model is small, the bias for the
conjunctive decision model is also small.
Discussion
The conjunctive model that we use to derive the best
heuristic contains a new, complex optimization procedure. One should not, however, equate the complexity of the derivation of the decision rule with
the complexity of the use of the rule. Other decision
rules, such as using a linear additive model or the
take-the-best rule, also require optimization methods.
The take-the-best rule relies on a rank-ordering of all
cues based on cue validity, a well-deﬁned mathematical construct. Complex analysis of data is required to
form such a rank-ordering. To derive a linear additive model requires computing the sum of squared
errors. Our speciﬁc optimization procedure was motivated by discussions with the decision makers, which
revealed an apparent conjunctive n, p rule.
We conclude from our analysis that the rules analysts appear to use are simple in that they perform straightforward sums of counts, but complex in
the sense that they use signiﬁcantly more cues than
what is typically observed in other decision-making
contexts. Processing information on the large number of cues is likely made simpler by the analysts
using a form in which all cues are listed and scores
are recorded and by the case-based comparison that
anchors judgments.
Notice that in the conjunctive model, cue weights
are either 1 or 0. However, it is still a better forecaster than the linear statistical model, which has
nonequal weights. These results are not due to overﬁtting of the statistical model on the estimation sample.
The different results might instead be due to different cues picked out by the conjunctive and statistical
model. However, we ﬁnd this an unlikely explanation because analysis showed that there was a whole
set of conjunctive models with varying sets of cues
that all performed better than the statistical model.
Instead, we argue that the reason for the difference is
the conjunctive model’s noncompensatory nonlinear
structure. In the conjunctive model, a large number
of good cue scores can never “save” a project where
there are more than three bad cues. In the additive
linear statistical model, such compensation is possible. The noncompensatory feature might be particularly appropriate in decision-making situations where
a project that does not meet a set objective cannot
go forward. For example, no matter how large the
demand, a perpetuum mobile will not make it to the
market.
Our results agree with previous literature ﬁndings that a “bootstrap” model replicating experts’

Management Science 52(3), pp. 395–409, © 2006 INFORMS

judgments typically does better at forecasting than
the experts themselves. This is probably because the
model consistently applies the same rules, whereas
there is typically less reliability in human judgment
(e.g., Goldberg 1968). However, in this case, the linear
additive bootstrap model is “beaten” by the decision makers, who in turn are beaten by the conjunctive decision heuristic. We believe these results
also agree with previous results. The data and the
decision-making context are more complex, so the linear additive regression model is simply not sufﬁcient
to describe the nonlinearities present. Once we discovered and encoded the experts’ rules, the model
applies these rules with greater consistency than the
experts, thereby lifting the forecasting accuracy above
the experts’ average accuracy.
We highlight that the models (and judgments) are
based on scores representing subjective estimates of
various information. Two issues arise from this consideration: (1) Are such subjective estimates accurate?
(2) How does one become proﬁcient at making such
estimates?
Addressing the ﬁrst point, we note that Einhorn
(1972) showed that humans are better able to consistently measure items than they are at evaluating
these measurements for summary judgments. In addition, Baker and Albaum (1986) found high Cronbach
alphas for raters of these speciﬁc cues. We also note
that the predictive accuracy of the conjunctive model
is relatively high in an absolute sense (Goldberg 1968).
Furthermore, the distance to the accuracy of the probability matching rule, which uses no cue information
(at 80.3% accuracy), indicates that the cues indeed
contain valuable information.
But because the cues are subjectively measured,
some uncertainty remains regarding the transferability of the results to practice. Our results do not inform
others how to perform the subjective assessments of
the cues, only how to make a reasonably accurate
judgment in a simple way once the cues have been
scored. However, with some training by individuals
knowledgeable about the IAP’s process, it should be
possible to use such a model by assessors at, for example, venture capital ﬁrms focused on seed and earlystage investments. One indication that training judges
in cue assessment is relatively easy is obtained from
Baker and Albaum (1986). They trained decision makers familiar with the context to use the instrument
through written instructions in a mail survey, obtaining high reliability.
Venture capital (VC) decision making might be an
area containing some signiﬁcant biases in judgment
that may proﬁt extraordinarily from the application
of decision-support tools such as the one developed
here. Indeed, Zacharakis and Meyer (2000) conducted
an experiment in which 51 experienced VCs received

<-----Page 12----->Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures
Management Science 52(3), pp. 395–409, © 2006 INFORMS

407

several pieces of information about 25 actual investments that had subsequently achieved either success or failure. Approximately 57% of the investments
were in the seed and early stages. The VCs were
requested to evaluate the ventures on four cues, as
they would during the initial screening stage. Their
predictions were then compared to the actual outcomes, and the percentage of correctly classiﬁed outcomes was computed. This study showed that VCs
have a low ability to correctly forecast the outcomes
of ventures—at best, one VC had a classiﬁcation accuracy of approximately 40% while a bootstrap model
of their decisions had a classiﬁcation accuracy of 60%
(the base rate was 50%). The more information about
the venture provided to the VCs, the less able they
were at predicting outcomes. When information about
the track record of the team and competition was
included, their average classiﬁcation accuracy was
reduced to 31%, and when additional information
about the team and product was introduced, the classiﬁcation accuracy declined to 17%. These results indicated that VCs are rather poor at making investment
decisions and that they suffer from some signiﬁcant
decision-making biases.
The results should bring support for the argument
that simple, but not extremely simple, decision rules
can perform well, especially because this test was performed on a large number of nonexperimental decisions. The results also deviate signiﬁcantly from past
simulations, indicating that single decision cues are
effective. The single-best-cue rule cannot be calibrated
to perform any better because of a lack of granularity
in predictor values, so it is not a useful rule in this
context.

Safety

Are potential dangers or undersirable side
effects expected?

Environmental
impact

Will the innovation lead to pollution, litter,
misuse of natural resources, or the like?

Technology of
production

Are the technology and skills required to
produce the invention available?

Tooling cost

How great a burden is the cost of production
tooling required to meet the expected
demand?

Cost of
production

Does production at a reasonable cost level
appear possible?

Need

Does the innovation solve a problem, ﬁll a
need, or satisfy a want for the customer?

Potential market

How large and how enduring is the total
market for all products serving this function?

Trend of
demand

Will the demand for such an innovation be
expected to rise, remain steady, or fall in the
lifetime of this idea?

Duration of
demand

Is the demand for the innovation expected to
be “long term”?

Demand
predictability

How closely will it be possible to predict
sales?

Product line
potential

Can the innovation lead to other proﬁtable
products or services?

Societal beneﬁts

Will the innovation be of general beneﬁt to
society?

Compatibility

Is the innovation compatible with current
attitudes and ways of doing things?

Learning

How easily can the customer learn the correct
use of the innovation?

Visibility

How evident are the advantages of the
innovation to the prospective customer?

Appearance

Does the appearance of the innovation convey
a message of desirable qualities?

Acknowledgments

Function

Does this innovation work better than the
alternatives or fulﬁll a function not now
provided?

Durability

Will this innovation endure “long usage”?

Service

Will this innovation require less servicing or
less costly servicing than alternatives?

Price

Does this innovation have a price advantage
over its competitors?

Existing
competition

Does this innovation already face competition
in the marketplace that will make its entry
difﬁcult and costly?

New
competition

Is this innovation likely to face new
competition in the marketplace from other
innovations that must be expected to threaten
its market share?

Marketing
research

How great an effort will be required to deﬁne
the product and price that the ﬁnal market
will ﬁnd acceptable?

Åstebro acknowledges partial ﬁnancial support from the
Natural Sciences and Engineering Research Council of
Canada, grant #RGPIN 183683-00 and in-kind support from
the Canadian Innovation Centre. Elhedhli acknowledges
partial support from the National Science and Engineering Research Council of Canada, grant #RGPIN 249491-02.
The authors thank Baruch Fischhoff, Shane Frederick, Scott
Jeffrey, Derek Koehler, and Joachim Winter for comments
and suggestions.

Appendix A.
Cue

Explanations of Cues
Explanation

Technical
feasibility

Is the technical solution sound and complete?

Functional
performance

Does this innovation work better than the
alternatives?

Research and
development

How great a burden is the remaining research
and development required to bring the
innovation to a marketable stage?

Promotion cost

Is the cost and effort of promotion to achieve
market acceptance of the innovation in line
with expected earnings?

Technology
signiﬁcance

How signiﬁcant a contribution to technology
or to its application is proposed?

Distribution

How difﬁcult will it be to develop or access
distribution channels for the innovation?

<-----Page 13----->408

Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures
Management Science 52(3), pp. 395–409, © 2006 INFORMS

Legality

Does the invention meet the requirements of
applicable laws, regulations, and product
standards and avoid exposure product
liability?

Development
risk

What degree of uncertainty is associated with
complete, successful development from the
present condition of the innovation to the
market-ready state?

Dependence

To what degree does this innovation lose
control of its market and sales due to its
dependence on other products, processes,
systems, or services?

Protection

Is it likely that worthwhile commercial
protection will be obtainable for this
innovation through patents, trade secrets, or
other means?

Size of
investment

Is the total investment required for the project
likely to be obtainable?

Potential sales

Is the sales volume for this particular
innovation likely to be sufﬁcient to justify
initiating the project?

Payback period

Will the initial investment be recovered in the
early life of the innovation?

Proﬁtability

Will the expected revenue from the innovation
provide more proﬁts than other investment
opportunities?

Appendix B

Algorithm
1. Initial set of cues is all cues, call it S.
2. Generate all combinations of size S − 2.
3. For each n in 0 1 2 3 4 and each p in
5 6 7 8 9 10:
a. Find the set of cues with the highest objective
(10S1 + S2 where S1 and S2 are the number of
successes and failures classiﬁed correctly,
respectively). Call it S ∗ .
b. If the overall objective is improved
i. Update the best objective and the overall best set
of cues
4. If S ∗  > a certain prespeciﬁed value (e.g., 20).
a. S becomes S ∗ .
b. Go to step 1.
5. Else, stop

References
Alba, J. W., H. Marmorstein. 1987. The effects of frequency knowledge on consumer decision making. J. Consumer Res. 14(1)
14–25.
Angrist, J. D. 2000. Estimation of limited-dependent variable models with dummy endogenous regressors: Simple strategies for
empirical practice. Technical working paper, National Bureau
of Economic Research, Boston, MA.
Åstebro, T. 1997. The economics of invention and inventor’s assistance programs. Report to the Canadian Innovation Centre,
Waterloo (November 12), Waterloo, Canada.
Åstebro, T. 1998. Basic statistics on the success rate and proﬁts for
independent inventors. Entrepreneurship Theory Practice 23(2)
41–48.
Åstebro, T. 2003. The return to independent invention: Evidence
of unrealistic optimism, risk seeking or skewness loving?
Econom. J. 113 226–239.

Åstebro, T. 2004. Key success factors for technological entrepreneurs’ R&D projects. IEEE Trans. Engrg. Management 51(3)
314–321.
Åstebro, T., I. Bernhardt. 1999. The social rate of return to Canada’s
inventor’s assistance program. Engrg. Econom. 44(4) 348-361.
Åstebro, T., G. Chen. 2004. Statistical decision-making models and
treatment effects. Manuscript, University of Toronto, Toronto,
Ontario, Canada.
Åstebro, T., Y. Gerchak. 2001. Proﬁtable advice: The value of information provided by Canada’s entrepreneur’s assistance program. Econom. Innovation New Tech. 10(1) 45–72.
Åstebro, T., D. Koehler. 2004. Calibration accuracy of a judgmental process that predicts the commercial success of inventions.
Manuscript, University of Toronto, Toronto, Canada.
Baker, K. G., G. S. Albaum. 1986. Modeling new product screening
decisions. J. Product Innovation Management 3(1) 32–39.
Ben-Shakhar, G., M. Bar-Hillel, Y. Bilu, G. Sheﬂer. 1998. Seek and
ye shall ﬁnd: Test results are what you hypothesize they are.
J. Behavioral Decision Making 11(4) 235–249.
Berretty, P. M., P. M. Todd, P. W. Blythe. 1997. Categorization
by elimination: A fast and frugal approach to categorization.
M. G. Shafto, P. Langley, eds. Proc. Nineteenth Annual Conf.
Cognitive Sci. Soc., Lawrence Erlbaum Associates, Mahwah, NJ,
43–48.
Camerer, C. 1981. General conditions for the success of bootstrapping models. Organ. Behavior Human Decision Processes 27(3)
411–422.
Campbell, D. T., D. W. Fiske. 1959. Convergent and discriminant
validation by the multi-trait-multi-method matrix. Psych. Bull.
56 81–105.
Chapman, L. J., J. P. Chapman. 1967. Genesis of popular but erroneous psychodiagnostic observations. J. Abnormal Psych. 72(3)
193–204.
Chapman, L. J., J. P. Chapman. 1982. Test results are what you think
they are. D. Kahneman, P. Slovic, A. Tversky, eds. Judgment
Under Uncertainty: Heuristics and Biases. Cambridge University
Press, New York, 239–248.
Czerlinski, J., G. Gigerenzer, D. G. Goldstein. 1999. How good are
simple heuristics? G. Gigerenzer, P. M. Todd, and the ABC
Research Group. Simple Heuristics That Makes Us Smart. Oxford
University Press, New York, 97–118.
Dawes, R. 1979. The robust beauty of improper linear models. Amer.
Psychologist 34.
Dawes, R., B. Corrigan. 1974. Linear models in decision making.
Psych. Bull. 81 95–106.
Dawes, R. M., D. Faust, P. E. Meehl. 1989. Clinical versus actuarial
judgment. Science 243 1668–1674.
Edwards, W., D. von Winterfeldt. 1986. Cognitive illusions and their
implication for the law. Southern California Law Rev. 59 225–276.
Einhorn, H. 1972. Expert measurement and mechanical combination. Organ. Behavior Human Performance 7 86–106.
Einhorn, H. J., R. M. Hogarth. 1978. Conﬁdence in judgment: Persistence in the illusion of validity. Psych. Rev. 85 395–416.
Ettenson, R., J. Shanteau, J. Krogstad. 1987. Expert judgment: Is
more information better? Psych. Rep. 60 227–238.
Faust, D. 1984. The Limits of Scientiﬁc Reasoning. University of
Minnesota Press, Minneapolis, MN.
Fischhoff, B. 1975. Hindsight is not equal to foresight: The effect of
outcome knowledge on judgment under uncertainty. J. Experiment. Psych.: Human Perception Performance 1(3) 288–299.
Fischhoff, B. 1982. Debiasing. D. Kahneman, P. Slovic, A. Tversky,
eds. Judgment under Uncertainty: Heuristics and Biases. Cambridge University Press, Cambridge, UK, 422–445.
Fischhoff, B., R. Beyth. 1975. “I knew it would happen”: Remembered probabilities of once-future things. Organ. Behavior
Human Decision Processes 13(1) 1–16.

<-----Page 14----->Åstebro and Elhedhli: Simple Decision Heuristics: Forecasting Commercial Success for Early-Stage Ventures
Management Science 52(3), pp. 395–409, © 2006 INFORMS

Gerchak, Y., T. Åstebro. 2000. Calculating the expectation and variance of the present value for a random proﬁt stream of uncertain duration. The Engrg. Economist 45(4) 339–349.
Gigerenzer, G., D. G. Goldstein. 1996. Reasoning the fast and frugal way: Models of bounded rationality. Psych. Rev. 103(4)
650–669.
Goldberg, L. R. 1968. Simple models or simple processes? Some
research on clinical judgments. Amer. Psychologist 23 483–496.
Grove, W. M., P. E. Meehl. 1996. Comparative efﬁciency of informal
(subjective, impressionistic) and formal (mechanical, algorithmic) prediction procedures: The clinical-statistical controversy.
Psych., Public Policy, Law 2(2) 293–323.
Hammond, K. R., D. A. Summers. 1965. Cognitive dependence on
linear and nonlinear cues. Psych. Rev. 72(3) 215–224.
Hoffman, P. J. 1960. The paramorphic representation of clinical
judgment. Psych. Bull. 57 116–131.
Holte, R. C. 1993. Very simple classiﬁcation rules perform well on
most commonly used datasets. Mach. Learn. 3(11) 63–91.
Kahneman, D., A. Tversky. 1979. Prospect theory: An analysis of
decisions under risk. Econometrica 47 263–291.
Keeney, R. L., H. Raiffa. 1976. Decisions with Multiple Objectives.
Cambridge University Press, Cambridge, UK.
Makridakis, S., M. Hibon. 2000. The M3-Competition: Results, conclusions and implications. Internat. J. Forecasting 16 451–476.
Manski, C. F. 1995. Identiﬁcation Problems in the Social Sciences.
Harvard University Press, London, England.
Murphy, A. H., R. L. Winkler. 1984. Probabilistic of precipitation
forecasts: A review. J. Amer. Statist. Assoc. 79 391–400.
Payne, J. W., J. R. Bettman, E. J. Johnson. 1993. The Adaptive Decision
Maker. Cambridge University Press, New York.

409

Russo, J. E., B. A. Dosher. 1983. Strategies for multi-attribute
binary choice. J. Experiment. Psych.: Learning, Memory Cognition
9 676–696.
Shanteau, J. 1988. Psychological characteristics and strategies of
expert decision makers. Acta Psych. 68 203–215.
Shanteau, J. 1992. How much information does an expert use? Is it
relevant? Acta Psych. 81 75–86.
Shanteau, J., M. Grier, J. Johnson, E. Berner. 1991. Teaching decision making skills to student nurses. J. Baron, R. Brown, eds.
Teaching Decision Making to Adolescents. Erlbaum, Hillsdale, NJ.
Skov, R. B., S. J. Sherman. 1986. Information-gathering processes:
Diagnosticity, hypothesis-conﬁrming strategies, and perceived
hypothesis conﬁrmation. J. Experiment. Soc. Psych. 22 93–121.
Thorngate, W. 1980. Efﬁcient decision heuristics. Behavioral Sci. 25
219–225.
Todd, P. M. 1999. Simple inference heuristics versus complex decision machines. Minds Mach. 9 461–477.
Tversky, A. 1972. Elimination by aspects: A theory of choice. Psych.
Rev. 79(4) 281–299.
Tversky, A., D. Kahneman. 1974. Judgment under uncertainty:
Heuristics and biases. Science 185 1124–1131.
Tversky, A., D. Kahneman. 1983. Extensional versus intuitive reasoning: The conjunction fallacy in probability judgment. Psych.
Rev. 90(4) 293–315.
Udell, G. 1989. Invention evaluation services: A review of the state
of the art. J. Product Innovation Management 6 157–168.
Weiss, S. M., R. S. Galen, P. V. Tadepalli. 1990. Maximizing the predictive value of production rules. Artiﬁcial Intelligence 45 47–71.
Zacharakis, A. L., G. D. Meyer. 2000. The potential of actuarial decision models: Can they improve the venture capital investment
decision? J. Bus. Venturing 15(4) 323–346.

