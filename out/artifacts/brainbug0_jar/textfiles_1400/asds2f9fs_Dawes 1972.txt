<-----Page 0----->Schachter's reluctance to honor the placement of the
locus of obesity in the hypothalamus as anything more
than a tentative guess: "I must emphasize that this
guess is based entirely on the persistent and tantalizing
analogies between lesioned rats and obese humans.
There is absolutely no relevant independent evidence
[p. 143]."
Even though the body of Schachter's article cited
Mrosovsky's hypothesis about a "functionally quiescent" area in the hypothalamus, the article's conclusion remembers only analogies with organic lesions
for placing the locus of obesity in the hypothalamus.
Perhaps Schachter's article contained the seed for the
contradiction in the comments based on it.
Schachter predicted a radical revision of our notions
about the hypothalamus if future work should support
its speculation. This prediction is a self-fulfilling
prophecy in the sense that the self of the prophet has
got to be fulfilled by a prophecy that cannot fail because it was fulfilled even before it was made. The
fulfillment came about independently of Schachter's
evidence in support of his stimulus-binding hypothesis.
The hypothalamic regulation of appetite and satiety
has been reported long ago by physiologists (Gellhorn
& Loofbourrow, 1963), and has even reached unwashed clinicians (Kaplan, 1966) who reported it, if
not in The Reader's Digest, in another medical journal. The American Psychologist was the last to know.
While Schachter was so tentative in rediscovering
the status quo, he was highly confident about 'his own
hypothesis that obese humans are controlled externally
or are stimulus bound. Perhaps the hierarchy of
confidence values should have been inverted, for Bauer
(1971) has questioned Schachter's most confidently
held hypothesis that fat people are stimulus bound.
She assumes both that fat people really want to eat
and also that they eat furtively. There occurs, according to Bauer, a contamination between external cues
per se and cues that make cheating difficult.
As a clinician who has worked with obese people, it
seems to me that Bauer's comment failed to take seriously the pitiful condition of many obese sufferers
who sincerely want to reduce but who cannot seem to
control their appetites. Nor are these helpless people
simple victims of trying to conform to the arbitrary
standards of our weight-conscious society as suggested
by Smart and Smart. Obesity can be a genuine threat
to survival, and it is not just another one of our culture's silly "no-no's."
The gravity of the obesity problem makes Schachter's psychological findings valuable in showing how
people function whose cues about appetite and satiety
supply little or false information. The value of his
findings may be cheapened by the uncritical association
with an enthusiastically held but poorly supported

hypothesis about cardinal psychological types who incidentally are obese. The humorous tone of Schachter's article indicates that it may be time for psychology to abandon some of its humor about neurons
and to embrace some truth about neurohumors. The
time seems overdue to build a scientific understanding
of people where behavior and physiology combine to
give an integrated picture of people coping both consciously and unconsciously to survive.
REFERENCES
BAUER, E. R. Inhibition of eating in the obese: Cognition
. or guilt? American Psychologist, 1971, 26, 738.
GELLHORN, E., & LOOFBOURROW, G. N. Emotions and
emotional disorders: A neurophysiological study. New
York: Harper & Row, 1963.
KAPLAN, S. D. Obesity and the emotions. Nebraska State
Medical Journal, 1966, 51, 41-47.
MROSOVSKY, N. Hibernation and the hypothalamus. New
York: Appleton-Century-Crofts, 1971.
SCHACHTER, S. Some extraordinary facts about obese humans and rats. American Psychologist, 1971, 26, 129144.
SMART, M. S., & SMART, R. C. On Schachter on obesity.
American Psychologist, 1971, 26, 935-936.
TEMPLER, D. I. Anorexic humans and rats. American
Psychologist, 1971, 26, 935.

S. DAVID KAPLAN
Sedgwick County Mental Health Center
Wichita, Kansas

In Defense of "Bootstrapping"
In a recent comment, Weinstein (1972) suggested
that my findings supporting "bootstrapping" (Dawes,
1971) "may have been an artifact of an inappropriate
comparison between two different samples." There
appears to have been some misunderstanding on his
part—or lack of communication on mine—because, in
fact, nowhere in the entire study did I ever compare
validities based on two different samples.
Weinstein stated that I found a low relationship
(r — .19) between admissions ratings and consequent
faculty ratings of performance in one sample of 23
graduate students. Absolutely true. He then went on
to state,
It should be perfectly clear that this relationship ignores
all applicants who were not admitted, and there is a strong
likelihood that the reported correlation is an underestimate
of the committee's forecasting ability because the range
of the admissions committee's ratings is restricted severely.

Again, absolutely true; in fact, Footnote 4 of my
article begins "Only selected applicants can be studied.
The resulting restriction of the range of talent attenuAMERICAN PSYCHOLOGIST • AUGUST 1972 • 773

<-----Page 1----->ates correlations . . . ." But the point is that the
correlation of .19 was compared to a correlation of .25
computed on the same restricted range of subjects,
that is, students who were actually admitted and who
came to the University of Oregon. (The linear composite itself was based on the paramorphic representation of admissions committee's ratings of a separate
sample of applicants and hence has no need to be
"cross-validated"; apparently, this fact was not made
sufficiently clear, because Weinstein refers to this correlation as "not cross-validated.") Further, the second comparison of admissions ratings to linear composites was again based on a sample in the same restricted range of students who had been admitted and
who came to the University of Oregon.
Weinstein could have a point if it were the case
that the restricted sample led to a greater reduction
in variance of admissions committee ratings than in
variance of linear composites. Here, with the criterion
variable held constant, a greater relative reduction in
the range of one predictor than in the range of another
could have artifactually resulted in a lower correlation.
But the exact opposite appears to be the case. While
I was not able to reevaluate all of the data discussed
in the article, I was able to compute the variances of
the linear composites and of the mean admissions committee ratings for both the selected and unselected students applying for the fall of 1970. The variance of
the linear composites for the entire applicant population was 1.11, compared to .24 for the population of
the students who actually came to Oregon. The variance of the mean admissions committee ratings for
the entire applicant population was 1.83, compared
with .49 for the population of students who actually
came. Thus, the variance of the linear composites was
reduced by a factor of 4.6, while that of the mean
ratings was reduced by a factor of 3.7.
Weinstein suggested that I "correct" the correlations
based on the restricted samples for attenuation due to
range of talent. The reason I did not do so was that
such corrections are of dubious value when attenuation
is as extreme as it was in my sample (Novick, personal
communication).
Finally, Weinstein wrote that "in his zeal to support 'bootstrapping,' Dawes completely ignored another
of his findings." Rather than ignore this finding, I
used it to illustrate the very first principle I discussed:
that linear composites based on paramorphic representations are superior to those based on actuarial analysis.
Clearly, no linear prediction of criterion performance
can be superior to that derived by the standard leastsquares procedure to predict such performance. The
value of bootstrapping is that it may be used in context where such actuarial analysis is impossible—for
example, where criterion information is lacking, or

774 • AUGUST 1972 • AMERICAN PSYCHOLOGIST

where it may not become available until after the
time when the decisions must be made. (For research
purposes, I have used a situation in which the criterion is in fact available; the technique is intended to
be used, however, where it is not.) I will, on the
other hand, plead guilty to having some "zeal" for
bootstrapping—not on the basis of ignoring data, but
on the basis of the consistency with which it has
worked—in my admissions study, in Goldberg's (1970)
study, in the Wiggins and Kohen (1971) study, and
in a replication of their study that we have conducted
in Oregon. In fact, in the last two studies, only 1 out
of 139 judges failed to be bootstrapped.
REFERENCES
DAWES, R. M. A case study of graduate admissions:
Application of three principles of human decision making.
American Psychologist, 1971, 26, 180-188.
GOLDBERG, L. R. Man versus model of man: A rationale,
plus some evidence, for a method of improving on clinical
inferences. Psychological Bulletin, 1970, 73, 422-432.
WEINSTEIN, A. G. On Dawes' "Bootstrapping." American
Psychologist, 1972, 27, 231.
WIGGINS, N., & KOHEN, E. S. Man versus model of man
revisited: The forecasting of graduate school success.
Journal of Personality and Social Psychology, 1971, 19,
100-106.
ROBYN M. DAWES
University of Oregon
and
Oregon Research Institute,
Eugene

Signifying Significant Significance
The question of whether or not research journals
tend to reject articles yielding nonsignificant results
has been raised periodically (Bakan, 1966; Sidman,
1960; Sterling, 1959). In addition, the evidence has
suggested that published significant results are seldom
verified by independent replication of the type that
the methodology corresponds closely to that of initial
studies (Smith, 1970). Cohen (1965) and Lykken
(1968) have also, referred to difficulties with tests of
significance in psychological research. Sterling reviewed the January-December 1965 editions of the
Journal of Experimental Psychology, the J'ournal of
Clinical Psychology, and the Journal of Comparative
and Physiological Psychology. He found that in the
362 research reports, 81% used tests of significance, of
which 97% reported rejection of the null hypothesis at
less than or equal to the .05 alpha level. None of
these research reports were replications of previously
published experiments.

