<-----Page 0----->EDITORIAL BOARD
Michael Lissack, Institute for the Study of Coherence and Emergence
<http://www.emergence.org/>; <lissack@lissack.com>
Max Boisot, Judge Management Institute, Cambridge, <boisot@attglobal.net>
David Boje, New Mexico State University, <dboje@nmsu.edu>
Jerry L.R. Chandler, George Mason University, <jlrchand@erols.com>
Paul Cilliers, University of Stellenbosch, <fpc@sun.ac.za>
Colin Crook, Citicorp (retired), <colin_crook@email.msn.com>
Lynn Crawford, University of Technology, Sydney <lynn.crawford@uts.edu.au>
Kevin Desouza, University of Illinois at Chicago <kdesou1@uic.edu>
Kevin Dooley, Arizona State University, <kevin.dooley@asu.edu>
William Frederick, University of Pittsburgh, <billfred@katz.pitt.edu>
Raghu Garud, New York University, <rgarud@exchange.stern.nyu.edu>
Jeffrey Goldstein, Adelphi University, <goldstei@adelphi.edu>
Hugh Gunz, University of Toronto, <gunz@fmgmt.mgmt.utoronto.ca>
John Hassard, Manchester School of Management, <john.s.hassard@umist.ac.uk>
Heather Hopfl, Newcastle Business School, <h.hofpl@unn.ac.uk>
Alicia Juarrero, Prince George’s Community College, <juarreax@pg.cc.md.us>
Stu Kauffman, BiosGroup, <stu@biosgroup.com>
Hugo Letiche, University for Humanist Studies, <h.letiche@uvh.nl>
Steve Maguire, McGill University, <smaguire@management.mcgill.ca>
Bill McKelvey, University of California, <smckelvey@anderson.ucla.edu>
Yasmin Merali, University of Warwick, <yasmin.merali@warwick.ac.uk>
Gerald Midgley, University of Hull, <g.r.midgley@hull.ac.uk>
Don Mikulecky, Virginia Commonwealth University, <mikulecky@hsc.vcu.edu>
Eve Mitleton-Kelly, London School of Economics, <e.mitleton-kelly@lse.ac.uk>
Steven Phelan, University of Texas, Dallas, <sphelan@utdallas.edu>
Larry Prusak, IBM Consulting, <lprusak@us.ibm.com>
Kurt Richardson, Institute for the Study of Coherence and Emergence, <kurt@kurtrichardson.com>
Jan Rivkin, Harvard Business School, <jrivkin@hbs.edu>
John Seely Brown, XEROX PARC, <john_seely_brown@pa.xerox.com>
Andrew Tait, Idea Sciences, <andrew.tait@ideasciences.com>
Haridimos Tsoukas, University of Cyprus, <htsoukas@atlas.pba.ucy.ac.cy>
Willard Uncapher, University of Texas, <paradox@home.actlab.utexas.edu>
Robin Wood, The White Space Partnership Limited, <robin@inspiralworld.org>
Production Editor: Cindy Capitani, Lawrence Erlbaum Associates, Inc., <cynthia.capitani@erlbaum.com>
Managing Editor: Jacco van Uden, <jacco@isce.edu>
Subscriber Information: Emergence is published four times a year by Lawrence Erlbaum Associates, Inc., 10
Industrial Avenue, Mahwah, NJ 07430-2262. Subscriptions are available electronic only on a calendar-year basis.
Electronic subscription rates are $45 for individuals, $200 for institutions, and $20 for students. Order electronic
subscriptions through the Journal Subscription Department, Lawrence Erlbaum Associates, Inc., 10 Industrial
Avenue, Mahwah, NJ 07430-2262, or visit the LEA Web site at http://www.erlbaum.com for complete information.
Copyright © 2003, Lawrence Erlbaum Associates, Inc. No part of this publication may be reproduced, stored in
a retrieval system, or transmitted, in any form or by any means, electronic, mechanical, photocopying, microfilming, recording, or otherwise, without permission of the publisher. Send special requests for permission to the
Permissions Department, Lawrence Erlbaum Associates, Inc., 10 Industrial Avenue, Mahwah, NJ 07430-2262.
Printed in the United States of America. ISSN 1521-3250.

<-----Page 1-----><-----Page 2----->Emergence
A Journal of Complexity Issues in
Organizations and Management
a publication of The Institute for the Study of
Coherence and Emergence
Volume #5, Issue #3, 2003

Editor’s Note

3

Complexity and the Role of Ethics in Health Care
Ann E. Mills, Mary V. Rorty, & Patricia H. Werhane

6

Using the Creative Problem Solving Profile (CPSP) for
Diagnosing and Solving Real-World Problems
Min Basadur & Garry Gelade

22

The Redefinition of Memes: Ascribing Meaning to an
Empty Cliché
Michael R. Lissack

48

The Dark Side of Organizations and a Method to Reveal It
David A. Bella, Jonathan B. King, & David Kailin

66

Open Source as a Complex Adaptive System
Moreno Muffatto & Matteo Faldani

83

About the Authors

101

<-----Page 3-----><-----Page 4----->EMERGENCE, 5(3), 3–5
Copyright © 2003, Lawrence Erlbaum Associates, Inc.

Editor’s Note

D

uring the five years of this journal, much attention has
been paid to the vagaries associated with various words
and concepts important to the complexity perspective.
Recently I attended a meeting on Evolution and
Emergence, which brought home to me the continuing gap between how
many of the concepts are used in the sciences and how they get used
within the domain of human organizations. The word in question is the
very title of this journal: emergence.
The scientists attending the meeting placed an emphasis on the idea
that the only type of emergence worthy of consideration was what they
referred to as “ontological” emergence: the arrival into the world of something truly new. An awareness of new properties or descriptions as one
crosses levels of analysis was dismissed as mere “epistemological emergence” and “subject to reduction: therefore not worthy of discussion.”
The exceptions to this view came from yours truly and from Stuart
Kauffman.
The quasi-realist bias of the attendees was evident, and perhaps the
rejection of the validity of descriptive claims stemmed from the realist
perspective. From the perspective of a pragmatically based constructivism, there is an ontological validity to observations that are new to the
observer. For that observer, newly cognized entities are indeed new entities and the new cognition can lead to a change in perspective or behavior. The scientists at the conference rejected this assertion. They afforded
no validity to the idea that for any given set of observers a concept,
description, property, or entity might be new. To them, validity was
ascribed only to absolute newness; that is, for all possible sets of
observers (i.e., the universe) the observed entity was new. Thus the
scientists placed an emphasis on the process of emergence and on its
uniqueness. By contrast, those concerned with human organizations
3

<-----Page 5----->EMERGENCE
recognize that emergence of the observer-dependent cognitive variety is
a common occurrence with manifold consequences.
In human organizations it is not the process of emergence that has lasting significance; instead, it is the consequences of the process—systemlevel changes in properties, descriptions, labels, cognitions—the
emergents that are afforded import. These changes are highly observer
dependent. It is not always the case that the members of the organization
(the agents) will have an awareness of the system-level properties giving
rise to the emergence/emergents in question. The presence or absence of
such awareness gives rise to the possibility of a feedback loop, which itself
may then lead to further emergence or to resistance to such emergence.
This type of feedback loop is usually not even a possibility in the emergence models of the scientists and further distinguishes the concerns and
activities of human organizations from the computer models and biological experiments with which the emergence scientists are concerned.
The feedback loop has yet another consequence: In human organizations the opportunity for communication about the pressures and resistance to what are recognized as emergents summons the equivalent of an
immune system response. This response has a further critical distinction:
The co-adaptation of a transformation may be incorporated into the “self ”
requiring protection. Biological organisms seldom incorporate systemic
transformation into definitions of self; human organizations do it often.
Indeed, this journal is about to undergo such a transformation. Beginning with Volume 6 our publisher will no longer be Laurence Erlbaum
Associates but will become Palgrave/Macmillan. Our format will once
again include an in-print paper edition. Our title will continue as
Emergence, but the words following the colon will change to reflect a
broader scope: Complexity and Organization. The journal will bring
together the efforts of three organizations: the Institute for the Study of
Coherence and Emergence, the Complexity Society of the UK, and the
Cynnefin Institute of IBM and the University of Cardiff.
Emergence such as this has many lasting emergents. Readers and
potential contributors are urged to visit the journal’s website at
www.emergence.org to learn how our reviewing methods are being tightened, how we will be encouraging the submission and publication of
practitioner-oriented articles, and how we have reorganized the editorial
board to reflect our widened scope. I am pleased to announce that
Emergence will have three editors-in-chief: Peter Allen, Jeffrey
Goldstein, and David Snowden; and a new managing editor, Steven
Barth. The next issue (5.4) will be my last as editor, though I will continue
4

<-----Page 6----->VOLUME #5, ISSUE #3
with the journal in a new role as Founding Editor Emeritus and with a
regular short column.
Emergence (the journal) has seen the complexity and organization
community transform over the past five years and we have been proud of
our role in that transformation. Thanks are due to our readers, editors,
contributors, reviewers, and the many members of the Complex-M
Internet mailing list. Emergence is emerging—despite what the hard
scientists and realists might think.
Michael R. Lissack

5

<-----Page 7----->EMERGENCE, 5(3), 6–21
Copyright © 2003, Lawrence Erlbaum Associates, Inc.

Complexity and the Role of
Ethics in Health Care
Ann E. Mills, Mary V. Rorty, & Patricia H. Werhane

T

his article addresses the problem of organizational change
in a rapidly changing institutional sector, the United States
health care system. After a brief respite, the cost of health
care has continued to rise. In addition, industry leaders are
concerned about the rate of medical errors and other threats to quality
that result in the needless deaths of between 44,000 and 92,000
Americans per year (Kohn et al., 2000). Thus, the health care system and
its components are under pressure to improve the quality of processes
and outcomes of care, but simultaneously they are wrestling with
demands to reduce, or at least constrain, costs (Kleinke, 2001; Robinson,
1999; Scott et al., 2000).
Even when change is necessary, conflicts of values and goals can
impede the capacity of a complex organization to implement those necessary changes. The extent to which the values of its members are congruent with and further the goals of the organization plays an important
role in its success in initiating and surviving change. Congruence in values between the organization and its members can result in an ethical climate that is conducive to and supportive of change, but such congruence
will depend on the appropriate identification of the systems and
processes that make up the organization’s culture.
The influential Institute of Medicine, a research organization devoted
to problems of the US health care system, recently addressed the problem of improving that system’s quality by recommending that it be
approached as a complex adaptive system (Committee on Quality and
Health Care in America, 2001; hereafter CQC). In what follows we

6

<-----Page 8----->VOLUME #5, ISSUE #3
accept that committee’s assumption that this approach will prove fruitful
in addressing the problems of this troubled sector, and focus on one segment of the larger system, the health care organization. We distinguish
between an adaptive and a mechanical approach to its subsystems and
processes, and describe what we mean by a positive ethical climate, and
its role as an indicator of organizational culture. We discuss actual and
potential damaging effects of approaching adaptive systems mechanically,
and recommend an organization ethics program to increase the flexibility
of the health care organization’s culture in a way that does not threaten its
cohesiveness.

COMPLEXITY

AND HEALTH CARE

There has been considerable work done in the last few decades applying
complex systems theory, the study of the dynamics of change, to social
systems. Despite significant success in generating applicable models in
other disciplines, complexity is not yet a science when applied to some
areas of human social interactions. However, complexity theory offers a
new perspective on the relationships that make up various systems, and
in particular, the approach can be useful in understanding the relationships that characterize organizations. As a science applied to organizations, complexity theory recommends the empirical study of
organizational populations to develop models that can explain organizational dynamics and open up the possibility of interventionist strategies
(Dooley & Van de Ven, 1999: 358).
This descriptive and analytical task, which “models how microstate
events self-organize into emergent aggregate structures” (McKelvey,
1999: 5) is beyond the scope of this article. Our more modest goal is to
adopt a complexity perspective. In this approach, complexity is not a
methodology, but a way of thinking about organizations (Mitleton-Kelly,
1997: 3). Scholars occupied with particular problems in the social
sciences have found the approach illuminating in their own areas, and
there are a growing number of influential publications on strategy and
organizational complexity (Mitleton-Kelly, 1997; Olson & Eoyang, 2001;
Stacey, 1995, 1996, 2000).
A “system” is a complex of interacting components, together with the
relationships between them, which permits the identification of a
boundary-maintaining entity or process (Laszlo & Krippner, 1988: 51).
Systems may be micro (small, self-contained, relatively autonomous) or
macro (complex, with a large number of interconnections). There is a
7

<-----Page 9----->EMERGENCE
difference between primarily mechanical and primarily adaptive systems.
This distinction, in terms of rigidity, is fundamental. It describes how the
system is designed and how it responds to external stimuli. Social systems
differ from natural systems in that they incorporate human agents as components, affecting and affected by other agents and the environment,
capable of free will and innovation. Approaching the health care organization as a complex adaptive system emphasizes interrelations, interactions, and connectivity (Zimmerman & Dooley, 2001: 73), an approach
that is intuitively appealing when applied to health care, a service industry with human interaction at its core.
The Institute of Medicine report on quality suggests an orientation on
the goal of the health care system: to continually reduce the burden of illness, injury, and disability, and to improve the health and functioning of
the people of the United States (CQC: 39). It gives six specific aims to be
kept in mind as values to be maximized in developing strategies for
change: The resulting system should be safe, effective, patient centered,
timely, efficient, and equitable (CQC: 40). The recommendations bring
into prominence the normative aspect of organizational function: the values and obligations felt by individuals within the health care organization
in carrying out their activities. The recommendations of this report, conceived and forwarded in the spirit of complex adaptive thinking, can be
implemented in that spirit, in which case they will forward the goals of
the report, or taken more mechanically, in which case they may not be of
much help.
A health care organization is characterized by a number of complex
functions, processes, and roles, where objectives are often divergent,
leadership roles are shared, and power is diffuse (Denis et al., 2001). It is
composed of interlocking micro systems, some of which may be primarily
mechanical in nature. A system designed to produce predictable results
where there is a strong consensus about what outcomes are desirable can
usefully be viewed and treated as a mechanical system. In mechanical
systems we can predict in great detail the interaction of each of the parts
in response to a given stimulus. For instance, a health care organization
may employ mechanical processes in its billing or in other procedures
that are expected to occur in the same way time after time. When deviation from the anticipated interaction occurs, it is unexpected and generally provokes study and action to prevent recurrence (Plsek, 2001).
When a system has as its primary working parts human beings in
interaction, however, the parts of the system “have the freedom and ability to respond to stimuli in many different and fundamentally unpre8

<-----Page 10----->VOLUME #5, ISSUE #3
dictable ways” (Plsek, 2001: 310). A health care organization employs
teams to evaluate, treat, and monitor patients. These teams will be composed of case managers, doctors, nurses, social workers, chaplains, and
others. The interactions of the team members are not always identical and
so their consequences cannot always be foreseen or planned. Unplanned
consequences can be perceived as an error, or as “emergent, surprising,
creative behavior” (Plsek, 2001: 310) If the right conditions are present,
a patient team may interact together to produce surprising and creative
solutions to specific problems.

ETHICS

AND COMPLEXITY

We said above that the recommendations of the Institute of Medicine
report on quality bring into prominence the values and obligations felt by
individuals within the health care organization in carrying out their activities. Organizations also demonstrate their values and obligations through
their actions and decisions. For instance, an organization can be operating completely in accord with legal regulations and still be viewed as
behaving “unethically” according to generally accepted social norms, by
treating its employees unfairly, taking advantage of the ignorance of its
patients, or treating objects of wider social concern—endangered
species, the environment, underdeveloped societies—in ways with which
constituent members of the organization feel uncomfortable. Conversely,
an organization can clearly express its agreement with all the generally
accepted social norms that govern its areas of activity, but fail to institute
policies and procedures that accord with those values, creating dissonance in its membership between its espoused values and its actual
behavior. Because the approach of the Institute of Medicine’s report
focuses on goals and values to be realized, the ethical climate of a health
care organization becomes an important indicator of how successfully an
organization is orienting itself on its ultimate objectives.
The terminology of “ethical climate” comes from a large body of studies of organizational culture and climate in organization theory (Collins &
Porras, 1994; Sims, 2000; Trevino & Nelson, 1995; Victor & Cullen, 1988).
Recent scholarship has noted that the terms “culture” and “climate” are
sometimes used interchangeably and often refer to the same empirical
indicators (Denison, 1996; Detert et al., 2000). We distinguish the culture
of the organization—its structures, administrative style, priorities and
values, degree of tightness of interrelations, and feedback loops—from
the climate, its impacts on its constituent members. The reactions of the
9

<-----Page 11----->EMERGENCE
individuals who make up the organization to the structures, processes,
and rules that instantiate its espoused values result in a positive ethical
climate if the organization furthers their feelings of agency and reinforces
their personal and professional values, and a negative one if it impedes
them. The culture of an organization conceived as a complex adaptive
system may enact a different set of values and structures than an organization that conceives of itself as a mechanical system, and its ethical climate will be different as a consequence.
A positive ethical climate will have at least two important characteristics. First, it is the reflection of an organizational culture in which the mission and vision of the organization inform the expectations for
professional and managerial performance and are implemented in its
actual practices. Second, it embodies a set of values that reflect social
norms for what such an organization should value. In a health care organization, a positive ethical climate will result if the organization’s constituents are aware of its mission to provide excellent care at reasonable
cost, and will work to bring their activities at all levels of function in line
with that mission. An organizational culture that encourages, supports,
and rewards excellent professional standards and expert professional
judgment will have a positive ethical climate insofar as its constituent
members have a wide knowledge of, and internalization of, organizational
values, and perceive those values as consonant with their independent
professional and individual values and standards. An organization in an
environment that is forcing change upon it, or that desires to improve and
adapt but has structures or rules that impede change or impose change
without consensus, will have a negative ethical climate: low morale and
impeded agency. In such a case, the individuals whose decisions and
behavior constitute the organization will perceive it to be mouthing values on which it does not act, or to be impeding the processes that it is
simultaneously demanding.
In health care organizations there are several loci for normative consideration of organizational and individual actions. The legal department
attends to organizational compliance with federal, state, and local regulations and legislation. There may be a committee of medical staff to deal
with professional conduct by physicians, and hospitals of more than 200
beds are required for accreditation to maintain an institutional ethics
committee or process charged with consultation on conflicts arising in
decision making for patient care (Joint Commission on Accreditation of
Healthcare Organizations, 1992). Institutional ethics committees as
presently constituted have primary responsibility for the clinician/patient
10

<-----Page 12----->VOLUME #5, ISSUE #3
dyad and the policies associated with that relationship. This alreadyoperating normative locus in the institution, if expanded and cultivated as
recommended in this article, can serve some of the wider purposes of the
organization by being the custodian of the organization’s ethical climate.
In what follows, we suggest that the ethical climate of an organization
is an indicator for the extent to which it is adapting to the requirements
for survival and success in the current environment of turbulent change;
that the more a health care organization adopts a “complexity” approach
to appropriate systems and processes the more positive the ethical climate will be; and, finally, that an organization ethics process, introduced
in an adaptive, rather than mechanical, spirit, can encourage and sustain
a positive ethical climate.
We agree with the Institute of Medicine that the current situation in
health care requires flexibility, adaptability, and a strong orientation on
the goals and mission of the system: precision in areas of high predictability where there is a strong consensus about what outcomes are
desirable, such as quality control and efficiency of process, combined
with flexibility in areas of less predictability, where successful outcomes
depend on expert judgment and experience. Needless to say, one of the
greatest difficulties confronting any organization in tumultuous times is
properly to distinguish the areas in which greater control is an advantage
from areas in which it will prove an impediment. If these areas are
misidentified, they will be treated inappropriately and the goals of the
system may become obscure to those whose function it is to realize them,
while if the areas are appropriately identified, the goals of the system
components will be clear.

QUALITY

AND THE HEALTH CARE ORGANIZATION

Organization theorist Ralph Stacey calls the simultaneous presence of
two self-contradictory, essentially conflicting forces a “paradox.” It is possible, in some instances, to resolve the paradox by reframing the problem
or by consistently choosing one force all the time. In other instances, it
may not be possible to remove one or the other force; both must be
accommodated at the same time, and it is only possible to do this by continually shifting priorities (Stacey, 2000: 12). The current situation in
health care is rife with such competing pressures. We will discuss two
such paradoxes, one a product of environmental pressures on the health
care organization, one an internal one.

11

<-----Page 13----->EMERGENCE

AN

ENVIRONMENTAL PARADOX:
QUALITY IMPROVEMENT

COST

CONSTRAINT VS.

The delivery of health care has always been a business, but in the US it
has historically been a business that was generously funded by a society
that believed health care was more than simply a market commodity.
Despite criticisms that the industry was wasteful, and that payment
mechanisms and government funding incentivized unnecessary treatment and excess capacity, it can be reasonably argued that the US health
care system reflected the values of society concerning the delivery of care
for most of the last century (Starr, 1982). But that has changed.
Much of the current disarray in the health care system can be traced
to the reluctance of payers to continue to fund the increasing costs of
care. This changing paradigm has caused assumptions about the values
surrounding care to change as well. Both the costs and the quality of the
system are in need of improvement. However, for an individual health
care organization, the net effect can be its being subjected simultaneously
to incompatible pressures: “improve quality, whatever the cost” and “constrain costs, whatever the impact on the quality of care.” While use of
computer-based clinical decision-support systems, for instance, can
reduce errors in drug selection, dosage, interactions, and side effects, the
initial expense of the technology may be prohibitive for a small hospital
struggling for economic survival. Reducing staffing may save on payroll
expenses, but have undesirable effects on patient satisfaction and safety.
As market problems began to have a greater impact on hospital management, market solutions began to appear as well. Health care organization leaders, faced with revenue squeezes, a radical departure from the
past, looked to other industries to derive techniques that could help them
restrain the costs of health care. These techniques included restructuring
through merging, downsizing, consolidating to eliminate duplicate structures and excess capacity, and financial incentives to control clinician
behavior. These techniques share the same goal, of controlling costs
through changing the culture of the organization, and that has meant
changing its ethical climate.
Many manufacturing industries have introduced various “quality
improvement” technologies to improve the efficiency of their production
processes, and these technologies later spread to service industries,
including health care. The hope, and sometimes the promise, was that
improving efficiency of process would also reduce costs. Many of these
techniques were designed in the automotive and airplane industries and
employed as highly mechanical systems (Grant et al., 1994; Pande et al.,
12

<-----Page 14----->VOLUME #5, ISSUE #3
2000). The technologies employed by these initiatives are not flexible,
relying as they do on reducing waste or the misuse of resources through
the elimination of variation in process, and monitoring outcomes through
qualitative accountability mechanisms. Their application in health care
delivery organizations is problematic, because they typically assume that
tightening up the system will improve efficiency, and improved efficiency
will lead to a more effective system.
However, in health care increased efficiency in processes may or may
not improve the effectiveness of outcomes. Complexity thinking reminds
us that in the real world a fixed set of inputs will never produce a predictable set of outcomes, even when those inputs are apparently similar
and other factors are held constant. “In social systems, there are always
an infinite number of inputs that cannot be accounted for fully or held
constant” (Kleinke, 2001: 110). Changes in core functions need to be
introduced in a way that acknowledges the complexity of the organization
and allows for flexibility, monitoring their impact and accommodating to
unexpected results.

AN

INTERNAL PARADOX:
PATIENT PREFERENCES

EVIDENCE-BASED

MEDICINE VS.

Change in the social environment of health care is imposing the conflict
between cost containment and quality improvement on the health care
organization, because of reluctance or inability to continue to support
increasing costs. However, there are also competing values that must be
negotiated by individual practitioners and by organizations in evaluating
outcomes and the effectiveness of care.
Improving the quality of outcomes of clinical practice tends to focus
on standardizing treatments of the same disease across practitioners and
practice locations, through clinical guidelines and, in the last decade,
through increasing emphasis on evidence-based medicine (Kimberly,
2003: 209). Early definitions of evidence-based medicine emphasized the
“conscientious, explicit and judicious use of current best evidence in
making decisions about the care of individual patients” (Sackett et al.,
1996). It recommends utilization of population-based studies of treatment
outcomes in different locations, and suggests that variation in care of similar cases is a negative value and that uniformity and consistency across
cases are desirable.
At the same time, there is increasing attention to patient-centered
care—care customized, as the Institute of Medicine report puts it,
“according to patient needs and values” (CQC: 67). In the report, both
13

<-----Page 15----->EMERGENCE
patient-centered care and evidence-based medicine are proposed as
important values to be maximized in any reforms of health care delivery.
Evidence-based medicine is defined as “the integration of best research
evidence with clinical expertise and patient values” (CQC: 76). The
emphasis on customization based on patients’ needs and values suggests
variety and flexibility, giving maximal weight to clinical expertise and
patient values. The emphasis on standardization for uniformity of treatment constrains that maximal flexibility. Even within one central recommendation of the report, competing tensions toward mechanization and
adaptation are therefore visible. Administrative changes that move the
institution toward greater uniformity in clinical function may risk constraining clinical expertise or patient values.
How this tension is resolved will depend on whether or not the health
care organization appropriately distinguishes subsystems that should be
approached mechanically from those that should be treated adaptively,
whether it is able to distinguish those areas where greater control is
appropriate from those areas where it is not appropriate. While the
employment of efficiency processes in some of the mechanical functions
and subsystems of the health care organization may achieve savings,
approaching direct patient care in a mechanical, rather than adaptive,
way may be a threat to the flexibility that is crucial if professional expertise and patient values and preferences are going to be respected in clinical decision making. These choices will affect the culture and the ethical
climate of the organization, and determine the relationship that the
organization has with its constituents.
Changing the culture of the health care organization to reflect efficiency through a rigid approach has produced what many Americans
view as unacceptable results. Quality of care has suffered as team
empowerment has failed (Bednash, 2000), the physician–patient relationship is suspect (Feldman et al., 1998), nurses are leaving the field in
droves (Bednash, 2000; Berliner & Ginzber, 2002), many people are
frightened of health care organizations (Kao et al., 1998), and flexibility in
care is giving way to utilization measurements, punitive accountability
mechanisms, and what some physicians call “cook-book” medicine
(Flores et al., 2000). Many of these results we attribute directly to the
imposition of a complexity of rules formulated through the management
techniques we mentioned above, and imposed without regard for their
appropriateness for the system or subsystem in question, or for the
beliefs, values, and obligations of those affected (Mills & Rorty, 2002).

14

<-----Page 16----->VOLUME #5, ISSUE #3

CONFRONTING

PARADOX

Balancing tensions or competing goals is nothing new. Organizations and
individuals do it on a daily basis. The competing imperatives that we see
in health care cannot be reconciled by reframing the issue, nor is it a simple matter of prioritization. The problem is one of balancing the provider
mission of providing excellent patient care, with attention to patients’ values and preferences, and the goal of achieving it at a reasonable cost,
which many leaders of the “quality movement” in health care have taken
to mean reducing variations in delivery (Becher & Chassin, 2001;
Berkowitz & Checkley, 2000; Chassin et al., 1998). Complexity theory,
however, highlights the importance of deciding what kind of system
design is appropriate for the task at hand. If a health care organization can
appropriately identify those systems that call for mechanization and those
that require adaptivity, it can make appropriate choices within the context of achieving its goal of excellent patient care, thus sustaining an
appropriate culture and aligning important values.
For reasons of internal and external pressures, the health care system
is in a turbulent period of change. However, if we approach the health
care organization as a complex adaptive, rather than a mechanical, system, and accept the assumption of complex adaptive systems theory that
the ability to change and to encourage innovation will increase the likelihood of organizational survival and success, we need to consider what
structures and programs the health care organization might need to promote congruity of values among its agents. How can a positive ethical climate be developed, articulated, and maintained? We explore below a
process that the health care organization can introduce to encourage the
flexibility and creativity necessary for its mission.

THE

ORGANIZATION ETHICS PROCESS

In 1995, the Joint Commission on Accreditation of Healthcare Organizations (JCAHO) introduced a requirement for accreditation that requires
health care organizations to conduct their business and patient care practices in an “honest, decent and proper manner,” while maintaining the
priority of excellent clinical care. The JCAHO called this mandate
“organization ethics” (Joint Commission on Accreditation of Healthcare
Organizations, 1996: 95–7). A broader, more process-oriented definition
of health care organization ethics has been advanced by the Virginia
Healthcare Ethics Network:
15

<-----Page 17----->EMERGENCE
Organization ethics consists of [a set of] processes to address ethical issues
associated with the business, financial, and management areas of healthcare organizations, as well as with professional, educational, and contractual relationships affecting the operation of the healthcare organization.
(Spencer et al., 2000: 212)

Either approach to “organization ethics” recognizes that the quality of
care experienced by patients depends in part on the relationships that the
health care organization has with its stakeholders. These relationships
depend on stakeholder interactions. Both approaches insist that health
care organizations pay attention to these relationships and interactions by
creating a positive ethical climate throughout the health care organization. This approach directs attention to how the mission of the health care
delivery organization—to provide excellent care at reasonable cost—is
carried out in the organization’s business, clinical, and professional practices (Spencer et al., 2000). Thus, it directs attention to the culture of the
organization.
Although no particular structure for such a program or process is
specified by the accrediting agency, a model exists in the clinical ethics
committees already functioning in most hospitals. Some clinical ethics
committees are expanding membership and responsibility to take on
organization ethics roles; other institutions have established a separate
committee to address broader organizational issues (West & White,
2001).
A program designed to meet the JCAHO organization ethics mandate
could be approached mechanically or adaptively. Consonant with our
approach in this article, we do not propose that an organization ethics
program take on a rule-generating role, nor should it constitute yet
another decision-making authority. Instead, it should include representatives of the main functions of the organization, report to either top management or the governing board, and function as a forum for the
discussion of perceived conflicts of values arising in the course of organizational strategic change. It would have an advisory and educational
mandate.
For instance, in the case of proposed changes to clinical functions for
cost control, the program might form an ad hoc team to strategize about
what form the changes might take to reduce costs while maximizing
effectiveness. The mission and values of the organization include both
financial survival and clinical excellence, so the organizational culture
must include both these values, which means that the structure must
16

<-----Page 18----->VOLUME #5, ISSUE #3
have some degree of flexibility, as well as some means of adjudicating
when the two conflict. The organization ethics program represents an
opening for communication and adaptability—a process to bring together
all stakeholders associated with difficult decisions to ensure that the
voices of affected parties are represented. Conflict of values can be
treated as a threat to be avoided, or as inevitable, to be utilized as an
opportunity for creativity and innovation, and resolved within a broad
consensus on the value of patient care. Rather than serving as a source of
rules, the organization ethics program could help make many rules dispensable by supporting flexibility and creative interaction among the various agents of the health care delivery organization.

THE

ADAPTIVE ORGANIZATION

The health care delivery organization is not an island, but rather a subset
of a larger health care system that is itself subject to competing pressures
that affect all aspects of care. It is not appropriate to assign part of its mission—excellent clinical care—to the clinical component, while leaving
cost constraints to another component, the administration. The entire
organization must function as an organic whole to achieve all its objectives, but that may require some adjustment of traditional roles and
responsibilities. It is well advised to identify those expectations that persist through environmental alterations and define it as a health care
delivery organization (i.e., reducing patient suffering, increasing clinical
expertise), and work toward promoting an awareness of these expectations through the organization’s beliefs, behaviors, and methods of decision making rather than through mechanical imposition of rules.
However, it is important that expectations about the desired goal are
clear, that the few simple rules are appropriate means to the desired goal,
and that if and when the rules or expectations conflict, some way for adjudication is available.
Adaptability in an organization depends on the connections between
its agents. The degree of communication and trust between organizational stakeholders is a better predictor of successful adaptation to a
changing environment than are inflexible role definitions and tight compartmentalization of work units. Changes in policy or procedure will have
the best chance of success if the proposed innovations are discussed in
advance with those who will be most affected by them, and if their implementation is accompanied by ongoing feedback and fine tuning.
Approaching the health care organization as a complex adaptive system,
17

<-----Page 19----->EMERGENCE
as recommended by the Institute of Medicine reports, will have implications for the structure, administrative style, priorities and values, degree
of tightness of interrelation, and availability of options for feedback—the
culture of the organization. An organization that focuses on its defining
values and works to further them in a flexible and dynamic way has the
best chance of surviving and thriving in a changing environment.

SUMMARY

AND CONCLUSION

A new approach to the health care delivery organization is needed—one
that creates the conditions for fostering information flow, connectivity,
relationships, and the emergence of creative problem solving from the
members of the organization (Olson & Eoyang, 2001: 19). “Complexity is
not a methodology or a tool,” one advocate writes, “but a way of thinking”
(Mitleton-Kelly, 1997: 3). Industry leaders are beginning to adopt this
way of thinking about the health care system and are urging that all of its
components adopt a few simple rules to support the goal of reducing the
burden of illness in the US.
We have accepted the premise of the Institute of Medicine report that
problems of quality improvement in the health care system can best be
addressed by adopting an adaptive, rather than a mechanical, model of
that system, and have examined some implications for the health care
organization, itself viewed as a complex adaptive system. To view the
health care system as a complex adaptive system, as the Institute of
Medicine report recommends, or the health care organization as a complex adaptive system, as we have attempted to do in this article, is to
adopt a perspective on an organization that foregrounds processes, not
structures, relations, and interactions, not rigid institutional roles or
atomistic individuals. It takes rules and roles as thumb rules, goals, and
guidelines for action, not rigid prescriptions or constraints, and emphasizes the extent to which any locus of agency, be it an individual or organization, reacts to and can influence the whole of which it is a part.
Focusing on two possible sources of conflict that affect the daily functioning of the health care organization, we have recommended adopting
an organization ethics program, conceived as an internal forum for
addressing conflicts of value. Positioning an organization ethics program
as facilitator and guardian of a positive ethical climate can increase the
health care organization’s chances of attaining its long-term goals while
simultaneously preserving enough flexibility to allow beneficial emergent
behavior.
18

<-----Page 20----->VOLUME #5, ISSUE #3

NOTE
This work was supported by a grant from the Batten Institute of the Darden Graduate
School of Business Administration at the University of Virginia.

REFERENCES
Becher, E. C. & Chassin, M. R. (2001) “Improving quality, minimizing error: Making it happen, a five point plan and why we need it,” Health Affairs, 20(3): 68–81.
Bednash, G. (2000) “The decreasing supply of registered nurses: Inevitable future or call to
action?,” Journal of the American Medical Association, 283(22): 2985–7.
Berkowitz, K. S. & Checkley, J. R. (2000) “Blueprint for success,” Managed Healthcare,
10(4): 27–9.
Berliner, H. S. & Ginzber, E. (2002) “Why this hospital nursing shortage is different,”
Journal of American Medical Association, 288(21): 2742–4.
Chassin, M. R., Galvin, R. W., & the National Roundtable on Health Care Quality (1998)
“The urgent need to improve health care quality,” Journal of the American Medical
Association, 280(11): 1000–5.
Collins, J. C. & Porras, J. I. (1994) Built to Last: Successful Habits of Visionary Companies,
New York: HarperCollins.
Committee on Quality and Health Care in America (2001) Crossing the Quality Chasm: A
New Health System for the 21st Century, Institute of Medicine, Washington, D.C.:
National Academy Press.
Denis, J. L., Lamothe, L., & Langley, A. (2001) “The dynamics of collective leadership and
strategic change in pluralistic organizations,” Academy of Management Journal, 44(4):
809–37.
Denison, D. R. (1996) “What is the difference between organizational culture and organizational climate? A native’s point of view on a decade of paradigm wars,” Academy of
Management Review, 21: 619–54.
Detert, J. R., Schroeder, R. G., & Mauriel, J. J. (2000) “A framework for linking culture and
improvement initiatives in organizations,” Academy of Management Review, 25(4, Oct):
850–63.
Dooley, K. J. & Van de Ven, A. H. (1999) “Explaining complex organizational dynamics,”
Organization Science, 10(3): 358–72.
Feldman, D. A., Novack, D., & Gracely, E. (1998) “Effects of managed care on
physician–patient relationships, quality of care, and the ethical practice of medicine,”
Archives of Internal Medicine, 10/24(Aug): 1626–32.
Flores, G., Lee, M., Bauchner, H., & Kastner, B. (2000) “Pediatricians’ attitudes, beliefs and
practices regarding clinical practice guidelines: A national survey,” Pediatrics, 105(3,
Mar): 496–501.
Grant, R. W., Shani, R. & Krishnan, R. (1994) “TQM’s challenge to management theory and
practice,” Sloan Management Review, 35(2): 25–35.
Joint Commission on Accreditation of Healthcare Organizations (1992) “Patient rights,” in
Comprehensive Manual for Hospitals, Oakbrook Terrace, IL: Joint Commission on
Accreditation of Healthcare Organizations: 103–5.
Joint Commission on Accreditation of Healthcare Organizations (1996) “Patient rights and
organizational ethics: Standards for organizational ethics,” in Comprehensive Manual
for Hospitals, Oakbrook Terrace, IL: Joint Commission on Accreditation of Healthcare
Organizations, 95–7.
Kao, A. C., Green, D. C., Davis, N. A., Koplan, J. P., & Cleary, P. D. (1998) “Patients’ trust in

19

<-----Page 21----->EMERGENCE
their physicians: Effects of choice, continuity, and payment method,” Journal of General
Internal Medicine, 13(10): 681–6.
Kimberly, J. R. & Minvielle, E. (2003) “Quality as an organizational problem,” in S. S. Mick
& M. E. Wyttenbach (eds), Advances in Health Care Organization Theory, San
Francisco: Jossey Bass.
Kleinke, J. D. (2001) Oxymorons: The Myth of a U.S. Health Care System, San Francisco:
Jossey Bass.
Kohn, L. T., Corrigan, J. M., & Donaldson, M. S. (eds) Committee on Quality of Health Care
in America (2000) To Err is Human: Building a Safer Health System, Institute of
Medicine, Washington, D.C.: National Academy Press.
Laszlo, A. & Krippner S. (1998) “Systems theories: Their origins, foundations and development,” in J. Scott Jordon (ed.), Systems Theories and a Priori Aspects of Perception,
Amsterdam: Elsevier: 47–74.
McKelvey, B. (1999) “Complexity theory in organization science: Seizing the promise or
becoming a fad?,” Emergence, 1(1): 5–32.
Mills, A. E. & Rorty, M. V. (2002) “Total quality management and the silent patient,”
Business Ethics Quarterly, 12(4): 481–504.
Mitleton-Kelly, E. (1997) “Organisations as co-evolving complex adaptive systems,” British
Academy of Management Conference, reproduced in the Business Process Resource
Center files, http://bprc.warwick.ac.uk/eve.html, last visited 4/17/2003.
Olson, E. E. & Eoyang, G. (2001) Facilitating Organization Change: Lessons from
Complexity Science, San Francisco: Jossey Bass/Pfeiffer.
Pande, P. S., Neuman, R. P. & Cavanagh, R. R. (2000) The Six Sigma Way: How GE, Motorola,
and Other Top Companies Are Honing Their Performance, New York: McGraw-Hill.
Plsek, P. (2001) “Redesigning health care with insights from the science of complex adaptive
systems,” in Crossing the Quality Chasm: A New Health System for the 21st Century,
Washington D.C.: National Academy Press: 310–33.
Robinson, J. C. (1999) The Corporate Practice of Medicine, Berkeley, CA: University of
California Press.
Sackett, D. L., Rosenberg, W. M. C., Gray, J. A. M., Haynes, R. B., & Richardson, W. S.
(1996) “Evidence based medicine: What it is and what it isn’t,” British Journal of
Medicine, 312: 71–2.
Scott, W. R., Rueff, M., Mendel, P. J., & Caronna, C. A. (2000) Institutional Change and
Healthcare Organizations, Chicago: University of Chicago Press.
Sims, R. R. (2000) “Changing an organization’s culture under new leadership,” Journal of
Business Ethics, May: 65–78.
Spencer, E. M., Mills, A. E., Rorty, M. V., & Werhane, P. H. (2000) Organization Ethics for
Healthcare Organizations, New York: Oxford University Press.
Stacey, R. D. (1995) “The science of complexity: An alternative perspective for strategic
change processes,” Strategic Management Journal, 16(6): 477–95.
Stacey, R. D. (1996) Complexity and Creativity in Organizations, San Francisco: BerrettKoehler.
Stacey, R. D. (2000) Strategic Management and Organizational Dynamics: The Challenge of
Complexity, London: Pearson Education.
Starr, P. (1982) The Social Transformation of American Medicine, New York: Basic Books.
Trevino, L. K. & Nelson, K. A. (1995) Managing Business Ethics: Straight Talk about How to
Do It Right, New York: John Wiley.
Victor, B. & Cullen, J. (1988) “The organizational bases of ethical work climates,”
Administrative Science Quarterly, 33(3): 101–25.

20

<-----Page 22----->VOLUME #5, ISSUE #3
West, J. & White E. (2001) “The development of the Sentara healthcare system’s ethics program,” in A. E. Mills, E. M. Spencer, & P. H. Werhane (eds), Developing Organization
Ethics in Healthcare: A Case-Based Approach to Policy, Practice and Compliance,
Frederick, MD: University Publishing Group.
Zimmerman, B. & Dooley, K. (2001) “Mergers versus emergers: Structural change in health
care systems,” Emergence, 3(4): 65–82.

21

<-----Page 23----->EMERGENCE, 5(3), 22–47
Copyright © 2003, Lawrence Erlbaum Associates, Inc.

Using the Creative Problem
Solving Profile (CPSP) for
Diagnosing and Solving
Real-World Problems
Min Basadur & Garry Gelade

O

rganizations around the world face a common challenge:
the need to improve their performance in order to capitalize on rapid change. In North America, restructuring
and downsizing have become a way of life as organizations struggle to regain market share from global companies producing
higher-quality products. In eastern Europe, managers and employees
strive to establish new behaviors and procedures that will allow their
companies to compete in the free market. In the developing world, countries hungry for economic development look for growth markets abroad.
In Japan, organizations that once had a clear target—to overtake their
western competitors—now lack a blueprint for further progress.

A

SIMPLE BLUEPRINT

Mott (1972) presented evidence that effective organizations display three
characteristics: efficiency, adaptability, and flexibility. The efficient organization follows well-structured, stable routines for delivering its product
or service in high quantities, with high quality, and at low cost. In a stable world, efficient organizations may be successful. But in a changing
world, organizations also need adaptability. While efficiency implies mastering a routine, adaptability means mastering the process of changing a
22

<-----Page 24----->VOLUME #5, ISSUE #3
routine. Adaptable organizations monitor the environment for new technologies, ideas, and methods, anticipate threats and opportunities, and
implement changes accordingly. They deliberately and continually
change their routines to improve quality, raise quantities, reduce costs,
and stay ahead of their competitors. The most effective organizations are
both efficient and highly adaptable. While adaptability is a proactive
process of looking for ways to change, flexibility is reactive. Flexibility
allows the organization to react quickly to unexpected disruptions without getting mired in organizational bureaucracy. It allows the efficient
organization to deal with disruptions while maintaining its routines. In
today’s rapidly changing world, leaders of effective organizations aiming
to achieve sustained competitive edge induce not merely efficiency and
flexibility but adaptability.

THE

PROCESS APPROACH TO APPLIED CREATIVITY

Basadur (1992, 1995) provided evidence that organizations can attain sustainable competitive edge by institutionalizing creativity as an
organization-wide process. In this article, we suggest a multi-stage
process model for understanding and implementing organizational creativity. We outline this multi-stage process in terms of different ways of
gaining and using knowledge. Recognizing that individual preferences
vary for different stages of the process, the article describes the Creative
Problem Solving Profile (CPSP) inventory, a practical tool that helps in
understanding organizational creativity as a process and serves as a
method of diagnosing and solving real-world problems. We outline several real-world applications of the CPSP and suggest avenues for future
research.

A

NEW THEORY OF CREATIVITY AS A CIRCULAR, MULTI-STAGE
PROCESS

Adaptability is driven by organizational creativity, which can be defined
as a continuous process of thinking innovatively, or of finding and solving
problems and implementing new solutions. Various researchers have
focused on the circular nature of adaptability, or the creative process.
Gordon (1956, 1971) recognized that knowledge acquisition (learning)
and knowledge application (for inventing) flow continuously and sequentially into one another. Field research by Carlsson et al. (1976) supported
Gordon’s approach by showing that the organizational research and
development (R&D) process follows a continuous, circular flow of
23

<-----Page 25----->EMERGENCE

Quadrant IV
IMPLEMENTING
Creating options in the
form of actions that get
results and gain
acceptance for
implementing a change
or a new idea

Quadrant I
GENERATING
Creating options in the
form of new possibilities—
new problems that might
be solved and new
opportunities that might be
capitalized on

Quadrant III
OPTIMIZING
Creating options in the
form of ways to get an
idea to work in practice
and uncovering all the
factors that go into a
successful plan for
implementation

Quadrant II
CONCEPTUALIZING
Creating options in the
form of alternate ways to
understand and define a
problem or opportunity
and good ideas that help

Figure 1 The four stages of the creative process
creating new knowledge to replace old knowledge. Consistent with these
findings, Basadur’s field work (1974, 1983) on organization-wide deliberate change depicted the creative process as a circle, recognizing that new
problems and solutions lead continuously to further problems and opportunities. Each quadrant in the circle corresponds to a specific stage of a
four-stage creative process. The first two quadrants represent the components of problem finding: generation and conceptualization. The third
and fourth quadrants represent problem solving (optimization) and solution implementation as the final two stages of the creative process. In
each stage, people gain and use knowledge and understanding in various
ways.
The complete process is called the Simplex Creative Problem Solving
process (Figure 1). Basadur et al. (1982) demonstrated that individuals
and organizations could deliberately develop skills in executing each
stage of this process, and in executing the complete process. Additional
field research supporting the practicality of applying this process in
organizations is summarized in Basadur (1994, 2000).

24

<-----Page 26----->VOLUME #5, ISSUE #3

THE

FOUR STAGES OF CREATIVITY

Following is a brief description of the four quadrants integrating the concepts of the various researchers above.

Quadrant 1: Generating
The first quadrant gets the creative process rolling. Creative activity in
this quadrant involves gaining knowledge and understanding by physical
contact and involvement in real-world activities, and utilizing this knowledge to create new problems, challenges, opportunities, and projects
that are potentially worth defining and undertaking through subsequent
solving and implementing. Understanding is derived from what is experienced, including emotions and feelings of self and others through empathy. New possibilities are imagined from what is concretely experienced.
Quadrant 1 activity thus consists of sensing, seeking, or anticipating problems and opportunities, and is called generation. An outcome of this stage
is a problem worthy of investigation but not yet clearly defined or
understood.
Edwin Land, in a Life magazine cover story (Callahan, 1972), told the
tale of his invention of the Polaroid camera. Having snapped the last
exposure on his film, he suggested to his young daughter that they take
the film for processing so that they could see the pictures in about a
week’s time. Her frustrated response was, “Why do I have to wait a week
to see my picture?” Like a flash bulb going off in his mind, her simple
question sparked a challenge that had never occurred to him: “How can
we make a device that yields instantaneous pictures?” Within about an
hour, he had formulated several directions toward a solution. And within
about four years, he had commercialized a product that has changed our
lives. Looking back, the then-chairman of Polaroid said that the most
important part of the process was not finding the solution itself—the
camera—but finding the problem—how to get instantaneous pictures. If
Land had not experienced the chance encounter, he might never have
created the problem to be solved. He thus demonstrated the generation
stage of the creative process: initiating problems to solve instead of waiting for problems to be provided.
At Japan’s electronics giant Toshiba, most engineers and scientists
beginning their careers in research and development actually start working in the sales department (Basadur, 1992). This apparently backward
approach is designed to teach them the process of problem finding. Since
they will spend their working lives creating products to solve customers’
problems, what better start than by learning first-hand about their
25

<-----Page 27----->EMERGENCE
customers, their needs, their habits, and their problems—both visible
and hidden. At Nippondenso, a major auto parts supplier, employees are
trained and encouraged from day one to find problems, to be discontented with their jobs. Employees write down their “discontents” and
post them for co-workers to read. Here and at many other Japanese companies, this is the start of the creative process called the employee suggestion system. What is important is that the entire suggestion system
hinges on problem finding.

Quadrant II: Conceptualizing
The second quadrant, conceptualizing, keeps the creative process going.
Creative activity in this quadrant involves gaining knowledge and understanding mentally, or working in the abstract—analyzing, pondering, and
theorizing about the information received to create a sound conceptualization or model of the problem domain. Understanding is not gained by
direct experience, but instead by detached, abstract thinking. What is
understood through rational, systematic analysis is turned into new
insights that help define problems, and create theoretical models and
ideas to explain things. Quadrant II activity consists of turning a problem
recognized in Quadrant I into a well-understood problem definition and
some fledgling solution ideas and, thus, is called conceptualization.
For example, the senior author was once asked for help by a Procter
& Gamble product development team formed at short notice to respond
to a competitor’s new product. Colgate’s green-striped Irish Spring had
been the first striped soap bar introduced to North America. With its
aggressive advertising campaign emphasizing “refreshment,” Colgate’s
new product was finding ready consumer acceptance. Procter & Gamble
worked by the rule that, if a team (or person) was the second entrant into
a new market, it had to demonstrate a product’s competitive advantage
before it could carry out a market test. When asked what was going
wrong, the team members said that they had been unable to produce a
green-striped bar that worked better than Irish Spring in a consumer
preference blind test. The team had experimented with several greenstriped bars, all of which merely equaled Irish Spring in blind testing. It
became evident that the team had chosen to define its problem as: “How
might we make a green-striped bar that consumers will prefer over Irish
Spring?”
During a creative problem solving meeting, one of the important
activities was to develop alternative ways to define the challenge. The
flash of inspiration came from an answer to a question posed from a con26

<-----Page 28----->VOLUME #5, ISSUE #3
sumer’s point of view: “We want to make a bar that makes people feel
more refreshed.” This led to the new conceptualized challenge: “How
might we better connote refreshment in a soap bar?” This less restrictive
conceptualization, which included no mention of green stripes, provided
more room for creative solutions. The team broke this new problem into
three separate components: “How might we better connote refreshment
in appearance, shape, and odor?”—a new conceptualization—and then
focused their imaginations on ideas. Beginning with the product’s
appearance, they visualized scenes, images, and situations that suggested
refreshment. One pictured himself at the sea coast. Another imagined sitting on a beach and looking at a blue sky and white clouds. Later, when
the team sat back to evaluate its many ideas, these two ideas were
selected and combined. The result was the concept of a blue-and-whiteswirled bar with a unique odor and shape. The concept later achieved
market success under the brand name Coast. By leaping prematurely into
solutions, the team had wasted almost six months before coming up with
a superior conceptualization.

Quadrant III: Optimizing
The third quadrant moves the creative process further. Creative activity
in this quadrant involves gaining knowledge and understanding mentally
by working in the abstract: thoroughly analyzing a defined problem and
utilizing this knowledge to develop and evaluate ideas and options and
create an optimal, practical solution. What is understood through
rational, systematic, and orderly analysis is used to mentally evaluate situations and options to convert abstract ideas into practical solutions and
plans. Quadrant III activity is called optimization. At this point, a good
solution to an important, well-defined problem exists, but has not yet
been implemented.
For example, the newly defined concept of a refreshment bar in the
example above still had to be converted into a practical solution. The team’s
engineering members created and evaluated several optional versions of
the new appearance, odor, and shape. The options were evaluated on several criteria, including cost, feasibility, and time to implement. A final optimal prototype was chosen and successfully tested with consumers,
demonstrating an exploitable competitive advantage over its competitor.

Quadrant IV: Implementing
The fourth quadrant completes the creative process. Apprehension in
this quadrant involves gaining knowledge and understanding by physical
27

<-----Page 29----->EMERGENCE
contact and involvement in the real world. Utilization consists of employing evaluation to convert this knowledge into implemented solutions that
work and accomplish valuable results. What is experienced and felt is
used to evaluate. Creative activity in this quadrant consists of gaining
experience with new solutions, evaluating the outcomes, and making
adjustments to implement them successfully. Thus this stage is called
implementation.
For example, in the above refreshment bar example, the team was still
not finished. Before the new soap formula could be sold, a patent problem in the machinery design had to be overcome. There were already no
fewer than six worldwide patents restricting how blue-and-white soap
pastes could be blended. The team had to find a machine design to make
the new product without infringing on anybody else’s technique. The
team assembled diverse points of view in a special group of engineers,
technicians, lawyers, and even a few people who were unfamiliar with
soap technology. Sketches and prototypes of the patented processes were
displayed and examined and the equipment was adjusted and rebuilt
repeatedly until a breakthrough insight emerged and the new product
was finally produced satisfactorily for delivery and purchase. A full cycle
of the creative process was now complete.

CONSTRUCTING

THE FOUR-STAGE

CPSP

THEORY

In most of the research literature from the 1950s to the 1980s (see review
by Basadur, 1994), creativity was perceived largely as generating ideas to
presented problems using techniques such as brainstorming. However,
practitioners who employ such limited conceptions of the creative
process seldom attain practical results (Sternberg et al., 1997). More
recently research has focused on creativity as a multi-stage process
(Basadur, 1994, 1995; Kabanoff & Rossiter, 1994; Rickards, 1994). Other
models of creativity as a process of stages include Wallas’s (1926) four
stages of preparation, incubation, illumination, and verification; the
Osborn–Parnes five-step process of fact finding, problem finding, idea
finding, solution finding, and acceptance finding (Parnes et al., 1977);
Amabile’s (1988) five stages of presentation, preparation, generation, validation, and assessment; Boyd’s OODA (Observe, Orientate, Decide, Act;
Hammond, 2001); and Kelly’s (1955) theory of personal constructs. Additional models are provided in Rickards (1994), Kabanoff & Rossiter
(1994), and Basadur (1995).
Beyond merely identifying stages or steps, our model explains and
measures each of four stages through established psychological cognitive
28

<-----Page 30----->VOLUME #5, ISSUE #3
constructs that differentiate each stage from the others. Each stage represents a different kind of creativity that contributes to the complete creative process of Figure 1. These explanations and measures are based on
selected fundamental theories and constructs of intelligence and mental
operations associated with creative thinking. These theories are
Guilford’s (1967) landmark Structure of Intellect (SOI); Sternberg’s
(1988) triarchic intelligence; Osborn’s (1953) pioneering four brain functions concept; and Parnes et al.’s (1977) disciplined freedom paradigm.

OSBORN’S

FOUR BRAIN FUNCTIONS AND
MENTAL OPERATIONS

GUILFORD’S

FIVE

Osborn (1953) modeled the brain as having four distinct functions: absorb
(gaining knowledge), retain (memory), imagine, and judge. Osborn advocated developing skill in deferring judgment, or using the imagination
and judgment functions independently. Developing Osborn’s model further, Parnes et al. (1977) created a simplified formula for creativity as follows: C (creativity) = K (knowledge) × I (imagination) × E (evaluation).
Their term “disciplined freedom” emphasizes that creativity requires a
balance of knowledge and imagination and good judgment.
Guilford (1967) identified two very different ways of gaining knowledge. One way is the mental operation of cognition, or gaining knowledge by experiencing, which he described as the immediate discovery,
awareness, rediscovery, or recognition of information. We suggest that
some people gain understanding preferentially by such physical processing of information—what we call experiential intelligence (Basadur &
Gelade, 2002). The other way of gaining knowledge is what Guilford
called the mental operation of convergent production. Guilford described
convergent production as the generation of information from given information to achieve unique or conventionally accepted best outcomes in
which the given information often fully determines the response. This is
also what Sternberg (1996) defined as theoretical, analytical intelligence.
We suggest that some people gain understanding preferentially by such
mental processing of information. Further, we suggest that people use
knowledge by two very different methods, no matter how that knowledge
is gained. One way of using knowledge is what Guilford called the mental operation of divergent production, or creating options from information. This operation resembles Sternberg’s construct of creative
intelligence. The other way of utilizing knowledge is what Guilford called
the mental operation of evaluation, or evaluating options (the main component of what Sternberg called practical intelligence).
29

<-----Page 31----->EMERGENCE

Figure 2 Four combinations of different methods of gaining and using
knowledge
We suggest a new simplified formula: C = (KX + KT) × I × E, in which
KX is knowledge apprehension by experiencing and KT is knowledge
apprehension by theoretical analysis (thinking); see Figure 2. We also
suggest that there are two dimensions underlying the process of Figure 1.
The first dimension, apprehension, involves acquiring knowledge or
understanding in two different ways. One is relatively more open, nonrational, experiential, nonanalytical, and divergent (cognition); the other
is more closed, rational, theoretical, analytical, and convergent (convergent production). The second dimension of Figure 2, utilization, involves
applying knowledge or understanding (however acquired) in two different ways: nonjudgmentally creating new information to increase the variety of options (divergent production), and judgmentally reaching
decisions about new information to reduce the variety of options
(evaluation).
In Figure 2, the four stages depicted in Figure 1 are explained as combinations of these two bipolar dimensions. Combining the preference for
learning experientially (KX) with the preference for creating options (I =
ideation) yields a measure of preference for the first stage of the process,
or generation (KX U I). Combining the preference for learning theoretically (KT) with the preference for creating options (I) yields a measure of
preference for the second stage, or conceptualization (KT U I). Combin30

<-----Page 32----->VOLUME #5, ISSUE #3
ing the preference for learning theoretically (KT) with the preference for
evaluating options (E) yields a measure of preference for the third stage,
or optimization (KT U E). Combining the preference for learning experientially (KX) with the preference for evaluating options (E) yields a measure of preference for the fourth stage, or implementation (KX U E).

MEASURING

INDIVIDUAL STYLES AND PREFERENCES

Individuals in organizations have varying preferences for each of the
quadrants or stages in the creative process because they have varying
preferences for the bipolar modes of apprehension and utilization. Generating ideas for new products, services, and methods must start somewhere. Individuals inclined toward generating are continually
experiencing and scanning the environment, picking up data and cues
from customers, suppliers, and others, and suggesting possible opportunities for change and improvement. Thus, the generation stage is where
new information and possibilities are raised—usually not fully developed
but in the form of starting points for new projects. People with dominant
conceptualizer styles lead in compiling facts and idea fragments from the
generator stage into well-defined, insightful problems and challenges and
more clearly developed ideas and projects worth further evaluation.
Skilled conceptualizers give sound structure to fledgling ideas and opportunities. People inclined toward optimization usually lead in taking these
well-defined ideas and finding a practical best solution and detailing efficient plans for proceeding. Finally, implementers lead in carrying forward
the practical solutions and plans, including convincing colleagues or customers of the worth of the changes, and adapting the solutions and plans
to make them fit real-life situations and conditions.

THE CREATIVE PROBLEM SOLVING PROFILE (CPSP)
INVENTORY

The Creative Problem Solving Profile (CPSP) inventory measures an
individual’s unique blend of preferences for the four stages of the process
in Figures 1 and 2. Plotting inventory scores on a two-dimensional graph
displays an individual’s preferred blend of the four different stages. The
largest quadrant on the graph represents the preferred or dominant style,
with relative sizes of the other quadrants representing supporting orientations. The unique blend of styles is the individual’s profile. Figure 3
shows how individual differences in orientation can yield different creative problem solving process styles and profiles. If the area of quadrant
31

<-----Page 33----->EMERGENCE

Figure 3 Examples of different profiles of creative problem solving with
the same style dominant and with different styles dominant
1 is largest, the primary process style is generating; if quadrant 2, then
conceptualizing; if quadrant 3, then optimizing; and if quadrant 4, then
implementing. Each of these styles reflects individual preferences—and
preferences of teams and entire organizations—for ways of gaining and
using knowledge.
The CPSP’s scale construction, scoring, interpretation, reliability, and
validity have been fully described by Basadur and Gelade (2002), but a
brief summary is presented here.
The CPSP questionnaire consists of 12 scored items, and six distractor items that are not scored. Each scored item consists of four words,
descriptive, respectively, of learning experientially (KX), learning theoretically (KT), creating options (I), and evaluating options (E). Respondents
are asked to decide which words are most characteristic of their problem
32

<-----Page 34----->VOLUME #5, ISSUE #3
solving style, and to rank the four words from one (“least characteristic of
me as a problem solver”) to four (“most characteristic of me as a problem
solver”) within each item accordingly. An individual’s CPSP profile is
obtained by summing their scores on KX, KT, I, and E respectively; plotting the resulting totals on the axes shown in Figure 2, and constructing
the quadrants as shown in Figure 3, gives a pictorial representation of the
respondent’s problem solving preferences.
As reported in Basadur and Gelade (2002), factor analysis of the questionnaire scores confirms the existence of two orthogonal bipolar dimensions corresponding to KX–KT and I–E, and scores on these dimensions
show satisfactory reliability (alpha = .80). Convergent validity has also been
demonstrated with the Kirton Adaptation Innovation Inventory and the
Myers-Briggs Type Inventory (Basadur et al., 1990; Basadur, 1998; 2000).
NOT TRAITS, AND ALL FOUR QUADRANTS ARE
CREATIVE

STATES

This Creative Problem Solving Profile (CPSP) inventory measures states,
not traits. No one quadrant is considered any more “creative” than any
other. All four quadrants require creativity of different kinds. Each quadrant contributes uniquely to the overall innovative process and innovative
results. An individual’s unique creative problem solving profile shows
only their preferred activities within the Simplex Creative Problem
Solving process. Most people enjoy some stages more than others. A particular style reflects relative preferences for each of the stages of the
process: generating, conceptualizing, optimizing, and implementing. A
person’s thinking processes cannot be pigeonholed in any single quadrant. Rather, they are a combination or blend of quadrants. A person will
likely prefer one quadrant in particular, but also have secondary preferences for one or two adjacent quadrants, as shown in Figure 3. Skills are
needed in all stages.
Everyone has a different valuable creative contribution to make to the
innovation process as a whole. One goal is to capitalize on an individual’s
preferred orientation, thus making their work more satisfying and pinpointing development opportunities. Another goal is to tap resources in
all four quadrants to help the individual, team, or organization cycle skillfully through the complete innovation process.

ORGANIZATIONS

HAVE THEIR OWN PROFILES

Entire organizations also have creative process profiles. An organization’s
profile reflects such factors as the kinds of people it hires, its culture, and
33

<-----Page 35----->EMERGENCE
its values. For example, if an organization focuses almost entirely on
short-term results, it may be overloaded with implementers with few conceptualizers or generators. The organization will show strengths in
processes that deliver its current products and services efficiently. But it
will show weaknesses in long-term planning and product development
that might help it to stay ahead of change. Rushing to solve problems, this
organization will continually find itself reworking failed solutions without
pausing to conduct adequate fact finding and problem definition. By contrast, an organization with many generators or conceptualizers and few
implementers will continually find good problems to solve and great
ideas for products and processes to develop. But it will never carry them
to their conclusion.
Following are a case study and additional real-world examples of how
organizations may apply the CPSP to diagnose problems and improve
creativity and innovation performance.

REAL-WORLD
A

APPLICATIONS OF THE

CPSP

CASE STUDY

By 1981, an automobile manufacturer had suffered several losing business quarters. In an effort to change its operations, the company had
launched many initiatives. One of the most important was its decision to
involve its people in improving quality and customer satisfaction and
increasing innovation. The company wished to involve managers in actually “managing the business” rather than just “doing my job.”
The company and its union had agreed to implement a joint employee
involvement (EI) program for unionized employees. Both sides provided
resources, including both unionized and salaried employees, to diagnose
important training needs and to create strategies and programs to meet
those needs. Their first step was to form problem solving groups in the
plants, guided by local and national joint steering committees. To build
skills in problem solving, these groups had been taught standard analytical tools borrowed from statistical process control and total quality management programs (such as “cause-and-effect diagramming” and
“cause-unknown diagnosis”).
The company now wished to expand employee involvement to
include salaried employees, and to develop problem solving processes
that were better suited for their jobs. The organization hoped that these
employees and their managers would take more initiative in identifying
opportunities for improvement and tackling them creatively. During a
34

<-----Page 36----->VOLUME #5, ISSUE #3
preconsult and preliminary training workshop for several key employees,
we agreed on a strategy to train a number of employees in applying the
Simplex process and in training others in the company.
During this training, we had a chance to apply the process to a problem at a newly modernized plant that made a major component of the
company’s new front-wheel-drive automobiles. The plant was setting
new records for quality and low cost, but one department was struggling.
Only about one-third of its output met the company’s high quality standards, and employees had to work heavy overtime schedules in order to
keep up with orders. The plant managers had tried several quick-fix solutions to resolve the production and quality problems, but none had
worked. We established a cross-functional team of 15 plant managers and
supervisors in order to apply the Simplex Creative Problem Solving
process to the problem.
Along with one of the company’s internal consultants who was training as a Simplex facilitator and trainer, the senior author conducted the
application session with this team. About half a day was set aside for training in the Simplex process and process skills, and two and a half days to
apply the process to the team’s fuzzy situation. During the training, the
team members were asked to complete the Creative Problem Solving
Profile (CPSP) inventory to identify individual differences in preferences
for various stages of the creative problem solving process.
The team discovered a very revealing insight. Of the 15 team members, eight showed creative problem solving styles heavily oriented
toward quadrant 4, or implementation. The other seven showed styles
heavily oriented toward quadrant 3, or optimization. None had creative
problem solving styles oriented toward quadrants 1 or 2 (generation and
conceptualizing). The team was composed of people who preferred to
jump quickly to action rather than carry out fact finding and problem definition. Team members were able to identify many instances when they
had mistakenly made assumptions about this particular problem, leading
to one failed solution after another. Rather than take the time to define
the problem accurately, they had simply jumped from the fuzzy situation
to one solution after another. They had spent all of their time alternating
between quadrants 3 and 4, and none in quadrants 1 or 2 (Figure 4).
These solution- and action-oriented individuals agreed to spend two
days in quadrant 1 and 2 activity, gathering facts and defining problems
(Figure 5)—even though the whole exercise was against their nature.
Three specific problem definitions emerged from this exercise. On the
third day, the group was able to create simple but specific solutions to
35

<-----Page 37----->EMERGENCE

No fact finding

Implementer
(Action)
Think of a
solution and try
it; when it fails,
repeat this half
cycle
Optimizer
(Solutions)

No problem
definition

Only half of the creative process used

Figure 4 The results of heavy orientation toward quadrant 3 and 4
thinking styles

Implementation

Implementer
(Action)

Generator
(Problem finding, fact
finding)
Two days in
fact finding and
problem
defining

Optimizer
(Solutions)

Conceptualizer
(Problem definition)

One day in
solution
development

The entire creative process used

Figure 5 Balancing orientations toward all four thinking styles
36

<-----Page 38----->VOLUME #5, ISSUE #3
each defined problem that it could quickly implement. Within several
months, most of the plant’s production was high quality and was still
improving.

A

DIAGNOSTIC TOOL

On the following pages are four examples of CPSP scatter diagrams,
which depict the array of preferences for each of the four quadrants of the
creative process for individuals within a team or organization. Each 
symbol represents an individual’s pair of coordinates derived from their
score on the vertical apprehension axis (XT) coupled with their corresponding score on the horizontal utilization axis (IE).
The first scatter diagram displays the preferences of a typical group of
managers in a large engineering company servicing the aircraft, airline,
and aerospace industries (Figure 6). Most middle and senior managers in
the company are strongly oriented toward action rather than toward gen-

Figure 6 Scatter diagram example #1: Not enough generators
37

<-----Page 39----->EMERGENCE

Figure 7 Scatter diagram example #2: Not enough time devoted to
conceptualization and optimization
erating new opportunities. The company has established high growth targets into new products and markets, but is failing to achieve them
because of a strong organizational culture that favors quick fixes to shortterm problems. To improve its short- and long-term balance, the company
is developing a major training effort to increase awareness and encourage
more generation and is also creating structures that will encourage
employees to participate more in quadrant 1 and 2 activities.
In the second example, a large bank had formed teams to bring many
new financial products to market quickly in a very competitive environment, but those teams were encountering a high percentage of failures.
The organization’s teams were found to be heavily weighted toward
implementers (Figure 7). Further discussion showed that the teams often
developed new products by rushing from an initial idea directly into
implementation, without spending much time in conceptualization and
38

<-----Page 40----->VOLUME #5, ISSUE #3

Figure 8 Scatter diagram example #3: Not enough implementers
optimization. Had the teams taken more time for conceptualization, they
likely would have identified more limitations in many new product ideas.
With more time in optimization, they would have reduced the frequency
of product flaws reaching the market. By taking more time through these
second and third stages of the process, the teams began to make wiser
choices about which new, fledgling ideas to pursue (and which to terminate) and to develop more reliable product designs for market testing.
In the third example, a new managing director was hired specifically
to develop a breakthrough product concept and bring it to market. He
assembled a team that, in very little time, created a great new idea.
However, the team had subsequently ground to a standstill. Members
failed to attend meetings regularly and several felt that there was nothing
important remaining to be done. Subsequent diagnosis found that all of
the team members whom the managing director had intuitively selected
were oriented toward quadrants 1 and 2. In Figure 8, the managing
39

<-----Page 41----->EMERGENCE

Figure 9 Scatter diagram example #4: An imbalance—not enough
generators or optimizers
director is the lone individual in quadrant 3, and there is no one in quadrant 4, implementation. He now realized that the team needed to add
people oriented toward quadrants 3 and especially 4 in order to implement the new product concept successfully.
The fourth example comes from the management team of a small engineering company that was growing too quickly, allowing many human
resource problems to pile up. The company had more business than it
could handle: new engineering projects were being designed and implemented with customers all over the world. Left unidentified and ignored
by the busy management team, the human resource problems left people
feeling severely stressed, overworked, and underappreciated. Resulting
high turnover and its deteriorating corporate reputation made it difficult
for the company to hire replacements or new staff. As shown in Figure 9,
the management team was unbalanced, being virtually devoid of genera40

<-----Page 42----->VOLUME #5, ISSUE #3
tors and optimizers. Most members were implementers or conceptualizers, demonstrating little interest in either surfacing problems or solving
them. As a first step toward ensuring that it identified and solved important people problems, the company hired its first human resources manager for this explicit purpose.

IMPROVING

TEAM PERFORMANCE

In a creative organization, everyone is responsible for doing at least one
of the four stages defined by Figure 1. Some people initiate new things.
Some are responsible for understanding and defining new initiatives and
planning. Some produce practical solutions to new problems and initiatives. Others are responsible for finishing things off, or taking action to
implement new solutions. If the four-stage process of creativity outlined
above adequately represents the creative process, it would be expected
that teams with a heterogeneous mix of preferred creative process styles
(Figure 1) would significantly outperform teams with a homogeneous mix
of creative process styles in innovative work. In the former case, all stages
of the process are readily available within the team. One could also predict that members of homogeneous teams would experience more satisfaction working with like-minded team mates.
The predictions were confirmed by a study by Basadur and Head
(2001), which assessed groups of MBA students on a problem solving
task. Groups including individuals with different styles (heterogeneous
groups) outperformed homogeneous groups whose members all had the
same style. Rated by a judges’ panel on four dimensions of innovative
performance, the mean score for the 21 heterogeneous groups was 4.22
(sd = 0.42) and the mean for the homogeneous groups was 3.69 (sd =
0.64); a statistically significant difference (Student’s t = 3.0, p < .01).
Asked about their teamwork experience, individuals in the heterogeneous groups expressed less satisfaction than those in the homogeneous groups. The mean overall satisfaction for the 57 participants in
the heterogeneous groups was 7.50 (sd = 1.98) compared to 8.15 (sd =
1.32) for the 85 participants in the homogeneous groups; a statistically
significant difference (Student’s t = 2.2, p < .05).
Heterogeneity is often an inherent characteristic of cross-functional
teams, as people in various occupations favor different CPSP styles. For
example, people in industrial engineering, training and development, and
other improvement and change-initiation departments often favor the
generator style. Employees in market research, strategic planning, and
R&D often favor conceptualizing. People in accounting, finance,
41

<-----Page 43----->EMERGENCE
engineering, and systems development gravitate toward optimizing. People in manufacturing production, logistics/distribution/warehousing,
sales, administrative support, customer service, and operations favor
implementation.
No matter which process style an individual prefers, however, a team’s
members have to learn to use their differences to advantage. Teams, especially those involved in continuous improvement and innovation, require
a mix of people who enjoy working in different steps around the Simplex
Creative Problem Solving process: finding new problems and opportunities, clarifying and refining those problems and creating ideas, developing practical solutions and plans, and making new solutions work.
Whether in teams or not, helping individuals learn to shift among orientations also ensures that the entire organization has a complete blend of
process styles. In fact, an individual’s dominant orientation is less important than their ability to shift among the different orientations. Preferences for certain quadrants within the innovation process are not static
“traits,” but dynamic “states.” Individuals can learn to work in any of the
four CPSP quadrants in order to complement others in a given situation.

APPLICATION

TO ORGANIZATIONAL ECOSYSTEMS

Basadur and Gelade (2002) report CPSP scores for a sample of 3,942
adults (39 percent female, 61 percent male) in 38 different occupations
and working in a wide variety of organizations, including large and small
corporations, banks, schools, universities, and hospitals. In this sample,
36 percent were in nonmanagement or supervisory roles, 27 percent in
managerial roles, and 25 percent in professional or technical roles; the
remainder were in other roles or did not specify their role. High percentages of generators were found in fields such as teaching (56 percent),
academia (38 percent), and art (34 percent), and low percentages in fields
such as IT systems development (9.5 percent), manufacturing engineering (9 percent), and engineering/engineering design (7.5 percent). Overall, the results suggested that few business and industrial occupations had
a high proportion of generators (see Figure 10).
This raises some interesting questions, because the most perplexing
challenge for many organizations is how to be more innovative in the face
of accelerating change. Indeed, many leading management consultants
exhort corporations to “begin their revolutions”—to expand their thinking and do things differently. Rather than simply improve existing methods and procedures, they advocate deliberate change. They advise
corporations not to defend old markets, but to explore new ones. Many
42

<-----Page 44----->VOLUME #5, ISSUE #3
More
Generators

More
Implementers

IT operations
Customer relations
Secretarial/administration
Project manager
Sales
Engineering/design
Manufacturing engineering
Finance
IT systems developer
IT programmer/analyst

More
Optimizers

Schoolteacher
Academic
Artistic
Nonprofit/university
administration
Training and development
Organizational development
Strategic planning
Market research
Design
R&D

More
Conceptualizers

Figure 10 Occupations by dominant quadrant mix
corporations find this an appealing strategy, although one that is difficult
to implement. While one could speculate that a reason for this difficulty
may be the lack of employees who prefer the generator style of thinking,
this may be an overly simplistic explanation. For example, a single generator might initiate enough work for ten “implementers.” A more productive approach might be to raise broader questions and hypotheses about
the appropriate mixes or ratios of the four quadrant preferences within
various organizational departments and functions, or within an organization as a whole.
From an intra-organizational perspective, different ratios of the four
quadrants might be appropriate within, say, manufacturing or service
organizations, or within the particular departments of a given organization, such as R&D, sales, IT, or finance. The optimal mix for a top management team might differ from that for a lower-level team. Our previous
research (Basadur, 1994, 1995) has suggested that a business unit’s optimal ratio may depend on the typical proportion of work oriented toward
problem finding rather than toward problem solving or implementation.
From an inter-organizational perspective, management consultants
exhorting client organizations to initiate deliberate change could be
viewed as performing the generator function from outside the organization. However, outside consultants are considered as being weak at
delivering whole projects (e.g., IT implementations). On the other hand,
43

<-----Page 45----->EMERGENCE
organizations are often seen as too reliant on outside consultants to identify problems for them and suggest solutions. Perhaps a successful
consultant–client relationship requires an optimal blend of quadrant
styles among the organization’s staff and the consulting or advisory team.
Analysis of organizational quadrant styles might identify organizations
that would benefit from hiring consultants, and whether project management consultants (project implementers) or change-initiating consultants
might be more effective. We also speculate that successful consultants or
consultant teams function effectively in more than one CPSP quadrant in
order to maintain an optimal balance of quadrant styles when working
with organizational teams. Other inter-organizational ecosystems, such as
customer–supplier relationships, may be viewed similarly. The success of
inter-organizational strategic alliances, mergers, or acquisitions may also
be dependent on achieving an optimal blend of creative thinking styles,
especially at the top level.

SUMMARY

AND FUTURE RESEARCH

We have presented a theory of organizational creativity as a process comprising four stages: generating, conceptualizing, optimizing, and implementing. We explain and measure each stage of the process using
cognitive constructs from established models of intelligence and educational psychology. These constructs differentiate the mental activities in
each stage of the process from those of the other stages. Each stage represents a different kind of creativity that contributes to the complete creative process.
We have also presented a psychological instrument that measures the
constructs and stages of the process, called the Creative Problem Solving
Profile (CPSP) inventory. Individuals, teams, and organizations may use
the CPSP to help diagnose inadequate organizational problem solving
and performance. The CPSP also provides a blueprint for people to
understand organizational creativity as a process of continually finding
and defining important organizational problems, solving those problems,
and implementing the solutions.
The four-stage process represented by the CPSP is built on two
underlying dimensions: apprehension and utilization. Apprehension
involves acquiring knowledge or understanding in two different ways:
more open, nonrational, experiential, nonanalytical, and divergent, versus more closed, rational, theoretical, analytical, and convergent. Utilization involves applying knowledge or understanding in two different ways:
44

<-----Page 46----->VOLUME #5, ISSUE #3
nonjudgmentally creating new information to increase the variety of
options, versus judgmentally reaching decisions about new information
to reduce the variety of options. The four stages of the creative process
are explained as combinations of these two bipolar dimensions. Individuals in organizations have varying preferences for each of the stages
because they have varying preferences for the bipolar modes of apprehension and utilization. The CPSP inventory measures an individual’s
unique blend of preferences of the four stages, or their creative process
“profile.”
Teams and entire organizations also have unique creative process profiles, and the CPSP can be applied to diagnose problems and improve
creativity and innovation performance. Heterogeneity of CPSP styles is
often an inherent characteristic of interdisciplinary teams, as people in
various occupations tend to favor different CPSP styles. Because CPSP
preferences are not static “traits” but dynamic “states,” individuals can
learn to work effectively in any of the four CPSP quadrants in order to
complement other team members’ preferences and help the team move
smoothly through the four-stage process. Research has shown that more
heterogeneous teams outperform more homogeneous teams in innovative
work but experience less satisfaction.
Our research indicates that generators (people who prefer stage 1
activity) are the least represented of the four CPSP styles in industrial
(business) organizations. In fact, few industrial occupations had a high
proportion of generators. The other three stages were better represented
occupationally. The overall distribution favored implementers (highest)
followed by conceptualizers, optimizers, and generators (lowest). These
data suggest several interesting intra-organizational and interorganizational ecosystem questions that might be approached through
the framework presented in this article. For example, the effectiveness of
organizations, departments, or functions—and relationships among
organizations, advisers, customers, suppliers, and strategic partners—
may depend partly on the ability to exploit diverse thinking styles and on
how well the mix of available styles matches the cognitive work.
Similar considerations might, in principle at least, be extended to the
dynamics of creativity and change at higher (supra-organizational)
ecosystem levels. Dealing effectively and creatively with change is a challenge not merely for organizations but for entire economic systems,
industries, and societies. Our experience of innovation at this level has
generally been painful. The charismatic and visionary “generator” with a
remedy for society’s ills is a well-known archetype. But even the best45

<-----Page 47----->EMERGENCE
intentioned of these is likely to cause more harm than good if the thinking stops at this stage. Continued inertia and excessive conservatism are
likely either to cause atrophy and decay or build irresistible pressures,
leading to an uncontrolled and destructive catharsis. A better understanding of the dynamics of creativity, and the diversity of thinking
processes needed to navigate change at the micro level, might contribute
to a better understanding of how to avoid such difficulties at the macro
level.

REFERENCES
Amabile, T. M. (1988) “A model of creativity and innovation,” in B. M. Staw & L. L.
Cummings (eds), Research in Organizational Behavior, Greenwich, CT: JAI Press: 10,
123–67.
Basadur, M. S. (1974) “Think or sink,” The Deliberate Methods Change Bulletin, July–
September, Cincinnati, OH: Procter & Gamble Management Systems Division.
Basadur, M. S. (1983) “Employee involvement creative problem-solving workshop,” Ford
Education and Training Catalog, September, Dearborn, MI: Ford Education and
Personnel Research Department: 115.
Basadur, M. S. (1992) “Managing creativity: A Japanese model,” Academy of Management
Executive, 6(2): 29–42.
Basadur, M. S. (1994) “Managing the creative process in organizations,” in M. A. Runco
(ed.), Problem Finding, Problem Solving and Creativity, New York: Ablex: 237–68.
Basadur, M. S. (1995) Power of Innovation, Toronto: AC Press.
Basadur, M. S. (1998) “The Basadur Simplex creative problem-solving profile inventory:
Development, reliability and validity,” Management of Innovation and New
Technology Research Centre, Working Paper No. 83, December, Hamilton, Ontario:
McMaster University.
Basadur, M. S. (2000) “Evaluating the psychometric improvements provided by Basadur
CPSP 2-Experimental,” Management of Innovation and New Technology Research
Centre, Working Paper No. 99, September, Hamilton, Ontario: McMaster University.
Basadur, M. S. & Gelade, G. (2002) “Knowing and thinking: A new theory of creativity,”
Management of Innovation and New Technology Research Centre, Working Paper No.
105, December, Hamilton, Ontario: McMaster University.
Basadur, M. S. & Head, M. (2001) “Team performance and satisfaction: A link to cognitive
style within a process framework,” Journal of Creative Behavior, 35(4): 227–48.
Basadur, M. S., Graen, G. B., & Green, S. G. (1982) “Training in creative problem solving:
Effects on ideation and problem finding in an applied research organization,”
Organizational Behavior and Human Performance, 30: 41–70.
Basadur, M. S., Takai, J., & Wakabayashi, M. (1990) “Cross-validation of creative problem
solving/creative style inventories: Validating Basadur’s CPSP with Kirton’s KAI inventory,” in J. Misumi, B. Wilpert, & H. Motoaki (eds), Organizational and Work
Psychology: Proceedings of the 22nd International Congress of Applied Psychology,
Kyoto, Japan, Vol. 1, Hillsdale, NJ: Lawrence Erlbaum Associates, Inc.: 153–5.
Callahan, S. (1972) “Dr. Land’s Magic Camera,” Life, 27 October: 42.
Carlsson, B., Keane, P., & Martin, J. B. (1976) “R&D organization as learning systems,”
Sloan Management Review, 17(1): 1–15.
Gordon, W. J. J. (1956) “Operational approach to creativity,” Harvard Business Review, 9(1).

46

<-----Page 48----->VOLUME #5, ISSUE #3
Gordon, W. J. J. (1971) The Metaphorical Way, Cambridge, MA: Porpoise Books.
Guilford, J. P. (1967) The Nature of Human Intelligence, New York: McGraw-Hill.
Hammond, G. T. (2001) The Mind of War, Washington, D.C.: Smithsonian Institute Press.
Kabanoff, B. & Rossiter, J. R. (1994) “Recent developments in applied creativity,”
International Review of Industrial and Organizational Psychology, 9: 283–324.
Kelly, G. A. (1955) The Psychology of Personal Constructs, New York: Norton.
Mott, P. E. (1972) Characteristics of Effective Organizations, New York: Harper & Row.
Osborn, A. F. (1953) Applied Imagination: Principles and Procedures of Creative ProblemSolving, New York: Charles Scribner’s Sons.
Parnes, S. J., Noller, R. B., & Biondi, A. M. (1977) Guide to Creative Action, New York:
Charles Scribner’s Sons.
Rickards, T. R. (1994) “Creativity from a business school perspective: Past, present, and
future,” in S. G. Isaksen, M. C. Murdock, R. L. Firestien, & D. J. Treffinger (eds),
Nurturing and Developing Creativity: The Emergence of a Discipline, Norwood, NJ:
Ablex: 155–76.
Sternberg, R. J. (1988) The Triarchic Mind: A New Theory of Human Intelligence, New York:
Viking.
Sternberg, R. J. (1996) Successful Intelligence: How Practical and Creative Intelligence
Determine Success in Life, New York: Simon & Schuster.
Sternberg, R. J., O’Hara, L. A., & Lubart, T. I. (1997) “Creativity as investment,” California
Management Review, 40(1): 8–21.
Wallas, G. (1926) The Art of Thought, New York: Harcourt Brace.

47

<-----Page 49----->EMERGENCE, 5(3), 48–65
Copyright © 2003, Lawrence Erlbaum Associates, Inc.

The Redefinition of Memes:
Ascribing Meaning to an
Empty Cliché
Michael R. Lissack
Memetics has reached a crunch point. If, in the near future, it does not
demonstrate that it can be more than merely a conceptual framework, it
will be selected out. While it is true that many successful paradigms
started out as such a framework and later moved on to become pivotal
theories, it also true that many more have simply faded away. A framework
for thinking about phenomena can be useful if it delivers new insights but,
ultimately, if there are no usable results academics will look elsewhere.
Such frameworks have considerable power over those that hold them for
these people will see the world through these “theoretical spectacles”
(Kuhn, 1969)—to the converted the framework appears necessary. The
converted are ambitious to demonstrate the universality of their way of
seeing things; more mundane but demonstrable examples seem to them
as simply obvious. However such frameworks will not continue to persuade new academics if it does not provide them with any substantial
explanatory or predictive “leverage.” Memetics is no exception to this
pattern. (Edmonds, 2002)

W

hile the popular media has had several rounds of fascination with the concept of memes, the application
of memes to management and to complexity has been
negligible. The Edmonds quote above ascribes the
problem to the stage of development of memetics: that memetics needs
to provide explanatory leverage to get past the “crunch point.”
48

<-----Page 50----->VOLUME #5, ISSUE #3
This article suggests that the answer to memetics’ “crunch point” lies
in turning the concept of memes inside out. If memes are “units of cultural transmission which propagate themselves” (Dawkins, 1976) or “the
least unit of sociocultural information relative to a selection process that
has favorable or unfavorable selection bias that exceeds its endogenous
tendency to change” (Wilkins, 1998), then the failure of the field of
memetics to meet the three challenges outlined by Edmonds (a conclusive case study; a theory for when memetic models are appropriate; and
a simulation of the emergence of a memetic process) is problematic and
perhaps indicative of “irrelevance.” Indeed, there have been few managerial examples of the potency of a meme to explain or cause anything—
and in the absence of explanatory or casual power, it is difficult to find the
relevance of a concept for managers.
If, on the other hand, memes are redefined such that the evolutionary
selection process is no longer an aspect of the ontology of memes but
rather of the environmental niche (cf. Laland & Odling-Smee, 2000;
Laland et al., 1999; Odling-Smee et al., 2003) of which the memes are evidence, then the field may have other avenues of advancement and a
potential relevance to managers. Such a redefinition would entail recognition of the relationship between a given meme and the context of the
social and ideational environment of which it is an affordance and which
it demands be attended to. Memes in this casting are a label for successful boundary object indexicals and lose their privileged status as replicators. Instead, the replicator status is ascribed to the environmental niches
and the memes are their representatives, symbols, or semantic
indexicals.1
With this definition, memes are repackaged as symbols and their
impact on management is not that of a viral contagion but rather as an
indicator of success and change in environmental niches. If an environmental niche has an important managerial role, then paying attention to
its symbols and affordances can also be important. Memes are stripped of
their casual role and instead become semantic tokens capable of evoking
ascribed meanings. It is the process of evoking and the efficacy of the
meme as the trigger for attention, recall, and repetition of the ascribed
meaning that give memes relevance to managers.
The argument herein2 thus assumes that memes exist, but that their
definition is not that of replicator but rather that of indexical token. The
meme tokens are representatives of the environmental niche in which
they flourish and about which they offer efficient communicative potential. Memes, it is argued, succeed when they are accepted and used as
49

<-----Page 51----->EMERGENCE
tools for the accomplishment of a communicative purpose. Memes fail
when their ontic status itself becomes a focus. Memes have longevity only
if they both succeed and serve as a useful tool for a successful environmental niche. Memes can be short-lived due to the failure of their communicative efficacy or the failure of the niche they represent or both.

MEMES

AS INDEXICALS

Indexicals are concepts that we make use of nearly every day but, for
most of us, they are unknown and unthought about. The dictionary or
encyclopedia entries are actually of little help. Take this entry from the
Stanford Encyclopedia of Philosophy:
Indexicals are linguistic expressions whose reference shifts from utterance to utterance. “I,” “here,” “now,” “he,” “she,” and “that” are classic
examples of indexicals. Two people who utter a sentence containing an
indexical may say different things, even if the sentence itself has a single
linguistic meaning. For instance, the sentence “I am female” has a single
linguistic meaning, but Fred and Wilma say different things when they
utter it, as shown by the fact that Fred says something false, while Wilma
says something true.

Indexicals are words used to stand for a set of other words; that is, they
function like an index on the stock market. The Dow Jones Industrial
average, for example, stands for a basket of particular stocks and stands
for many of us as an indicator of the market as a whole. Pronouns as
described above are indexicals in that they stand for the noun and take on
different meanings in different situations. “Where a word acquires its
sense from the context in which it appears; in different contexts, it
changes its sense” (Vygotsky, 1986).
In American society the most commonly heard indexical is the mythical “they” who do things to us or others. “Look at what they are doing
now.” Perhaps the second most popular indexical is “You know…, you
know who I mean.” Indexicals are often distinguished by the fact that
their reference systematically varies with the context of usage. Indexicals
offer a simple means of making, expressing, and communicating our references, and they are particularly useful when proper names or descriptions are either cumbersome or unavailable. Similarly, in interpreting
someone’s “that way” in response to a request for direction, one must be
able to determine independently what direction the person is indicating.
50

<-----Page 52----->VOLUME #5, ISSUE #3
One must discover what relations one bears to the indexical referents in
order to locate and act on them, but there is nothing indexical about these
relations themselves (Millikan, 1993). To interpret an indexical, therefore,
is to establish what other items, entities, and representations it coincides
with. By itself, it tells us neither about its contents—what it bears its
adapting relation to—nor about its contexts; context determines the
indexical’s content, but context is not what content is about. As David
Kaplan (1989) puts it:
What is common to [indexicals] is that the referent is dependent on the
context of use and that the meaning of the word provides a rule which
determines the referent in terms of certain aspects of the context.3

Indexical language possesses a quality that Barwise and Perry (1983) call
efficiency. This refers to the capacity of an indexical representation to refer
to different individuals on different occasions. The efficiency of an indexical relates to the engineering quality of efficiency in the notion that the
same symbol is capable of standing for a multiplicity of meanings—the
greater the number of potentially stood-for meanings, the greater the efficiency of the indexical. In organizations, management frequently refers to
the company, a team, a symbol, or mission, vision, and values as absolutes
without being aware of their indexical content. Thus, despite the likelihood
that an organizational symbol carries a multiplicity of meanings, managers
might make use of such symbols as if the only possible referents are the
ones conceived of by the manager him- or herself. Yet, it is possible by
ethnographic observation for a careful outsider to discern at least some of
the various referents summoned up by the use of these “unintended”
indexicals in situ. Indeed, by such processes of observation a corporate
ethnographer or anthropologist can reach tentative conclusions about the
corporate culture and climate of the organization being observed.
Indexicals are situated. The use of an indexical succeeds when the
combination of context and symbol evokes an intended meaning. The
indexical provides a locating space into which many variants of personalized and situated meaning can be ascribed, attributed, or devolved. This
space is the container of which Prigogine first spoke when describing
self-organizing systems. In the absence of such containers, selforganization is nearly if not totally impossible. In the arena of culture, the
meme as indexical is a locator or referent affording the evocation of situated meaning. Efficacy of memes is determined by that evoking and the
relevant situating.
51

<-----Page 53----->EMERGENCE
The efficiency of indexicals means that they can break, that the context and situatedness that help to afford meaning to the indexical can
stretch it beyond breaking points. When indexicals break or are challenged, they raise questions of boundaries, frames, and identities. While
the challenges to indexicals can be very subtle, when they break they
break the entire frame of how a situation is understood. Americans were
made aware of this when Senator Jim Jeffords of Vermont switched his
party affiliation from Republican to Independent (and thereby altered
control of the US Senate). His speech of explanation was a discussion of
his perceived limits to the indexical “republican.” If memes are understood to be indexicals, then their success or failure is not marked by evolutionary inheritance but rather by the longevity of their efficacy. That
longevity is in many ways determined by the situation and the meaning
“carrying capacity” of the meme indexical.
Donati (1992) observes that people frame an object around which an
issue revolves rather than the issue itself, and that the study of frames
involves identifying how people understand an issue, rather than determining if they are “for” or “against” a proposition. Gratton (2000) notes,
working to create a shared and coherent meaning in line with corporate
aspirations demands an understanding of the current meanings within the
organization. We strive to interpret our world, not simply by imposing
structure but by translating events and developing frameworks for
understanding.

Frames are patterns of organized information by which people make
sense of the world. These “patterns,” “schemas,” or “frames” form part of
the “discursive universe” in which people interact with each other. People learn frames as they learn to use a language fluently and as they learn
the narrative structures and ideologies present in the cultures that use
that language. When people encounter new information or a new experience, they make sense of that information or experience by fitting it into
an existing frame. Nevertheless, people will generally be able to fit any
given collection of information into multiple frames; though, at the same
time, they will also tend to perceive information selectively, focusing on
details that most readily fit into the frames they know.
As humans, we seek to solve problems as presented; we acquiesce in
their frames. Indeed, we become prisoners of the frame. Shira White
(2002) tells an illustrative story of such prisons:

52

<-----Page 54----->VOLUME #5, ISSUE #3
Scientists have done some fascinating and suggestive experiments with
ordinary houseflies. If you capture and keep houseflies in a jar and then
remove the lid after a few days, most of them will not fly away. In fact,
they stay right where they are—inside the jar—even though they could
escape if only they could see their way to freedom. But they seem “committed” to a lid that is no longer there. Psychologists have identified this
phenomenon as “premature cognitive commitment.” It is premature cognition in the sense that it occurs, more or less automatically, before we are
aware of or fully understand the stimulus. It is “commitment” because we
are locked into a specific set of thoughts. Like the houseflies, we give up
the freedom to choose once we become committed to the nonexistent lid.
The first step in challenging a commitment is recognizing that you have
made it in the first place.

The American philosopher John Dewey prefigured this situation in his
1934 book, Art and Experience:
No matter how ardently the artist might desire it, he cannot divest himself, in his new perception, of meanings funded from his past intercourse
with his surroundings, nor can he free himself from the influence they
exert upon the substance and manner of his present being. If he could and
did there would be nothing left in the way of an object for him to see.

The symbols and signs that we use to express meaning or hope will evoke
meaning in others not only as communication devices but also as boundary setters. The words and the meanings that they evoke set up boundaries with regard to our ability to attend to, cognize, or be aware of
aspects of our situation.
According to what can loosely be described as “boundary theory”
(Michaelsen & Johnson, 1997; Nippert-Eng, 1996a, b; Zerubavel, 1991),
individuals create and maintain boundaries as a means of simplifying and
ordering the environment. “Mental fences” (Zerubavel, 1991: 2) are
erected around geographical areas, historical events, people, ideas, and so
on that appear to be contiguous, similar, functionally related, or otherwise
associated. The process results in the creation of slices of reality domains
that have particular meaning for the individual(s) creating and maintaining the boundaries. “Home,” “work,” and “church” are examples of the
social domains created by boundaries (Nippert-Eng, 1996a). The boundaries are real in the sense that the individual perceives them as such and

53

<-----Page 55----->EMERGENCE
acts as though they are real (cf. Weick, 1979). Although a given domain
may be socially constructed and more or less institutionalized (e.g., people share a general consensus on what home means), Nippert-Eng (1996a,
b) has shown that the boundaries around that domain are somewhat idiosyncratically constructed (e.g., one person allows home to cross over into
work, whereas another keeps them separated). Further, by circumscribing
domains, boundaries enable one to concentrate more on whatever domain
is currently salient and less on other domains. (Ashforth et al., 2000)

These boundaries can be triggered by repetition and word choice. Gould
(2000) suggested that they were triggered by “canonical stories”—the
shorthand for which are often labeled by the media as “memes.”
The vertebrate brain seems to operate as a device tuned to the recognition of patterns. When evolution grafted consciousness in human form
upon this organ in a single species, the old inherent search for patterns
developed into a propensity for organizing these patterns as stories, and
then for explaining the surrounding world in terms of the narratives
expressed in such tales. As for mind, even when we can attribute a pattern
to conventional nonrandom reasons, we often fail to apprehend both the
richness and the nature of those causes because the lure of canonical stories leads us to entertain only a small subset among legitimate hypotheses
for explaining the recorded events. Even worse, since we cannot observe
everything in the blooming and buzzing confusion of the world’s surrounding richness, the organizing power of canonical stories leads us to
ignore important facts readily within our potential sight, and to twist or
misread the information that we do manage to record. In other words, and
to summarize my principal theme in a phrase, canonical stories predictably “drive” facts into definite and distorted pathways that validate the
outlines and necessary components of these archetypal tales. We therefore fail to note important items in plain sight, while we misread other
facts by forcing them into preset mental channels, even when we retain a
buried memory of actual events.

Word choices afford the possibility of new meanings, new analogies, and
new insights, which, in turn, can lead to new or next activity. As people
share framed information, they need not refer to all aspects of a frame
directly to communicate which frame they have adopted to make sense of
the information. Instead, they need only make reference to one dimension of a pattern to enable hearers or readers of their text to recall the
54

<-----Page 56----->VOLUME #5, ISSUE #3
whole frame. This evocative “power” is one of the attractive aspects of the
meme concept. By viewing signifiers of meaning such as memes as mediums with a context dependence, we can see how the frames that result
from word choice can work to limit or expand the very possibilities that
we recognize as being afforded by our current situation. Word choice
matters as a delimiter of possibility space as well as a means of communication. This provides the context in which mechanisms of memes
operate.

MECHANISMS

4

A word in context means both more and less than the same word in isolation: more, because it acquires new context; less, because its meaning is
limited and narrowed by the context. The sense of a word... changes in
different minds and situations and is almost unlimited. It is not merely the
content of a word that changes, but the way reality is generated and
reflected in a word. A complex is a word which does not function as a carrier of a concept but rather as a family name for a group of objects belonging together not logically but factually. (Vygotsky, 1986)
It is through language that we construct reality. With words we define,
shape, and experience. Without the words to think, communicate, experience, or understand our lives would be very different from what they are.
Words expand our consciousness but also limit us as we can only fully
experience those things that we have the words for. Language provides
the framework through which we perceive, experience, and act. As language constructs reality, so symbolization constitutes objects. Symbolization constitutes objects not conceptualized before, objects which would
not exist except for the context of social relationships wherein symbolization occurs. Language does not simply symbolize a situation or object
which is already there in advance; it makes possible the existence or the
appearance of the situation or object, for it is a part of the mechanism
whereby that situation or object is created. (Mead, 1934)

One example of this is the word “set,” which has more than 100 meanings. The multiplicity of such meanings is the substrate for the mechanisms of imitation, transmission, and evolution that are “normally”
ascribed to memes. Words evoke families of meanings. In Lissack and
Letiche (2004), these families of meanings are referred to as a glom.
(Vygotsky, in his work, used a word that is usually translated as “complex.”
55

<-----Page 57----->EMERGENCE
Lissack and Letiche opted for “glom” so as to avoid confusion.) The multiplicity of meanings implicit in a glom allows, when each such meaning
is viewed as a medium, new possibilities for action. Vygotsky distinguishes between more primitive gloms—a word that does not function as
a carrier of a concept, rather as a family name for a group of objects
belonging together not logically but factually—and higher-level concepts. First come the gloms, and it is when abstracted traits are synthesized anew and the resulting abstract synthesis becomes the main
instrument of thought that a concept emerges (Vygotsky, 1986).
Gloms differ from indexicals. Gloms are primitive collections of families of meaning. Thus, when a child is learning about daddy going to the
office, an entire realm of experience is built into the glom of “daddy’s
office,” “office,” and “going to the office.” Only later will the child be able
to separate the primitive wealth of experiences into distinguishable parts
and associate a socially acceptable label with some of those parts to better “bound” the concept of daddy’s office (the subway trip and its associated people and smells may be in the glom but will have been removed
from the concept). By contrast, indexicals have no meaning independent
from the situated context in which they are evoked.
Because indexicals have no inherent meaning independent from context, the use of an indexical is constrained by the variety of contexts in
which it is deployed and the multitude of meanings from which the interplay between context and indexical is required to distinguish. The effective indexical serves as a medium to evoke meaning. The ineffective
indexical will instead call attention to itself with the demand for further
clarification. In essence, its ability to carry meaning will have been compromised. The overloaded indexical reveals itself via a lack of transparency to its medium-serving (medionic) functions and the implicit
question of “this or that?” When something new is encountered (a perturbation) or emerges at another level, the prior sense of clarity in the
fundierung between indexical and situation can break down, much like
the tragedy of the commons as described by economists. When the context does not evoke a clarity of meaning and multiple meanings are possible, evoked, and present, the indexical is broken and what has been
called a glom has been evoked instead.
The important observation is what Vygotsky says occurs when there is
dissonance between the understood meaning of a concept and new input,
whatever it might be. When a concept breaks down there is reversion
back to the glom. That reversion allows for change. The dissonance produced thereby forces a reversion in the perceived meaning of the word.
56

<-----Page 58----->VOLUME #5, ISSUE #3
Context dependence takes over. “It is not merely the content of a word
that changes, but the way reality is generated and reflected in a word”
(Vygotsky, 1986).
Inherent in the multiplicity of meanings is the recognition that only
one meaning will be primary within the context of a given situated activity. That primary meaning will not be the solely representative meaning,
but will take its primacy from the context. When there is coherence
between the situation and the meaning, the word choice will display a
transparency with regard to medionic function. When that coherence is
weak or absent, the very act of picking a label will demand some amount
of attention. What coherence there is about the meaning, if it is to exist,
would be forced to overcome or overwhelm such attentional demands.
The multiplicity of meanings undercuts the effective use of analogy as
the word tokens of memes. Metaphors and analogies create constraints by
focusing attention on that which is like and the resulting tendency by the
user to attempt to justify the analogy. These constraints may not be readily apparent when the weakness of the analogy or the affinity is being
exposed. Analogy involves inexact likeness. Butchvarov (1970, 1979) distinguishes between conceptual clarity and conceptual distinctness. Via
analogy we can see the relative position as far as distinctness but can
never achieve clarity. The former is a location in conceptual space and
can be determined by noting similarities and differences between the
entity being compared and other entities in conceptual space. However,
clarity involves the content of the entity itself. It can be modeled, but the
limitations of the model must be noted. Understanding is the desire for
clarity, not merely distinctiveness. There is a remainder between the two.
While categorization can suffice on distinctiveness, understanding
cannot.
When we use analogy we are calling attention to some “like aspect” of
two entities (call them source and object). If we were to dialogue with full
disclosure about the analogy—this is similar, this is different; notice how
the similars might react in situation x and contrast that with the differences, and so on—we would lose the shorthand and efficiency evoked by
the analogy. Thus, we tend to allow our use of analogy to emphasize similarity over difference and substitution over care. In practice, when we
assert that a is analogous to b, we often then make use of b as a label or
category into which a falls. Affording such primacy to the similarities is to
grant supervenience to the characteristics of the source at the expense of
a fuller description of the object. When the similarities of a metaphor or
analogy are allowed to supervene such that the analogy source is
57

<-----Page 59----->EMERGENCE
substituted in meaning for the description of the object, mistakes happen,
possibility spaces are misconstrued, retrospective sensemaking might not
make sense, and taken-for-granted fundierung relations may hide nasty
surprises. To the extent that coherence is perceived, it may be based on
fantasy. Indeed, much of the Internet/telecom bubble of the late 1990s
seems to have been fueled by the supervenience of the characteristics of
an “insatiable appetite” associated with convenience and newness over
the demands for infrastructure, use, and value. The same pattern has
been displayed by many of the bubbles documented in the history of
economics.
Word choice and metaphor use allow for the emergence of new
memes, the replacement of memes, and the death of memes via a concept
that Douglas Hofstadter (1995) has labeled “conceptual slippage.” In
essence, the use of a metaphor or analogy evokes a glom of meanings.
Each such use of metaphor is a perturbation to the existing selfreferencing system (be it an individual, the organization, or some part
thereof). The perturbations (please notice the plural) caused by the glom
or gloms interact in multiple dimensions with the self-referenced core. As
this series of interactions and resultant emergent behavior self-organizes,
the principle of “least action” takes over. The basin of attraction that is the
least demanding of energy is likely to determine the “winning” meaning.
The least-action principle suggests that the energy demands of attention
or of the carrying of a full description are likely to be supervened by the
efficacy of using an analogy, a label, or a name, even if incorrectly. Thus,
one concept can slip to another via the energy demands of the least-action
principle. The “whatever” of the current teen does not mean permission,
tolerance, or inclusiveness, it means indifference—though most over-40s
would not recognize that except after a series of painful experiences.
Thagard and Nerb (2002) make a similar claim to Hofstadter’s conceptual slippage in describing emotional gestalts:
Thagard (1996: Ch. 11) described how dynamical systems theory can be
applied to psychological phenomena by means of the following explanation schema: Human thought is describable by a set of variables. These
variables are governed by a set of nonlinear equations. These equations
establish a state space that has attractors. The system described by the
equations is chaotic. The existence of the attractors explains stable patterns of behavior. Multiple attractors explain abrupt phase transitions.
The chaotic nature of the system explains why behavior is unpredictable.
In the language of dynamical systems theory, the perceptual system has

58

<-----Page 60----->VOLUME #5, ISSUE #3
two attractor states, and the gestalt shift involves a phase transition from
one attractor to the other. Analogously, we might think of an emotional
state as a gestalt that emerges from a complex of interacting environmental, bodily, and cognitive variables, and think of emotional change as a
kind of gestalt shift… Emotional gestalt shifts occur when changes in representations and their valences generate a new array of acceptances and
valences that maximize constraint satisfaction differently from before.
Through parallel constraint satisfaction, this shift may alter the acceptance status of other propositions.

When an emotional gestalt occurs, so too might conceptual slippage. Both
undercut the effectiveness of a meme set in a new context.
Fauconnier and Turner (2002) go further in that they not only look for
a slippage in conceptual meaning, but also for the activation of a new
meaning. This is an extension of the emotional gestalt argument.
In any theory of meaning, activation does not come for free. The existence
of frames, knowledge, experience, scenarios, and memories does not come
for free. Ease of activation and degree of entrenchment by themselves
impose very strong constraints on the imagination and the use of language.
Linguists, logicians, and, for the most part, even psychologists tend to
focus on the entrenched cases, which are already built and usually easy to
activate. When only the rigid and entrenched patterns are used, meaning
becomes predictable based on the mapping schemes and those patterns…
Blends arise in networks of mental spaces which they call conceptual integration networks. Conceptual integration networks can have several input
spaces and even multiple blended spaces. In conceptual integration, there
is partial matching between input spaces of many kinds: connections
between frames and roles in frames, connections of identity or transformation or representation, analogical connections, and metaphoric connections. In blending, structure from two input mental spaces is projected to
a new space, the blend. Generic spaces and blended spaces are related:
Blends contain generic structure captured in the generic space but also
contain more specific structure, and they can contain structure that is
impossible for either of the inputs. Similarly, not all elements and relations
from the inputs are projected to the blend. Thus, emergent structure can
arise in the blend that is not copied there directly from any input.

Blends, emotional gestalts, and conceptual slippages are all evidence of
the least-action principle (lower energy expenditure) at work.
59

<-----Page 61----->EMERGENCE
Lower energy expenditure is the driving pursuit in the information
space world (cf. Boisot, 1995). In Vygotskian terms, a group and its members begin with some existing set of concepts and they encounter change.
The encounter reduces some of the concepts to the status of gloms, and
in such a status, the possibility arises for new conceptual understanding
to emerge. This understanding will be influenced by the metaphors and
analogies available to label the gloms, for in the adjacent meanings
implicit in the metaphors is the potential synthesis represented by the
new concept. The premises of least action suggests that a contextdependent glom is an efficient vehicle (in the same manner that Perry and
Barwise suggest that indexicals are efficient), provided that supervenience is possible. This is because we use words as tokens and allow
context to evoke meaning from among the gloms represented thereby. If
supervenience is possible, then such evoked meanings are triggered by
the situated activity in which they occur. By contrast, gloms will not work
well in a system that is dependent on representations, reductions, and
causality. In such a world, evoked meanings become reified and are carried across new situated activities. Dissonance from the mismatch is the
likely result.
To a group member, context includes ongoing change—which then
disrupts the shared-context content of existing codification and disturbs
the agreed meanings of abstractions. A key least-action observation is that
personal coding of meaning is transformed within an organization into
institutionalized codification, so as to both maximize the value of shared
meaning and minimize the need for the energy expended to transmit
shared context. Emergent change erodes the ability of codification to
hold. In the absence of an offsetting response to this erosion, institutional
codification recedes to personalized coding, and the ability of common
abstractions to transmit shared meaning deteriorates. Concepts become
gloms. Such disturbances can have an emergent character that itself is
disturbing, because the cumulative effects thereof cannot be predicted or
planned for. This lack of prediction or planning poses a threat to coherence. And coherence preservation is another energy-conserving action
within the information space.
Thus, we have a mechanism for meme success and failure. Emergent
change occurs in the environment. In Vygotskian terms, the dissonance
introduced by emergent change forces previously accepted concepts to
recede to gloms. Uncertainty of meaning is introduced. For our purposes,
uncertainty can be regarded as a label better defined as the inverse of
one’s propensity to act (Dretske, 1981; Fransman, 1994). Given uncer60

<-----Page 62----->VOLUME #5, ISSUE #3
tainty’s threat to coherence, organizations must find a way to combat its
increase, for uncertainty is a significant energy drain running counter to
the principle of least action. Increases in uncertainty can be attributed to
loss of identity, to a perceived need for more and “better data,” and to an
increase in the perceived threat from taking an incorrect action.
This translates into the lack of a well-understood model of the possibility space and thus the substitution of a need to search for a willingness
to act. If identity is to be preserved, then there must be an offsetting
emergent response to rebuild context so as to replace the content lost to
uncertainty (i.e., that which was contained in the institutional codifications and abstractions that have now encountered disconfirming notions
and been forced to revert to the more primitive gloms of meaning). Success is related to the evolution of the ideational niche for which the meme
is a token. If that niche has failed, so too will the meaning-evocation powers of the token. The successful meme is one whose indexical quality can
bridge both the old context and the new, such that the users of the meme
token can dialogue about the meanings evoked by that token without
asserting incommensurability. The unsuccessful meme is one whose
indexical quality cannot bridge the gap between contexts and thus cannot
make the transition to new context and new situation.

IMPLICATIONS
We need to do memetics to demonstrate when, where and how memetics has
a relative and relevant advantage over social science devoid of memetics. The
future of memetics will not be decided by those talking about memetics,
whether grand theorising or armchair philosophy about the evolution of culture, history, consciousness or how we think, but will be decided by those
doing memetics and demonstrating its relevance. (Hales & Marsden, 2002)

A memetics that accepts memes as indexical catalysts and tools can
demonstrate the advantage that Hales and Marsden seek. Such a memetics allows for study of the content of information and its use, with a focus
on processes and mechanisms vastly different from what passes today as
information science, knowledge management, or linguistics. This is not a
memetics that studies the evolution of memes per se, for the ontological
status of memes is changed within it. However, such a memetics can
demonstrate relevance, advantage, and application.
For example, if this approach were adapted to an extension of
Salingaros and Mikiten’s (2002) exploration of modernism as an
61

<-----Page 63----->EMERGENCE
architectural meme, the discussion would explore the environmental
niche in which the qualities laid out for the success of the modernism
thrive. This would be followed by an exploration of what potential risks
for the success of the meme lie within and without that niche, and what
factors of the meme and/or the niche contribute to its ongoing resilience.
Once the risks and resilience factors have been so identified, they can be
mapped to other domains and compared with the success/failures of other
memes both within and without the architectural domain. This seems far
more fruitful an approach to making social science advances than the
mere mapping of modernism in architecture as a meme (a mapping that
allows critics to reply “So what?”).
Edmonds’ (2002) three challenges can be answered by this revised
form of memetics. For example, his first challenge argues that a “conclusive case study” would “clearly demonstrate that there is at least one cultural process that is of an evolutionary nature, where ‘evolutionary’ is
taken in a narrow sense.” If the requirement that it is the meme that must
be of an evolutionary nature is dropped, then Edmonds’ challenge is easily fulfilled. Anthropology and sociology can document hundreds of cultural processes that are evolutionary and many of these will have a history
of successful memes associated with them. What is difficult for meme as
replicator is much easier for meme as indexical catalyst.
Lissack and Letiche’s forthcoming Coherence Emerges: A Complexity
Theory of Organization (2004) is an example of work that meets
Edmonds’ second challenge. So too does much of the case-study work on
organizational symbolism. Edmonds’ third challenge is perhaps incommensurate with the revisions suggested above. Memetic processes of the
catalytic indexical variety are easily found and documented in the “real”
world and are not in need of “simulation.” Such “real” examples should,
in any case, be considered as a firmer foundation for an applied theory
than simulations could provide. Memetic processes of the catalytic indexical variety also seem to address many of the concerns raised in Bloch
(2000) and Kuper (2000).
This redefinition of memes recognizes that they are efficient tools for
evoking particular affordances to be attended to in situ. Such a definition
is consistent with theories of niche construction. This article suggests that
Dawkins created an indexical (meme=gene) and it has exceeded its
carrying capacity and thus lost its efficacy. Worse, that indexical is evoking images and affordances that stand in the way of the memetics field
making true progress. It is time to recognize that ontic status has been
misplaced. Memes need a new meme: meme as catalytic indexical.
62

<-----Page 64----->VOLUME #5, ISSUE #3
For managers, memes defined as catalytic indexicals raise the potentialities offered by other catalysts—the provisioning of an environment
with a catalyst can afford the possibility of a transformation that is much
more difficult than without the catalyst’s presence. Memes would be
studied for their catalytic roles and managers would be taught sensitivity
to the conditions that aid and hinder the evolution of such catalysts.
As catalytic indexicals, memes can be meaningfully assigned explanatory and causal roles—the very ingredients that Edmunds claims memetics needs, and the qualities that managers are often seeking.

NOTES
1

2
3

4

This notion does not conflict with the definition of meme in the Oxford English
Dictionary: An element of a culture that may be considered to be passed on by nongenetic means.
An application of this argument is forthcoming in Lissack & Letiche (2004).
Cf. T. Kapitan’s “Autonomy of indexical reference” and related works at
http://www.soci.niu.edu/~phildept/ and G. Nunberg’s “Indexicality and deixis” (1993)
and related work at http://www-csli.stanford.edu/~nunberg/linguistics.html.
Much of the mechanism argument was first developed in Lissack & Roos (1999) and has
been expanded in Lissack & Letiche (2004).

REFERENCES
Ashforth, B., Kreiner, G., & Fugate, M. (2000) “All in a day’s work: Boundaries and micro
role transitions,” Academy of Management Review, 35: 472–91.
Barwise, J. & Perry, J. (1983) Situations and Attitudes, Cambridge, MA: MIT Press.
Bloch, M. (2000) “A well-disposed social anthropologist’s problem with memes,” in R.
Aunger (ed.), Darwinizing Culture: The Status of Memetics as a Science, Oxford, UK:
Oxford University Press.
Boisot, M. (1995) Information Space, Oxford, UK: Oxford University Press.
Butchvarov, P. (1970) The Concept of Knowledge, Evanston, IL: Northwestern University Press.
Butchvarov, P. (1979) Being qua Being: A Theory of Identity, Existence and Predication,
Bloomington, IL/London, UK: Indiana University Press.
Dawkins, R. (1976) The Selfish Gene, Oxford, UK: Oxford University Press.
Dewey, J. (1934) Art as Experience, New York: Perigree.
Donati, P. (1992) “Political discourse analysis,” in M. Diani & R. Eyerman (eds), Studying
Collective Action, London: Sage.
Dretske, F. (1981) Knowledge and the Flow of Information, Oxford, UK: Blackwell.
Edmonds, B. (2002) “Three challenges for the survival of memetics,” Journal of Memetics:
Evolutionary Models of Information Transmission, 6(2).
Fauccioner, G. & Turner, M. (2002) The Way We Think: Conceptual Blending and The Mind’s
Hidden Complexities, New York, Basic Books.
Fransman, M. (1994) “Information, knowledge, vision and theories of the firm,” Industrial
and Corporate Change, 3(3): 713–57.
Gould, S. J. (2000) “Jim Bowie’s letter & Bill Buckner’s legs,” Natural History, 109: 26–40.
Gratton, L. (2000) Living Strategy: Putting People at the Heart of Corporate Purpose,
London: Financial Times/Prentice Hall.

63

<-----Page 65----->EMERGENCE
Greeno, J. & Moore, J. (1993) “Situativity and symbols, response to Vera and Simon,”
Cognitive Science, 17: 49–59.
Hales, D. & Marsden, P. (2002) “Editorial: Memetics malaise?,” Journal of Memetics:
Evolutionary Models of Information Transmission, 6(2).
Hargadon, A. & Fanelli, A. (2002) “Action and possibility: Reconciling dual perspectives of
knowledge in organizations,” Organization Science, 13(3): 290–302.
Hofstadter, D. (1995) Fluid Concepts and Creative Analogies, New York, Basic Books.
Kapitan, T. “Autonomy of indexical reference,” http://www.soci.niu.edu/~phildept/speakers/Kapitan_Indexicals.html#ref5.
Kaplan, D. (1989) “Demonstratives,” in J. Almog, J. Perry, & H. Wettstein (eds), Themes
from Kaplan, New York: Oxford University Press: 481–563.
Kuhn, T. (1969) The Structure of Scientific Revolutions, Chicago: University of Chicago
Press.
Kuper, A. (2000) “If memes are the answer, what is the question?,” in R. Aunger (ed.),
Darwinizing Culture: The Status of Memetics as a Science, Oxford, UK: Oxford
University Press.
Laland, K. N., Odling-Smee, J., & Feldman, M. W. (1999) “Niche construction, biological
evolution and cultural change,” Behavioral and Brain Sciences, 23(1).
Laland, K. & Odling-Smee, J. (2000) “The evolution of the meme,” in R. Aunger (ed.),
Darwinizing Culture: The Status of Memetics as a Science, Oxford, UK: Oxford
University Press.
Lissack, M. & Letiche, H. (2004) Coherence Emerges: A Complexity Theory of Organization,
Cambridge, MA: MIT Press.
Lissack, M. & Roos, J. (1999) “Words count: Viewing organizations as emerging systems of
languaging,” http://lissack.com/writings/AMRfinal.doc.
McGrenere, J. & Ho, W. (2000) “Affordances: Clarifying and evolving a concept,”
Proceedings of Graphics Interface 2000: 179–86.
Mead, G. H. (1934) Mind, Self and Society, Chicago: University of Chicago Press.
Michaelsen, S. & Johnson, D. (1997) Border Theory: The Limits of Cultural Politics,
Minneapolis: University of Minnesota Press.
Millikan, R. (1993) White Queen Psychology and Other Essays for Alice, Cambridge, MA:
MIT Press.
Nippert-Eng, C. (1996a) “Calendars and keys: The classification of ‘home’ and ‘work,’
Sociological Forum, 11(3): 563–82.
Nippert-Eng, C. (1996b) Home and Work: Negotiating Boundaries through Everyday Life,
Chicago: University of Chicago Press.
Odling-Smee, F. J., Laland, K., & Feldman, M. (2003) Niche Construction: The Neglected
Process in Evolution, Princeton, Princeton University Press.
Prigogine, I. (1997) The End of Certainty, Time, Chaos and the New Laws of Nature, New
York: Free Press.
Prigogine, I. & Stengers, I. (1984) Order out of Chaos: Man’s New Dialogue with Nature,
New York: Bantam.
Salingaros, N. A. & Mikiten, T. M. (2002) “Darwinian processes and memes in architecture:
A memetic theory of modernism,” Journal of Memetics: Evolutionary Models of
Information Transmission, 6.
Simon, H. A. (1994) “Literary criticism: A cognitive approach,” in G. Guzeldere & S. Franchi
(eds), “Bridging the Gap,” special supplement to Stanford Humanities Review, 4(1): 1–26.
Stanford Encyclopedia of Philosophy, http://plato.stanford.edu/.
Thagard, P. (1996) Mind: Introduction to Cognitive Science, Cambridge, MA: MIT Press.

64

<-----Page 66----->VOLUME #5, ISSUE #3
Thagard, P. & Nerb, J. (2002) “Emotional gestalts: Appraisal, change, and emotional coherence,” Personality and Social Psychology Review, 6: 274–82.
Vygotsky, L. (1986) Thought and Language, A. Kozulin (ed.), Cambridge, MA: MIT Press.
Weick, K. (1979) The Social Psychology of Organizing, Reading, MA: Addison-Wesley.
White, S. P. (2002) New Ideas about New Ideas: Insights on Creativity from the World’s
Leading Innovators, New York: Perseus.
Wilkins, J. S. (1998) “What’s in a meme? Reflections from the perspective of the history and
philosophy of evolutionary biology,” Journal of Memetics: Evolutionary Models of
Information Transmission, 2: 2–33.
Zerubavel, E. (1991) “The great divide. The social lens,” in E. Zerubavel (ed.), The Fine
Line: Making Distinctions in Everyday Life, Chicago: University of Chicago Press.

65

<-----Page 67----->EMERGENCE, 5(3), 66–82
Copyright © 2003, Lawrence Erlbaum Associates, Inc.

The Dark Side of Organizations
and a Method to Reveal It
David A. Bella, Jonathan B. King, & David Kailin

The ability to see the larger context is precisely what we need to liberate
ourselves. (Milgram, 1992: xxxii)

F

ew who have read Stanley Milgram’s book, Obedience to
Authority (1974), or have seen videos of these “shocking”
experiments can forget them. In our view, Milgram’s experiments offer important lessons about contexts, human
behaviors, and the role of contexts in setting boundary conditions around
such behaviors. This article takes these lessons seriously. But first, a succinct summary of the experiments.
A “teacher” is instructed by the “scientist-in-charge” to administer an
electric shock to a “student” every time he gives a wrong answer—which
is most of the time. The teacher is given a list of questions in advance.
The electric shocks range from 15 to 435 volts and are visibly displayed
on a panel facing the teacher: Slight 15+ … Intense 255+ … Danger
375+ … XXX 435. The student—a superb actor who is not actually
shocked—starts to grunt at 75 volts. He follows a standard script.
At 120 volts he complains verbally; at 150 he demands to be released from
the experiment. His protests continue as the shocks escalate, growing
increasingly vehement and emotional. At 285 volts his response can only
be described as an agonized scream. (Milgram, 1974: 4)

And that’s with 150 volts yet to go! At the high end, the student is dead
silent. What happens if the teacher (repeatedly) objects? The scientist is
66

<-----Page 68----->VOLUME #5, ISSUE #3
only allowed to “prompt” her or him with such comments as, “Please continue, please go on,” “The experiment requires that you continue,” “You
have no other choice, you must continue.” No threats, no demeaning
remarks about the student; just calmly stated reasons why the teacher
should continue.
So, at what point would you or I stop? The bad news is that over 60
percent of us go all the way even when we can hear the student screaming. The really bad news is the disparity between our actual behaviors
and the predictions of “psychiatrists, graduate students and faculty in the
behavioral sciences, college sophomores, and middle-class adults.”
They predict that virtually all subjects will refuse to obey the experimenter; only a pathological fringe, not exceeding one or two percent, was
expected to proceed to the end of the shockboard. The psychiatrists… predicted that most subjects would not go beyond the 10th shock level (150
volts, when the victim makes his first explicit demand to be freed); about 4
percent would reach the 20th shock level, and about one subject in a thousand would administer the highest shock on the board. (Milgram, 1974: 31)

Why the stunning disparity? What are we overlooking? For starters, how
did Milgram interpret the significance of such unexpected findings?
I must conclude that Arendt’s conception of the banality of evil comes
closer to the truth than one might dare imagine… This is, perhaps, the
most fundamental lesson of our study: ordinary people, simply doing their
jobs, and without any particular hostility on their part, can become agents
in a terrible destructive process… Men do become angry; they do act
hatefully and explode in rage against others. But not here. Something far
more dangerous is revealed: the capacity for man to abandon his humanity—indeed, the inevitability that he does so—as he merges his unique
personality into larger institutional structures. (Milgram, 1974: 6, 188)

“Larger institutional structures”? What are such things? And why are we
apparently blind to the emergence of their dark side?
We propose that the first general lesson to be drawn from Milgram’s
experiments is that contexts are powerful determinants of human behavior. In his experiments, Milgram essentially constructed a context. And
subjects found it extremely difficult to act out of context—to refuse to
continue the testing. A second general lesson is that the power of context
to shape human behavior has been vastly underestimated if not
67

<-----Page 69----->EMERGENCE
overlooked entirely. For Milgram’s work also demonstrates that when the
experiments were described to people—including experts—virtually all
failed to foresee anything remotely close to the compliance that actually
occurred. A third lesson that we shall literally illustrate is that Milgram’s
experimental results not only extend to and pervade human existence,
but that such contexts are typically neither the result of deliberate design
nor otherwise intended. Instead, they emerge.
This article presents a method to see past the business that preoccupies us to expose the character of contexts that promote compliance no
less disturbing than the compliance of Milgram’s subjects. While disarmingly simple, this method is far from simplistic, for it allows us to illustrate
the patterns that lie behind the countless tasks of ordinary people who are
simply doing their jobs, getting by, and struggling to succeed. From such
patterns, great harm can emerge. But within the context of such patterns,
one finds individuals who are hard-working, competent, and welladjusted. The key to understanding such claims is to take emergence very
seriously.
Put bluntly, outcomes that we consider harmful, distorting, and even
evil can and too often do emerge from behaviors that are seen as competent, normal, and even commendable. These emergent outcomes cannot
be reduced to the intentions of individuals, but, more disturbingly, dark
outcomes can emerge from interactions among well-intended, hardworking, competent individuals. Such phenomena do not require the setting of Milgram’s experiment—the “authority” of a laboratory complete
with a “scientist” dressed in a white lab coat—quite the contrary. They
are an everyday feature of our lives. Therefore, rather than focusing on
the actions of irresponsible individuals, we must—most importantly—
attend to the contexts within which normal, well-adjusted people find
good reasons for behaving as they do.

SKETCHING

CONTEXT

Consider the normal behavior of well-adjusted students in a university
library. At a football game, these students yell and cheer. At the library
they do not. Why? The behavioral contexts are different and—this is a
key claim—contexts shape behavior. To understand this claim, consider a
sketch of the library context given in Figure 1. To read this sketch, begin
with any statement of behavior. Read forward or backward along an arrow
to the next statement. Say “therefore” when you move forward along an
arrow and “because” when you move backward. Wander through the
68

<-----Page 70----->VOLUME #5, ISSUE #3

Figure 1 A sketch of the university library context. Read forward (say
“therefore”) or backward (say “because”)
entire sketch, moving forward and backward along the many loops, until
you grasp the character of the whole. Please note: If you do not work
through the sketches in this manner, you will likely misperceive the fundamental claims of this article.
Yes, there are rules for proper behavior within the library, but very
few read them. Instead, we find that amid the busy activities of students,
general behaviors tend to settle into mutually reinforcing patterns. These
emergent patterns constitute the context. Figure 1 therefore serves to
explain not the specific behaviors of particular students, but rather the
context that sustains normal behaviors as many students come and go.
Table 1 outlines the general method of sketching applied to Figure 1.
Column A describes how human behaviors, in general, respond to any
given context. Column B describes a disciplined approach to sketching
that expresses the general behaviors given in Column A. Read these two
parallel columns and note their relationships. Together they show that the
way we behave within a context (Column A) can be sketched by the
method given in Column B.
This method of disciplined sketching exposes behavioral patterns that
are typically taken for granted. Such patterns, we claim, constitute behavioral contexts. Figure 1 is an example. Within this context, students find
good reasons not to yell and cheer. This is what contexts do: They provide
reasons for some kinds of behaviors and not others.
By using information relevant to the context of interest, this method
can uncover the character of different contexts. Table 1 provides a discipline to such an inquiry. First, we are led to look for persistent behaviors
69

<-----Page 71----->EMERGENCE
Table 1 General observations of human behaviors (Column A) and
related guidelines for sketching (Column B)
A
Within a given context

B
To develop a sketch of a given context

Some behaviors and conditions tend to
persist and reoccur

Place simple descriptive statements of
behaviors (conditions) in boxes;
statements should make sense to
those involved
Each boxed statement should have at
least one incoming arrow from a
boxed statement that provides a
reason that makes sense to those
involved*
Each boxed statement should have at
least one outgoing arrow pointing to
a boxed statement that is a
consequence

Persistent and reoccurring behaviors
(conditions) are supported by
reasons that make sense to those
involved
Persistent and reoccurring behaviors
(conditions) have consequences
that are also persistent and
reoccurring

*Occasionally a given statement can be employed without an incoming arrow, indicating
that the reasons lie beyond the scope of the sketch

and to express them in general terms. Second, we are forced to seek reasons—not “causes” but “reasons”—for such behaviors, reasons that make
sense from the perspectives of those acting out the behaviors. Having
done this, we make a sketch under the guidance of Table 1. Figure 1 was
sketched (after many revisions) in this manner. Notice that, with the
exception of the “given” (double-lined box), all the behaviors must meet
two commonsense guidelines:
1 Behaviors that tend to persist (keep coming up) do so because they
have reasons that make sense to those acting out the behaviors.
2 Behaviors that tend to persist have consequences that tend to persist.
The first guideline is met when each behavior statement (except the
“given”) has at least one incoming arrow (a reason). The second guideline
is met when each behavior has at least one outgoing arrow (a consequence). The patterns that emerge from these guidelines take the form of
loops. Our method of sketching serves to uncover such patterns, exposing the fundamental character of a context that is often hidden in countless distracting details.
Notice some features of this simple sketch. The “elements” or “components” of the system, the boxed statements, do not refer to “agents” or
70

<-----Page 72----->VOLUME #5, ISSUE #3
to groups of people. Neither do these boxes represent “storage tanks” as
in stock-and-flow models. They are not “control volumes” as often
employed in the derivation of differential equations. Instead, the boxes
describe behaviors or behavioral conditions. In turn, the arrows do not
represent transfers (inputs and outputs). Instead, when read backward an
arrow gives a reason; when read forward it gives a consequence. Notice
also that the figure reads in natural or ordinary language. This allows
readers quickly to grasp the pattern as a whole without struggling with
unfamiliar notations, jargon, or symbols. Such sketches involve only a few
statements—usually fewer than 14—so that the reader is drawn not to
details but to the pattern as a whole. Sketches gain validity when people
who have been involved within the context recognize it within the sketch.
Finally, notice the form of the pattern: multiple loops of mutually reinforcing behaviors.
In sum, we claim that emergent outcomes in human affairs appear in
such forms and that such forms become apparent through the application
of this method. We will now show how this sketching method serves to
expose a whole class of problems that are commonly overlooked and
misperceived.

SIMPLE

AND COMPLEX PROBLEMS

Imagine that a student does yell and cheer in the library; that is, that he
or she acts out of context. This would constitute a problem—a condition
that demands attention. “But,” you might respond, “we don’t need such
sketches to notice, let alone understand, this kind of problem.” We agree!
The out-of-context (improper, maladjusted) behavior clearly stands out
without the need of a method. So, when is this method of exposing context important? Why bother sketching loops if we don’t need to? The
answer becomes apparent when we recognize the difference between
simple and complex human problems.
A problem arising from out-of-context behavior—a student shouting
in the library—is a simple problem. Simple problems can be reduced to
the improper behavior of the offending individuals. Thus, the problem
lies in the part, not the whole. For complex problems, however, the condition that demands attention is the context as a whole. Unlike a maladjusted student yelling in the library, a complex problem arises from the
well-adjusted behaviors of people acting within a context. Thus, the context itself demands our attention. However, unlike a shouting student, the
context does not stand out in general, let alone as something abnormal in
71

<-----Page 73----->EMERGENCE
particular. Quite the opposite! The context defines the norm and is usually taken for granted.
If all human problems were simple problems, then disciplined sketching would be of little use. But if complex problems are both common and
significant, then the patterns of normal and well-adjusted behaviors
should concern us. Such patterns constitute the contexts that normal and
well-adjusted people take for granted. Context defines normal behaviors.
There are few things that can hide and sustain a problem as well as normalcy. We will now apply this method to a complex problem that is serious, widespread, and sustained by the normal behaviors of well-adjusted
people.

THE

SYSTEMIC DISTORTION OF INFORMATION

Clearly, information can be distorted through the willful intent of individuals. Without denying such willful distortions, we claim that information distortion can also emerge as a complex problem that cannot be
reduced to the intentions of individuals. Figure 2 illustrates such systemic distortions. This sketch was selected because it has been peer
reviewed by practitioners from a wide range of disciplines and appears to
describe a pervasive, complex problem (Bella, 1987, 1996).
Wander through the entire sketch, moving forward (“therefore”) and
backward (“because”) along the many different loops, until you comprehend the whole picture. You can sense how information favored by “the
system” serves to support, sustain, promote, and propagate the system.
Such information is more readily sought, acknowledged, developed, and
distributed, while unfavorable information has more difficulty coming up,
going anywhere, or even surviving.
Such contexts and the information they sustain shape the premises
and perceptions of those involved, instilling within them what are taken
for granted as proper and acceptable behaviors. Those who raise troubling matters, questions that expose distortions, are out of context. As
with simple problems, they become the problem “trouble-makers.” They
may face personal criticism, being charged with improper, even “unethical,” behavior. In the private sector, the possibility of legal action—“You’ll
hear from our lawyer”—can be very threatening. However, the problem
sketched herein is not a simple problem; the context itself is the problem.
Now conduct the following exercise. Imagine that you have reviewed
a recent report describing the consequences of an organization’s activities
(environmental impacts, as an example). You are upset to find that
72

<-----Page 74----->VOLUME #5, ISSUE #3

Figure 2 The systemic distortion of information (Bella, 1987)
information concerning adverse consequences was omitted. You question
the individuals involved. Your questions and their answers are given in
Table 2. As you read their answers, keep in mind the context sketched in
Figure 2. Notice that the answers given in Table 2 make sense to those
acting within this organizational context. In sum, the problem—systemic
distortion—emerges from the context (pattern, system) as a whole and
cannot be reduced to the dishonest behaviors of individual participants.
Unlike the library context, systemic distortion of information is a complex
problem where the context itself demands our attention.
The larger point is that complex problems are particularly dangerous
because the individual behaviors that lead to them do not stand out as
abnormal—as out of context. Quite the contrary, for as illustrated in Table
2, each individual finds good reasons for his or her behavior within the
context. Indeed, distortions can become so pervasive and persistent that
views contrary to—that don’t fit within—the prevailing patterns are dismissed as misguided and uncalled for.
While such distortions can harm the organizations that produce them
(Larson & King, 1996), they can also serve to propagate the systems that
produce them, covering up adverse consequences and externalized risks.
As a case in point, the model (Figure 2 and Table 2) was originally developed in 1979 to describe the frustrations of professionals involved in the
assessments of environmental consequences. Here, the primary concern
73

<-----Page 75----->EMERGENCE
Table 2 Reasoning of participants within the context sketched in Figure
2 (Bella, 1987)
Person in the system Question

Assumed answer to question

Higher-level manager

Why didn’t you consider the
unfavorable information your own
staff produced?

Midlevel manager

Why didn’t you pass the
information up to your superiors?

Professional
technologist

Why wasn’t the unfavorable
information checked out and sent
back up to your superiors?
Why didn’t you follow up on the
information that you presented?

I am not familiar with the information
that you are talking about. I can assure
you that my decisions were based upon
the best information available to me.
I can’t pass everything up to them.
Based upon the information available to
me, it seemed appropriate to have this
information reevaluated and checked
over.
That wasn’t my job. I had other tasks to
do and deadlines to meet.

Trouble-maker

Higher-level manager

Midlevel manager

Professional
technologist

Trouble-maker

Higher-level manager

Midlevel manager

Professional
technologist

Trouble-maker

74

I only worked on part of the project.
I don’t know how my particular
information was used after I turned it in. I
did my job. Even if I had all the
information, which I didn’t, there was no
way that I could stop this project.
Why has the organization
I resent your accusation! I have
released such a biased report?
followed the development of this report. I
have reviewed the drafts and the final
copy. I know that the report can’t please
everybody, but based upon the
information available to me, I can assure
you that the report is not biased.
Why has the organization
It is not just my report! My sections of
released such a biased report?
the report were based upon the best
information made available to me by
both my superiors and subordinates.
Why has the organization
It is not my report! I was involved in
released such a biased report?
a portion of the studies that went into the
report. I completed my tasks in the best
way possible given the resources
available to me.
Why has the organization
Don’t ask me! I’m not on this project
released such a biased report?
anymore and I really haven’t kept up with
the project. I turned in my report. It dealt
with only a part of the project.
Why was the source of unfavorable I hardly know the person. A lot of people
information (the trouble-maker)
have worked on this project. I must, of
removed from the project?
course, make decisions to keep this
organization running, but there has been
no plot to suppress people! On the
contrary, my decisions have been
objectively based upon the available
information and the recommendations of
my staff.
Why was the source of unfavorable I don’t like your implications! I’ve got
information (the trouble-maker)
tasks to complete and deadlines to meet
removed from the project?
with limited resources. I can’t let
everybody do their own thing; we’d never
finish anything. I based my
recommendations and assignments on
the best available information.
Why was the source of unfavorable I’m not sure about the details because I
information (the trouble-maker)
don’t work with him. I guess it had to do
removed from the project?
with a reorganization or a new
assignment. He is a bright person,
somewhat of an eccentric, but I’ve got
nothing personal against him.
Why were you removed from the
My assignment was completed and I was
project?
assigned to another project. I don’t think
that anybody was deliberately out to get
me. My new job is less of a hassle.

<-----Page 76----->VOLUME #5, ISSUE #3
was self-propagating distortions that benefited the organizational system
that produced them while allowing harmful consequences to accrue in
the larger environment and society.
If all systemic distortions were self-harming, we would expect this
complex problem to be self-correcting. But where distortions benefit,
sustain, and promote the systems that produce them, the presumption of
self-correction does not apply. These are arguably the most serious forms
of systemic distortion, propagating the systems that produce them.

DISTORTION

AND EMERGENCE

We realize that much more is involved in organizational systems than
shown in this sketch (Figure 2). But, of course, complex systems are
“incompressible” (Richardson et al., 2001). Thus, all models (sketches) are
simplifications. A test of any model is: Does the model describe some
matters of importance better than its chief rivals?
In the case of information distortion, the dominant rivals involve lines
of reasoning as sketched in Figure 3.
There is much appeal to such straightforward reasoning. We can
blame others and it requires little effort on our part. However, this ease
of reasoning arises from linear presumptions. In brief, one presumes that
wholes, systemic distortions, can be reduced to the character of parts,
individuals. Ergo, blame (Figure 3). If the world were linear, such reasoning would make sense. But of course, if the world were linear we
could be great musicians. On a grand piano we could play grand notes.
Alas, the world is nonlinear and the sum of our grand notes does not add
up to grand music! Clearly, the character of wholes cannot be reduced to
the character of parts. Blame, like the pounding of individual notes, is a
linear misperception that fails to conceive emergent wholes. By sketching whole behavioral patterns in a disciplined way, rather than focusing
on parts (individuals), we can expose emergent phenomena not reducible

Figure 3 Common and straightforward (linear) explanations of distortion
75

<-----Page 77----->EMERGENCE
to parts. However, to make such sketches, one must blame less and listen
more.
Compare Figures 1 and 2 on the one hand with Figure 3 on the other.
Notice the strikingly different form of thought. Instead of a “line” or
“chain” of reasoning (Figure 3), we find that human behaviors tend to settle into mutually reinforcing patterns (Figures 1 and 2). Behaviors
continue because they are sustained by such patterns. Emergent behaviors arise from the patterns as wholes.
Concerning “emergence,” we are in agreement with the following
general statements by John H. Holland (1998):
Recognizable features and patterns are pivotal in this study of emergence... The crucial step is to extract the regularities from incidental and
irrelevant details… This process is called modeling… Each model concentrates on describing a selected aspect of the world, setting aside other
aspects as incidental (pp. 4–5)… emergence usually involves patterns of
interaction that persist despite a continuing turnover in the constituents
of the patterns (p. 7)… Emergence, in the sense used here, occurs only
when the activities of the parts do not simply sum to give activity to the
whole (p. 14).

This modeling approach (disciplined sketching) is different from (and we
believe complementary to) the approaches of Holland and others. Nevertheless, Holland’s statements do apply to our notion of systemic distortions as emergent phenomena. Furthermore, we find that these sketches
are quickly grasped by participants within organizational systems.
Indeed, Figure 2 was sketched in response to the stories of frustration of
people within actual organizational systems (Bella, 1987). Rather than
dismissing their frustrations as evidence of “poor attitude” (a form of
blame), we took them seriously and sketched the context that (a) made
sense of credible frustrations and (b) avoided blame. In brief, amid the
busy activities of countless people involved in endless tasks, general
behaviors tend to settle into mutually reinforcing patterns. These patterns constitute the contexts for the normal behaviors of well-adjusted
people. In scale, duration, and complexity, the distortions that can
emerge from such patterns far exceed the capabilities of deliberate
designs. This has radical implications that are easily overlooked by a more
straightforward (linear) understanding of distortion (Figure 3).

76

<-----Page 78----->VOLUME #5, ISSUE #3

IMPLICATIONS

FOR OUR EMERGING TECHNOLOGICAL
WORLD

In the modern world, getting a drink of water is such a simple thing.
Merely turn the faucet. But this simple act depends on a vast technosphere far beyond the capacity of any group to design deliberately. The
components of our faucet may come from distant parts of the world. Following the faucet back through pipes, pumps, electrical grids, power
plants, manufacturing facilities, and mining operations, one encounters
vast and interconnecting complexities in all directions. The technological,
informational, and financial interconnections are bewildering and vast.
Yet, somehow it all comes together so that you can turn on your faucet
and get water.
This global technosphere requires the busy and highly diverse activities of countless people involved in endless tasks. If we focus on only one
project manager on one of seemingly countless projects, we find remarkable abilities that few of us appreciate. The real challenge is not scientific
analysis of some physical entity or device. Rather, the challenge is getting
the right materials, equipment, people, and information together at the
right place and at the right time within a world that is constantly changing and ripe with the potential for countless conflicts and misunderstandings. If one is not impressed by the abilities of successful project
managers, one simply does not understand what is going on.
However, the scale and complexity of such human accomplishments—the continuously changing technosphere on which we depend —
extend far beyond the abilities of any conceivable project management
team. Our drink of water, indeed our very lives, depend on vast, complex,
adaptive, and nonlinear (CANL) systems. They are self-organizing and
continually adapting. Through them, highly diverse activities are drawn
together and outcomes emerge far beyond the abilities of individuals and
groups. The activities of numerous people, including our successful project manager, occur within the contexts sustained by such CANL systems.
Indeed, contexts are CANL systems emerging at multiple levels, shaping
behaviors in coherent ways despite vast differences among individuals
and the tasks they perform.
A growing body of literature, popular and academic, has been rightly
fascinated by the remarkable behaviors of CANL systems, which are not
subject to our traditional analytical habits of thought (Kauffman, 1995;
Waldrop, 1992; Wheatley, 1992). Richardson et al. (2001) write:

77

<-----Page 79----->EMERGENCE
Complexity science has emerged from the field of possible candidates as
a prime contender for the top spot in the next era of management science.

We agree. We are concerned, however, that too often the literature is
silent on the dangers of emergent outcomes in human affairs. Indeed,
some (Stock, 1993) treat emergent order in human affairs with a religiouslike reverence. In our assessment, emergent outcomes can be powerful
and they can also be dangerous, deceptive, and distorting.
We therefore face a worrying imbalance. Complexity science may well
help managers expand the effectiveness, scale, and influence of organizational systems. But with respect to the distortion of information, a crude
form of linear reductionism, blame, continues to prevail.

EMERGENCE

AND THE DARK SIDE OF
ORGANIZATIONAL SYSTEMS

There is a dark side to organizational systems that is widespread and well
documented (Vaughan, 1999). Much of this involves the emergence of
systemic distortions. After the first shuttle (Challenger) explosion in 1986
(see Vaughan, 1996), Figure 2 and Table 2 were sent to Nobel physicist
Richard Feynman, who served on the commission to investigate the accident. Although the model was developed long before the accident without any study of NASA, Feynman (1986) wrote back:
I read Table 2 and am amazed at the perfect prediction of the answers
given at the public hearings. I didn’t know that anybody understood these
things so well and I hadn’t realized that NASA was an example of a widespread phenomena.

We agree that general phenomena are involved, emergent phenomena
that too often are distorting and destructive. Did the second and more
recent shuttle (Columbia) tragedy involve such phenomena? Follow the
investigation and judge for yourself.
The tobacco industry serves as an exemplar of our concerns. Here we
find global systems that were among the most economically successful and
powerful of the twentieth century. They produced addictive products that
contributed to the deaths of 400,000 Americans every year. The method
presented in this article has been applied to the tobacco industry, illustrating how its economic success was closely tied to systemic and selfpropagating distortions that emerged over many decades (Bella, 1997).
78

<-----Page 80----->VOLUME #5, ISSUE #3
The widespread distortions of information in recent years by huge
businesses, including the formerly prestigious accounting firm of Arthur
Andersen, provide evidence of much more than individual fraud (Toffler,
2003). “Favorable” information (hyping stock, inflating profits, etc.)
gushed from these systems while “unfavorable” information (exposing
risks, improper accounting, unethical behaviors, etc.) too often went
nowhere. The transfers of wealth were enormous; some, who exploited
the distortions, made fortunes; many lost savings (Gimein, 2002).
What, then, tends to limit the extent of systemic distortions and their
consequences? Our answer reflects a growing understanding of CANL
systems in general. The character of CANL systems emerges from the
interplay of order (pattern) and disorder (disturbance) over time (Bella,
1997). As an example, forest ecologists tell us that the state of a forest
ecosystem reflects its “disturbance regime,” its history of events (fires,
storms, etc.) that disturbed emerging patterns. In a similar manner, we
claim that the extent of systemic distortion reflects the history of credible
disturbances, those compelling events that disrupt more distorting patterns allowing less distorting patterns to emerge.
In human systems, credible disruptions arise in two forms. First, they
arise through the independent inquiries, questions, objections, and challenges that people raise. Second, they arise from accidents, explosions,
and collapses that the system cannot cover up. Both serve to disrupt distorting patterns, but, clearly, the former are preferable to the latter.
Credible disturbances of the first (human) kind emerge from independent checks and open deliberation. This view leads to a conjecture:
The extent of systemic distortions and their consequences have been, are,
and will be inversely proportional to the history of credible disturbances
sustained by independent checks and public deliberation not shaped by
the systems themselves.

If evidence supports such a conjecture, as we believe it will, then we
must take far more seriously the crucial importance of independent
checks, including public agencies, and what Eisenhower (1961) called the
duties and responsibilities of an “alert and knowledgeable citizenry.” The
implications are significant: The market is insufficient, independent public agencies are vital, and higher education must involve far more than
economic development and job preparation.

79

<-----Page 81----->EMERGENCE

RESPONSIBILITY: BEYOND

LINEAR PRESUMPTIONS

Conventional notions of responsibility—and, more generally, notions of
good and evil—reflect linear presumptions. This linear attitude can be
simply stated: “I’m a responsible person if I act properly, don’t lie, cheat,
or steal, and do my job in a competent manner.” The problem raised by
such common understandings of responsibility is that we see no reason
why the individuals of Table 2 would not fit this notion of responsible
behavior. Likewise, people tend to reason that evil outcomes arise from
evil people: “If the individuals are good (competent, well-intended), then
the outcomes should be good.” Such linear perceptions fail to grasp the
importance of emergent outcomes. Distorting and even evil outcomes
can and do emerge from the actions of individuals, in spite of the fact that
each may believe that his or her own behaviors are proper and competently done—those in high positions might honestly say, “There was no
attempt to mislead or deceive.” And within their contexts, they may be
correct. However, if the context is the problem, then emergence has radical implications for notions of responsibility.
We do not deny the importance of competency, involving actions that
are credible, rightly done, and commendable within a given context
(game, course, assignment, organizational system, market, etc.). Competency calls for the ability to respond in ways credible within the context.
Yet, there is no reason to assume that greater competency would reduce
systemic distortions; in fact, the reverse may be true! When the context
is the problem, an additional and radically different form of responsibility is required, responsibility that transcends contexts.
The responsibility to transcend context is a universal historical theme
in the search for Truth, the pursuit of Justice, and the service of the
Sacred. Responding to a calling that transcends context serves to liberate
us from our bondage to contexts. Such contexts give us reasons to say, “I
just don’t have the time,” “It’s not my job,” “It won’t make any
difference.”
The traditional name for a responsibility to transcend context—and
which informs the essence of universal intent—is “faith.” Wilfred
Cantwell Smith (1977, 1979), who devoted a lifetime of study to the
meaning of faith in other ages and cultures, found that faith never meant
belief (and especially not belief in spite of evidence to the contrary).
Rather, the very meaning of faith has been radically distorted—lost, given
up—in our modern age. The point is that faith does not deny the reality
of context; faith transcends context. To paraphrase Viktor Frankl (1978),
80

<-----Page 82----->VOLUME #5, ISSUE #3
faith “pulls” or “calls” for responsible behaviors from beyond, above, or
even “in spite of ” the context.
None of this, however, makes sense unless the dangers of contexts
themselves become apparent. Distortions and, yes, evil, can and often are
emergent outcomes not reducible to the “values” and “beliefs” of individuals. Without an appreciation of the dangers of emergence and the
need for responsibility that transcends context, faith becomes reduced to
individual beliefs and, more dangerously, the self-reinforcing behaviors of
“true believers.”
The method of disciplined sketching proposed herein seeks to expose
the dangers of such reductionist thinking. This method, therefore,
entails relational self-knowledge—know thy contexts. While such a challenge may be easily voiced, enacting it requires the system to be transcended. In our modern age of organizations, this constitutes a basic
moral calling.

EPILOGUE
In 1982 John Naisbitt published a widely acclaimed book, Megatrends. In
this book he declared:
In the information society, we have systematized the production of knowledge and amplified our brainpower. To use an industrial metaphor, we
now mass-produce knowledge and this knowledge is the driving force of
our economy.

In the decades that followed, such declarations became so pervasive that
objections to the idea might well be called a heresy of the age. Naisbitt’s
statement expresses the ideology of the age and, for many, its intellectual
paradigm. Nevertheless, in this age we find evidence of information distortions arising from systems that selectively shape information in selfpropagating ways. Such distortions, we claim, are emergent phenomena,
emerging from patterns of behaviors that provide the contexts within
which normal and well-adjusted people are busy at work. We provide a
method to sketch such patterns.
To grasp the heretical implications of such claims, change one word in
Naisbitt’s declaration. Instead of “knowledge,” insert the word “propaganda”—information selectively shaped to propagate the systems that
produce it. The declaration now reads:

81

<-----Page 83----->EMERGENCE
In the information society, we have systematized the production of propaganda and amplified our brainpower. To use an industrial metaphor, we
now mass-produce propaganda and this propaganda is the driving force
of our economy.

Clearly, there is a moral difference. Judge for yourself. Has this “information age,” our “knowledge” economy, provided evidence that this alteration
of Naisbitt’s declaration—and many others—should be taken seriously?
We believe it does. But the evidence will not be understood if we persist in
linear presumptions, reducing all distortions to individual fraud, a “few bad
apples,” or conspiracies to deliberately mislead or deceive. Emergence is
real. Distortions emerge. This article presents a method to reveal how distortions emerge from contexts that well-adjusted people take for granted.

REFERENCES
Bella, D. A. (1987) “Organizations and systemic distortion of information,” Journal of
Professional Issues in Engineering, 113: 360–70.
Bella, D. A. (1996) “The pressures of organizations and the responsibilities of university professors,” BioScience, 46(10): 772–8.
Bella, D. (1997) “Organized complexity in human affairs: The tobacco industry,” Journal of
Business Ethics, 16: 977–99.
Eisenhower, D. D. (1961) “Farewell radio and television address to the American people,” Public
Papers of the President, Washington, D.C.: U.S. Government Printing Office, 1035–40.
Feynman, R. P. (1986) Personal communication to D. A. Bella, June 27.
Frankl, V. (1978) The Unheard Cry for Meaning, New York: Simon & Schuster.
Gimein, M. (2002) “You bought, they sold,” Fortune, 146(4): 64–74.
Holland, J. H. (1998) Emergence, Reading, MA: Perseus Books.
Kauffman, S. (1995) At Home in the Universe, New York: Oxford University Press.
Larson, E. W. & King, J. B. (1996) “The systemic distortion of information: An ongoing challenge to management,” Organizational Dynamics, 24 (Winter): 49–61.
Milgram, S. (1974) Obedience to Authority, New York: Harper Perennial.
Milgram, S. (1992) The Individual in a Social World: Essays and Experiments, J. Sabini & M.
Silver (eds), New York: McGraw-Hill.
Naisbitt, J. (1982) Megatrends, New York: Warner Books.
Richardson, K. A., Cilliers, P., & Lissack, M. (2001) “Complexity science: A ‘gray’ science for
the ‘stuff in between,’” Emergence, 3(2): 6–18.
Smith, W. C. (1977) Belief and History, Charlottesville, VA: University Press of Virginia.
Smith, W. C. (1979) Faith and Belief, Princeton: Princeton University Press.
Stock, G. (1993) Metaman: The Merging of Human and Machines into a Global
Superorganism, New York: Simon & Schuster.
Toffler, B. L. (2003) Final Accounting, New York: Broadway Books.
Vaughan, D. (1996) The Challenger Launch Decision, Chicago: University of Chicago Press.
Vaughan, D. (1999) “The dark side of organizations: Mistake, misconduct, and disaster,”
Annual Review of Sociology, 25: 271–305.
Waldrop, M. M. (1992) Complexity, New York: Simon & Schuster.
Wheatley, M. J. (1992) Leadership and the New Science, San Francisco: Berrett-Koehler.

82

<-----Page 84----->EMERGENCE, 5(3), 83–100
Copyright © 2003, Lawrence Erlbaum Associates, Inc.

Open Source as a Complex
Adaptive System
Moreno Muffatto & Matteo Faldani

T

he concepts of complexity prevalent at various historical
times have influenced the frames of mind with which organizations and the models of social planning and organizational design have been analyzed.
During the Industrial Revolution, the model of organizational design
derived from the conceptual model of the machine. In this model, the
concept of the hierarchical control of functions prevailed. The consequent approach was top-down thinking. Much of the organizational
theory of the twentieth century was based on determinism, reductionism,
and equilibrium as key principles. If an organization is conceived of as a
machine, the control of the organization is obtained through a reduction
in its complexity; that is, in the states of the machine or its variety.
The Information Revolution and the development of networks have
produced phenomena such as the growing connection between elements
that are often extremely different from one another (computers, people,
even smart objects). This has led to phenomena that cannot be planned
according to a top-down logic, but, on the contrary, “emerge” from interactions between elements and therefore “from the bottom.” The
approach most suitable for analyzing these phenomena is bottom-up
thinking.
If in the past the world could be represented as a machine, today it is
represented as a network and increasingly as an ecosystem. The Internet,
for example, can be considered not only as a technological infrastructure
and a social practice, but also as a new way of thinking related to the concepts of freedom of access and diffusion of knowledge. Furthermore, the
83

<-----Page 85----->EMERGENCE
Internet is an organizational model without a center and without absolute
control.
With the development of information networks, the Internet in particular, it has been observed that not all phenomena that are developed
can be designed and planned. In other words, networks involve social
structures that make phenomena, to a certain degree, “emergent.” Therefore, there has been growing interest in an approach that interprets phenomena from the bottom up; that is, from the network of relationships
and the interactions between players.
The growth of the Internet has led to the development of many types
of online communities whose aims vary significantly. Only the creation of
the Open Source community has offered the possibility of developing
something concrete; that is, software products. Software lends itself to
online development since it can be easily transferred via the Internet
itself. The many communities working together to produce Open Source
software offer new stimuli for research in the context of complexity
theory. The complexity of Open Source is due not only to technical
aspects, relative to the complexity of software, but to the social complexity that characterizes the software development process.
In order to better understand this social complexity, some important
studies have been carried out to interpret complex social phenomena
(Axelrod & Cohen, 1999; Kauffman, 1995; McKelvey, 1999; Waldrop,
1992). In this analysis we will make reference to the theory of complex
adaptive systems. A system can be considered complex and adaptive
when the system’s agents have the possibility of continually adapting
their actions in response to the environment and the behavior of the other
agents. Therefore, the agents have the ability to influence and be influenced by other agents. Consequently, the possibility of transferring information from one agent to another is extremely important in complex
systems.
One of the most significant characteristics of complex systems is the
presence of emergence; that is, the emergence of new states in the system
that have new capabilities and offer new evolutionary possibilities. The
very nature of this phenomenon makes it difficult to foresee what the new
states of the system will be, since it is not always possible to extrapolate
the new system properties from the existing system components.
The unpredictability of events and of the results makes understanding
and interpreting a complex system that much more difficult. Nonetheless,
one of the most interesting and significant aspects of the approach to
complex systems is not the search for methods to limit their complexity,
84

<-----Page 86----->VOLUME #5, ISSUE #3
but, on the contrary, the exploitation of the complexity itself (Axelrod &
Cohen, 1999).
The Open Source community and its activities can be considered to
have the characteristics of a complex adaptive system. The Open Source
system is unique because it is neither controlled by a central authority,
which defines strategy and organization, nor totally chaotic. It can be
placed in a middle position between a designed system and a chaotic one
(Lerner & Tirole, 2001). In this position, nonformal rules exist that allow
the system to produce appreciable results.

THE OPEN SOURCE

COMMUNITY

Software has not always been a commercial product. It was originally
considered to be simply a tool for using computer hardware. Only hardware had a commercial value, whereas software was a complementary
product needed to use and diffuse computers. Consequently, software
was produced and distributed freely, just like other products based on
knowledge and scientific research. The development of software was the
fruit of the work of a small community of university researchers who collaborated closely with a few hardware manufacturers. Software was considered, just as academic research is, to be a common good (Di Bona et
al., 1999).
With the widespread diffusion of personal computers, software took
on the characteristics of a commercial product. Since not all personal
computer users had the technical skills to understand, develop, and configure software themselves, they were willing to buy it (Tzouris, 2002;
Weber, 2000).
In 1985, Richard Stallman, a researcher at MIT, established the Free
Software Foundation (FSF) with the aim of rebuilding a community for
the free and independent development of software (Free Software
Foundation, 2002). However, the word “free” was often wrongly interpreted as “free of charge.” Therefore, it became necessary to substitute
the word “free” with another word that described the characteristics of
product accessibility, efficiency, reliability, and flexibility.
In 1998, another group of developers founded the Open Source
Initiative (OSI) with the aim of making the concept of free software
appealing to companies as well (Open Source Initiative, 2002). The term
“free software” was thus substituted with “Open Source.” In order to
avoid further misinterpretations of the new term, an official definition
was drawn up to specify the indispensable characteristics of Open Source
85

<-----Page 87----->EMERGENCE
products. For a product to be considered Open Source, it must respect
a series of rules summarized in the license that accompanies the product’s source code. These rules regard the copying and distribution of
the software, including the source code, and the products derived from
it. Open Source licenses guarantee the freedom to distribute and use
the software, study the source codes, and, if necessary, modify them
according to specific needs. The licenses do not discriminate against
any category of users, group or person, and they do not prohibit the use
of the software in any particular field of application. Furthermore,
according to the Open Source definition, the software developed and
distributed cannot later be resold or appropriated by anyone. Open
Source software is thus associated with the freedom that it concedes
and not with the fact that it is free of charge, as a superficial analysis of
the phenomenon might lead one to believe.
Open Source products are made within a community composed of a
heterogeneous group of players or agents who interact but are driven by
different interests and motivations (Bonnacorsi & Rossi, 2002; Lerner &
Tirole, 2001; Tzouris, 2002; Weber, 2000). Some authors refer to the
Open Source community using the metaphor of a bazaar, since it
expresses the idea of the frenzy and chaos with which the activities in the
community are carried out (Raymond, 1998). The Open Source community can also be seen as an immense “magic cauldron” of ideas to which
volunteers contribute on a continuous basis (Raymond, 1999a). Anyone
can draw from this cauldron to suit their needs without having to contribute money or knowledge.
It seems inconceivable that this type of system is able to continue to
maintain itself. What seems even more improbable is that its apparent
disorganization can produce concrete results. Nonetheless, the products
developed in recent years (e.g., Linux, Apache) have made it possible to
show that organizational criteria actually do exist within this community.
By observing numerous Open Source projects, it is possible to identify the following five categories of agents involved in the community.

USER
This category is made up of all the people who use Open Source products
but do not directly participate in their development because they do not
have the ability, time, and/or resources to do so. Users are of fundamental importance, as they make it possible to carry out the timely and
exhaustive process of observing and testing the product, and thus the
code, which in turn produces feedback for the software developers.
86

<-----Page 88----->VOLUME #5, ISSUE #3

PROSUMER (PRODUCER

AND CONSUMER)

Prosumers are the software developers who actively participate in product development not only to meet their own needs but for the pure pleasure of developing products, and, in most cases, with the hope of
improving their own professional prospects.
This group is the nucleus of Open Source code development. It is
generally made up of people who come from different social classes and
use their free time to work on the development of a code. They might be
students or software developers/professionals with very different cultural
backgrounds and professional needs.

LEADER

TEAMS

This category is made up of software developers and is a sort of élite
group chosen by the community based on merit. This group of people is
given the authority and responsibility for managing development
projects.
A leader team is made up of a tight circle of prosumers who have participated in the definition and production of Open Source products from
the beginning.
Leaders dedicate much of their time to planning, managing, and
checking the product development process and, therefore, often do not
participate in programming. They have the important task of coordinating the development community and are responsible for helping integrate the contributions and feedback from the community. The leader
team is, thus, a point of reference for all of the agents, companies, and
institutions involved and interested in Open Source software.

COMPANIES
This category is made up of the companies that are interested in the
Open Source community and its products. They interact with the Open
Source community by using software and financing, and sometimes participating in, the development of software. Therefore, they either influence the development process and evolution of products or simply
observe the community in order to improve their own organizational
structure and business.

INSTITUTIONS
Institutions are nonprofit organizations and public bodies interested in
using, and thus diffusing, Open Source products. Many public bodies,
above all universities, have created the cultural environment in which
87

<-----Page 89----->EMERGENCE

Figure 1 Structure of an Open Source community
many Open Source products have been developed. Some important
products, such as Linux, were created thanks to the technical, and sometimes financial, support of universities. Recently, public bodies have also
shown interest in the Open Source community and its products by carrying out studies and sometimes promoting the use of Open Source products in their own structures.
The community of agents meets online and creates a dynamic virtual
team; that is, a team characterized by the continuous coming and going of
agents belonging to the various categories mentioned above. A virtual
team is created by agents who contact each other via virtual meetings
such as forums and mailing lists. These meeting points make it possible
to diffuse concepts, ideas, and strategies to the whole community and at
the same time avoid dispersing or slowing down the flow of information
and decisions.
Figure 1 shows the five categories of agents who make up the Open
Source community and the relationships that exist between them.

88

<-----Page 90----->VOLUME #5, ISSUE #3

CHARACTERISTICS

OF THE ORGANIZATION AND
PROCESSES OF OPEN SOURCE

Open Source products are, as has been explained above, the result of the
collaboration, within a virtual community, of independent and heterogeneous players driven by different interests and motivations (Bonaccorsi
& Rossi, 2002; Feller & Fitzgerald, 2002; Lerner & Tirole, 2001; Muffatto
& Faldani, 2003; Tzouris, 2002; Weber, 2000). One might expect such a
community to become an uncontrollable system. In fact, in order to avoid
the generation of negative phenomena, the community has defined its
own rules of behavior and functioning that guarantee quality results, stability, and continuity over time. The main characteristics defining how
the community works deal with the organizational structure and development process (Bonaccorsi & Rossi, 2002; Dafermos, 2001). This analysis
will focus on open participation and bottom-up organization (organizational structure) and the speed of development and parallelism of the
process (development process).
Figure 2 overleaf summarizes these four main characteristics and the
relationships that exist between them. As can be seen from the figure,
open participation leads to both the other characteristic of organization—
that is, bottom-up organization—and the two main characteristics of the
development process—that is, the speed of development and parallel
development.
Open participation generates decentralized decision-making power
and thus the absence of rigid top-down planning. Projects can therefore
be more flexible and have greater freedom to evolve. However, this can
also lead to code forking, which is a situation that occurs when independent development paths of a code fork off in different directions
(Raymond, 1999b). When code forking happens, the community tends to
lose interest in the project. This loss of interest may provoke a gradual yet
unstoppable distancing of software developers from the project, which is
consequently destined to die. The end result could be the implosion of
the community itself.
However, decentralized decision-making power does not mean a total
lack of organization. In fact, in the Open Source community each project
has a team of leaders whose appropriate management of consensus can
limit the negative effects of code forking. The leader team is responsible
for the development process and must answer to the whole community
and all of the users. This small group of agents is also responsible for
guaranteeing the compatibility and integration of the contributions. The
89

<-----Page 91----->EMERGENCE

Figure 2 Characteristics of the organization and development process of
the Open Source community
power of the leader team does not come from a privileged position or
from property rights; rather, the position they occupy is legitimized by
the development community itself. Their power is recognized according
to the credibility and trust the community places in them. This credibility allows the leaders to exercise the power of dissuasion when there are
actions that could lead to code forking.
Another positive effect of open participation is the possibility it offers
to explore different alternatives and keep strategies flexible. However,
flexibility makes it difficult to define precise deadlines for development.
This uncertainty could lead to a lack of incentives for software developers and limit their commitment to a project, which could, in turn, slow
90

<-----Page 92----->VOLUME #5, ISSUE #3
down the development process. However, the software developers try to
avoid these problems by producing many frequent releases of the code in
order to motivate themselves and others to contribute actively
(Jørgensen, 2001).
The speed of development and frequency of releases create a continuous evolution of the products. At the same time, the codes are relatively
instable due to their incessant evolution, making it difficult for users to
use the products. Even though on the one hand continuous modifications
and new releases help keep the products technologically advanced and
innovative, on the other hand this could discourage their being used.
Innovation does not always guarantee product reliability and stability; at
least not until products have undergone sufficient checks, trials, and
modifications. In other words, users are not willing or inclined to use
recent versions of a product whose quality the community is still not able
to guarantee.
In order to reach a satisfactory compromise between the exploration
of new solutions and the exploitation of existing ones, a project’s development process is usually split into two development paths. The first one,
called the stable path, is made up of products that have been proved to be
stable and whose compatibility over time with future versions of the same
products has been guaranteed. The second one, called the development
path, is made up of the most recent versions of products that have not
been sufficiently checked and tested, and are therefore still merely the
fruit of research and innovation. The subdivision of development into two
paths, product exploitation and exploration, makes it possible to improve
the distribution of responsibilities and the organization of activities, while
maintaining a relatively fast speed of development and high degree of
innovation.
The last effect of open participation is the parallel development of
projects. When there are many different possible solutions, it is not
always easy immediately to identify the best one. Parallelism allows many
different players to explore different alternatives contemporaneously
without forcing them to follow one particular evolutionary path. However, a disadvantage of parallelism is that any overlap and/or interference
between the various contributions could lead to incompatability, thus
making it difficult to manage development projects.
When software is produced in the traditional way, excessive parallelism is considered to be a waste of resources and a factor that increases
the complexity of the development process. Brooks’ Law states that as the
number of software developers increases, there is a proportional increase
91

<-----Page 93----->EMERGENCE
in the amount of code produced, but also an increase in the complexity of
the project proportional to the square of the number of software developers (Brooks, 1975). This complexity leads to higher communication and
management costs and a greater probability of making errors. In order to
avoid these problems, the Open Source model suggests subdividing relatively large products into more simple modules. In this way, resources
are used more efficiently and any interferences between single contributions are more easily solved.
The leader team is responsible for the modularity of Open Source
products. The leaders plan products and the interface protocols to be
used for communication between the various modules. Modularity also
means that additions, modifications, and imperfections present in one
module do not have negative effects on the whole code, but rather are
limited to that one module.
We will now interpret these characteristics of the Open Source community in the context of complex adaptive systems theory, but before
doing so will briefly define some key aspects of this theory.

COMPLEX

ADAPTIVE SYSTEMS

A system is made up of a heterogenous group of interrelated elements.
Some of these elements can be defined as agents. Agents can interact
with each other and with their environment. Each agent has its own strategy. A strategy is the way in which an agent pursues its own goals, interacts with the other agents, and reacts to stimuli from the environment.
Strategies are selected using certain measures of success (Axelrod, 1984;
Axelrod & Cohen, 1999). An efficient strategy tends to be followed by
many agents. This leads to a population of agents; that is, a group of agents
that imitate one another’s way of acting. The evolution of a system heads
in a given direction according to the strategy identified by its population
of agents.
A system is said to be complex and adaptive when the agents have the
possibility of continually adapting their actions in response to the environment and the behavior of the other agents. For this reason, the possibility of transferring information from one agent to another, which
depends on connectivity, is particularly important in complex systems.
The high level of connectivity that characterizes complex adaptive systems
allows for the creation of a dynamic network of agents that are constantly
communicating and interacting (Coleman, 1999; Kelly, 1994; Lissack,
1999; McKelvey, 1999; McKelvey & Maguire, 1999; Waldrop, 1992).
92

<-----Page 94----->VOLUME #5, ISSUE #3
The interaction between the agents leads the system to take on some
emergent properties that characterize the system but are not present in
any single agent. The word “emergent” means that the properties of a system “emerge” from the interaction between agents and are not dictated
by a central authority. The emergent properties can lead a system toward
new evolutions that cannot be foreseen. Therefore, a structured and predefined organizational control system cannot work. Nonetheless, the fact
that the evolution of a complex system is difficult to foresee does not
mean that there is no organization. In fact, a complex adaptive system is
characterized by self-organization.
Three fundamental processes can be identified in complex adaptive
systems: variation, interaction, and selection (Axelrod & Cohen, 1999).

VARIATION
In any system, at any time, it is possible to find a certain degree of variety, which is defined as the set of differences and alternatives that characterize both the agents and their strategies. Variety is the result of a
process of variation; that is, changes in the set of alternatives. Variation
determines the number of possible alternatives in a system.

INTERACTION
Interaction is defined by the ties that exist between agents and the ways
in which the agents and their strategies influence each other. Interactions
are neither random nor completely predictable. The quantity and quality
of the interactions determine the dynamics of the system.

SELECTION
Selection is the process of choosing and diffusing or eliminating properties that characterize agents and their strategies. Therefore, it deals with
the ability a system has developed to identify which agents and strategies
are to be chosen and thus diffused, and which, on the other hand, are to
be eliminated. Consequently, selection determines the evolution of a
system.
All of these characteristics of complex adaptive systems can be found
in the Open Source community.

OPEN SOURCE

AS A COMPLEX ADAPTIVE SYSTEM

The Open Source community can be considered an example of a complex
adaptive system. It is made up of a population of heterogenous players,
93

<-----Page 95----->EMERGENCE
each having its own role and self-defined strategies (Axelrod & Cohen,
1999; Kuwabara, 2000). In the Open Source community, the various roles
are not rigidly assigned by a higher authority; on the contrary, each player
has the freedom to act and interact with the other players in the system.
Therefore, the players in the Open Source community have the characteristics to be defined as agents. They can influence the system by interacting with the rest of the community and are able to use their experience
and memory to model their behavior in the present.
The definition of agent proposed by complex adaptive systems theory
makes it possible to include users in this category as well. In fact, users
can stimulate the system—that is, the community—through explicit and
implicit feedback. Users are an integral part of the Open Source system
since they participate in the processes of variation, interaction, and selection and, by doing so, can influence the evolution of the system.
According to Axelrod and Cohen, the concept of complex adaptive
systems can be most easily related to problems that are long term or diffused, require continuous innovation, need a great deal of feedback in a
short period of time, or have a low risk of catastrophe. All of these characteristics can be found in Open Source products.
Long-term or diffused applications offer many opportunities for
agents to come together. This leads to a critical mass that can activate significant processes of variation and interaction. In the case of software,
examples of this type of application are operating systems, network platforms, web servers, programming languages, and all of the components
and protocols that have created the standards of the Internet. Some Open
Source products are part of this category of long-term applications. They
are usually platforms or common standards; for example, Linux, Apache,
and PHP.
In the case of applications that require continuous innovation—that
is, those in particularly dynamic industries—there is a signifcant need to
explore new solutions. This is the case for software applications related to
the Internet, such as web servers, protocols, browsers, and so on. Since
Open Source products are technologically advanced and innovative, they
stimulate the creativity of the community and the continuous exploration
of alternatives.
As far as applications that require a great deal of feedback over a short
period of time are concerned, significant advantages can be gained from
the interaction between the agents in a development community. In the
Open Source community, the users are considered to be the main source
of inspiration for and evaluation of the quality of the products. The fact
94

<-----Page 96----->VOLUME #5, ISSUE #3
that products are available at a low cost makes it possible to obtain a significant quantity of information and to have the software undergo an
extensive process of observation and checking based on daily use. The
fact that the code is open and available to all makes it easier to carry out
better measurements of product performance. This in turn gives agents a
precise series of parameters that they can use to evaluate product performance objectively and, consequently, base their choices on.
Applications with a low risk of catastrophe are those for which the
efforts committed to exploring alternatives should not put the survival of
the entire system at risk. A system that manages to do this is dynamic and
at the same time stable and, therefore, not at risk of implosion. The modular structure of Open Source products limits the effects that each activity can have on the entire product and makes it possible to avoid the
diffusion of any imperfections. Furthermore, the failure of one or more
exploratory actions does not lead to the failure of the entire system, which
nevertheless continues to survive since there are other players involved
in the development process. In fact, in Open Source nobody has total
control over or responsibility for products and each activity is usually
shared by a group of autonomous agents. Should any agent decide to stop
carrying out its activities, it can easily and quickly be substituted regardless of the position that it occupied.
Axelrod and Cohen consider Open Source mainly as an example of the
variation mechanism, since it very much exploits the advantages gained
from conserving diversity within a system. One of the main dangers for a
complex system is the extinction of a type of agent or strategy that reduces
a system’s diversity. Since the creation of a type requires resources and
effort, its premature extinction should be avoided. A type that is not very
successful in the present might have characteristics that could prove to be
very important in the future. The Open Source community manages to
conserve diversity by keeping track of the whole evolutionary process in
order to be able easily to find anything that might be needed.
It is also possible to identify the interaction and selection mechanisms
in the Open Source community. Above all, it is possible to understand
how the close relationship that exists between these mechanisms allows
the Open Source community efficiently and effectively to exploit its own
complexity.
Axelrod and Cohen identify a sequence in the mechanisms of variation, interaction, and selection. They consider variation to be a premise
for the activation of different forms of interaction, which, in turn, produce
effects of selection within a system. However, it is possible to hypothesize
95

<-----Page 97----->EMERGENCE

Figure 3 Characteristics of a complex adaptive system in the Open
Source community
that there are other sequences of variation, interaction, and selection in
the characteristics of the Open Source organization and development
process mentioned above; that is, open participation, bottom-up organization, speed of development, and parallel development. The benefit of
each characteristic can be interpreted as one of the mechanisms, but it is
also possible to identify a negative effect, which can be interpreted as
another mechanism, and the actions taken to solve the problem can be
interpreted as the remaining mechanism (Figure 3).
96

<-----Page 98----->VOLUME #5, ISSUE #3
The advantage of open participation—that is, the free exploration of
alternatives and flexibility of strategies—can be interpreted in terms of
variation. In the Open Source community, however, agents tend to work
on development for long periods of time without making their solutions
available. In this way, they do not stimulate the other agents in the community. This can be interpreted as a phenomenon of premature and
highly subjective selection. In other words, this selection remains within
the subjective evaluation of individual agents and does not benefit from
the contribution of many different agents in terms of peer review.
Furthermore, the agents are not solicited enough to offer new contributions to the development process. The result of this excess is that the
exploration process slows down, limiting the variety in the system. One
solution to this problem is to increase the frequency with which software
is released. Basically, the community makes a release each time there is a
new feature, even if it is relatively insignificant, in order to motivate and
involve the agents in the community. This action, seen from the point of
view of complexity theory, has the effect of increasing the interaction
between agents.
Another characteristic of the organizational structure of the Open
Source community is decentralized decision-making power; that is, the
implementation of a bottom-up organization. As has often been noted, the
advantage of decentralized power is an increase in the flow of information
within an organization. If the organization of the Open Source community is interpreted as a complex system, this effect can be interpreted as
an increase in the possibilities for interaction between the agents in the
system. This increase in horizontal interaction can, however, lead to a
negative effect, code forking. Code forking can be interpreted as a negative aspect of variation that can damage the development of Open Source
projects. The solution, in this case, is to create elements of organizational
structure in the Open Source community as well; that is, leader teams.
The leaders’ efforts to maintain consensus help the community not to lose
its connectivity, as is the case with code forking where agents work on the
same objects without exploiting the positive effects of interaction. In this
way, leaders carry out selection by deciding what direction product evolution will take.
As we have seen, the Open Source development process is characterized by frequent releases in order to motivate the community to participate. The advantage of frequent releases is the continuous evolution of
the products; that is, their dynamic variation, which leads to significant
variation in the system itself. Nonetheless, if new versions of a product
97

<-----Page 99----->EMERGENCE
are released too rapidly, there could be an excess of exploration, to the
disadvantage of the exploitation of the results already obtained. This
effect could lead to a lack of focus and scarce and ineffective interaction
between agents. The Open Source community attempts to avoid this
problem by separating the development process into a dual path. In the
stable path, which corresponds to the exploitation of results already
obtained, variation is very slow. In the development path, which corresponds to the exploration of new alternatives, there is a great deal of variation in the system. The two different development paths are managed
through a process of selection, in which contributions must be separated
into two groups: on the stable path there are those that only need to be
consolidated, while on the development path there are those that need to
be developed further.
Finally, there is the parallel development of products. The advantage
of this is the possibility of exploring a greater number of different alternatives at the same time. In other words, parallelism has the positive
effect of variation regarding both the type of agents involved in the system and the strategies they pursue. Nonetheless, the parallel development of one product can also lead to excessive complexity and even
incompatibility between components and alternative product solutions.
In fact, one single modification can have a significant impact on other
parts of the product and the effect of the impact is unpredictable. This
could be seen as a negative effect of the interaction between the elements
in the system. The solution to the possible negative consequences is parallel development organized according to modular product planning. A
precise definition of the modularity forces agents to make a selection of
the objects on which they want to work, and at the same time limits possible interference with the activities of other agents.
In conclusion, in each of the functioning characteristics of the Open
Source community it is possible to highlight the three fundamental mechanisms of complex adaptive systems. Whereas in the variation–interaction–selection sequence all the mechanisms have positive effects on the
system, we have considered the possibility of other sequences characterized by the presence of a mechanism having negative effects on the system. Finally, we have shown that the solution to the problems caused by
the negative effects of one of the mechanisms can be interpreted as the
effect of another one.

98

<-----Page 100----->VOLUME #5, ISSUE #3

IMPLICATIONS
The observations made in this article can lead us to reflect on how the
interpretation of the phenomena analyzed here can be extended within
this context as well as to other contexts. Similar contexts could be those
dealing with knowledge products whose characteristics are similar to
those of software. This analysis could therefore also be extended to
involve the processes of scientific research in general, and those of
highly innovative fields such as bioinformatics or pharmaceutical
research in particular. Furthermore, since Open Source tends to diffuse
and impose itself as a standard, it would be worthwhile studying the
problem of strategies for setting and diffusing technological standards.
Finally, since the concept of complexity can be used to interpret social
characteristics as well, the complex adaptive systems theory would certainly be suitable for interpreting networks and clusters. Given the flexibility of the complex adaptive systems theory, it would certainly be
worth dedicating significant analysis to the applicability of this theory to
various contexts.

REFERENCES
Axelrod, R. (1984) The Evolution of Cooperation, New York: Basic Books.
Axelrod, R. & Cohen, M. D. (1999) Harnessing Complexity: Organizational Implications of
a Scientific Frontier, New York: Free Press.
Bonaccorsi, A. & Rossi, C. (2002) Why Open Source Software Can Succeed, Pisa, Italy:
Laboratory of Economy and Management, Sant’Anna School of Advanced Study.
Brooks, F. (1975) The Mythical Man Month: Essays on Software Engineering, London:
Addison Wesley.
Coleman, J. H., Jr. (1999) “What enables self-organizing behavior in businesses,”
Emergence, 1(1): 33–48.
Dafermos, G. N. (2001) “Management and virtual decentralised networks: The Linux project,” First Monday, 6(11).
Di Bona, C., Ockman, S., & Stone, M. (1999) Opensources: Voices from the Opensource
Revolution, Sebastopol, CA: O’Reilly & Associates.
Feller, J. & Fitzgerald, B. (2002) Understanding Opensource Software Development,
London: Addison Wesley.
Free Software Foundation (2002), February, http://www.fsf.org.
Jørgensen, N. (2001) “Putting it all in the trunk: Incremental software development in the
FreeBSD open source project,” Information Systems Journal, 11: 321–36.
Kauffman, S. A. (1995) At Home in the Universe: The Search for Laws of Self-Organization
and Complexity, Oxford, UK: Oxford University Press.
Kelly, K. (1994) Out of Control: The New Biology of Machines, Social Systems, and the
Economic World, Reading, MA: Addison Wesley.
Kuwabara, K. (2000) “Linux: A bazaar at the edge of chaos,” First Monday, 5(3).
Lerner, J. & Tirole, J. (2001) “Some simple economics of Open Source,” Journal of Industrial
Economics, 50: 197–234.

99

<-----Page 101----->EMERGENCE
Lissack, M. R. (1999) “Complexity: The science, its vocabulary, and its relation to organizations,” Emergence, 1(1): 110–26.
McKelvey, B. (1999) “Complexity theory in organization science: Seizing the promise or
becoming a fad?,” Emergence, 1(1): 5–32.
McKelvey, B. & Maguire, S. (1999) “Complexity and management: Moving from fad to firm
foundations,” Emergence, 1(2): 5–49.
Muffatto, M. & Faldani M. (2003) “Realtà e prospettive dell’Open Source,’” Economia &
Management, 3.
Open Source Initiative (2002), 24 February, http://www.opensource.org.
Raymond, E. S. (1998) “The cathedral and the bazaar,” First Monday, 3(3).
Raymond, E. S. (1999a) “The magic cauldron,” http://www.catb.org/~esr/writings/magiccauldron/magic-cauldron.html.
Raymond, E. S. (1999b) The Cathedral and the Bazaar: Musings on Linux and Open Source
by an Accidental Revolutionary, Peking/Cambridge, MA/Farnham, UK: O’Reilly &
Associates.
Tzouris, M. (2002) Software Freedom, Open Software and the Participant’s Motivation: A
Multidisciplinary Study, London: London School of Economics and Political Science.
Waldrop, M. M. (1992) Complexity: The Emerging Science at the Edge of Order and Chaos,
New York: Simon & Schuster.
Weber, S. (2000) “The political economy of Open Source software,” BRIE working paper
140, Berkeley, CA: E-conomy Project.

100

<-----Page 102----->About the Authors
Min Basadur is a leading world expert in the implementation of innovative thinking processes for tangible business results, the founder of the Basadur Applied
Creativity Center for Research, and Professor of Organizational Behavior at
McMaster University. Dr. Basadur consults internationally with many large and
small organizations including PepsiCo, Kimball International, Stelco, Magna,
Goodrich, Frito Lay, and Procter & Gamble. Dr. Basadur’s extensive publications
include two books, The Power of Innovation and Simplex: A Flight to Creativity,
numerous scientific journal articles, training manuals, and creativity and innovation assessment instruments like the Basadur Creative Problem Solving Profile
Inventory and Ideation-Evaluation Preference Scale. He also makes keynote
speeches and presentations worldwide.
David Bella is Emeritus Professor of Civil Engineering. He received his BS from
the Virginia Military Institute in 1961, and MS and PhD from New York University in 1967 in Environmental Engineering. His research involved computer simulation of ecosystems and the assessment of technological consequences. In recent
decades, his research has shifted to the study of complex human systems. Publications in addition to those listed in the references include “Plug and chug, cram and
flush,” Journal of Professional Issues in Engineering Education and Practice,
2003; “Salmon and complexity: Challenges to assessment,” Human and Ecological
Risk Assessment, 2002; and “Strategic defense: Catastrophic loss of control,”
Journal of Peace Research, 1989.
Matteo Faldani is a PhD student at the University of Padua. His research interests
are in the field of software product development and Open Source software in particular. He is currently working on a study on the adoption of Open Source software by private companies and public administrations.
Garry Gelade is a cognitive and organizational psychologist, and a consultant to
business in corporate creativity and statistical analysis. He is a charter member of
the British Psychological Society and an Associate of the Basadur Applied Creativity
Center, Ontario, Canada. Following a corporate career that included management
positions in American Express, Mercantile Credit, and Lloyds Bank, Dr. Gelade
formed his own consulting practice in 1990. He specializes in the application of creative thinking and statistical modeling in management and business, and has been a
residential school tutor on the Creativity, Innovation and Change module of the UK’s
Open University MBA course. He continues to conduct research and to publish scientific papers and articles on cognition, creativity, and organizational psychology.

101

<-----Page 103----->EMERGENCE
David Kailin is a professional medical futurist (http://www.convergentmedical.com),
consulting with organizations interested in developing preferable health care
futures. He received a Master of Public Health degree from the University of
Washington and a PhD in Public Health from Oregon State University. His academic interests involve social systems science and the development of human
sciences. Publications include “Evaluating organizational readiness for integrative
medicine” and “Clinical perspectives in risk management,” in Integrating
Complementary Medicine into Health Systems, 2001; and Acupuncture Risk
Management, 1997.
Jonathan King is Associate Professor of Management, College of Business, Oregon
State University. He received a PhD in Business, Government, and Society and an
MBA from the University of Washington and a BA in Philosophy from Antioch
College. His primary research interests are in moral philosophy and systems
theory. Noteworthy publications include “Taking stories seriously: Emotional and
moral intelligences,” Teaching Business Ethics, 2001 (with J. Down); “The systemic distortion of information: An ongoing challenge to management,”
Organizational Dynamics, 1996 (with E. W. Larson); “Learning to solve the right
problems: The case of nuclear power in America,” Journal of Business Ethics,
1993; and “Common knowledge of the second kind,” Journal of Business Ethics,
1989 (with D. A. Bella).
Michael R. Lissack is director of the Institute for the Study of Coherence and
Emergence as well as the editor-in-chief of Emergence. He is chairman and CEO
of Knowledge Ventures Inc. His research focuses on the use of complexity theorybased metaphors and models in the management of knowledge-related businesses
such as the Internet. Dr. Lissack received his doctorate in business administration
from Henley Management College in the UK and is a graduate of Williams College
and the Yale School of Management. He has taught economics as a lecturer at
Williams, research techniques at Henley, business strategy at IMD, and business
ethics at the Rotterdam School of Management.
Ann E. Mills has written on the health care delivery system and, along with Mary
Rorty and Patricia Werhane, is the co-author of two books on health care organization ethics. She is on the editorial advisory board for the journal Organization
Intersections, launched in the spring of 2003. She is an Assistant Professor in
Medical Education and member of the Core Faculty at the Center for Biomedical
Ethics at the University of Virginia. Ms. Mills teaches System Ethics in the Medical
School of the University of Virginia. Her research focuses on the intersection of
clinical, business, professional, and research ethics in health care delivery organizations. She has a BA from Sarah Lawrence College, a Master’s in economics from
the London School of Economics, and an MBA from James Madison University.

102

<-----Page 104----->VOLUME #5, ISSUE #3
Moreno Muffatto is Professor of Business Administration and Management, University of Padua, Italy. His main research interests concern the management of
innovation and new product development, operations management and logistics,
and the impact of new information and communication technologies on organizations. He is a research affiliate of the International Motor Vehicle Program at MIT,
associate editor of the International Journal of Product Development, and European editor of the International Journal of Entrepreneurship and Innovation
Management, as well as being a member of the editorial advisory boards of the
International Journal of Logistics: Research and Application and the International
Journal of Process Management and Benchmarking. Professor Muffatto has been
co-chairman of the International Symposium on Logistics since 1997 and is author
(with Matteo Faldani) of the forthcoming book (in Italian), Open Source: Strategy,
Organization, Perspectives. Web page www.morenomuffatto.org.
Mary V. Rorty is a Batten Fellow at the Darden Graduate School of Business and
Clinical Associate Professor at the Stanford University Medical Center. She has
written on reproductive rights, women’s health, and the health care delivery system, and has taught philosophy, women’s studies, and health care ethics. She was
director of graduate studies at the University of Virginia Center for Biomedical
Ethics from 1994 to 1998. She has a PhD in philosophy from Johns Hopkins
University and a MA in Clinical Ethics from the University of Virginia.
Patricia Werhane is the Peter and Adeline Ruffin Professor of Business Ethics and
a Senior Fellow at the Olsson Center for Applied Ethics at the Darden School,
University of Virginia. She is the author or editor of 15 books, including Ethical
Issues in Business (with Thomas Donaldson), now in its sixth edition; Adam Smith
and his Legacy for Modern Capitalism; Organization Ethics for Health Care (with
E. Spencer, A. Mills, & M. Rorty); and Moral Imagination and Management
Decision-Making. She is the founding editor of Business Ethics Quarterly. Her
latest book is Employment and Employee Rights with Blackwell’s. She has a BA
from Wellesley College and an MA and PhD from Northwestern University.

103

<-----Page 105----->SUBMISSION

INFORMATION

Emergence is interested in receiving work from a wide range of perspectives: theoretical
and practitioner based; both conventional and unconventional methodologies; case study
work; approaches to teaching management or leadership; work covering a variety of organizational types, size and ownership; cross-cultural studies and work from Australasia and
the Far East as well as the USA and Europe.
We ask that authors set their paper clearly within the context of the notion of complexity and complex systems, however they chose to define such, and that the practical implications and transferable lessons from their work be clearly described.
Note that quantitative studies (including those that focus on survey results and related
statistics) are not suitable for Emergence. Authors are limited to one mathematical formula
per paper (additional formulae may appear in the technical appendix). If you wish to submit work of a quantitative nature, please represent it qualitatively. Figures and tables should
be illustrative. Quantitative and statistically based submissions will be returned without
review.
Each article in Emergence will be accompanied by space on the Emergence website for
additional materials and discussion forums.
Format
All submissions are electronic. Suggested length is 4000 to 5000 words. Review pieces and
essays should be 2000 to 3000 words. Note: additional material considered relevant and/or
related by the author(s) can be posted on the website, which will be associated with each
accepted article. The author(s) will be responsible for securing all necessary permissions for
material to be posted on the website.
All submissions must be in either MS Word (6.0 or later) or Corel Wordperfect (6.0
or later). All manuscripts should be formatted as typed, 11 or 12 pitch, double spaced
(including references) on 8 1/2 by 11 inch white paper with margins of at least 1 inch on
all four sides; or if on A4 paper, with appropriately adjusted margins, as all origination for
printing will be done in the USA.
There is detailed information on the format for submissions on the website,
www.emergence.org.
Submissions should be sent to: editor@emergence.org with one hard copy to:
Michael Lissack, Editor, Emergence, 2338 Immokalee Road #292, Naples FL 341101445, USA.
Phone 941-254-9648. Fax 617-249-0663
Acceptance Procedure
The Editor will review all submissions for suitability. Manuscripts deemed suitable are
reviewed independently by members of the editorial review board, and their recommendations guide the Editor in his acceptance decision. The reviews are double blind—neither
authors nor reviewers know the identity of each other.
All reviewing for Emergence is done electronically. Authors will be updated via email.

All in-text references underlined in blue are linked to publications on ResearchGate, letting you access and re

