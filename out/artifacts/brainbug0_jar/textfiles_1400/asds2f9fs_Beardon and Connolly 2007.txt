<-----Page 0----->Organizational Behavior and Human Decision Processes 103 (2007) 147–158
www.elsevier.com/locate/obhdp

Multi-attribute sequential search
J. Neil Bearden *, Terry Connolly
University of Arizona, Department of Management and Organizations, 405 McClelland Hall, Tucson, AZ 85721, USA
Received 3 February 2005
Available online 23 March 2007

Abstract
This article describes empirical and theoretical results from two multi-attribute sequential search tasks. In both tasks, the DM
sequentially encounters options described by two attributes and must pay to learn the values of the attributes. In the continuous
version of the task the DM learns the precise numerical value of an attribute when she pays to view it. In the threshold version
the DM learns only whether the value of an attribute is above or below a threshold that she sets herself. Results from the continuous
condition reveal that DMs tended to terminate their searches too early relative to the optimal policy. The pattern reversed in the
threshold condition: DMs searched for too long. Maximum likelihood comparisons of two diﬀerent stochastic decision models
showed that DMs under both information conditions performed in ways consistent with the optimal policies. Those oﬀered continuous-valued attribute information did not, however, spontaneously degrade this information into binary (acceptable/unacceptable)
form, despite the theoretical ﬁnding that satisﬁcing can be a very eﬀective and eﬃcient search strategy.
Ó 2006 Elsevier Inc. All rights reserved.
Keywords: Optimal stopping; Sequential search; Satisﬁcing

Decision makers (DMs) must frequently choose
among options that they encounter sequentially, and
whose values are initially revealed only imperfectly.
The DM may, at some cost of time, eﬀort or money,
reduce her uncertainty about the value of an encountered option (e.g., by paying for expert advice, or by
simply spending more time evaluating the option).
Alternatively, she may go on to the next option. Hence,
she must continuously decide when to stop searching
within an option—to get a better estimate of its
value—and when to stop searching between options—
to ﬁnd one of high value. Striking a balance between
depth (within-option) and breadth (between-option)
search presents a complex problem. Should one interview the current applicant in more detail, or go on to
the next candidate? Should one pay for a detailed
inspection of a house that one is interested in or go on

*

Corresponding author. Fax: +1 520 325 4171.
E-mail address: jneilb@gmail.com (J.N. Bearden).

0749-5978/$ - see front matter Ó 2006 Elsevier Inc. All rights reserved.
doi:10.1016/j.obhdp.2006.10.006

to the next possibility? Miller and Todd (1998) present
an example in the context of mate selection. Depending
on the speciﬁc features of the search problem (e.g., how
many options are available, how costly search is, etc.),
the economically rational search policy for this type of
problem may be cognitively very demanding.
Herbert Simon (1955) proposed a behavioral model
of sequential search for problems of this sort, introducing his now-famous notion of ‘‘satisﬁcing’’. Simon proposed that real DMs have cognitive limitations that
compel them to pursue only ‘‘bounded’’, not global
rationality. They do not attempt to maximize the expected value of the options they select. Instead, they search
for options that are good enough or that satisﬁce. Suppose an option X is represented by a vector of k attributes X=(x1, . . . , xk) and that the value of the ith
attribute is xi. Under Simon’s formulation of satisﬁcing,
the DM sets an aspiration level or cut-oﬀ value, bi, for
each attribute. Then, when the options are encountered
sequentially, the DM selects the ﬁrst X for which xi P bi
for all i, i.e., the ﬁrst option that satisﬁces. Simon

<-----Page 1----->148

J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

postulated that the aspiration levels might be dynamic,
being aﬀected by the DM’s experience in the search process and by the length of the search horizon (the number
of options available for the DM to search). Hence, the
aspiration levels can be denoted in a more general form
by bin, where n denotes the position of the option in the
sequence. For example, a house seller may be prepared
to accept a lower price for his old house as the date
on which he must begin paying the mortgage on a new
house gets closer.
Satisﬁcing is often discussed as if it represented a single decision strategy. It does not. Satisﬁcing refers to a
class of decision strategies, whose performance is critically shaped by the aspiration levels the DM sets for
each attribute. If they are all set very low, poor options
encountered early in the sequence are likely to be selected.
If they are all set very high, excessive search costs
will be incurred as the DM sifts through a long, perhaps
endless, list of options. Relative importance of diﬀerent
attributes can be reﬂected in the relative severity or laxness of the cut-oﬀs; and, as noted, cut-oﬀs can be adjusted
over time as experience accumulates and option (or
DM) exhaustion threatens. For a given problem and
preference function, then, some satisﬁcing strategies
are better than others. (See also Baumol, 2004.) We have
used the term ‘‘optimal satisﬁcing’’ to refer to the satisﬁcing strategy that oﬀers the highest expected payoﬀ for
a given task and preference function. Lim, Bearden, and
Smith (2006) present structural proofs for optimal policies for the class of multi-attribute optional stopping
problems considered here. Bearden and Connolly
(2006) describe numerical methods for computing optimal search policies for satisﬁcing search policies.
Satisﬁcing is not the only strategy that allows DMs to
achieve some measure of success in complex decision
problems despite limited computational abilities. The
best-developed program of research on the alternative
forms of bounded rationality is that associated with
Gerd Gigerenzer and his colleagues under the rubric of
‘‘fast and frugal heuristics’’ (Gigerenzer, 2004; Gigerenzer & Todd, 1999; Goldstein & Gigerenzer, 2002;
Hertwig & Todd, 2003; Todd, 2001). This program grew
from a rejection of the ‘‘heuristics and biases’’ research
program associated with Daniel Kahneman and Amos
Tversky (Kahneman, Slovic, & Tversky, 1982). Gigerenzer and colleagues reject that program’s reliance on optimal models, preferring instead to start by specifying
what they judge to be psychologically plausible sets of
simple rules by which real humans might approach complex problems and then testing these rules as models of
actual task performance. A variety of such models has
now been proposed and tested, yielding important
insights into the behavior of DMs in complex settings.
The advantages and disadvantages of the two
research strategies are complex and hotly debated (see,
for example, Gigerenzer, 2004) and we will not attempt

a summary here. Our own view is that the two
approaches oﬀer complementary advantages, and both
have a role to play. In the present paper we ﬁrst review
previous research on sequential search and present a
speciﬁcation of a new and challenging task structure of
substantial real-world signiﬁcance: multi-attribute
optional stopping problems. In multi-attribute optional
stopping problems, DMs must choose among multi-attribute alternatives that are encountered sequentially.
The problems capture features of many practical problems such as hiring decisions, technology adoption decisions, and purchasing decisions. In all cases, the
alternatives can diﬀer from one another along a number
of attributes (e.g., in the hiring case, applicants can diﬀer
in work experience, technical skills, and various assessment measures), and the DM must consider trade-oﬀs
among these attributes when making a selection
decision.
After formally describing the general problem, we
present optimal (expected payoﬀ maximizing) strategies
for two diﬀerent versions, one in which numerical attribute values are available, the other in which the DM
learns only whether or not each attribute exceeds a speciﬁed cut-oﬀ value. We then describe an experiment
examining search behavior in the new problems and
present the results. The ﬁnal section outlines directions
for future research and discusses how our ﬁndings speak
to the notions of satisﬁcing put forward by Simon.

Previous research on sequential search
Optional stopping problems
In a standard optional stopping task, a DM sees a
series of single-valued options one at a time and must
simply decide when to stop the search and accept an
option. In most versions of the problem there is a ﬁxed
search cost c for viewing the value of each option. The
payoﬀ to the DM for selecting the nth option, whose
value we denote xn, is typically given by a function
of the form f(x1, . . . , xn)  nc. When the DM cannot
return to previously encountered options, the search
problem is said to be with no recall and
f(x1, . . . , xn) = xn; the payoﬀ is the value of the last
option examined, net of search costs. When recall is
allowed f(x1, . . . , xn) = max{x1, . . . , xn}; the payoﬀ is
the value of the best of the options examined, net of
search costs. Optimal policies have been derived for a
variety of these problems (e.g., Chow, Robbins, &
Siegmund, 1971).
These problems have also been studied experimentally
(e.g., Cox & Oaxaca, 1989; Hey, 1981, 1982, 1987;
Kogut, 1990; Rapoport & Tversky, 1966, 1970). Variations on the standard task have included making the distribution of xn unknown to the DM (e.g, Cox & Oaxaca,

<-----Page 2----->J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

1989) and making the distribution of xn depend on n—
i.e., making the distribution non-stationary, as in rising
or falling sequences (Brickman, 1972; Shapira & Venezia, 1981). In many instances, the optimal search model
has provided a reasonably good account of the behavioral results (see, e.g., Cox & Oaxaca, 1989; Rapoport
& Tversky, 1970), though there is general a tendency
for the DMs to terminate their searches too early.
All of these experimental studies have looked at
optional stopping when the options are described by a
single value—either the actual value of the option or
the rank of the option on this single value. (This latter
case corresponds to the well-known Secretary Problem,
see, e.g., Bearden, Murphy, & Rapoport, 2005; Bearden,
Rapoport, & Murphy, 2006; Corbin, Olson, & Abbondanza, 1975; Dudey & Todd, 2002; Seale & Rapoport,
1997, 2000; Zwick, Rapoport, Lo, & Muthukrishnan,
2003.) More generally, however, in natural (‘‘realworld’’) problems, the options through which a DM
searches are composed of several values or attributes,
some of which may be known to the DM and some of
which may be unknown. The unknown attributes are
often costly to observe. Experimental studies of information-purchase tasks (e.g., Connolly, 1988; Connolly
& Gilani, 1982; Connolly & Wholey, 1988; Edwards,
1965) indicate that striking a balance between the cost
of information and its decisional value is often quite difﬁcult, even in relatively simple versions of these tasks. A
related literature examines speciﬁcally the rules that
DM’s use to terminate search (e.g., Saad & Russo,
1996). Browne and Pitts (2004) distinguish stopping
rules that apply to the design (option generating) and
choice (option selection) phases of decision making.
Newell, Weston, and Shanks (2003) found that the ‘‘take
the best’’ (TTB) heuristic proposed by Gigerenzer and
Goldstein (1996) was frequently violated in a sequential
depth-of-search task, primarily by participants continuing to purchase attribute information after the TTB
stopping rule would have required them to stop.
In general the experimental evidence suggests that
both depth-of-search and breadth-of-search problems
are cognitively quite demanding. Combining the two,
as in the optional stopping tasks considered here, is thus
likely to present the DM with signiﬁcant diﬃculties. In
the problems described in the following section we will
therefore restrict ourselves to options described by just
two attributes.

149

learn about the values of the attributes. The two problems diﬀer only in terms of the information revealed to
the DM about the values of the attributes. In the ﬁrst
problem the DM learns the actual numerical value of
the attribute; in the second, she only learns whether or
not the value of the attribute is above a threshold which
she determines herself.
The multi-attribute sequential search problem (MASSP)
Let X n ¼ ðxn1 ; xn2 Þ denote the nth option (n ¼ 1; . . . ; N )
where each xi is an i.i.d. random variable with known
density f(xi). The value of Xn is
Psimply the sum of its
attribute values, i.e., U ðX n Þ ¼ i xni . To acquire information about the value of xni the DM must pay a ﬁxed
cost cni ¼ c, which is constant for all i and n. The payoﬀ
to the DM for selecting the nth option is given by:
pðX n Þ ¼ U ðX n Þ 

n X
2
X
j¼1

bjk c;

ð1Þ

k¼1

Overview

where bjk ¼ 1 if xjk was viewed and bjk ¼ 0 otherwise—i.e.,
the total value of the option net of search costs. If the
DM reaches the Nth option, she must accept it.
We will consider two diﬀerent versions of this problem, distinguished by the sort of information the DM
receives when she purchases attribute information:
Continuous case: When the DM pays to view the ith
value of the nth option, she learns the actual value of
xni . Once she selects an option, her payoﬀ is given by
Eq. (1).
Threshold case: When the DM pays to view the ith
value of the nth option, she learns only whether
xni P bni , where bni is a threshold she sets for each option
before purchasing. Once she selects an option, her payoﬀ
is given by Eq. (1).
The threshold case thus constrains the DM to using a
satisﬁcing strategy. The continuous case allows, but does
not compel, the use of such a strategy. The following
section describes optimal decision policies with and
without this constraint; the empirical portion of the
paper describes the behavior of actual experimental subjects under the two conditions. For simplicity we will
consider only the case in which both attributes are sampled from the same distribution, so that the order in
which attributes are purchased is immaterial.
Optimal policy: continuous case. For each option n,
the optimal decision policy is given by a 3-tuple (a1n,
a2n, a3n): an upper and lower threshold for the ﬁrst attribute, and a total value threshold for the entire option
(Lim et al., 2006; Smith, Lim, & Bearden, in press).
The decision policy works as follows:

In this section, we describe two new search problems
in which the DM sequentially encounters options composed of two attributes and must pay a ﬁxed cost to

1. If xn1 P an1 , (i.e. the ﬁrst attribute is above its upper
threshold) then choose this option and terminate the
search.

Two new multi-attribute sequential search problems

<-----Page 3----->150

J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

2. If xn1 < an2 , (i.e. the ﬁrst attribute is below its lower
threshold) then do not pay to view xn2 and proceed
to the next option.
3. If an2 6 xn1 < an1 , (i.e. the ﬁrst attribute is between the
upper and lower thresholds), then pay to view the value of xn2 and go to step 4.
4. If xn1 þ xn2 P an3 , (i.e. the total value of the option is
above the total value threshold) then choose this
option and terminate search. Otherwise proceed to
the next option.
Thus, if the value of xn1 is suﬃciently high, the DM
will select the nth option immediately (Step 1); likewise,
if the value is suﬃciently low, she will proceed to the
next option immediately (Step 2). In between these
extremes, she pays to learn the value of xn2 before deciding to accept the option or move on to the next one
(Step 3). Finally, if she does view xn2 , she either stops
her search or proceeds
based on the total value of the
P
option, U ðX n Þ ¼ i xni , (Step 4). In fact, once the value
of xn2 is known, the DM’s decision problem reduces to
the standard single-dimensional optional stopping
problem.
Optimal policy: threshold case. For each option n, the
optimal decision policy is given by a 3-tuple ðbn1 ; bn2 ; bn3 Þ.
Here, b1 and b2 are (real-valued) thresholds for attributes 1 and 2, respectively. The third policy element
b3 2 {0, 1} dictates when the DM should shift from a
strategy appropriate for the early part of the search
(b3 = 1) to an alternative strategy appropriate as the
DM approaches the end of the options (b3 = 0). The
decision policy works according to the following steps:
1. If xn1 P bn1 (i.e. ﬁrst attribute is above threshold) and
bn3 ¼ 0 (late search), then choose option n and terminate the search.1
2. If xn1 P bn1 and bn3 ¼ 1 (early search), then pay to view
the value of xn2 , and go to step 3; else do not pay to
view xn2 , proceed to next option, and return to Step 1.
3. If xn2 P bn2 (i.e., second attribute is above threshold)
then choose this option and terminate the search;
otherwise proceed to next option.
That is, if she is nearing the end of the options
(bn3 ¼ 0Þ, she selects an option immediately if the value
of the ﬁrst attribute exceeds her threshold. Earlier in
1
A reviewer points out that the special rules for late search, which
dictate than an option should be accepted if it passes only the ﬁrst
threshold, without inspection of the second attribute, is not strictly a
satisﬁcing procedure. This is perfectly correct, by the deﬁnition we
oﬀered earlier. Such an option satisﬁes the ﬁrst cut-oﬀ, but its status on
the second is unknown, and it is not economically advantageous to
determine it. However, unless confusion seems likely, we will continue
to use the term ‘‘satisﬁcing’’ to refer to problems in which attribute
information, if considered at all, is considered in the form of binary
above/below threshold values rather than as continuous variables.

the search (bn3 ¼ 1Þ she views the second attribute if
the ﬁrst is above threshold, and selects the option
if the second is also good enough. If not she declines
the option and goes on to the next. The optimal DM
always proceeds to the next option when the value of
the ﬁrst attribute is below her aspiration level.
Numerical methods for computing optimal policies
Using dynamic programming and numerical optimization methods, it is possible to calculate the numerical
values of ðan1 ; an2 ; an3 Þ and ðbn1 ; bn2 ; bn3 Þ at each stage that
maximize the expected (net) earnings of the search. A
proof that the optimal decision policy is a threshold policy of the type just described, as well as details of an
optimization procedure that can be used to obtain the
optimal thresholds, can be found in Lim et al. (2006).
In short, the optimal policies must satisfy Bellman’s
Principle of Optimality. That is, at each step of the
search process, the DM must take the action that yields
the highest expected payoﬀ assuming that she behaves
optimally thereafter. As an example, optimal policies
are shown in Tables 1 and 2 for the continuous and
threshold cases when a maximum of 10 options are presented (N = 10), both attribute values are sampled from
a uniform distribution Uni[1, 100], and with information
cost c = 5. (These are also the parameter values for the
experimental task reported below.)
For the continuous case (Table 1) all three optimal
thresholds decrease as n increases. As the DM approaches
the horizon at which she will have to take what she
gets (i.e. when n = N), she becomes increasingly likely
to accept an option with small values of either attribute
and of their total. Interestingly, the probability (.37 in
this instance) of viewing the value of the second attribute, xn2 , given that the DM has arrived at option n, is
constant for all n < N. However, the probability of
selecting the nth option given that one has reached it
increases with n. Finally, the DM’s expected payoﬀ
(v*) decreases as she gets deeper into the options.
The optimal policy for the threshold case (Table 2) is
broadly similar but has some interesting diﬀerences.
The DM’s thresholds for both attributes decrease for
options 1–7 and she always gets information on the
value of xn2 whenever xn1 P bn1 . At option 8, however,
her optimal strategy shifts, as indicated by the shift
in b3. At this point she should no longer be willing
to pay for information on the value of the second attribute, but she should be more demanding on the ﬁrst
attribute. In contrast to the continuous case, the
DM’s information purchase probability—conditional
on reaching option n—increases up to n = 8 and then
goes to zero as the optimal strategy changes. As for
the continuous case, however, her conditional stopping
probability increases in n, while her expected payoﬀ
decreases.

<-----Page 4----->J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158
Table 1
Continuous case optimal solution properties for c = 5

Period

n

a1

a3

a3

Prob(Buy
|Period = n)

Prob(Select
|Period = n)

v*(n)

1
2
3
4
5
6
7
8
9
10

89
89
88
87
86
84
81
76
68
—

53
52
52
51
49
48
45
40
31
—

122
121
120
120
118
116
114
109
100
—

.37
.37
.37
.37
.37
.37
.37
.37
.37
0

.29
.29
.30
.31
.32
.34
.37
.42
.50
1

122
122
121
120
120
118
116
114
109
100

Note. v*(n) is the expected payoﬀ for playing optimally from stage n to
stage N.

Table 2
Threshold case optimal solution properties for c = 5

Period

151

H3: Total incurred cost will be greater in the threshold
case than in the continuous case.
H4: Information purchase will be greater in the threshold case than in the continuous case.
The following section describes an experiment testing
these four hypotheses.

Methods
Participants
Sixty University of Arizona undergraduates (30 per
experimental condition) participated for both course
credit and cash payment.
Procedure

n

b1

b2

b3

Prob(Buy
|Period = n)

Prob(Select
|Period = n)

v*(n)

1
2
3
4
5
6
7
8
9
10

57
57
56
55
54
53
51
57
50
—

40
40
40
39
38
37
36
—
—
—

1
1
1
1
1
1
1
0
0
—

.43
.43
.44
.45
.46
.47
.49
.00
.00
.00

.26
.26
.27
.27
.28
.30
.32
.43
.51
1

120
119
119
118
117
116
114
112
107
100

Under optimal policies, expected earnings are virtually
identical for the two versions of the problem. For
most values of n, DMs in the threshold case are expected
to make around 98% of the proﬁt earned by DMs in the
continuous case. As Simon (1955) intuited, the penalty
for satisﬁcing rather than optimizing using continuousvariable attribute values may be quite small—as long
as the satisﬁcing is done optimally. We explore later in
the paper the sensitivity of these payoﬀs to ‘‘detuning’’
the optimal thresholds.
The optimal strategies presented in Tables 1 and 2
represent the results of considerable analytical and computational eﬀort. It seems highly unlikely that unaided
human decision makers will closely approximate these
optimal strategies. However we were interested to see
whether or not actual DMs follow strategies that mirror
optimal strategies in their broad qualitative (i.e., structural) features and, if they do not, in what ways they differ from optimality and how costly these deviations are.
To examine these questions, we use the predictions of
the optimal model to derive the following hypotheses:
H1: Average earnings in the continuous case will be
greater than those in the threshold case.
H2: DMs will search deeper into the set of options in
the threshold case than in the continuous case.

Participants arriving at the experiment site ﬁrst
signed consent forms, and were then shown to individual
lab rooms in which the experiment was presented on a
computer. They were instructed that they would be acting as buyers of bundles composed of two goods, Good
1 and Good 2. The bundles could not be decomposed
but had to be accepted or declined intact. In each trial
the participant would be oﬀered bundles sequentially
up to a maximum of 10 bundles, and at each stage could
either accept the one currently oﬀered or decline it and
go on to the next oﬀer. If she declined the ﬁrst nine oﬀers
in a trial, she would be required to accept the tenth bundle oﬀered. Each bundle contained some quantity of
each good, and the participants were told that the value
to them of any given bundle was simply the sum of the
values of the two goods it contained. For each bundle
the buyer could learn, at a cost of c per good, the value
of one or both goods the bundle contained. Participants
in both conditions were told:
Before deciding whether to buy a particular bundle,
you can get information about the worth (or value)
of one good or both goods—it’s your choice, but
you must get information on at least Good 1 before
making a decision2. The goods are valued in an artiﬁcial currency called francs, where 1 franc = $.10.
Each determination costs you 5 francs, so it costs
you 10 francs to check out a bundle completely. In
each bundle the worth of each good will be
2
This constraint was added after some subjects in pilot tests made
repeated choices without buying information on the value of either
attribute. We read this as evidence that they had not grasped the basic
nature of the task and decided not to collect more samples of such
behavior. Since the two attributes were sampled from identical
distributions, no generality was lost in selecting Attribute 1 for
enforced purchase, leaving purchase of Attribute 2 information
optional.

<-----Page 5----->152

J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

determined randomly and independently. The worth
of each good will be between 1 and 100 francs with
all possible values 1, 2, . . . , 100 being equally likely.
So a bundle is worth anywhere between 2 and 200
francs.
Additionally, participants in the threshold condition
read:
You get information about the worth of a good in a
bundle by (a) setting a target level for the good, and
(b) paying 5 francs (5f). A target level is a number
you set between 1 and 100f. Then, when you pay 5f
to learn about the worth of the good, you learn
whether the good’s worth is above or below the target
level you set. For example, suppose you set your Target level for Good 1 at 50f. Then, if the real value of
Good 1 is 80f, you would get the message True, which
means that in that bundle there is 50f or more of
Good 1. If the worth of Good 1 were 40f, however,
you would be told False, meaning that in this bundle
there is less than 50f of Good 1. You will be able to
set Target levels for each separate good (Good 1
and Good 2) in each separate bundle. You will learn
the actual worths of the goods only after you buy a
bundle.
The participants were then taken through several
example trials showing them what might happen at each
step. The experimenter answered any questions the participants had. There were 100 experimental (non-practice) trials.
Payment
The participants were told that they would be paid
their actual earnings (in dollars) for one randomly
selected trial of the 100 experimental trials and that they
themselves would determine the trial for which they
would be paid by drawing a number from a hat. The
average payoﬀ for the 1 h session was approximately
$12.
Results
Earnings
The average (net) earnings in the continuous
(M = 116.73, SD = 4.35) and threshold (M = 115.49,
SD = 4.86) conditions were both signiﬁcantly lower
than predicted under the optimal policy, t(29) = 6.77,
p < .001, d = 2.51, and t(29) = 4.65, p < .001, d = 1.73,
respectively.3 However, in violation of Hypothesis 1
3

In addition to conventional test statistics, we will present eﬀect size
estimates using Cohen’s d throughout (see Cohen, 1988; Rosnow,
Rosenthal, & Rubin, 2000).

the average earnings did not signiﬁcantly diﬀer between
conditions, t(58) = 1.04, p = .30, d = 0.27. Interestingly
the average value of the selected option was signiﬁcantly
higher in the threshold condition (M = 141.49,
SD = 5.33) than in the continuous condition
(M = 136.54, SD = 7.32), t(58) = 2.99, p = .004,
d = 0.79. This diﬀerence was oﬀset by the signiﬁcantly
higher average information costs incurred in the threshold case, results that we present below. Looking more
closely, we ﬁnd that the diﬀerence between the conditions in the value of the selected option is driven by
the diﬀerence in the average value of Good 2 for the
selected options (continuous condition: M = 61.92,
SD = 4.93; threshold condition: M = 65.93, SD = 5.45;
t(58) = 2.98, p = .004, d = 0.79). The average Good 1
values of the selected option did not diﬀer signiﬁcantly
between conditions (continuous condition: M=74.61,
SD = 4.61; threshold condition: M = 75.55, SD = 4.25;
t(58) = .82, p = .41, d = 0.22). In short, participants in
the threshold condition examined more options than
did those in the continuous condition, incurring higher
information costs but also choosing options with higher
values of Good 2. The net result was that overall earnings did not diﬀer signiﬁcantly between the two
conditions.
Stopping position
Under the optimal policy, the expected stopping position in the continuous condition is 3.21; in the threshold
condition, it is 3.52. We computed the mean stopping
position for each subject in each condition and compared this with the expected stopping position under
the optimal policy. The mean stopping position of participants in the continuous condition (M = 2.79,
SD = 0.58) was signiﬁcantly less than expected stopping
position under the optimal policy, t(29) = 3.92, p < .001,
d = 1.46. In contrast, the mean stopping position in the
threshold condition (M = 3.81, SD = .85) was somewhat larger than that expected under optimal policy,
though the diﬀerence was only marginally signiﬁcant
(t(29)=1.85, p = .08, d = 0.69). Consistent with Hypothesis 2, we ﬁnd that search in the threshold case tends to
go deeper into the set of options than search in the continuous case, t(58) = 5.38, p < .001, d = 1.41.
Incurred costs
Under the optimal policy, the expected incurred costs
for a given trial is 22.02 for the continuous condition
and 25.13 for the threshold condition. We ﬁnd that the
average incurred costs are signiﬁcantly lower than predicted by the optimal policy in the continuous condition
(M = 19.69, SD = 4.16), t(29) = 3.01, p= .001, d = 1.12,
but not in the threshold condition (M = 25.99,
SD = 5.96), t(29) = .079, p = .43, d = 0.03. The average

<-----Page 6----->J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

153

incurred cost in the threshold case is indeed higher than
in the continuous case, t(58) = 4.70, p < .001, d = 1.23,
consistent with Hypothesis 3.
Buying of good 2
The expected buying probabilities follow directly from
the expected incurred costs and the expected stopping
positions for each condition. Recall that the DMs were
obliged to purchase information on Good 1. Hence, the
total cost incurred on a trial equals the cost of purchasing
Good 1 information times the bundle on which the search
terminated plus the number of times information on Good
2 was purchased times the cost of doing so. By simple algebra, then, the expected number of times information on
Good 2 will be obtained can be derived from the expectations presented in the previous two sub-sections. In optimal play, the expected number of Good 2 information
purchases for the continuous condition is 1.19 and for
the threshold condition is 1.51. In neither experimental
condition did we ﬁnd that the average information purchase departed signiﬁcantly from these optimal policies:
for the continuous condition (M = 1.17, SD = .41),
t(29) = .27, p = .79, d = 0.10; and for the threshold condition, (M = 1.39, SD = .46), t(29) = 1.38, p = .18,
d = 0.51. As predicted by Hypothesis 4, the average number of Good 2 information purchases was higher in the
threshold condition than in the continuous condition,
though the diﬀerence is only marginally signiﬁcant
(t(58) = 1.95, p = .056, d = 0.51).
Average thresholds for threshold condition
The average cut-oﬀs set by participants in the threshold condition are shown in Fig. 1. For both Good 1 and
Good 2, the DMs tended to set their cut-oﬀs (the bs in
the ﬁgure) too high relative to the optimal cut-oﬀs (the
b*s in the ﬁgure). The high cut-oﬀs set for Good 1
account in part for the under-buying of Good 2 information: the sampled value of Good 1 was often below
the DM’s cut-oﬀ, discouraging purchase of Good 2
information. (Note: The increase in average thresholds
in later periods is due to the fact we could not observe
late period thresholds for some participants, namely
those with relatively low thresholds. Participants with
lower thresholds tended to search less, while those with
higher thresholds searched more. The increase in
average thresholds in later periods is driven by the subset of participants for whom we could observe these
thresholds—i.e., by those with higher thresholds.)
The corresponding cut-oﬀs for the continuous condition are, of course, not directly observable. We therefore
used the modeling approach detailed in Appendix A to
examine participants’ search policies. For each individual we estimated (stochastic) compensatory and satisﬁcing policies using maximum likelihood estimation

Fig. 1. Optimal (solid lines) and mean empirical (dashed lines)
thresholds across periods (bundles) for the threshold decision problem.

Table 3
Model comparison statistics
Condition

Model

Percentage of
DMs best ﬁt

Mean ln L

Continuous

Compensatory
Satisﬁcing

80
20

137.77
147.17

Threshold

Compensatory
Satisﬁcing

7
93

153.79
167.18

procedures. Summary statistics by experimental condition are shown in Table 3.
As the table shows, nearly all the participants in the
threshold condition (28 of 30: 93%) were better ﬁt
by the satisﬁcing model than by the compensatory
model—reassuringly, since the information needed for
a compensatory procedure was not available to these
participants. In the continuous condition, however, a
considerable majority (24 of 30: 80%) were better ﬁt
by the compensatory model, providing strong evidence
that when actual attribute values were available participants used them in their choices. It does not appear,
then, that DMs in the continuous condition spontaneously imposed a satisﬁcing-type procedure on their attribute value information. Restricting DMs to binary
information, as in the threshold condition, changed
decision strategies as well as average search depth and
information costs incurred.

Discussion
One of our objectives in this paper has been to reexamine, both theoretically and empirically, the notion of
satisﬁcing in sequential search problems in which
decision options are composed of multiple attributes.

<-----Page 7----->154

J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

Since Simon (1955) ﬁrst proposed the idea as a descriptively plausible response to cognitive overload, satisﬁcing appears to have acquired a connotation of sloppy,
second-rate, ineﬀective decision making. Simon’s suggestion that satisﬁcing is forced on us by our cognitive
limits seems to have acquired the implicit corollary that
we pay a substantial penalty for our shortcomings.
Careful simulation studies (e.g. Payne, Bettman, &
Johnson, 1993: 123ﬀ) appear to conﬁrm this view. Payne
et al’s satisﬁcing models used arbitrary cut-oﬀs and performed substantially worse than optimal models
(though at considerable savings in cognitive eﬀort). A
central thrust of the current ﬁndings is that this conclusion may not generalize to other tasks, especially if the
satisﬁcing cut-oﬀs are well-chosen.
The multi-attribute sequential search problems
(MASSPs) we introduce here generalize the single-attribute sequential search problems that have already
received considerable empirical attention. In the singleattribute problems the DM faces a single decision: when
to stop searching and take an option. The MASSP generalizes these kinds of problems to situations in which a
DM must strike a balance between searching within
options to learn their true worth and searching across
options to learn what is available.
In the ﬁrst part of this paper we described the optimal
(expected payoﬀ maximizing) strategies for two types of
MASSPs: those in which the DM gets precise information
about attribute values (the ‘‘continuous’’ case) and those
in which she learns only binary (good enough/not good
enough) information about the attributes (the ‘‘threshold’’ case). Optimal policies for the two cases diﬀer,
though both are ‘‘dynamic’’ in the sense that they require
the DM to adjust her decision criteria as she moves
through the sequence of available options. A somewhat
surprising ﬁnding from this analysis is that, at least for
the parameterization of the task we considered here, the
diﬀerence in expected net payoﬀ for the continuous and
the threshold cases is negligible. Though the DM in the
threshold case receives only binary information, she can
earn 98% of what the DM in the continuous case earns,
if both follow their respective optimal strategies. Additional analysis (not reported here) of a large class of
MASSPs revealed the same pattern. For wide ranges of
N (number of options), k (number of attribute values), c
(search costs), and attribute distributions, the diﬀerence
in optimal payoﬀs between the two information conditions is small. In fact we have been unable to produce a
problem in which the diﬀerence in payoﬀs exceeds 3%. Satisﬁcing (which mimics search in the threshold case) does
not in itself impose a large penalty on DMs in MASSPs.
In an experimental decision problem based on the
two versions of the MASSP, participants in the continuous and threshold conditions achieved similar (statistically indistinguishable) earnings. They did not do as well
as they could have, but they did relatively well, earning

about 95% of optimal, on average. Participants in the
continuous case tended to search through fewer options
than required by the optimal policy, whereas those in
the threshold condition searched through more, and
acquired more information, than optimality dictates
(cf Newell et al., 2003). However, in both cases the eﬀect
was small and only marginally signiﬁcant. We observed
some modest learning in early trials, but behavior was
generally constant across repeated play. Finally, ﬁtting
two alternative stochastic choice models to individual
participant data showed that most (80%) of the
participants in the continuous condition were best ﬁt
by a compensatory (non-satisﬁcing) model, while the
overwhelming majority (93%) of those in the threshold
condition were best ﬁt by a non-compensatory (satisﬁcing) model. Participants in the continuous condition
thus appear not to have used satisﬁcing search policies,
while those in the threshold condition were compelled to
do so. However, and crucially, those who were forced
to satisﬁce (the threshold group) did as well as those
who did not satisﬁce (most of the continuous group).
Before we conclude too much from this pattern of
ﬁndings, we should address the issue of payoﬀ sensitivity
to departures from optimal policies in these tasks. Insensitivity of payoﬀs to strategy variation—the ‘‘ﬂat
maximum’’ problem—plagues a number of problems
studied in experimental economics (see, e.g., Harrison,
1989). In our experiment, we observed only a negligible
diﬀerence in actual participant payoﬀs between the continuous and the threshold conditions: both achieved
close to optimal payoﬀs. Is this the result of good strategy choices by the participants or of the insensitivity of
payoﬀs to strategy errors? To address this, we examined
the expected payoﬀs for various non-optimal decision
policies for each condition, multiplying the optimal
cut-oﬀs (a1, a2, a3, for the continuous case; b1, b2, for
the threshold case) by a constant p (p > 0). The expected
payoﬀs for each condition as a function of p are shown
in Fig. 2. Note that the payoﬀs decline as p moves above
or below 1.0 (i.e., optimal cut-oﬀs), more for the continuous case than the threshold case. The peaks are not
especially sharp, but it is clearly not the case that any
randomly chosen strategy will achieve good results in
these tasks. Judged by the relatively good payoﬀs our
participants achieved, whatever strategies they were
using were reasonably well-adapted to their tasks.
Search policies in the threshold (satisﬁcing) condition
appear to be more robust to departures from optimality
than are those in the continuous condition. To probe this
observation further we examined the robustness of search
policies to a second non-optimality: constraining the cutoﬀs ai and bi to be constant across all options. We set the
cut-oﬀs to values that would be optimal for the ﬁrst option
in each case (a1 = 89, a2 = 53, and a3 = 122, for the continuous case, and b1 = 57 and b2 = 40 for the threshold
case) and examined the eﬀect on expected payoﬀ of

<-----Page 8----->J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

Fig. 2. Expected payoﬀ as a function of ‘‘tuned’’ optimal policies for
continuous and threshold conditions.

Fig. 3. Expected payoﬀs of heuristic (ﬁxed cut-oﬀ) policies for
threshold and continuous conditions.

detuning these values by a constant multiplier p as before.
Expected payoﬀs are shown in Fig. 3.
As before the payoﬀs in the continuous case are sensitive to the value of p, those in the threshold case substantially less so. When the cut-oﬀs are ﬁxed in the
continuous case, the payoﬀs suﬀer dramatically, with
the penalty being greatest for setting the cut-oﬀs too
high. In the threshold case, the payoﬀs are relatively stable across values of p. And relying on a static (non-optimal) policy with ﬁxed cut-oﬀs across options leads to
higher payoﬀs in the threshold than in the continuous
case, in contrast to the optimal policy with shifting
thresholds that gives higher payoﬀs in the latter.4
4
Of course, one could do a number of tests of diﬀerent search
policies and parameterizations. They all (qualitatively) support the
conclusions we draw here based on the subset of the results we are
presenting.

155

The broad implication of our study is that a well-chosen satisﬁcing strategy may be much better than a mere
second-rate decision process forced on us by cognitive
limitations. At least in MASS problems such as those
examined here, analytical and empirical evidence both
suggest that little is lost when one makes sequential
search decisions using only binary (satisﬁed or not?)
information rather than using the full detail of continuous attribute values. (A similar point is made by Dudey
& Todd, 2002, working in the fast and frugal heuristics
tradition.) Further, the outcomes of satisﬁcing search
are not overly sensitive to the precise cut-oﬀs used to
make satisﬁcing decisions. In short one can search using
satisﬁcing (which is not very cognitively demanding)
without worrying about getting one’s satisﬁcing criteria
just right and still do well in sequential search problems.
It is interesting to speculate as to the potential practical implications of these results, should they prove to
extrapolate into real-world settings in essentially their
present form. Studies comparing habitual maximizers
and habitual satisﬁcers (Schwartz, 2004; Schwartz
et al., 2002) have found that those who attempt to maximize generally are less happy with the outcomes of their
choices than are habitual satisﬁcers. This ﬁnding is consistent with the present evidence that satisﬁcing search
may do little to reduce overall payoﬀs, and saves considerable cognitive eﬀort. Similarly there appear to be
numerous practical decision settings (for example,
action guidelines for emergency medical personnel;
search criteria for important multi-person decisions such
as the selection of a college president) where complex
multi-attribute tradeoﬀs are intentionally reduced to
simpler binary criteria in order to avoid decision delay,
cognitive work or interpersonal conﬂict. The present
ﬁndings suggest that such deliberate simpliﬁcations of
the decision process may impose small or no penalty
in payoﬀ terms (quality of the medical treatment or of
the candidate chosen). Satisﬁcing strategies may thus
oﬀer real practical beneﬁts at small cost in terms of quality of option selected.
This ﬁrst study of the MASSP leaves considerable
room for future research. As predicted our approach
provides only broad characterizations of our participants’ strategies, and detailed process models of their
behavior will require more micro-level approaches such
as those promoted by the ‘‘fast and frugal heuristics’’
paradigm. Here, we avoided going beyond two attributes in the experiment because the ﬂat maximum problem introduces itself quickly as k grows. In problems
with three or more attributes it makes little diﬀerence
what the DM does; for most reasonable policies the payoﬀs are roughly the same. The same may not be true
when the payoﬀ for selecting an option is something
other than an additive function of its attribute values.
We are currently working on developing optimal
policies for problems in which the payoﬀ function is

<-----Page 9----->156

J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

multiplicative in the attribute values. This theoretical
analysis will also allow us to say more about the broader
applicability and performance of satisﬁcing strategies in
sequential search. In the meantime, we are left with the
intriguing possibility that there appear to be at least
some situations in which satisﬁcing is, in fact, the overall
best policy.

Acknowledgments
We gratefully acknowledge ﬁnancial support under
Grant F49620-03-1-0377 from the AFOSR/MURI to
the Department of Systems and Industrial Engineering
and the Department of Management and Organizations
at the University of Arizona.
Appendix A. Two models of multi-attribute sequential
decision making
For each option presented, the DM faces a well-deﬁned set of decision alternatives (see Fig. A1). First,
she sees the value of x1 and then either accepts the
option or not. If she accepts the option the trial ends.
If not, then she can either choose to view the value of
x2 for this option or immediately continue to the next
option. If she chooses to view x2, she can then either
select the present option, ending the trial, or proceed
to the next option. Here we propose two stochastic models of this process, one compensatory, the other satisﬁcing. Under both models, decisions to select, continue or
view more information are made probabilistically based
on the information available to the DM and the DM’s
decision parameters, /1  /3 , representing the probabilities of each possible move from one decision stage to
the next.
Compensatory search model. The compensatory
search model (CSM) is based on the form of the optimal
policy for the continuous search problem. In fact, the
optimal policy for the continuous problem is a special

case of that for the CSM. Under this model, the DM
has a set of three decision thresholds or aspiration levels
Rn1 , Rn2 and Rn3 (0 6 Rn1 ; Rn2 6 100; 0 6 Rn3 6 200Þ for each
option (n = 1, . . . , N) and sensitivity levels for each: kn1 ,
kn2 , and kn3 (0 < kni Þ. Her decision probabilities for each
option are based on a sigmoidal response function:
/ni ¼

1
n ;
1 þ ezi

ðA1Þ

where zn1 ¼ kn1 ðxn1  Rn1 Þ, zn2 ¼ kn2 ðxn1  Rn2 Þ, and zn3 ¼
kn3 ½ðxn1 þ xn2 Þ  Rn3 . That is, the more x1 exceeds her
aspiration level Rn1 , the more likely she is to accept the
option immediately. If she does not stop immediately,
the probability that she views x2 increases as the diﬀerence between x1 and her aspiration level Rn2 increases.
Most importantly—and this is what distinguishes the
CSM from the model described next—her decision to
accept an option after viewing x2 is based on the sum
of x1 and x2. Speciﬁcally, she is more likely to accept
the current option as the diﬀerence in the worth of the
option (x1 þ x2 Þ and her aspiration level for the worth
(Rn3 Þ increases. The steepness of each of the probabilistic
response functions is governed by the parameter kni : The
response functions for larger kni are steeper around their
respective aspiration levels. Fig. A2 shows response
functions for various values of kni for a given Rni . Note
that as kni ! 1 the response function becomes
deterministic.
Satisﬁcing search model. The satisﬁcing search model
(SSM) is identical to the CSM up to the stage at which
the DM decides whether to accept an option after viewing x2. Rather than make her decision based on the sum
of x1 and x2, at this stage, the DM under the SSM considers only the value of x2. Formally, we get the SSM
from the CSM by computing /n3 with zn3 ¼ kn3 ðxn2  Rn3 Þ.
Under the SSM, after choosing to view x2, the DM decides whether the option is acceptable solely on the basis of
the value of x2. Taken together, then, once x2 has been
viewed, she accepts an option only if both of its attributes
are acceptable (in probability); she does not base her
decision on the total worth of the option, as the DM

Fig. A1. Graphical representation of the multi-attribute sequential decision problem.

<-----Page 10----->J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

Fig. A2. Stopping probability for diﬀerent values of l for a ﬁxed
aspiration level R.

Table A1
Model event probabilities for both models
Decision

Probability

E1:
E2:
E3:
E4:

P ðEn1 Þ ¼ /n1
P ðEn2 Þ ¼ ð1  /n1 Þð1  /n2 Þ
P ðEn3 Þ ¼ ð1  /n1 Þ/n2 /n3
P ðEn4 Þ ¼ ð1  /n1 Þ/n2 ð1  /n3 Þ

Stop After x1
Continue After x1
View x2 then Stop
View x2 then Continue

under the CSM does. Table A1 shows the possible decisions the DM can make under each model and the corresponding (unconditional) probabilities for each.
Estimating model parameters. We ﬁt each model to
each experimental subject’s data by ﬁnding the set of
parameters R ¼ ðR11 ; . . . ; R1N ; R12 ; . . . ; R3N Þ and k ¼
ðk11 ; . . . ; k1N ; k12 ; . . . ; k3N Þ that maximize the log-likelihood
of the subject’s decision sequence E ¼ ðE1i;1 ; E2i;1 ; . . . ;
sð1Þ
sð100Þ
Ei;1 ; E1i;2 ; . . . ; Ei;100 Þ, where Eni;k is the subject’s decision
at stage n on trial k and s(k) is the stage of trial k at
which the DM made a terminal decision (i.e., E1 or
E3). Hence, the log-likelihood of the decision sequence
can be written as
ln LðEÞ ¼

sðkÞ
100 X
X

log½P ðEni;k Þ:

ðA2Þ

k¼1 n¼1

This measure was computed for each participant in both
CSM and SSM and the participant assigned to one or
the other category on the basis of which model provided
the better ﬁt for the participant’s data. The assignments
are summarized in Table 3.

References
Baumol, R. (2004). Rational satisﬁcing. In B. Augier & J. G. March
(Eds.), Essays in honor of Herbert Simon. Cambridge, MA: MIT
Press.

157

Bearden, J. N., & Connolly, T. (2006). On optimal satisﬁcing: how
simple policies can achieve excellent results. University of Arizona
working paper.
Bearden, J. N., Murphy, R. O., & Rapoport, A. (2005). A multiattribute extension of the secretary problem: theory and experiments. Journal of Mathematical Psychology, 49, 410–422.
Bearden, J. N., Rapoport, A., & Murphy, R. (2006). Sequential
selection and assignment with rank-dependent payoﬀs. An experimental test. Management Science, 52, 1437–1449.
Brickman, P. (1972). Optional stopping in ascending and descending
series. Organizational Behavior and Human Performance, 7, 53–62.
Browne, G. J., & Pitts, M. G. (2004). Stopping rule use during
information search in design problems. Organizational Behavior
and Human Decision Processes, 95, 208–224.
Chow, Y. S., Robbins, H., & Siegmund, D. (1971). Great expectations:
the theory of optimal stopping. Boston: Houghton Miﬄin.
Cohen, J. (1988). Statistical power analysis for the behavioral sciences
(2nd ed.). Hillsdale, NJ: Earlbaum.
Connolly, T. (1988). Studies in information-purchase processes. In B.
Brehmer & C. R. B. Joyce (Eds.), Human judgment: the SJT view.
Amsterdam: Elsevier-North Holland.
Connolly, T., & Gilani, N. (1982). Information search in judgment
tasks: a regression model and some preliminary ﬁndings. Organizational Behavior and Human Performance, 30, 330–350.
Connolly, T., & Wholey, D. R. (1988). Information mispurchase in
judgment tasks: a task-driven causal mechanism. Organizational
Behavior and Human Decision Processes.
Corbin, R. M., Olson, C. R., & Abbondanza, M. (1975). Context
eﬀects in optimal stopping rules. Organizational Behavior and
Human Performance, 14, 207–216.
Cox, J. C., & Oaxaca, R. L. (1989). Laboratory experiments with a
ﬁnite horizon job-search model. Journal of Risk and Uncertainty, 2,
301–330.
Dudey, T., & Todd, P. M. (2002). Making decisions with minimal
information: simultaneous and sequential choice. Journal of
Bioeconomics, 3, 195–215.
Edwards, W. (1965). Optimal strategies for seeking information:
models for statistics, choice reaction times, and human information
processing. Journal of Mathematical Psychology, 2, 312–329.
Gigerenzer, G. (2004). Striking a blow for sanity in models of
rationality. In B. Augier & J. G. March (Eds.), Essays in honor of
Herbert Simon. Cambridge, MA: MIT Press.
Gigerenzer, G., & Goldstein, D. G. (1996). Reasoning the fast and
frugal way: Models of bounded rationality. Psychological Review,
103, 650–669.
Gigerenzer, G., Todd, P. M., & the ABC Research Group (1999).
Simple heuristics that make us smart. New York: Oxford University Press.
Goldstein, D. G., & Gigerenzer, G. (2002). Models of ecological
rationality: the recognition heuristic. Psychological Review, 109.
Harrison, G. (1989). Theory and misbehavior of ﬁrst-price auctions.
American Economic Review, 79, 749–762.
Hertwig, R., & Todd, P. M. (2003). More is not always better: the
beneﬁts of cognitive limits. In D. Hardman & L. Macchi (Eds.),
Thinking: psychological perspectives on reasoning, judgment and
decision making. West Sussex: Wiley & Sons.
Hey, J. D. (1981). Are optimal search rules reasonable? And vice versa?
Journal of Economic Behavior and Organization, 2, 47–70.
Hey, J. D. (1982). Search for rules of search. Journal of Economic
Behavior and Organization, 3, 65–81.
Hey, J. D. (1987). Still searching. Journal of Economic Behavior and
Organization, 8, 137–144.
Kahneman, D., Slovic, P., & Tversky, A. (Eds.). (1982). Judgment
under uncertainty: heuristics and biases. Cambridge University
Press.
Kogut, C. A. (1990). Consumer search behavior and sunk costs.
Journal of Economic Behavior and Organizations, 14, 381–392.

<-----Page 11----->158

J.N. Bearden, T. Connolly / Organizational Behavior and Human Decision Processes 103 (2007) 147–158

Lim, C., Bearden, J. N., & Smith, C. (2006). Sequential search with
multi-attribute options. Decision Analysis, 3, 3–15.
Miller, G. F., & Todd, P. M. (1998). Mate choice turns cognitive.
Trends in Cognitive Science, 2, 190–198.
Newell, B. R., Weston, N. J., & Shanks, D. R. (2003). Empirical tests
of a fast and frugal heuristic: not everyone takes-the-best.
Organizational Behavior and Human Decision Processes, 91, 82–96.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1993). The adaptive
decision maker. Boston, MA: Cambridge University Press.
Rapoport, A., & Tversky, A. (1966). Cost and accessibility of oﬀers as
determinants of optional stopping. Psychonomic Science, 4, 145–146.
Rapoport, A., & Tversky, A. (1970). Choice behavior in an optimal
stopping task. Organizational Behavior and Human Performance, 5,
105–120.
Rosnow, R. L., Rosenthal, R., & Rubin, D. B. (2000). Contrasts and
correlations in eﬀect-size estimation. Psychological Science, 11,
446–453.
Saad, G., & Russo, J. E. (1996). Stopping criteria in sequential choice.
Organizational Behavior and Human Decision Processes, 67,
258–270.
Schwartz, B. (2004). The paradox of choice. New York: Harper Collins.
Schwartz, B., Ward, A., Monterosso, J., Lyubomirsky, S., White, K.,
& Lehman, D. R. (2002). Maximizing versus satisﬁcing: happiness

is a matter of choice. Journal of Personality and Social Psychology,
83, 1178–1197.
Seale, D. A., & Rapoport, A. (1997). Sequential decision making with
relative ranks: an experimental investigation of the secretary
problem. Organizational Behavior and Human Decision Processes,
69, 221–236.
Seale, D. A., & Rapoport, A. (2000). Optimal stopping behavior with
relative ranks: the secretary problem with unknown population
size. Journal of Behavioral Decision Making, 13, 391–411.
Shapira, Z., & Venezia, I. (1981). Optional stopping in non-stationary
series. Organizational Behavior and Human Performance, 27, 32–49.
Simon, H. (1955). A behavioral model of rational choice. Quarterly
Journal of Economics, 59, 99–118.
Smith, J. C., Lim, C., & Bearden, J. N. (in press). On the multiattribute stopping problem with general value functions. Operations Research Letters.
Todd, P. M. (2001). Fast and frugal heuristics for environmentally
bounded minds. In G. Gigerenzer & R. Selten (Eds.), Bounded
rationality: the adaptive toolbox (pp. 51–70). Cambridge, MA: MIT
Press.
Zwick, R., Rapoport, A., Lo, A. K. C., & Muthukrishnan, A. V.
(2003). Consumer sequential search: not enough or too much?
Marketing Science, 22, 503–519.

