<-----Page 0----->ANNUAL
REVIEWS

Further

Quick links to online content
Ann. Rev. Psychol. 1981. 32:53-88
© 1981

Copyright

by Annual Reviews Inc. All rights reserved

BEHAVIORAL DECISION

+340

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

THEORY: PROCESSES
OF JUDGMENT AND CHOICE
Hillel J. Einhorn and Robin M. Hogarth
Center for Decision Research, Graduate School of Business, University
of Chicago, Chicago, Illinois 60637

CONTENTS
INTRODUCTION .........................................................................................................

ARE OPTIMAL DECISIONS REASONABLE? .......................................................
Task
Task ...............................................................................

vs Optimal Model of
Environment vs Problem Space .................................................................................
Intuitive Responses and Optimal Models .................................................................

.

.

.

.

.

STRATEGIES AND MECHANISMS OF JUDGMENT AND CHOICE ...............

The ��/� of Acquisition in Evaluation .....................................................................
AcqUISitIOn
Evaluation/Action .....................................................................................................
u
y:dff�:��!, ��':;�;J::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
Conflict in Action......................................................................................................

.

.

..................................................................................................................

.

..

LEARNING/FEEDBACK ...........................................................................................
METHODOLOGICAL CONCERNS ...........................................................................
CONCLUSION...............................................................................................................

.

.

.

53
55
55
57
59
61
62
63
69
71
73
74
77
80
83

INTRODUCTION
Why are normative theories so prevalent in the study of judgment and
choice, yet virtually absent in other branches of science? For example,
imagine that atoms and molecules failed to follow the laws supposed to
describe their behavior. Few would call such behavior irrational or subopti­
mal. However, if ,people violate expected utility axioms or do not revise
probabilities in accord with Bayes' theorem, such behavior is considered
suboptimal and perhaps irrational. What is the difference, if any, between
53

0066-4308/80/0201-0053$01.00

<-----Page 1----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

54

EINHORN & HOGARTH

the two situations? In the latter we implicitly assume that behavior is
purposive and goal-directed while this is less obvious (if at all) in the former.
(It is problematic how one might treat plant and animal behavior according
to a descriptive-normative dichotomy.) Therefore, if one grants that behav­
ior is goal-directed, it seems reasonable to assume that some ways of getting
to the goal are better, in the sense of taking less time, making fewer errors,
and so on, than others. Indeed, much of decision research concerns evaluat­
ing and developing ways for improving behavior, thereby reflecting a strong
engineering orientation (Edwards 1977; Hammond, Mumpower & Smith
1977; Keeney & Raiffa 1976). Moreover, comparison of actual behavior
with normative models has been important in focusing attention on the
discrepancies between them, and this in turn has raised important questions
about the causes of such discrepancies.
Central to normative theories are the concepts of rationality and optimal­
ity. Recently Simon (1978) has argued for different types of rationality,
distinguishing between the narrow economic meaning (Le. maximizing be­
havior) and its more general dictionary definition of "being sensible, agree­
able to reason, intelligent." Moreover, the broader definition itself rests on
the assumption that behavior is functional. That is,
Behaviors are functional if they contribute to certain goals, where these goals may be
the pleasure or satisfaction of an individual or the guarantee of food or shelter for the
members of society.... It is not necessary or implied that the adaptation of institutions
or behavior patterns of goals be conscious or intended.... As in economics, evolutionary
arguments are often adduced to explain the persistence and survival of functional pat­
terns and to avoid assumptions of deliberate calculation in explaining them (pp. 3-4).

Accordingly, Simon's concept of "bounded rationality," which has pro­
vided the conceptual foundation for much behavioral decision research, is
itself based on functional and evolutionary arguments. However, although
one may agree that evolution is nature's way of doing cost/benefit analysis,
it does not follow that all behavior is cost/benefit efficient in some way. We
discuss this later with regard to misconceptions of evolution, but note that
this view: (0) is unfalsifiable (see Lewontin 1979, on "imaginative recon­
structions"); (b) renders the concept of an "error" vacuous; (c) obviates the
distinction between normative and descriptive theories. Thus, while it has
been argued that the difference between bounded and economic rationality
is one of degree, not kind, we disagree.
The previous review of this field (Slovic, Fischhoff & Lichtenstein 1977)
described a long list of human judgmental biases, deficiencies, and cognitive
illusions. In the intervening period this list has both increased in size and
influenced other areas of psychology (Bettman 1979, Mischel 1979, Nisbett

<-----Page 2----->BEHAVIORAL DECISION THEORY

55

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

& Ross 1980). Moreover, in addition to cataloging the types of errors

induced by the manner in which people make judgments and choices,
concern has now centered on explaining the causes of both the existence and
persistence of such errors. This is exemplified by examination of a basic
assumption upon which adaptive and functional arguments rest, namely the
ability to learn (Einhorn & Hogarth 1978, Hammond 1978a, Brehmer,
1980). However, if the ability to learn is seriously deficient, then dysfunc­
tional behavior can not only exist but persist, thus violating the very notion
of functionality. It is therefore essential to delimit the conditions under
which this can occur. Indeed, the general importance of considering the
effects of specific conditions on judgment and choice is emphasized by the
following irony: the picture of human judgment and choice that emerges
from the literature is characterized by extensive biases and violations of
normative models whereas in work on lower animals much choice behavior
seems consistent with optimizing principles (e.g. Killeen 1978, Rachlin &
Burkhard 1978, Staddon & Motheral 1978). The danger of such pictures is
that they are often painted to be interesting rather than complete. In the
next section we consider the complexities involved in evaluating discrepan­
cies between optimal models and human responses, and how persistent
dysfunctional behavior is consistent with evolutionary concepts.

ARE OPTIMAL DECISIONS REASONABLE?
How are discrepancies between the outputs of optimal models and human
responses to be evaluated? First, consider the latter to be generated through
a cognitive model of the task and note the different possibilities: 1. Both
models could inadequately represent the task, but in different ways; 2. the
optimal model is a more adequate representation than that of the person.
Indeed, this is the assumption upon which most decision research is predi­
cated; and 3. the person's model is more appropriate than the optimal model
-a hypothesis suggested by March (1978). Furthermore, in the absence of
discrepancies, neither model could be appropriate if they misrepresent the
environment in similar ways. Therefore, before one compares discrepancies
between optimal models and human judgments, it is important to compare
each with the environment.

Task vs Optimal Model of Task
We begin by offering a definition of optimality; namely, decisions or judg­
ments that maximize or minimize some explicit and measurable criterion
(e.g. profits, errors, time) conditional on certain environmental assumptions
and a specified time horizon. The importance of this definition is that it
stresses the conditional nature of optimality. For example, Simon (1979)

<-----Page 3----->56

EINHORN & HOGARTH

points out that because of the complexity of the environment, one has but
two alternatives: either to build optimal models by making simplifying
environmental assumptions, or to build heuristic models that maintain
greater environmental realism (also see Wimsatt 1980). Unfortunately, the
conditional nature of optimal models has not been appreciated and too few
researchers have considered their limitations. For instance, it has been
found that people are insufficiently regressive in their predictions (Kahne­
man & Tversky 1973). While this is no doubt true in stable situations,

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

extreme predictions are not suboptimal in nonstationary processes. In fact,
given a changing process, regressive predictions are suboptimal. The prob­
lem is that extreme responses can occur at random or they can signal
changes in the underlying process. For example, if you think that Chrysler's
recent large losses are being generated by a stable process, you should
predict that profits will regress up to their mean level. However, if you take
the large losses as indicating a deteriorating quality of management and
worsening market conditions, you should be predicting even more extreme
losses. Therefore, the optimal prediction is conditional on which hypothesis
you hold.
The above is not an isolated case. For example, Lopes (1980) points out
that the conclusion that people have erroneous conceptions of randomness
(e.g. Slovic, Kunreuther & White 1974) rests on the assumption that well­
defined criteria of randomness exist. She convincingly demonstrates that
this is not the case. Or consider the work on probability revision within the
Bayesian framework (e.g. Slovic & Lichtenstein 1971). Much of this work
makes assumptions (conditional independence, perfectly reliable data, well­
defined sample spaces) that may not characterize the natural environment.
Moreover, alternative normative models for making probabilistic inferences
have been developed based on assumptions different from those held by
Bayesians (Shafer 1976, Cohen 1977; also see Schum 1979 for a discussion
of Cohen). In fact, Cohen's model rests on a radically different system that
obeys rules quite different from the standard probability calculus. Compet­
ing normative models complicate the definition of what is a "bias" in
probability judgment and has already led to one debate (Cohen 1979,
Kahneman & Tversky 1979b). Such debate is useful if for no other reason
than it focuses attention on the conditionality of normative models. To
consider human judgment as suboptimal without discussion of the limita­
tions of optimal models is naive. On the other hand, we do not imply that
inappropriate optimal models always, or even usually, account for observed
discrepancies.
The definition of optimality offered above deals with a single criterion or
goal. However, actual judgments and choices typically are based on multi­
ple goals or criteria. When such goals conflict, as when they are negatively

<-----Page 4----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

BEHAVIORAL DECISION THEORY

57

correlated (e.g. quantity and quality of merchandise, cfCoombs & Avrunin
1977), there can be no optimal solution in the same sense as the single
criterion case (Shepard 1964). That is, the most one can do is to execute
the trade-offs or compromises between the goals that reflect one's values.
Therefore, the imposition of (subjective) values for resolving conflicts leads
to rejecting "objective" optimality and replacing it with the criterion of
consistency with one's goals and values. Furthermore, even the single g�al
situation is transformed into a multiple goal case when judgments and
choices are considered over time. For example, consider the single goal of
maximizing profit. Conflicts between short-run and longer-run strategies
can exist even with a single well-defined criterion. Therefore, unless a time
horizon is specified, optimality can also be problematic in what might seem
to be simple situations.

Environment vs Problem Space
The importance to behavior of the cognitive representation of the task, i.e.
"problem space," has been emphasized by Newell & Simon (1972). It is now
clear that the process of representation, and the factors that affect it, are
of major importance in judgment and choice. Illustrations of the effects of
problem representation on behavior are found in work on estimating
probabilities via fault trees (Fischhoff, Slovic & Lichtenstein 1978); re­
sponse mode effects inducing preference reversals (Grether & Plott 1979);
coding processes in risky choice (Kahneman & Tversky 1979a); "problem
isomorphs" in problem solving (Simon & Hayes 1976); context effects in
choice (Aschenbrenner 1978, Tversky & Sattath 1979) and agenda setting
(plott & Levine 1978); purchasing behavior (Russo 1977); and causal sche­
mas in probability judgments (Tversky & Kahneman 1980a).
It is essential to emphasize that the cognitive approach has been con­
cerned primarily with how tasks are represented. The issue of why tasks are
represented in particular ways has not yet been addressed. However, given
functional arguments, this is a crucial issue in view of the way minor
contextual changes can lead to the violation of the most intuitively appeal­
ing normative principles, e.g. transitivity.
The reconciliation of persistent errors and biases with functional argu­
ments has taken two forms. First, it has been claimed that such effects can
be overcome by increasing incentives (through higher payoffs and/or pun­
ishments). In one sense, this argument is irrefutable since it can always be
claimed that the incentive wasn't high enough. However, direct evidence
shows that increased payoffs do not necessarily decrease extreme overconfi­
dence (Fischhoff, Slovic & Lichtenstein 1977) nor prevent preference rever­
sals (Grether & Plott 1979). Furthermore, the indirect evidence from
clinical judgment studies in naturally occurring settings, where payoffs are

<-----Page 5----->58

EINHORN & HOGARTH

presumably high enough to be motivating, continues to indicate low validity
and inferiority to statistical models (Dawes 1979). In addition, claims that
people will seek aids and/or experts when the stakes are high (Edwards
1975) are predicated on the assumptions that:
don't know; and

(b)

(a )

people know that they

they know (or believe) that others do. On the other

hand, it is foolish to deny that payoffs, and thus motivation, have no effect
on processes of judgment and choice. Indeed, one only needs to recall the
fundamental insight of signal detection theory (Green & Swets 1966), which

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

is that both cognitive and motivational components affect judgment (also
see Killeen 1978).
A second way of reconciling biases with functional arguments involves
enlarging the context in which performance is evaluated. This has taken
four forms: 1. One view of evolutionary theory (as espoused by the sociobi�
ologists; for example, Wilson 1978) could lead to the belief that the human
system represents the optimal design for a complex environment. Heuristics
exist because they serve useful functions and their benefits outweigh their
costs. While this view is often espoused, there is surprisingly little evidence
to support it. An important exception is the simulation study by Thorngate

(1980), where it was shown how heuristics can often pick the best of several
alternatives across a range of tasks. However, neither this study nor any
other that we are aware of has considered the distribution of tasks in the
natural environment in which heuristics would work well or poorly. 2.
Hogarth (1980a) has argued that most judgments and choices occur sequen­
tially and that many biases reflect
in dynamic environments. Furthermore, the static tasks typically investi­
gated reflect
which optimal models can be constructed.

3. Toda (1962) has claimed that

it is the coordination of behavior that reflects
individual and thus isolated actions. Furthermore, coordination between
functions requires trade-offs and these can be facilitated by limitations (e.g.
a limited memory facilitates efficient forgetting of needless detail).

4. Cost/

benefit analyses can be expanded to include "the cost of thinking" (Shugan
1980), which seems compatible with notions of bounded rationality.
While there is much merit in the above arguments, care must be taken
since they can easily become tautological; i.e. costs and benefits can be
defined post hoc in accord with a presumption of optimality. However, can
there be actual dysfunctional behavior (rather than seeming dysfunctional
behavior) that persists, and if so, by what mechanism(s)?
Since functional arguments rest on evolutionary theory, it is easy to
overlook the fact that nonadaptive behavior can also be compatible with
principles of natural selection: 1. Biological evolution is directly related to
the amount of variance in the genotype (Lewontin 1979). For example, the

<-----Page 6----->BEHAVIORAL DECISION THEORY

59

development of wings could be functional for humans on many occasions.
However, without an appropriate mutation (the chance of which is minis­
cule), such evolution cannot take place. While it is evident that physical
limitations preclude certain types of behavior regardless of incentives to the
contrary, biological limitations can also preclude certain cognitive opera­
tions (Russo

1978). For example, the study of memory indicates limitations
(1970) has

on short-term storage and retrieval. Furthermore, Seligman

explicated biological limitations in the learning process itself. Cognitive

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

limitations can therefore persist and be dysfunctional (relative to given
goals) for the same reasons that account for physical limitations. 2. The
time-frame of human biological evolution is such that it can be considered
constant over many generations. It is thus difficult to determine whether
any current trait or mechanism is becoming more or less adaptive, or is a
vestige without apparent function (e.g. the human appendix: see also Skin­
ner

1966). Therefore, without denying general costibenefit considerations

over the very long run, dysfunctional behaviors may persist for extremely
long periods by human standards. The demise of the dinosaur, for example.
is popularly cited as an example of the effectiveness of natural selection.

160 million
2.5 million years old (Sagan 1977). 3.

However, it is easy to forget that dinosaurs existed for about
years. So far, humans are a mere

Humans adapt the environment to their own needs as well as adapting to
the environment. For example, poor eyesight is certainly dysfunctional. yet
a major judgment aid, eye glasses, has been invented to deal with this
problem. Furthermore. note that this aid actually works against natural
selection, i.e. those with poor vision will not be selected against since their
survival chances are now equal to those without the need for glasses. In fact,
if poor eyesight were correlated with higher reproductive rates. there would
be an increase in the aggregate level of this deficiency.

4. The analogy has

been drawn between learning and evolution (e.g. Campbell 1960). However.
the attempt to link individual learning with species level survival is prob­
lematic (Lewontin 1979). For example, consider whether response competi­
tion within an organism can be viewed as identical to competition between
organisms. While the latter can and has been analyzed via game theoretic
ideas of zero-sum payoffs and conflicting interests, such an approach seems
foreign to intraindividual response competition.

Intuitive Responses and Optimal Models
The above arguments leave us on the horns of a dilemma. Given the
complexity of the environment, it is uncertain whether human responses or
optimal models are more appropriate. Furthermore, we know of no theory
or set of principles that would resolve this issue. Indeed. the optimal­
intuitive comparison presents the following paradox: Optimal models have

<-----Page 7----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

60

EINHORN & HOGARTH

been suggested to overcome intuitive shortcomings. However, in the final
analysis the outputs of optimal models are evaluated by judgment, i.e. do
we like the outcomes, do we believe the axioms to be reasolllible, and should
we be coherent?
If the assessment of rationality ultimately rests on judgment, what are its
components? To discuss this, imagine being a juror in a trial and having to
decide whether someone who has committed a heinous crime acted "ratio­
nally." The prosecution argues that the crime was meticulously planned and
carried out, thus demonstrating that the person was in complete control of
what he/she was doing. Note that this argument defines rationality by the
efficiency with which means are used to attain ends. Moreover, this manner
of defining rationality is exactly what decision theorists have stressed, that
is, given one's goals, what is the best way of attaining them. However, the
defense argues that the goal of committing such a crime is itself evidence
of irrationality. That is, rationality is to be judged by the goals themselves.
Moreover, the argument is made that the deliberative way such despicable
goals were reached is itself an indication of irrationality. Finally, the defense
argues that when one understands the background of the defendant (the
poverty, lack of parental love, etc), the irrational goals are, in fact, reason­
able. This last point emphasizes that goals can only be understood within
the person's task representation. Moreover, this argument highlights a
crucial problem; namely, to what extent should one be responsible for one's
task representation (cf Brown 1 978)?
What are the implications of the above for behavioral decision theory?
First, jUdgments of rationality can be conceptualized as forming a con­
tinuum which can be dichotomized by imposing a cutoff when actions must
be taken. This idea has been advanced by Lopes (1 980) with respect to
judging randomness. Moreover, she suggests that the placement of the
cutoff can be viewed within a signal-detection framework; i.e. payoffs and
costs are reflected by the cutoff point. Second, judged rationality is a mix­
ture of the efficiency of means to ends (called "instrumental rationality,"
Tribe 1 973) and the "goodness" of the goals themselves (cf Brown 1 978).
While the former is familiar to decision theorists, the latter is the concern
of moral philosophers, theologians, and the like. However, at a practical
level it is of concern to all. In fact, it may well be that the efficacy of decision
aids comes from structuring tasks so that the nature of one's goals is
clarified (Humphreys & McFadden 1980). Third, the importance of behav­
ioral decision theory lies in the fact that even if one were willing to accept
instrumental rationality as the sole criterion for evaluating decisions,
knowledge of how tasks are represented is crucial since people's goals form
part of their models of the world. Moreover, their task representation may
be of more importance in defining errors than the rules they use within that
representation. For example, imagine a paranoid who processes information

<-----Page 8----->BEHAVIORAL DECISION THEORY

61

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

and acts with remarkable coherence and consistency. Such coherence of
beliefs and actions is likely to be far greater than in so-called "normal"
people (when does coherence become rigidity?) Thus, the representation of
the world as a place where others persecute one is the source of difficulty,
and not necessarily the incorrect or inconsistent use of inferential rules or
decision strategies.

STRATEGIES AND MECHANISMS OF JUDGMENT
AND CHOICE
The inescapable role of intuitive judgment in decision making underscores
the importance of descriptive research concerned with how and why pro­
cesses operate as they do. Moreover, the most important empirical results
in the period under review have shown the sensitivity of judgment and
choice to seemingly minor changes in tasks. Such results illustrate the
importance of context in understanding behavior in the same way that the
context of a passage affects the meaning of individual words and phrases.
We consider context to refer to both the formal structure and the content
of a task. On the other hand, normative models gain their generality and
power by ignoring content in favor of structure and thus treat problems out
of context (cf Shweder 1 979). However, content gives meaning to tasks and
this should not be ignored in trying to predict and evaluate behavior. For
example, consider the logical error of denying the antecedent; i.e. "if A, then
B", does not imply "if not-A, then not-B." However, as discussed by Harris
& Monaco (1978), the statement: "If you mow the lawn (A), I'll give you
$5 (B)", does imply that if you don't mow the lawn (not-A) you won't get
the $5 (not-B). Or consider a choice between a sure loss of $25 and a gamble
with 3 : 1 odds in favor of losing $ 1 00 vs $0. Compare this with the decision
to buy or not buy an insurance policy for a $25 premium to protect you
against a .75 chance of losing $ 100. Although the two situations are struc­
turally identical, it is possible for the same person to prefer the gamble in
the first case yet prefer the insurance policy in the second (for experimental
results, see Hershey & Schoemaker 1 980a). Such behavior can be explained
in several ways: (a) the person may not perceive the tasks as identical since
content can hide structure (Einhorn 1980); and (b) even if the two situations
are seen as having identical structure, their differing content could make
their meaning quite different. For example, buying insurance may be seen
as the purchase of protection (which is good) against the uncertainties of
nature, while being forced to choose between two painful alternatives is
viewed as a no-win situation.
While context has typically been defined in terms of task variables, it is
clear from the above examples that it is also a function of what the person
brings to the task in the way of prior experience via learning, and biological

<-----Page 9----->62

EINHORN & HOGARTH

limitations on attention, memory, and the like, that affect learning. There­
fore, the elements of a psychological theory of decision making must include
a concern for task structure, the representation of the task, and the informa­
tion processing capabilities of the organism.
In order to discuss specific findings in the literature, we artificially decom­
pose processes of judgment and choice into several subprocesses, namely,
information acquisition, evaluation, action, and feedbackllearning. We are
well aware that these subprocesses interact and that their interaction is of

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

great importance in the organization and coordination of decision making.
Accordingly, we consider these issues within subsections where appropri­
ate.

The Role of Acquisition in Evaluation
Much work in judgment and choice involves the development and testing
of algebraic models that represent strategies for evaluating and combining
information (see Slovic & Lichtenstein
tion continues (e.g. Anderson

1971). Although work in this tradi­
1979), it has been accompanied by increasing

dissatisfaction in that processes are treated in a static manner; i.e. judgments
and choices are considered to be formed on the basis of information that
is given. In contrast, the process of information search and acquisition
should also be considered (cf Elstein, Shulman & Sprafka

1978) since

evaluation and search strategies are interdependent. In fact, the evaluation
strategies proposed in the literature imply various search processes either
explicitly (e.g. Tversky & Sattath 1979) or implicitly (payne 1976). Of great
importance is the fact that the concern for how information is acquired
raises questions aoout the role of attention and memory in decision making

1980b,
1980). Furthermore, concern for the dynamics of information

that have received relatively little concern (however, see Hogarth
Rothbart

search has necessitated the use of different methodologies; e.g. process­
tracing approaches such as verbal protocols and eye movements, as well as
information display boards (Payne 1976). However, these methods need not
replace more general modeling efforts and may in fact be complementary
to them (payne, Braunstein & Carroll 1978; Einhorn, Kleinmuntz & Klein­
muntz

1979).

The importance of considering the interdependence of evaluation and
acquisition can be seen in considering the issue of whether people lack
insight into the relative importance they attach to cues in their judgment
policies. The literature contains conflicting evidence and interpretations
(Nisbett & Wilson

1977, Schmitt & Levine 1977). However, the use of

weights in models as reflecting differential cue importance ignores the im­
portance of attention in subjective weight estimates and illustrates our
emphasis on understanding persons and tasks. Correspondence between
subjective and statistical weights requires that people attend to and evaluate

<-----Page 10----->63

BEHAVIORAL DECISION THEORY

cues and that such cues contain both variance and low intercorrelations.
Disagreement between sUbjective and statistical weights can thus occur for
three reasons: I . people indeed lack insight; 2. people attend to, but cannot
use, cues that lack variance (Einhorn et aI 1 979); 3. cues to which attention
is not paid are correlated with others such that the nonattended cues receive
inappropriate statistical weights. Both process-tracing methods and statisti­
cal modeling are necessary to untangle these competing interpretations.

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

Acquisition
Acquisition concerns the processes of information search and storage­
both in memory and the external environment. Central to acquisition is the
role of attention since this necessarily precedes the use and storage of
information. We discuss attention by using an analogy with the perceptual
concept of figure-ground noting that, as in perception, the cognitive decom­
position of stimuli can be achieved in many ways. Accordingly, different
decompositions may lead to different task representations (cf Kahneman &
Tversky 1 979a). Indeed, context can be thought of as the meaning of figure
in relation to ground.
In an insightful article, Tversky ( 1 977) analyzed the psychological basis
of similarity judgments, and in so doing emphasized the importance of
context and selective attention in judgmental processes. He first noted that
our knowledge of any particular object "is generally rich in content and
complex in form. It includes appearance, function, relation to other objects,
and any other property of the object that can be deduced from our general
knowledge of the world" (p. 329). Thus, the process of representing an
object or alternative by a number of attributes or features depends on prior
processes of selective attention and cue achievement. Once features are
achieved, the similarity between objects a and b, s(a,b), is defined in terms
of feature sets denoted by A and B, respectively. Thus,

s(a,b)

=

() I(An B) - a I(A-B) - f3 fiB-A)

1.

where An B
features that a and b have i n common; A-B, B-A
distinctive features of a and b, respectively; I
salience of features; and
fJ, a, and f3 are parameters. Note that Equation I expresses s(a,b) as a
weighted linear function of three variables thereby implying a compensa­
tory combining rule. The importance of Equation I lies in the concept of
salience (j) and the role of the parameters. Tversky first defines salience as
the intensity, frequency, familiarity, or more generally the signal-to-noise
ratio of the features. Thereafter, the way in which the f scale and the
parameters depend on context are discussed. We consider three important
effects: asymmetry and focus, similarity vs difference, diagnosticity and
extension.
=

=

=

<-----Page 11----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

64

EINHORN & HOGARTH

Asymmetry in similarity judgments refers to the fact that the judged
similarity of a to b may not be equal to the similarity of b to a. This can
occur when attention is focused on one object as subject and the other as
referent. For example, consider the statements, "a man is like a tree" and
"a tree is like a man." It is possible to judge that a man is more like a tree
than vice versa, thus violating symmetry (and metric representations of
similarity). The explanation is that in evaluating s (a,b) vs s (b,a), a> fJ
in 1 ; i.e. the distinct features of the subject are weighted more heavily than
those of the referent. Hence, the focusing of attention results in differential
weighting of features such that symmetry is violated.
The similarity/difference effect occurs when a fJ and s (a,b) s(b,a).
In judging similarity, people attend more to common features, while in
judging difference, they attend more to distinctive features. This leads to the
effect in which "a pair of objects with many common and many distinctive
features may be perceived as both more similar and more different than
another pair of objects with fewer common and fewer distinctive features"
(Tversky 1 977, p. 340).
The first effect results from a shift in attention due to focusing on an
anchoring point (the subject). The second is caused by a shift in attention
induced by different response modes. The third effect, diagnosticity and
extension, involves changes in the salience of the features in an object due
to the specific object set being considered. For example, consider the feature
"four wheels" in American cars. Such a feature is not salient since all
American cars have four wheels. However, a European car with three
wheels on an American road would be highly salient. Therefore, salience
is a joint function of intensity and what Tversky calls diagnosticity, which
is related to the variability of a feature in a particular set (cf Einhorn &
McCoach 1 977). An important implication of diagnosticity is that the
similarity between objects can be changed by adding to (or subtracting
from) the set. For example, consider the similarity between Coca-Cola and
Pepsi-Cola. Now add 7-Up to the set and note the increased similarity of
the colas.
Although Tversky's paper is of great importance for judgment and
choice, it has not been linked to earlier concepts such as representativeness,
anchoring and adjusting, or availability. However, the question of context
and the figure-ground issues which und,erlie similarity would seem to be of
great importance in understanding these heuristics and their concomitant
biases as well as a wide range of phenomena in the literature. To illustrate,
we first discuss work on base rates.
Earlier work (reviewed in Slovic et a1 1 977) indicated that subjects ignore
base rates, and it was postulated that this resulted from use of the represen­
tativeness heuristic and/or the apparent salience of concrete or vivid infor=

=

<-----Page 12----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

BEHAVIORAL DECISION THEORY

65

mation (Nisbett et al 1976). However, a base rate can only be defined
conditional on some population (or sample space). Whereas many might
agree that the base rates defined by experimenters in laboratory tasks make
the sample space clear, the definition of the population against which judg­
ments should be normalized in the natural ecology is unclear. Consider an
inference concerning whether someone has a particular propensity to heart
disease. What is the relevant population to which this person should be
compared? The population of people in the same age group? The population
of the United States? Of Mexico? There is no generally accepted normative
way of defining the appropriate population. Thus, for naturally occurring
phenomena it is neither clear whether people do or do not ignore base rates,
nor whether they should (see also Goldsmith 1 980, Russell 1948).
Even in the laboratory, base rates are not always ignored. Indeed,
Tversky & Kahneman (1980a) have argued that base rates will be used to
the extent that they can be causally linked to target events. Their data
supported this hypothesis, and Ajzen ( 1977) independently reached similar
results and conclusions. A further implication of causal thinking concerns
asymmetries in the use of information; i.e. information that receives a causal
interpretation is weighted more heavily in judgment than information that
is diagnostic (although probability theory accords equal weight to both).
Whether such judgments are biased or not depends on whether one believes
that causality should be ignored in a normative theory of inference (as is
the case in standard probability theory; see Cohen 1 977, 1979 for a different
view).
Bar-Hillel (1980) further explicated the conditions under which base
rates are used. She argued that people order information by its perceived
degree of relevance to the target event (with high relevant dominating low
relevant information). Causality, Bar-Hillel argued, is but one way of induc­
ing relevance (it is sufficient but not necessary). Relevance can also be
induced by making target information more specific, which is tantamount
to changing the figure-ground relationship between targets and populations.
We believe that further elucidation of the role of causality in judgment is
needed (Mowrey, Doherty & Keeley 1979) and note that the notion of
causality, like probability, is conditional on the definition of a background
or "causal field" (Mackie 1 965).
Central to the distinction between figure and ground is the concept of cue
redundancy. As Gamer (1970) has stated, "good patterns have few alterna­
tives," i.e. cue redundancy helps achievement of the object and thus sharp­
ens figure from ground. Tversky ( 1977) makes the point that for familiar,
integral objects there is little contextual ambiguity; however, this is not the
case for artificial, separable stimuli. For example, consider the differential
effects of acquiring information from intact or decomposed stimuli (the

<-----Page 13----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

66

EINHORN & HOGARTH

former being more representative of the natural ecology, the latter of experi­
mental tasks). Phelps & Shanteau (1978) have shown that when expert
livestock judges are presented with information in the form of 11 decom­
posed, orthogonal attributes of sows, they are capable of using all the
information in forming their judgment; however, when presented with in­
tact stimuli (photographs), their judgments can be modeled by a few cues.
These results illustrate that people can handle more information than previ­
ously thought; moreover, they can be interpreted as indicating that cue
redundancy in the natural ecology reduces the need for attending to and
evaluating large numbers of cues. Redundancy in the natural ecology also
implies that cues can indicate the presence of other cues and can thus lead
one to expect cue co-occurrences. For example, in a study of dating choice,
Shanteau & Nagy (1979) showed that subjects used cues not presented by
the experimenters. That is, when choosing between potential dates from
photographs, subjects' choices were influenced by the probability that their
requests for dates would be accepted even though this cue was not explicitly
given.
The importance of redundancy in acquisition has been discussed by
Einhorn et al (1979), who note the following benefits: "(a) Information
search is limited without large losses in predictive accuracy; (b) attention
is highly selective; (c) dimensionality of the information space is reduced,
thereby preventing information overload; (d) intersubstitutability of cues is
facilitated; and (e) unreliability of cues is alleviated by having multiple
measures of the same cue variable" (p. 466). Studies and models that fail
to consider cue redundancy in search processes are thus incomplete. For
example, consider risky choice in the natural ecology vs the laboratory (for
reviews of risk see Libby & Fishburn 1977, Vlek & Stallen 1980). In the
former, probabilities are typically not explicit and must be judged by what­
ever environmental cues are available. A particularly salient cue is likely to
be the size of the payoff itself, especially if people have beliefs about the
co-occurrence of uncertainty and reward (e.g. large payoffs occur with small
probabilities). Thus, payoff size can be used as a cue to probability (cf
Shanteau & Nagy 1979). Moreover, the degree of perceived redundancy
may also be important in understanding issues of ambiguity in decision
making (cf Yates & Zukowski 1976). That is, one's uncertainty about a
probability estimate (so-called second order probability) may be related to
a variety of cues, including payoff size. In fact, Pearson (1897) noted that
although means and variances of distributions are usually treated as inde­
pendent, in the natural ecology they tend to be correlated and can thus be
used as cues to each other. The analogy to means and variances of payoff
distributions from gambles seems useful.

<-----Page 14----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

BEHAVIORAL DECISION THEORY

67

The temporal order of information acquisition can also affect salience,
both by creating shifts in figure-ground relations and differential demands
on attention and memory. Consider, for example, the effects of simulta­
neous vs sequential information display. In a study of supermarket shop­
ping, Russo (1977) found that when unit prices were presented to shoppers
in organized lists (ordered by relative size of unit prices, hence simultaneous
presentation), purchasing behavior was changed relative to the situation
where shoppers either did not have unit price information or such informa­
tion was simply indicated next to products on the shelves (the latter imply­
ing sequential acquisition). An interesting aspect of this study is that it
represents a form of decision aiding quite different from those proposed in
earlier work. That is, instead of helping people to evaluate information that
has already been acquired (e.g. through bootstrapping or multiattribute
models), one eases strain on memory and attention by aiding the acquisition
process itself. However, that greater understanding of attention and mem­
ory processes is necessary for this approach to be successful was under­
scored in a study by Fischhoff et al (1 978) on the use of "fault trees." Fault
trees are diagnostic check lists represented in tree-like form. The task
studied by Fischhoff et al (1 978) involved automobile malfunction and had
both experts (i.e. automobile mechanics) and novices as subjects. The results
indicated that the apparently comprehensive format of the fault tree blinded
both expert and novice subjects to the possibility of missing causes of
malfunction.
Since information is normally acquired in both intact form and across
time (i.e. sequentially), determining the manner and amount of information
to be presented in acquisition aids is a subject of great importance. It raises
issues of both how external stimuli cue memory and the organization of
memory itself (Broadbent, Cooper & Broadbent 1 978; Estes 1980). Differ­
ent ways of organizing information, for example by attributes or by alterna­
tives in a choice situation, could have implications for task representation.
In addition, several recent studies of the "availability" heuristic (Tversky
& Kahneman 1 973) have further emphasized how ease of recall from mem­
ory has important effects on judgment (Kubovy 1 977). Moreover, experi­
menters should be aware that subjects interpret stimuli rather than respond
to them. For example, Tversky & Kahneman (l980a) show that when
information is presented in a manner involving an ambiguous time se­
quence, intuitive interpretations may reflect a reordering of that informa­
tion to conform to the time dependence of naturally occurring phenomena.
That the figure-ground relation at a particular point in time affects judg­
ment and choice has been demonstrated in a number of studies. A particu­
larly compelling example is given by Tversky & Kahneman (1980b): It is

<-----Page 15----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

68

EINHORN & HOGARTH

expected that a certain fiu will kill 600 people this year and you are faced
with two options: option 1 will save about 200 people; option 2 will save
about 600 people with probability of YJ and no people with probability of
%. Now consider a re-wording of the alternatives: option 1 will result in
about 400 people dying; option 2 gives a YJ probability that none will die
and a % chance that about 600 people will die. By a simple change in the
reference point induced by formulating the same problem in terms of lives
lost or saved, cognitive figure and ground are reversed, as were the choices
of a majority of subjects. Similar preference reversals can be obtained
through the isolation effect where sequential presentation of information
can isolate and hence highlight the common components of choice alterna­
tives. Aspects seen to be common to alternatives are cancelled out and the
choice process determined by comparing the distinctive features of the
alternatives.
Payne, Laughhunn & Crum (1979) have linked reference effects to the
dynamic concept of aspiration level and further illustrated how this affects
the encoding of outcomes as losses or gains relative to a standard (rather
than considering the overall wealth position implied by different end states).
Sequential effects in choice have also been demonstrated by Levine & Plott
(1977) and Plott & Levine (1978) in both field and laboratory studies. The
structure of an agenda was shown to affect the outcomes of group choice
by sequencing the comparisons of particular subsets of alternatives. Tversky
& Sattath (1979) have further considered implications of these effects within
individuals when sequential elimination strategies of choice are used. That
jUdgment should be affected in a relative manner by momentary reference
points should, however, come as no surprise (cf Slovic & Fischhoff 1977).
Weber's law predicts just this, and the prevalence of "adjustment and
anchoring" strategies in dynamic judgmental tasks is congruent with these
findings (Hogarth 1980a).
Cognitive figure-ground relations vary considerably on the ease with
which they can be reversed. On the one hand, the tendency not to seek
information that could disconfirm one's hypotheses (Mynatt, Doherty &
Tweney 1977, 1978) illustrates strong figure-ground relations where con­
firming evidence is attracted to the figure and possible disconfirming evi­
dence remains in the ground. Consider also the difficulty of reformulating
problem spaces in creative efforts where inversion of figure and ground is
precisely what is required. On the other hand, situations also arise where
figure and ground can invert themselves with minor fluctuations in atten­
tion, as in the case of "reversible figures" in perception. Whereas the anal­
ogy one could draw between "preference reversals" and "reversible figures"
is possibly tenuous, both do emphasize the role of attention. In particular,
its fluctuating nature implies that for certain types of stimulus configura-

<-----Page 16----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

BEHAVIORAL DECISION THEORY

69

tions, task representations can be unstable. Both choice and the application
of judgmental rules have often been stated to be inherently inconsistent and
hence probabilistic (Brehmer 1978, Tversky & Sattath 1 979). However, the
effects of fluctuating attention in producing such inconsistencies has not
been explored.
Lest it be thought that the importance of attention in acquisition is
limited to descriptive research, Suppes (1966) has stated: "What I would
like to emphasize . . . is the difficulty of expressing in systematic form the
mechanisms of attention a rationally operating organism should use" (p.
64). Furthermore, Schneider & Shiffrin ( 1 977) have raised the possibility
that attention is not completely under conscious control. Thus the norma­
tive problem posed by Suppes takes on added difficulty.

Evaluation/Action
Imagine that you are faced with a set of alternatives and have at your
disposal the following evaluation strategies: conjunctive, disjunctive, lexico­
graphic, elimination by aspects, additive, additive difference, mUltiplicative,
majority of confirming instances, or random. Furthermore, you could also
use combinations of any number of the above. How do you choose? The
wide range of strategies one can use in any given situation poses important
questions about how one decides to choose (Beach & Mitchell 1 978, Sven­
son 1 979, Wallsten 1980). For example, what environmental cues "trigger"
particular strategies? What affects the switching of rules? Are strategies
organized in some way (e.g. hierarchically), and if so, according to what
principles? Although there has been concern for meta-strategies, most nota­
bly in Abelson's "script" theory ( 1976), the need for general principles is
acute. This can be illustrated in the following way: each evaluation strategy
can be conceptualized as a multidimensional object containing such at­
tributes as speed of execution, demands on memory (e.g. storage and re­
trieval), computational effort, chance of making errors, and the like.
However, each strategy could also be considered as a metastrategy for
evaluating itself and others. For example, an elimination by aspects metas­
trategy would work by eliminating strategies sequentially by distinctive
attributes. However, the choice of a metastrategy would imply a still higher
level choice process thereby leading to an infinite regress.
The above emphasizes the need for finding principles underlying choice
processes at all levels. One appealing possibility suggested by Christensen­
Sza1anski (1978, 1980) is that of an over-riding costlbenefit analysis, which
can induce suboptimal behavior in particular circumstances. However, this
raises several issues: 1 . The meaning of costs and benefits is necessarily
dependent on task representation, and thus context. For example, a tax cut
can be viewed as a gain or a reduced loss (Kahneman & Tversky 1 979a; also

<-----Page 17----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

70

EINHORN & HOGARTH

see Thaler 1 980 for an illuminating discussion of how this affects economic
behavior). 2. Costibenefit "explanations" can always be applied after the
fact an4 thus become tautological (see earlier discussion). 3. The very notion
of balancing costs and benefits indicates that conflict is inherent in judgment
and choice. For instance, consider our earlier example of the options of
insuring against a possible loss versus facing a no-win situation. The former
can be conceptualized as an approach-avoidance conBict, the latter as an
avoidance-avoidance conflict. In fact, Payne et al (1 97 9) have demonstrated
the importance of considering the perceived conflict in choice in the follow­
ing way: Subjects first made choices between pairs of gambles. A constant
amount of money was then added or subtracted from the payoffs such that,
for example, an approach-avoidance gamble was changed to an approach­
approach situation. With gambles altered in this manner, systematic prefer­
ence reversals were found. Hence, while the structure of the gambles
remained unchanged, the nature of the conflict and the choices did not.
The importance of conflict in choice has been emphasized by Coombs &
Avrunin (1 977), who considered the joint effects of task structure and the
nature of pleasure and pain. They begin by noting the prevalence of single­
peaked preference functions (Le. nonmonotonic functions relating stimulus
magnitUde to preference) in a wide variety of situations. For example,
consider the usual belief that more money is always preferred to less. While
this violates single-peakedness, note that great wealth increases the risk of
being kidnapped, of social responsibility to spend wisely, of lack of privacy,
and so on. Thus, if one also considered these factors, it may be that there
is some optimal level beyond which more money is not worth the increased
trouble. Hence, there is an approach-avoidance conflict between the "utility
for the good" and the "utility for the bad." The nature of this conflict
eventuates in a single-peaked function, given the behavioral assumption that
"Good things satiate and bad things escalate" (p. 224). Therefore, at some
point, the bad becomes greater than the good and overall utility decreases.
(In the single object case, it is not central that the bad escalate, only that
it satiate at a slower rate than the good.)
The theory becomes more complex when objects are characterized on
mUltiple dimensions. For example, consider a number of alternatives that
vary on price and quality and suppose that some are both higher in price
and lower in quality than others. Such dominated alternatives would seem
to be eliminated quickly from further consideration. Indeed, the second
principle in the theory is just this; dominated options are ignored. Hence,
the alternatives that remain form a Pareto optimal set. While single-peaked­
ness requires stronger conditions than this, from our perspective the impor­
tant point is that the remaining set of alternatives highlights the basic
conflict; that is, higher quality can only be obtained at a higher cost.

<-----Page 18----->BEHAVIORAL DECISION THEORY

71

While the role of conflict in choice has received earlier attention (Miller
1959), its usefulness for elucidating psychological issues in decision making
has not been fully exploited (however, see Janis & Mann 1 977). We consider
some of these issues by examining the role of conflict in, respectively,
judgments of worth or value, deterministic predictions, and probabilistic
judgments. Subsequently, conflict in taking action is discussed.

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

Conflict in Judgment
Consider the conflict between subgoals or attributes when one is judging
overall value or worth. If dominated alternatives are eliminated, this will
result in negative correlations between the attributes of objects in the non­
dominated set, thereby insuring that one has to give up something to obtain
something else. The resolution of the conflict can take several forms, the
most familiar being the use of compensatory strategies (usually of additive
form, although multiplicative models have also been used, cf Anderson
1979). Psychologically, this approach can be thought of as conflict "con­
fronting" since conflict is faced and resolution achieved through compro­
mise. Of crucial concern in executing one's compromise strategy is the issue
of judgmental inconsistency (Hammond & Summers 1972). While the
origin of such inconsistency is not well understood (cf Brehmer 1 978), it has
often been considered as reflecting environmental uncertainty (Brehmer
1 976). However, inconsistency may exist in the absence of environmental
uncertainty. For example, price and quality can each be perfectly correlated
with overall worth, yet one could argue that this highlights the conflict and
thus contributes to inconsistency. Although the theoretical status of conflict
and inconsistency needs further development, it should be noted that meth­
ods for aiding people to both recognize and reduce conflict through compen­
satory compromise have been developed, and several applications are
particularly noteworthy (Hammond & Adelman 1976; Hammond, Mum­
power & Smith 1977).
Alternatively, conflict in judging overall worth can be resolved by avoid­
ing direct confrontation and compromise. Specifically, noncompensatory
strategies allow evaluation to proceed without facing the difficulties (com­
putational and emotional) of making trade-offs. As indicated above, the
conditions in both task and person that control strategy selection remain
relatively unchartered. However, in addition to the error/effort trade-offs
thought to influence such decisions (Russo 1 978), the existence of conflict
per se and the need to take it into account makes this issue problematic.
The evaluation of information in making predictions from multiple cues
raises further questions concerning conflict in judgment. In particular,
when a criterion is available for comparison One can consider conflict and
uncertainty to arise from several sources: uncertainty in the environment

<-----Page 19----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

72

EINHORN

&

HOGARTH

due to equivocal cue-criterion relations; inconsistency in applying one's
information combination strategy; and uncertainty regarding the weighting
of cues appropriate to their predictiveness. These three aspects and their
effects on judgmental accuracy have been considered in great detail within
the lens model framework (Hammond et al 1975). Moreover, the integra­
tion of uncertain and contradictory evidence, which is at the heart of
prediction, can be seen as an attempt to establish "compensatory balance
in the face of comparative chaos in the physical environment" (Brunswik
1943, p. 257). Brunswik called this process "vicarious functioning," and
Einhorn et al (1 979) have expanded on this to show that the compensatory
process captured in linear models can also be seen in the fine detail of
process-tracing models developed from verbal protocols. Furthermore, they
argued that linear models represent cognitively complex and sophisticated
strategies for information integration. However, the continued predictive
superiority of bootstrapping, and even equal-weight linear models over
clinical judgment (Dawes 1979), attests to the difficulty of establishing the
correct compensatory balance (also see Armstrong 1 978a, 1978b and
Dawes 1 977 for further work on the statistical vs clinical prediction contro­
versy).
The basic issues involved in studying deterministic predictive judgment
also underlie interest in probability judgment. That is, both are concerned
with the making of inferences from uncertain and conflicting datalevidence.
However, the different terminologies used in each approach reflect different
historical antecedents; the psychology of inference on the one hand, and a
formal theory of evidence (de Finetti, Savage) on the other. Formal ap­
proaches are concerned with developing general structures for inferential
tasks independent of specific content. However, as noted previously, the
psychology of inference is intimately concerned with both content and
structure. This distinction is central for understanding the discrepancies
between the outputs of formal models and intuitive processes found in
recent research. To illustrate, whereas causality has no role in probability
theory, it is important in human inference (Tversky & Kahneman 1 980a).
Moreover, the existence of causal schemas can lead to the reinforcement of
a person's cognitive model after receiving contradictory evidence, rather
than its revision. Schum (1980) has demonstrated the enormous statistical
intricacies involved in the Bayesian modeling of inferences made from
unreliable data. Indeed, one interpretation of this work is that a purely
formal approach cannot handle the evaluation of evidence in any relatively
complex task (such as a trial). The role of content, however, in simplifying
these tasks has not been explored. For example, the use of a heuristic such
as representativeness, which depends on content via similarity, takes on
added importance in a normative sense (cf Cohen 1979). That is, in the face

<-----Page 20----->BEHAVIORAL DECISION THEORY

73

of great complexity, the use of heuristics and content may be necessary to
induce structure.
The importance of heuristics in making inferences has long been recog­
nized (Polya

1941, 1954), and current interest in them seems well justified.

However, their present psychological status requires more specific ation (cf
Olson

1976). For example, the use of the same heuristic can lead to opposite
1980).

predictions (for an example concerning "availability," see Einhorn

In addition, the ease with which heuristics can be brought to mind to

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

explain phenomena can lead to their nonfalsifiability. For example, if repre­
sentativeness accounts for the nonregressiveness of extreme predictions, can
adjustment and anchoring explain predictions that are too regressive?
As in deterministic predictions, there has been much concern with the
accuracy of probabilistic judgment. However, measurement of accuracy
raises issues of defining criteria and the adequacy of samples. Moreover, in
the Bayesian framework subjective probabilities represent statements of
personal belief and therefore have no objective referent. Nonetheless, Baye­
sian researchers have borrowed relative frequency concepts to measure how
well probabilistic judgment is calibrated, i.e. the degree to which probability
judgments match empirical relative frequencies (Lichtenstein, Fischhoff &

1977) and what variables affect calibration (Lichtenstein & Fisc­
1977). Calibration has therefore become the accuracy criterion for

Phillips
hhoff

probabilistic judgment similar to the achievement index in the lens model.
Moreover, the research findings in the two paradigms are also similar; that
is, most people are poorly calibrated and even the effectiveness of training
is limited for generalizing to other tasks (Lichtenstein & Fischhoff 1980).

Judgment

=

Choice?

Is judgment synonymous with choice? The normative model treats them as
equivalent in that alternative x will be chosen over y if and only if u(x) >
u(y); i.e evaluation is necessary and sufficient for choice. However, from a
psychological viewpoint, it may be more accurate to say that while judg­
ment is generally an aid to choice, it is neither necessary nor sufficient for
choice. That is, judgments serve to reduce the uncertainty and conflict in
choice by processes of deliberative reasoning and evaluation of evidence.
Moreoever, taking action engenders its own sources of conflict (see below)
so that judgment may only take one so far; indeed, at the choice point,
judgment can be ignored. The distinction between judgment and choice,
which is blurred in the normative model, is exemplified in common lan­
guage. For example, one can choose in spite of one's better judgment
whereas the reverse makes little sense.
The distinction made above should not be construed to mean that judg­
ment and choice are unrelated. In many situations they are inseparable. For

<-----Page 21----->74

EINHORN

&

HOGARTH

example, consider diagnostic and prognostic judgments and the choice of
treatment in clinical situations. It seems unthinkable that the choice of
treatment could proceed without prior diagnosis and prognosis. More gen­
erally, this example illustrates several further points: 1. since judgment is
deliberative, there must be sufficient time for its formation;

2.

deliberation

can itself be affected by the size of payoffs�.g. people may invest in
judgment to insure against accusations of irresponsibility from others and
from oneself in the event of poor outcomes (cf Hogarth 1980b);

3. when

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

alternatives are ordered on some continuum, a quantitative judgment may

be necessary to aid choice, as when choosing a therapy that varies in
intensity. These examples point to the importance of considering the condi­
tions under which jUdgment and choice are similar or different, a crucial
question that has barely been posed.

Conflict in Action
The conflict inherent in taking action, as distinct from conflict in judgment,
occurs because action implies greater commitment (cf Beach & Mitchell
1978, Janis & Mann 1977). Such commitment induces conflict in several
ways: 1. Whereas the existence of alternatives implies freedom to choose,
the act of choice restricts that very freedom. Hence, keeping "one's options
open" is in direct conflict with the need to take action.

2.

Given a set of

nondominated alternatives, Shepard ( 1964) has stated, " . . . at the moment
when a decision is required the fact that each alternative has both advan­
tages and disadvantages poses an impediment to the attainment of the most
immediate sub-goal; namely, escape from the unpleasant state of conflict
induced by the decision problem itself' (p. 277). Thus, conflict is inherent
in choice as an attribute of the choice situation.

3. Unlike judgments, actions

are intimately tied to notions of regret and responsibility. For example,
consider the decision to have children faced by married career women. An
important component in this choice may involve imagining the regret asso­
ciated with both alternatives later in life. Or imagine the conflict involved
in choosing a place to live and work where the responsibility to oneself and
one's family do not coincide.
As with the resolution of conflict in judgment, conflict resolution in
action can involve either avoidance or confrontation. One important form
of avoidance is to not choose. Corbin (1980) has recognized the importance
of the "no choice" option noting that it can take three forms: refusal, delay,
and inattention. Moreover, she notes that attraction to the status quo has
two advantages: it involves less uncertainty, and there may be "less respon­
sibility associated with the effects of 'doing nothing' than with some con­
scious choice" (Corbin 1980). Toda ( 1980a) points out that people often
make "meta-decisions" (e.g. to smoke), to avoid the conflict of having to

<-----Page 22----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

BEHAVIORAL DECISION THEORY

75

continually decide on each of many future occasions. Thaler & Shiffrin
(1980) further point out the importance of developing and enforcing self­
imposed rules (rather than allowing oneself discretion) in avoiding conflicts
in self-control problems.
Although choice involves considerable conflict, the mode of resolution
typically considered in the literature is a confronting, compensatory strat­
egy embodied in the expected utility model. This model is based on the
following tenets: 1 . The expected utility, E(U), of a gamble whose payoffs
are x and y with probabilities p and q (p + q = 1 .0), is given by E(U) =
P u (x) + q u(y). Note from the formulation that: (a) the rule says that the
evaluation of a gamble is a weighted average of future pleasures and pains,
where the weights are probabilities of attaining these outcomes; (b) the
evaluation is solely a function of utility and probability, there being no
utility or disutility for gambling per se; (c) the rule assumes that payoffs are
independent of probabilities, i.e. wishful thinking (optimism) or pessimism
are not admissible; (d) there is no inconsistency or error in executing the
rule. Thus, although the rule specifically deals with the uncertainty of future
events, it does not consider the evaluation process itself to be probabilistic
(however, see Luce 1977). Moreover, choice is assumed to follow evaluation
by picking the alternative with the highest E(U). 2. The theory assumes that
the utility of payoffs is integrated into one's current asset position. Hence,
final asset positions determine choice, not gains and/or losses. 3. Although
not central to E(U), it is generally assumed that people are risk averse, i.e.
utility is marginally decreasing with payoff size.
Whereas the E(U) model has been proposed as a prescriptive theory,
much confusion exists in that it has been used extensively to both explain
and predict behavior. However, while the descriptive adequacy of E(U) has
been challenged repeatedly (Anderson & Shanteau 1970, Slovic et aI 1977),
Kahneman & Tversky's "prospect theory" (1979a) represents a major at­
tempt at an alternative formulation. Since elements of this theory are dis­
cussed throughout this review, we only consider the proposed evaluation
model. Prospect theory superficially resembles the E(U) model in that · the
components involve a value function, v; decision weights, 71'(p); and a
compensatory combining rule. However, the value function differs from
utility in that: 1. It is defined on deviations from a reference point [where
v(O) = 0] rather than being defined over total assets. Furthermore, the
reference point may be either identical to or different from the asset position
depending on a number of factors (somewhat akin to Helson's adaptation
level). 2. It is concave for gains but convex for losses inducing "reflection
effects" via risk aversion for gains and risk seeking for losses. For example,
consider the choice between $3000 and a .50 chance at $6000 or O. While
many would prefer the sure gain of $3000 to the gamble (thus exhibiting

<-----Page 23----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

76

EINHORN & HOGARTH

risk aversion), if the sign of the payoff is changed, e.g. -$3000 or a .50
chance at -$6000 or 0, they might prefer the gamble to the sure loss. Note
that the reflection effect contradicts the widely held belief that people gener­
ally abhor and seek to avoid uncertainty (Hogarth 1975, Langer 1977). 3.
It is steeper for losses than gains, i.e. the pain of losing is greater than the
pleasure of winning an equal amount.
Although decision weights are not subjective probabilities as such, they
reflect the impact of uncertainty on the evaluation of prospects (gambles)
and are transformations of probabilities. They have several interesting prop­
erties; for example, the sum of complementary decision weights does not
sum to one (subcertainty), and small probabilities are overweighted. These
properties, when combined with those of the value function in bilinear form
induce overweighting of certainty (thus resolving Allais' paradox), viola­
tions of the substitution axiom, and avoidance of probabilistic insurance.
Karmarkar ( 1 978, 1 979) was also able to explain many similar violations
of the E(U) model by transforming probabilities into weights (using a single
parameter) and then incorporating them in what he called a SUbjectively
weighted utility model.
Although the above models are an important step in analyzing choice
behavior, March ( 1 978) has made a penetrating analysis of the deficiencies
in conceptualizing tastes/preferences in such models. He points out that
people are often unsure about their preferences (see also Fischhoff, Slovic
& Lichtenstein 1980) and that uncertainty concerning future preferences
complicates the modeling of choice. For example, how does one model the
knowledge that one's tastes will change over time but in unpredictable
ways? Moreover, although instability and ambiguity of preferences are
treated as deficiencies to be corrected in normative approaches and as
random error in descriptive models, March ( 1 978) points out that " . . . goal
ambiguity like limited rationality, is not necessarily a fault in human choice
to be corrected but often a form of intelligence to be refined by the technol­
ogy of choice rather than ignored by it" (p. 598).
The management of conflict induced by unstable preferences over time
is also central to self-control (Thaler 1980). The recognition that one's tastes
can change, and that such changes are undesirable, leads to precommitment
strategies to prevent the harm that follows such changes. For example,
consider saving money in Christmas clubs which pay no interest but which
restrict the freedom to withdraw money before Christmas in order to pro­
tect one against one's self. Such behavior is difficult to explain without resort
to a multiple-self model (Freud 1 923, Sagan 1 977, Toda 1980b). Conceptu­
alizing decision conflict as the clash between multiple selves is a potentially
rich area of investigation and could provide useful conceptual links between
phenomena of individual and group behavior. For example, individual

<-----Page 24----->BEHAVIORAL DECISION THEORY

77

irrationality might be seen as similar to the various voting paradoxes found
in group decision making (Plott 1 976).

LEARNING/FEEDBACK

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

•

The beginning of this review indicated a questioning of the basic assumption
upon which functional and adaptive arguments rest, namely, the ability to
learn. We now consider this in light of our discussion of heuristic and other
rule-based behavior. For example, how are rules tested and maintained (or
not) in the face of experience? Under what conditions do we fail to learn
about their quality? Are we aware of our own rules?
Hammond (1978a) and Brehmer (1980) have discussed a number of
important issues bearing on the ability to learn from experience. The former
paper considers six "modes of thought" for learning relations between
variables which include: true experiments, quasi-experiments, aided judg­
ment, and unaided intuitive judgment. Moreover, these modes vary on six
factors, including the degree to which variables can be manipulated and
controlled, feasiblity of use, and covertness of the cognitive activity involved
in each. Hammond points out that the most powerful modes (involving
experimentation) are least feasible and thus not likely to be implemented.
Unfortunately, the least powerful modes are most feasible and hence most
common. Thus, correct learning will be exceptionally difficult since it will
be prey to a wide variety ofjudgmental biases (Campbell 1959). The serious­
ness of this is further emphasized by the seeming lack of awareness of the
inadequacy of unaided judgment. Brehmer (1 980) has further considered
the difficulties inherent in learning from experience by contrasting such
learning with laboratory studies (and formal learning through teaching).
The former is far more difficult in that: 1 . we don't necessarily know that
there is something to be learned; 2. or if we do, it is not clear what is to
be learned; and 3. there is often much ambiguity in judging whether we
have learned (e.g. what, if anything, did the U.S. learn from the
Viet Nam war?).
The general difficulties of learning from experience have also been dem­
onstrated in specific areas. For example, Shweder (1 977) has analyzed the
ability of adults to learn environmental contingencies and points out that:
1 . Whereas adults are capable of correlational reasoning, they frequently
use cognitive strategies that can result in the genesis and perpetuation of
myths, magic, and superstitious behavior. 2. Judgments of contingency are
frequently based on likeness and similarity. For example, the treatment of
ringworm by fowl excrement in primitive societies is based on the similarity
of symptoms to "cure." 3. Contingencies provide the links in structuring
experience by implying meaning through context. For example, "the trip

<-----Page 25----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

78

EINHORN & HOGARTH

was not delayed because the bottle shattered" can be understood when
speaking of "launching a ship."
The learning of contingencies between actions and outcomes is obviously
central for survival. Moreover, contiguity of actions and outcomes is an
important cue for inferring causality (Michotte 1 963) and thus for organiz­
ing events into "causal schemas" (Tversky & Kahneman 1 980a). A particu­
larly important type of contingent learning that has received little attention
involves the learning and changing of tastes and preferences. For example,
consider the unpleasant affect felt by a child after eating a particular vegetable, and the ensuing negative utility so learned; or imagine the changes in
the same child's taste for members of the opposite sex as he or she grows
older. Concern with the normative model, in which tastes are fixed, has
obscured important psychological questions about the nature oftastes/pref­
erences (cf March 1978).
The learning of action-outcome connections illustrates an obvious but
essential point, that is, learning occurs through outcome feedback (cf Pow­
ers 1 973). Moreover, since multiple actions must be taken over time, judg­
ment is often required to predict which actions will lead to specified
outcomes. Thus, feedback from outcomes is used to evaluate both judg­
ments and actions. This assumes that the quality of decisions can be assessed
by observing outcomes. Nonetheless, decision theorists have pointed out
that outcomes also depend on factors that people cannot control; hence,
decisions should be evaluated by the process of deciding. While there is
much merit in this argument, the distinction between good/bad decisions
and good/bad outcomes is strongly counterintuitive and may reflect several
factors: (a) people have a lifetime of experience in learning from outcomes;
(b) whereas process evaluation is complex, outcomes are visible, available,
and often unambiguous; and (c) evaluation of process is conditional upon
an appropriate representation of the task (see above). People cannot ignore
outcomes in evaluating decisions.
The role of outcome feedback has been studied extensively within a
number of probability learning paradigms. However, Estes (1976a,b) has
emphasized the importance of considering what is learned in such tasks. In
a series of experiments using simulated public opinion polls, he found that
subjects coded outcomes as frequencies rather than probabilities. Indeed, as
the history of probability indicates, the notion of probability was late in
developing, a key difficulty being the specification of the sample space (such
problems persist, see Bar-Hillel & Falk 1980). Einhorn & Hogarth ( 1 978)
note that the transformation of frequency into probability requires paying
attention to nonoccurrences of the event of interest as well as the event
itself. This added burden on attention and memory may thus favor the
coding of outcomes as frequencies rather than probabilities. Moreover, the

•

<-----Page 26----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

BEHAVIORAL DECISION THEORY

79

tendency to ignore nonoccurrences is intimately related to the lack of search
for disconfirming evidence (Wason & Johnson-Laird 1972, Mynatt et al
1 977, 1978). Furthermore, attempts to alter this tendency have been gener­
ally unsuccessful, although Tweney et al (1980) have reported some success.
Whether or not this tendency can be modified, we note that it is not limited
to scientific inference; e.g. how many people seek disconfirming evidence to
test their political, religious, and other beliefs by reading newspapers and
books opposed to their own views?
The implications of the above for learning from experience were explored
by Einhorn & Hogarth (1 978). They specifically considered how confidence
in judgment is learned and maintained despite low (and or even no) judg­
mental validity. The tasks analyzed are those in which actions are based on
an overall evaluative judgment and outcome feedback is subsequently used
to assess judgmental accuracy. However, the structure of this task makes
learning difficult in that: 1 . When jUdgment is assumed to be valid, out­
comes that follow action based on negative judgment, cannot typically be
observed. For example, how is one to assess the performance of rejected job
applicants? 2. Given limited feedback (which can also result from a lack of
search for disconfirming evidence), various task variables such as base rates,
selection ratios, and the self-fulfilling treatment effects of taking action per
se can combine to produce reinforcement through positive outcome feed­
back. Thus, one can receive positive feedback in spite of, rather than be­
cause of, one's judgmental ability. A formal model of this process was
developed in which outcomes were generated by combining various task
variables with the validity of judgment. The results indicated a wide range
of conditions where overconfidence in poor judgment can be learned and
maintained.
Of great importance to the issue of learning from experience is the role
of awareness of the task factors that can influence outcomes. This includes
the probabilistic nature of the task itself (cf Brehmer 1980), as well as other
task variables discussed in multiple-cue probability learning studies (Ham­
mond et aI 1975). Einhorn (1980) has discussed this issue within the concept
of outcome-irrelevant-Iearning-structures (OILS). This refers to the fact
that in certain tasks positive outcome feedback can be irrelevant or even
harmful for correcting poor judgment when knowledge of task structure is
missing or seriously in error. This concept is obviously similar to the notion
of "superstitious" behavior (Skinner 1948, Staddon & Simmelhag 1 97 1).
However, the concept of OILS raises the issue of what is reinforced (Wick­
elgren 1979). For example, consider a consumer who uses a conjunctive rule
when purchasing a wide range of products. It could be argued that positive
outcomes following purchases reinforce the use of the rule, the specific
behaviors, or both. This is a complex issue that would seem to depend on

<-----Page 27----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

80

EINHORN & HOGARTH

the extent to which people are aware of their own judgmental rules (Hayek
1962, Nisbett & Wilson 1977, Smith & Miller 1 978). That is, to what extent
are judgmental rules reinforced without awareness, and can inappropriate
rules be un learned? The importance of this question is that it raises the issue
of whether, or to what extent, procedures for correcting judgmental defi­
ciencies can be developed.
It is important to stress that awareness of task structure does not neces­
sarily lead to learning (see Castellan 1 977). Furthermore, it is possible to
choose not to learn. For example, consider a waiter in a busy restaurant who
believes he can predict those customers most likely to leave generous tips,
and the quality of his service reflects this prediction. If the quality of service
has a treatment effect on the size of the tip, the outcomes confirm the
prediction. With awareness of the task structure, the waiter could perform
an experiment to disentangle the treatment effects of quality of service from
his predictions; i.e. he could give poor service to some of those judged to
leave good tips and good service to some of those judged to leave poor tips.
Note that the waiter must be willing to risk the possible loss of income if
his judgment is accurate, against learning that his judgment is poor. There­
fore, there is conflict between short-run strategies for action that result in
reasonably good outcomes vs long-run strategies for learning that have
potential short-run costs. That is, would you be willing to risk the loss of
income by doing a real experiment in order to learn? This dilemma is quite
frequent, yet it is not clear that awareness of it would lead to the choice to
learn.

METHODOLOGICAL CONCERNS
The substantive matters discussed in this review raise various issues regard­
ing the methodology of decision research. We consider some of these by
posing the following questions: 1 . How can we know whether applications
of decision aids improve the quality of decisions? 2. How prevalent are
judgmental biases in the natural environment? 3. What methods are most
likely to provide insight into decision processes?
The review by Slovic et al (1 977) reported a growing number of applica­
tions of decision aids in a wide variety of fields and this growth continues
(see e.g. lungermann 1980 and references). However, it is appropriate to ask
whether such applications work and how one can know this. While care in
applying basic principles of experimental design involving consideration of
threats to internal and external validity are recognized in some applications
(cf Russo 1 977), many more can be characterized as one-shot case studies
where the experimental treatment is the decision aid or procedure. Al­
though painful, it might be remembered that such a design is scientifically
useless for assessing treatment efficacy. Moreover, the fact that clients are

<-----Page 28----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

BEHAVIORAL DECISION THEORY

81

likely to seek aid from decision analysts (broadly defined) when things are
not going well renders evaluation of pretest-posttest designs lacking control
groups particularly susceptible to regression effects.
The difficulties in evaluating decision aids have been noted by Fischhoff
(1980), who draws an analogy between decision analysis and psychother­
apy. He writes that, "like psychotherapy, decision analysis is advocated
because the theory is persuasive, because many clients say that it helps
them, because many practitioners are extremely talented and because the
alternative seems to be to sink back into an abyss (seat-of-the-pants decision
making)." Indeed, we note that decision analysis might be called "rational
therapy" if that term were not similar to one already in use (see Ellis 1 977
on "rational-emotive therapy"). The importance of Fischhoffs analogy is
twofold: it raises basic questions regarding the evaluation of decision aids,
and it provides some necessary (ifnot sufficient) motivation to do something
about it.
The issue concerning the prevalence of judgmental biases in the natural
environment raises familiar questions of external validity (Brunswik 1 956).
Ebbesen & Konecni (1980) have studied several judgment tasks within
laboratory and natural settings (e.g. setting of bail, driving a car) and have
found major differences in results. In reviewing these and other studies they
conclude:
There is considerable evidence to suggest that the external validity of decision making
research that relies on laboratory simulations of real-world decision problems is low.
Seemingly insignificant features of the decision task and measures cause people to alter
their decision strategies. The context in which the decision problem is presented, the
salience of alternatives, the number of cues, the concreteness of the information, the
order of presentation, the similarity of cue to alternative, the nature of the decomposi­
tion, the form of the measures, and so on, seem to affect the decisions that subjects make.

Given the above, the issue of external validity is not liable to be resolved
without recourse to theory that attempts to answer how tasks vary between
the laboratory and the natural environment and what kinds of effects can
be expected from such differences. Howell & Burnett (1978) have taken a
first step in this direction by proposing a cognitive taxonomy based on task
variables and response demands that affect judgments of uncertainty. How­
ever, greater concern with how people's experience influences their judg­
ment is needed. For example, Bar-Hillel (1979) has pointed out that
although people ignore sample size in certain laboratory studies, they seem
to judge sample accuracy by the ratio of sample size to population. Further­
more, she emphasizes that such a rule can be justified in the natural environ­
ment since one typically samples without replacement. For example,
"When dining out, one samples, without replacement, some dishes from a
menu and generalizes about the restaurant's quality. When shopping in a

<-----Page 29----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

82

EINHORN & HOGARTH

new store, one samples, without replacement, the price of several items and
judges how expensive the store is" (p. 250).
Lacking theoretical guidance, one has no recourse but to judge the preva­
lence ofjudgmental biases. There are two extreme views. The most optimis­
tic asserts that biases are limited to laboratory situations which are
unrepresentative of the natural ecology. However, Slovic et al ( 1 977) point
out that in a rapidly changing world it is unclear what the relevant natural
ecology will be. Thus, although the laboratory may be an unfamiliar envi­
ronment, lack of ability to perform well in unfamiliar situations takes on
added importance. The pessimistic viewpoint is that people suffer from
"cognitive conceit" (Dawes 1 976); i.e. our limited cognitive capacity is such
that it prevents us from being aware of its limited nature. Even in a less
pessimistic form, this view is highly disturbing and emphasizes the impor­
tance of further research on the factors which foster or impede awareness
of the quality of one's judgmental rules.
Both of the above positions presuppose the internal validity of the experi­
mental evidence concerning judgmental biases. However, Hammond
( 1978b) has criticized much of this research by pointing out the inadequacy
of exclusive reliance on between-subjects-designs for studying cognition.
For example, he notes that many experimental demonstrations of "illusory
correlation" rest on the incorrect specification of the sampling unit; i.e. the
sampling unit should be defined by the stimuli judged (within each person),
not the people doing the judging. Thus, while group data may indicate large
effects unless sufficient stimuli are sampled, no single individual can be
shown to exhibit the bias (see also Hershey & Schoemaker 1980b). However,
within-subjects designs can also be problematic in that effects due to mem­
ory when responding to stimuli across time (e.g. anchoring and carry-over)
may distort the phenomenon being studied (Greenwald 1 976). This is par­
ticularly important when considering possible biases in judgment made in
unique circumstances. Hence, the temporal spacing between administration
of stimuli is a crucial variable in within-subjects designs and its effects also
need to be studied.
While there is controversy regarding the appropriateness of different
experimental designs for studying decision processes, there is more agree­
ment on the need for multimethod approaches (Payne et al 1 978). Such
approaches, which can use methods as diverse as statistical modeling and
verbal protocols or eye movements, not only provide much needed evidence
on convergent validity, but may also be necessary to discriminate between
strategies that can result in identical outcomes (Einhorn et a1 1979, Tversky
& Sattath 1 979). Furthermore, in addition to positive scientific effects,
multimethod approaches may have the salutory effect of convincing re­
searchers that "truth" can be shared.

<-----Page 30----->BEHAVIORAL DECISION THEORY

83

Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

CONCLUSION

Decision making is a province claimed by many disciplines, e.g. economics,
statistics, management science, philosophy, and so on. What then should
be the role of psychology? We believe this can be best illustrated by the
economic concept of "comparative advantage." For example, how much
typing should the only lawyer in a small town perform (Samuelson 1948)?
Even if the lawyer is an excellent typist, it is to both his/her and the town's
advantage to concentrate on law, provided that typing is not a rare skill.
Similarly, we believe that psychologists can best contribute to decision
research by elucidating the basic psychological processes underlying judg­
ment and choice. Indeed, this review has tried to place behavioral decision
theory within a broad psychological context, and in doing so we have
emphasized the importance of attention, memory, cognitive representation,
conflict, learning, and feedback. Moreover, the interdependence and coordi­
nation of these processes suggest important challenges for understanding
complex decision making. In order to meet these, future research must
adopt a broader perspective (cf Carroll 1 980) by not only investigating the
topics discussed here, but also those not usually treated in the decision
literature (e.g. creativity, problem solving, concept formation, etc). Indeed,
given the ubiquity and importance of judgment and choice, no less a per­
spective will do.
ACKNOWLEDGMENT

We wish to thank Jay Russo for his many incisive comments on an earlier
draft of this review. We also wish to thank, the following people for their
suggestions and support: Maya Bar-Hillel, Nick Dopuch, Baruch Fischhoff,
Paul Hirsch, Ed Joyce, John Payne, Paul Schoemaker, Rick Shweder, and
Paul Slovic. The superb abilities of Charlesetta Nowels in handling the
preparation of this chapter are gratefully acknowledged.
Literature Cited
Abelson, R. P. 1976. Script processing in atti­
tude formation and decision making. In
Cognition and Social Behavior, ed. J. S.
. Carroll, J. w. Payne, pp. 3 3-46. Hillsdale, NJ: Erlbaum. 290 pp.
Ajzen, I. 1977. Intuitive theories of events
and the effects of base-rate information
on prediction. J. Pers, Soc. Psychol.
35:303-1 4
Anderson, N . H. 1979. Algebraic rules in
psychological measurement. Am. Sci.
67:555-63
Anderson, N. H., Shanteau, J. C. 1 970. Infor-

mation integration in risky decision
making. J. Exp. Psycho/, 84:44 1-5 1
Armstrong, J. S. 1978a. Long Range Fore­
casting. New York: Wiley. 6 1 2 pp.
Armstrong, J. S. 1 978b. Forecasting with
econometric methods: Folklore versus
fact. J. Bus. 5 1 :549-64
Aschenbrenner, K. M, 1978. Single-peaked
risk preferences and their dependability
on the gambles' presentation mode. J.
Exp. PsychoL-Hum. Percept. Perform.
4:5 1 3-20
Bar-Hillel, M. 1 979. The role of sample size

<-----Page 31----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

84

EINHORN & HOGARTH

in sample evaluation. Organ. Dehav.
Hum. Perform. 24:245-57
Bar-Hillel, M. 1 980. The base-rate fallacy in
probability judgments. Acta Psychol. In
press
Bar-Hillel, M., Falk, R. 1980. Some teasers
concerning conditional probabilities.
Presented at 1 8th Conf. Bayesian Infer­
ence and Decision Making, Univ.
South. Calif.
Beach, L. R., Mitchell, T. R. 1978. A contin­
gency model for the selection of deci­
sion strategies. Acad. Manage. Rev.
3 :439-49
Bettman, J. R. 1979. An Information Process­
ing Theory of Consumer Choice. Read­
ing, Mass: Addison-Wesley. 402 pp.
Brehmer, B. 1976. Note on clinical judgment
and the formal characteristics of clinical
tasks. Psychol. Bull. 83:778-82
Brehmer, B. 1978. Response consistency in
probabilistic inference tasks. Organ.
Behav. Hum. Perform. 22: 103- 1 5
Brehmer, B . 1 9 80. I n one word: Not from
experience. Acta Psychol. 45. In press
Broadbent D. E., Cooper, P. J., Broadbent,
M. H. P. 1978. A comparison of hierar­
chical and matrix retrieval schemes in
recall. J. Exp. Psychol-Hum. Learn.
Mem. 4:486-97
Brown, H. I. 1978. On being rational. Am.
Phi/os. Q. 1 5:241-48
Brunswik, E. 1943. Organismic achievement
and environmental probability. PsychoL
Rev. 50:255-72
Brunswik, E. 1956. Perception and the Repre­
sentative Design of Experiments. Ber­
keley: Univ. Calif. Press. 154 pp. 2nd
ed.
Campbell, D. T. 1959. Systematic error on
the part of human links in communica­
tion systems. In! Control 1 :334-69
Campbell, D. T. 1960. Blind variation and
selective retention in creative thought as
in other knowledge processes. PsychoL
Rev. 67:380-400
Carroll, J. S. 1980. Analyzing decision behav­
ior: The magician's audience. In Cogni­
tive Processes in Choice and Decision Be­
havior, ed. T. S. Wallsten. Hillsdale,
NJ: Erlbaum. In press
Castellan, N. J. Jr. 1977. Decision making
with multiple probabilistic cues. In Cog­
nitive Theory, ed. N. J. Castellan, O. B.
Pisoni, G. R. Potts, 2: 1 1 7-47. Hillsdale,
NJ: Erlbaum. 342 pp.
Christensen-Szalanski, J. J. J. 1978. Problem
solving strategies: A selection mecha­
nism, some implications, and some
data. Organ. Dehav. Hum. Perform.
22:307-23

Christensen-Szalanski, J. J. J. 1980. A further
examination of the selection of prob­
lem-solving strategies: The effects of
deadlines and analytic aptitudes. Organ.
Behav. Hum. Perform. 25:107-22
Cohen, L. J. 1977. The Probable and the Prov­
able. Oxford: Clarendon. 272 pp.
Cohen, L J. 1979. On the psychology of pre­
diction: Whose is the fallacy? Cognition
7:3 85-407
Coombs, C. H., Avrunin, G. S. 1977. Single­
peaked functions and the theory of pref­
erence. Psychol. Rev. 84:21 6-30
Corbin, R. M. 1 9 80. Decisions that might not
get made. See Carroll 1 9 80. In press
Dawes, R. M. 1976. Shallow psychology. See
Abelson 1976, pp. 3-1 1
Dawes, R. M. 1977. Case-by-case versus rule­
generated procedures for the allocation
of scarce resources. In Human Judg­
ment and Decision Processes in Applied
Settings, ed. M. F. Kaplan, S. Schwartz,
pp. 83-94. New York: Academic. 2 8 1
pp.
Dawes, R. M. 1979. The robust beauty of
improper linear models in decision
making. Am. Psychol 34:571-82
Ebbesen , E. B., Konecni, Y. J. 1980. On the
external validity of decision-making re­
search: What do we know about deci­
sions in the real world? See Carroll
1 980. In press
Edwards, W. 1975. Comment. J. Am. Stat.
Assoc. 70:291-93
Edwards, W. 1977. Use of multiattribute util­
ity measurement for social decision
making. In Conflicting Objectives in De­
cisions, ed. D. E. Bell, R. L. Keeney, H.
Raiffa, pp. 247-75. New York: Wiley.
442 pp.
Einhorn, H. J. 1980. Learning from experi­
ence and suboptimal rules in decision
making. See Carroll 1980. In press
Einhorn, H. J., Hogarth, R. M. 1978. Confi­
dence in judgment: Persistence of the
illusion of validity. Psychol. Rev.
85:395-416
Einhorn, H. J., Kleinmuntz, D. N., Klein­
muntz, B. 1979. Linear regression and
process-tracing models of judgment.
Psychol. Rev. 86:465-85
Einhorn, H. J., McCoach, W. P. 1977. A sim­
ple multiattribute utility procedure for
evaluation. Behav. Sci. 22:270-82
Ellis, A. 1977. The basic clinical theory of
rational-emotive therapy. In Handbook
ofRational-Emotive Therapy, ed. A. El­
lis, R. Grieger, pp. 3-34. New York:
Springer. 433 pp.
Elstein, A. S., Shulman, L. E., Sprafka, S. A.
1978. Medical Problem Solving: An
Analysis of Clinical Reasoning. Cam-

<-----Page 32----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

BEHAVIORAL DECISION THEORY
bridge, Mass: Harvard Univ. Press. 330
pp.
Estes, W. K. 1 976a. The cognitive side of
probability learning. Psychol. Rev.
83:37-64
Estes, W. K. 1 976b. Some functions of mem­
ory in probability learning and choice
behavior. In The Psychology ofLearning
and Motivation: Advances in Research
and Theory, ed. G. H. Bower, 10: 1--45.
New York: Academic. 247 pp.
Estes, W. K. 1 980. Is human memory obso­
lete? Am. Sci. 68:62-69
Fischholf, B. 1980. Decision analysis: Clini­
cal art or clinical science? In Human
Decision Making, Vol. I, ed. L. Sjoberg,
T. Tyszka, J. A. Wise. Bodafors, Swe­
den: Doxa. In press
Fischholf, B., Slovic, P., Lichtenstein. S.
1977. Knowing with certainty: The ap­
propriateness of extreme confidence. J.
Exp. Psychol -Hum. Percept. Perform.
3:552-64
Fischholf, B., Slovic, P., Lichtenstein, S.
1978. Fault trees: Sensitivity of esti­
mated failure probabilities to problem
representation. J. Exp. Psychol.-Hum.
Percept. Perform. 4:330--44
Fischholf, B., Slovic, P., Lichtenstein, S.
1980. Knowing what you want: Mea­
suring labile values. See Carroll 1980. In
press
Freud, S. 1 960. The Ego and the Id. New
York: Norton. Orginally published
1923. 67 pp.
Gamer, W. R. 1 970. Good patterns have few
alternatives. Am. Sci. 58:34--42
Goldsmith, R. W. 1980. Studies of a model
for evaluating judicial evidence. Acta
Psychol. 45. In press
Green, D. M., Swets, J. A. 1966. Signal De­
tection Theory and Psychophysics. New
York: Wiley. 455 pp.
Greenwald, A. G. 1976. Within-subjects de­
signs: To use or not to use? Psycho!
Bull. 83:3 1 4-20
Grether, D. M., Plott, C. R. 1979. Economic
theory of choice and the preference re­
versal phenomenon. Am. Econ. Rev.
69:623-38
Hammond, K. R. 1978a. Toward increasing
competence of thought in public policy
formation. In Judgment and Decision in
Public Policy Formation, ed. K. R.
Hammond, pp. 1 1-32. Denver: West­
view. 1 75 pp.
Hammond, K. R. 1978b. Psychology's Scien­
.tiftc Revolution: Is It in Danger? Univ.
Colo. Inst. Behav. Sci. Cent. Res. Judg­
ment and Policy, Rep. No. 2 1 1
Hammond, K. R., Adelman, L. 1 976.

85

Science, values and human judgment.
Science 1 94:389-96
Hammond, K. R., Mumpower, J. L., Smith,
T. H. 1977. Linking environmental
models with models of human judg­
ment: A symmetrical decision aid.
IEEE Trans. Syst. Man Cybern.
(SMC)5 :358-67
Hammond, K. R., Stewart, T. R., Brehmer,
B., Steinmann, D. O. 1975. Social judg­
ment theory. In Human Judgment and
Decision Processes, ed. M. Kaplan, S.
Schwartz, pp. 271-3 1 2. New York:
Academic. 325 pp.
Hammond, K. R., Summers, D. A. 1972.
Cognitive
control.
PsychoL
Rev.
79:58-67
Harris, R. J., Monaco, G. E. 1 978. Psy­
chology of pragmatic implication: In­
formation processing between the lines.
J. Exp. Psychol 1 07 : 1 -22
Hayek, F. A. 1962. Rules, perception,
and intelligibility. Proc. Or. Acad.
48:32 1--44
Hershey, J. C., Schoemaker, P. J. H. I 980a.
Risk taking and problem context in the
domain of losses: An expected utility
analysis. J. Risk Insur. 46: 1 1 1-32
Hershey, J. C., Schoemaker, P. J. H. 1 980b.
Prospect theory's reflection hypothesis:
A critical examination. Organ. Behav.
Hum. Perform. 25:395-4 1 8
Hogarth, R . M . 1975. Cognitive processes
and the assessment of subjective proba­
bility distributions. J. Am. Stat. Assoc.
70:27 1-94
Hogarth, R. M. 1980a. Beyond static biases:
Functional and dysfunctional aspects of
judgmental heuristics. Univ. Chicago,
Grad. Sch. Bus., Cent. Decis. Res.
Hogarth, R. M. 1980b. Judgement and
Choice: The Psychology of Decision.
Chichester, England: Wiley. In press
Howell, W. C., Burnett. S. A. 1978. Uncer­
tainty measurement: A cognitive tax­
onomy. Organ. Behav. Hum. Peform.
22:45-68
Humphreys, P., McFadden, W. 1 980. Expe­
rience with MAUD: Aiding decision
structuring through reordering versus
automating the composition rule. Acta
Psycho! In press
Janis, I. L., Mann, L. 1 977. Decision Making:
A Psychological Analysis of Conflict,
Choice, and Commitment. New York:
Free Press. 488 pp.
Jungermann, H. 1 980. 'Decisionectics': The
art of helping people to make personal
decisions. Acta Psychol. 45. In press
Kahneman, D., Tversky, A. 1973. On the
psychology of prediction. Psychol. Rev.
80:25 1 -73

<-----Page 33----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

86

EINHORN & HOGARTH

Kahneman, D., Tversky, A. 1 979a. Prospect
theory: An analysis of decision under
risk. Econometrica 47:263-9 1
Kahneman, D., Tversky, A. 1 979b. On the
interpretation of intuitive probability. A
reply to Jonathan Cohen. Cognition
7:409-1 1
Karmarkar,
U.
S.
1978.
Subjectively
weighted utility: A descriptive exten­
sion of the expected utility model. Or­
gan. Behav. Hum. Perform. 2 1 :6 1-72
Karmarkar,
U.
S.
1979.
Subjectively
weighted utility and the Allais paradox.
Organ. Behav. Hum. Perform. 24:67-72
Keeney, R. L., Raiffa, H. 1976. Decisions with
Multiple Objectives: Preferences and
Value Tradeoffs. New York: Wiley. 569
pp.
Killeen, P. R. 1978. Superstition: A matter of
bias, not detectability. Science 199:
88-90
Kubovy, M. 1977. Response availability and
the apparent spontaneity of numerical
choices. J. Exp. Psychol.-Hum. Percept.
Perform. 3:359-64
Langer, E. J. 1977. The psychology of
chance. J. Theory Soc. Behav. 7: 1 85207
Levine, M. E., Plott, C. R. 1977. Agenda
influence and its implications. Va. Law
Rev. 63:561-604
Lewontin, R. C. 1979. Sociobiology as an ad­
aptationist program. Behav. Sci. 24:
5-1 4
Libby, R., Fishburn, P . C . 1977. Behavioral
models of risk-taking in business deci­
sions. J. Account. Res. 1 5:272-92
Lichtenstein, S., Fischhoff, B. 1977. Do those
who know more also know more about
how much they know? Organ. Behav.
Hum. Perform. 20: 1 59-83
Lichtenstein, S., Fischhotf, B. 1980. Training
for calibration. Organ. Behav. Hum.
Perform. In press
Lichtenstein, S., Fischhoff, B., Phillips, L. D.
1977. Calibration of probabilities: The
state of the art. In Decision Making and
Change in Human Affairs. ed. H. Jun­
germann, G. de Zeeuw, pp. 275-324.
Dordrecht-Holland: Riede!. 527 pp.
Lopes, L. L. 1 980. Doing the impossible: A
note on induction and the experience of
randomness. Dep. Psycho!., Univ. Wis.,
Madison
Luce, R. D. 1977. The choice axiom after
twenty years. J. Math. PsychoL 1 5 :
2 1 5-33
Mackie, J. L. 1965. Causes and conditions.
Am. Phi/os. Q. 2:245-64
March, J. G. 1978. Bounded rationality, am­
biguity, and the engineering of choice.
Dell J. Econ. Manage. Sci. 9:587-608

Michotte, A. 1 963. The Perception of Causal­
ity. London: Methuen. 425 pp.
Miller, N. E. 1 959. Liberalization of basic
S-R concepts: Extensions to conflict be­
havior, motivation, and sociai iearning.
In Psychology: A Study ofa Science, ed.
S. Koch, 2 : 1 96--2 92. New York:
McGraw Hill. 706 pp.
Mischel, W. 1 979. On the interface of cogni­
tion and personality: Beyond the per­
son-situation debate. Am. Psychol.
34:740-54
Mowrey, J. D., Doherty, M. E., Keeley, S. M.
1979. The influence of negation and task
complexity on illusory correlation. J.
Abnorm. Psychol. 88:334-37
Mynatt, C. R., Doherty, M. E., Tweney, R.
D. 1977. Confirmation bias in a simu­
lated research environment: An experi­
mental study of scientific inference. Q.
J. Exp. Psychol. 29:85-95
Mynatt, C. R., Doherty, M. E., Tweney, R.
D. 1978. Consequences of confirmation
and disconfirmation in a simulated re­
search environment. Q. J. Exp. Psychol.

30:395-406

Newell, A., Simon, H. A. 1972. Human Prob­
lem Solving. Englewood Cliffs, NJ:
Prentice-Hall. 920 pp.
Nisbett, R. E., Borgida, E., Crandall, R.,
Reed, H. 1976. Popular induction: In­
formation is not necessarily informa­
tive. See Abelson 1976, pp. 1 1 3-33
Nisbett, R. E., Ross, L. 1 980. Human Infer­
ence: Strategies and Shortcomings ofSo­
cial Judgment. Englewood Cliffs, NJ:
Prentice-Hall. 334 pp.
Nisbett, R. E., Wilson, T. D. 1977. Telling
more than we can know: Verbal reports
on mental processes. Psychol. Rev.
84:23 1 -59
Olson. C. L. 1976. Some apparent violations
of the representativeness heuristic in
human judgment. J. Exp. PsychoL­
Hum. Percept. Perform. 2:599-608
Payne, J. W. 1 976. Task complexity and con­
tingent processing in decision making:
An information search and protocol
analysis. Organ. Dehav. Hum. Perform.
1 6:366--8 7
Payne, J. W., Braunstein, M. L., Carroll, J. S.
1 978. Exploring predecisional behavior:
An alternative approach to decision re­
search. Organ. Behav. Hum. Perform.
22: 1 7-44
Payne, J. W., Laughhunn, D. J., Crum, R.
1979. Levels ofaspiration andpreference
reversals in risky choice. Grad. Sch.
Bus., Duke Univ., Durham, NC
Pearson, K. 1 897. On the scientific measure
of variability. Nat. Sci. 1 1 : 1 1 5- 1 8

<-----Page 34----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

BEHAVIORAL DECISION THEORY
Phelps, R. H., Shanteau, J. 1978. Livestock
judges: How much information can an
expert use? Organ. Behav. Hum. Per­
form. 2 1 :209-1 9
Plott, C. R . 1976. Axiomatic social choice
theory: An overview and interpretation.
Am. J. Polito Sci. 20: 5 1 1-96
Plott, C. R., Levine, M. E. 1978. A model of
agenda influence on committee deci­
sions. Am. Econ. Rev. 68: 146---60
Polya, G. 1941. Heuristic reasoning and the
theory of probability. Am. Math. Mon.
48:450-65
Polya, G. 1954. Patterns of Plausible Infer­
ence, Vol. 2. Princeton, NJ: Princeton
Univ. Press. 190 pp.
Powers, W. T. 1973. Feedback: Beyond be­
haviorism. Science 179:35 1-56
Rachlin, H., Burkhard, B. 1978. The tempo­
ral triangle: Response substitution in in­
strumental conditioning. PsychoL Rev.
85:22-47
Rothbart, M. 1980. Memory processes and
social beliefs. In Cognitive Processes in
Stereotyping and Intergroup Perception,
ed. D. Hamilton. Hillsdale, NJ:Erl­
baum. In press
Russell, B. 1948. Human Knowledge: Its
Scope and Limits. New York: Simon &
Schuster. 524 pp.
Russo, J. E. 1977. The value of unit price
information. J. Mark. Res. 14:1 93-201
Russo, J. E. 1978. Comments on behavioral
and economic approaches to studying
market behavior. In The Effect ofInfor­
mation on Consumer and Market Be­
havior, ed. A. A. Mitchell, pp. 65-74.
Chicago: Am. Mark. Assoc. 1 1 2 pp.
Sagan, C. 1 977. The Dragons of Eden. New
York: Random House. 263 pp.
Samuelson, P. A. 1948. Economics. An Intro­
ductory Analysis. New York: McGraw
Hill. 622 pp.
Schmitt, N., Levine, R. L. 1977. Statistical
and subjective weights: Some problems
and proposals. Organ. Behav. Hum.
Perform. 20: 1 5-30
Schneider, W., Shilfrin, R. M. 1977. Con­
trolled and automatic human informa­
tion processing: I. Detection, search,
and attention. Psychol. Rev. 84:1-66
Schum, D. A. 1979. A review of a case
against Blaise Pascal and his heirs.
Univ. Mich. Law Rev. 77:446---8 3
Schum, D. A. 1980. Current developments in
research on cascaded inference pro­
cesses. See Carroll 1980. In press
Seligman, M. E. P. 1 970. On the generality of
the laws of learning. Psycho!. Rev.
77:406--- 18
Shafer, G. 1976. A Mathematical Theory of

87

Evidence. Princeton, NJ: Princeton
Univ. Press. 297 pp.
Shanteau, J., Nagy, G. F. 1979. Probability of
acceptance in dating choice. J. Pers.
Soc. PsychoL 37:522-33
Shepard, R. N. 1964. On SUbjectively op­
timum selections among multi-attribute
alternatives. In Human Judgments and
Optimality, ed. M. W. Shelly, G. L.
Bryan, pp. 257-8 1 . New York: Wiley.
436 pp.
Shugan, S. M. 1980. The cost of thinking. J.
Consum. Res. 7: In press
Shweder, R. A. 1977. Likeness and likelihood
in everyday thought: Magical thinking
in judgments about personality. Curr.
AnthropoL 1 8:637-58
Shweder, R. A. 1979. Rethinking culture and
personality theory. Part II: A critical
examination of two more classical pos­
tulates. Ethos 7:279-3 1 1
Simon, H . A . 1978. Rationality as process
and as product of thought. Am. Econ.
Rev. 68: 1 - 1 6
Simon, H. A. 1979. Rational decision making
in business organizations. Am. Econ.
Rev. 69:493-5 1 3
Simon, H . A., Hayes, J. R . 1976. The under­
standing process: Problem isomorphs.
Cogn. Psychol. 8 : 1 65-90
Skinner, B. F. 1948. "Superstition" in the
pigeon. J. Exp. Psychol. 38: 1 68-72
Skinner, B. F. 1966. The phylogeny and
ontogeny of behavior. Science 1 5 3 :
1205-13
Siovic, P., Fischholf, B. 1977. On the psy­
chology of experimental surprises. J.
Exp. Psychol.-Hum. Percept. Perform.
3:544-5 1
Siovic, P., Fischhoff, B., Lichtenstein, S.
1977. Behavioral decision theory. Ann.
Rev. Psychol 28: 1-39
Siovic, P., Kunreuther, H., White, G. F.
1974. Decision processes, rationality
and adjustment to natural hazards. In
Natural Hazards, Local, National, and
Global, ed. G. F. White, pp. 1 87-205.
New York: Oxford Univ. Press. 288 pp.
Siovic, P., Lichtenstein, S. 1 97 1 . Comparison
of Bayesian and regression approaches
to the study of information processing
in judgment. Organ. Behav. Hum. Per­
form. 6:649-744
Smith, E. R., MiIIer, F. D. 1978. Limits on
perception of cognitive processes: A re­
ply to Nisbett and Wilson. Psychol. Rev.
85:355-62
Staddon, J. E. R., Motheral, S. 1978. On
matching and maximizing in operant
choice experiments. PsychoL Rev.
85:436-44

<-----Page 35----->Annu. Rev. Psychol. 1981.32:53-88. Downloaded from arjournals.annualreviews.org
by UNIVERSITY OF WATERLOO on 01/09/10. For personal use only.

88

EINHORN & HOGARTH

Staddon, J. E. R., Simmelhag, V. L. 197 1 .
The "superstitious" experiment: A re­
examination of its implications for the
principles of adaptive behavior. Psychol.
Rev. 78:3-43
Suppes, P. 1 966. Probabilistic inference and
the concept of total evidence. In Aspects
of Inductive Logic, ed. J. Hintikka, P.
Suppes, pp. 49-65. Amsterdam: North­
Holland. 320 pp.
Svenson, O. 1979. Process descriptions of de­
cision making. Organ. Beha.v. Hum.
Perform. 23:86-1 1 2
Thaler, R. 1980. Toward a positive theory of
consumer choice. J. Econ. Behav. Or­
gan. In press
Thaler, R., Shiffrin, H. M. 1980. An economic
theory of self-control Grad. Sch. Bus.,
Cornell Univ.
Thorngate, W. 1980. Efficient decision heu­
ristics. Behav. Sci. 25:219-25
Toda, M. 1962. The design of a fungus-eater:
A model of human behavior in an unso­
phisticated environment. Behav. Sci.
7: 1 �8 3
Toda, M. 1980a. What happens a t the mo­
ment of decision? Meta decisions, emo­
tions and volitions. In Human Decision
Making, Vo!' 2, ed. L. Sjoberg, T.
Tyszka, J. A. Wise. Bodafors, Sweden:
Doxa. In press
Toda, M. 1980b. Emotion and decision mak­
ing. Acta Psycho!. 45. In press
Tribe, L. H. 1973. Technology assessment
and the fourth discontinuity: The limits
of instrumental rationality. South.
Calif. Law Rev. 46:61 7-60
Tversky, A. 1977. Features of similarity. Psy­
chol. Rev. 84:327-52
Tversky, A., Kahneman, D. 1973. Avail­
ability: A heuristic for judging fre­
quency and probability. Cogn. Psychol.
5:207-32

Tversky, A., Kahneman, D. 1 980a. Causal
schemas in judgments under uncer­
tainty. In Progress in Social Psychology,
ed. M. Fishbein, 1 :49-72. Hillsdale,
NJ:Erlbaum. 240 pp.
Tversky, A., Kahneman, D. 1980b. The
framing of decisions and the rationality
ofchoice. Dep. Psycho!., Stanford Univ.
Tversky, A., Sattath, S. 1979. Preference
trees. Psychol. Rev. 86:542-73
Tweney, R. D., Doherty, M. E., Womer, W.
J., Pliske, D. B., Mynatt, C. R., Gross,
K. A., Arkkelin, D. L. 1980. Strategies
of rule discovery in an inference task.
Q. J. Exp. Psychol. 32: 109-23
Vlek, c., Stallen, P. 1980. Rational and per­
sonal aspects of risk. Acta Psycho!. In
press
Wallsten, T. S. 1980. Processes and models to
describe choice and inference. See Car­
roll 1 9 80. In press
Wason, P. C., Johnson-Laird, P. N. 1 9 72.
Psychology of Reasoning. Structure and
Content. London: Batsford. 264 pp.
Wickelgren, W. A. 1979. Chunking and con­
solidation: A theoretical synthesis of se­
mantic networks, configuring in condi­
tioning, S-R: versus cognitive learning,
normal forgetting, the amnesic syn­
drome, and the hippocampal arousal
system. Psychol. Rev. 86:44-60
Wilson, E. O. 1978. On Human Nature.
Cambridge, Mass: Harvard Univ. Press.
260 pp.
Wimsatt, W. C. 1980. Reductionistic re­
search strategies and their biases in.the
units of selection controversy. In Scien­
tific Discovery, Vol. 2, ed. T. Nickles.
Dordrecht, Holland: Reidel. In press
Yates, J. P., Zukowski, L. G. 1976. Charac­
terization of ambiguity in decision mak­
ing. Behav. Sci. 2 1 : 19-25

