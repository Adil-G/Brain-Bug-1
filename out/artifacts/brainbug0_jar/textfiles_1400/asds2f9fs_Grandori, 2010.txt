<-----Page 0----->Rationality
and Society
http://rss.sagepub.com/

A rational heuristic model of economic decision making
Anna Grandori
Rationality and Society 2010 22: 477
DOI: 10.1177/1043463110383972
The online version of this article can be found at:
http://rss.sagepub.com/content/22/4/477

Published by:
http://www.sagepublications.com

Additional services and information for Rationality and Society can be found at:
Email Alerts: http://rss.sagepub.com/cgi/alerts
Subscriptions: http://rss.sagepub.com/subscriptions
Reprints: http://www.sagepub.com/journalsReprints.nav
Permissions: http://www.sagepub.com/journalsPermissions.nav
Citations: http://rss.sagepub.com/content/22/4/477.refs.html

>> Version of Record - Oct 25, 2010
What is This?

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 1----->Article

A rational heuristic
model of economic
decision making

Rationality and Society
22(4) 477–504
© The Author(s) 2010
Reprints and permission:
sagepub.co.uk/journalsPermissions.nav
DOI: 10.1177/1043463110383972
http://rss.sagepub.com

Anna Grandori
Bocconi University Center of Research on Organization and Management, Italy

Abstract
A conspicuous ‘hole’ lies between the ‘rational-choice’ paradigm and the ‘behavioral
decision-making’ paradigm. The ‘missing model’ is ‘heuristic’ (research-based) yet
‘rational’ (non-biasing): a set of methods for the logically sound discovery and design
of economic actions, options and objectives. Such a model is developed in this
paper, enriching the notion and repertory of heuristics that are typically considered
in economic and cognitive sciences with the notion and set of heuristics typically
considered in the philosophy of science and the logic of discovery. The model then
provides a response to the hitherto unaddressed question of how knowledge, on
which the rationality and wisdom of any decision largely depends, can be constructed
in a valid and reliable way. The specification of the heuristics that can effectively and
efficiently guide economic discovery and innovation seems to be overdue in an
economy said to be knowledge intensive and innovation oriented.

Key words
discovery, heuristics, rationality, uncertainty

It is commonplace to say that the modern economy is knowledge based.
Central to this are innovation, exploration, design, discovery, and so forth.
Nevertheless, the ‘logic of economic discovery’ is not a central concern in
dominant rationality and decision-making models. Two key approaches are
predominantly employed to understand economic decision making, the
‘rational-choice’ paradigm of economics and the ‘bounded-rationality’
Corresponding author:
Anna Grandori, Bocconi University Center of Research on Organization and Management,
Bocconi University via Roentgen 1, Milan, Italy
Email: anna.grandori@unibocconi.it

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 2----->478		

Rationality and Society 22(4)

paradigm of behavioral science. However, neither one is particularly well
equipped to explain and guide discovery and invention. In fact, on one side,
economic rational-choice models frame decision-making largely as ‘choice’
in well-defined problems, paying little attention to the epistemic problems
of knowledge construction (Shackle, 1972). The behavioral tradition, on the
other side, points out that the ‘search’ and ‘discovery’ of alternatives is at
least as important, if not more so, than choices from among known alternatives. However, that tradition has devoted much more attention to the commonly followed shortcuts, rules of thumb and routines, quick (and often
dirty) methods able to reduce cognitive effort and search costs; and much
less attention to another, better class of heuristics, i.e. rational research
methods aimed at producing valid and reliable knowledge.
This paper is devoted to precisely single out some of the building blocks
of this ‘rational heuristic’ approach, drawing on fields where this problem
has always been central and received superb logical treatments, i.e. epistemology and philosophy of science. Resorting to this tradition is refreshing
because the meaning of the terms ‘rationality’ and ‘heuristics’ is broader, and
the type of uncertainty considered is stronger, than in economic sciences.
The first section, therefore, is devoted to pointing out the differences in
the definition of the core terms of rationality, heuristics, and uncertainty;
arguing that, in the same way as discovery processes in science, it is both
possible and desirable to define ‘rational heuristics’ for discovery processes
in economic problem solving under strong uncertainty.
The second section presents historical evidence on discovery and invention processes in innovative economic decision making. These descriptions
show that real and significant processes remain unexplained by the existing
models. They provide the material to identify effective heuristics for rational discovery through a ‘rational reconstruction of history’ – an approach
that has also been applied to identifying the most effective heuristics guiding scientific discovery (Lakatos, 1970a).
The third section specifies the features of a rational heuristic decisionmaking model as a set of operators or heuristics that pass an efficiency and
effectiveness test. The model is intended to complement, not substitute, the
two main existing, but rather polarized, models of rational and behavioral
choice, modeling the rather uncharted terrain between the two.

Rationality, heuristics, and uncertainty in economics
and epistemics: Contrasting meanings
According to the best encyclopedic definitions, the term ‘rationality’ comes
from the Latin word ratio, rationis, and it is ‘the principle governing the

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 3----->479

Grandori	

activity of knowing’: something is rational if ‘it proceeds from reason,’ if ‘it
is founded on logically sound procedures, on scientific method.’ These definitions of rationality fit perfectly with the meaning of the word rationality in
the logic and philosophy of science. Rationality has little to do with knowing everything, but a lot to do with following good rather than bad procedures in data gathering, hypothesis testing, assessing probabilities, and
comparing options. In fact, if we have come to know something from the
centuries of philosophical and epistemological debate on the nature of
knowledge and the logic of discovery, even in the more rationalistic schools,
it is that there can be no such thing as complete and infallible knowledge
(Nagel, 1963; Popper, 1959[1935]; Russell, 1948). As Nagel (1963: 214)
pointed out (in an effective effort to defend economic science from the
charge of being ‘unrealistic’): a ‘trivial way in which any statement can be
said to be unrealistic is that it can never give a complete description of all
the infinite aspects of any real objects or situation.’1 Analogously, in the
founding formulation of the rational-choice model, Savage (1954) asserted
‘the necessity of confining attention to, or isolating, relatively simple situations in almost all applications of the theory of decision developed in this
book.’ Economic models in practice do conform to this template, as they are
usually very selective and stylized, considering very few alternatives and
very few possible states of the world to be able to make value maximizing
calculations, not models that take into account ‘all possible’ dimensions of
action, alternative actions, and contingencies. In other words, value maximizing decision behaviors rest on stylized and simplified problems, not on
omniscience. Hence, according to the canons of ‘correct reasoning’ in the
logics and philosophy of knowledge, statements such as ‘all possible alternatives are considered’ or ‘with rational agents contingencies are never
unforeseen’ (Tirole, 1999: 756), should be seen as logically impossible (and
thus, arguably, not rational).
Therefore, a first contradiction lies between the meaning attributed to
rationality by the largest and most dominant part of economics and that used
in the philosophy of science and knowledge. As forcefully argued by Shackle
(1972), the notion of rationality employed in rational-choice theory is ‘thin’:
restricted to mean ‘logical,’ ‘consistent,’ ‘deductively correct,’ but not including systematic, valid, and sound methods for constructing the knowledge on
which decisions are based. It focuses on the deductive component of rationality, not on its heuristic component. Recent developments in economic philosophy have also emphasized that utility based, calculative ‘instrumental
rationality’ (reason exercised to adopt the best means to an end) is only a part
of human rationality, and in particular, is different from epistemic rationality
(reason exercised to distinguish true from false statements) (Foley, 1987).

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 4----->480		

Rationality and Society 22(4)

A second contradiction lies behind the notion of ‘heuristics.’ The term
comes from the Greek eurisco, meaning ‘to find, to discover.’ In the logic of
science ‘heuristics is that part of a science that has as an objective the discovery of facts or truths,’ the ‘very method of research’ (Lakatos, 1970b). In
Simon’s writings on scientific methods, heuristics also indicated methods of
discovery that could be meaningfully compared in terms of effectiveness
and efficiency. For example, he undertook a demonstration that computer
programs discovering laws in raw data – based on the observation of pattern
recognition and the ‘abduction’ of hypotheses on the laws that may regulate
the observed patterns – are more efficient than programs scanning ‘all conceivable laws’ in a blindly sequential way (Simon, 1977a).
In subsequent developments in behavioral science and behavioral economics, instead, the notion of heuristics has been increasingly and predominantly employed to indicate those search methods that people commonly
employ to reduce cognitive effort, or to generate ‘some’ (not necessarily
‘good’) solution to complex problems. That notion of heuristics has given
rise to at least three approaches:
•	 A formidable effort in constructing a repertory of ‘heuristics and biases,’
in the sense of shortcuts that are demonstrably dangerous, to improve
decision making mainly by ‘heuristics avoidance’ (Kahneman et al.,
1981);
•	 Some effort in singling out when and where the advantages in terms of
cognitive effort actually make the use of ‘simple heuristics’ smarter than
the use of other more sophisticated but more cumbersome decision processes (Gigerenzer et al., 1999);
•	 An incorporation of ‘behavioral parameters’ as assumptions or descriptors of the logic of decision makers in economic models so as to improve
the empirical validity of the models (e.g. Thaler, 1991; Tversky and
Kahneman, 1981) – the most diffused approach in behavioral economics and finance.
In all these approaches the dominant research question has been: how do
people actually behave? – either to ‘correct’ people’s behavior or to adjust
economic models to account for observed behaviors. A rather neglected
question, however, has been: how might people behave to the best of their
possibilities? The difference between the two questions has a perfect parallel in the debate on how science does or should proceed. In the critical tradition in the logic of scientific discovery (Lakatos, 1976; Popper, 1959[1935];
Simon, 1977a) and of invention and design (Simon, 1969), the approach is
empirically based but prescriptive: the relevant research question is not

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 5----->481

Grandori	

‘how do scientists actually think?’ but ‘which are the best patterns of thinking that can be found in scientific thinking?’ (Kiss, 2006); and thus the
‘logic of discovery’ is distinguished from the sociology or psychology of
science (Lakatos and Musgrave, 1970).
In this paper, we address the second question, thus far rarely addressed in
economic sciences. In other words, we focus on the logically correct and
‘powerful’ heuristics that might guide decision-making procedures with the
best chance of leading to the discovery of successful actions; rather than on
the ‘illusory and biasing,’ or even on the ‘fast and frugal,’ heuristics that are
commonly used in decision making.
Another difference in the decision behavior model proposed here, adding
to existing models, lies in the type of uncertainty envisaged. Although critics have often understated the type of uncertainty that rational-choice models can manage, a minimal requirement is that at least problems should be
defined in terms of types of alternatives and states of the world under consideration. Experimental and behavioral studies on decision making have
put the ‘search’ for alternatives center stage; most often however, ‘giving’
experimental subjects defined problems to solve.
The rational behavior model outlined in this paper is instead built on, and
suited to, decision-making processes where problems have to be defined.
This difference is crucial. In fact, it has been repeatedly noted that if problems are well defined and finite – even if complex – heuristics such as satisficing, elimination by aspects, limited search, incrementalism, and others,
can be justified as optimally imperfect decisions (Baumol, 2004; Baumol
and Quandt, 1964). The difference between a heuristic and a deductive
approach becomes relevant when problems ‘are not well defined’ (Arrow,
2004) or when they have to be defined and there is more than one way to do
so (Grandori, 1984). This difference can be more precisely defined using
the notions of ‘computational complexity’ and ‘aleatory uncertainty’ on one
side; as contrasted, on the other side, with what economics usually calls
‘Knightian uncertainty’ and other sciences (decision science, engineering,
environmental sciences, computational philosophy) call ‘epistemic uncertainty’ (Oberkampf et al., 2001). Computational complexity (Simon, 1969)
refers to the number of actions/states of the world combinations: it thus
includes the number of alternative moves available to a decision maker, the
number of parameters for evaluating them (‘parametric uncertainty,’ e.g.
Langlois, 1986) and the variety of possible exogenous changes in the ‘state
of the world’ or in the moves of others (‘aleatory uncertainty,’ e.g. Oberkampf
et al., 2001). Knightian or epistemic uncertainty, instead, is partial knowledge of the world, the ‘lack of knowledge’ on cause–effect relations and
therefore on what the relevant alternative moves and parameters for

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 6----->482		

Rationality and Society 22(4)

evaluating them might be all together. This second type of uncertainty does
not derive from being unable to anticipate what will be observed at a later
point in time, or from being unable to consider too many alternatives, but
derives from the epistemological problems posed by the observation and
measurement of phenomena, and by the construction of reliable and valid
models representing those phenomena (decision making under epistemic
uncertainty includes, for example in environmental sciences, preventive
action to be taken in the face of possible natural disasters).
Conditions of Knightian or epistemic uncertainty cannot be addressed
by instrumental value maximizing rationality alone, as economists also
admit (Arrow, 2004). Classic bounded-rationality heuristics are applicable,
but they do not indicate ‘the best patterns of thinking’ in order to proceed
rationally under these conditions. They typically indicate ‘average’ or ‘frequent’ procedures, and most often focus on the ‘biasing’ procedures to be
avoided rather than on the rational procedures to be followed. This paper
focuses on the latter class of heuristics, on the ‘best practices of thought’
under uncertainty.

Case histories in economic discovery
This section introduces some evidence on actual economic decision-making
processes oriented to discovery. The processes described are ‘real’ hence
‘possible’ in terms of cognitive capabilities. However, they are selected and
selectively analyzed with the aim of finding ‘the best patterns of thinking’
under uncertainty, rather than reviewing the most common way of thinking
under uncertainty, with the entire intricate mixture of useful tricks and dangerous mistakes that this implies.
Edison’s business plan
Zander (2007: 1146–7) reports historical evidence on ‘how the inventive genius
of Thomas A. Edison coincided with meticulous market analysis in the process
of substituting incandescent light for gas illumination in New York City’. He
‘started to collect every kind of data about gas; bought all the transactions of
the gas engineering societies, and all the back volumes of the gas journals.
Having obtained all the data and investigated gas-jet distribution in New York by
actual observation, he concluded that the problem of the subdivision of electric
current could be solved and made commercial. Additional efforts included
canvassing the district to obtain information on the number of gas jets burning
at each hour up to three in the morning, a house-to-house survey which provided
complete data on exactly how many jets were in each building, the average hours
of burning, and the cost of this light to the consumer (Edison collected some

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 7----->483

Grandori	

24 books containing gas-light bills of consumers in the district). Eventually,
Edison was able to calculate the variable and overhead cost component of the
gas which sold for $2.25 per 1000 cubic feet, and was confident that he could
get one-half of the lighting business in the district by setting the price of electriclight equivalent to gas at $1.50’.

This first case shows that innovative economic action, as much as good
scientific work, starts out and is based on hypothesis driven, systematic data
gathering. Systematic research has in fact been recognized and prescribed
in entrepreneurship and innovation (Drucker, 1985; Fiet, 2002), albeit not
clarifying the precise meaning of ‘systematicity.’ While the use of heuristics
such as ‘availability,’ ‘local search,’ and ‘past or comparable experience’ are
biasing, and gathering ‘all information’ is impossible, the heuristic of
hypothesis driven data gathering is defendable as an approach that is ‘systematic’ and as rational as possible (the reading endorsed here of Simon’s
notion of ‘intendedly rational’ behavior).
The second case is an interview-based reconstruction of the reasoning
that led one of the most successful and innovative entrepreneurs in Silicon
Valley to identify the opportunity on which he founded his last firm.2
I analyze it with the aim of identifying further rational heuristics.
Taking off on olive water
‘I am a chemist by training. I founded five firms in 25 years. I am also fond
of natural food and environment-friendly agriculture. My last firm actually was
born also thanks to the cultivation of that side-interest. I was thinking of buying a
piece of land in Tuscany to spend some holiday time at, cultivate olive trees, and
produce extra-virgin high quality oil. In reading and studying about oil production
I first discovered that in olden times (even back to the Greeks and Romans), oil
was not produced by pressing the entire olive, as is nowadays mostly done, but
by pressing only its pulp. Being a chemist, I first gathered evidence that indeed,
not only is the juice from pulp sweeter, but that there are harmful components
coming from seeds that increase the acidity of oil (which in fact is then treated
and sweetened with additional substances). Visiting some farms to see if any had
kept some equipment for pressing olives separately from seeds, I made a second
discovery. In the process of olive pressing (with or without seeds), the liquid
produced is stored so as to let oil separate from water, and the water is thrown
away. My economic and environmentalist mind made me think: What a waste!
My scientific and chemist mind made me advance the question: “Do you know
what you are throwing away? Have you ever analyzed that water?” No they
hadn’t. The hypothesis coming to my mind was that “waste water” (actually a
costly and problematic disposal problem for the industry) could contain precious
chemical components. After all, some of the beneficial substances present in

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 8----->484		

Rationality and Society 22(4)

olive oil may well have been present in olive water. I had the water analyzed. The
answer was yes, olive water was very rich in highly beneficial polyphenol, with
tremendous antioxidant capacity, found mainly in olives, responsible for most
extra-virgin olive oil health benefits, and contained 300–500 times more in olive
water. The possibilities of uses were to be defined, but with that anti-oxidant
capacity they couldn’t be few. I patented the process and constituted the firm,
which extracts the polyphenol through a proprietary process and technology, and
provides it to pharmaceutical, healthcare, agriculture and food industries, and
still other application sectors. We also directly produce some dietary products
employing the substance.’
(Interview personally conducted by the author, 2005)

This discovery and innovation story provides material to identify some
heuristics employable in defining problems, objectives, and alternatives,
neglected in the rational-choice view and different from those contemplated
in the behavioral tradition.
The ‘problem’ is not defined as a performance gap and alternatives are
not sought (either comparatively or sequentially) as specific, describable
actions having precise consequences on some performance parameters.
Rather, the problem is defined as a hypothesis (olive water contains beneficial substances) and alternatives are generated according to cause–effect
hypotheses: certain resources (e.g. polyphenols) are hypothesized to be put
to certain uses (e.g. food production), which in turn should produce consequences that may be evaluated as desirable (health) and valuable also in
economic terms. Systematic observation, questioning, and problem reframing by using ‘theories’ new to the field at hand figure prominently as heuristics in the hypothesis generation phase of this process; and systematic
empirical testing of propositions is the main heuristic behind the acceptance
of the course of action thus generated; much in the same way as they are in
scientific reasoning (Magnani et al., 1999).
As to utility and objectives, neither utility maximizing nor satisficing
seem to be the main devices. Rather, the decision to invest seems to be
based on high confidence in the hypothesis that a given resource (polyphenols in this case) may have many highly valuable potential uses. This
hypothesis has two interesting features. First, the hypothesis is based on a
causal theory, which makes the prediction stronger than predictions based
on the mere observation of empirical regularity in the success of certain
actions in one’s own or other’s experience. This feature reduces the ‘epistemic risk’ of accepting a false hypothesis. Second, the hypothesis does not
specify any single precise outcome, not even that outcomes will fall above
certain acceptability thresholds on specified performance parameters, but
predicts high potential for generating many diverse possible uses and

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 9----->485

Grandori	

consequences, albeit indescribable at the outset. This feature reduces downside risk and increase the robustness of action, even if those uses and consequences are not imaginable, enumerable, and describable ex-ante.
One could object that the process described is exceptional either
because it was specific to one case or because it was specific to the science-based economy, which, for the scientific part of the ‘search’ process,
is more likely to employ science-like processes than others. Both these
restrictions of validity can be ruled out by the following counter-examples
and counter-arguments.
The applicability of the identified ‘best patterns of thinking’ or effective
heuristics outside the specific single case, and irrespective of the presence
of specially gifted persons, is sustained by research on search processes
sustaining innovation in entire industries. The following further case history, giving a very detailed account of the evolution of ‘rational drug discovery’ techniques in the pharmaceutical industry, substantiates the claim.
Rational drug discovery in the pharmaceutical industry
‘In earlier phases (50s–90s) the prevailing approach was “random screening”:
natural and chemically derived compounds randomly screened in test
tube experiments and laboratory animals for potential therapeutic activity.
Pharmaceutical companies maintained enormous “libraries” of chemical
compounds added to their collections by searching for new compounds in places
such as swamps, streams, and soil samples. Thousands if not tens of thousands,
of compounds might be subjected to multiple screens before researchers honed
in a promising substance.’
(Henderson et al., 1999: 272)
The more traditional path of starting with a problem and searching for a solution
was also common, especially in commissioned research, e.g. ‘Find me something
that will lower blood pressure.’
The shift from the ‘traditional synthetic chemical world’ to biotechnology changed
effective search strategies, ‘since it calls for firms to develop deep understanding
of the role of particular proteins in causing disease.’ Two new strategies defined
as ‘rational guided search’ or ‘rational drug design’ emerged in response: ‘the first
explores the therapeutic properties of a known protein, a “protein in search of a
use” strategy,’ the second ‘attempt[s] to find a protein that might have therapeutic
effect’ for a specified disease. (Henderson et al., 1999: 288–289). These authors
maintain that the adoption of these ‘rational drug discovery’ strategies was one of
the main sources of competitive advantages for pharmaceutical firms.

The processes described testify that problem structuring and the generation of alternatives can systematically follow the heuristics of employing

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 10----->486		

Rationality and Society 22(4)

theories and causal models of problem solving phenomena, and that
research can proceed either from causes in search of effects, or in the opposite direction, effects in search of causes (the only one typically envisaged
in the problem solving tradition).
The applicability of the identified ‘best patterns of thinking’ or effective heuristics outside ‘science-based’ industries and/or the development
of science-based products can be supported by both logical argument and
empirical evidence. First, there are other ‘sciences’ beyond natural and
technical sciences. If products can be developed ‘scientifically’ if they
are based on engineering, biotechnology, and medicine, why cannot they
be so if they are based on consumer psychology, the sociology of family,
or urban and environmental sciences? Second, if rational hypothesis formulation and testing is part of the distinctive capabilities of ‘human
nature as we know it,’ it would be quite an ad hoc hypothesis to hold that
only some humans, namely scientists, are capable of and interested in
applying it. Any person can be interested in being as rational as a scientist
in their way of proceeding, and professional decision makers possibly
more than others.
Empirical evidence also proffers that science-like, rational hypothesis
testing is possible and successful as an economic decision strategy, even
outside of ‘science-based’ industries and beyond exceptional breakthroughs
and radical innovations. Regular strategy making is perfectly understandable as an exercise in making, testing, and revising hypotheses on which
goods and services, and which competitive positioning, will yield positive
returns on which performance parameters (Liedtka, 2000). Evidence has
been provided that the decision processes governing investments in new
management systems, such as information systems, are based on models
that are revised over time on the basis of the gathering of evidence on the
effects of these systems; for example, problems are initially framed as technical and cost reduction problems, but then refined by the discovery of other
relevant parameters, such as productivity, satisfaction, decision speed and
quality, professional development, and so forth (Grandori, 1984). The entire
field of ‘evaluation research’ consists of a set of codified and prescribed
methods for evaluating action in public and business administration based
on scientific research methods. Of particular interest here, a core heuristic
employed in evaluation is not to fix the evaluation parameter ex-ante, but
empirically inquire into the actual effects of action in order to evaluate it.
For example, it has been documented that educational and other public programs, initially set up to generate instruction level and job opportunity
results (and performing poorly on those dimensions), have then been discovered to cause a variety of other consequences (social integration,

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 11----->487

Grandori	

mobility); which should be and were incorporated into the evaluation and
problem model guiding subsequent decisions (Chen and Rossi, 1981).
These examples suggest that over time knowledge grows, in areas of
economic action as much as in areas of technology and science, and that the
collectively learned problem models in any particular area, as long as the
field is not radically transformed by exogenous shocks, typically ‘improve’
in their predictive validity and reliability as hypothesized effects that are not
observed are discarded and unexpected effects that are observed are
included; or by modifying the considered causes (the independent variables,
the ‘alternatives’) rather than the effect (the dependent variable, the consequence, and the evaluation parameter). In other words, in so far as many
elements of the tested model can be refuted, substituted or added, economic
problems can and should ‘shift,’ pretty much as they can and should in any
knowledge growth process, from empirical scientific research (Lakatos,
1970b) to the development of mathematical theorems (Lakatos, 1976), to
any kind of inventive processes with functional requirements, such as
design (March, 1976; Simon, 1969).

Rational heuristics for economic discovery
The case histories reported in the previous section show that a variety of
effective and efficient logical strategies, not really contemplated either in
the rational-choice paradigm or in the behavioral decision-making paradigm, are actually possible. In this section, they are systematized as a set of
‘rational heuristics’ capable of guiding decision making under uncertainty.
Any decision-making model with any pretense of rationality, should
specify procedures for problem definition, the generation of alternatives,
probability assessment, and the structuring of objectives (Simon, 1955).
Rational heuristics for performing all these operations under uncertainty are
specified in this section and summarized at the end in Table 1.

Problem modeling heuristics: From performance gaps to
performance potentials
A problem model is a set of hypotheses on cause–effect relationships, where
alternatives are causes and consequences are effects (e.g. analytical skills
predict performance in high education programs in science-based degrees;
investments in IT increase decision-making quality/efficiency if decision
makers use them; information disclosure attracts investments if investors
read reports; etc.). In economic decision making, consequences or effects
can also be ‘valued’: questions and answers such as ‘Why X? Y would

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 12----->488		

Rationality and Society 22(4)

explain X. Then let’s hypothesize Y à X’ become: ‘How to do X? Y may
produce X. Then let’s do Y to get X’ (Thagard and Croft, 1999). This transformation introduces a ‘desirability judgment,’ which is typically missing in
positive science, but is common not only in economic sciences but in any
design-oriented science such as medicine and engineering (Nagel, 1961;
Simon, 1969).
Two heuristics are important in defining problems in both an epistemically and instrumentally rational way (based on valid knowledge and conducive to desired effects).
First, desired effects may be the known input and the problem may be
defined as effects in search of causes. In this case, the problem is defined
as a performance gap (Simon, 1955). An alternative possibility is that
‘available alternatives’ may be the ‘known input’ and the starting point,
whereas the problem may be defined as causes in search of effects – a
strategy that has been called ‘effectuation’ (Sarasvathy, 2001). As in the
research processes described in the first section, the type of question
defining a problem and starting a research process then becomes: ‘We
observe/have Y. What consequences can Y produce? Which of those are
“useful”? X and Z are generated by Y and are useful. Then apply Y to get
X and Z.’ In this case, we can say that the problem is defined as performance potential.
Defining problems as performance potentials reduces the risk of finding no solution and losing resource investments. In economic activity, in
fact, resources are the typical inputs that can be in search of uses and can
be defined as potential for action (Penrose, 1959; Shackle, 1979). An
interesting property of resources is that – differently from the services,
activities, and actions that can be produced with them – it is easier to
evaluate their quality independently from any precise prediction of payoffs, foresight of contingencies, and assignment of probabilities, relying
only on causal hypotheses such as the quality and complementarity of
resources being positively related to the expected quality of actions and
therefore of performance. As Knight (1921: II.X.13) observed: ‘Though
we cannot anticipate a concrete situation accurately enough to meet it
without the intervention of conscious judgment at the moment, it can be
foreseen that under certain circumstances the kind of things that will turn
up will be of a character to be dealt with by a kind of capacity which can
be selected and evaluated… Knowledge of men’s capacities to know turns
out to be more accurate than direct knowledge of things.’ Therefore, the
definition of problems in terms of performance potential of ‘resources in
search of use’ rather than the reverse, is particularly indicated in conditions of Knightian uncertainty.

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 13----->489

Grandori	

A second useful heuristic for problem definition in conditions of epistemic uncertainty is to treat the problem itself as a hypothesis and let it shift
according to experimental (physical or mental) results (Campbell, 1960;
Lakatos, 1970b, 1976). Campbell defined this strategy as ‘opportunistic
multipurposedness’ and observed that it is intensively used in the thought
processes of scientists (1960: 394): ‘In the pure science to which they were
accustomed, if they were unable to solve problem A, they could turn to
problem B, and while studying this with perhaps small prospect of success,
they might suddenly come across a clue to the solution of problem C.’
However, the effectiveness of this strategy is by no means bound to ‘pure’
science, as testified by the already described cases in evaluation research
and by the following account of the invention of JAVA, a technological and
business innovation.
The invention of JAVA
‘In 1990, Patrick Naughton, a top programmer at Sun Microsystems, told
Sun’s chief Scott McNealy that he was quitting to join NeXT Computer
where he could work on more interesting projects. Convinced by Naughton’s
contention that Sun was becoming insufficiently innovative, McNealy told
Naughton he could have a million dollar budget to put together a small team
of outstanding programmers and engineers that would work without corporate
interference from Sun. With carte blanche to pursue new projects, Naughton
recruited Gosling and a few other top people, and in a hot tub in Lake Tahoe
in 1991 they decided to build a prototype of a small device that could control
everyday consumer appliances. To control this device, they originally decided
to program the device in C++, a popular computer language. However, for use
in consumer appliances, the program needed to be more reliable and simpler
than was possible with C++, so Gosling decided to develop a new computer
language. The result was initially called ‘Oak’ …: it was a simplified, more
reliable adaptation of C++, but its major innovation was in the way it could be
used by different kinds of computers …. By August 1992, Naughton, Gosling
and their seven-person team had produced a prototype personal digit assistant
with a small, touch-operated screen that could control TVs and VCRs, but
attempts to sell the device for use in interactive television and computer games
failed. Then, in June 1993, the first Mosaic browser was released and the
world-wide web began to take off. Bill Joy, Sun Microsystems’ co-founder
realized that Oak could naturally be adapted for use on the Internet. By 1995,
Gosling had produced a web-suitable version of Oak, now renamed Java, and
Naughton had written HotJava, an interpreter for Web browsers. Since then,
many thousands of Java applications have been produced and are available on
the world wide web.’
(Thagard and Croft, 1999: 131–132)

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 14----->490		

Rationality and Society 22(4)

Generating and testing alternatives: From search to research
Can alternatives be generated rationally? Or are we bound to the bifurcation
between the ‘given’ alternatives of the rational-choice paradigm and the
experience-based ‘evoked’ set of relevant alternatives of the behavioral
paradigm? The question is especially relevant in innovative settings, where
reliable past or comparable/vicarious experience may not be available
(Bandura, 1986) and ‘pattern recognition’ may not work due to lack of accumulated empirical knowledge on the ‘patterns’ to be recognized.
Fortunately though, other and more powerful heuristics are available,
and recommendable, in conditions where merely empirical approaches to
the generation of alternatives may have no solid basis due to lack of consolidated experience and empirical knowledge. Cognitive research has shown
that observable, hence possible, effective behaviors in those conditions,
both in scientific and social problem solving are guided by theoretical
abduction (Magnani, 1999) and modeling (Bandura, 1986). Abduction or
‘retroduction’ (as called by the original proponent of the concept, Charles
Sanders Pierce) can in fact take two forms: ‘empirical’ (recognize patterns
in data and posit laws that can regulate them) (Simon, 1977a) or ‘theoretical’ (formulate theory based, causal hypotheses from which the observed or
sought action/consequence chain would follow) (Hanson, 1958). Modeling
also strictly mimics a scientific approach: in order to understand how to act
in a situation, if past experience cannot be trusted, a rational actor needs first
of all to construct a model of the situation, including ‘independent variables’
(alternatives, causes) and ‘dependent variables’ (consequences, effects)
(Bandura, 1986).
The ensuing proposition, as applied to economic decision making, is that
alternatives generated by constructing a causal model of a situation, using
available theories, would be more innovative and are more likely to be valid
in the specific, eventually new, situation at hand; as compared to alternatives generated by ‘recognizing’ the problem and applying the ‘solutions’
that are supposed to work for that ‘type’ of problem.
Once generated, the alternatives have to be tested, as any hypothesis
does. Beyond any reasonable doubt, the core rational heuristic in this
domain is falsification. Popper himself took pains in arguing in some detail
(Popper, 1989) that the logic of hypothesis testing is the same, no matter
whether the hypothesis ‘predicts’ the behavior of planets or of men, the
discovery of a new chemical compound or of a way out of a dark place, the
chances that a montgolfier or a new product will fly. In fact, in Simon’s
(1955) initial model of heuristic decision making, the adjustment of the sets
of considered alternatives based on the ‘success’ or ‘failure’ in finding

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 15----->491

Grandori	

alternatives with the hypothesized features, plays the role of a (very) simple
falsificationist process. Behavioral decision research has highlighted how
some of the classical errors that may be committed in controlling scientific
propositions are also always lying in ambush in controlling hypotheses on
economic actions – e.g. Type I and Type II errors, positive sample biases,
self-confirmation rather than falsification (Bazerman, 1986; Einhorn and
Hogarth, 1981) – and has also specified some ‘positive heuristics,’ such as
‘design four-cell experiments’ to reduce Type I and II errors and sample
biases.
Grandori (1984) specified a wider set of ‘positive’ falsificationist heuristics to test economic action hypotheses in a flexible and logically correct
way. In fact, as in any hypothesis testing process, the failure to find what
was expected should not lead directly to rejecting the hypothesis, since
many other things are inevitably tested at the same time and may be responsible for the ‘failure,’ in particular: observational propositions and ‘auxiliary theories’ embodied in observation tools, theories of cause–effect
relations and the type of alternatives and consequences considered, and
ceteris paribus conditions (Lakatos, 1970b). For example, if it is hypothesized that a candidate with certain features is required for a certain position,
and is difficult to find, the procedure of rejecting the hypothesis and lowering the requirements is not the best heuristic available to produce an instrumentally and epistemically intended rational decision. In fact, all other
components of the hypothesis can be tested and modified before modifying
the level of expected consequences: perhaps there were measurement errors
in the evaluation of the candidate, or the auxiliary theories embodied in the
questionnaires/interviews were inaccurate, or the cause–effect hypothesis
that certain features (say a degree in engineering) were essential to produce
good results could have been wrong and other (rather than lower) degrees
and performance parameters could be considered. Alternatively, an engineer
with the specialization sought could be hypothesized to be found only under
certain conditions in the labor market, so that, if not met in a certain time
and place, it would be wiser to wait or to look in another country, rather than
renouncing. All these ‘side-tests,’ and in particular the heuristic of testing
and modifying either or both the causes or the consequences considered in
kind (rather than in level), improve the problem model, thereby increasing
the epistemic rationality of the decision and simultaneously preventing
acceptance of reductions in expected utility, thereby preserving or increasing instrumental rationality.
A quite important issue in option testing is if and how, in the course of
falsifying hypotheses, the risk of the hypotheses being false can also
be reduced. Following sound abductive heuristics for the generation of

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 16----->492		

Rationality and Society 22(4)

hypotheses is a first and crucial way of devising ‘correct’ alternatives.
Another way is to devise ‘robust’ alternatives. Robustness is the property
of performing well under a wide range of circumstances. Robust action is
therefore an action with multiple functions and consequences (Padgett and
Ansell, 1998), thus performing well if evaluated against different parameters and points of view, and under different contextual conditions. For
example, in the choice of which product to launch or which new project or
even people to invest in, research can be applied to find solutions whose
stream of consequences can be judged to be superior to other courses of
action ‘no matter what’ the state of the world is. ‘Robustness’ intended as
a decision-making heuristic, would recommend generating alternatives
with multiple functions and entailing positive consequences independently
from the state of the world. In conditions of strong uncertainty where
states of the world and contingencies cannot be foreseen, and looking for
alternatives with either maximum or acceptable consequences in given
states of the world is arguably not applicable due to lack of knowledge, the
robustness criterion is a rational alternative to maximization or acceptability criteria.
The invention of the JAVA language process offers a pertinent illustration of how effective betting on robust resources (top engineers) together
with flexible falsificationism (if the language/device does not work for TV
remote control, it may work for something else...), can be.

Probabilities and preferences: Rational heuristics for expected
utility judgments

Probability assessments.  If and once a model of relevant cause–effect relations is constructed, then probabilities can eventually be attached to them.
Whether and when it is rational to assign probabilities is an issue in need of
clarification.
As known, ‘there are two fundamentally different ways of arriving at the
probability judgment in the form of a numerical proportion: a priori calculation or empirical statistics’ (Knight 1921: II.7.25). Let us revisit them, as
they seem to imply a much less acknowledged conclusion, namely, that
assigning probabilities should be a contingent strategy.
In the case of a priori probabilities defined by the structure of possibilities (i.e. the dice), they can be logically deduced rather than tested. If a
problem can be reduced to the format of a finite number of possibilities, the
formula of ‘favorable cases’ over ‘possible cases’ can be computed, as is
now widely implemented in modeling cognitive processes of structured
problems (Klayman and Ha, 1986; Oaksford and Chater, 1998).

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 17----->493

Grandori	

Where a priori judgments cannot be rationally made, since there is no
finite list of possibilities, and if all other elements are well defined in the
problem model, probability judgments can be effectively ‘calibrated’ on the
basis of the observed frequencies (Lichtenstein et al., 1982) and ‘up-dated’
following Bayesian learning (Oaksford and Chater, 1998).
However, many if not most, scientific as well as economic problems, are
less structured and more uncertain than those tractable with these procedures. Probabilities may be ‘unknown,’ in the strict sense that assigning them
would be ‘impossible or meaningless’ (Knight, 1921), i.e., non-rational – no
matter what ‘new information’ may come up. Put in the language of logics
and epistemology, in unstructured problems such as those involving empirically based discovery, the ‘potential falsifiers’ of the cause–effect laws
employed are infinite in number; and thus, the probability of any such
cause–effect relation being true is always zero (Popper, 1959[1935]). Hence,
in those conditions, not assigning probabilities at all can be justified as a
rational strategy.3 In fact, scientists in most cases do not specify the probability of their theories being true (and are advised not to do so) and game
players do not judge the probability of other players making specific moves
(and are advised not to do so) in interactive and epistemic games (Schelling,
1960). Nevertheless, hypotheses can be tested and moves devised in a logically sound way. As argued in the former section, alternatives can be evaluated and compared (or designed to be comparable) by making causal
hypotheses on their relative capacity of producing unspecified but rankable
streams of consequences, independently of foresight of which state of the
world will occur with what probability.
In sum, whether to assign probabilities should be a contingent strategy,
in a rational discovery perspective and, under epistemic uncertainty on what
the relevant actions, states of the world, and consequences are, it is rational
not to assign them at all.
The rational discovery of objectives.  Is there any way to ‘discover’ preferences
rationally? Or is there at least a way to define preferences to allow the rational discovery of actions? This is the toughest terrain.
In the rational-choice paradigm preferences are intended as ‘orderings of
alternatives’ and are then usually judged to be more or less rational only in
terms of formal properties (transitivity, completeness, consistency) (Elster,
1983). Bounded-rationality models did offer a starting view on how preferences can be learned. As known, the core mechanism of preference definition in Simon’s behavioral model of rational choice is ‘aspiration level
adjustment.’ Simon (1955: 104–105) introduced the notion of aspiration
levels by noting that both in economics and psychology there is the notion

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 18----->494		

Rationality and Society 22(4)

of ‘lower bounds’ of acceptable payoffs and ‘that in psychological theory
we would fix the boundary at the aspiration level; in economic theory we
would fix the boundary at the price which evokes indifference’ between
transacting or not (i.e. at the ‘reservation price’). To this point, both economic and behavioral models of rational choice concur in saying that to fix
‘lower bounds’ of acceptable payoffs is a rational heuristic that can be used
in shaping utility functions, actually a necessary element in formulating
judgments on ‘rejection’ or ‘acceptance’ of alternatives.
To proceed only with the guidance of a lower bound, though, is not the
best ‘pattern of thinking.’ If a maximum payoff can be defined, even if it is
uncertain whether it can be reached, an upper bound to aim at is provided
(Raiffa, 1982). When problems are open-ended and a ‘maximum payoff’
cannot be defined, the usefulness of upper goals does not disappear: it has
been empirically demonstrated that actual performance (and payoff to the
actor) heavily depends on ambitious ‘goal setting’ and not only on setting
reservation prices (Bazermann and Carroll, 1987; Locke, 1991). Needless to
say, these are ‘hypotheses’ on maximum attainable results, not objective
maxima.
Some special caveats should be considered in testing those hypotheses
on minimum and maximum desired payoffs, as they include two judgments
that differ in kind: a value judgment and a probability judgment. The probability component can and should be adjusted or ‘updated’ as a function of
finding ‘favorable cases,’ as discussed in the former paragraph. Instead,
‘lowering aspiration levels’ on the basis of ease or frequency of attainment
(the basic heuristic envisaged in the classic model of behavioral choice), is
a highly biasing heuristic, actually it is a ‘sour grape fallacy’ (Elster, 1983).
In addition to being a logical fallacy, the downward adjustment of the utility
levels deemed acceptable (rather than the probability judgment only) may
seriously undermine justice and innovation. This is likely to promote
inequality, as desiring only what has been attained or is not difficult to attain
is a key driver of resignation to conditions of deprivation or otherwise to
poor opportunity structures (Sen, 2002).4 Second, it is likely to depress
innovation: as Simon himself stressed (1977b), the likelihood of discovery
greatly benefits from ‘persistence’ in the analysis of difficult problems,
where possible solutions are all but easy to find: in other terms, if Leonardo
da Vinci, and the Wright brothers, hadn’t preserved their judgment on the
high desirability of flying, in spite of, and along with, the judgment that it
was very difficult to achieve, we would never have had airplanes.
Hence, distinguishing value judgments from possibility judgments is a
rational heuristic for defining preferences and assigning values or utilities.
In addition, as previously pointed out, the generation of hypotheses on new

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 19----->495

Grandori	

performance parameters, hence on new objectives is a better (more instrumentally and epistemically rational) reaction to ‘failure’ than lowering aspirations. The JAVA case also illustrates this point (we would not have a JAVA
language had aspiration levels been lowered as opposed to new consequences being sought).
With respect to the prescriptions on how to define preferences available in
the rational-choice view, another useful complementary heuristic can be suggested. If alternatives are ‘given’ then preferences may be judged more or less
rational only in terms of the formal properties (transitivity, completeness etc.)
of their ordering. Defining preferences over alternatives, however, ‘freezes’ the
problem, in the sense that it considers alternatives as ‘given.’ This is not just a
matter of ‘assumption’; it is actually a decision strategy that may substantially
affect payoff. Negotiation research has been especially instructive in showing
that distinguishing ‘positions’ from underlying ‘interests’ is a fundamental
heuristic in effective bargaining (Bazerman and Carroll 1987; Raiffa, 1982).
In utility theory terms, ‘positions’ are preferences defined over alternatives,
i.e. a party prefers a higher price or a higher percentage of shares. However, if
parties rank alternative prices or shares in opposite ways, the negotiation may
have no solution or may be solved simply by ‘dividing the pie.’ Rather, if a
price or territory or a share of property is seen as a means of contributing to
some underlying interests, other matters may be generated and exchanged so
as to increase both the likelihood and the payoff of agreements (the size of the
pie) – e.g. if the underlying interest is ‘control,’ a lower percentage of shares
may be exchanged for a higher percentage of positions on boards.
If preferences are seen as hypotheses on the types and amounts of
resources that may contribute to realizing underlying interests, it becomes
possible to enlarge the set of matters that have a bearing on those interests
(a case of discovering new alternatives); or to enlarge the set of interests that
might be realized through the matters/alternatives generated.5
Hence, in condition of uncertainty, distinguishing interests from orderings of alternatives and holding an expandable set of interests (utility
parameters) is an effective and efficient heuristic.
In sum, under epistemic uncertainty, flexible, wide and hierarchically
structured objectives are more rationally defined, both instrumentally and
epistemically, than fixed (predefined), narrow (single criterion) and flat
(actions ranking only) preferences.

Research stopping and choice rules
When to stop the research process and turn to choice? In available models,
search stopping rules tend to coincide with choice rules. In bounded-rationality

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 20----->496		

Rationality and Society 22(4)

models, the core heuristic is to search for, and actually choose, acceptable
alternatives according to predefined parameters, eventually adjusting the
level according to what is found. In value maximization models, so far as
rational choice is characterized as based on having considered ‘all relevant’
alternatives and contingencies, the knowledge-based criterion for stopping
the search would be ‘when all the relevant elements have been considered’
and the utility-based criterion would be ‘when the marginal benefits of
search becomes equal to its marginal costs.’
Both approaches suffer from important limitations under substantial
uncertainty. In fact, as already argued, in any real setting of some complexity, the calculation of the marginal costs and benefits of research is technically unfeasible and a consideration of ‘all’ aspects of a situation is logically
impossible. On the other side, the truncation of search based on ‘aspiration
levels’ (a) requires a lot of knowledge on what is sought, (b) collapses possibility judgments with desirability judgments.
In order to identify rational research stopping heuristics that are viable
under strong uncertainty, useful inputs can be drawn from three sources: (a)
the methodology of research, (b) the foundations of statistical decision theory and (c) cognitive psychology research.
a)	 According to research methodology canons, which we ourselves usually follow in scientific problem solving, research can be stopped
when the problem model has passed a series of acceptability tests:
acceptability of observational propositions as reliable and valid constructs and representations, acceptability of cause–effect propositions
as significant relationships, acceptability of ‘ceteris paribus clauses,’
states of the world and conditions under which the relations are
expected to hold (Lakatos, 1970b). These ‘methodological decisions’
on the acceptability of knowledge elements also have a research stopping rule function.
b)	 In the single most important foundational study on the ‘rational actor
paradigm’ Savage (1954) singled out an almost opposite criterion for
defining problems and stopping research with respect to that of including everything, eventually taking into account search costs. He stated
that value maximizing rational decision is applicable to stylized and
simplified problems, considering as few elements as possible, rather
than as many elements as possible. Savage consequently also posed the
further question of when a problem model is ‘satisfactorily’ constructed. He responds: a problem model is satisfactory (acceptable) if
the utility judgments over the alternatives and consequences within the
‘small world’ of the problem model do not change if transferred into the

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 21----->497

Grandori	

real, ‘grand world’ of which they are a ‘partition.’ Namely, acceptance
of a problem model, and the termination of research intended to construct it, is performed with a criterion that includes both a utility instrumental criterion and the epistemic criterion of the predictive validity
and representational stability of the model. This heuristic is quite consistent with the prescription, derivable from research methodology, of
stopping research when our models of reality have ‘good’ descriptive
and predictive capacities (eventually taking into account the costs of
investments in research).
c)	 Cognitive research helps in further clarifying what a ‘good’ representational capacity is. Browne and Pitts’ (2004) review of research and
experiments on search stopping rules is particularly useful for our
purposes. In fact, they observed that search stopping rules were investigated mainly in ‘choice problems’ (where problems are given),
neglecting ‘design problems’ intended to ‘explore future possibilities
and preferences, to structure the problem, and, in many cases, to determine what choices are available’ (page 208). Design problems, thus
intended, are a sub-class of the research-based problem-solving cumproblem-modeling considered here. Browne and Pitts single out from
available descriptive research four stopping rules that have potential
applications to these unstructured design-intensive and researchintensive problems: (1) stop when a predetermined threshold in the
amount of evidence gathered is reached, or (2) when a predefined list
of items to be inquired into has been covered, (3) stop when marginal
net value of new information becomes small/negligible or (4) stop
when the cognitive representation of the problem gets stabilized and is
no longer changed by further inquiry. Let us note that, in terms of the
type of rationality involved, the first two rules imply a judgment of
‘satisfaction’ against a known standard, but the acceptability level is
defined as a ‘satisfactory amount of search’ rather than as a ‘satisfactory payoff.’ In order to be able to define a ‘satisfactory amount of
search,’ there should be plenty of prior experience and prior knowledge
on the quantity and quality of ‘necessary,’ ‘minimal satisfactory’
enquiry to solve a category of problems. Hence, these criteria are arguably not enormously useful in relation to new problems. The other two
rules are more ‘marginalist’ – stopping research when the problem
model becomes stable and the added value of new information shrinks
– but again both have to do with the marginal acquisition of knowledge
and not with the marginal payoff of alternatives. Given that they require
less prior experience, they represent heuristics applicable to more
exploratory situations where the problem model has to be constructed.

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 22----->498		

Rationality and Society 22(4)

In fact, the research results show, although the authors do not discuss
them in this light, that rules based on the marginal contribution of information and on the representational stability of problem models are used
more by analysts with less experience in the field at hand, which can be
considered a proxy of the level of uncertainty of the problem solver.
Another interesting descriptive result of the study is that stopping rules
based on the marginal growth of knowledge do not necessarily entail
higher quantities of information gathering than rules based on predefined thresholds, but quite often the contrary. This empirical regularity contributes to illustrating an important feature of rational heuristics
in general: they do not necessarily entail more information gathering
and a wider search, actually quite often the opposite is true. That is,
rational heuristics imply both quality enhancement and information
cost savings; ‘being more rational’ should not mean, as it is often
assumed, gathering more information, being ‘more comprehensive,’
attaining a ‘more complete’ description of the world, and to try to foresee everything; but, rather, to devise robust models and moves, possibly with less search.
In sum, rational heuristics to understand ‘how much to invest in research’
and when to stop the search in innovative, highly uncertain problem solving
are centered on the (marginal) representational stability of problem
models.6
This ‘decreasing marginal improvement’ criterion can also be applied to
consequences and utilities, thereby becoming a choice criterion. Negotiation
analysis helps again here. Parties in any complex negotiation cannot know
the ‘maximum’ payoff attainable, if for no other good reason than the counterparty has no incentive to reveal the real reservation price. Therefore, the
best they can do is to ‘Pareto-improve’ (and Nash-improve) the point of
agreement, until the benefits of further adjustments and exchanges of matters become small enough (Grandori, 1991; Raiffa, 1982). Interestingly, a
Pareto-improvement criterion lies somewhere between a value maximization criterion and an acceptability threshold criterion and has several interesting properties of both. The decision process can proceed without
comparing objectives (an essential feature if utilities belong to different
actors, but also useful if one single actor holds incomparable objectives).
Comparisons among alternatives are made, and not only between alternatives and aspiration levels or reservation prices, whereby the problem space
is widely explored. A point-wise prediction of the expected cardinal utility
of alternatives is not however necessary, since Pareto-superiority is an ordinal utility judgment.

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 23----->499

Grandori	

Conclusions
Table 1 summarizes what has been identified and appraised as rational heuristics for economic decision making under epistemic uncertainty. Taken
together, these heuristics define a new decision-making model, capable of
capturing and guiding exploratory, innovative, design-oriented and yet rational behavior. The model extends the repertory of heuristics contemplated in
the behavioral tradition to include science-like rational heuristics capable of
explaining, guiding and sustaining the growth of economic knowledge
through a logically sound discovery of economic actions, options and objectives. This approach to decision making is able to master conditions of
‘strong,’ ‘Knightian,’ ‘epistemic’ uncertainty on the causal structure of the
world and how to define problems. The model has descriptive validity, in the
sense of giving an account of a variety of heuristics that are used and highly
effective, but are not contemplated in existing rational or behavioral choice
models. The model also has prescriptive validity, grounded in a rational

Table 1.  Rational heuristics for economic decision making
Problem formulation
–	 Performance potentials (resources/alternatives in the search of uses and
consequences, ‘effectuation’) in addition to performance gaps (pursued
consequences in the search of causes/alternatives)
Logic of discovery and justification of alternatives
–	 Systematic hypothesis driven data gathering
–	 Theoretical abduction and causal modeling
–	 Methodological falsificationism – test and revise the characterization of
alternatives (observational propositions) or the type of alternatives and
consequences considered (theories of cause-effect relations) or the contextual
conditions of experimentation (ceteris paribus conditions)
–	 Logic of ‘robustness’ (alternatives causing positive streams of consequences,
no matter what the contingencies).
Definition of objectives and expected utility
–	 Desirability judgments separate from possibility judgments
–	 Contingent probability assignments: either a priori, frequency-based, or none
–	 Causal hierarchical structuring of objectives (appraisal of underlying
interests, rather than just ordering of alternatives)
–	 Flexible, wide objective sets (‘opportunistic multipurposedness’)
Research stopping and choice rules
–	 Acceptability of problem models based on decreasing marginal representational
stability
–	 Acceptability of payoffs based on decreasing marginal Pareto-improvements

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 24----->500		

Rationality and Society 22(4)

reconstruction of the ‘best patterns of thinking’ among those actually used
by decision makers under epistemic uncertainty.
It thus provides a tool that is missing in decision making under uncertainty, adding to the available ‘negative heuristics’ (procedures to be
avoided) ‘positive heuristics’ (procedures to be followed) to proceed rationally in economic decisions requiring (or allowing) discovery and new
knowledge production.
In terms of future research, therefore, this focus can open a new research
agenda in what may be called ‘epistemic economics.’ It should include
research on the ‘best practices of thought’ used in constructing and solving
problems with an innovation and an economic component in controlled
experimental conditions, conducted especially with expert subjects (entrepreneurs, designers, scientists in business). This type of research should
enable us to refine our knowledge on the different types of uncertainty, on
the repertory of rational heuristics, and on the relations between them. Such
a body of knowledge should provide a currently missing set of tools for
improving actual decision making in our times, when the growth of knowledge is the major source of economic growth, and conditions of strong
uncertainty and innovation pursuit are more the rule than the exception.
Acknowledgements
The main points and earlier versions of this paper have been presented at Columbia
University, Universitat Pompeu Fabra, Harvard Business School, Copenhagen
Business School, and Berkeley Haas School of Business. I am grateful to the colleagues at those universities who invited me – Daniel Beunza, Giovanni Gavetti,
Nicolai Foss, John Freeman – providing useful occasion for discussion; and to the
Editor and anonymous reviewers of Rationality and Society for their constructive
suggestions. This study contributes to the research program on ‘The microfoundations of innovation,’ coordinated by Anna Grandori, within the Bocconi Center of
Research on Organization and Management and data gathering activities have been
supported by funds of the Italian Ministry of University and Research.

Notes
1.	 Nagel was criticizing the type of defense that Friedman gave of the legitimacy of
‘unrealistic assumptions’ in economics, attacked by Simon. Interestingly, Nagel
concluded that ‘unrealism’ can be defended precisely because there can be no
‘complete’ description of reality and no ‘perfect foresight’ of the world.
2.	 From a three-hour interview released to the author in May 2005. Some technical
details have been specified and up-dated using the company’s website.
3.	 In other words, the models of ‘rational search’ based on Bayesian inference
(Oaksford and Chater, 1998; Radner, 2000) focus on a particular, relatively structured, case of discovery, where probabilities can be defined on some sound

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 25----->501

Grandori	

logical basis. As a consequence, we can do better than choosing between a
‘Bayesian’ and a ‘Popperian’ approach to probability assessment, in a universalistic, non-contingent way, as is often envisaged (March, 1976). Whether probability judgments on the likelihood of a hypothesis being true can or cannot be
made should not be a matter of faith or assumption. A more rationally posed
question is whether we can structure the matter enough to have conventionally
finite possibilities and make probability judgments. Hence, we may well be
sometimes Bayesian and sometimes Popperian. Even in science this is the case:
there are structured problems – say a phenomenon that may be represented by
some specified alternative models among which we may select ‘the best’ with
maximum likelihood methods – while in less structured problems we have rival
theories that may live for years in a state of ‘acceptance’ and ‘corroboration’
without any possibility of comparing their relative likelihood.
4.	 For example, results of empirical surveys on blue collar worker satisfaction show
that, unexpectedly, they may declare high satisfaction on all aspects of their
working life but at the same time, when asked whether they would like to see
their sons doing the same job, they respond: never. Hence, a ‘theory of preferences’ which simply says they are formed on the basis of experience is not even
fully accurate as a descriptive theory in addition to being dangerous in prescriptive terms.
5.	 Another decision-making area where it is commonly recommended to hold an
expandable set of objectives (evaluation parameters) is design (Hatchuel, 2001)
for analogous reasons – the solutions should respond to multiple, often noncomparable, functional requirements.
6.	 Admittedly, in economic problem solving there are situations where convenience
rather than conviction should lead to accept a hypothesis without testing it, i.e.
there may be ‘instrumental rather than epistemic reasons to believe’ (Foley,
1987). These are particular situations though, especially due to the ‘self-fulfilling
prophecies’ phenomenon. For example, organizational leaders, knowing that
behaving with their employees on the basis of ‘theory X’ (they are shirking and
naturally inclined to save effort) rather than ‘theory Y’ (they are naturally inclined
to spend effort in interesting things) will increase the probability that employees
conform to the expectation and confirm the theory (McGregor, 1960), may rationally choose to behave as if they believe in the second hypothesis, even in the
absence of overwhelming evidence.

References
Arrow KJ (2004) Is bounded rationality unboundedly rational? Some ruminations.
In: Augier M and March JG (eds) Models of a Man. Essays in Memory of Herbert
A. Simon. Cambridge: MIT Press, 47–55.
Bandura A (1986) Social Foundations of Thought and Action. Englewood Cliffs:
Prentice-Hall.
Baumol WJ (2004) On rational satisficing. In: Augier M and March JG (eds) Models
of a Man. Essays in Memory of Herbert A. Simon. Cambridge: MIT Press, 57–66.

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 26----->502		

Rationality and Society 22(4)

Baumol WJ and Quandt RE (1964) Rules of thumb and optimally imperfect decisions. American Economic Review 54: 23–46.
Bazerman MH (1986) Judgment in Managerial Decision Making. New York: John
Wiley and Sons.
Bazerman MH and Neale MA (1992) Negotiating Rationally. New York: The Free
Press.
Browne GJ and Pitts MG (2004) Stopping rule use during information search in
design problems. Organizational Behavior and Human Decision Processes 95:
208–24.
Campbell DT (1960) Blind variation and selective retention in creative thought as in
other knowledge processes. Psychological Review 67: 380–400.
Chen HT and Rossi PH (1981) A multi-goal theory-driven approach to evaluation.
Evaluation Research 6: 38–54.
Drucker PF (1985) The discipline of innovation. Harvard Business Review 63(3):
67–72.
Einhorn HJ and Hogarth RM (1981) Behavioral decision theory: Processes of judgment and choice. Annual Review of Psychology 32: 52–88.
Elster J (1983) Sour Grapes. Studies in the Subversion of Rationality. Cambridge:
Cambridge University Press.
Fiet JO (2002) The Systematic Search for Entrepreneurial Discoveries. Westport
CT: Quorum Books.
Foley R (1987) The Theory of Epistemic Rationality. Cambridge, MA: Harvard
University Press.
Gigerenzer G, Todd PM, and the ABC Research Group (1999) Simple Heuristics
that make us Smart. Oxford: Oxford University Press.
Grandori A (1984) A prescriptive contingency view of organizational decision making. Administrative Science Quarterly 29: 192–208.
Grandori A (1991) Negotiating efficient organization forms. Journal of Economic
Behavior and Organization 16: 319–340.
Hanson NR (1958) Patterns of Discovery. An Enquiry into the Conceptual
Foundation of Science. Cambridge: Cambridge University Press.
Hatchuel A (2001) Towards design theory and expandable rationality: The unfinished programme of Herbert Simon. Journal of Management and Governance
5(3–4): 260–73.
Henderson R, Orsenigo L, and Pisano GP (1999) The pharmaceutical industry and
the revolution in molecular biology: Interaction among scientific, institutional,
and organizational change. In: Mowery DC and Nelson RR (eds) Sources of
Industrial Leadership. Cambridge: Cambridge University Press, 267–311.
Kahneman D, Slovic P, and Tversky A (eds) (1982) Judgment under Uncertainty:
Heuristics and Biases. Cambridge: Cambridge University Press.
Kiss O (2006) Heuristic, methodology or logic of discovery? Perspectives on
Science 14(3): 302–17.
Klayman J and Ha Y-W (1986) Confirmation, disconfirmation and information in
hypothesis testing. Psychological Review 94(2): 211–28.

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 27----->503

Grandori	

Knight FH (1921) Risk, Uncertainty and Profit. Boston: Houghton Mifflin.
Lakatos I (1970a) History of science and its rational reconstructions. PSA:
Proceedings of the Biennial Meeting of the Philosophy of Science Association
Vol. 1970: 91–136.
Lakatos I (1970b) Falsification and the methodology of scientific research programmes. In: Lakatos I and Musgrave A (eds) Criticism and the Growth of
Knowledge. Cambridge: Cambridge University Press, 91–196.
Lakatos I (1976) Proofs and Refutations. The Logic of Mathematical Discovery.
Cambridge: Cambridge University Press.
Lakatos I and Musgrave A (eds) (1970) Criticism and the Growth of Knowledge.
Cambridge: Cambridge University Press.
Langlois RN (1986) Rationality, institutions and explanation. In: Langlois RN (ed)
Economics as a Process. Cambridge: Cambridge University Press, 225–55.
Lichtenstein S, Fishoff B, and Phillips LD (1982) Calibration of probabilities.
In: Kahneman D, Slovic P, and Tversky A (eds) Judgment under Uncertainty:
Heuristics and Biases. Cambridge: Cambridge University Press, 306–34.
Liedtka J (2000) In defense of strategy as design. California Management Review
42(3): 8–30.
Locke EA (1991) The motivation sequence, the motivation hub, and the motivation
core. Organizational Behavior and Human Decision Processes 50: 288–99.
Magnani L (1999) Theoretical abduction. In: Magnani L (ed.) Abduction, Reason
and Science. Processes of Discovery and Explanation. Dordrecht: Kluwer
Academic Publishers, 15–50.
Magnani L, Nersessian NJ, and Thagard P (eds) (1999) Model-based Reasoning in
Scientific Discovery. Dordrecht: Kluwer Academic Publishers.
March L (1976) The logic of design and the question of value. In: March L (ed.) The
Architecture of Form. Cambridge: Cambridge University Press, 1–40.
McGregor D (1960) The Human Side of Enterprise. New York: McGraw-Hill
Nagel E (1961) The Structure of Science. New York: Harcourt, Brace & World.
Nagel E (1963) Assumptions in economic theory. American Economic Review.
Papers & Proceedings 53: 211–19.
Oaksford H and Chater N (eds) (1998) Rational Models of Cognition. Oxford:
Oxford University Press.
Oberkampf WL, Helton JC, and Sentz K (2001) Mathematical representation of
uncertainty. AIAA Non-deterministic Approaches Forum, Seattle, Pap.n 2001–
1645.
Padgett J and Ansell C (1992) Robust action and the rise of the Medici. American
Journal of Sociology 98: 1259–330.
Penrose E (1959) The Theory of the Growth of the Firm. Oxford: Oxford University
Press.
Popper KR (1959[1935]) Logik der Forschung (The Logic of Scientific Discovery).
London: Hutchinson.
Popper KR (1989) The critical approach versus the mystique of leadership. Human
Systems Management 8: 259–65.

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

<-----Page 28----->504		

Rationality and Society 22(4)

Radner R (2000) Costly and bounded rationality in individual and team decision
making. Industrial and Corporate Change 9(4): 623–58.
Raiffa H (1982) The Art and Science of Negotiation. Cambridge: Cambridge
University Press.
Russell B (1948) Human Knowledge: Its Scope and Lmits. New York: Simon
&Schuster.
Saravasthy S (2001) Causation and effectuation: Towards a theoretical shift from
economic inevitability to entrepreneurial contingency. Academy of Management
Review 26(2): 243–63.
Savage LJ (1954) The Foundations of Statistics. New York: Wiley.
Schelling TC (1960) The Strategy of Conflict, Cambridge, MA: Harvard University
Press.
Sen A (2002) Rationality and Freedom. Cambridge, MA: Harvard University Press.
Shackle GL (1972) Epistemics and Economics. Cambridge: Cambridge University
Press.
Shackle GL (1979) Imagination and the Nature of Choice. Edinburgh: Edinburgh
University Press.
Simon HA (1955) A behavioral model of rational choice. Quarterly Journal of
Economics 69: 99–118.
Simon HA (1969) The Sciences of the Artificial. Cambridge, MA: MIT Press.
Simon HA (1977a) Does scientific discovery have a logic? In: Simon HA Models of
Discovery and Other Topics in the Method of Science. Reidel, Dordrecht, Boston.
Simon HA (1977b) Models of Discovery and Other Topics in the Method of Science.
Reidel, Dordrecht, Boston.
Thagard P and Croft D (1999) Scientific discovery and technological innovation:
Ulcers, dinosaurs extinction, and the programming language Java. In: Magnani
L, Nersessian NJ, and Thagard P (eds) Model-based Reasoning in Scientific
Discovery. Dordrecht: Kluwer Academic Publishers, 125–37.
Thaler RH (1991) Quasi Rational Economics. New York: Russell Sage Foundation.
Tirole J (1999) Incomplete contracts: Where do we stand? Econometrica 67(4):
741–81.
Tversky A and Kahneman D (1981) The framing of decisions and the psychology of
choice. Science 211: 453–58.
Zander I (2007) Do you see what I mean? An entrepreneurship perspective on
the nature and boundaries of the firm. Journal of Management Studies 44(7):
1141–64.

Downloaded from rss.sagepub.com at TEMPLE UNIV on September 13, 2012

