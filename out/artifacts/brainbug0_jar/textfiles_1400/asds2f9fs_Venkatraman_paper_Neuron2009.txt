<-----Page 0----->Neuron

Article
Separate Neural Mechanisms Underlie Choices
and Strategic Preferences in Risky Decision Making
Vinod Venkatraman,1,2 John W. Payne,2,3 James R. Bettman,2,3 Mary Frances Luce,2,3 and Scott A. Huettel1,2,*
1Brain

Imaging and Analysis Center, Duke University Medical Center, Box 3918, Durham, NC 27710, USA
for Neuroeconomic Studies, Duke University, Box 90999, Durham, NC 27710, USA
3Fuqua School of Business, Duke University, 1 Towerview Drive, Durham, NC 27708, USA
*Correspondence: scott.huettel@duke.edu
DOI 10.1016/j.neuron.2009.04.007
2Center

SUMMARY

Adaptive decision making in real-world contexts often
relies on strategic simplifications of decision problems. Yet, the neural mechanisms that shape these
strategies and their implementation remain largely
unknown. Using an economic decision-making task,
we dissociate brain regions that predict specific
choices from those predicting an individual’s preferred
strategy. Choices that maximized gains or minimized
losses were predicted by functional magnetic resonance imaging activation in ventromedial prefrontal
cortex or anterior insula, respectively. However,
choices that followed a simplifying strategy (i.e.,
attending to overall probability of winning) were associated with activation in parietal and lateral prefrontal
cortices. Dorsomedial prefrontal cortex, through
differential functional connectivity with parietal and
insular cortex, predicted individual variability in strategic preferences. Finally, we demonstrate that robust
decision strategies follow from neural sensitivity to
rewards. We conclude that decision making reflects
more than compensatory interaction of choice-related
regions; in addition, specific brain systems potentiate
choices depending on strategies, traits, and context.
INTRODUCTION
The neuroscience of decision making under risk has focused on
identifying brain systems that shape behavior toward or against
particular choices (Hsu et al., 2005; Kuhnen and Knutson, 2005;
Platt and Huettel, 2008). These studies typically involve compensatory paradigms that trade two decision variables against each
other, as when individuals choose between a safer, lower-value
option and a riskier, higher-value option (Coricelli et al., 2005; De
Martino et al., 2006; Huettel, 2006; Tom et al., 2007). Activation in
distinct regions reliably predicts the choices that are made:
increased activation in the anterior insula follows risk-averse
choices (Paulus et al., 2003; Preuschoff et al., 2008) and
increased activation in the ventromedial prefrontal cortex
(vmPFC) and striatum predicts risk-seeking choices (Kuhnen
and Knutson, 2005; Tobler et al., 2007). In contrast, prefrontal

and parietal control regions support executive control processes
associated with risky decisions, as well as the evaluation of risk
and judgments about probability and value (Barraclough et al.,
2004; Huettel et al., 2005; Paulus et al., 2001; Sanfey et al.,
2003). These and other studies have led to a choice-centric
neural conception of decision making: tradeoffs between decision variables, such as whether someone seeks to minimize
potential losses or maximize potential gains, reflect similar tradeoffs between the activation of brain regions (Kuhnen and Knutson, 2005; Loewenstein et al., 2008; Sanfey et al., 2003). Accordingly, individual differences in decision making have been
characterized neurometrically by estimating parameters associated with a single model of risky choice and identifying regions
that correlate with individual differences in those parameters
(De Martino et al., 2006; Huettel et al., 2006; Tom et al., 2007).
Yet, following a purely compensatory approach to decision
making would require substantial computational resources,
especially for complex decision problems that involve multiple
decision variables. It has become increasingly apparent that
people employ a variety of strategies to simplify the representations of decision problems and reduce computational demands
(Camerer, 2003; Gigerenzer and Goldstein, 1996; Kahneman
and Frederick, 2002; Payne et al., 1992, 1988; Tversky and Kahneman, 1974). For example, when faced with a complex decision
scenario that could result in a range of positive or negative monetary outcomes, some individuals adopt a simplifying strategy that
deemphasizes the relative magnitudes of the outcomes but maximizes the overall probability of winning. Other individuals emphasize the minimization of potential losses or the maximization of
potential gains in ways consistent with more compensatory
models of risky choice such as expected utility maximization
(Payne, 2005). Adaptive decision making in real-world settings
typically involves multiple strategies that may be adopted based
on the context and computational demands of the task (Gigerenzer and Goldstein, 1996; Payne et al., 1993). As noted above,
there has been considerable research on identifying brain
systems that shape behavior toward or against particular choices
(risky or safer gambles); however, much less is known about the
neural mechanisms that underlie inter- and intraindividual variability in decision strategies. We sought to address this limitation
in the present study by dissociating choice-related and strategyrelated neural contributors to decision making.
We used an incentive-compatible decision-making task (Payne,
2005) that contained economic gambles with five rank-ordered

Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc. 593

<-----Page 1----->Neuron
Strategies and Choices in Risky Decision Making

Figure 1. Experimental Task and Behavioral Results
(A) Subjects were first shown, for 4–6 s, a multiattribute mixed gamble consisting of five potential outcomes, each associated with a probability of occurrence. Then, two alternatives for improving the gambles were highlighted in
red, whereupon subjects had 6 s to decide which improvement they preferred.
Finally, after two arrows identified the buttons corresponding to the choices,
subjects indicated their choice by pressing the corresponding button as
soon as possible. Here, the addition of $20 to the central, reference outcome
would maximize the overall probability of winning (Pmax choice), whereas the
addition of $20 to the extreme loss would reflect a Lmin choice. The next trial
appeared after a variable interval of 4, 6, or 8 s. In other trials, subjects could
have a chance to add money to the extreme gain outcome, reflecting a Gmax
choice.

outcomes, ranging from large monetary losses to large monetary
gains (Figure 1). There were three types of choices: gain maximizing (Gmax), loss minimizing (Lmin), or probability maximizing
(Pmax). Making a Gmax choice increased the magnitude of the
largest monetary gain (i.e., the most money that could be won),
whereas making a Lmin choice reduced the magnitude of the
largest monetary loss (i.e., the most money that could be lost).
The gambles were constructed so that these two choices (Gmax
and Lmin) were generally consistent with a compensatory strategy
(see Supplemental Experimental Procedures for a discussion of
model predictions), such as following expected utility theory
and/or rank-dependent expectation models like cumulative prospect theory (Birnbaum, 2008; Payne, 2005; Tversky and Kahneman, 1992). On the other hand, making a Pmax choice increases
the overall probability of winning money compared to losing
money. Therefore, such choices would be consistent with a simplifying strategy (e.g., ‘‘maximize the chance of winning’’) that
ignores reward magnitude. Finally, we characterized our subjects’
strategic preferences according to their relative proportion of
simplifying (Pmax) versus compensatory (Gmax and Lmin) choices.
Such a definition positions the two strategies as the end points
of a continuum with a high value indicating an individual’s preference for a simplifying strategy and a low value indicating a preference for a compensatory strategy. We emphasize that, as defined
operationally here, strategies for decision making may be either
explicit or implicit.
To distinguish neural mechanisms underlying choices from
those underlying the strategies that generate those choices,

594 Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc.

we collected several forms of behavioral and functional magnetic
resonance imaging (fMRI) data. Consistent with many previous
studies (De Martino et al., 2006; Sanfey et al., 2003), we characterized brain regions as choice related if the magnitude of their
activation predicted a specific behavior (e.g., selecting the
option providing the largest gain) throughout our subject sample.
In contrast, we characterized brain regions as strategy related
based on their association with individual difference measures;
i.e., if the magnitude of their activation depended on whether
or not an individual engages in their preferred strategy, regardless of which of the choices that entails. Moreover, strategyrelated regions should exert a modulatory influence on choicerelated regions. A strong candidate for a strategy-related region
is the dorsomedial prefrontal cortex (dmPFC), which has been
shown to play an important role in tasks involving decision
conflict, as well as in making decisions that run counter to
general behavioral tendencies (De Martino et al., 2006; Pochon
et al., 2008). Moreover, this region exhibits distinct patterns of
functional connectivity to affective and cognitive networks (Meriau et al., 2006), making it a candidate for shaping activation in
those networks based on context and computational demands
(Behrens et al., 2007; Kennerley et al., 2006).
Using large-sample behavioral experiments, we first demonstrate systematic individual variability in decision making, with
a significant bias toward choices that maximize the overall probability of winning (i.e., toward a simplifying strategy). Then, using
fMRI, we show that distinct neural systems underlie choices
made on each trial and variability in strategic preferences across
individuals. Finally, we also demonstrate a striking relation
between neural sensitivity to monetary outcomes and individual
differences in strategic preferences, indicating that robust decision strategies may follow from the neural response to rewards.
These results demonstrate that decision making under uncertainty does not merely reflect competition between brain regions
predicting distinct decision variables; in addition, the relation
between neural activation and subsequent decisions is mediated by underlying strategic tendency.
RESULTS
We conducted two behavioral experiments (n1 = 128 and n2 = 71)
and one fMRI experiment (n = 23), all involving the basic paradigm illustrated in Figure 1. Subjects were young adult volunteers from the Duke University community (see Supplemental
Experimental Procedures for details on the experiments).
Research was conducted under protocols approved by the Institutional Review Boards of Duke University and Duke University
Medical Center.
Across both behavioral experiments (details available in
Supplemental Experimental Procedures), we found a significant
bias toward the Pmax choices (Figure S1 available online), extending prior findings in the behavioral literature (Payne, 2005).
In addition to demonstrating the robustness of the preferences
toward the Pmax choices, the second experiment also indicates
that this bias can be reversed or accentuated by experimental
manipulations. The findings from these studies are also consistent with Pmax choice representing a simplifying strategy (see
Supplemental Experimental Procedures). Finally, importantly

<-----Page 2----->Neuron
Strategies and Choices in Risky Decision Making

Figure 2. Distinct Sets of Brain Regions
Predict Choices
(A) Increased activation in the right anterior insula
(peak MNI space coordinates: x = 38, y = 28, z = 0)
and in the vmPFC (x = 16, y = 21, z = 23) predicted Lmin and Gmax choices, respectively, while
increased activation in the lateral prefrontal cortex
(x = 44, y = 44, z = 27) and PPC (x = 20, y = 76, z =
57) predicted Pmax choices. Activation maps show
active clusters that surpassed a threshold of z >
2.3 with cluster-based Gaussian random field
correction.
(B–D) Percent signal change in these three regions
to each type of choice. Error bars represent ± 1
standard error of the mean for each column.

for the goals of our imaging studies, we also found substantial
interindividual variability: some subjects nearly always preferred
a simplifying strategy (choosing the Pmax option in most trials);
others nearly always preferred a compensatory strategy
(choosing the Gmax or Lmin options in most trials), while still others
switched strategies on different trials resulting in both intra- and
intersubject variability in strategy (Figure S2).
Variability in Underlying Neural Mechanisms
We used high-field (4T) fMRI to evaluate the neural systems
associated with strategic decision making under uncertainty.
We adapted the basic design from our behavioral experiments
to the fMRI setting. Subjects first made a series of choices
without feedback. On each trial, subjects initially viewed the
decision options and then learned the assignment of choices
to responses, to eliminate any potential confounding effects of
response selection (Pochon et al., 2008). Then, following the
completion of all decision trials, we resolved a set of those trials
for real monetary rewards. This allowed us to measure rewardrelated activation without altering subsequent decisions through
learning.
Consistent with our two behavioral experiments, fMRI subjects
made Pmax choices on approximately 70% of the trials when the
choices were matched for expected value. Moreover, the proportion of Pmax choices was systematically modulated by the tradeoff in expected value between the choices, indicating that
subjects were not simply insensitive to expected value (Table
S1). We evaluated intrasubject choice consistency using splitsample analysis. We split each subject’s choices into samples
from odd-numbered runs and from even-numbered runs. There
was a strong correlation between the proportion of Pmax choices
in each sample (r = 0.61; p < 0.01), even without considering other
factors like relative expected value. For comparison, we used
a similar split-sample approach to estimate subject-specific

parameters for canonical expected utility
and cumulative prospect theory models
of decision making (see Supplemental
Experimental Procedures). We found
that model parameters estimated from
one half of the experimental data did not
significantly classify choices within the
other runs (Figure S3). Finally, the proportion of Pmax choices decreased with increasing self-reported
tendency to maximize (r = 0.67, p < 0.001; Figure S4).
Neural Predictors of Choices
Our initial analyses identified brain regions whose activation was
driven, across subjects and trials, by the selected choice. There
was greater activation in anterior insular cortex (aINS) and vmPFC
(Figure 2A) for the compensatory magnitude-sensitive choices
(combined across Gmax and Lmin). These regions are typically
associated with emotional function, particularly the affective evaluation of the outcome of a choice in decision-making tasks
(Bechara et al., 2000; Dalgleish, 2004; Paulus et al., 2003; Sanfey
et al., 2003). We subsequently performed a region of interest (ROI)
analysis to explore specifically the differences in activation
between Gmax and Lmin. Note that this analysis was restricted,
a priori, to a subset of 15 subjects with a sufficient number of
choices in each condition of interest. We found a clear double
dissociation between aINS and vmPFC: Gmax choices were associated with greater activation within vmPFC, whereas Lmin
choices were associated with increased activation in aINS
(Figures 2B and 2C). Conversely, Pmax choices resulted in
increased activation in the dorsolateral prefrontal cortex (dlPFC)
and posterior parietal cortex (PPC; Figure 2A and Table S2),
regions typically associated with executive function and decision
making under risk and uncertainty (Bunge et al., 2002; Huettel
et al., 2005, 2006; Paulus et al., 2001). These regions showed
greater activation for Pmax choices compared to both Gmax and
Lmin, but no difference between Gmax and Lmin options (Figure 2D).
Neural Predictors of Strategic Variability
across Individuals
We next investigated whether there were brain regions whose
activation varied systematically with individual differences in
strategic preferences. To do this, we entered each subject’s

Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc. 595

<-----Page 3----->Neuron
Strategies and Choices in Risky Decision Making

Figure 3. dmPFC Predicts Strategy Use
during Decision Making
(A and B) Activation in dmPFC (x = 10, y = 22, z =
45; indicated with arrow) and the rIFG exhibited
a significant decision-by-trait interaction, such
that the difference in activation between compensatory and simplifying choices was significantly
correlated with preference for simplifying strategy
(mean-subtracted) across individuals.
(C and D) Functional connectivity of dmPFC varied
as a function of strategy: there was increased
connectivity with dlPFC (and PPC) for simplifying
choices and increased connectivity with aINS
(and amygdala) for compensatory choices. Error
bars represent ± 1 standard error of the mean for
each column.

strategic preference as a normalized regressor into the acrosssubjects fMRI analyses of the contrast between choices. Strategic variability predicted individual differences in activation in
two clusters (Figures 3A and 3B): the dmPFC and the right inferior frontal gyrus (rIFG). Within these regions, there was no significant difference in activation between the choices. However,
there was a significant interaction: activation increased when
an individual with preference for the more compensatory
strategy made a simplifying Pmax choice and vice versa. We
focus on the dmPFC in the rest of this manuscript, based on
our prior hypothesis about the role of this region as well as the
fact that only this region significantly predicted trial-by-trial
choices (as discussed later).
We next evaluated whether dmPFC activation might shape
activation in those regions that predicted specific choices (i.e.,
Pmax: dlPFC and PPC; Lmin: aINS; Gmax: vmPFC), using seedvoxel-based whole-brain functional connectivity analyses. This
would provide additional converging evidence for the role of this
region in determining choice behavior, contingent on preferred
strategies. We found a double dissociation in the functional
connectivity of dmPFC depending on the choice made by the
subject (Figures 3C and 3D). When subjects made Pmax choices,
connectivity with dmPFC increased in dlPFC and PPC, whereas
when subjects made more magnitude-sensitive compensatory

596 Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc.

choices, connectivity increased in the
aINS (and amygdala, but not in vmPFC).
Moreover, the relative strength of the
connectivity between dmPFC and these
regions was significantly associated with
individual differences in strategy preferences across subjects (Figure S5). Finally,
we also conducted additional analyses to
rule out the possibility that dmPFC activation was related to response conflict, as
has been found in several previous studies
(Botvinick et al., 1999; Kerns et al., 2004;
details can be found in Supplemental
Experimental Procedures).
Thus, we provide a broad range of
converging results, drawn from overall
activation, functional connectivity, factor
analysis of behavioral data (see Supplemental Experimental
Procedures), association with individual differences in strategy,
and trial-by-trial analysis (below), that together indicate that
dmPFC supports strategic considerations during decision making by shaping behavior toward or against individual strategic
preferences.
Integrating Choices and Strategies to Predict Behavior
We used the brain regions implicated above as choice related
(aINS, vmPFC, dlPFC, and PPC) or strategy related (rIFG and
dmPFC) to predict choices on individual trials. We extracted,
for every trial for every subject, the activation amplitude in
each of these ROIs, along with the decision made on that trial.
We used a hierarchical logistic regression approach to evaluate
which of these regions were significant and independent predictors of trial-to-trial decisions (Table 1).
We first entered into the model subjects’ overall preference for
the simplifying strategy (proportion of Pmax choices). We found,
unsurprisingly, that this was a highly significant predictor of
trial-to-trial choices. Next, we used activation values from our
brain ROIs, considering them both in isolation and with strategic
preference already entered into the model. We found that activation in insular cortex was a significant predictor of magnitudesensitive choices, while parietal activation was a significant

<-----Page 4----->Neuron
Strategies and Choices in Risky Decision Making

Table 1. Predicting Trial-by-Trial Choices from Trait and Neural Data
Model Variables

Coefficient (SE)

Wald (Significance)

Trait
Constant

0.14 (0.05)

6.19 (0.13)

Proportion of Pmax choices

1.02 (.12)

70.79 (0.000)

Constant

0.21 (0.06)

13.10 (0.000)

Right PPC

32.41 (8.43)

14.80 (0.000)

Right anterior insula

40.52 (13.28)

9.31 (0.002)

0.22 (0.06)

13.38 (0.000)

Brain

Trait (+ Brain)
Constant
Proportion of Pmax choices

1.00 (0.12)

67.23 (0.000)

Right PPC

30.54 (8.62)

12.56 (0.000)

Right anterior insula

33.32 (13.69)

5.93 (.012)

0.23 (0.06)

13.78 (.000)

Trait + Brain + (Trait*Brain)
Constant
Proportion of Pmax choices

1.10 (0.13)

71.75 (.000)

Right PPC

31.96 (8.70)

13.49 (.000)

Right anterior insula

33.00 (13.77)

5.74 (.017)

dMPFC * strategic variability

70.58 (26.28)

7.21 (.007)

Model Significance (c2)

Model Fit (Nagelkerke R2)

76.09

0.069

18.05

0.017

90.26

0.081

97.66

0.088

All c2 values were highly significant (p < 10 4). We used stepwise logistic regression to evaluate the contributions of trait effects (i.e., overall proportion
of choices) and brain effects (i.e., activation of a given region on a given trial) to the specific choices (coded as a binary variable of Pmax choice) made by
subjects. As expected, subjects’ overall preference for simplifying strategy was a good predictor of Pmax choices on individual trials. An independent
logistic regression analysis revealed that two brain regions, the PPC and anterior insula, were significant positive and negative predictors of Pmax
choices and that these regions remained significant predictors even when the behavioral data were included in the model. Note that the dmPFC
activation, when not weighted by strategy, did not significantly improve the model fit at any stage. However, when weighted by strategy, the resulting
brain * strategy variable was a highly significant predictor of choices, even when the strategy itself was already included in the model. Regions not
indicated in this table were not significant predictors of choice behavior.

predictor of Pmax choices. Critically, activation in these brain
regions improved the fit of the model even when the behavioral
data had already been included. None of the other regions,
including dmPFC, predicted either type of choice. Yet, when
we weighted dmPFC activation with each subject’s strategy
preference, the resulting variable became a significant and
robust predictor of behavior and overall model error was
reduced (Table 1). Thus, dmPFC activation does not predict
either type of choice, but instead predicts choices that are inconsistent with one’s preferred decision strategy.
We emphasize that the brain-behavior relations reported here
were highly significant even though the behavioral choice data
across trials for each subject (an indicator of behavioral strategy)
were already included in the logistic regression model. That is,
we could use the fMRI activation evoked within key brain regions
to improve our predictions of subjects’ decisions on individual
trials over what was predicted from behavioral data alone.
Neural Reward Sensitivity Predicts Individual
Differences in Strategy
Finally, we evaluated whether an independent neural measure of
reward sensitivity could predict the strategic preferences outlined in the previous sections. At the end of the scanning session,
each subject passively viewed a subset of their improved
gambles, which were each resolved to an actual monetary gain
or loss. While subjects were anticipating the outcome of each

gamble, there was increased activation in the ventral striatum
(vSTR), a brain region commonly implicated in learning about
positive and negative rewards (Schultz et al., 1997; Seymour
et al., 2007; Yacubian et al., 2006). Then, when the gamble
was resolved, vSTR activation increased to gains but decreased
to losses (Figures 4A and 4B). Moreover, there were striking and
significant correlations between strategic variability and vSTR
activation: those individuals who showed the greatest vSTR
increases to gains and decreases to losses both preferred the
simplifying Pmax strategy (Figure 4C) and scored low on a behavioral measure of maximizing (Figure S6). These results suggest
that the use of a simplifying strategy that improves one’s overall
chances of winning (Pmax) may result from increased neural
sensitivity to reward outcomes.
DISCUSSION
When facing complex decision situations, many individuals
engage in simplifying strategies, such as choosing based on
the overall probability of a positive outcome, to reduce computational demands compared to compensatory strategies. Here, we
demonstrated two neural predictors of strategic variability in
decision making. First, during the decision process, the dmPFC
shapes choices (in a manner depending on strategic tendency)
through changes in functional connectivity with insular and
prefrontal cortices. Second, independent neurometric responses

Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc. 597

<-----Page 5----->Neuron
Strategies and Choices in Risky Decision Making

Figure 4. Ventral Striatal Sensitivity to Rewards Predicts Strategic Variability
At the end of the experiment, some gambles were resolved to monetary gains or losses.
(A and B) Activation in the vSTR (x = 14, y = 16, z = 10) increased when subjects were waiting for gambles to be resolved (anticipation) and, after resolution,
increased to gains but decreased to losses. Error bars represent ± 1 standard error of the mean for each column.
(C) Notably, the difference between gain-related and loss-related activation in the vSTR correlated with variability in strategic preferences across subjects, with
subjects who were most likely to prefer the Pmax exhibiting the greatest neural sensitivity to rewards.

to rewards predicted strategic preferences: those individuals
with the greatest striatal sensitivity to reward valence are most
likely to use a simplifying strategy that emphasizes valence, but
ignores magnitude. These results provide clear and converging
evidence that the neural mechanisms of choice reflect more
than competition between decision variables; they additionally
involve strategic influences that vary across trials and individuals.
A large literature suggests that decisions between simple
gambles can be predicted by compensatory models like expected utility and Cumulative Prospect Theory (Fennema and
Wakker, 1997; Huettel et al., 2006; Preuschoff et al., 2008; Wu
et al., 2004). Individual differences in sensitivity to the parameters within these models lead to distinct patterns of choices,
even when the same model is applied to all individuals (Huettel
et al., 2006; Tom et al., 2007). As decision problems become
more complex, however, the assumption of a single canonical
decision strategy becomes more and more problematic. As suggested by Tversky and Kahneman (1992) and Payne et al. (1993),
people employ a variety of strategies to represent decision problems and evaluate options. Some of those strategies will be
consistent with traditional models like expected utility maximization, whereas other strategies will be more heuristic or simplifying. Further, depending on the decision context, people shift
among multiple strategies to maintain a balance between minimizing cognitive effort or maximizing decision accuracy, among
other goals (Payne et al., 1993). Finally, strategy use to solve the
same decision problem differs across individuals, perhaps reflecting trait differences such as a tendency toward satisficing
versus maximizing. Our findings, from both behavioral and neuroimaging experiments, provide evidence in favor of intra- and
intersubject variability in the use of strategies across participants. Importantly, we show that the parameters estimated
using traditional economic models of risky choice were poor
predictors of choices in our paradigm, providing possible
evidence for differences in decision strategy within and across
participants.
One influential conjecture in decision making is that people
frequently use a variety of simplifying heuristics that reduce effort

598 Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc.

associated with the decision process (Shah and Oppenheimer,
2008; Simon, 1957). Pmax choices in the current task are consistent with such an effort-reduction framework, given that they
were associated with faster response times in the behavioral
experiments (note that we do not have accurate estimates of
response times in the imaging experiment as we sought to
explicitly separate the decision and response phases in our
design) and that the proportion of Pmax choices decreased adaptively with increasing cost in terms of expected value in all experiments. We suggest, therefore, that strategic preferences in the
current task reflect tradeoffs, resolved differently by individual
subjects and over trials, between one strategy that simplifies
a complex decision problem by using a simple heuristic of maximizing the chances of winning (Pmax) and another, more
compensatory strategy that involves consideration of additional
information as well as the emotions associated with extreme
gains (Gmax) or losses (Lmin).
To the extent that the Pmax choices reflect a more simplifying
strategy, the pattern of activations seen in this study seems
counterintuitive: the regions conventionally associated with
automatic and affective processing (aINS and vmPFC) predicted
magnitude-sensitive choices that were more consistent with
traditional economic models such as expected utility maximization, whereas the regions conventionally associated with executive functions (dlPFC and PPC) predicted choices more consistent with a simplifying strategy. The lateral prefrontal cortex
has been shown in previous studies to be active during probabilistic decision making (Heekeren et al., 2004, 2006) as well as
sensitive to individual differences in the processing of probability
(Tobler et al., 2008). Neurons within this region have also been
shown to track reward probabilities (Kobayashi et al., 2002)
and process reward and action in stochastic situations (Barraclough et al., 2004). Similarly, the parietal cortex also plays an
important role in tracking outcome probabilities (Dorris and
Glimcher, 2004; Huettel et al., 2005). Given that Pmax choices
are based on the overall probability of winning, activation in
dlPFC and PPC could be associated with tracking subjective
probabilities in these gambles.

<-----Page 6----->Neuron
Strategies and Choices in Risky Decision Making

Conversely, the Gmax and Lmin choices increase the chances of
an aversive outcome, relative to a neutral aspiration level (Lopes
and Oden, 1999). Supporting this interpretation, we found a clear
double dissociation with activation in vmPFC predicting Gmax
choices and activation in aINS predicting Lmin choices. The
contributions of vmPFC to gain-seeking behavior (at the expense
of potential losses) have been documented in both patient
(Bechara et al., 2000) and neuroimaging studies (Tobler et al.,
2007). Conversely, there has been substantial recent work
demonstrating the importance of aINS for aversion to negative
consequences, even to the point of making risk-averse mistakes
in economic decisions (Kuhnen and Knutson, 2005; Paulus et al.,
2003; Preuschoff et al., 2008; Rolls et al., 2008). Together, these
findings suggest that the conventional notion that decisions
reflect compensatory balancing of decision variables is an oversimplification. In addition, different brain regions bias how
people approach decision problems, which may in turn lead to
one form of behavior or another depending on the task context.
Furthermore, the balance between cognitive and affective
brain regions did not, by itself, explain individual differences in
strategy preferences. Activation in another region, dmPFC, predicted variability in strategic preferences across subjects. We
note that the role of dmPFC in complex decision making remains
relatively unknown. One very recent experiment found increased
activation in this region when subjects faced greater decisionrelated conflict (Pochon et al., 2008), as dissociable from the
more commonly reported response conflict (Botvinick et al.,
2001). A similar region of dmPFC was implicated by De Martino
et al. (2006), again when subjects made decisions counter to
their general behavioral tendency (i.e., against typical framing
effects). However, it is important to note that all subjects in their
study exhibited a bias toward using the framing heuristic, while in
the current study subjects varied in their relative preference for
two different strategies. Therefore, a parsimonious explanation
for the function of this region of dmPFC is that it supports
aspects of decision making that are coded in relation to an
underlying strategic tendency, not effects specific to framing.
Further support for this hypothesis is provided by the differential
functional connectivity of the dmPFC to dlPFC and anterior insula for simplifying and compensatory choices, respectively.
These findings are consistent with the interpretation that activation differences of the dmPFC shape behavior by modulating
choice-related brain regions, with the strength of this modulatory
effect dependent on an individual’s preferred strategy.
We additionally observed a striking relationship between neurometric sensitivity to reward and strategic biases across individuals. Our initial analyses found that activation of the vSTR
increased when anticipating the outcome of a monetary gamble,
increased further if that gamble was resolved to a gain, but
decreased if that gamble was resolved to a loss. This pattern
of results was consistent with numerous prior studies using
human neuroimaging (Breiter et al., 2001; Delgado et al., 2000;
Seymour et al., 2007) and primate electrophysiology (Schultz
et al., 1997). However, we additionally observed the result that
the magnitude of the vSTR response was a strong predictor of
individual strategic preferences. Specifically, the sensitivity to
gains and losses in the vSTR is greatest for individuals who
prefer the Pmax choices, consistent with their strategy of

maximizing their chances of winning. We emphasize that the
gambles were not resolved until after all decisions were made,
so this effect could not be attributed to learning from outcomes.
Although our design does not allow determination of the direction of causation, these results suggest that an increased sensitivity to reward valence may lead to simple decision rules that
overemphasize the probability of achieving a positive outcome.
Depending on the circumstances, organisms may adopt strategies that emphasize different forms of computation, whether to
obtain additional information (Daw et al., 2006), to improve
models of outcome utility (Montague and Berns, 2002), or to
simplify a complex decision problem. Accordingly, the activation
of a given brain system (e.g., dlPFC) may sometimes lead to
behavior consistent with economic theories of rationality (Sanfey
et al., 2003) and in other circumstances (such as the present
experiment) predict a nonnormative choice consistent with
a simplifying strategy. Our results demonstrate that decision
making reflects an interaction among brain systems coding for
different sorts of computations, with some regions (e.g., aINS
and vmPFC) coding for specific behaviors and others (e.g.,
dmPFC) for preferred strategies.
EXPERIMENTAL PROCEDURES
Subjects
We conducted two behavioral experiments (n1 = 128 and n2 = 71) and one fMRI
experiment (n = 23). All subjects were young adults who participated for monetary payment. All subjects gave written informed consent as part of protocols
approved by the Institutional Review Boards of Duke University and Duke
University Medical Center. Details of the procedures for the behavioral experiments can be found in the Supplemental Experimental Procedures.
Twenty-three healthy, neurologically normal young-adult volunteers
(13 female; age range 18–31 years; mean age 24 years) participated in the
fMRI session. No subject was repeated from the behavioral pilot session. All
subjects acclimated to the fMRI environment using a mock MRI scanner and
participated in two short practice runs consisting of six trials each, one inside
and one outside of the fMRI scanner. Three subjects were excluded from some
analyses involving strategy effects due to lack of variability in their response
(two subjects always chose the Pmax option while the third subject never chose
the Pmax option), leaving a total of 20 subjects in the complete analyses of
the decision-making trials. One additional subject was excluded from the
outcome-delivery trials due to a computer error in saving the timing associated
with the trials.
At the outset of the experiment, subjects were provided detailed instructions
about the payment procedures (see Supplemental Experimental Procedures
for details). They were then given a sealed envelope that contained an endowment to offset potential losses; this envelope was sufficiently translucent that
they could see that there was cash inside, even though the quantity could not
be determined. Subjects were also told that there was no deception in the
study and were given an opportunity to question the experimenter about any
procedures before entering the scanner. All subjects expressed that they
understood and believed in the procedures.
Experimental Stimuli
In the fMRI experiment, all subjects were presented with a total of 120 fiveoutcome mixed gambles in a completely randomized order. Each of the
gambles comprised two positive outcomes (an extreme outcome of $65 to
$80 and an intermediate outcome of $35 to $50), two negative outcomes (an
extreme outcome of $65 to $85 and an intermediate outcome of $35 to
$50), and a central, reference outcome. The reference outcome was $0 in
half the trials and a negative value ranging from $10 to $25 in the remaining
half of the trials. Probabilities of each of the five outcomes varied between 0.1
and 0.3 in units of 0.05 and always summed to 1 across the five outcomes. We

Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc. 599

<-----Page 7----->Neuron
Strategies and Choices in Risky Decision Making

describe the similar stimuli and methods for the behavioral experiments in the
Supplemental Experimental Procedures.
On each trial, subjects could choose between two options for adding money
to one of the outcomes. Adding to the reference outcome increased the overall
chance of winning money compared to losing money and hence was called
the Pmax choice. Alternatively, adding money to an extreme option either
increased the magnitude of the best monetary outcome or decreased the
magnitude of the worst monetary outcome and hence were referred to as
Gmax and Lmin choices, respectively. The amount of money that subjects could
add to the outcomes ranged between $10 and $25 and could differ between
the two outcomes. For trials with negative reference values, one of the options
for adding money always changed the reference option to $0. All outcome
values used in this experiment were multiples of $5.
Expected value relations between the two choices were systematically
manipulated by changing the amount and/or probabilities associated with
each of the options (See Supplemental Experimental Procedures). Only trial
types that placed the two choices in maximal conflict (72 gambles per subject)
were included in the primary imaging analyses; other trials were included in the
model as separate regressors, but not further analyzed. Note that the trials
were counterbalanced for valence of the extreme outcome (i.e., gain or loss)
and for valence of the reference outcome (i.e., neutral or loss).
Experimental Design
Each trial began with the display of a five-outcome gamble for 4 or 6 s
(Figure 1). Subjects were instructed to examine each gamble as it was presented. Subsequently, subjects were given a choice between two ways of
improving the gamble. The amount that could be added and the resulting
modified outcome values were displayed in red for both choices, to minimize
individual differences resulting from calculation or estimation biases. The
modified gamble remained on the screen for 6 s, whereupon two arrows appeared to specify which button corresponded to which choice. The association of the buttons to choice was random. Subjects then pressed the button
corresponding to their choice. Response times were coded as the time
between the appearance of arrows and the button press response (note that
this may not be a true representation of the actual decision times in this
task). Subjects were instructed to arrive at their decision during the 6 s interval
and to press the button corresponding to their choice as soon as the arrows
appeared. The decision and response phases were explicitly separated to
prevent the contamination of decision effects with response-preparation
effects. During the intertrial interval of 4–8 s, a fixation cross was displayed
on the screen. Notice that no feedback was provided at the end of each trial
and hence there was no explicit learning during the decision phase of the task.
Subjects participated in six runs of this decision task, each containing 20
gambles and lasting approximately 6 min. Before those runs, subjects had
the opportunity to practice the experimental task (without reward) in two sixgamble blocks, one presented outside the MRI scanner and the other presented within the MRI scanner but prior to collection of the fMRI data. All
stimuli were created using the Psychophysics Toolbox (Brainard, 1997; Pelli,
1997) for MATLAB (Mathworks, inc.) and were presented to the subjects via
MR-compatible LCD goggles. Subjects responded with the index fingers of
each hand via a MR-compatible response box.
After completion of the decision phase, there was a final 6 min run in which
40 of the improved gambles were resolved to an actual monetary gain or loss.
These gambles were selected randomly from the gambles presented during
the decision phase and were presented in modified form based on that
subject’s choices. On each trial, subjects passively viewed one of these
improved gambles on the screen for 2 s (anticipation phase), during which
time random numbers flashed rapidly at the bottom of the screen before stopping at a particular value. A text message corresponding to the amount won or
lost was then displayed for 1 s, followed by an intertrial fixation period of 3–7 s
before the onset of the next trial.
Imaging Methods
We acquired fMRI data on a 4T GE scanner using an inverse-spiral pulse
sequence (Glover and Law, 2001; Guo and Song, 2003) with the following
parameters: TR = 2000 ms; TE = 30 ms; 34 axial slices parallel to the AC-PC
plane, with voxel size of 3.75 3 3.75 3 3.8 mm. High-resolution 3D full-brain

600 Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc.

SPGR anatomical images were acquired and used for normalizing and coregistering individual subjects’ data.
Analysis was carried out using FMRI Expert Analysis Tool (version 5.63),
which is part of FMRIB’s Software Library (www.fmrib.ox.ac.uk/fsl) package
(Smith et al., 2004). The following pre-statistics processing steps were applied:
motion correction using MCFLIRT, slice-timing correction, removal of nonbrain voxels using BET, spatial smoothing with a Gaussian kernel of FWHM
8 mm, and high-pass temporal filtering. Registration to high-resolution and
standard images was carried out using FLIRT. All statistical images presented
were thresholded using clusters determined by z > 2.3 and a whole-brain corrected cluster significance threshold of p < 0.05.
We used separate first-level regression models to analyze decision effects
and outcome effects. The decision model comprised two regressors modeling
the magnitude-sensitive compensatory choices (Gmax and Lmin were
combined for additional power) and simplifying Pmax choices in the conflict
conditions, one regressor modeling the responses in the remaining conditions,
one regressor for the initial presentation of the gamble, and one regressor to
model the subject responses. (An additional post-hoc analysis on a subset
of 15 subjects separated the magnitude-sensitive choices according to
whether they were Gmax or Lmin.) Analysis for the outcome phase consisted
of three regressors: one to model the anticipation phase (as subjects were
waiting for the corresponding outcome to be revealed), one for positive
outcomes (gain), and one for negative outcomes (loss). All regressors were
generated by convolving impulses at the onsets of events of interest with
a double-gamma hemodynamic response function. Second-level analysis
for condition and decision effects within each subject was carried out using
a fixed-effects model across runs. Random-effects across-subjects analyses
were carried out using FLAME (stage 1 only). When evaluating the effects of
behavioral traits (transformed into z scores) on brain function, we included
our subjects’ trait measures as additional covariates in the third-level analysis.
Logistic Regression Models of Trial-by-Trial Choices
For obtaining the parameter estimates from individual trials for trial-by-trial
prediction analysis, we used data that were corrected for motion and differences in slice scan timing but were not smoothed. The data were also transformed into standard space on which the individual ROIs were defined. We
used seven different ROIs for this analysis: the right anterior insula and vmPFC,
which show greater activation for Lmin and Gmax choices respectively; the right
PPC, the right precuneus, and right dlPFC, which show greater activation for
Pmax choices; and finally the dmPFC and rIFG, which track strategic variability
across subjects. All ROIs were defined functionally based on the third-level
activation maps. Activation amplitude was defined as the mean signal change
(in percent) over the 6 s time interval from 4 s to 10 s after the onset of decision
phase (i.e., when subjects are shown the two alternative choices). This time
window was chosen to encompass the maximal signal change of the fMRI
hemodynamic response. A summary measure was obtained for each ROI by
averaging over all constituent voxels.
We then performed a hierarchical logistic regression using SPSS to predict
the choices made by subjects on each individual trial based on strategic preference (proportion of Pmax choices), brain activation, and interactions between
trait and activation. The complete model included a total of 1440 trials (72 trials
for each of 20 subjects). Parameters were entered into the model in a stepwise
manner, starting with just the behavioral trait measure, then brain activations
from the seven ROIs, and finally an interaction term consisting of activation
in dmPFC multiplied by strategic tendency. All parameters that significantly
improved the model at each stage are summarized in Table 1. The results
were consistent regardless of whether forward selection or backward elimination was used in the hierarchical regression.
Functional-Connectivity Analyses
We used a modified version of the decision model described above to perform
task-related connectivity analysis. A seed region was defined using activation
in the dmPFC that covaried with the strategic variability across subjects
(Figure 3). For each run for each subject, we then extracted the time series
from this region. A box-car vector was then defined for each condition of
interest, with the ‘‘on’’ period defined from 4 s to 10 s after the onset of the
decision phase for each trial in that condition. These box-car vectors were

<-----Page 8----->Neuron
Strategies and Choices in Risky Decision Making

then multiplied with the extracted time series to form the connectivity regressors. This allowed us to examine brain connectivity as a function of strategy,
specific to the decision phase. These regressors were then used as covariates
in a separate GLM analysis, which included the original variables of interest,
from the decision model described above (Cohen et al., 2005). Group activation maps were then obtained in the same way as the traditional regression
analysis. A positive activation for the connectivity regressors indicates that
the region correlates more positively with the seed region during the experimental condition of interest.

SUPPLEMENTAL DATA
Supplemental Data include Supplemental Experimental Procedures, two
tables, and eight figures and can be found with this article online at http://
www.cell.com/neuron/supplemental/S0896-6273(09)00288-8.

ACKNOWLEDGMENTS
We thank Antonio Rangel and Charles Noussair for suggestions about
behavioral analyses; Michael Platt, Alison Adcock, and Enrico Diecidue for
comments on the manuscript; Adrienne Taren for assistance with the connectivity analysis; and Kelsey Merison for assistance in data collection. All authors
contributed to the design of the experiments. V.V. led the programming of the
experiments, data collection, and data analysis, in collaboration with S.A.H. All
authors contributed to writing and editing the final manuscript. This research
was supported by the U.S. National Institute of Mental Health (NIMH-70685)
and by the U.S. National Institute of Neurological Disease and Stroke
(NINDS-41328). S.A.H. was supported by an Incubator Award from the Duke
Institute for Brain Sciences.
Accepted: April 7, 2009
Published: May 27, 2009
REFERENCES
Barraclough, D.J., Conroy, M.L., and Lee, D. (2004). Prefrontal cortex and
decision making in a mixed-strategy game. Nat. Neurosci. 7, 404–410.
Bechara, A., Tranel, D., and Damasio, H. (2000). Characterization of the decision-making deficit of patients with ventromedial prefrontal cortex lesions.
Brain 123, 2189–2202.
Behrens, T.E., Woolrich, M.W., Walton, M.E., and Rushworth, M.F. (2007).
Learning the value of information in an uncertain world. Nat. Neurosci. 10,
1214–1221.
Birnbaum, M.H. (2008). New paradoxes of risky decision making. Psychol.
Rev. 115, 463–501.
Botvinick, M., Nystrom, L.E., Fissell, K., Carter, C.S., and Cohen, J.D. (1999).
Conflict monitoring versus selection-for-action in anterior cingulate cortex.
Nature 402, 179–181.
Botvinick, M.M., Braver, T.S., Barch, D.M., Carter, C.S., and Cohen, J.D.
(2001). Conflict monitoring and cognitive control. Psychol. Rev. 108, 624–652.

Coricelli, G., Critchley, H.D., Joffily, M., O’Doherty, J.P., Sirigu, A., and Dolan,
R.J. (2005). Regret and its avoidance: a neuroimaging study of choice
behavior. Nat. Neurosci. 8, 1255–1262.
Dalgleish, T. (2004). The emotional brain. Nat. Rev. Neurosci. 5, 583–589.
Daw, N.D., O’Doherty, J.P., Dayan, P., Seymour, B., and Dolan, R.J. (2006).
Cortical substrates for exploratory decisions in humans. Nature 441, 876–879.
De Martino, B., Kumaran, D., Seymour, B., and Dolan, R.J. (2006). Frames,
biases, and rational decision-making in the human brain. Science 313,
684–687.
Delgado, M.R., Nystrom, L.E., Fissell, C., Noll, D.C., and Fiez, J.A. (2000).
Tracking the hemodynamic responses to reward and punishment in the striatum. J. Neurophysiol. 84, 3072–3077.
Dorris, M.C., and Glimcher, P.W. (2004). Activity in posterior parietal cortex is
correlated with the relative subjective desirability of action. Neuron 44,
365–378.
Fennema, H., and Wakker, P. (1997). Original and cumulative prospect theory:
a discussion of empirical differences. J. Behav. Decis. Making 10, 53–64.
Gigerenzer, G., and Goldstein, D.G. (1996). Reasoning the fast and frugal way:
models of bounded rationality. Psychol. Rev. 103, 650–669.
Glover, G.H., and Law, C.S. (2001). Spiral-in/out BOLD fMRI for increased SNR
and reduced susceptibility artifacts. Magn. Reson. Med. 46, 515–522.
Guo, H., and Song, A.W. (2003). Spiral-in-and-out functional image acquisition
with embedded z-shimming for susceptibility signal recovery. J. Magn. Reson.
Imaging 18, 389–395.
Heekeren, H.R., Marrett, S., Bandettini, P.A., and Ungerleider, L.G. (2004). A
general mechanism for perceptual decision-making in the human brain. Nature
431, 859–862.
Heekeren, H.R., Marrett, S., Ruff, D.A., Bandettini, P.A., and Ungerleider, L.G.
(2006). Involvement of human left dorsolateral prefrontal cortex in perceptual
decision making is independent of response modality. Proc. Natl. Acad. Sci.
USA 103, 10023–10028.
Hsu, M., Bhatt, M., Adolphs, R., Tranel, D., and Camerer, C.F. (2005). Neural
systems responding to degrees of uncertainty in human decision-making.
Science 310, 1680–1683.
Huettel, S.A. (2006). Behavioral, but not reward, risk modulates activation of
prefrontal, parietal, and insular cortices. Cogn. Affect. Behav. Neurosci. 6,
141–151.
Huettel, S.A., Song, A.W., and McCarthy, G. (2005). Decisions under uncertainty: probabilistic context influences activity of prefrontal and parietal
cortices. J. Neurosci. 25, 3304–3311.
Huettel, S.A., Stowe, C.J., Gordon, E.M., Warner, B.T., and Platt, M.L. (2006).
Neural signatures of economic preferences for risk and ambiguity. Neuron 49,
765–775.
Kahneman, D., and Frederick, S. (2002). Representativeness revisited: attribute substitution in intuitive judgement. In Hurestics and Biases: The
Psychology of Intuitive Thought, T. Gilovich, D. Griffin, and D. Kahneman,
eds. (New York: Cambridge University Press), pp. 49–81.

Brainard, D.H. (1997). The psychophysics toolbox. Spat. Vis. 10, 433–436.

Kennerley, S.W., Walton, M.E., Behrens, T.E., Buckley, M.J., and Rushworth,
M.F. (2006). Optimal decision making and the anterior cingulate cortex. Nat.
Neurosci. 9, 940–947.

Breiter, H.C., Aharon, I., Kahneman, D., Dale, A., and Shizgal, P. (2001). Functional imaging of neural responses to expectancy and experience of monetary
gains and losses. Neuron 30, 619–639.

Kerns, J.G., Cohen, J.D., MacDonald, A.W., 3rd, Cho, R.Y., Stenger, V.A., and
Carter, C.S. (2004). Anterior cingulate conflict monitoring and adjustments in
control. Science 303, 1023–1026.

Bunge, S.A., Hazeltine, E., Scanlon, M.D., Rosen, A.C., and Gabrieli, J.D.
(2002). Dissociable contributions of prefrontal and parietal cortices to
response selection. Neuroimage 17, 1562–1571.

Kobayashi, S., Lauwereyns, J., Koizumi, M., Sakagami, M., and Hikosaka, O.
(2002). Influence of reward expectation on visuospatial processing in macaque
lateral prefrontal cortex. J. Neurophysiol. 87, 1488–1498.

Camerer, C.F. (2003). Behavioural studies of strategic thinking in games.
Trends Cogn. Sci. 7, 225–231.

Kuhnen, C.M., and Knutson, B. (2005). The neural basis of financial risk taking.
Neuron 47, 763–770.

Cohen, M.X., Heller, A.S., and Ranganath, C. (2005). Functional connectivity
with anterior cingulate and orbitofrontal cortices during decision-making.
Brain Res. Cogn. Brain Res. 23, 61–70.

Lopes, L.L., and Oden, G.C. (1999). The role of aspiration level in risky choice:
a comparison of cumulative prospect theory and SP/A theory. J. Math. Psychol. 43, 286–313.

Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc. 601

<-----Page 9----->Neuron
Strategies and Choices in Risky Decision Making

Loewenstein, G., Rick, S., and Cohen, J.D. (2008). Neuroeconomics. Annu.
Rev. Psychol. 59, 647–672.

Sanfey, A.G., Rilling, J.K., Aronson, J.A., Nystrom, L.E., and Cohen, J.D.
(2003). The neural basis of economic decision-making in the Ultimatum
Game. Science 300, 1755–1758.

Meriau, K., Wartenburger, I., Kazzer, P., Prehn, K., Lammers, C.H., van der
Meer, E., Villringer, A., and Heekeren, H.R. (2006). A neural network reflecting
individual differences in cognitive processing of emotions during perceptual
decision making. Neuroimage 33, 1016–1027.

Schultz, W., Dayan, P., and Montague, P.R. (1997). A neural substrate of
prediction and reward. Science 275, 1593–1599.

Montague, P.R., and Berns, G.S. (2002). Neural economics and the biological
substrates of valuation. Neuron 36, 265–284.

Seymour, B., Daw, N., Dayan, P., Singer, T., and Dolan, R. (2007). Differential
encoding of losses and gains in the human striatum. J. Neurosci. 27, 4826–
4831.

Paulus, M.P., Hozack, N., Zauscher, B., McDowell, J.E., Frank, L., Brown,
G.G., and Braff, D.L. (2001). Prefrontal, parietal, and temporal cortex networks
underlie decision-making in the presence of uncertainty. Neuroimage 13,
91–100.
Paulus, M.P., Rogalsky, C., Simmons, A., Feinstein, J.S., and Stein, M.B.
(2003). Increased activation in the right insula during risk-taking decision
making is related to harm avoidance and neuroticism. Neuroimage 19,
1439–1448.
Payne, J.W. (2005). It is whether you win or lose: the importance of the overall
probabilities of winning or losing in risky choice. J. Risk Uncertain. 30, 5–19.
Payne, J.W., Bettman, J.R., and Johnson, E.J. (1988). Adaptive strategy selection in decision making. J. Exp. Psychol. Learn. Mem. Cogn. 14, 534–552.

Shah, A.K., and Oppenheimer, D.M. (2008). Heuristics made easy: an effortreduction framework. Psychol. Bull. 134, 207–222.
Simon, H.A. (1957). Models of Man: Social and Rational (New York: Wiley).
Smith, S.M., Jenkinson, M., Woolrich, M.W., Beckmann, C.F., Behrens, T.E.J.,
Johansen-Berg, H., Bannister, P.R., De Luca, M., Drobnjak, I., Flitney, D.E.,
et al. (2004). Advances in functional and structural MR image analysis and
implementation as FSL. Neuroimage 23, S208–S219.
Tobler, P.N., O’Doherty, J.P., Dolan, R.J., and Schultz, W. (2007). Reward
value coding distinct from risk attitude-related uncertainty coding in human
reward systems. J. Neurophysiol. 97, 1621–1632.

Payne, J.W., Bettman, J.R., Coupey, E., and Johnson, E.J. (1992). A constructive process view of decision-making—multiple strategies in judgment and
choice. Acta Psychol. (Amst.) 80, 107–141.

Tobler, P.N., Christopoulos, G.I., O’Doherty, J.P., Dolan, R.J., and Schultz, W.
(2008). Neuronal distortions of reward probability without choice. J. Neurosci.
28, 11703–11711.

Payne, J.W., Bettman, J.R., and Johnson, E.J. (1993). The Adaptive Decision
Maker (Cambridge, UK: Cambridge University Press).

Tom, S.M., Fox, C.R., Trepel, C., and Poldrack, R.A. (2007). The neural basis of
loss aversion in decision-making under risk. Science 315, 515–518.

Pelli, D.G. (1997). The VideoToolbox software for visual psychophysics: transforming numbers into movies. Spat. Vis. 10, 437–442.
Platt, M.L., and Huettel, S.A. (2008). Risky business: the neuroeconomics of
decision making under uncertainty. Nat. Neurosci. 11, 398–403.
Pochon, J.B., Riis, J., Sanfey, A.G., Nystrom, L.E., and Cohen, J.D. (2008).
Functional imaging of decision conflict. J. Neurosci. 28, 3468–3473.

Tversky, A., and Kahneman, D. (1974). Judgment under uncertainty: heuristics
and biases. Science 185, 1124–1131.
Tversky, A., and Kahneman, D. (1992). Advances in prospect theory: cumulative representation of uncertainty. J. Risk Uncertain. 5, 297–323.

Preuschoff, K., Quartz, S.R., and Bossaerts, P. (2008). Human insula activation
reflects risk prediction errors as well as risk. J. Neurosci. 28, 2745–2752.

Wu, G., Zhang, J., and Gonzalez, R. (2004). Decision under risk. In Handbook
of Judgment and Decision Making, D. Koehler and N. Harvey, eds. (Oxford,
UK: Blackwell Publishing).

Rolls, E.T., McCabe, C., and Redoute, J. (2008). Expected value, reward
outcome, and temporal difference error representations in a probabilistic decision task. Cereb. Cortex 18, 652–663.

Yacubian, J., Glascher, J., Schroeder, K., Sommer, T., Braus, D.F., and
Buchel, C. (2006). Dissociable systems for gain- and loss-related value predictions and errors of prediction in the human brain. J. Neurosci. 26, 9530–9537.

602 Neuron 62, 593–602, May 28, 2009 ª2009 Elsevier Inc.

<-----Page 10----->Venkatraman et al.

Neural Strategic Variability

Separate Neural Mechanisms Underlie Choices and
Strategic Preferences in Risky Decision Making
Supporting Online Material
Behavioral Experiment 1
One hundred twenty eight young adults participated in the first behavioral experiment conducted
at the Fuqua School of Business. All subjects were compensated for their participation in this
study with a fixed payout ($8) not related to their choices. All subjects provided informed consent
as a part of a protocol approved by the Institutional Review Board of Duke University.

Subjects were presented with eight three-outcome and eight five-outcome mixed gambles on a
computer using the Psychophysics Toolbox program in MATLAB (Brainard, 1997; Pelli, 1997).
Cognitive load was also manipulated between-subjects by asking subjects to memorize 3 or 7letter pseudo-words for each trial. For compatibility with the imaging data, only results from the
eight five-outcome gambles, collapsed across both the load conditions, are presented here. First,
each subject was presented with a risky gamble and asked to rate its attractiveness. Subsequently,
they were given two choices for modifying the gamble, one of which always involved adding a
fixed amount to the reference to maximize the overall probability of winning (Pmax option) and
another which involved adding the same amount to either the extreme loss to minimize the worst
possible loss (Lmin) or the extreme gain outcome to maximize the best possible gain (Gmax option).
Subjects were shown both versions of the modified gamble on the screen beside each other and
were asked to choose one of the options. There was no time constraint for making the choice. In
four gambles, the probabilities of the two outcomes were matched (equal expected value) while
for the remaining four gambles, the probability associated with Pmax choice was less than the
probability of the alternative choice by 5 or 10% (unequal expected value).

As hypothesized, there were significant biases toward Pmax choice (overall proportion = 0.69)
when expected value was matched (Supplementary Fig. 1). Even when choosing the Pmax option
required sacrificing expected value (i.e., when the alternative option resulted in a bigger increase
in value and/or probability), they preferred the Pmax option in 59% of the trials. The results of this
experiment are consistent with and extend prior findings in the behavioral literature (Payne,

p. 1

<-----Page 11----->Venkatraman et al.

Neural Strategic Variability

2005). We also found substantial inter-individual variability: some subjects nearly always
preferred the Pmax option; others nearly always preferred the Gmax or Lmin options while still others
switched based on trial variables, resulting in both intra- and inter-subject variability in strategy
(Supplementary Fig. 2A). We further note that Pmax choices were also associated with faster
response times (Supplementary Fig. 2C), consistent with it representing a simplifying strategy.

Behavioral Experiment 2
The second behavioral experiment (E2) manipulated the basic paradigm in three ways – to
maintain, eliminate, or exaggerate the probability-maximizing choice – to rule out potential
confounding factors and establish that these effects were indeed driven by the need to maximize
the overall probability of winning. Seventy one young adults participated in a second behavioral
experiment conducted at the Fuqua School of Business. Compensation for subjects was similar to
the previous experiment. All subjects provided informed consent as a part of a protocol approved
by the Institutional Review Board of Duke University.

Subjects were presented with eight five-outcome mixed gambles similar to the first experiment on
a computer. Four of these gambles were matched for expected value and the other four were not.
Additionally, subjects were also presented with eight gambles where adding value to the middle
option did not involve a change in overall probability. In these Pmax-unavailable trials, we made
one very subtle change to the experimental design: we added or subtracted a small amount from
the central choice option (e.g., adding value to an option that was already $5 and not $0; or
adding money to an option that changes it from -$20 to -$5). Thus, there were no options in the
gamble whose selection would change the overall probability of success.

Finally, subjects were presented with four additional trials where adding values to the extreme
loss or gain outcomes changed the overall probability of the gamble. In these Pmax-exaggerated
trials, we altered the basic gambles so that one of options, if selected, would translate a certain
loss gamble to an uncertain loss gamble (by modifying an all loss-outcome gamble to a gamble
with one gain outcome) or translate an uncertain gain gamble to a certain gain gamble (by
modifying a gamble with one loss outcome to an all gain-outcome gamble). These gambles were
created by selecting two basic gambles from the set of four equal expected value core problems
above and transposing them by adding or subtracting a constant value from all outcomes. For e.g.,
the core gamble: {60, 0.2; 45, 0.2; -20, 0.2; -40, 0.2; -80, 0.2} was transposed it to the new
gamble: {130, 0.2; 115, 0.2; 50, 0.2; 30, 0.2; -10, 0.2} and subjects were given a choice between

p. 2

<-----Page 12----->Venkatraman et al.

Neural Strategic Variability

adding $30 to the -$10 option (making it a certain win gamble) or to the $50 reference option
(which would correspond to the Pmax option in the untranslated version).

In the control trials, which replicates the design of the first behavioral experiment, subjects still
showed a systematic bias (65%) towards the Pmax choices (Supplementary Fig. 1). Again, the
preference for Pmax response reduced slightly (58%, but was still the majority response) when it
was associated with lower expected value. In the critical Pmax-unavailable trials, we found a
significant shift in the pattern of subjects’ choices: subjects now chose the option nearest to $0
only 39% of the time. This result provides confirmation that many subjects do preferentially
select the choice that improves the overall probability of winning when it is available, but readily
switch to magnitude-sensitive choices otherwise. Moreover, these results also indicate that the
choices of subjects for these mixed gambles cannot be explained solely by parameters within
standard descriptive economic models, because the addition of $5 to one option of a complex,
large-magnitude gamble should have negligible effects upon the predictions of those models.
Finally, in the Pmax-exaggerated trials, subjects overwhelmingly preferred the probabilitymaximizing option (83%). Thus, our behavioral data not only demonstrate the robustness of the
preferences toward the Pmax choices, but more importantly that this bias can be reversed or
accentuated by experimental manipulations.

Consistent with our first behavioral experiment, we also found substantial inter-individual
variability in this subject population (Supplementary Fig. 2B). Again, Pmax choices were
associated with faster response times (Supplementary Fig. 2C). Moreover, across subjects, the
proportion of Pmax choices was negatively correlated with an independent measure of behavioral
maximizing (Schwartz et al., 2002) (r = -0.26; p < 0.05), which assesses an individual’s tendency
to seek the best possible option in all situations. Finally, the proportion of Pmax choices was also
significantly negatively correlated with a trait measure of sadness (Fordyce, 1988) (r = -0.29; p <
0.05).

Does Pmax Represent a Simplifying Strategy?
Across both experiments, we find four lines of evidence that support the view that Pmax choices
represent an effort-reduction simplifying strategy. First, Pmax choices were significantly faster in
terms or response times, as would be expected of a less effortful strategy. Second, individual
differences in the preference for Pmax were significantly and negatively correlated with a trait
measure of maximizing in E2, consistent with effort-reduction. Third, individual variability in

p. 3

<-----Page 13----->Venkatraman et al.

Neural Strategic Variability

proportion of Pmax choices also significantly and negatively correlated with a trait measure of
sadness in E2, consistent with sadness being associated with reduced heuristic processing
(Bodenhausen et al., 1994; Schwarz et al., 1991). Finally, the proportion of Pmax choices
decreased with increasing cost in terms of expected value. Together, these findings are consistent
with Pmax representing a simplifying strategy. Additionally, as discussed below in the comparison
of choice models, these choices were also inconsistent with compensatory models like expected
utility and cumulative prospect theory.

Supplementary Methods: fMRI Experiment
Stimuli: Trial Types.
There were a total of five different types of conditions: (i) the value (amount added to the option)
and probability were higher for the central reference outcome (Ref_EV+), (ii) the value and
probability were the same for both reference and extreme outcomes (Ref_EV=), (iii) the value was
the same but the probability of the reference outcome was lower (Ref_P-), (iv) the probability was
the same but value added to the reference outcome was lower (Ref_V-) and (v) both the
probability and the value were lower for the reference option (Ref_EV-). The proportion of Pmax
choices was systematically modulated by the tradeoff in expected value of the two types of
choices, indicating that subjects were not simply insensitive to expected value (Supplementary
Table 1). As seen from the table, the greatest conflict existed when the expected values were
equal or similar (when only one of value or probability was lower). Therefore, only these trials
were included for analyzing the neural correlates of decisions.

Subject Payments.
Subjects were informed at the beginning of the fMRI session that a portion of their earnings
would depend on their choices. Specifically, they would gain or lose money based on the
outcomes of two randomly selected gambles (plus a fixed $40 participation payment). They were
told that the outcome of each trial would be multiplied by an unknown, but fixed percentage, and
that they could lose some or all of a monetary endowment that was given to them at the start of
the experiment. To ensure that choices were incentive-compatible, we gave each subject (before
they entered the scanner) a sealed envelope containing both a cash endowment and a message
indicating the payment multiplier. The values of the endowment and multiplier were both
unknown to the subjects. For all subjects, the endowment was set at $20 and the multiplier was
set at 10%. The final total payoffs ranged from $46 to $76 (mean = $61, s.d. = $8.66).

p. 4

<-----Page 14----->Venkatraman et al.

Neural Strategic Variability

Behavioral Trait Measures.
At the end of the scanning session, subjects completed a series of questionnaires. These included:
(i)

A Maximization Scale that consists of 13 questions aimed at distinguishing people
based on those who try to get the best out of a situation from those who settle for
something good enough (Schwartz et al., 2002),

(ii)

Barratt’s Impulsiveness Scale (BIS) that consists of 30 questions categorized into
cognitive, planning and motor subscales (Patton et al., 1995),

(iii)

A cognition-intuition questionnaire, where the two subscales are faith-in-intuition that
leads to more heuristic experiential processing and need-for-cognition that leads to
more analytic rational processing (Epstein et al., 1996),

(iv)

A decision-making styles inventory (DMSI) with sub-scales as rational, intuitive,
avoidant, dependent and spontaneous (Scott and Bruce, 1995) and

(v)

A second decision styles inventory (WN_DMSI) with the sub-scales as analytical,
intuitive and regret (Nygren and White, 2002).

Factor Analysis.
Individual subject responses from all subscales of these five questionnaires, along with the
behavioral measure of choice tendency from the fMRI experiment, were then subjected to a factor
analysis using SPSS. We used principal components analysis to extract the factors and performed
varimax rotation of the resulting loading matrices to facilitate interpretation. The extraction
criterion was set to an eigenvalue of one or greater.

The behavioral data loaded onto four factors which together accounted for approximately 75% of
the total variance; these can be broadly labeled as impulsiveness, magnitude-focus, intuitiveness,
and regretfulness in decreasing order of explained variance. The rotated factor matrix for each of
the four factors is summarized in Supplementary Table 3. Loading values with absolute value of
0.5 and greater are shown in the table. We then calculated scores for each factor for each subject,
which were then used as covariates in the third-level fMRI analyses to evaluate the robustness
and specificity of our findings to strategic variability.

We included subjects’ scores on each of these factors as across-subjects regressors in out thirdlevel analysis looking at differences between magnitude-sensitive compensatory and simplifying
Pmax choices. We found that the difference in activation between the two choices within the
dmPFC was significantly negatively correlated with the magnitude-focus factor (the preference

p. 5

<-----Page 15----->Venkatraman et al.

Neural Strategic Variability

for simplifying strategy loaded negatively on this factor) but not with any other factor, replicating
the interaction effect in Fig. 3 in the main text of the manuscript (Supplementary Fig. 7).

Dorsomedial Prefrontal Cortex: Strategy or Response Conflict?
We conducted two additional analysis to rule out the possibility that dmPFC activation was
related to response conflict, as has been found in several previous studies (Botvinick et al., 1999;
Kerns et al., 2004). First, we evaluated whether there was any correlation, across subjects,
between response time and dmPFC activation, as would be expected in the case of response
conflict. No such correlations were found, whether considering each strategy independently or
their interaction (Supplementary Fig. 8A-C). Second, subjects who were indifferent to
compensatory and simplifying strategies (hence having maximal response conflict as they choose
both options equally often) exhibited low dmPFC activation that was equal for both choices
(Supplementary Fig. 8D), a finding that is inconsistent with a response-conflict explanation.

p. 6

<-----Page 16----->Venkatraman et al.

Neural Strategic Variability

Comparison of Choice Models.
Given the significant preference for Pmax choices across our subjects, we sought to characterize if
these biases were consistent with traditional economic models. We focused mainly on Expected
Utility (EU) and Cumulative Prospect Theory (CPT) models. Note that we do not discuss
Original Prospect Theory (OPT) as it was primarily introduced for simple two-outcome gambles
and it violates first-order stochastic dominance, which is particularly important consideration in
multi-outcome gambles like the ones used in this study. We stress that the model testing to be
reported should not be viewed as implying that an overall probability of winning is a new and
“better” general model of risky choice behavior. Clearly this “simplifying strategy” does not even
apply to risky choice problems that involve only “pure” gain or loss options. This purpose of
model comparisons is simply to highlight the potential value added by incorporating an overall
probability of winning metric in any descriptive theory of how people respond to complex risky
choices.

The gambles used in this study were of the form G = {x1,p1; x2,p2; x3,p3; x4,p4; x5,p5} with xi
representing the outcomes and pi the associated probabilities The outcomes are ordered so that x1
is the largest gain, x5 is the largest loss, and k is the index of the smallest gain (k=2 or k=3 for the
gambles in this paper). The values for the gambles presented during the imaging study were
chosen such that expected value, expected utility and cumulative prospect theory make unique
predictions.

The expected utility (EU) of a gamble G is given by:

⎧⎪ xi β , xi ≥ 0
⎫⎪
EU = ∑ u ( xi ) pi , where u ( xi ) = ⎨
⎬.
⎪⎩− | xi |1+(1− β ) , xi < 0⎪⎭
i =1
5

The cumulative prospect theory (CPT) predictions were obtained using:

⎧⎪ xi β , xi ≥ 0
⎫⎪
CPT = ∑ v( xi )c(i ) where v( xi ) = ⎨
⎬,
⎪⎩− λ | xi | β , xi < 0⎪⎭
i =1
5

p. 7

<-----Page 17----->Venkatraman et al.

Neural Strategic Variability

⎧w + ( pi ), i = 1
⎫
⎪
⎪
⎞
⎛ i −1 ⎞
⎪ + ⎛⎜ i
⎪
+
⎟
⎜
⎟
⎪w ⎜ ∑ p j ⎟ − w ⎜ ∑ p j ⎟, i = 2,.., k ( gains ) ⎪
⎝ j =1 ⎠
⎪ ⎝ j =1 ⎠
⎪
c(i ) = ⎨
⎬,
5
5
⎛
⎞
⎛
⎞
⎪ −⎜
⎪
−
⎟
⎜
⎟
⎪w ⎜ ∑ p j ⎟ − w ⎜ ∑ p j ⎟, i = k + 1,..,4 (losses)⎪
⎝ j =1+1 ⎠
⎪ ⎝ j =i ⎠
⎪
⎪⎩w − ( pi ), i = 5
⎪⎭
pγ

+

w ( p) =

+

+

pγ

−

+

[ p γ + (1 − p ) γ ]

1 +

γ

and w ( p ) =

−

−
−

[ p γ + (1 − p) γ ]

1 −

γ

For the first level of model comparisons, we made predictions for each of the 72 nearly equal
expected-value gambles (the set of gambles that were used in choice analyses) using standard
parameter values for each of the models. This included using a concave utility function for the
expected utility model with β = 0.88. For the cumulative prospect theory model, we used the
following values for each of the parameters: γ+ = 0.61, γ- = 0.69 and λ = 2.25 based on previous
experimental studies (Tversky and Kahneman, 1992). The findings were inconsistent with
observed behavior. For example, for equal EV problems, expected utility predicts that subjects
should choose Pmax option only in trials involving comparison to Gmax and not in trials where Pmax
is contrasted against Lmin. However, subjects showed no such difference in their choices, choosing
the Pmax option in 70% of trials when compared to Gmax and 68% of trials when compared to Lmin.
Similarly, in all trials where the Pmax option is associated with equal or lesser expected value
compared to the alternative option, CPT model with the parameters above predicts the choice of
Gmax or Lmin option, inconsistent with the actual choices observed in this study. These findings
suggest that existing models of risky choice fail to account for this bias towards the choice that
maximizes overall probability of winning, which plays an important role in multi-outcome mixed
gambles.

To account for the fact that there could be individual differences in parameter values for each
subject, we performed a split-sample analysis. We selected one half of the choices of each
participant and estimated a subset of parameters for the above models that best fit the subject’s
choices. We estimated one parameter, β, for the EU model and two parameters,{β,γ}, for the CPT
model, keeping λ fixed at 2.25. Note that we also simplified the equation for CPT in our
estimation by assuming γ+ = γ-. We then assessed how well the fitted models predicted the other

p. 8

<-----Page 18----->Venkatraman et al.

Neural Strategic Variability

half of that subject’s data, comparing the performance of the EU and CPT models. These findings
are summarized in Supplementary Fig. 3. As seen from the figure, the parameters estimates
from one half of the sample failed to significantly predicted choices in the complementary sample
across subjects. However, the proportion of Pmax choices was highly correlated across the two
samples, indicating that subjects were highly consistent in their choices across the experiment.

p. 9

<-----Page 19----->Venkatraman et al.

Neural Strategic Variability

Supplementary Tables
Supplementary Table 1: Summary of the proportion of Pmax choices made by subjects (N=23)
and response times across all condition types, within our fMRI experiment.
Proportion of Pmax Choices (%)
+

Ref_EV

=

Ref_EV
-

Ref_V
Ref_P

-

Ref_EV

Response Time (s)

Mean

S.E

Mean

S.E.

90.58

2.63

0.883

0.068

69.38

5.18

0.994

0.083

45.65

5.45

1.091

0.118

33.70

5.47

1.031

0.117

29.17

5.45

0.992

0.088

p. 10

<-----Page 20----->Venkatraman et al.

Neural Strategic Variability

Supplementary Table 2: Regions whose activation was significantly modulated by the decision
that was made (i.e., compensatory magnitude-sensitive or simplifying probability-maximizing) or
whose choice-related activation was modulated by the proportion of Pmax choices across subjects.
The coordinates and z-values correspond to the peak activated voxel within the region.

MNI Coordinates

Brodmann

z-value

x

Y

Z

Area

Right anterior Insula

38

28

0

13

3.42

Right ventromedial PFC

16

21

-23

11

2.74

Right Posterior Parietal Cortex

20

-76

57

40

3.40

Precuneus

3

-72

57

7

2.79

Right dorsolateral Prefrontal Cortex

44

44

27

46

2.99

Right Inferior Frontal Gyrus

47

42

8

46

3.64

Right dorsolateral Prefrontal Cortex

42

25

22

44

3.14

Dorsomedial Prefrontal Cortex

10

22

45

32

2.99

10

42

29

32

2.77

Compensatory > Simplifying

Simplifying > Compensatory

(Compensatory - Simplifying) *
Strategy Preference

p. 11

<-----Page 21----->Venkatraman et al.

Neural Strategic Variability

Supplementary Table 3: Behavioral data from twenty subjects loaded onto four main factors
that could be categorized as reflecting impulsiveness, maximizing, intuitiveness, and
regretfulness; here ordered in increasing proportion of explained variance. Only responses with
rotated component matrix loading of greater than 0.5 (or lesser than -0.5 for negative loadings)
are shown.

Inferred Factor Label

Factor 1

Factor 2

Factor 3

Factor 4

Impulsiveness

Magnitude-

Intuitiveness

Regretfulness

focus
BIS
Nonplanning

0.76

-

-

-

-

0.67

-

-

Motor

0.87

-

-

-

Analytical

-0.78

-

-

-

Intuitive

-

-

0.90

-

Regret-based

-

-

-

0.56

Spontaneity

0.86

-

-

-

Avoidant

-

0.75

-

-

Dependent

-

0.51

-

0.55

Intuitive

-

-

0.91

-

Rational

-0.80

-

-

-

Need for Cognition

-

-

-

-0.88

Faith in Intuition

-

-

0.76

-

-

0.78

-

-

-

-0.71

-

-

Cognitive

WN-DMSI

DMSI

Cognitive-Intuitive

Maximizing Scale
Preference for Simplifying
Strategy

p. 12

<-----Page 22----->Venkatraman et al.

Neural Strategic Variability

Supplementary Figure Captions
Supplementary Figure 1. Subjects prefer choices that increase the overall probability of
winning. In behavioral experiment E1 (N=128), subjects show a significant bias towards Pmax
choices. This effect is replicated in E2 (N=71). More importantly, the preference for the Pmax
choices can be reversed or accentuated by experimental manipulations. When values were
modified slightly such that none of the options could change the overall probability, subjects now
avoided the middle option in the gamble (i.e., they now preferred to add money to an extreme
value). Similarly, when provided with an option to eliminate the chance of losing or to create a
chance for winning where none existed, Pmax choices increased dramatically. Finally, the bias
towards Pmax choices was replicated in the fMRI experiment. Note that the Pmax-unavailable
condition did not have any choice that changed the overall probability, and the value in the plot
represents the proportion of choices of the central outcome in these gambles.

Supplementary Figure 2. Results from the behavioral experiments. (A,B) To provide
validation of our experimental task in a large sample, subjects made decisions about a series of
eight gambles in two experiments (E1: N=128 and E2: N=71), each constructed according to the
rules described in the Supplementary Methods. In both experiments, subjects’ choices were
biased toward the Pmax option, with substantial inter-individual variability. (C) Response times
were significantly faster (p < 0.05) when subjects chose the Pmax option in both behavioral
experiments, consistent with a speeding of choices that involve a simplifying strategy.

Supplementary Figure 3. Evidence that a focus on overall probability of winning (and not
economic models) best explain subjects’ choices. We used a split-sample analysis to evaluate
the relative consistency of possible choice parameters. (A) The proportion of Pmax choices (meansubtracted) in one sample significantly predicted the proportion of Pmax choices in the
complementary sample. However, choice models based on (B) expected utility (EU) and (C)
cumulative prospect theory (CPT) were poor predictors of choices, even though those latter
models included additional free parameters.

Supplementary Figure 4. Individual differences in strategy correlated with a trait measure
of Maximization. The participants’ strategic preferences during the fMRI experiment (x-axis)
had a strong negative correlation with an independent trait measure of maximization (y-axis).

p. 13

<-----Page 23----->Venkatraman et al.

Neural Strategic Variability

Supplementary Figure 5. Differences in dmPFC connectivity strength predict subjects’
choices. Functional connectivity analysis showed differential connectivity of the dmPFC with
posterior parietal cortex and anterior insula as a function of choice. Individual differences in the
strength of these connections tracked strategic variability. These findings suggest that differences
in the magnitude of functional connectivity between dmPFC and PPC predict Pmax choices while
differences in the magnitude of functional connectivity between dmPFC and aINS predict
magnitude-sensitive compensatory choices.

Supplementary Figure 6. Activation of the ventral striatum was predicted by an
independent behavioral measure of maximization. Within the ventral striatum region that
exhibited a significant activation difference between observed monetary gains and losses (x = 14,
y = 16, z = -10; indicated with arrow; see also Fig. 4), we found a significant correlation with an
independent behavioral maximization scale. Subjects with lower values on the maximization
scale exhibited a very large difference between gain- and loss-related activation in this region.
Conversely, experienced gains and losses had little effect on subjects with larger values on the
maximization scale.

Supplementary Figure 7. Areas of activation associated with specific decision factors.
Subjects in our sample were differentiated into four main factors based on their responses to a
battery of questionnaire-based decision-making responses. Each of these factors were then used
as a covariate, across subjects, for the activation difference between compensatory magnitudesensitive and simplifying choices. This generated a set of four maps, each reflecting a different
decision * trait interaction. (A) The cognitive impulsiveness factor positively predicted activation
in the posterior parietal cortex. (B) The magnitude focused factor negatively predicted activation
in dorsomedial prefrontal cortex (i.e., exhibited greater difference in activation between the two
choices for subjects loading heavily on this factor). This region overlaps with the dmPFC region
that predicts strategy in Fig. 3. (C) Intuitiveness positively predicted activity in ventromedial
prefrontal cortex. (D) Activation in ventral striatum negatively predicted the fourth factor, which
we roughly characterize as reflecting regretfulness.

Supplementary Figure 8. Dorsomedial prefrontal cortex activation is not correlated with
responses. To evaluate whether decision difficulty could explain the observed activation in
dorsomedial prefrontal cortex (dmPFC), we evaluated the correlation between response time (xaxes) and (A) Magnitude-sensitive choice activation, (B) Pmax choice activation, and (C) the

p. 14

<-----Page 24----->Venkatraman et al.

Neural Strategic Variability

difference in activation between choices. Response time was not significantly correlated with any
activation measure. (D) We split our fMRI subject sample into three groups of subjects, the
middle of which consisted of individuals (N = 6) who were equally likely to prefer the
compensatory or simplifying strategy. These subjects can be assumed to have poorly developed
strategies (i.e., minimal strategy conflict) such that no particular choice is preferred on each trial
(i.e., maximal response conflict). Under a strategy-conflict explanation, these individuals would
be expected to have low dmPFC activation, whereas under a response-conflict explanation they
should have high dmPFC activation. We found that the neutral subjects had low-amplitude
dmPFC activation that was equal between the two choices, supporting the strategy-conflict
interpretation.

p. 15

<-----Page 25----->Venkatraman et al.

Neural Strategic Variability

References for Supplementary Materials
Bodenhausen, G.V., Sheppard, L.A., and Kramer, G.P. (1994). Negative Affect
and Social Judgment - the Differential Impact of Anger and Sadness. European
Journal of Social Psychology 24, 45-62.
Botvinick, M., Nystrom, L.E., Fissell, K., Carter, C.S., and Cohen, J.D. (1999).
Conflict monitoring versus selection-for-action in anterior cingulate cortex. Nature
402, 179-181.
Brainard, D.H. (1997). The Psychophysics Toolbox. Spatial Vision 10, 433-436.
Epstein, S., Pacini, R., Denes-Raj, V., and Heier, H. (1996). Individual
differences in intuitive-experiential and analytical-rational thinking styles. Journal
of Personality and Social Psychology 71, 390-405.
Fordyce, M.W. (1988). A Review of Research on the Happiness Measures - a 60
Second Index of Happiness and Mental-Health. Social Indicators Research 20,
355-381.
Kerns, J.G., Cohen, J.D., MacDonald, A.W., 3rd, Cho, R.Y., Stenger, V.A., and
Carter, C.S. (2004). Anterior cingulate conflict monitoring and adjustments in
control. Science 303, 1023-1026.
Nygren, T.E., and White, R.J. (2002). Assessing Individual Differences in
Decision Making Styles: Analytical vs. Intuitive. In Human Factors and
Ergonomics Society 46th Annual Meeting (Baltimore, MD), pp. 953-957.
Patton, J.J., Stanford, M.S., and Barratt, E.S. (1995). Factor structure of the
Barratt Impulsiveness Scale. Journal of Clinical Psychology 51, 768-774.
Payne, J.W. (2005). It is whether you win or lose: The importance of the overall
probabilities of winning or losing in risky choice. J Risk Uncertainty 30, 5-19.
Pelli, D.G. (1997). The VideoToolbox software for visual psychophysics:
Transforming numbers into movies. Spatial Vision 10, 437-442.
Schwartz, B., Ward, A., Monterosso, J., Lyubomirsky, S., White, K., and Lehman,
D.R. (2002). Maximizing versus satisficing: happiness is a matter of choice.
Journal of Personality and Social Psychology 83, 1178-1197.
Schwarz, N., Bless, H., and Bohner, G. (1991). Mood and Persuasion - Affective
States Influence the Processing of Persuasive Communications. Advances in
Experimental Social Psychology 24, 161-199.
Scott, S.G., and Bruce, R.A. (1995). Decision making style: the development of a
new measure. Educational and Psychological Measurements 55, 818-831.
Tversky, A., and Kahneman, D. (1992). Advances in prospect theory: Cumulative
representation of uncertainty. J Risk Uncertainty 5, 297-323.

p. 16

<-----Page 26----->Supplementary Figure 1

<-----Page 27----->(A)

(B)

Supplementary Figure 2

(C)

<-----Page 28----->Supplementary Figure 3

<-----Page 29----->Supplementary Figure 4

<-----Page 30----->Supplementary Figure 5

<-----Page 31----->Supplementary Figure 6

<-----Page 32----->Supplementary Figure 7

<-----Page 33----->(D)

Supplementary Figure 8

