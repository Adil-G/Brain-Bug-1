<-----Page 0----->Judgment and Decision Making, Vol. 3, No. 3, March 2008, pp. 195–204

Cognitive processes, models and metaphors in decision research
Ben R. Newell∗
School of Psychology, University of New South Wales
Arndt Bröder
University of Bonn and Max Planck Institute for Research on Collective Goods

Abstract
Decision research in psychology has traditionally been influenced by the homo oeconomicus metaphor with its emphasis on normative models and deviations from the predictions of those models. In contrast, the principal metaphor of
cognitive psychology conceptualizes humans as ‘information processors’, employing processes of perception, memory,
categorization, problem solving and so on. Many of the processes described in cognitive theories are similar to those
involved in decision making, and thus increasing cross-fertilization between the two areas is an important endeavour.
A wide range of models and metaphors has been proposed to explain and describe ‘information processing’ and many
models have been applied to decision making in ingenious ways. This special issue encourages cross-fertilization between cognitive psychology and decision research by providing an overview of current perspectives in one area that
continues to highlight the benefits of the synergistic approach: cognitive modeling of multi-attribute decision making.
In this introduction we discuss aspects of the cognitive system that need to be considered when modeling multi-attribute
decision making (e.g., automatic versus controlled processing, learning and memory constraints, metacognition) and
illustrate how such aspects are incorporated into the approaches proposed by contributors to the special issue. We
end by discussing the challenges posed by the contrasting and sometimes incompatible assumptions of the models and
metaphors.
Keywords: cognitive models, modeling, metaphors.

1

Introduction

The traditional approach to the study of judgment and
decision making (JDM) is to compare a judgment or a
decision (which can be considered as a judgment about
what to do (Baron, 2004)) to a standard or “benchmark.”
The comparison enables an evaluation of whether a particular judgment is “good” or “bad” relative to the standard. Normative models which provide these standards
are valuable because their clear sets of rules or axioms,
such as those derived from economics (expected utility
theory) and mathematics (probability theory) can be used
to test predictions about human behavior. When behavior
deviates from the predictions of normative models — i.e.,
biases are observed — attempts can be made to ascertain
why and, often, techniques for overcoming such biases
can be prescribed .
∗ Acknowledgements: Ben Newell acknowledges the support of the
Australian Research Council (Grant: DP 0558181) and the University
of New South Wales for awarding him the John Yu Fellowship to Europe. Both authors would also like to thank the Max Planck Institute for Research on Collective Goods for hosting Ben Newell’s visit
and the symposium. Corresponding author: Ben R. Newell, School of
Psychology, University of New South Wales, Sydney 2052, Australia,
ben.newell@unsw.edu.au

This approach with its focus on deviations from normative models contrasts the ideal of a homo oeconomicus
with the apparent reality of a cognitive miser (or even
loser) and has been enormously influential and useful.
However, it has not been without its critics (e.g., Einhorn & Hogarth, 1981; Gigerenzer, 1996; Lopes, 1991).
Both metaphors fall short of psychology’s actual goal because they tend “to define human decision making by
what it is not” (Medin & Bazerman, 1999, p. 533), and
as a consequence JDM research has tended to follow its
own path and, some would argue, become disconnected
from much of psychology in general and cognitive psychology in particular (e.g., Medin & Bazerman, 1999)1 .
This “disconnection” is a great pity given that many of
the issues at the core of understanding human judgment
and decision making are, necessarily, central to the wider
goal of understanding human cognition.
The papers in this special issue of the Judgment and
Decision Making grew from a symposium held at the
Max Planck Institute for Research on Collective Goods
1 One could also argue that this disconnection has occurred because mainstream cognitive psychology tends to focus on basic research
whereas JDM research has traditionally been concerned with more applied issues.

195

<-----Page 1----->Judgment and Decision Making, Vol. 3, No. 3, March 2008

which focused on one area of JDM research which we
believe has and will continue to benefit from its overlap
with more mainstream cognitive psychology. The area is
multi-attribute judgment and the symposium explored recent advances in the cognitive modeling approaches that
have been brought to bear on the basic question of how
we make judgments when faced with multiple pieces of
information. In the 30 years since the seminal attempt by
John Payne (1976) to make JDM research “more cognitive” a wide range of approaches from cognitive psychology has been applied to this question. Our aim in this
issue is to provide the reader with an up-to-date overview
of these approaches and to emphasize the important and
influential advances that can be made by taking the interface between JDM and cognitive psychology seriously.
Contrasting the different approaches allows for the identification of possible boundary conditions for their appropriateness as valid models of cognitive processing, and,
we hope will suggest fruitful avenues for future research.
This paper is structured as follows: we begin with a
brief introduction (adapted from Holyoak, 1999) which
serves to highlight the things we know about cognition
that should be incorporated into models of multi-attribute
judgment; we then discuss briefly how these aspects are
addressed in some of the models considered by contributors to the special issue. This collection of models,
however, cannot simply be viewed as complementary accounts since they sometimes conflict with respect to fundamental assumptions. A sample of these incompatibilities between different metaphors is discussed at the end
of the paper.

2

The overarching metaphor:
Wo/man as an information
processor

Forty years ago Neisser (1967) introduced the idea that an
intelligent organism operates in a perception-action cycle: the senses take in information from the environment,
the mind/brain performs computations on that information and the outputs of those computations are used to
guide subsequent goal-directed actions. A key aspect of
this “information processing” metaphor is that biological
organisms are capacity limited; there is a limit on how
much information can be processed and thus the organism needs to be selective in what it attends to in the environment — i.e., the information taken in via the senses
(e.g., Miller, 1956).
The interaction between attention and memory is also
fundamental to the information processing metaphor. The
notion of working memory (Baddeley & Hitch, 1974) is
now widely accepted as a descriptive model of how var-

Models and metaphors

196

ious forms of information (visual, phonological) are represented in a temporary memory store. In this model a
central executive is responsible for allocating attention to
various processing tasks such as the controlled thought
needed for problem solving, decision making, reasoning
and so on. The degree to which processing relies on this
controlled versus relatively automatic processing is often
a function of the involvement of memory. Tasks that have
been encountered numerous times in the past become
straightforward to execute or solve because relevant actions or solutions can be retrieved from memory and thus
performance is less dependent on active attention. In the
traditional “gambling paradigm” of JDM research (Goldstein & Hogarth, 1997), such routine- and experiencebased changes in the cognitive processes and their respective “costs” have largely been neglected (Betsch &
Haberstroh, 2005; Klein, 1998).
Another vital aspect of information processing is that
organisms are endowed with an ability to adaptively alter
their behavior — i.e., learn. Human and non-human animals alike are able to learn contingencies among events
and actions; an ability which is fundamental for survival
in a changing environment. The understanding of the
cause-effect structure of the world gained through this
learning process also facilitates causal reasoning and induction which in turn can lead to the development of
categorization — the process by which we organize our
knowledge. Categorization is influenced by our causal
knowledge and (perceptual) similarity relations between
objects (e.g., Murphy & Medin, 1985). As well as being
able to organize knowledge, humans also have the ability
to think about their own thinking, this regulation of cognition or metacognition is directly connected to the adaptivity of our behaviour (e.g., our ability to decide how to
decide in different situations, (Payne, Bettman, & Johnson, 1993)) and may be related to intelligence (Bröder,
2003; Stanovich & West, 2000).
This whistle-stop tour through some of the “facts”
about the cognitive system serves to orient our thinking
about what needs to be considered when we attempt to
build and implement cognitive models. Given that multiattribute judgment is “simply” another task performed by
the system, it is important that our attempts to model how
it is done are embedded both theoretically and empirically in what we already know about the operation of that
system. Thus some key aspects to consider are: 1) capacity limitation, 2) the distinction between automatic and
controlled processing and the role that memory plays in
their interaction, 3) the ability to learn, 4) the translation
of cause-effect learning to the development of categorization, and 5) the regulation of cognition. In the following
sections we examine some of the ways in which these
aspects are incorporated into the models and metaphors
proposed by the contributors to this issue.

<-----Page 2----->Judgment and Decision Making, Vol. 3, No. 3, March 2008

3

Capacity limitation

The capacity limitation stressed by the information processing metaphor is a limitation in cognitive capacity —
specifically a limit on the amount of information that
an organism can attend to and/or process at any given
time. However, focusing solely on these limitations of
the mind ignores the crucial role played by the environment in shaping human behaviour (e.g., Simon, 1956;
Gigerenzer, Todd et al., 1999). Many theorists argue that,
to model cognition adequately, we must understand the
connection between the limitations imposed by the mind
(e.g., attention span, memory) and those imposed by the
environment (e.g., information costs). This view, first
proposed by Simon (1956), is captured in the analogy:
“Human rational behaviour is shaped by a scissors whose
blades are the structure of task environments and the computational capabilities of the actor” (Simon, 1990, p. 7).
To understand how scissors cut, we must consider both
blades; to understand how we make decisions, we must
consider both mind and environment.
One way of incorporating the limitations of the mind
and the structure of environments into cognitive models is
to propose simplifying heuristics or shortcuts which enable people to “satisfice” or make “good enough” judgments (Christensen-Szalanski ,1978; 1980; Payne et al.,
1993; Simon, 1956). Some of the approaches that take
this line combine the homo oeconomicus and information
processing metaphors to develop frameworks for considering the “cost of thinking.” For example the classic
paper by Shugan (1980) explicitly considered trade-offs
between the cost and benefits of thinking in consumer
choice using an economic/normative framework (see also
Payne et al., 1993). Other approaches explicitly eschew
the normative standards ascribed by mathematical and
economic models, preferring an “ecological” standard of
rationality (Gigerenzer, 2004) against which to compare
models of preference.
This approach to the study of multi-attribute judgment
has been embraced in the work of the Adaptive Behaviour
and Cognition group (ABC) and is well represented in
this special issue (Gaissmaier, Schooler & Mata, 2008;
Rieskamp, 2008). The key premise of the ABC approach is that decision makers have access to a “collection of specialised cognitive mechanisms that evolution
has built into the mind for specific domains of inference
and reasoning” (Gigerenzer & Todd, 1999, p. 30). These
mechanisms or heuristics describe how people can capitalize on both their own cognitive limitations (e.g., forgetting) and environmental limitations to act adaptively
and make good judgments. This approach is more aligned
with the information processing metaphor than the homooeconomicus one. In this way the work resonates with the
rational analysis pioneered by John Anderson (e.g., An-

Models and metaphors

197

derson et al., 2004) which seeks “an explanation of an
aspect of human behaviour based on the assumption that
it is optimized somehow to the structure of the environment” (Anderson, 1991, p. 471). Thus the standard for
rationality becomes one that refers to whether a particular strategy works well in an environment not whether it
adheres to a set of formalisms (cf. Hogarth & Karelaia,
2005; 2007), hence replacing the traditional and dominating coherence criterion of rationality with the pragmatists’ correspondence criterion.2
In their contribution Gaissmaier et al. (2008) explore
the exciting synergies between rational analysis and the
adaptive toolbox approach by using the cognitive architecture developed by Anderson — ACT-R — as a framework to implement some of the proposed decision strategies (e.g., the recognition heuristic). ACT-R incorporates
behaviorally informed assumptions about cognitive processing and its adaptivity with respect to recurrent environmental structures.
Proposing collections of simplifying heuristics for specific tasks is one way to account for capacity limitations
in cognitive models; a very different method is to propose a single decision model in which various alternative
courses of action or options are considered until one option surpasses a threshold and is chosen (Newell, 2005).
Such a dynamic decision process is known as a sequential sampling process (Busemeyer & Johnson, 2004). The
specific mechanisms underlying sequential sampling differ but in general the models assume that, rather than
taking a predetermined quantity of information, sampling
of each option occurs until evidence sufficient to favour
one option over the other has been accumulated (e.g.,
Busemeyer & Townsend, 1993; Dror, Busemeyer, & Basola, 1999; Lee & Cummins, 2004; Nosofsky & Palmeri,
1997; Ratcliff, 1978; Wallsten & Barton, 1982). The importance of the decision to the decision maker is then reflected in the threshold: trivial decisions for which little
consideration of options is required have a low threshold;
important decisions that require extensive and thoughtful
deliberation have a high threshold. In such models capacity limitation, and specifically limitation in the ability
to attend to information, is explicitly modeled in the way
that a decision maker can attend only to one option (and
its possible consequences) at any given moment (Busemeyer & Johnson, 2004).
Many of these models are applied to situations in
2 The standard of “ecological rationality” does appear to entail some
circularity. To say that a heuristic is adaptive if it “works well in an environment” is tantamount to tautology. The obvious questions to ask is:
“well” relative to what? If the answer is relative to some other “computationally intensive” mechanism which relies on normative integration of multiple pieces of information, (an algorithm for maximizing
utility) then the point of difference between normative and ecological
rationality becomes rather unclear. (See Chater, Oaksford, Nakisa &
Reddington, 2003, for further discussion of this issue.)

<-----Page 3----->Judgment and Decision Making, Vol. 3, No. 3, March 2008

Models and metaphors

198

which the interest is in preferential choice among valued options (e.g., Busemeyer & Townsend, 1993), but
others examine probabilistic inference or judgment tasks
that are the focus of much of the work in this special issue
(e.g., Lee & Cummins, 2004; Wallsten & Barton, 1982).
Hausmann and Läge (2008) review the sequential sampling/evidence accumulation approach to modeling decision making and present their own work in which the evidence threshold is conceived of as a person’s subjective
desired level of confidence in the outcome of a prediction.
Their work is especially interesting because they develop
a simple method of validating the threshold concept empirically and at the same time model (stable?) individual differences under the umbrella of a unified process
model.

Holyoak & Simon, 1999). A feature of the model is that
controlled processing can be used at the activation and
consistency maximizing phases to facilitate the formation of the consistent representation. Thus Glöckner and
Betsch propose a model of multi-attribute judgment that
incorporates the interaction between memory, automatic
and controlled processing, and they review data that validates their account. Karlsson, Juslin, and Olsson (2008)
also explore the possibility that multiple memory systems
which employ different amounts of controlled and automatic processing might contribute to multi-attribute judgment.

4

Learning and decision making are inextricably linked.
Judgments and decisions do not emerge out of thin air,
they are informed by our prior experience and each decision yields some information (did it work out well or
badly?) that we can add to our stock of experience for
future benefit (Newell, Lagnado & Shanks, 2007). Although in many real world situations feedback about a
particular decision might be delayed or degraded (by
noise in the environment; Tversky & Kahneman, 1986),
it is still the case that over time we can learn to adaptively alter our behavior to improve our decision making.
Given what appears to be a clear and important connection between learning and decision making it is perhaps
surprising that a large portion of JDM research has studied situations in which all the information required for
a decision or judgment is provided in descriptions (e.g.,
gambles, scenarios, and statements) for which no learning is required (see Busemeyer & Johnson, 2004 for a
similar point). There are exceptions to this focus, not
least the probability learning experiments of the 1960s
(e.g., Tversky & Edwards, 1966 — variants of which are
once again in vogue in the JDM literature — see Barron
& Erev, 2003; Erev & Barron, 2005; Newell & Rakow,
2007) and the multiple-cue probability learning studies
of the 1970s and 80s (e.g., Brehmer, 1980).
Much of the work on multi-attribute judgment, and indeed most of the papers in this special issue take their
lead from these tasks in which learning from experience
is an essential component of the judgment process. For
example, many of the tasks employ variants of a situation in which participants face repeated judgments about
which of two or more objects (cities, companies, horses,
insects) is highest on a criterion of interest (size, profitability, race-winning ability, toxicity). Typically each
object is described by cues (e.g., in the case of companies: share price, employee turnover, etc) that are probabilistically related to the criterion. The mechanism underlying the learning of these cue-criterion relations is

Automatic versus controlled
processing

An implicit assumption of arguments about the relevance
of capacity limitations for cognitive models of multiattribute judgment is that much of the information processing takes place in a controlled, serial manner. For
example, one of the key models of the adaptive toolbox
approach — Take-the-Best — has an explicit rule for sequential search through information, a rule for stopping
on the basis of the first cue found (in a pre-defined hierarchy) that discriminates alternatives, and a simple rule
for choosing the favored alternative. These simple rules
are said to be psychologically plausible because they adhere to what we know about the serial, explicit nature of
conscious thought. However, we also know that a vast
amount of neural activity takes place automatically and
in parallel (the processes underlying vision for example)
thus the assumption of serial processing may not always
be appropriate.
Glöckner and Betsch (2008) examine the intriguing
possibility that the contribution of automatic processes
to decision making has been underestimated. Or rather:
Reliance on the homo oeconomicus metaphor and its
descendants may have overemphasized controlled serial
processes. Glöckner and Betsch propose that when individuals encounter a decision situation, salient and associated information is activated in memory and a mental representation is formed that combines given and memorystored information. The mental representation is conceptualized as a temporarily active network. Once the
network is activated automatic processes operate on the
connections in the network to maximize consistency between pieces of information in the network. This consistency maximizing strategy results in the formation of a
representation of the decision situation in which one option usually dominates and this option is then chosen (cf.

5 Learning

<-----Page 4----->Judgment and Decision Making, Vol. 3, No. 3, March 2008

often not an explicit component of the models but is assumed to occur through some process of co-variation assessment, frequency counting or basic associative learning (see Newell, Lagnado & Shanks, 2007 for an extensive treatment of these issues). The models of judgment
tend to be more interested in how the products of this
low-level learning process are implemented in choosing
between alternatives or in predicting criterion values.
For example the learning might be conceptualized as
influencing the weights of connections in a network that
produces a dominant option (Glöckner & Betsch, 2008);
or the cue-criterion knowledge might be thought of as
the inputs to a linear summation model which produces
a predicted criterion value (Karlsson, Juslin & Olsson,
2008); another interpretation is that cue knowledge about
different objects is what is sampled sequentially in an
evidence-accumulation threshold model (Hausmann &
Läge, 2008); on yet another interpretation the knowledge
can be thought of as chunks of information retrieved from
memory and used in the execution of production rules
(Gaissmaier, Schooler & Mata). The papers in this issue
explore these varied and intriguing conceptualizations
and illustrate the value in understanding how the process
and products of learning influence multi-attribute judgment. Rieskamp’s paper is also concerned with learning
but at a higher level of abstraction — that of learning how
to decide or when to select a particular strategy.

6

Categorization

Categorization is a fundamental ability which allows us
to organize our knowledge, react appropriately and make
useful predictions about the properties of “things” we encounter in the world (Bruner, Goodnow, & Austin, 1956;
Medin, Ross, & Markman, 2001). Juslin, Olsson and
Olsson (2003) made the insightful observation that categorization and multi-attribute judgment research often
ask the same basic questions (e.g., How do you judge if
a person is a friend or a foe?) and often use tasks with
the same underlying structures; but very different formal
models of performance have dominated in the two areas
of research.
The driving metaphor in early multi-attribute judgment
research was that of the lens model (Brunswik, 1952;
Hammond, 1955) which emphasized the controlled integration of cue-criterion values that had been abstracted
via training or experience in the relevant environment.
The processes could generally be captured in multiplelinear regression models (e.g., Brehmer, 1994; Cooksey,
1996) which assume the weighting and adding of single
pieces of evidence. In contrast categorization research
has been influenced enormously by models which emphasize exemplar memory — the reliance on specific in-

Models and metaphors

199

stances of events/objects retrieved from memory (Juslin
et al. 2003 suggest a doctor making diagnoses on the basis of retrieved instances of similar patients as an illustrative example). This view dispenses with abstracted cuecriterion relations and emphasizes an organism’s ability to remember stimulus configurations. Several mathematical models of exemplar processing have been proposed (e.g., Medin & Schaffer, 1978; Nosofsky, 1984)
and more recently some have been applied to JDM phenomena (e.g., Dougherty, Gettys & Ogden, 1999; Juslin
& Persson, 2002).
Karlsson, Juslin & Olsson (2008) present an
overview of their stimulating work exploring the possibility that decision makers have both exemplar processes
and controlled cue abstraction processes at their disposal
when making multi-attribute judgments. The key issue
they examine is whether there is an automatic shift between these systems as a function of judgment error, or
whether such shifts are mediated by explicit intervention.

7 Metacognition
The question of explicit intervention raises the perennial
favourite issue in cognitive science — what about the homunculus? Who or what structure decides how to decide?
Can we describe meta-rules or criteria which select or determine the actual information processing (e.g., strategy
or evidence threshold or similarity function) that is used
in a specific decision situation? Unfortunately, cognitive
models tend to become less specific and process descriptions become more anthropomorphic when higher order
process like these are concerned.
Consequently, the most influential framework for strategy selection in decision making has been Beach’s and
Mitchell’s (1978) contingency model which heavily relies on economic cost/benefit analysis and sees the selection of a strategy as a “compromise between the press
for more decision accuracy ... and the decision maker’s
resistance to the expenditure of his or her personal resources” (Beach & Mitchell, 1978, p. 447). Although
they do not state this explicitly, this selection process
appears as an effortful and attention-demanding activity,
and research following the tradition has investigated it
in this way (Christensen-Szalanski, 1978; 1980; Chu &
Spires, 2003). To be adaptive, the task is to weigh potential cognitive costs of more or less costly strategies
against their expected accuracy or payoff. Since costs and
accuracy are typically thought to conflict, a compromise
is necessary. Payne, Bettman, and Johnson (1993) have
added valuable techniques for measuring cognitive effort
in terms of the assumed processing steps needed (assuming they are performed sequentially), and they relaxed
the assumption of effortful selection processes. However,

<-----Page 5----->Judgment and Decision Making, Vol. 3, No. 3, March 2008

multiple attributes

Models and metaphors

judgment / decision

sequential
cue abstraction

rule-based
models

evidence
accumulation
models

200

parallel
cue abstraction

intuitive
network
models

configural

exemplarbased
models

Figure 1: A schematic diagram showing the relation between four cognitive models of multi-attribute judgment.
they did so at the expense of specificity since they allow
for the selection to be “sometimes a conscious choice and
sometimes a learned contingency” (p. 14), and the selection will “also be a function of the recency and frequency
of prior use” (p. 71). In contrast to the assumption of effortful selection processes, learning models like the SSL
theory discussed by Rieskamp (2008; see also Rieskamp
& Otto, 2006) try to solve the problem of strategy selection by assuming a simple reinforcement process that requires no particular amount of cognitive capacity or reasoning ability.
Although the question of whether strategy selection
is effortful appears to be a straightforward task for empirical evaluation, answering the question is probably
less simple. Under some circumstances, the adaptive
choice of a strategy consumes cognitive capacity as reflected in intelligence measures (Bröder, 2003) or attention (Bröder & Schiffer, 2003), whereas a reinforcement
learning model captures the learning process well in other
situations (Rieskamp, 2006, Rieskamp & Otto, 2006).
Bröder and Schiffer (2006) observed both quick adaptation to new environments and slow adaptation to changing environments, suggesting different principles of strategy selection at different points in time; an issue examined by Rieskamp (2008).

8

Interim Summary

Multi-attribute judgment requires many cognitive processes which have been modeled in other areas of cognitive psychology. Examining these models is therefore
worthwhile because of their potential to explain decision
processes and incorporate decision making into mainstream cognitive psychology. Although it is tempting to
use established models from cognitive psychology for the
different processes described above and integrate them in
a complementary way, a caveat is necessary: Some of

the metaphors and models comprise at least partly incompatible assumptions. Hence, any fully-fledged theoretical
account of multi-attribute decision making will have to
specify boundary conditions of the respective applicability of each model.
In the final section of the paper, we will not try to provide a full treatment of all assumptions and their mutual
inconsistencies, but rather we illustrate the problem by
contrasting a metaphor that has influenced our own research — the adaptive toolbox metaphor — with three
other prominent metaphors that we have already briefly
discussed — evidence accumulation models, exemplarbased models and network models. The juxtaposition of
these metaphors highlights central topics that need to be
considered carefully when cognitive models of decision
making are developed. Figure 1 is a schematic diagram
of the relation between the metaphors we consider and
the cognitive processes hypothesized to underlie them.

9 Adaptive toolbox versus evidence
accumulation models
The adaptive toolbox metaphor (Gigerenzer, Todd, et al.,
1999) in particular and contingency models in general
assume that we possess a multitude of distinguishable
strategies or heuristics which involve qualitatively different processing steps. According to a yet unknown process involving explicit cost-benefit analyses or some yet
unknown other selection mechanism, we choose amongst
these strategies in a largely adaptive manner. The strategy we choose determines the amount of information we
search for and the sequence in which we search for it.
Hence, our decisions are sometimes frugal (involving few
pieces of information) and sometimes more opulent (integrating more information). Another metaphor, however,
is envisaged by evidence accumulation models which as-

<-----Page 6----->Judgment and Decision Making, Vol. 3, No. 3, March 2008

Models and metaphors

201

sume only one single process for deciding (sum pro and
con evidence for all options and choose when a threshold is surpassed). Since the threshold is conceived as
adjustable (depending on task demands, decision importance, time pressure etc.), evidence accumulation models
can mimic the use of apparently different heuristics which
use different amounts of information (Newell, 2005). But
despite involving contradictory metaphors for the decision process, contingency models and accumulation models are very hard to distinguish empirically. Whether this
matter can be resolved by inventing clever testing methods remains to be investigated (see Bergert & Nosofsky,
2007; Lee & Cummins, 2004; Newell, Collins & Lee,
2007, for recent attempts). If the issue cannot be addressed empirically, the question may have to be resolved
by determining which of the metaphors is more fruitful
and fits better into the nomological network of other theories of cognition and decision making .

alistic feature of real environments in which it is often
not clear which feature has to be predicted as a criterion
in the future. Second, the model dispenses with costly
information integration at the time of a decision since it
only compares the probes with stored exemplars. Hence,
there are some advantages of exemplar-based reasoning
in terms of cognitive costs (cf. Juslin & Persson, 2002).
Despite the attractive qualities of exemplar-based reasoning, there is evidence that in fact cue abstraction may be
a default option in judgment tasks and that this mode is
only supplemented by exemplar-based reasoning in environments where cue-criterion relations are hard to extract. One goal of further research is to delineate the conditions under which either of the decision modes is activated (see Juslin et al., 2003).

10

Contingency models in general (Beach & Mitchell, 1978;
Payne et al., 1993) and the Adaptive Toolbox metaphor in
particular are very explicit about cognitive costs. Compensatory strategies are viewed as “rational demons”
(Gigerenzer & Todd, 1999) that have a high demand for
cognitive resources and time. Also, processing is believed to be sequential: “In the kind of inference task
we are concerned with, cues have to be searched for, and
the mind operates sequentially, step by step and cue by
cue.” (Martignon & Hoffrage, 1999, p. 137). The usual
rhetoric is that “If . . . both summing without weighting
and weighting without summing can be as accurate as
weighting and summing, why should humans not use
these simpler heuristics?” (Brandstätter, Gigerenzer, &
Hertwig, 2006, p. 410). These arguments appear plausible because of their introspective appeal. However, critics argue that in other areas of cognition (e.g., perception, language planning), numerous automatic and parallel processes take place without consuming cognitive
effort at all. These processes involve automatic integration of numerous pieces of information (Chater, Oaksford, Nakisa & Redington, 2003). Simple one-layer neural networks can perform multiple regression analyses,
integrating many predictors to estimate a criterion (e.g.,
Stone, 1986). Hence, complex process do not necessarily imply the consumption of conscious resources or
much processing time and viewed from this perspective,
“simple” heuristics are probably not much simpler, subjectively than complex ones.
In principle, both views should be easy to distinguish
experimentally by restraining or enhancing cognitive resources and by observing the effects on strategy selection.
The evidence on this question is mixed, however: Bröder
(2003) and Bröder and Schiffer (2003) did not find ev-

Adaptive toolbox and evidence
accumulation versus exemplarbased models

There is a fundamental difference between the processes
described in strategies or heuristics and exemplar-based
models of decision making. Heuristics and also evidence accumulation models assume a piecemeal processing of cue-criterion relations which can be conceptualized
as sequential or parallel in nature (see Bröder & Gaissmaier, 2007). In evidence accumulation models like Decision Field Theory, consulting cues is clearly thought to
be a sequential process (Busemeyer & Townsend, 1993;
Diedrich, 1997; 2003; Roe, Busemeyer & Townsend,
2001); it is assumed that cues or attributes independently
support one option, and their respective contributions to a
decision are weighted and integrated. An internal knowledge base must therefore contain knowledge (or intuitions) about single cue-criterion functions that are actively integrated at the time of judgment. Usually, this
integration process is conceived of as cognitively costly
(Beach & Mitchell, 1978; Payne et al., 1993).
Exemplar-based decision models, on the other hand,
dispense with the idea of stored cue-criterion relations
and rather assume that past instances of options are stored
as attribute constellations. Options in a judgment or decision task act as memory probes for retrieving typical
(modal or average) criterion values that are associated
with their attribute constellations. The retrieved value
is generated by aggregating across the most similar attribute sets in memory. This model is “lazy” with respect
to two aspects: First, no cue-criterion relations have to
be learned to establish a knowledge base. This is a re-

11 Adaptive toolbox versus network models

<-----Page 7----->Judgment and Decision Making, Vol. 3, No. 3, March 2008

idence that strategies involving weighting and summing
were more costly than simple lexicographic strategies.
Quite to the contrary, higher cognitive capacity (intelligence, non-demanding second task) was associated with
simpler strategies when these were appropriate in the environment. This suggests that the selection rather than
the execution of strategies is associated with costly processing. On the other hand, Bröder and Gaissmaier
(2007) found evidence for sequential processing in cases
where cues had to be retrieved from memory to form a
judgment. Thus, the parallel/automatic versus sequential/effortful distinction is probably not an absolute one
in multi-attribute decisions. Rather, the task again will be
to investigate the boundaries of the respective cognitive
models as a function of task characteristics.

12

Conclusions

Our hope for this special issue is that highlighting areas of
overlap between cognitive modeling and multi-attribute
judgment will stimulate further cross-fertilization and inspire research examining the boundary conditions of various models. We believe this will strengthen JDM research in general and help to reconnect it with mainstream cognitive psychology.

References
Anderson, J. R. (1991). Is human cognition adaptive?
Behavioral and Brain Sciences, 14, 471–517.
Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S.,
Lebiere, C., & Qin, Y. (2004). An integrated theory of
the mind. Psychological Review, 111, 1036–1060.
Baddeley, A. D. & Hitch, G. J. (1974). Working memory.
In G. H. Bower (Ed.), The psychology of learning and
motivation, Vol. 8 (pp. 47–89). New York: Academic
Press.
Baron, J. (2004). Normative models of judgment and
decision making. In In D. J. Koehler & N. Harvey
(Eds.), The Blackwell handbook of judgment and decision making (pp. 19–36). Malden, MA: Blackwell.
Barron, G., & Erev, I. (2003).
Small feedbackbased decisions and their limited correspondence to
description-based decisions. Journal of Behavioral
Decision Making, 16, 215–233.
Beach, L. R., & Mitchell, T. R. (1978). A contingency
model for the selection of decision strategies. Academy
of Management Review, 3, 439–449.
Bergert, F. B. & Nosofsky, R. M. (2007). A responsetime approach to comparing generalized rational and
take-the-best models of decision making. Journal of
Experimental Psychology: Learning, Memory & Cognition, 33,107–129.

Models and metaphors

202

Betsch, T., & Haberstroh, S. (2005). Preface. In T. Betsch
& S. Haberstroh, The routines of decision making (pp.
ix-xxv). Mahwah, NJ, US: Lawrence Erlbaum Associates.
Brandstätter, E., Gigerenzer, G., & Hertwig, R. (2006).
The Priority Heuristic: Making choices without tradeoffs. Psychological Review, 113, 409–432.
Brehmer, B. (1980). In one word: Not from experience,
Acta Psychologica, 45, 223–241.
Brehmer, B. (1994). The psychology of linear judgement
models. Acta Psychologica, 87, 137–154.
Bröder, A. (2003). Decision making with the “adaptive
toolbox”: Influence of environmental structure, intelligence, and working memory load. Journal of Experimental Psychology:Learning Memory, and Cognition,
29, 611–625.
Bröder, A., & Gaissmaier, W. (2007). Sequential processing of cues in memory-based multi-attribute decisions.
Psychonomic Bulletin and Review, 45, 895–900.
Bröder, A., & Schiffer, S. (2003). Bayesian strategy assessment in multi-attribute decision making. Journal
of Behavioral Decision Making, 16, 193–213.
Bröder, A., & Schiffer, S. (2006). Adaptive flexibility and
maladaptive routines in selecting fast and frugal decision strategies. Journal of Experimental Psychology:
Learning, Memory, & Cognition, 32, 904–918.
Bruner, J. S., Goodnow, J. J., & Austin, G. A. (1956). A
study of thinking. New York, NY: Wiley.
Brunswik, E. (1952). The conceptual framework of psychology. Chicago: The University of Chicago Press.
Busemeyer, J. R. & Johnson, J. G. (2004). Computational
models of decision making. In In D. J. Koehler & N.
Harvey (Eds.), The Blackwell handbook of judgment
and decision making (pp. 133–154). Malden, MA:
Blackwell.
Busemeyer, J. R., & Townsend, J. T. (1993). Decision
field theory: A dynamic-cognitive approach to decision making in an uncertain environment. Psychological Review, 100, 432–459.
Chater, N., Oaksford, M., Nakisa, R., & Redington, M.
(2003). Fast, frugal and rational: How rational norms
explain behavior. Organizational Behavior and Human Decision Processes, 90, 63–80.
Christensen-Szalanski, J. J. J. (1978). Problem solving
strategies: a selection mechanism, some implications
and some data. Organizational Behavior and Human
Performance, 22, 307–323.
Christensen-Szalanski, J. J. J. (1980). A further examination of the selection of problem solving strategies:
the effects of deadlines and analytic aptitudes. Organizational Behavior and Human Performance, 25, 107–
122.
Chu, P. C., & Spires, E. E. (2003). Perceptions of accuracy and effort of decision strategies. Organizational

<-----Page 8----->Judgment and Decision Making, Vol. 3, No. 3, March 2008

Behavior and Human Decision Processes, 91, 203–
214.
Cooksey, R. W. (1996). Judgment Analysis: Theory,
Methods, and Applications. San Diego, CA: Academic
Press.
Diederich, A. (1997). Dynamic stochastic models for decision making under time constraints. Journal of Mathematical Psychology, 41, 260.
Diederich, A. (2003). MDFT account of decision making under time pressure. Psychonomic Bulletin and
Review, 10, 157–166.
Dougherty, M. R., Gettys, C. F., & Ogden, E. E. (1999).
MINERVA-DM: A memory processes model for judgments of likelihood. Psychological Review, 106, 180–
209.
Dror, I. E., Busemeyer, J. R., & Basola, B. (1999). Decision making under time pressure: An independent test
of sequential sampling models. Memory & Cognition,
27, 713–725.
Einhorn, H. J., & Hogarth, R. M. (1981). Behavioral decision theory: processes of judgment and choice. Annual Review of Psychology, 32, 53–88.
Erev, I., & Barron, G. (2005). On adaptation, maximization, and reinforcement learning among cognitive
strategies. Psychological Review, 112, 912–931.
Gaissmaier, W., Schooler, L. J. & Mata, R. (2008). An
ecological perspective to cognitive limits: Modeling
environment-mind interactions with ACT-R. Judgment
and Decision Making, 3, 278–291.
Gigerenzer, G. (1996). On narrow norms and vague
heuristics: A reply to Kahneman and Tversky. Psychological Review, 103, 592–596.
Gigerenzer, G. (2004). Fast and frugal heuristics: The
tools of bounded rationality. In D. Koehler & N. Harvey (Eds.), Handbook of Judgement and decision making. Oxford, UK: Blackwell.
Gigerenzer, G., & Todd, P. M. (1999). Fast and frugal
heuristics: the adaptive toolbox. In G. Gigerenzer, P.
M. Todd & the ABC Research Group, Simple heuristics that make us smart (pp. 3–34). New York: Oxford
University Press.
Gigerenzer, G., Todd, P. A. & the ABC Research Group
(1999). Simple heuristics that make us smart. New
York: Oxford University Press.
Glöckner, A., & Betsch, T. (2008). Modelling option and
strategy choices with connectionist networks: Towards
an integrative model of automatic and controlled decision making. Judgment and Decision Making, 3, 215–
228.
Goldstein W. M., & Hogarth, R. M. (1997). Judgment
and decision research: some historical context. In W.
M., Goldstein, & R. M., Hogarth (Ed.), Research on
judgment and decision making: Currents, connections,

Models and metaphors

203

and controversies (pp. 3–68). Cambridge, UK: Cambridge University Press.
Hammond, K. R. (1955). Probabilistic functioning and
the clinical method. Psychological Review, 62, 255–
262.
Hausmann, D. & Läge, D. (2008). Sequential evidence
accumulation in decision making: The individual desired level of confidence can explain the extent of information acquisition. Judgment and Decision Making, 3, 229–243.
Hogarth, R. M., & Karelaia, N. (2005). Ignoring information in binary choice with continuous variables: When
is less “more”? Journal of Mathematical Psychology,
49, 115–124.
Hogarth, R. M., & Karelaia, N. (2007). Heuristic and
linear models of judgment: Matching rules and environments. Psychological Review, 114, 733–758.
Holyoak, K. J. (1999). Psychology. In R. A. Wilson and
F. C. Keil (Eds.) The MIT Encyclopedia of the cognitive sciences (pp xl-xlix) Cambridge, MA.:MIT Press
Holyoak, K. J. & Simon (1999). Bidirectional reasoning
in decision making by constraint satisfaction. Journal
of Experimental Psychology: General, 128, 3–31.
Juslin, P., & Persson, M. (2002). PROBabilities from
EXemplars (PROBEX): A “lazy” algorithm for probabilistic inference from generic knowledge. Cognitive
Science, 26, 563–607.
Juslin, P., Olsson, H., & Olsson, A. C. (2003). Exemplar effects in categorization and multiple-cue judgment. Journal of Experimental Psychology: General,
132, 133–156.
Karlsson, L., Julsin, P., & Olsson, H. (2008). Exemplarbased inference in multi-attribute decision making:
Contingent, not automatic, strategy shifts? Judgment
and Decision Making 3, 244–260.
Klein, G. (1998). Sources of Power: How people make
decisions. Cambridge, MA: MIT Press.
Lee, M. D., & Cummins, T. D. R. (2004). Evidence accumulation in decision making: Unifying the “take the
best” and the “rational” models. Psychonomic Bulletin
and Review, 11, 343–352.
Lopes, L. L. (1991). The rhetoric of irrationality. Theory
and Psychology, 1, 65–82.
Martignon, L., & Hoffrage, U. (1999). Why does onereason decision making work? A case study in ecological rationality. In G. Gigerenzer, P. M. Todd & t. A.
R. Group (Eds.), Simple heuristics that make us smart
(pp. 119–140). New York: Oxford University Press.
Medin, D. L., & Bazerman, M. H. (1999). Broadening
behavioral decision research: Multiple levels of cognitive processing. Psychonomic Bulletin and Review, 6,
533–546.
Medin, D. L., & Schaffer, M. M. (1978). Context theory
of classification learning. Psychological Review, 85,

<-----Page 9----->Judgment and Decision Making, Vol. 3, No. 3, March 2008

207–238.
Medin, D. L, Ross, B. H., & Markman, A. B. (2001).
Cognitive Psychology (3rd ed.). Fort Worth, TX: Harcourt.
Miller, G. A. (1956). The magical number seven, plus or
minus two: some limits on our capacity for processing
information. Psychological Review, 63, 81–97.
Murphy, G. L., & Medin, D. L. (1985). The role of theories in conceptual coherence. Psychological Review,
92, 289–31
Neisser, U. (1967). Cognitive Psychology. Englewood
Cliffs, NJ: Prentice-Hall.
Newell, B. R. (2005). Re-visions of rationality. Trends in
Cognitive Sciences, 9, 11–15.
Newell, B. R., Collins, P., & Lee, M. D. (2007). Adjusting the spanner: Testing an evidence accumulation
model of decision making. In D. McNamara and G.
Trafton (Eds.), Proceedings of the 29th Annual Conference of the Cognitive Science Society (pp 533–538).
Austin, TX: Cognitive Science Society.
Newell, B. R., Lagnado, D. A, & Shanks, D. R. (2007).
Straight Choices: The psychology of decision making.
Hove, UK: Psychology Press.
Newell, B. R., & Rakow, T. (2007). The role of experience in decisions from description. Psychonomic
Bulletin and Review, 14, 1133–1139.
Nosofsky, R. M. (1984). Choice, similarity, and the context theory of classification. Journal of Experimental
Psychology: Learning, Memory & Cognition, 10, 104–
114.
Nosofsky, R. M., & Palmeri, T. J. (1997). An exemplarbased random walk model of speeded classification.
Psychological Review, 104, 266–300.
Payne, J. W. (1976). Task complexity and contingent processing in decision making: An information search and
protocol analysis. Organizational Behavior and Human Performance, 16, 366–387.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1993).
The adaptive decision maker. Cambridge: Cambridge
University Press.

Models and metaphors

204

Ratcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85, 59–108.
Rieskamp, J. (2006). Perspectives of probabilistic inference: Reinforcement learning and an adaptive network compared. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 32, 1355–1370.
Rieskamp, J. (2008). The importance of learning when
making inferences. Judgment and Decision Making, 3,
261–277.
Rieskamp, J. & Otto, P. (2006). SSL: A theory of how
people learn to select strategies. . Journal of Experimental Psychology:General, 135, 207–236.
Roe, R. M., Busemeyer, J. R., & Townsend, J. T. (2001).
Multialternative decision field theory: A dynamic connectionist model of decision making. Psychological
Review, 108, 370–392.
Shugan, S. (1980). The cost of thinking. The Journal of
Consumer Research, 7, 99–111.
Simon, H. (1956). Rational choice and the structure of
the environment. Psychological Review, 63, 129–138.
Simon, H. A. (1990). Invariants of human behavior. Annual Review of Psychology, 41, 1–19.
Stanovich, K. E., & West, R. F. (2000). Individual differences in reasoning: Implications for the rationality
debate? Behavioral and Brain Sciences, 23, 645–726.
Stone, G. O. (1986). An analysis of the delta rule and the
learning of statistical associations. In: D. E. Rumelhart, J. McClelland & the PDP Research Group, Parallel distributed processing, Volume 1: Foundations
(365–422), Cambridge, MA: MIT Press.
Tversky, A., & Edwards, W. (1966). Information versus
reward in binary choices. Journal of Experimental
Psychology, 71, 680–683.
Tversky, A. & Kahneman, D. (1986). Rational choice
and the framing of decisions. Journal of Business, 59,
251–284.
Wallsten, T. S., & Barton, C. (1982). Processing probabilistic multidimensional information for decisions.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 8, 361–384.

