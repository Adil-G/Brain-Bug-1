<-----Page 0----->Advanced Review

Decision making under risk
and uncertainty
Joseph G. Johnson1∗ and Jerome R. Busemeyer2
Decision making is studied from a number of different theoretical approaches.
Normative theories focus on how to make the best decisions by deriving algebraic
representations of preference from idealized behavioral axioms. Descriptive
theories adopt this algebraic representation, but incorporate known limitations
of human behavior. Computational approaches start from a different set of
assumptions altogether, focusing instead on the underlying cognitive and
emotional processes that result in the selection of one option over the other. This
review comprehensively but concisely describes and contrasts three approaches in
terms of their theoretical assumptions and their ability to account for behavioral and
neurophysiological evidence from experimental research. Although each approach
contributes substantially to our understanding of human decision making, we
argue that the computational approach is more fruitful and parsimonious for
describing and predicting choices in both laboratory and applied settings and for
understanding the neurophysiological substrates of decision making.  2010 John
Wiley & Sons, Ltd. WIREs Cogn Sci 2010 1 736–749

D

ecision making is a faculty that is evident in
nearly everything we do. From the commonplace
to the consequential, our lives are guided by the
decisions we make. Therefore, it is important to
understand how we make decisions, so that we may
be aware of how various factors may have exerted an
influence on past decisions, and so that we may be able
to improve upon future decisions. Indeed, one could
easily argue that our decision-making ability and the
agency it provides us is what separates us from lower
order animals.
Because decision making is so central to our
lives, it is not surprising that it receives research
attention from a wide range of disciplines: cognitive
psychology, economics, political science, marketing,
social psychology, engineering, philosophy, and more.
Although this breadth in contributing disciplines
is beneficial in bringing multiple perspectives to
bear, it is also (at least partly) responsible for
somewhat divergent or inconsistent research goals.
Some researchers are interested in how to make the
‘best’ decision under specific conditions, while others

∗ Correspondence

to: johnsojg@muohio.edu

1 Department of Psychology,

Miami University, Oxford, OH 45056,

USA
2 Psychological and Brain Sciences, Indiana University, Bloomington,

IN 47405, USA
DOI: 10.1002/wcs.76

736

are interested in the explanation for a specific course
of action; some prefer to know what decision should
be made, while others strive to understand why. In
the current review, we identify three major streams of
development in decision theory that can be classified
according to the focal behaviors and functional nature
of the corresponding decisions.
First, a great deal of foundational decision
research was focused on the notion of making ‘optimal’ decisions. Given a particular situation, how
should one go about selecting the best among competing alternatives? This normative research stream has
the goal of reducing a decision situation essentially
to a mathematical optimization problem and finding
the correct solution to this problem. It is responsible
for treating decision outcomes as random variables,
casting decision problems in expectation terms, and
deriving solutions that maximize the expected utility
among probability distributions of outcomes produced by different actions.
Second, this treatment gave rise to a counterpoise
among researchers who wanted to impart a more
psychological and constrained view of decision
making. Because humans often make ‘suboptimal’
decisions, how can we describe and predict the choices
that one will make in a particular situation? Research
with this descriptive focus attempts to describe how
humans actually make decisions, rather than trying to

 2010 Jo h n Wiley & So n s, L td.

Vo lu me 1, September/Octo ber 2010

<-----Page 1----->WIREs Cognitive Science

Decision making

find ideal decisions for any given situation. People are
not likely to be able to apply the analytic machinery
developed within the normative approach, and the
descriptive perspective can be characterized by the
addition of psychological factors that embellish this
basic machinery. That is, this approach retains a form
of the utility maximization goal but is focused on
what psychological adjustments need to be made to
account for observed human decisions.
Third, beyond providing psychological meaning
and justification to descriptive modifications of the
normative theories, many recent researchers examine
the decision processes themselves, rather than just
the final choice. What mental or neural operations
are taking place that lead to the selection of one
option over another in a given situation? This
computational approach seeks to understand what
the underlying (cognitive and emotional) processes
are that produce the observable actions predicted by
the descriptive theories. Rather than beginning with
utility maximization goals derived from the normative
approach, and then modifying them as needed in the
descriptive approach, the computational approach is
built directly from cognitive and emotional processing
assumptions. It attempts to formally define the
dynamic processes—whether neural, componential,
or holistic—that over time determine a final decision.
This advanced review will provide an update
on the status and contemporary research for each of
these major research streams. It will provide sufficient
background in the development of each approach
but focus on how they deal with current issues and
challenges in the realm of decision making. It will
focus on individual (rather than collective or group)
decision making. It will also focus on situations
dealing mainly with risk in the form of known possible
outcomes with well-specified probabilities. These
situations are distinct from situations of uncertainty
involving ambiguity in the probability distribution
over outcomes, or situations of certainty where choice
outcomes are clearly defined. Although these different
domains share some similarities, they are treated
distinctly in the extant literature; space constraints
prevent detailed treatment of each.

NORMATIVE APPROACHES TO
DETERMINE ‘OPTIMAL’ CHOICE
We make many different types of decisions everyday.
What should I do this weekend? Should I pay off
my credit card or wait? Should I take the job offer
or not? Do I take this job or keep looking? Most
theories of decision making assume any of these
decisions can be abstracted and represented as the
Vo lu me 1, September/Octo ber 2010

selection of a single course of action X described
by the value of the possible outcomes {x1 , x2 ,
. . ., xn } that could result from selecting the action
and the associated probability that each outcome
would occur if the action were selected {p1 , p2 ,
. . ., pn }. This representation reduces the choice task
to one of selecting from among competing simple
random variables (see Ref 1, for a critique of this
‘gambling metaphor’, or Ref 2, for an alternative
‘naturalistic’ research paradigm). The simplest rule,
mathematically, is then to select the option X that has
the highest expected value EV(X):
EV(X) =

n


pi xi

(1)

i=1

For example, take a decision with two options:
(A) a certain outcome valued at $1 million, and
(B) an uncertain option with an 89% chance of
$1 million, a 10% chance of 5 million, and a 1%
chance of receiving nothing. The expected value
calculation in Eq. (1) suggests that one should take
the second option, because EV(B) = $1.39 million >
$1 million = EV(A).
The EV rule seems reasonable for gambles played
repeatedly many times. But for gambles with high
stakes that are only played once, it is easy to see
that this objective may not be so appealing. Bernoulli3
observed that most people did not make choices in
line with the expected value rule when the values
(x) were determined with large objective amounts
(e.g., $1 million). He proposed that people did not
view (monetary) outcomes objectively, but rather they
did so subjectively. That is, $1000 does not have
the same subjective value to both a miller and a
millionaire—the former places more subjective worth
on the same objective dollar amount. In fact, given
the hypothetical choice between A and B above, the
majority of experimental participants select A even
though it has a lower expected value. Presumably,
this is due to the fact that the subjective experience of
receiving $5 million instead of $1 million is not five
times as pleasurable as receiving $1 million instead
of $0. Rather, as wealth increases, the additional
value placed on subsequent increments decreases (an
additional $1 million means more if you are broke
than if you already have $4 million).

DIMINISHING MARGINAL UTILITY
The increments in subjective value corresponding
to increases in objective value decrease as the
initial objective value increases; this is termed as

 2010 Jo h n Wiley & So n s, L td.

737

<-----Page 2----->Advanced Review

wires.wiley.com/cogsci

diminishing marginal utility. This explains why a raise
of $10,000 per year would be quite meaningful to
the average reader, but probably not to Bill Gates.
The concept is similar to the Weber–Fechner Law in
psychophysics, where changes in stimulus intensity
have different psychological sensations depending on
the initial magnitude. Mathematically, this is typically
represented with a simple power utility function,
U(x) = xα . This form also allows for describing an
individual’s risk attitudes with a single parameter:
when 0 < α < 1, the utility function is concave and
risk-averse behavior is predicted, whereas a convex
function predicting risk-seeking behavior emerges if
α > 1.
Mathematically, this involves a function that
transforms objective value into subjective utility, U(x).
A simple modification then suggests one should select
an option with the highest expected utility EU(X):
EU(X) =

n


pi U(xi )

(2)

i=1

Bernoulli’s concept is intuitively plausible and could
explain actual choice behavior. Furthermore, it is easy
to impute psychological meaning on the utility function, such as risk attitudes (see section Diminishing
Marginal Utility). However, this approach was criticized by some theorists who adhered strongly to
the normative approach, because there was no rational foundation for why people should use the EU
for choices only played once. In 1944, a seminal
book by von Neumann and Morgenstern overcame
this limitation by providing an axiomatic foundation
for expected utility theory. The original EU theory
was restricted to gambles with objectively known
probabilities, but Savage4 is credited with further
extending the axiomatic foundation of von Neumann
and Morgenstern5 beyond subjective utility to additionally include subjective probability for uncertain
events with no objectively known probabilities, a
notion raised earlier by Ramsey6 and de Finetti,7
as well as by von Neumann himself. Mathematically,
the subjective expected utility (SEU) of an option then
becomes
SEU(X) =

n


πi U(xi )

(3)

i=1

Here, the events are assigned subjective probabilities,
πi . Savage’s4 axiomatization is still considered as a
rational theory, as the subjective probabilities were
still constrained by the laws of probability. However,
it did not take long before additional empirical
738

evidence about human choice behavior challenged
SEU on other grounds.
Allais8 presented people with the choice between
A and B introduced earlier, as well as a choice between
two other options: (C) an 11% chance of receiving $1
million, otherwise nothing and (D) a 10% chance of
receiving $5 million, otherwise nothing. Here, the
options C and D are created simply by changing
a ‘common consequence’ of an 89% chance at $1
million in A and B, respectively, to an 89% chance at
$0. If one chooses A over B in the first choice, then
this implies a utility function that predicts one should
still take option C over D, because SEU(A) > SEU(B)
implies SEU(C) > SEV(D). However, although most
people select A instead of B, they select D instead
of C. This choice pattern is inconsistent with SEU,
regardless of the form of U(x). Specifically, it violates
one of the axioms (independence) set forth by von
Neumann and Morgenstern5 and Savage.4
This empirical inconsistency prompted researchers to explore further modifications to the SEU
framework. At this point, although the basic algorithm
was retained (maximization of a mathematical
expectation), theories began to depart substantially
from these previous ‘rational’ ideals in order to explain
the decisions of we ‘irrational’ humans.
Another important advance in utility theory was
the extension of the theory to outcomes described by
multiple conflicting attributes.9 For example, when
choosing a medical insurance plan, one needs to
consider not only the cost of the plan but also
the breadth of the coverage, the quality of the
care provided by the coverage, and other attributes
of the plan. Thus this decision involves evaluating
consequences with respect to several conflicting
objectives. Should one spend more money to achieve
greater coverage or should one save money but take
a risk with lower coverage? The most commonly
used multiattribute utility model combines the values
of the conflicting attributes according to a weighted
additive rule (much like the utility theory for gambles),
where the weights reflect the tradeoffs among the
attributes. The weighted additive rule is considered to
be a compensatory rule which allows deficits on one
attribute to be compensated by advantages on other
attributes.

DESCRIPTIVE APPROACHES
TO EXPLAIN OBSERVED CHOICE
Descriptive theories in decision making, as their name
suggests, are more concerned with describing the
choices people actually make rather than providing
a ‘rational’ basis for making choices, as EV, EU, and

 2010 Jo h n Wiley & So n s, L td.

Vo lu me 1, September/Octo ber 2010

<-----Page 3----->WIREs Cognitive Science

Decision making

SEU aimed to do. This shift is due, in large part, to the
fact that psychologists began to relax the idealistic
models heretofore introduced by mathematicians,
statisticians, and economists. The most popular
descriptive theory of choice is termed as prospect
theory, introduced by Kahneman and Tversky.10

(a)

UG(x)

S

x

Prospect Theory
Prospect theory introduced four important aspects
from cognitive psychology to impart a more humancentered view of decision making.10 First, it suggested
a predecisional ‘editing’ stage where the decision
problem is prepared, such as by eliminating clearly
inferior choice options and simplifying and mentally
ordering outcomes. Second, it introduced the notion
of reference dependence, where outcomes are not
evaluated absolutely but relative to some benchmark,
such as one’s current wealth or ‘status quo’.11
Third, it suggested that outcomes could be evaluated
differentially based on whether they were seen as gains
or losses relative to the status quo—that is, there were
separate utility functions for gains UG (x) and losses
UL (x). Fourth, specifically, it proposed the concept of
loss aversion, that the marginal utility of a constant
change is greater for losses (a $100 loss is more
aversive than a $100 gain is pleasant).
Formally, these assumptions can be incorporated into Eq. (3) with the appropriate specification (Figure 1): UG (x) = f (x − S) for x − S > 0 and
UL (x) = −λf (S − x) for x − S < 0 where S is the status quo and f is concave for gains, convex for losses,
and steeper for losses (λ is a parameter to model
the degree of loss aversion). Kahneman and Tversky also introduced the term decision weight for the
multiplier attached to each outcome. Although they
assumed decision weights were based on the objective
probabilities, π (p), they explicitly distinguished this
notion from a purely probabilistic evaluation.12 They
put forth a strictly convex form for π (p) that implied
overweighting of small probabilities and underweighting of large probabilities; a revised form suggests
concavity for small probabilities (Figure 1).25 . These
restrictions on Eq. (3), spurred by reflecting on human
thinking rather than any rational calculus, produced
a theory that was much more accurate at describing
actual choices—but only to a degree.

SUBJECTIVE PROBABILITY
AND UNCERTAINTY
Prospect theory introduced the important notion of
decision weights, but this in turn raises the question
of how these weights are psychologically determined.
Vo lu me 1, September/Octo ber 2010

UL(x)

(b)
p(p)

p

FIGURE 1 | Cumulative prospect theory’s value and weighting
functions.

Kahneman and Tversky10 introduced the probability
weighting function, which could be interpreted in
terms of concepts such as discriminability and
attractiveness,13 or affective notions such as elation
and disappointment.14 Computational models of
decision weighting describe how these weights may
result from probability judgments based on memory
retrieval15 or as the result of differential attention and
‘dwelling’ on specific outcomes or events.16
Craig Fox’s extension of support theory to
decision making17–19 describes how individuals in
circumstances of uncertainty might estimate probabilities, which in turn can then be used to derive
decision weights. Support theory distinguishes among
different descriptions of events as the carriers of belief
(rather than the objective events themselves) and is
based on support for a focal or salient description
relative to other possible descriptions. This is an
important theory for extending decisions under risk
(known event probabilities) to situations of uncertainty (unknown event probabilities).

 2010 Jo h n Wiley & So n s, L td.

739

<-----Page 4----->Advanced Review

wires.wiley.com/cogsci

Rank-Dependent Theories
Even prospect theory was unable to account for all
the observed trends in human choice behavior.10,20,21
For example, it predicted that people would choose
options even if they were clearly dominated by other
options in the choice set (see Ref 22, for a review)
and was severely limited to choice options with only
two outcomes. It also implied that the weight given
to an outcome was independent of the value of the
outcome. That is, the weight given to a probability
of 0.10 would be the same regardless whether this
probability corresponded to the worst or the best
outcome of a gamble, which is not true for human
choices.23
In the late 1980s, several researchers independently arrived at an idea that served as the next
major modification to the expected utility framework. In particular, it allowed the decision weight
of an outcome to be dependent on the rank order
of the outcome (e.g., whether it was the worst or
the best), and hence these theories are called rankdependent utility (RDU) theories (see also rank-andsign-dependent utility in Ref 24). This was achieved
by changing the basis of the weighting function
from the probability of winning x to the probability of winning x or more (decumulative probability). Tversky and Kahneman25 extended their
original theory into cumulative prospect theory,
perhaps the most popular RDU theory. Formally,
RDU theories propose the following general function for the decision weight assigned to a positive
outcome xj :
 n 
 n 


w(xi ) = π
pj − π
pj
i

(4)

i+1

A notational change produces the following overall
utility of an option X:
RDU(X) =

n


w(xi )U(xi )

(5)

i=1

RDU theories, via Eqs (4) and (5), introduce
a subtle but important distinction between the
subjective probability and the decision weight. The
subjective probability refers to the distortion of
decumulative probability, π (·), and is thus essentially
a psychophysical measure. Decision weight, w(·), is
a further transformation that describes the relative
weight given to an outcome when integrating across
other outcomes to determine the holistic value of
an option. In earlier SEU models, the decision
740

weight was simply equal to the subjective probability,
w(p) = π (p).

Configural Weight Theories
Michael Birnbaum and his colleagues advocate a
descriptive theory that is similar in some respects to
RDU theories, but incorporates important differences
and makes competing predictions regarding some
important empirical phenomena.26,27 For example,
RDU theories predict that individuals should never
choose an option that is stochastically dominated
by another. If we define XQ as the random value
produced by gamble Q and XR as the random value
produced by gamble R, then option Q stochastically
dominates option R if and only if Pr(XQ > x) ≥
Pr(XR > x) for all x, and the inequality is strict for at
least one x (i.e., the cumulative distribution function
of Q is always above that of R). In fact, for certain
gamble types, people seem to robustly select an option
that is stochastically dominated by another option in
the choice set.27
Birnbaum’s configural weight utility (CWU)
theories are able to explain these violations of
stochastic dominance, as well as the other behaviors
covered previously. CWU theories retain the algebraic
representation and expectation maximization rule of
all previous utility theories. The key difference is in
the specification of the weighting function, which
is exemplified by the transfer of attention exchange
CWU model (TAX; see Ref 28). In the TAX model,
similar to the RDU models, lower values of a gamble
‘steal’ or ‘tax’ decision weight from higher values.
But in addition, the TAX model assigns a separate
weight to each outcome listed in a gamble even
if the same value is listed more than once. For
example, the single weight assigned to $100 for
the gamble ‘0.5 chance to win $100 or else win
nothing’ is not the same as the total weight assigned
to both of the $100 outcomes in the gamble ‘0.25
chance to win $100, 0.25 chance to win $100, and
0.5 chance to win nothing’. RDU theories assign
weight based on the cumulative probability of an
outcome, and so these two gambles would be treated
as the same. The violations of stochastic dominance
indicate that people do not treat these gambles as the
same.

HISTORICAL PERSPECTIVES
ON CONFIGURAL WEIGHTING
The configural weight models formally applied to
decision-making behavior are found as early as Birnbaum and Sutton.29 However, it is notable that the

 2010 Jo h n Wiley & So n s, L td.

Vo lu me 1, September/Octo ber 2010

<-----Page 5----->WIREs Cognitive Science

Decision making

idea of configural weighting can be traced back even
earlier to explanations of social judgment biases in
Birnbaum and Stegner,30 , based on work by Birnbaum
et al.31 Thus, configural weighting theories actually
predate both the decision-theoretic work on rankdependent weighting functions and even prospect
theory.

Regret Theory
Prospect theory, RDU theories, and CWU theories
strove to incorporate human tendencies into the evaluation of outcomes and their associated probabilities,
or weights. Other theories sought to redefine the basic
currency of a choice option, such as by introducing utility derived not just from the actual outcome
values, but also by comparisons to outcomes of foregone options.32,33 Loomes and Sugden33 introduced
their regret theory in response to prospect theory and
showed how it could explain the same empirical results
put forth by Kahneman and Tversky10 as evidence for
the latter. Essentially, regret theory assumes that utility U(x) is composed of two distinct components,
an evaluation of the outcome that is obtained and a
difference between that outcome and those forgone.
For example, assume one is choosing between
two gambles, A and B, determined by a coin flip.
If one chooses A, then $100 is won if the coin
lands on heads, and nothing is won if it lands on
tails; B offers $70 for heads and $30 for tails. In
evaluating option A, regret theory proposes that the
utility assigned to the outcome ‘heads’ will be a (linear)
combination of the utility of $100 and the additional
utility or ‘rejoice’ associated with the fact that, had
B been chosen, then only $70 would have been won.
Conversely, evaluation of the outcome ‘heads’ for
option B involves the utility of $70 as well as the
disutility or ‘regret’ associated with the fact that one
could have obtained $30 more had A been chosen. The
basic psychological mechanisms involved in regret
theories are similar to those studied extensively in
other psychological domains, such as work in social
psychology on counterfactual thinking.34 Mellers
et al.35 extended these ideas and developed a more
detailed model of the emotional basis for these regrets.

Security-Potential/Aspiration Theory
Lola Lopes introduced additional psychological constructs such as hope, fear, and goal achievement to
develop a descriptive theory of decision making called
security-potential/aspiration (SP/A) theory.36,37 This
theory assumes that a decision maker simultaneously
considers two distinct criteria in making decisions.
First, one considers a utility component similar to
Vo lu me 1, September/Octo ber 2010

those found in RDU theories. However, Lopes allows
for evaluation of outcomes in both a low-to-high,
cumulative fashion and the decumulative, high-to-low
fashion posited by RDU theories. Her reasoning is that
individuals may exhibit security-minded behavior that
focuses on the probability of obtaining an outcome
with a value of x or less, and/or a potential-minded
analysis in line with RDU that focuses on the probability of obtaining an outcome with a value of x or more.
Mathematically, Lopes allows for a parameter that
moderates the degree to which the security-minded
versus potential-minded analyses contribute to the
assessment of outcome utility.
Second, SP/A theory includes the notion of an
aspiration level or goal achievement component. That
is, in addition to the value assigned to options based on
the assessment of their outcome value (as described
in the preceding paragraph), options are evaluated
favorably if they allow a decision maker to achieve
some preset goal. Mathematically, this aspiration
criterion evaluation for an option is based on the
probability that the option provides an outcome at
or above the aspiration level. If one has a goal of
winning $80 in the coin flip choice from the previous
section, then A has a 50% chance of meeting this
aspiration level (corresponding to the ‘heads’ value
of $100 > $80) and B has no chance of meeting the
aspiration level (neither outcome is >$80).
SP/A theory assumes that a decision maker integrates the two components into a holistic utility value
for each option and again maximizes the expectation of this utility. Each single component may
produce competing predictions that produce internal
conflict. For example, with an aspiration level of $80,
A is preferred using the goal criterion; however, a
security-minded decision maker who focuses on the
low outcomes may prefer option B on this criterion
(due to its advantageous low outcome, relative to A).
Mathematically, model parameters can specify the relative degree to which each component contributes to
choice behavior.

COMPUTATIONAL APPROACHES TO
MODEL LATENT CHOICE PROCESSES
Descriptive theories of choice embellish the basic
framework of maximizing an expectation with observations from human psychology. Prospect theory,
RDU theories, and CWU theories make claims about
the specific nature of utility and probability assessment that depart from rational norms and laws of
probability. Other theories include additional considerations beyond an expected utility assessment, such as
the potential satisfaction or disappointment resulting

 2010 Jo h n Wiley & So n s, L td.

741

<-----Page 6----->Advanced Review

wires.wiley.com/cogsci

from comparing outcomes to those forfeit (regret theory), or the desire for a choice option to fulfill some
goal (SP/A theory). In contrast to all of these descriptive approaches which focus on choice as determined
by the maximization of some utility function, computational approaches focus on the underlying cognitive,
motivational, and emotional processes from which
choices dynamically emerge. In this section, we will
review several popular research streams that adhere
to this philosophy.38

PROCESSING ASSUMPTIONS AND
MODEL REPRESENTATION
Computational models do not begin with the algebraic
utility maximization assumptions of the normative
and (most) descriptive approaches. However, it
could be that choices in line with the normative
goals of utility maximization evolve from the
underlying processes. If so, it could be that utility
maximization is indeed representative of human
choice behavior, even if the algebraic representation
is merely paramorphic—thus, computational and
descriptive approaches are not mutually exclusive.

Heuristic and Rule-Based Approaches
Perhaps the most intuitive computational approaches
specify simple procedures for making choices, often
called heuristics. Heuristics are typically expressed as
verbalizable rules or flowcharts for applying discrete
steps to make a decision (see Ref 39, for a review and
organizing framework).

Elimination by Aspects
One of the earliest popular heuristics was Tversky’s40
elimination by aspects (EBA) model. Consider for
example the problem of buying a new digital
camera. This is a multiattribute decision involving the
consideration of attributes such as price, resolution
of the camera, size of the camera, etc. Rather than
maximizing a weighted average of attribute values,
as suggested by multiattribute utility theories, the
EBA model proposes that individuals sequentially
consider different aspects, such as whether the
price is within budget, whether the resolution is
satisfactory, and whether size is sufficiently small for
a new digital camera. The probability of considering
an aspect is proportional to its importance, so
that if price is the most important attribute to a
consumer, it is most likely to be considered first.a
When considering an aspect, any choice option that
does not meet a minimum criteria (e.g., a price
over one’s budget of $300) is eliminated from the
742

choice set and not considered any further. This
sequential aspect selection and elimination process
continues until only a single choice option ‘survives’.
Tversky40 illustrated the ability of this model to
account for violations of rational choice axioms
(e.g., violations of independence from irrelevant
alternatives; see Ref 41 for discussion). Although
Tversky40 also showed how EBA could be represented
as a (random) utility model, it has a decidedly
different flavor through its presentation in terms of
simple rules and is not ‘rational’ in the sense that
it is noncompensatory. An option can be eliminated
from consideration simply on the basis of a single
attribute even though it may be holistically the
‘best’ because of its many advantages on other
attributes.

Thorngate’s Heuristics for Gamble Forms
Thorngate42 proposed 10 distinct decision heuristics,
based largely on the work of Coombs et al.43 that were
formulated for application to choices among gambles
like those presented earlier. For example, his minimax
heuristic selects the alternative with the highest minimum outcome value, or max[x1 ], and the maximax
heuristic chooses according to max[xn ]. His leastlikely heuristic chooses the alternative with the lowest
probability of its worst outcome, min[p1 ], whereas the
most likely heuristic chooses according to max[p1 ].
Other suggested heuristics include elimination heuristics like EBA, and an equal-weighting heuristic that
selects based on the highest average outcome value
(ignoring probabilities; see also Ref 44). Thorngate’s
analyses showed that these simple heuristics often
selected options that were normatively optimal (in
terms of expected utility) or very close to it.

The Adaptive Decision Maker Hypothesis
Payne et al.45,46 proposed that decision strategies,
including utility maximization algorithms as well as
simple heuristics, could be formalized in terms of
what they called elementary information processing
(EIP) units, such as ‘retrieve’, ‘add’, ‘multiply’,
and ‘compare’. Implementing maximax among two
alternatives A and B would involve four EIPs:
retrieve a1 , retrieve b1 , compare a1 , b1 , choose
max [a1 , b1 ]. This specification welcomes precise
implementation in computer simulations and allows
for the derivation of measures such as decision time
and information acquisition. It is worthy to note that,
although Payne et al.45,46 did not introduce novel
heuristics per se, their method of formalizing and
studying heuristics has been enormously influential
on subsequent computational modeling. Furthermore,
they introduced an adaptive view of strategy selection,

 2010 Jo h n Wiley & So n s, L td.

Vo lu me 1, September/Octo ber 2010

<-----Page 7----->WIREs Cognitive Science

Decision making

based on an efficient frontier involving a tradeoff
between desired levels of effort (in terms of EIPs)
and accuracy (relative to a normative algorithm). This
represents an important advance in understanding
which heuristic from among many may be applied in
any given situation.

Gigerenzer’s Adaptive Toolbox
Gigerenzer and Todd47 and the ABC Research
Group also advance the notion of a collection of
decision heuristics. Many of their heuristics are
very similar to the earlier mentioned heuristics in
terms of the process description. For example, the
priority heuristic48 involves sequential application of
thresholded versions of the maximin, most-likely,
and maximax heuristics. First, choose the option
that maximizes the minimum possible outcome; but
only if the minimum outcome value is sufficiently
larger than the other options’ minimum outcomes.
Otherwise, consider the probability p1 of each option’s
lowest outcome, and so on. Although the actual
heuristics are very similar to those already mentioned,
this research stream is notable for three additional
characteristics. First, it is applied to prediction,
inference, and categorization, as well as decision
making. Second, like Payne et al.,46 it stresses the
adaptive nature of the development and application
of simple heuristics (hence the term ‘adaptive toolbox’)
in terms of ecological fit between the heuristics and the
environment. Third, they decompose the majority of
their heuristics into three distinct components: a rule
for guiding information search, a rule for determining
when to stop search, and a decision rule applied
to the information collected. This strikes a balance
between the low-level EIP-based description and the
presentation of holistic rules.

Decision Field Theory
The most influential type of decision model in cognitive science is the sequential sampling/accumulation
model. This type of model has been applied to neuroscience, sensation, perception, memory, and categorization domains.49 The first application of sequential
sampling models to decision making under risk and
uncertainty was decision field theory (DFT; Refs
50–53, for reviews; see also Ref 54, for a neural
network representation of DFT). Most broadly, DFT
is a mathematical model based on cognitive principles of selective attention and relative evaluation, that
models deliberation as a dynamic system accumulating evidence in favor of each choice option. The first
option to reach a criterion level of evidence is selected.
In contrast to descriptive utility theories, DFT thus
Vo lu me 1, September/Octo ber 2010

makes specific quantitative predictions about information acquisition and response times, in addition to
choices.
First, DFT assumes that attention shifts to different dimensions of the choice task over time. For
gambles, these shifts occur (independently) across
the outcomes of each option, with the probability of
attending to an outcome proportional to its objective
probability (see Ref 16, for details). For preferential choice, these transitions are typically assumed
to be defined across attributes, with the simplifying
assumption that attention to a specific attribute (e.g.,
the price of all camera models) at any moment is proportional to the attribute’s importance51 (see Ref 55,
for alternative assumptions).
Second, the current focus of attention generates
a relative evaluation for each choice option. When
price is under consideration, then those options with
the highest prices will receive low evaluations. Specifically, an option’s evaluation is based on the affective
reaction to the option’s value on the focal attribute,
relative to the average reaction of all the other competing options’ values.
Third, these momentary evaluations are accumulated over time to describe the current preference
for each option at each point during deliberation
(Figure 2). To the extent that attention focuses on features that are favorable for a particular option, that
option will have a greater value of preference over
time. This accumulation process can be subject to specific effects such as gradual decay to produce recency
effects, as well as inhibitory influences from competing options (i.e., as one option becomes preferred, it
inhibits or reduces the preference for other similar
options). An option is chosen, ending deliberation,
when it reaches a preset threshold level of preference
used as a criterion for being ‘good enough’ to merit
selection.
DFT has been successful in accounting for various puzzling phenomena in pairwise choice between
gambles under risk and uncertainty,50 as well as robust
paradoxes arising in multialternative and multiattribute choice problems51 and pricing.56 It provides
a measure of preference strength (rather than just
direction) and has recently been extended to predict
decision confidence as well.57 It also uniquely accounts
for effects of decision time such as speed–accuracy
tradeoffs50 and changes in preference under time
pressure.58 DFT has also been extended to model rule
learning and rule-based decision making, including
strategy switching.59 It has been successfully applied
to engineering problems such as human-in-the-loop
control systems60 and agent-based models of emergency evacuation decisions.61

 2010 Jo h n Wiley & So n s, L td.

743

<-----Page 8----->Advanced Review

wires.wiley.com/cogsci

P(t)
θ2

Options

O1

O2

O3

Attributes

A1

A2

A3

θ1
A

B
Attention

X

FIGURE 3 | Generic neural network representation of a decision
t0 t1

t2

t3

t

FIGURE 2 | Decision field theory (DFT) representation of preference
accumulation for two options. Preference P(t) accumulates for each
option, shown as separate trajectories, over time t. At time t1 , option B
is preferred with a higher value of P(t) ; at time t2 , preference is equal
between the two options, after which option A is consistently preferred.
Choice is determined when an option’s trajectory reaches the threshold
level of preference, P(t) = θ. A decision maker with a threshold of θ 2
would thus select option A at time t3 ; a more impulsive individual
modeled by θ 1 would select option B at time t1 .

Connectionist Approaches
Several contemporary computational models of
decision making besides DFT have been cast in neural network architectures. While these models may
be less transparent and in some sense more complex, they are popular in many cognitive domains and
have the advantage of neurally plausible mechanisms
(Figure 3).

Leaky Competing Accumulator Model
Usher and McClelland 62 proposed a connectionist
model that employs a recursive network to describe
how preference builds for various choice options over
time. This model is very closely related to DFT
(see Ref 63, for a comparison of the two). It also
involves sequential comparison of attributes where
the options ‘compete’ for preference based on their
relative excellence, and these momentary comparisons
are ‘accumulated’ over time into a holistic preference
value for each option, with some degree of decay (or
‘leaking’). In contrast to DFT, it includes the notion of
loss aversion from prospect theory as a fundamental
assumption.

Coherence-Seeking Network Models
Thagard and Milgram64 applied Thagard’s network
model called ECHO to decision making, and other
researchers have since extended this formulation.65–67
744

problem. Each of three choice options is described by three attributes.
An attention node determines which attribute(s) is/are processed at
each time step and thus embodies decision weight. Links between
attributes and options represent the value of each option on the
corresponding attribute. All solid connections are assumed to be
bidirectional for parallel constraint satisfaction (PCS) models, and
feedforward for leaky competing accumulator (LCA) and decision field
theory (DFT). Inhibitory bidirectional connections among options
(dashed lines) model competition among options in LCA, PCS, and DFT
models. LCA and DFT assume an additional layer between options and
attributes to compute differences.

Most recently, Andreas Glöckner et al.68,69 have
successfully applied one of these parallel constraint
satisfaction (PCS) models to various decision-making
tasks. PCS models involve a search for coherence or
consistency among a set of choice options, such as in
trying to resolve conflicting preferences across options
(one option may have a lower price, but another has
better resolution, and so on). Upon presentation of a
choice problem, PCS mechanisms are activated to find
the best interpretation of the problem in a perceptionlike process. Rather than explicitly describing any
necessarily conscious strategy or heuristic that is
applied to a choice problem, these models rely on
a more holistic or Gestalt conceptualization where a
preferred option ‘emerges’ instantly or over the course
of deliberation.
Choice options and outcome values are represented as network nodes, and links represent the
possession of certain aspects as well as their decision
weight (based on link strength; see (Figure 3). The
basic intuition is that there are some sets of node activations (option preference strengths) that will produce
a stable network (consistent representation), based on
the constraints in the form of attribute values and
weights. Given the decision problem representation,
initial advantages of one option are automatically
highlighted by increasing the activation of supporting
and decreasing the activation of contrary information.

 2010 Jo h n Wiley & So n s, L td.

Vo lu me 1, September/Octo ber 2010

<-----Page 9----->WIREs Cognitive Science

Decision making

An activation updating algorithm continues to adjust
the node activations until a stable state is achieved, at
which point the node (choice option) with the highest
activation is predicted to be chosen. Importantly, these
models involve bidirectional links between attributes
and options and are thus able to explain ‘restructuring’ of the choice problem,70,71 such as changes
in attribute importance or decision weight across the
choice task (i.e., coherence shifts) that are not possible
in static, descriptive approaches.

Memory-Based Approaches
Several researchers have acknowledged the crucial
role that memory plays in decision making.72,73
In fact, simple recognition memory can be used
to make inferential decisions when the likelihood
of recognition based on salience is correlated with
the decision criterion.74 Dougherty et al.15 use a
memory-based judgment model to account for several
robust phenomena in judgment and estimation tasks,
such as base-rate neglect, hindsight bias, and the
conjunction fallacy.75 Elke Weber, Eric Johnson, and
colleagues also propose that memory processes can
be used to model decision tasks.76,77 This approach,
most recently dubbed ‘Query theory’, assumes that
preferences that drive choice and other decisions are
based on a collection of serially posed queries to
memory concerning relevant characteristics of the
task. For example, if deciding whether to buy a
certain digital camera, an individual might attempt
to recall experiences with similar models or generate
the pros and cons of buying the camera. Query
theory is able to explain some empirical trends
in human decision behavior by embellishing this
simple notion with what is known about human
memory, such as serial position effects, priming, and
interference. Although the theory’s assumptions have
been empirically supported, at this point it has not
been formally introduced as a mathematical model
or at a specific algorithmic level, as the preceding
computational models have.

SUMMARY AND FUTURE DIRECTIONS
We do not propose that any of the approaches
described above is privileged in any objective sense.
Rather, each approach may be seen as possessing
inherent strengths and weaknesses, or as differentially applicable across domains or academic pursuits.
The class of utility models born from the normative
approach has the appeal of an axiomatic foundation,
meaning that adherence to specific principles ensures
that a utility representation can be created to describe
Vo lu me 1, September/Octo ber 2010

and predict their choices.24 This allows for a strict and
concise way of expressing a decision policy, and lends
itself to easy derivation of closed-form predictions.
The problem arises when individuals or people in general fail to adhere to these principles. Computational
approaches benefit from increased attention to mental and emotional processes and thus psychological
plausibility. They can also account for many of the
violations of these principles and often of collections
of violations. However, these models are less transparent and thus often more difficult to treat analytically,
often requiring simulation or direct application to a
specific context to derive predictions. Finally, both
within and across classes of models, it is important
to understand the tradeoff between flexibility and
robustness of models. For example, does the increased
predictive power of prospect theory over earlier SEU
theories justify the ‘cost’ of increasing the number of
free parameters? Furthermore, is the increase in fit to
the data theoretically meaningful above and beyond
that afforded by this increased flexibility (see Refs
78–80, for excellent discussions of these issues)?
This review has provided a comprehensive but
concise account of the development of theories in
decision making under risk and uncertainty. Although
decision research has come a long way, there are still
many open questions that are not fully addressed,
even by the more sophisticated theories covered
in this review (see Ref 81). How independent are
evaluations of attributes and/or alternatives? Is the
evaluation of probability (or weight) separable from
the evaluation of outcome value? Furthermore, this
review is not exhaustive of the theories and approaches
in decision research. For example, an entire class of
random utility theories82 is beyond the scope of this
review, as are some of the more recent computational
models. A ‘dual systems’ approach recognizing the
role of automatic or intuitive processes, in addition
to more directed and deliberative processes, is also
becoming quite popular83–85 (see Ref 86 and the
related commentaries for various perspectives; and
Ref 87, for the historical precedent in cognitive
science). Finally, the field has relatively recently
focused a great deal on understanding the role of
affect or emotion in decision making35,88–90 (see Ref
91, for an earlier treatment).
An important recent development in decision
research is the advent of neuroscientific methods
to better understand decision making under risk
and uncertainty (see Ref 92, for a concise review
and organizing framework; for more extensive
summative treatment, see Refs 93,94). In fact, this has
spawned an entire ‘subfield’ called neuroeconomics
or decision neuroscience that attempts to verify

 2010 Jo h n Wiley & So n s, L td.

745

<-----Page 10----->Advanced Review

wires.wiley.com/cogsci

the underlying neural substrates associated with the
various components of decision theories and their purported mechanisms.95 Work in this vein has indeed
found evidence for brain regions responsible for representing the components of utility theories such as
probability and reward value96 (see Ref 97, for a discussion), as well as evidence for distinctions between
gains and losses consistent with prospect theory.98
Although this work supports the necessary condition
of an adequate neural representation underlying utility
theories, it is not sufficient evidence for the maximization goal process. That is, there is evidence for the
ingredients of utility theories, but not necessarily for
the mechanism that uses this information to produce
choice (action selection).
There is now substantial neurophysiological evidence supporting the mechanisms hypothesized by
computational accumulation models such as DFT
and leaky competing accumulator (LCA) (see Refs
99,100, for reviews). Specifically, recent research indicates that neuronal activation accumulates over time
during decisions under risk and uncertainty, and an
action is performed when the accumulated evidence
surpasses a threshold.94,101,102 Thus, in contrast to
the normative and descriptive utility maximization
theories, there is considerable neuroscientific evidence

for neuronal populations that may be responsible for
the computational process that produces observable
decision behavior.
In closing, we would like to convey the excitement and opportunity that face the field of decision
making. Current advances are beginning to produce
fruitful practical results. For example, prospect theory
has impacted economic theory, and computational
models (heuristic rule-based models and dynamic
accumulation models) are being incorporated into
engineering and agent-based models of mixed human
and machine systems. The number and nature of
tools at our disposal continue to grow (including
experimental techniques for process tracing; see Refs
45,46,103), as does the number and nature of fields
involved in studying decisions. As they do, we hope to
better understand how people make decisions, predict
what decisions might be made in given situations, and
reflect and improve upon those already made.

NOTES
a Note

that this model is closely related to the earlier
lexicographic models of Coombs104 and Fishburn.105
These models, however, specified a deterministic order
for attribute selection.

REFERENCES
1. Goldstein WM, Weber EU. Content and discontent:
Indications and implications of domain specificity in
preferential decision making. In: Busemeyer JR, Hastie
R, Medin DL, eds. Decision Making from a Cognitive
Perspective. The Psychology of Learning and Motivation, vol. 32. New York: Academic Press; 1995,
83–136.
2. Zsambok CE, Klein GA, eds. Naturalistic Decision
Making. Mahwah, NJ: Lawrence Erlbaum Associates;
1997.
3. Bernoulli D. Specimen theorie novae de mensura sortis
[Exposition of a new theory of the measurement of
risk]. Econometrica 1738/1954, 22:23–36.
4. Savage LJ. The Foundations of Statistics. New York:
John Wiley & Sons; 1954.
5. von Neumann J, Morgenstern O. Theory of Games and
Economic Behavior. Princeton, NJ: Princeton University Press; 1944.
6. Ramsey, FP. Truth and probability. The Foundations
of Mathematics and other Logical Essays: Routledge &
Kegan Paul; 1931.

746

7. de Finetti B. Foresight: its logical laws, its subjective
sources. In: Kyburg H, Smokler H, eds. Studies in Subjective Probability: New York: John Wiley & Sons;
1937/1964.
8. Allais M. Le comportement de l’homme rationnel
devant le risque: critique des postulats et axiomes de
l’école AmØricaine [The behavior of the rational man
facing risk: Critique of the postulates and axioms of the
American school]. Econometrica 1953, 21:503–546.
9. Keeney RL, Raiffa H. Decisions with multiple objectives: Preferences and value tradeoffs. New York: John
Wiley & Sons; 1976.
10. Kahneman D, Tversky A. Prospect theory: an analysis of decision under risk. Econometrica 1979,
47:263–292.
11. Markowitz HM. Portfolio Selection. New York: John
Wiley & Sons; 1959.
12. Edwards W. Subjective probabilities inferred from decisions. Psychol Rev 1962, 69:109–135.
13. Gonzalez R, Wu G. On the shape of the probability
weighting function. Cognit Psychol 1999, 38:129–166.

 2010 Jo h n Wiley & So n s, L td.

Vo lu me 1, September/Octo ber 2010

<-----Page 11----->WIREs Cognitive Science

Decision making

14. Brandstätter E, Kühberger A, Schneider F. A cognitiveemotional account of the shape of the probability
weighting function. J Behav Decision Making 2002,
15:79–100.
15. Dougherty MRP, Gettys CF, Ogden EE. MINERVADM: a memory process model for judgments of likelihood. Psychol Rev 1999, 106:108–209.
16. Johnson JG, Busemeyer JR. Process weighting model.
Unpublished manuscript [under review], 2009.
17. Fox CR, Tversky A. A belief-based account of decision
under uncertainty. Manage Sci 1998, 44:879–895.
18. Fox CR. Strength of evidence, judged probability,
and choice under uncertainty. Cognit Psychol 1999,
38:167–189.
19. Tversky A, Fox CR. Weighing risk and uncertainty.
Psychol Rev 1995, 102:269–283.
20. Quiggin J. A theory of anticipated utility. J Econ Behav
Org 1982, 3:323–343.
21. Yaari ME. The dual theory of choice under risk. Econometrica 1987, 55:95–115.
22. Starmer C. Developments in non-expected utility theory: the hunt for a descriptive theory of choice under
risk. J Econ Lit 2000, 38:332–382.
23. Birnbaum MH, McIntosh WR. Violations of branch
independence in choices between gambles. Organ
Behav Hum Dec 1996, 67:91–110.
24. Luce, RD. Utility of Gains and Losses: Mahwah, NJ:
Lawrence Erlbaum Associates; 2000.
25. Tversky A, Kahneman D. Advances in prospect theory: cumulative representations of uncertainty. J Risk
Uncertain 1992, 5:297–323.
26. Birnbaum MH. New paradoxes of risky decision making. Psychol Rev 2008, 115:463–501.
27. Birnbaum MH, Navarette JB. Testing descriptive utility
theories: violations of stochastic dominance and cumulative independence. J Risk Uncertain 1998, 17:49–78.
28. Birnbaum MH, Chavez A. Tests of theories of decision
making: violations of branch independence and distribution independence. Organ Behav Hum Decis Process
1997, 71:161–194.
29. Birnbaum MH, Sutton SE. Scale convergence and utility
measurement. Organ Behav Hum Decis Process 1992,
52:183–215.
30. Birnbaum MH, Stegner SE. Source credibility in social
judgment: bias, expertise, and the judge’s point of view.
J Pers Soc Psychol 1979, 37:48–74.
31. Birnbaum MH, Parducci A, Gifford RK. Contextual
effects in information integration. J Exp Psychol 1971,
88:158–170.
32. Bell DE. Regret in decision making under uncertainty.
Oper Res 1982, 30:961–981.
33. Loomes G, Sugden R. Regret theory: an alternative theory of rational choice under uncertainty. Econ J Nepal
1982, 92:805–824.

Vo lu me 1, September/Octo ber 2010

34. Epstude K, Roese NJ. The functional theory of
counterfactual thinking. Pers Soc Psychol Rev 2008,
12:168–192.
35. Mellers BA, Schwartz A, Ho K, Ritov I. Decision affect
theory: emotional reactions to the outcomes of risky
options. Psychol Sci 1997, 8:423–429.
36. Lopes LL. Between hope and fear: the psychology of
risk. Adv Exp Soc Psychol 1987, 20:255–295.
37. Lopes LL. Algebra and process in the modeling of risky
choice. In: Busemeyer J, Hastie R, Medin DL, eds. Decision Making from a Cognitive Perspective. San Diego,
CA: Academic Press; 1995, 177–220.
38. Busemeyer JR, Johnson JG. Computational models of
decision making. In: Kohler DJ, Harvey N, eds. Blackwell Handbook of Judgment and Decision Making.
Oxford: Blackwell Science; 2004, 133–154.
39. Shah AK, Oppenheimer DM. Heuristics made easy:
an effort-reduction framework. Psychol Bull 2008,
134:207–222.
40. Tversky A. Elimination by aspects: a theory of choice.
Psychol Rev 1972, 79:281–299.
41. Rieskamp J, Busemeyer JR, Mellers BA. Extending the
bounds of rationality: evidence and theories of preferential choice. J Econ Lit 2006, 44:631–661.
42. Thorngate W. Efficient decision heuristics. Behav Sci
1980, 25:219–225.
43. Coombs C, Dawes R, Tversky A. Mathematical Psychology. Englewood Cliffs, NJ: Prentice Hall; 1970.
44. Dawes RH, Corrigan B. Linear models in decision
making. Psychol Bull 1974, 81:95–106.
45. Payne JW, Bettman JR, Johnson EJ. Behavioral decision
research: a constructive processing perspective. Annu
Rev Psychol 1992, 43:87–131.
46. Payne JW, Bettman JR, Johnson EJ. The Adaptive Decision Maker. New York: Cambridge University Press;
1993.
47. Gigerenzer G, Todd PM, the ABC Research Group.
Simple Heuristics that make us Smart. New York:
Oxford University Press; 1999.
48. Brandstätter E, Gigerenzer G, Hertwig R. Risky
choice with heuristics: Reply to Birnbaum (2008),
Johnson, Schulte-Mecklenbeck, and Willemsen (2008),
and Rieger and Wang (2008). Psychol Rev 2008,
115:281–290.
49. Ratcliff R, Smith PL. A comparison of sequential sampling models for two-choice reaction time. Psychol Rev
2004, 111:333–367.
50. Busemeyer JR, Townsend JT. Decision field theory:
a dynamic-cognitive approach to decision making
in an uncertain environment. Psychol Rev 1993,
100:432–459.

 2010 Jo h n Wiley & So n s, L td.

747

<-----Page 12----->Advanced Review

wires.wiley.com/cogsci

51. Roe RM, Busemeyer JR, Townsend JT. Multialternative decision field theory: a dynamic connectionist model of decision-making. Psychol Rev 2001,
108:370–392.
52. Busemeyer JR, Diederich A. Survey of decision field
theory. Math Soc Sci 2002, 43:345–370.
53. Busemeyer JR, Johnson JG. Micro-process models of
decision making. In: Sun R, ed. Cambridge Handbook of Computational Psychology. Cambridge, MA:
Cambridge University Press; 2008, 302–321.
54. Busemeye JR, Jessup RK, Johnson JG. Townsend
JTBuilding bridges between neural models and complex
human decision making behavior. Neural Networks
2006, 19:1047–1058.
55. Diederich A. Dynamic stochastic models for decision
making under time constraints. J Math Psychol 1997,
41:260–274.
56. Johnson JG, Busemeyer JR. A dynamic, stochastic, computational model of preference reversal phenomena.
Psychol Rev 2005, 112:841–861.
57. Pleskac TJ, Busemeyer JR. Two-Stage Dynamic Signal
Detection: A theory of confidence, choice, and response
time. Psychological Review, 2009 In press.
58. Diederich A. MDFT account of decision making under
time pressure. Psychon Bull Rev 2003, 10:157–166.
59. Johnson JG, Busemeyer JR. Rule-based Decision Field
Theory: a dynamic computational model of transitions among decision-making strategies. In: Betsch T,
Haberstroh S, eds. The Routines of Decision Making.
Mahwah, NJ: Lawrence Erlbaum Associates; 2005,
3–20.
60. Gao G, Lee JD. Extending the decision field theory to
model operator’s reliance on automation in supervisory
control systems. IEEE Trans Syst Man Cybern 2006,
36:943–959.
61. Lee S, Son Y, Jin J. Integrated human decision making
and planning model for evacuation scenarios under BDI
framework. ACM Trans Model Comput Simulation
(in press).
62. Usher M, McClelland JL. Loss aversion and inhibition
in dynamic models of multi-alternative choice. Psychol
Rev 2004, 111:757–769.
63. Busemeyer JR, Townsend JT, Diederich A, Barkan R.
Contrast effects or loss aversion? Comment on M.
Usher, J. L. McClelland’s. (2004). ‘Loss aversion and
inhibition in dynamical models of multi-alternative
choice.’ Psychol Rev 2005, 112:253–255.
64. Thagard P, Millgram E. Inference to the best plan:
a coherence theory of decision. In: Ram A, Leake
DB, eds. Goal-driven Learning. Cambridge, MA: MIT
Press; 1995, 439–454.
65. Guo FY, Holyoak KJ. Understanding similarity in
choice behavior: A connectionist model. In: Gray W,
Schunn C, eds. Proceedings of the Twenty-Fourth
Annual Conference of the Cognitive Science Society.

748

Hillsdale, NJ: Lawrence Erlbaum Associates; 2002,
393–398.
66. Holyoak KJ, Simon D. Bidirectional reasoning in decision making by constraint satisfaction. J Exp Psychol
Gen 1999, 128:3–31.
67. Simon D, Krawczyk DC, Holyoak KJ. Construction
of preferences by constraint satisfaction. Psychol Sci
2004, 15:331–336.
68. Glöckner A, Betsch T. Modeling option and strategy choices with connectionist networks: towards an
integrative model of automatic and deliberate decision
making. Judgm Decis Mak 2008, 3:215–228.
69. Glöckner A, Betsch T, Schindler N. Coherence shifts in
probabilistic inference tasks. J Behav Decision Making
(in press).
70. Montgomery H. From cognition to action: the search
for dominance in decision making. In: Montgomery H,
Svenson O, eds. Process and Structure in Human Decision Making. New York: John Wiley & Sons; 1989,
23–49.
71. Svenson O. Differentiation and consolidation theory of
human decision making: a frame of reference for the
study of pre- and post-decision processes. Acta Psychol
(Amst) 1992, 80:143–168.
72. Hastie R, Park B. The relationship between memory and
judgment depends on whether the judgment is memorybased or on-line. Psychol Rev 1986, 93:258–268.
73. Weber EU, Goldstein WM, Barlas S. And let us not
forget memory: the role of memory processes and
techniques in judgment and choice. In: Busemeyer JR,
Hastie R, Medin DL, eds. Decision Making from the
Perspective of Cognitive Psychology. Psychology of
Learning and Motivation Series. New York: Academic
Press; 1995.
74. Goldstein DG, Gigerenzer G. Models of ecological
rationality: the recognition heuristic. Psychol Rev 2002,
109:75–90.
75. Tversky A, Kahneman D. Extension versus intuititve
reasoning: the conjunction fallacy in probability judgment. Psychol Rev 1983, 90:293–315.
76. Weber EU, Johnson EJ. Constructing preferences from
memories. In: Lichtenstein S, Slovic P, eds. The Construction of New York, NY: Cambridge University
Press. 2006, 397–410.
77. Johnson EJ, Haubl G, Keinan A. Aspects of endowment: a query theory of value construction. J Exp
Psychol Learn Mem Cogn 2007, 33:461–474.
78. Myung IJ. The importance of complexity in model
selection. J Math Psychol 2000, 44:190–204.
79. Pitt MA, Myung IJ. When a good fit can be bad. Trends
Cogn Sci 2002, 6:421–425.
80. Roberts S, Pashler H. How persuasive is a good fit?
A comment on theory testing. Psychol Rev 2000,
107:358–367.

 2010 Jo h n Wiley & So n s, L td.

Vo lu me 1, September/Octo ber 2010

<-----Page 13----->WIREs Cognitive Science

Decision making

81. Hastie R. Problems for judgment and decision making.
Annu Rev Psychol 2001, 52:653–683.
82. McFadden D. Econometric Models of Probabilistic
Choice. In: Manski C and McFadden D, eds. Structural
Analysis of Discrete Data with Econometric Applications. Cambridge: MIT Press; 1981.
83. Sloman SA. The empirical case for two systems of
reasoning. Psychol Bull 1996, 119:3–22.
84. Sloman SA. Two systems of reasoning. In: Gilovich T,
Griffin D, Kahneman D, eds. Heuristics and Biases: The
Psychology of Intuitive Judgment. Cambridge: Cambridge University Press; 2002.
85. Kahneman D, Frederick S. Representativeness revisited: Attribute substitution in intuitive judgment. In:
Gilovich T, Griffin D, Kahneman D, eds. Heuristics
and Biases: The Psychology of Intuitive Judgment. New
York: Cambridge University Press; 2002, 49–81.
86. Stanovich KE, West RF. Individual differences in reasoning: implications for the rationality debate? Behav
Brain Sci 2000, 23:645–665.
87. Shiffrin RM, Schneider W. Controlled and automatic
human information processing: II. Perceptual learning,
automatic attending, and a general theory. Psychol Rev
1977, 84:127–190.
88. Bechara A, Damasio H, Damasio AR. Emotion, decision making, and the orbitofrontal cortex. Cereb Cortex 2000, 10:295–307.
89. Damasio AR. Descartes’ Error: Emotion, Reason, and
the Human Brain. New York: Grosset/Putnam; 1994.
90. Lowenstein G, Lerner J. The role of emotion in decision
making. In: Davidson RJ, Goldsmith HH, Scherer KR,
eds. Handbook of Affective Science. Oxford: Oxford
University Press; 2003.
91. Zajonc RB. Feeling and thinking: preferences need no
inferences. Am Psychol 1980, 35:151–175.
92. Rangel A, Camerer C, Montague PR. A framework
for studying the neurobiology of value-based decisionmaking. Nat Rev Neurosci 2008, 9:545–556.

93. Camerer C, Lowenstein G, Prelec D. Neuroeconomics:
How neuroscience can inform economics. J Econ Lit
2005, 43:9–64.
94. Gold JI, Shadlen MN. Representation of a perceptual
decision in developing oculomotor commands. Nature
2000, 404:390–394.
95. Sanfey AG, Loewenstein G, McClure SM, Cohen
JD. Neuroeconomics: cross-currents in research on
decision-making. Trends Cogn Sci 2006, 10:108–116.
96. Platt ML, Glimcher PW. Neural correlates of decision variables in parietal cortex. Nature 1999,
400:233–238.
97. Sanfey AG. Neural computations of decision utility.
Trends Cogn Sci 2004, 8:519–521.
98. Tom S, Fox CR, Trepel C, Poldrack RA. The neural
basis of loss aversion in decision making under risk.
Science 2007, 315:515–518.
99. Schall JD. Neural basis of deciding, choosing and acting. Nat Rev Neurosci 2001, 2:33–42.
100. Smith PL, Ratcliff R. Psychology and neurobiology of
simple decisions. Trends Neurosci 2004, 27:161–168.
101. Ratcliff R, Cherian A, Segraves M. A comparison of
macaque behavior and superior colliculus neuronal
activity to predictions from models of simple twochoice decisions. J Neurophysiol 2003, 90:1392–1407.
102. Schall JD. Neural correlates of decision processes: eural
and mental chronometry. Curr Opin Neurobiol 2003,
13:182–186.
103. Svenson O. Decision making and the search for fundamental psychological regularities: What can be learned
from a process perspective? Organ Behav Hum Decis
Process 1996, 65:252–267.
104. Coombs CH. A Theory of Data. New York, NY: Wiley;
1964.
105. Fishburn PC. Utility theory. Management Science 1968,
14:335–378.

FURTHER READING
Brandstätter E., Gigerenzer G, Hertwig R. The priority heuristic: making choices without trade-offs. Psychol
Rev 2006, 113:409–432.
Busemeyer JR, Jessup RK, Johnson JG, Townsend JT. Building bridges between neural models and complex
decision making behavior. Neural Netw 2006, 19:1047–1058.
Gold JI, Shadlen MN. The neural basis of decision making. Annu Rev Neurosci 2007, 30:535–574.
Koehler D, Harvey N, eds. Blackwell Handbook of Judgment and Decision Making. Oxford, UK: Blackwell
Science; 2004.
Lichtenstein S, Slovic P, eds. The Construction of Preference. New York: Cambridge University Press; 2006.

Vo lu me 1, September/Octo ber 2010

 2010 Jo h n Wiley & So n s, L td.

749

