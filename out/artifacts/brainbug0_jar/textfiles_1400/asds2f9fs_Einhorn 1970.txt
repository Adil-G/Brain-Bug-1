<-----Page 0----->Psychological Bulletin
1970, Vol. 73, No. 3, 221-230

THE USE OF NONLINEAR, NONCOMPENSATORY
MODELS IN DECISION MAKING1
HILLEL J. EINHORN "
Wayne State University
An important problem in decision making concerns finding the utility of a
multidimensional stimulus. This has traditionally been done by assuming that
total utility is a linear function of the attributes of the stimulus. In clinical
decision making, the linear regression model has been used to predict and
diagnose on the basis of multidimensional information as well as to approximate the clinician's own judgment. Other nonlinear, noncompensatory
models are available for combining information. These models, called conjunctive and disjunctive, are approximated here by suitable nonlinear functions of utility. They are then shown to give a better fit to certain decision
data than the linear model. The factors affecting the use of these models and
their implications are discussed.

One of the main problems in decision making has been the attempt to understand how
individuals assess the utility of each of a set
of stimulus objects when each stimulus can be
evaluated in terms of a set of multidimensional
attributes. Subjectively, this becomes a problem of weighting the various attributes making up the stimuli and then combining them
in some way to arrive at an overall value for
the stimulus. Typically, it has been assumed
that the utility of an object is a linear combination of the utilities of the various attributes making up that object. As Edwards
and Tversky (1967) have pointed out,
One idea so completely dominates the literature on
riskless choice that it has no competitors. It is the
additive composition notion. It asserts that the
utility of a multidimensional alternative, such as a
commodity bundle or a job offer, equals the sum of
the utilities of its components. The essence of this
model is that the various components of a multidimensional object contribute independently to its
overall worth or utility. This notion is closely re1
This paper is based on the first two chapters of
the author's dissertation, submitted in partial fulfillment of the requirements for the doctoral degree
at Wayne State University. The author would like to
thank his dissertation chairman and adviser, Dr.
Alan R. Bass for his continual help and assistance.
The help of the other committee members, Drs. Joel
Ager, Roger Simon, and Samuel Komorita is also
gratefully acknowledged.
2
Now at the University of Chicago, Graduate
School of Business.
Requests for reprints should be addressed to Hillel
J. Einhorn, University of Chicago, Graduate School
of Business, Chicago Illinois 60637.

lated to the lack of interaction in the analysis of
variance [p. 2551.

In an excellent review of the literature on
individual choice behavior in selecting among
multidimensional stimulus objects, Shepard
(1964) has said that although psychologists
have tried various methods of combining the
attributes of multidimensional stimuli, experimental results are usually averaged over
judges and/or trials. When averaging over
judges, it becomes necessary to take into account the cognitive activity that goes into the
judge's decision process. It is to be expected
that individual differences will play a large
part in any decision problem. By averaging
over judges, one may be losing these important
individual data. If one does not average over
judges, but instead considers each judge individually, then one is faced with considerable
variability of the decision process and a lack
of generality in terms of the kinds of methods
judges use to arrive at their decisions. However, one need not be concerned with these
problems if the judge can be made to perform
his decision many times, over somewhat comparable decision cases. Churchman (1961)
has argued that the values of the decision
maker can be inferred from his decisions over
a sufficiently large number of circumstances.
It is certainly an empirical question as to
whether different judges use different methods to arrive at their decisions.
In dealing with decision problems, the
linear regression model has usually been used

221

<-----Page 1----->222

HILLEL J. EINHORN

to predict actual decisions from component
cues. This model is additive and extremely
powerful. As Yntema and Torgerson (1961)
have shown, the linear model provides an excellent approximation to data even when
there are interactions or nonlinear relationships in the data. In analysis of variance
terms, this means that the amount of variation that the interactions account for are relatively small as compared to the main effects.
The linear model (or some variant) has
been used in many areas of psychology involving judgmental process. Anderson (1968),
for example, has summarized much of the
work he has done on the integration of information in impression and attitude formation. He has postulated an "averaging model"
of information combination which is a variant
of the general linear model. Anderson's work
has shown that his model is adequate for
representing the judgmental process involved
in impression and attitude formation. However, like other researchers in this area, he
feels that a linear model is somehow unrepresentative of how the cognitive process works.
For example, he states,
The model always fits the data quite well, but there
are almost always small, significant discrepancies. Inspection of the data has failed to reveal the origin of
the discrepancies; they may reflect some fundamental
error in the model, or they may result from remaining shortcomings in the experimental technique [p.
736],

In addition, he has said that when stimuli are
heterogeneous and contain different kinds of
information, the simple model may not be
adequate to handle the data.
In the clinical judgment area, many researchers have been concerned with the use
of interactions by the clinician in arriving at
his diagnosis. It has been claimed that the
clinician is superior to the actuary because he
can take into account complex interactions
and patterns which the actuary cannot do. It
is, of course, not true that actuarial methods
cannot handle complexities in the data. However, Yntema and Torgerson (1961) have suggested that when there are many variables to
process, the human information processor may
have to simplify the situation in order to
deal with it. They suggest that one way of
doing this may be to ignore interactions and

focus only on main effects. This is certainly
not consistent with the claims of the clinician's ability to handle complex relationships.
Meehl (1954, 1956), has shown that the
clinician's claims are without foundation. In
comparing studies using both clinical and
actuarial prediction methods, the actuarial
was clearly superior. A recent study by Sawyer
(1966) confirms the earlier findings of Meehl.
In addition, it has been found by numerous
investigators (e.g., Hoffman, 1960; Hoffman,
Slovic, & Rorer, 1968), that the clinician's
own judgment can be approximated very well
by using a linear compensatory model such
as multiple regression. By asking the clinician
to make a series of judgments over a wide
number of similar stimuli, one can correlate
his judgments of the stimuli with the various
attributes of the multidimensional stimuli. In
research of this type, interactions among the
attributes have been found to account for
little of the variance of clinical judgments,
thereby seriously questioning the assertion
that the clinician is using complex patterns or
interactions in his judgmental process. However, as Hoffman (1960) has pointed out, the
fitting of any mathematical model to cognitive functioning is at best a "paramorphic"
process. That is, even if a model is highly accurate in describing the judgmental process, it
does not necessarily mean that the process
has actually worked in exactly the way the
model has specified. Different models may be
equally powerful with respect to describing
the process. It therefore seems that accurately
describing the process is at least necessary
although not sufficient for describing the underlying cognitive processes.
The problem of nonlinearity and the clinical inferential process has been extensively
investigated by Hammond and his associates
(Hammond, 1955; Hammond, Hursch, &
Todd, 1964; Hammond & Summers, 1965;
Hursch, Hammond, & Hursch, 1964). Using
Brunswik's (1952) lens model as the theoretical model for their research, they have investigated the use of nonlinearity from both
sides of the lens, that is, from the point of
view of ecological validity as well as the
utilization of cues. In dealing with this problem, they have defined an index C which is
the correlation between the variance unac-

<-----Page 2----->MODELS IN DECISION

counted for by multiple correlation in the
ecology and the variance unaccounted for by
the multiple correlation in the subjects' response system. This index can take on values
between +1.00 and â€”1.00. However, this index is a general measure of nonlinearity and
does not specify exactly what the particular
nonlinear function is that is being used. In addition, problems in interpretation can arise
if C - 0.00. This results because C = 0.00
can occur for a variety of reasons such as the
nonlinearity used by the subject in combining cues does not match the nonlinearity involved in the ecological validity between distal
stimulus and cues at the lens; or, the variance
that is left after one takes out the linear effect (as shown by the multiple correlation),
is random error variance and not variance
due to nonlinearity. There is no way of knowing which interpretation is correct.
In a study by Hammond and Summers
(1965), the authors concluded that most of
the previous research shows the linear model
to provide a sufficiently good fit so as to suggest that judges combine cues in a linear
fashion. They also show that the use of a
linear model occurs even when there are significant nonlinear relationships in the ecological part of the lens (however, subjects do
use nonlinear relationships if they are given
information about their being in the task).
In looking for nonlinear methods for combining cues, the comparison of the linear
model with specific nonlinear models is notably absent from the literature. One such experiment was carried out by Wiggins and
Hoffman (1968). They compared two nonlinear models with the linear model in a task
involving the diagnosis of "neurotic" versus
"psychotic" on the basis of 11 scales from
the MMPI. The two nonlinear models were
the "quadratic" model, which consisted of
squares and products of the original set of
predictors added to the original set, and a
"sign" model which consisted of signs that
were rationally chosen, on the basis of expert
judgment from clinicians, to be related to
the criterion. This latter model could consist
of both simple and complex terms. The results for this experiment showed that some
judges were using configural methods of combination. However, as the authors point out,

MAKING

223

the magnitude of the differences between the
fit for the linear and configural models was
not large. In addition, even the most configural judges could be fairly well estimated
by a linear model.
OTHER COMBINATION MODELS
Although the linear compensatory model
has been used almost exclusively in dealing
with judgmental processes, it is not the only
combination model available. Coombs and Kao
(1955), Coombs (1964), and Dawes (1964a,
1964b) have specified additional models for
combining or using data. Three of these have
been called the conjunctive, disjunctive, and
lexicographic models. In dealing with these
models, Dawes (1964b) has called the function resulting from attaching of utility or
worth to a multiattribute stimulus an evaluation function. A person can be thought of as a
multiattribute vector with the components
being the separate attributes, that is, X =
(Xi,X2, . . . ,Xn).

Given this formulation, the conjunctive
model says that whether an individual surpasses some stimulus or standard F = (y-i, y%,
. . . , yn) will depend on xt being greater than
ji for all *'. Dawes has called this a minimum
evaluation function since the individual is
evaluated on his minimum ability. The implication of the conjunctive model is that a
person must have a certain minimum ability
on all the attributes. This implies a multiple
cutoff procedure rather than a linear compensatory procedure.
The disjunctive model is called the maximum evaluation function since the person is
judged on his best ability regardless of his
other attributes. If E(X) is the evaluation
function of X and E(F) is the evaluation
function of some standard F, then E(X) >
E(F) if one xt > yt regardless of yj> Xj
where i ^= j. In selecting players for a football
team, for example, we might want someone
who can kick or run or pass with a great deal
of skill. Each person is selected on his best
ability regardless of his other attributes.
The third model is the lexicographic. In
this model, the attributes are first ordered in
importance and a decision is made on the
basis of the most important variable before
proceeding to the next ordered variable. One

<-----Page 3----->224

HILLEL J. E1NHORN

only uses the next ordered variable if there is
equivalence on the preceding ordered variable. The lexicographic model has not been
dealt with mathematically as Debreu (1954)
has stated that this model cannot be given
explicit mathematical representation. For this
reason, it will not be dealt with here.
Dawes has defined the conjunctive, disjunctive, and compensatory models in terms
of a one-parameter function by assuming a
general evaluation function.

When r = 1 the function becomes compensatory. When r approaches + oo Dawes has
shown that V(X) becomes a maximum function and therefore the disjunctive model. When
r approaches â€” oo the function becomes a
minimum function and hence the conjunctive
model. For r greater than or equal to 1 the
function is the Minkowski distance from the
origin of a coordinate vector space to the
point X.
Dawes' formulation assumes that the various X{ of the vector X can be evaluated in
comparable scale units so that one can say
which of a number of attributes is either the
maximum or minimum. In addition, it is assumed that the evaluation function is objective although it is to be expected that different judges may evaluate the same stimulus
object differently. Judges may also be expected
to weight the xt's differentially. The value
of Dawes' formulation is to provide a general
framework for the various models although
the specific functions needed to represent
each of the models has yet to be worked out.
OBJECTIVES
The present paper has as its objectives
(a) the formulation of a theoretical model
based on utility assumptions to approximate
both the conjunctive and disjunctive models,
and (b) the comparison of these models with
the linear model in a decision task to see
which provides for a better fit of the data.
Tn addition, factors which affect decision making will be discussed after the presentation of
the models and data.

Formulation of the Model
A study was done in which four judges
were given a list of hypothetical applicants
for graduate school. The only information
each of the judges had was the percentile
score of the applicant on the three parts of
the Graduate Record Examination (GRE).
These subscales involve verbal aptitude, quantitative aptitude, and knowledge of psychology. There was a total of 20 hypothetical applicants. Each of the judges was asked to
rank order the applicants according to their
acceptability into the graduate program. Once
this was done, the judgments were used as
the criterion and a multiple regression procedure was used with the three scores on the
GRE as the predictors and the rankings as
the criterion. The actual scores used for the
hypothetical candidates were not chosen at
random but were selected by the experimenter
beforehand. The reason for this will be discussed later.
After the multiple correlation was obtained,
the regression weights were applied to a new
sample of 20 hypothetical applicants in order
to get a predicted rank ordering for the
judge. The judge was then asked to rank
order the new sample of applicants and his
actual ranking was correlated with the predicted ranking by means of the Spearman
rank-order correlation coefficient. The actual
rankings on the second sample were also used
as the criterion for the predictions made from
the conjunctive and disjunctive models. The
predicted rankings using these other models
were also correlated with the actual rankings
and the resulting correlations were compared.
The method will be illustrated shortly.
The problem of finding suitable functions
to approximate the disjunctive and conjunctive models is now considered. According to
Edwards (1954), one of the most important
assumptions in the theory of choice is that
choices are made to maximize something. The
maximization is usually thought of in terms
of utility. Using only two of the variables
(quantitative and verbal aptitude), it was
decided to hypothesize different response surfaces to approximate these models. These surfaces are in a three-dimensional space with
the two horizontal axes representing the

<-----Page 4----->MODELS IN DECISION

scores on each of the variables and a third
vertical axis representing the utility of the
scores, both separately and in combination,
for the particular judge.
For the disjunctive model it was hypothesized that a hyperbolic response surface would
approximate this model. The reasons for this
are as follows: On each of the variables, for
some judges, the scores at the low end of the
scale would make relatively little difference in
utility for selection. In other words, the difference between scores at the 10, 20, 30, 40, and
SO percentile points are not very large. The
judge does not discriminate between scores at
that level. On the other hand, differences between scores at the high end of the scale were
hypothesized to show greater differences in
utility for the judge. Mathematically, the
slope of the function relating to utility had to
be monotonically increasing. A hyperbolic
function fits this description and also has the
property of a rapid increase in slope as one
approaches the asymptote that make it ideal
for the disjunctive case. The general formula
used for the surface is,
tf= (!/Â«,- X). (I/a,-7)

[2]

where U = utility or height of the response
surface, X, Y = variables, 0Â« = some value
above the asymptotic level, that is, at > Xmax
and Ymax.
Figure 1 represents the hyperbolic surface
geometrically.
The constant a is arbitrarily set above the
highest X and Y score so that U will not be
infinite. For any score XtYj there is a coordinate point in plane XYO. The function
gives the height on the utility axis at any
point. For values of X and Y that result in
point P, for example, the predicted utility
score is at point Q. The actual value is not
important since a rank ordering on the U axis
for any pair of values of X and Y is wanted.
In this formulation of the function it is assumed that the variables have been weighted
equally. By introducing two parameters into
the equation it is possible to weight the
variables differentially.
U = (l/al-Xr-(l/ai-Y)'

[3]

The parameters b and c represent weighting

225

MAKING

FIG. 1. Hyperbolic response surface.

factors for the two variables. Values for them
can be obtained by using a log transformation and finding values for b and c that satisfy
the least-squares criterion. This can be done
by using a multiple regression procedure on
the transformed variables. This procedure has
been used by Komorita (1964). The function
then becomes,
log U = - b log (ai - X)

- c log (a, - Y) [4]
How does this surface approximate the disjunctive model? If one looks at point // in
the coordinate plane XYO, one finds that the
utility of the score that corresponds to that
point is high even though that person has a
very low score on the Y variable. This is because his high score on the X variable places
him on the back edge of the surface which has
a large height and therefore a high utility on
the U axis. In other words, a person will have
a high utility if he has either outstanding
ability on X or Y. This is then a case of
disjunctive selection. A decision maker, using
this model, will tend to rank highly not only
those who are high on both attributes, but
also those who are extremely high on only one
of the attributes.
Data will be presented to show how judges
actually used the disjunctive rather than the
compensatory model in making their decisions.
For Judge 1, the multiple correlation between

<-----Page 5----->226

HILLEL J. EINHORN

his rankings on the first sample and the three
predictors was .84. Using the regression
weights obtained on this sample, a predicted
ranking was obtained for the second sample.
From examination of the regression weights it
looked as if this judge was weighting quantitative scores about twice as heavily as the
verbal scores while there was little weight
attached to the psychology achievement score.
Using Equation 4 for the disjunctive formulation, a multiple correlation of .92 was obtained for the log transformed variables. The
values for the parameters showed that the
quantitative scores were being weighted twice
as heavily as the verbal scores. The second
sample was administered and the predicted
rank ordering from the linear model was
compared to the actual ranking. The correlation was .60 thereby shrinking, not unexpectedly, from the original .84. The predicted rank ordering using the hyperbolic
function correlated .92 with the actual rank
order on the new sample, thus showing no
shrinkage. The difference between these correlations for the two models is significant at
beyond the .01 level.
Some of the glaring errors in prediction
made by the linear model were picked up by
the disjunctive model. For example, the predicted rank for one of the hypothetical applicants with scores of 100 verbal, SO quantitative, and 10 psychology was 15. This is not
surprising since the weights of the first sam-

ple showed that the quantitative scores were
being weighted about twice as heavily as the
verbal scores. However, the actual ranking of
this person was 2. The disjunctive model predicted a rank of S for this person since his
high score on verbal placed him on the edge
of the response surface where the utility is
high regardless of the other score.
The second judge using the disjunctive
model was the author. His data are, of course,
not admissible but illustrate the method. The
author knowingly used a disjunctive model
weighting the variables of verbal and quantitative aptitude equally while ignoring the
psychology achievement scores. Using a value
for a= 110, the correlation of the predicted
and actual rankings on the cross-validated
sample using the linear model was .22 while
the correlation between the predicted and actual rankings using the disjunctive formulation was .93. This is again a highly significant
difference.
After finding a function to approximate the
disjunctive model, the next problem was to
approximate the conjunctive model. The formulation used here was,
U= (A')-(F)

[5]

Again, it is possible to add exponents to the
variables in order to get differential weights
so that the formulation becomes,
U=(Xr-(Y)Â»

[6]

or
log U = a log X + b log Y

FIG. 2. Parabolic response surface.

[7]

Figure 2 represents the conjunctive model
geometrically as a parabolic response surface.
Here we have a parabolic response surface
with scores Xt ~ Yt having the larger utility
than scores where there are wide discrepancies between X and Y. The height of the
surface is greatest along the line from the
origin to point L at the top of the surface.
For example, point P in the horizontal plane
has a utility at point Q on the U axis. This
utility is smaller than that for point H which
has a utility at point O on the U axis. This
is because the coordinates of point P consist
of one large value of X but a small value of
Y. On the other hand, point H has a moderate value for both variables. In this case

<-----Page 6----->227

MODELS IN DECISION MAKING

one cannot have a high utility if there is
lack of one ability. One cannot compensate
for this lack by high scores on the other
variable since the product of the two variables
is considered important.
This model seems to describe Judge 3.
Exactly the same procedure as was used in
the disjunctive case was used here, substituting the conjunctive formulation for the disjunctive to get the predicted rankings. The
predicted rankings were compared with the
actual rankings and the results showed a correlation of .82 for the linear regression model
on the new sample and a correlation of .94
for the conjunctive procedure. This difference
is significant at less than the .01 level due
to the high intercorrelation between the predicted rankings for the compensatory and
conjunctive models.
The data for Judge 4 raise some important
points. Using the linear model on the first
sample, a multiple correlation of .87 was obtained. This is in contrast to the multiple
correlation of .70 using the conjunctive formulation. However, on the cross-validation
sample, the predicted rankings and the actual
rankings for the linear model correlated .73
while for the conjunctive model the rank correlation was .70. This difference is not significant. What can one conclude about the
model Judge 4 was using? Since the correlations on the cross-validation sample are
fairly low for both models it might be said
that neither model fits the data very well.
A low correlation brings up an interesting
question of how to interpret the unexplained
variance of the judgments. As in the case of
Hammond and his associates, two possible explanations are available. One can treat the
unexplained variance as error resulting from
the judge making intransitive judgments, or
in changing strategies during the task, or
responding randomly to the stimuli. On the
other hand, one can view the unexplained
variance as being due to nonlinearity other
than the kinds we have proposed. Work by
Einhorn (1969), for example, has found that
judges do use complex strategies that involve
combinations of models. These strategies introduce a degree of nonlinearity not accounted for by the simple models proposed
here. In order to deal effectively with these

complex strategies, more complex equations
will be needed.
The formulation developed here for the
two-variable case can be extended to the N
variable case. For the conjunctive model,

For the disjunctive model the extension is,
= n (I/a* - *<)"
AT

1-1

i~Xl)

[9]

The method of testing for the significance
of the difference between correlated correlations is found in Hotelling (1940). This
procedure is used to test whether one variable correlates higher with a criterion than
another. In this study, the actual rankings are
the criterion and the different variables are
the predicted rankings obtained from the different models. The t test offered by Hotelling
was used here as an approximation since the
author knows of no statistical tests that deal
with the difference between correlated rankorder correlations.
Factors Affecting Decision Making
A number of issues are raised by these results. Perhaps the most important point concerns the large individual differences in the
processes by which individuals make decisions. Of the three judges used in this study
(the author is not included), each of the
judges used a different model to make his
decisions. If the data had somehow been
combined, the individual differences between
judges might have been lost. It might even
be that grouped data would show a linear
compensatory model while the individual data
do not. This is a problem for further study.
A second factor to consider is the distribution function of the actual numerical data.
An example of this is the range of scores included in the hypothetical cases presented to
the judge. Figure 3 illustrates this point for
both the data in this study and for grouped
learning data.

<-----Page 7----->228

HILLEL J. EINHORN

X

O

P

TIME

O

FIG. 3. Functions with truncated range.

In the first figure, if the range of X scores
were restricted to those below point 0, one
could not very well decide against a linear
fit since the range does not permit the whole
function to be used. Exactly the same thing
happens if we consider the typical learning
curve over time. Unless one allows enough
time for the curve to reach its asymptotic
value one might wrongly conclude that learning is a linear function of time (practice).
Another example of the importance of considering the actual range of data can be seen
in Figure 4 which compares decisions made
on the basis of a multiple cutoff procedure
with those made on the basis of a linear regression procedure.
The areas that are shaded are those in
which there is a difference between the models
in terms of the decisions made. These areas
involve extreme cases, but only by including
such cases can one distinguish between the
use of the models. The data used in this study
were in no way a random sample of scores
drawn from all possible combinations of X

FIG. 4. Comparison of conjunctive and compensatory
models.

and Y. These scores were picked so that there
would be those cases which would show a
difference in the use of the models if such
a difference existed. This point is extremely
important since it indicates that judges may
actually be responding to patterns of scores,
for example, although the linear model might
still provide a good fit. Both models are
"paramorphic" in Hoffman's sense of the term
and perhaps equally powerful in most practical situations. This may be caused by the
truncated range of the data in most studies.
Another important issue concerns the
method used to evaluate the stimulus objects.
In this study, the method of rank order was
used while many of the studies reviewed here
used ratings as the dependent variable. There
may be large differences in the cognitive use
of these different methods. Ranking involves
the comparison of each stimulus object with
every other while rating does not necessarily
imply a comparison procedure. When the
number of stimulus objects is large, ranking
becomes a difficult task while rating the objects may not be as affected by the number
of stimuli. If there are differences between
the two methods, these differences may affect
the use of the particular model used in evaluating the stimuli. It should also be mentioned
that the method of ranking is more clearly
related to theories of choice than rating
methods. Given n ranked stimuli, one can always specify any proportion of stimuli in
terms of a particular criteria (such as acceptreject; choose-not choose). For example, with
20 objects, if we were to select the best 2
from the 20, these 2 should have the rank
of one and two, respectively. For any given
proportion that we want to choose or select,
we can use the ranking to obtain the proportion desired.
A fourth consideration is the nature of the
scale of the data. In this study the data are
continuous while in many of the studies involving clinical judgment the data are categorical. It is possible that categorical data
are treated differently, in a cognitive sense,
from continuous data although this would be
difficult to show.
A fifth factor involves the dimensions of
the task that is being used as the decision
problem. The use of any of these models

<-----Page 8----->MODELS IN DECISION

cannot be predicted independently of the kind
of problem that is being used. Some decision
problems may be more likely to produce a
certain kind of solution than another. The
fact that the clinical inference literature has
shown the linear model to provide a good
fit to obtained data may be due, in part, to
the kind of task used. Einhorn (1969), for
example, in using a graduate-student selection and a job-preference task found large
differences in the relative use of the various
models. The latter task produced a great
amount of conjunctive-model use while the
graduate-selection task showed much less use
of this model. Such factors as the personal involvement of the decision maker, his motivation, and interest in the task, may all affect
the kind of strategy one might employ.
The number of variables the decision maker
has to deal with undoubtedly affects the kind
of strategy he employs. Sequential strategies
and complex models may be needed to deal
with cases of many variables. Yntema and
Torgerson (1961) see the introduction of
many variables as a handicap for the human
information processor. The simplification of
data is seen to be the way of handling complex data with the ignoring of interactions as
one method of simplification. In most of the
studies dealing with clinical inference processes, many variables have been included in
the task. It therefore seems that if interactions are being investigated the task should
be sufficiently simple to allow the decision
maker a chance to find them.
A seventh factor that affects the weighting
of the variables (although it is not known
if it affects the use of the different models)
is the correlation among the variables or attributes. Dudycha and Naylor (1966) have
shown that the correlation matrix affects the
way in which judges weight the different variables. Their conclusions are
If one is interested in obtaining information about
the judgmental policies of individuals toward a certain class of stimulus objects he needs to be certain
that the underlying cue R matrix for his experimental stimuli is representative of the R matrix
describing the population of stimuli of which the
sample is assumed to be a subset. Otherwise, his
ability to generalize is obviously going to be limited
[p. 602].

229

MAKING

Further complicating the findings of Dudycha and Naylor is a study by Chapman
(1967). He showed that subjects find it very
difficult not to associate certain cues with
other cues when they expect the cues to be
correlated. This occurs even when the cues
are presented in such a manner where there
is no objective correlation between them.
Chapman termed this phenomenon "illusory
correlation" since subjects "saw" relationships
where objectively there were none. This
finding has serious implications for learning
of clinical inferences since it may sometimes
be necessary to unlearn preconceived correlations between certain cues and start over
again. Generally, it would seem that "illusory
correlation" can be a powerful factor especially with regard to decision makers who
have some experience in dealing with a particular problem.
The context in which the decision is made
is another factor that can influence the decision process. Webster (1964) has shown
that in the interview situation, interviewers
will look for negative information on which
to disqualify a candidate. It seems as if they
were using a conjunctive model since selection is based on the applicant's minimum
ability. It is easy to see the reason for this
when the situation is analyzed. The interviewers receive all of the blame when they
make a mistake, that is, recommend someone who turns out badly, while they receive
no reward for making the correct decision.
Since the cost of a false positive is so high,
it seems that the rational approach for them
to take is to use a conjunctive model in selection.
CONCLUSION
There are many factors that affect decisionmaking. A few of these factors have been
enumerated here. Probably the most important point in dealing with judgmental data
is the large individual differences by which
decisions are made. If one can build a model
of individual behavior and at the same time
provide a theoretical classification of different "types," then one can combine an idiographic and nomothetic approach. The very
useful idea has been suggested by Brunswik
(1952). The theoretical utility model devel-

<-----Page 9----->230

HILLEL J. EINHORN

oped here to approximate the conjunctive and
disjunctive models provides for part of the
a priori classification scheme necessary to go
from a purely ipsative model of behavior to
some more general scheme.
Given the wide variety of individual differences as well as the large number of factors influencing the judgmental process, it
would seem unlikely that the models proposed
here (as well as the linear model) will prove
adequate for representing the full complexity
of the judgmental process. The questions to
be asked in future research should concern
the conditions, whether within the individual
or in the task, under which these models, or
more complex variations of them, will apply.
REFERENCES
ANDERSON, N. H. A simple model for information
integration. In R. P. Abelson, E. Aronson, W.
McGuire, T. Newcomb, M. J. Rosenberg, & P.
Tannenbaum (Eds.), Cognitive consistency: A
sourcebook. Chicago: Rand McNally, 1968.
BRUNSWIK, E. The conceptual framework of psychology. Chicago: University of Chicago Press,
1952.
CHAPMAN, L. J. Illusory correlation in observational
report. Journal of Verbal Learning and Verbal
Behavior, 1967, 6, 151-155.
CHURCHMAN, C. W. Prediction and optimal decision: Philosophical issues in a science of values.
Englewood Cliffs, New Jersey: Prentice Hall, 1961.
COOMBS, C. H. A theory of data. New York: Wiley,
1964.
COOMBS, C. H., & KAO, R. C. Nonmertic factor
analysis. (Research Bulletin No. 38) Ann Arbor:
University of Michigan Engineering Research Institute, 1955.
DAWES, R. M. Social selection based on multi-dimensional criteria. Journal of Abnormal and Social Psychology, 1964, 68, 104-109. (a)
DAWES, R. M. Toward a general framework for
evaluation. Ann Arbor: University of Michigan,
Department of Psychology, 1964. (b)
DEBREU, G. Representation of a preference ordering
by a numerical function. In R. M. Thrall, C. H.
Coombs, & R. L. Davis (Eds.), Decision processes.
New York: Wiley, 1954.
DUDYCHA, A. L., & NAYLOR, J. C. The effect of
variations in the cue R matrix upon the obtained
policy equation of judges. Educational and Psychological Measurement, 1966, 26, 583-603.

EDWARDS, W. The theory of decision making. Psychological Bulletin, 1954, 51, 380-417.
EDWARDS, W., & TVERSKY, A. (Eds.) Decision making. Baltimore: Penguin Books, 1967.
EINHORN, H. J. The use of nonlinear, noncompensatory models in decision making. Unpublished
doctoral dissertation, Wayne State University, 1969.
HAMMOND, K. R. Probabilistic functioning and the
clinical method. Psychological Review, 1955, 62,
255-262.
HAMMOND, K. R., HURSCH, C. J., & TODD, F. J.
Analyzing the components of clinical inference.
Psychological Review, 1964, 71, 438-456.
HAMMOND, K. R., & SUMMERS, D. A. Cognitive
dependence on linear and nonlinear cues. Psychological Review, 1965, 72, 215-224.
HOFFMAN, P. J. The paramorphic representation of
clinical judgment. Psychological Bulletin, I960,
57, 116-131.
HOFFMAN, P. J., SLOVIC, P., & RORER, L. G. An
analysis of variance model for the assessment of
configural cue utilization in clinical judgment.
Psychological Bulletin, 1968, 69, 338-349.
HOTELLING, H. The selection of variates for use in
prediction with some comments on the general
problem of nuisance parameters. Annals of Mathematical Statistics, 1940, 11, 271-283.
HURSCH, C. J., HAMMOND, K. R., & HURSCH, J.
Some methodological issues in multiple-cue probability studies. Psychological Review, 1964, 71, 4260.
KOMORITA, S. S. A model for decision-making under
risk. American Journal of Psychology, 1964, 77,
429-436.
MEEHL, P. E. Clinical versus statistical prediction.
Minneapolis: University of Minnesota Press, 1954.
MEEHL, P. E. Wantedâ€”a good cookbook. American
Psychologist, 1956, 11, 263-272.
SAWYER, J. Measurement and prediction: clinical
and statistical. Psychological Bulletin, 1966, 66,
178-200.
SHEPARD, R. N. On subjectively optimum selections
among multi-attribute alternatives. In M. W.
Shelly & G. L. Bryan (Eds.), Human judgment
and optimality. New York, Wiley, 1964.
WEBSTER, E. C. Decision making in the employment
interview. Montreal: Industrial Relations Centre,
McGill University, 1964.
WIGGINS, N. L., & HOFFMAN, P. J. Three models
of clinical judgment. Journal of Abnormal Psychology, 1968, 73, 70-77.
YNTEMA, D. B., & TORGERSON, W. S. Man-computer
cooperation in decisions requiring common sense.
IRE Transactions of the Professional Group on
Human Factors in Electronics, 1961, 2(1).
(Received April 21, 1969)

