<-----Page 0----->Applied Psychological Measurement
http://apm.sagepub.com

Appropriate Moderated Regression and Inappropriate Research Strategy: A Demonstration of
Information Loss Due to Scale Coarseness
Craig J. Russell, Jeffrey K. Pinto and Philip Bobko
Applied Psychological Measurement 1991; 15; 257
DOI: 10.1177/014662169101500305
The online version of this article can be found at:
http://apm.sagepub.com

Published by:
http://www.sagepublications.com

Additional services and information for Applied Psychological Measurement can be found at:
Email Alerts: http://apm.sagepub.com/cgi/alerts
Subscriptions: http://apm.sagepub.com/subscriptions
Reprints: http://www.sagepub.com/journalsReprints.nav
Permissions: http://www.sagepub.com/journalsPermissions.nav
Citations http://apm.sagepub.com/cgi/content/refs/15/3/257

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

<-----Page 1----->Appropriate Moderated Regression and
Inappropriate Research Strategy: A Demonstration
of Information Loss Due to Scale Coarseness
Craig J. Russell
Rutgers University
Jeffrey K.
University

Pinto
of Maine

Philip Bobko
Rutgers University

Paunonen and Jackson (1988) demonstrated
that stepwise moderated regression provides a test
of interaction effects that protects the nominal
Type I error rate. However, the stepwise procedure
has also been characterized as failing to detect
interaction effects in empirical studies. This issue
has led to questions regarding the method’s
statistical power (Bobko, 1986; Zedeck, 1971) in
applied research. It is demonstrated that, because
of a research strategy frequently used in empirical
investigations, the probability of Type II error in
detecting a true interaction effect is unknown.
Specifically, the number of scale steps used in
measuring the dependent variable is shown to
result in a form of systematic error that can
spuriously increase or decrease the expected effect
size of the interaction. The problem is also discussed in the context of testing more complex models.
Recommendations for eliminating this problem in
future research designs are provided.
Index terms:
information loss, interaction effects, Likert scales,
moderated regression, response transformation.

research. Since that time, the infrequency in the
applied psychological literature of findings supportive of moderator effects has fueled concerns
over the power of the procedure (Zedeck, 1971).
More recently, Bobko (1986) and Venkatraman
(1989) have reported specific concerns regarding
the correspondence or &dquo;fit&dquo; between an interactive conceptual framework and statistical procedures used to evaluate the framework.
The difficulty in detecting interactions has
often been attributed to multicollinearity among
predictor variables, particularly between a
multiplicative interaction and its respective component main effects (Drazin & Van de Ven, 1985;

Stepwise moderated regression analysis was first
described by Saunders (1955, 1956) as a statistical
tool for assessing moderator effects at an individual level of analysis. Shortly thereafter, Chow (1960)
described an identical procedure for assessing interaction effects at a macro level of organizational

demonstrated that stepwise moderated regression
is not susceptible to inflation of Type I error in
the presence of multicollinearity, Cronbach (1987)
has recently called for more sensitive research
strategies for the detection of interaction effects.
Because the statistical procedure is sound,
what alternate research strategies should be pursued ? At best, an investigator is confronted with
a well-formulated theory that dictates the strategy
of choice. For example, Bobko (1986) demon-

Sockloff, 1976a, 1976b). Unfortunately, recent attempts to statistically control for multicollinearity
effects (e.g., Morris, Sherman, & Mansfield,
1986) have not proved fruitful (Cronbach, 1987).
Although Paunonen and Jackson (1988)

257

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

<-----Page 2----->258
strated

research strategy of

specific cell conhypothesizing particular ordinal interactions. Unfortunately, as noted by
Cronbach (1987) and Venkatraman (1989), applied researchers are frequently faced with models
that are weakly specified.
a

trasts for theories

Yet another strategy focuses

on

the reduction

of measurement error (Schwab, 1980). Busemeyer
and Jones (1983) demonstrated how measurement
error influences the power of moderated regression (see their Equation 9). Specifically, suppose
a regression model attempts to predict a criterion
(Y) from two independent variables (Xl, X,) and
their interaction. Busemeyer and Jones (1983)
demonstrated that measurement error in the independent variables X, and X, reduces the expected effect size of moderated regression (i.e.,
the difference in the squared multiple correlation,
R 2, between the multiplicative and additive
models) when a true multiplicative relationship
exists between X, and X2 and the dependent
variable Y. Using instruments with known
reliabilities and Busemeyer and Jones’ formula,
investigators can determine the expected effect
size if a true multiplicative relationship exists and
hence identify sample size needed to yield adequate statistical power.
Cohen (1983) and Peters and Van Voorhis
(1940) demonstrated the impact of information
loss in the dependent variable on simple Pearson
product-moment correlations. This information
loss may occur when a continuous dependent
variable is reduced to a small set of categories
by the investigator in a known way. Cox (1950)
demonstrated how to minimize the loss of information by selecting optimally-sized groups of observations taken from a continuous distribution.
All prior work in this area has focused on information loss that occurs in some known fashion.
However, no study has examined the consequence
of persons responding to a discrete scale when,
in fact, the underlying construct is continuous.
This paper demonstrates that the number of options on the dependent scale will be a source of
unknown systematic error in moderated regression and, in turn, will spuriously increase or

decrease underlying statistical power.

Systematic Error and Information Loss
In applied research, most constructs of interest
are continuous. The actual number of options
available

on

response scales is often discrete. That

is, X,, X,, and Y are often measured on 1- to
5-point Likert scales (e.g., Stahl & Harrell, 1981;
Russell, 1985). Furthermore, note that if the three
variables are all measured on 5-point Likert
scales, then the empirical interaction term
X, X X2 is arithmetically defined by a 1- to
25-point scale. Thus, the measurement of Y (1 to
5) does not necessarily map, in any straightforward way, onto the 25-point interaction term
from the regression analysis. Information is lost
when

&dquo;coarse&dquo; response scale is used to
represent a near continuous or &dquo;fine&dquo; Y variable. As demonstrated below, this phenomenon
has direct implications for systematic contributions to error variation in the Likert response
format.
The original Likert method of scale construction involved the operationalization of continuous psychological constructs by summing
responses to questions of opinion (Likert, 1932).
Likert’s response scales contained five scale steps
(strongly agree, agree, undecided, disagree, and
strongly disagree). Likert and others demonstrated that this procedure resulted in low levels
of random error variation (i.e., high reliability)
in resultant scale scores (Edwards & Kenney, 1946;
a

Likert, 1932; Rasmussen, 1989). Furthermore,
Cicchetti, Showalter, and Tyrer (1985) and
Jenkins and Taber (1977), using monte carlo
studies, demonstrated that no substantial reduction in random error occurs when the number of
scale steps exceeds a range of five to seven points.
However, systematic error may be introduced
when respondents are faced with a fine, true
underlying response and a coarse, overt 5-point
response scale. The systematic error occurs when
information from the fine/true response is lost
as it is placed on a coarse 5-point response scale.
Although Cohen (1983) and Peters and Van
Voorhis (1940) demonstrated the impact on sim-

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

<-----Page 3----->259

ple linear regression analyses when the investigator decides how to transform a continuous
Y variable into categories in some known way, the
impact of requiring respondents to perform the
transformation in some unknown way has not
been considered. It is hypothesized that the
increased range of potential values characterizing a &dquo;true&dquo; response in interactive regression will

lead to

greater information loss and larger
opportunity for systematic error than in simple
linear regression. Because people respond to oneven

ly one question at a time, dependent scale scores
derived by summing responses to multiple Likerttype items will also suffer from this information
loss.
For

example, in

a

test of a

multiplicative

ex-

tions available. When respondents are faced with
a scale on the dependent variable that does not
have a sufficient number of response options, information loss is unavoidable.
The purpose of the analyses presented below
was to demonstrate how information loss caused by the overt response scale has an unknown
influence on effect sizes found in moderated
regression analysis. For purposes of explication,
two examples of hypothetical regression data were
generated in which the dependent scale (Y) did
not have a sufficient number of options to reflect
either a multiplicative effect or an additive effect.
An additive example demonstrates one way information might be lost when two variables are
additively combined.

pectancy theory model, Stahl and Harrell (1981)
a within-persons design with 11 levels of
valence, three levels of expectancy, and an

Multiplicative Example

used

11-point dependent response scale. If respondents
used a multiplicative function of expectancy and
valence to arrive at estimates of motivational
force, they were faced with placing a 33-point
(3 x 11) latent response space onto an overt
11-point dependent scale. Interestingly, the findings of Stahl and Harrell failed to support a
multiplicative expectancy model for the majority of respondents.
In contrast, Arnold (1981) used a withinpersons design with five levels of each independent variable (expectancy and valence) and 150
levels of the dependent variable (motivational
force). A multiplicative expectancy theory model
(force expectancy x valence) would require
25 points in the dependent response space. Using
a 150-point response scale, Arnold certainly gave
respondents sufficient options on Y to portray
their &dquo;true&dquo; response, regardless of whether a
multiplicative or additive model was correct. In
contrast to Stahl and Harrell (1981), Arnold
found substantial evidence supporting the multiplicative formulation of expectancy theory. These
conflicting findings may be related to the investigators’ choice of response scales. The
presence of a true interaction effect can create
more latent responses than actual response op=

’The Data

Three sets of dependent responses were
generated for purposes of illustration. Dependent
scales Y,, Y,, and Y, were generated from the
same array of X, and Xz observations. Each independent variable was characterized by a 5-point
scale (1, 2, 3, 4, 5) in a fixed effects two-way
ANOVA design (each level of X, and X2 occurred
with equal frequency). Thus, X, and X2each had
a mean of 3 and standard deviation of 1.41 (each
value of X, was paired with every value of X2 so
that rl,z
0.0).
The dependent scale (Yl) was created simply
by multiplying X, and X2 (YI X, x X2). The
=

=

resultant response range was from 1 to 25 and
represented the &dquo;true score&dquo; response expected
from a respondent who used a multiplicative
combination of X, and X2, who responded to the
dependent variable response scale (Y,) with no
random measurement error, and who was given
a dependent variable response scale that permitted all responses to be made without any information loss.
Information loss in the second dependent scale
(Y2) was created in one step by multiplying Xl and
X2and then recoding the data into five equal intervals. Specifically, all products of X, and X2be-

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

<-----Page 4----->260

were assumed to elicit a mean overt
the Y, scale of 1, original Y, values
between 6 and 10 were assumed to elicit a mean
overt Y, response of 2, and so forth. This was
meant to represent what might happen when a
5-point dependent variable response scale is used
to portray a 25-point latent response space. With
Y, representing the respondent’s &dquo;true&dquo; original
response, Y2 represented the response expected
from a respondent who used a multiplicative
combination of X, and X,, who responded to the
dependent variable response scale (Y,) with no
random measurement error, and who was given
a coarse dependent response scale that caused information to be lost from the &dquo;true&dquo; Y, response.
Information loss in the third dependent scale
(Y,) was created in two steps by taking the square
root of the product of X, and X2 and rounding
to the nearest integer. Although it seems unlikely that respondents can perform square root functions &dquo;in their heads,&dquo; there is strong evidence
from laboratory investigations of psychophysical
scaling that respondents do perform the mathematical equivalent of this procedure (Anderson,
1982; Birnbaum & Veit, 1974). There is no reason to believe that the YZ or Y3 transformation is
more appropriate than the other. However, information must be eliminated somehow if the
&dquo;true&dquo; response is to be placed on the five-point
scale, and Yz and Y, are both viable examples of
how information loss might occur. Table 1 contains all possible combinations of X, and X2
variables with their associated Y,, Y2, and Y,

tween 1 and 5

response

on

responses.

Table 1
Set of Independent Variables
and Dependent Variables for

Complete

Multiplicative Example

These effect sizes are reported in Table 2. First,
R 2 = 1.00 for Y&dquo; because Y, was constructed as the product of X, and X2with no random measurement error. Further, when there was
no information loss due to limited response options, Ra,,a = .90 and the incremental effect for
the interaction term is R~1U1t - R add 2
.10. In conif
the
trast,
5-point dependent response scale
caused information loss due to rounding latent
responses within equal-sized intervals (i.e., Y2),
the additive effect decreased and the expected
note that

=

Analyses and Results
Stepwise moderated regression analysis

was

performed for each of the dependent variables
Yj, Y,, and Y,. The effect size of interest was
&dquo;muli - ~dd from the following equations (Cohen
& Cohen, 1983):

Table 2
Moderated

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

Regression Effect Sizes

<-----Page 5----->261

effect size for the interaction increased to .180.
When the 5-point dependent response scale caused information loss through rounding the square
root of the latent response to the nearest integer
(i.e., ~3), the expected interaction effect size
decreased to .023.
It should be noted that the above univariate
distributions of X, and X2were uniform. When
the procedures were replicated under conditions
of normally distributed and/or correlated independent variables, the pattern of results was
the same.
It is of interest to note that relative to Y,, the
Radd for Y, was substantially lower and the Radd
for Y was slightly higher. R£~j, decreased for both
Y2 and Y,. It is the differential size of these
changes that contributed to inflation or deflation
of R~1U1t - Radd for the YZ and Y3 transformations.
There is no apparent theoretical explanation that
might account for the substantial drop in ~d for
Y,. However, Table 1 suggests that the Y2 transformation resulted in a disproportionate amount
of the &dquo;systematic&dquo; error occurring in the lower
range of values, resulting in moderate range restriction (there were more Is for Y2 than for Y3).
Although both the Y2 and Y, transformations
diminished a strong rank ordering among the 25
possible &dquo;true&dquo; responses, the effect of the resultant &dquo;ties&dquo; or grouping of Y, values into the &dquo;1&dquo;
category of Y2 had a stronger attenuation effect
on Ra~,~ than was the case for Y,.
An Additive

Example

The Data

Two sets of dependent responses were generated. Dependent scales Y, and YZ were generated
from the previous array of X, and XZ observations. As in the multiplicative example, each independent variable was characterized by a 5-point
scale with each value observed with equal frequency.

The first dependent scale (Y,) was created by
simply adding X, and X2 (again, under the assumption of no random measurement error). The
resultant response range was from 2 to 10 and in-

dividual

scores represented the &dquo;true score&dquo; reexpected from a respondent who used an
additive combination of X, and X2, who responded to the dependent response scale (Y,) with no
random measurement error, and who was given a
dependent response scale that permitted all re-

sponse

sponses to be made without any information loss.
The second dependent response scale (Y,) was

created by summing X, and X2 and then recoding
the sum into five equal intervals (original Y,
responses of 1 and 2 were recoded as 1, responses
of 3 and 4 were recoded as 2, and so forth) under
the assumption of no measurement error. Hence,
similar to the multiplicative example, YZ
represented the response expected from a respondent who used an additive combination of X,
and X2, who responded to the dependent
response scale (Yz) with no random measurement
error, and who was given a dependent response
scale that required information loss from the true
Y, response. Table 3 contains all possible combinations of X, and XZ variables with their
associated Y, and Y2 responses.

Analysis

and Results

By definition, the regression of the additive
combination of X, and XZ onto Y, yields
R2
1.00. When the Y2 dependent variable was
regressed onto an additive combination of Xj and
.951. Hence, the information loss imX2, 1Zz
=

=

posed on Y2 would decrease the likelihood of
detecting a true additive effect. Although Peters
and Van Voorhis (1940) and Cohen (1983)
demonstrated that the coarseness of the dependent scale will attenuate simple correlations, the
transformation will also attenuate additive
main effects in multiple regression. Note that this
type of result is also demonstrated in the R,,2,, column of Table 2 for the Y2 dependent variable,
whereas the opposite effect-that is, an inflation
of jR~d&horbar;occurred for Y3 (however, dependent
variables in Table 2 are transformations of a
multiplicative model, not an additive model).
same

Discussion
The results

clearly demonstrate that alternate

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

<-----Page 6----->262

Table 3

Complete Set of
Independent Variables and
Dependent Variables for
Additive Example

transformations of people’s original responses
can spuriously increase or decrease the expected
effect size in moderated regression analysis.
When a research design fails to provide a respondent with an overt response scale that is at least
as large as their original response space, incorrect conclusions can be drawn from moderated
regression analysis. This is a critical finding in
the analysis of applied research in which the
testing of interactive theories is frequent (e.g., Ar-

nold, 1981; Prescott, 1986; Russell, 1985;
Venkatraman, 1989). As noted earlier, Cronbach

(1987) has called for alternative research strategies
that are sensitive to interactive effects. A possible research strategy is the a priori identification
of theoretical response domains before dependent
response scales are developed. In turn, this identification process should help guarantee that the

operational

of the dependent
sufficient number of response

measurement

variable contains

a

options.
Future research needs to examine the process

underlying how information loss occurs and how
characteristics of the measurement situation (e.g.,
anchor response format, predictor collinearity)
influence the transformation. It is also possible
that the size of the &dquo;reduction&dquo; task will determine the type of transformation used by the
respondent. For example, if Xl and X2 are measured on 1- to 10-point scales, an additive model
would yield a response space ranging from Y = 2
to 20 whereas a multiplicative model would yield
a response space ranging from 1 to 100. Respondents may use different &dquo;reduction&dquo; processes to
make small versus large dependent &dquo;response
reductions.&dquo;
The current examples implicitly assume some
cognitive reduction process by the respondents;
that is, the respondents have to somehow
&dquo;squeeze&dquo; their latent dependent response to fit
it onto the discrete overt response scale (Anderson, 1982, labeled this the &dquo;response function&dquo;).
As one solution, researchers might consider using dependent scale formats that allow respondents to use a continuous response scale.
Arnold’s (1981) and Norman’s (1986) use of a
mark on a line segment permitted them to use
the mark’s distance from the end of the line (in
millimeters) as a dependent scale value, effectively
creating a continuous scale score. Although creating a somewhat cumbersome coding task, this
procedure might permit more accurate reflection
of a &dquo;true&dquo; underlying multiplicative response.
With an increasing number of questionnaires being administered on personal computers, software
that will present a relatively unobtrusive means
of obtaining computer-generated response lines
on the screen, with the respondent asked to use
a mouse to place a mark on the line, might soon
be seen. The computer would then generate a very
precise measurement of the mark’s position on
the line, effectively eliminating the awkward requirements of using a ruler to quantify each person’s response (the procedure has been used by

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

<-----Page 7----->263

Arnold, 1981, and Norman, 1986).
An additional approach to overcoming the

cognitive problem in applied research of response
reduction that is induced by scale coarseness
would require investigators to shift their initial
focus from the dependent variable to the independent variables. Specifically, investigators must
identify the number of conceptually distinct levels
possible for each independent variable before
developing measurement scales for the dependent
variable. For example, Arnold (1981) used the
results of earlier work by Shanteau (1974) to identify five levels of expectancy. Under these circumstances, manipulation checks become doubly
important to ensure that each independent variable has its intended effect and that the expected
number of levels of effect are present. If
manipulation of an independent variable yields
more &dquo;levels&dquo; than anticipated, moderated regression results may be essentially uninter-

pretable.
Busemeyer and Jones (1983) noted that when
respondents go through some unknown transformation between their true response and the
observed response, interpretation of moderated
regression analysis becomes problematic. The
current study reaffirmed and extended this notion by showing how systematic response error
is produced in the instance in which the number
of scale options on Y does not match the number of possible responses created by the multiplication of Xl and X2. The conflicting results of
Arnold (1981) and Stahl and Harrell (1981), and
potentially of any other empirical tests of interactive theories, may be due to the different
number of dependent scale options used in each

study.
As noted above, the current examples have all
been depicted within a cognitively-oriented interaction model (Expectancy Theory). A multiplicative relationship was further assumed between
fixed treatment effects (five &dquo;fixed&dquo; levels of X,
and X2 were specified a priori) and a dependent
measure obtained by asking questions of the
&dquo;treated&dquo; sample. These results should generalize to more complex models (e.g., conjunctive or

disjunctive decision models), to random effects
designs, and/or to archival measures as the
dependent variable.
A more complex model would involve both additive and multiplicative effects, that is,
Y
X, + X2 + X, x X2. Using this model,
data were generated to create an initial Yi, &dquo;true&dquo;
dependent response scale (with a maximum value
of 5 + 5 + 5 x 5 = 35), and a Y2 dependent
=

response scale in which all values of Y, between
1 and 7 were coded as 1, values between 8 and
14 were coded as 2, and so forth. For Yi,

1.00 (by definition) and Radd = .941,
Rm&dquo;,t
yielding a difference of .059. For Yz, R2.,,, = .949
and Iza~d
.900, yielding a difference of .049.
Hence, the same &dquo;grouping&dquo; transformation
used for Y2 throughout these examples resulted
=

=

in an inflated interaction effect size for a &dquo;true&dquo;
multiplicative model, and an attenuated interaction effect size for a &dquo;true&dquo; combined multiplicative-additive model. The same type of transformation will differentially impact the ability to
detect alternate &dquo;true&dquo; models. Models with
three- or four-way interaction terms and/or
exponential functions will drastically increase the
number of possible values in the dependent
variable space. Accurate testing of these more
elaborate functions would require a nearly continuous dependent response scale.
A similar situation arises when random effects
designs are considered. If the independent variables are truly continuous and the levels observed
by the investigator are specific to the sample at
hand (e.g., the primary valence variable of Stahl
& Harrell, 1981), the investigator is again faced
with an infinite dependent variable space and the
need to use a continuous dependent response
scale. Thus, for all but the simplest models, investigators should explore nontraditional means
of operationalizing their dependent variables.
These might include the cumbersome and labor
intensive coding required to measure respondents’
marks placed on an anchored line segment (Arnold, 1981), the development of optical scanning
technology or software that accurately measures
the distance down a line segment that respon-

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

<-----Page 8----->264

dents mark,

or

exploration of magnitude estima-

tion procedures.
The examples

throughout this

paper focused
that require

psychological dependent
people. Hence, it was implicitly
assumed that respondents reduce or &dquo;squeeze&dquo;
on

measures

responses from

their &dquo;fine&dquo; latent dependent response to fit on
a &dquo;coarse&dquo; dependent response scale. These arguments should also apply to studies using dependent variables &dquo;reduced&dquo; in some other manner. For example, Prescott (1986) examined the
interaction effect of organizational environment
and corporate strategy on an organization’s
return on investment (ROI) using archival data.
In this instance, ROI was captured with a continuous measure in monetary terms. However, what
if the archival data had been reduced to intervals
or ranges of ROI values, a common condition in
archival databases available to organizational
psychologists? Although the term &dquo;response
reduction&dquo; could be used to describe information loss due to coarse operationalizations of a
fine dependent variable space, there are many
ways in which a coarse operationalization can
lead to information loss. Archivists making decisions of convenience to use coarse categories to
summarize continuous data (e.g., as in Y2) are
but one example. Applied researchers must be
alert to alternate sources of information loss if
they are to accurately test all but the simplest
models. Again, the interest is not in knowing a
priori the optimal number of groupings to
minimize information loss (Cox, 1950) or in identifying the effect that all possible transformations
might have on the ability to detect nonlinear
models. Rather, the goal is to prevent spurious
conclusions from being drawn when research designs unintentionally lose critical information
from the dependent variable, through response
reduction or any other means.
Related Measurement Issues

As noted

above, it could be argued that in

survey research the measurement of the

depen-

dent variable becomes continuous when people’s
responses are summed across multiple dependent

scale items. For example, 10 dependent scale items
with 1- to 5-point response scales are typically
summed to yield a dependent scale score ranging from 10 to 50. Unfortunately, although an
investigator may sum responses across items to

yield a composite dependent scale, responses are
made sequentially to each item. Adding item
responses to form a dependent scale score effectively controls for the effects of random influences on people’s responses. However, it does
not necessarily negate any information loss or
&dquo;reduction&dquo; that might have occurred in their
item responses prior to summation into a single
scale score. In fact, the systematic error may
cumulate across the sum. Again, more basic
research is needed concerning the response reduction process.
Finally, it should also be noted that the effect
of information loss described here is different
from simple range restriction. Range restriction
when

contains observations
the potential range of
responses. Correlations between a measure suffering from range restriction and any predictor
variable will then be attenuated. In contrast, the
information loss due to &dquo;response reduction&dquo;
does not eliminate observations from a portion
of the potential range of responses. The response
reduction involves the respondent’s placement of
all potential responses on a scale that does not
have enough options to differentiate among all
of the responses. The variance is not necessarily
reduced; rather, the number of options within a
given range is limited. The results here indicate
that, depending on how people &dquo;reduce&dquo; their
responses, the result could yield a spurious attenuation or increase in effect size.
The analyses presented here demonstrate that
the number of response options on the dependent scale can severely influence the effect sizes
in moderated regression analysis. As demonstrated above, it is critical to give respondents enough
space when searching for moderator effects in applied psychological research and/or to be alert for
sources of information loss in archival data. More
basic research is needed regarding (1) how peooccurs

from only

a

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

a measure

portion of

<-----Page 9----->265

ple actually reduce &dquo;true&dquo; continuous responses
to yield an overt response to discrete response
options and (2) the relative efficacy of using continuous response scales to operationalize dependent responses.
References

Anderson, N. H. (1982). Methods of information integration theory. New York: Academic Press.
Arnold, H. J. (1981). A test of the multiplicative
hypothesis of expectancy-valence theories of work
motivation.

Academy of Management Journal, 24,

128-141.

Birnbaum, M., & Veit, C. T. (1974). Scale convergence
as a criterion for rescaling: Information integration
with difference, ratio, and averaging tasks. Perception and Psychophysics, 15, 7-15.
Bobko, P. (1986). A solution to some dilemmas when
testing hypothesis about ordinal interactions. Journal of Applied Psychology, 71, 323-326.
Busemeyer, J. R., & Jones, L. E. (1983). Analysis of
multiplicative combination rules when the causal
variables are measured with error. Psychological

Bulletin, 93, 549-562.
Chow, G. (1960). Test of equality between sets of coefficients in two linear regressions. Econometrica, 28,
591-604.

Cicchetti, D. V., Showalter, D., & Tyrer, P. J. (1985).
The effect of number of rating scale categories on
levels of interrater reliability: A monte carlo investigation. Applied Psychological Measurement, 9,
31-36.

Cohen, J. (1983). The cost of dichotomization. Applied

Psychological Measurement, 7,

249-253.

Cohen, J., & Cohen, P. (1983). Applied multiple regression/correlation analysis for the behavioral sciences
(2nd ed.). Hillsdale NJ: Erlbaum.
Cox, D. R. (1950). Note on grouping. Journal of the
American Statistical Association, 52, 543-547.

Cronbach, L. J. (1987). Statistical tests for moderator
variables: Flaws in analyses recently proposed.
Psychological Bulletin, 102, 414-417.
Drazin, R., & Van Der Ven, A. H. (1985). An examination of alternative forms of fit in contingency
theory. Administrative Science Quarterly, 30, 514-539.
Edwards, A. L., & Kenney, K. C. (1946). A comparison
of the Thurstone and Likert techniques of attitude
scale construction. Journal of Applied Psychology,

30, 72-83.

Jenkins, G. D., & Taber, T. D. (1977). A monte carlo
study of factors affecting three indices of composite
scale reliability. Journal of Applied Psychology, 62,
392-398.

Likert,

R. A. (1932). A technique for the measurement
of attitudes. Archives of Psychology, New York, No.
140.
Morris, J. H., Sherman, J. D., & Mansfield, E. R.
(1986). Failures to detect moderating effects with
ordinary least squares-moderated multiple regression : Some reasons and a remedy. Psychological
Bulletin, 99, 282-288.
Norman, K. L. (1986). Importance of factors in the
review of grant proposals. Journal of Applied
Psychology, 71, 156-162.
Paunonen, S. V., & Jackson, D. N. (1988). Type I error rates for moderated multiple regression analysis.
Journal of Applied Psychology, 73, 569-573.
Peters, C. C., & Van Voorhis, W. R. (1940). Statistical
procedures and their mathematical bases. New York:
McGraw-Hill.
Prescott, J. E. (1986). Environment as a moderator of

strategy-performance relationship. Academy of
Management Journal, 29, 329-346.
Rasmussen, J. L. (1989). Analysis of Likert-scale data:
A reinterpretation of Gregoire and Driver.
Psychological Bulletin, 105, 167-170.
Russell, C. J. (1985). Individual decision processes in
an assessment center. Journal ofApplied Psychology,
70, 737-746.
Saunders, D. R. (1955). The "moderator variable"

as

useful tool in prediction. Proceedings of the 1954
Invitational Conference on Testing Problems (pp.
54-58). Princeton NJ: Educational Testing Service.
Saunders, D. R. (1956). Moderator variables in prediction. Educational and Psychological Measurement, 16,
209-222.
Schwab, D. P. (1980). Construct validity in organizational behavior. In B. M. Staw &
L. L. Cummings
(Eds.), Research in organizational behavior (pp.
3-43). Greenwich CT: JAI Press.
Shanteau, J. C. (1974). Component processes in risky
decision making. Journal of Experimental Psychology,
103, 680-691.
Sockloff, A. (1976a). The analysis of nonlinearity via
linear regression with polynomial and product
variables: An examination. Review of Educational
Research, 46, 267-291.
Sockloff, A. (1976b). Spurious product correlation.
Educational and Psychological Measurement, 36,
33-44.
Stahl, M. J., & Harrell, A. M. (1981). Modeling effort
decisions with behavioral decision theory: Toward
an individual differences model of expectancy
theory. Organizational Behavior and Human Performance, 27, 303-325.
Venkatraman, N. (1989). The concept of fit in strategy
research: Toward verbal and statistical correspondence. Academy of Management Review, 14, 423-444.
a

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

<-----Page 10----->266

Zedeck, S. (1971). Problems with the use of &dquo;moderator&dquo; variables.

Psychological Bulletin, 76,

295-310.

Ackra&reg;wletl~rn~nts
The authors thank Edward Alf, Jerome Busemeyer, Martin Evans, Frank Schmidt, and Eugene Stone for their comments on an earlier draft of this report. Partial support
for this project was provided by the Coordinating Council for Business Studies Research Grants program of Ractgers University Revisions were made while the senior

author held a visiting appointment at the Krannert
Gradate School of Management, Purdue University The
authors also thank an anonymous reviewer for suggesting
questions of generalization to more complex models.

~leath&reg;r’s Address

reprints or further information to
Craig J. Russell, Department of Management, College
of Business, Louisiana State University, Baton Rouge
LA 70803-6312, U.S.A.
Send requests for

Downloaded from http://apm.sagepub.com at UNIV OF WATERLOO on February 17, 2010

