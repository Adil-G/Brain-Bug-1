<-----Page 0----->Strategic Variability in Risky Choice: Mechanisms and Implications for Neuroanatomy
of Cognitive Control
by
Vinod Venkatraman
Department of Psychology and Neuroscience
Duke University

Date:_______________________
Approved:
___________________________
Dr. Scott A. Huettel, Supervisor
___________________________
Dr. John W. Payne
___________________________
Dr. Roberto Cabeza
___________________________
Dr. Tanya L. Chartrand

Dissertation submitted in partial fulfillment of
the requirements for the degree of Doctor of Philosophy in the Department of
Psychology and Neuroscience in the Graduate School
of Duke University
2011

<-----Page 1----->ABSTRACT

Strategic Variability in Risky Choice: Mechanisms and Implications for Neuroanatomy
of Cognitive Control
by
Vinod Venkatraman
Department of Psychology and Neuroscience
Duke University

Date:_______________________
Approved:
___________________________
Dr. Scott A. Huettel, Supervisor
___________________________
Dr. John W. Payne
___________________________
Dr. Roberto Cabeza
___________________________
Dr. Tanya L. Chartrand

An abstract of a dissertation submitted in partial
fulfillment of the requirements for the degree
of Doctor of Philosophy in the Department of
Psychology and Neuroscience in the Graduate School
of Duke University
2011

<-----Page 2----->Copyright by
Vinod Venkatraman
2011

<-----Page 3----->Abstract
We make a variety of decisions throughout our lives. Some decisions involve
outcomes whose values can be readily compared, especially when those outcomes are
simple, immediate, and familiar. Other decisions involve imperfect knowledge about
their potential consequences: Should I accept the job offer I have now or wait for a
possible better offer in the future? Understanding the choice process when consequences
are uncertain – often called the study of decision making under risk – has been the focus
of research in behavioral economics, cognitive psychology, and now neuroscience.
Hallmark of human decision making is the ability to use multiple strategies in
representing and evaluating complex decision problems, and to flexibly adapt these
strategies to contextual changes in the environment. Yet, little is known about the
mechanisms underlying this flexible use of strategies, both across individuals as well as
decision contexts.
In a series of risky choice experiments, individuals demonstrate systematic bias
towards choices that maximize the overall probability of winning (or not losing) contrary
to the predictions of most economic models of risky choice. More importantly, there is
substantial variability in choice preferences as a function of decision context as well as
individual’s current state and traits. Analysis of information processing using eye
tracking reveals that this variability is associated with systematic differences in
information acquisition, consistent with the adaptive use of multiple strategies in decision
making.

iv

<-----Page 4----->Findings obtained using functional magnetic resonance imaging (fMRI) show that
distinct neural mechanisms are associated with choices and variability in strategic
preferences. Choices that maximize gains are associated with increased activation in
ventromedial prefrontal cortex while choices that minimize losses are predicted by
activation in anterior insula. However, choices that follow a simplifying strategy (i.e.,
attending only to the overall probability of winning) are associated with activation in
parietal and lateral prefrontal cortices. Dorsomedial prefrontal cortex, through its
differential functional connectivity with parietal and insular cortex, predicts individual
variability in strategic preference. There is also a striking relationship between neural
sensitivity to monetary outcomes in the ventral striatum and individual’s strategic
preferences, indicating that robust decision strategies may follow from the neural
response to rewards. Finally, 24 hours of total sleep deprivation (SD) evokes a strategy
shift during risky decision making such that the same individual moves from defending
against losses to seeking increased gains.
Though substantial recent research points to the role of the dorsomedial prefrontal
cortex (dmPFC) in the flexible control of behavior, nearly all such evidence comes from
paradigms involving executive function or response selection, not complex decision
making. However, empirical evidence from two independent experiments suggest that the
dmPFC contributes to strategic control in complex decision making: it signals changes in
how a decision problem is represented, and thus shapes computational processing
elsewhere in the brain based on the current strategy. FMRI experiment using multiple

v

<-----Page 5----->tasks that evoke distinct forms of control demands – response, decision and strategy –
provides new insight into the functional organization of dmPFC. Specifically, there is
evidence for three spatially distinct regions within the dmPFC: a posterior region
associated with control demands evoked by multiple incompatible responses, a middle
region associated with control demands evoked by the relative desirability of decision
options, and an anterior region that predicts control demands related to deviations from
an individual’s preferred decision-making strategy.
Such a functional topography in dmPFC is consistent with a similar hierarchical
organization of the dorsolateral prefrontal cortex (dlPFC), where progressively anterior
regions guide increasingly abstract choices. Evidence obtained using resting-state fMRI
demonstrates a posterior-to-anterior connectivity gradient between dmPFC and dlPFC,
with posterior dmPFC maximally connected to posterior dlPFC and anterior dmPFC
maximally connected to anterior dlPFC. This parallel topographic pattern replicates
across three independent datasets collected on different scanners, within individual
participants, and through both point-to-point and voxelwise analyses.
Based on these findings, I propose a hypothetical model of cognitive control that
is primarily characterized by hierarchical interactions – whose level depends on current
environmental demands – between functional subdivisions of medial and lateral PFC.

vi

<-----Page 6----->Dedication
This thesis is dedicated to my wife, Dhivya Chandrasekaran, who has been a
constant source of inspiration and a pillar of support. She has always stood by me and
supported my quest to complete my Doctorate in Philosophy wholeheartedly. In the
process, she has made numerous sacrifices of her own, without which this dissertation
would not be possible. Dhivya, thank you for everything and it means a lot to me. You
are very special and I love you.

vii

<-----Page 7----->Contents
Abstract .............................................................................................................................. iv
List of Tables .................................................................................................................... xii
List of Figures .................................................................................................................. xiii
Acknowledgements ........................................................................................................... xv
1

Decision Making: Models and Strategies ..................................................................... 1
1.1

Multi-attribute Decision Making ........................................................................ 2

1.1.1
1.2

Process Tracing Methods ................................................................................ 3
Strategies in Multi-attribute Decision Making ................................................... 6

1.2.1

Compensatory Decision Making..................................................................... 6

1.2.2

Heuristics and Non-Compensatory Decision Making .................................... 7

1.3

Contextual Effects on Multi-attribute Decision Making .................................... 9

1.4

Individual Differences in Strategy Use ............................................................. 12

1.5

Risky Choice as a Prototype for Studying Decision Making ........................... 13

1.5.1

Compensatory Models of Risky Choice ....................................................... 14

Expected Utility .................................................................................................... 14
Prospect Theory .................................................................................................... 15
Cumulative Prospect Theory................................................................................. 16
Transfer of Attention Model ................................................................................. 17
1.5.2
1.6
1.6.1

Non-compensatory Models of Risky Choice: Priority Heuristic .................. 17
Risky Choice: Single or Multiple Strategies? ................................................... 18
Demonstrating the use of Multiple Strategies in Risky Choice .................... 20

viii

<-----Page 8----->1.7
2

3

Summary ........................................................................................................... 22

Contextual and Individual Variability in Risky Choice.............................................. 23
2.1

Value Allocation Task ...................................................................................... 23

2.2

Variability in Preference for Probability-maximizing Heuristic ...................... 25

2.2.1

E1: Individuals Demonstrate Bias towards Pmax Option............................. 25

2.2.2

E2: Pmax Bias is Modulated by Decision Context ....................................... 27

2.2.3

Pmax Choices are Consistent with a Simplifying Strategy .......................... 30

2.3

Evaluations of Consistency with Economic Models ........................................ 31

2.4

E3: Eye-tracking Evidence for Multiple Strategies .......................................... 35

2.5

E4: Replication of Eye-tracking Results ........................................................... 56

2.6

General Discussion ........................................................................................... 59

Neural Correlates of Choice and Strategic Variability in Risky Choice .................... 63
3.1

Experimental Methods ...................................................................................... 67

3.2

Results ............................................................................................................... 74

3.3

Discussion ......................................................................................................... 81

4 State Effects on Risky Choice: Sleep Deprivation Biases the Underlying Neural
Mechanisms ...................................................................................................................... 87
4.1

Experimental Methods ...................................................................................... 89

4.2

Results ............................................................................................................... 95

4.2.1

Behavioral Findings ...................................................................................... 95

4.2.2

Neuroimaging Findings: Decision Phase ...................................................... 96

4.2.3

Neuroimaging Findings: Outcome Phase ..................................................... 99

4.3

Discussion ....................................................................................................... 100

ix

<-----Page 9----->5 Strategic Control in Decision Making: Implications for Neuroanatomy of Cognitive
Control ............................................................................................................................ 108

6

5.1

Cognitive Control............................................................................................ 113

5.2

Role of Lateral PFC in Cognitive Control ...................................................... 114

5.3

Role of Dorsomedial PFC in Cognitive Control ............................................. 116

Evidence of Topography in Dorsomedial Prefrontal Cortex .................................... 125
6.1

Methods........................................................................................................... 128

6.2

Results ............................................................................................................. 134

6.2.1

Response-related Control ............................................................................ 135

6.2.2

Decision-related Control ............................................................................. 136

6.2.3

Strategy-related Control .............................................................................. 137

6.2.4

Evidence for a Functional Topography in Dorsomedial PFC ..................... 138

6.3
7

8

Discussion ....................................................................................................... 140

A Parallel Functional Topography between Medial and Lateral Prefrontal Cortex . 145
7.1

Methods........................................................................................................... 147

7.2

Results ............................................................................................................. 153

7.3

Discussion ....................................................................................................... 157

Conclusions ............................................................................................................... 160
8.1

Neuroeconomics: From Variables to Strategies ............................................. 160

8.2

A Hierarchical Model for Cognitive Control .................................................. 162

Appendix A: Supplementary Material for Chapter 3 ...................................................... 165
Appendix B: Supplementary Material for Chapter 4 ...................................................... 174
Appendix C: Supplementary Material for Chapter 6 ...................................................... 182

x

<-----Page 10----->References ....................................................................................................................... 196
Biography........................................................................................................................ 218

xi

<-----Page 11----->List of Tables
Table 2-1: Choice proportions varied as a function of experimental conditions. ..............43
Table 2-2: Proportion of Pmax choices varied as a function of both individual
variability and problem type. .............................................................................................45
Table 2-3: Average number of acquisitions varied as a function of choice and
OPtype................................................................................................................................47
Table 2-4: Significant effect of OPtype and Choice on Payne Index ................................50
Table 2-5: The presentation format did not interact with Choices. ...................................51
Table 2-6: Results from stepwise logistic regression of trial-by-trial choice
preferences. ........................................................................................................................53
Table 2-7: Significant Choice x Strategy Type interaction on response times,
number of acquisitions and Payne Index ...........................................................................54
Table 2-8: Dwell times indicated a shift from exploratory to deliberative processing ......55
Table 2-9: Result summary from stepwise logistic regression for E4 ...............................58
Table 3-1: Results from logistic regression predicted trial-by-trial Pmax choices. ...........79
Table 7-1: MNI coordinates for dmPFC and dlPFC seed regions ...................................150
Table 7-2: Pairwise correlations between each dmPFC and dlPFC seed region for
each hemisphere. ..............................................................................................................155
Table 7-3: Summary of regression analysis using data pooled from all experiments. ....156

xii

<-----Page 12----->List of Figures
Figure 2-1: Individuals demonstrated variability in bias towards Pmax choices. .............27
Figure 2-2: Participants were faster for overall probability maximizing choices ..............29
Figure 2-3: Robustness of various models in predicting choices across trials ..................34
Figure 2-4: Schematic of stimuli and sample of eye-gaze movements (box numbers
represent sequence and size represents normalized gaze duration). ..................................38
Figure 2-5: Preference for the Pmax-heuristic was modulated by valence changes..........45
Figure 2-6: Variability in preference for Pmax choices across individuals. ......................46
Figure 2-7: Response times showed a significant effect of EVtype, OPtype, Choice
and a significant OPtype x Choice interaction. ..................................................................47
Figure 2-8: Normalized Gaze durations indicated a significant bias in processing for
cells that had the most unique information for the final choice. ........................................49
Figure 2-9: Payne Index was significantly correlated with the proportion of Pmax
choices across individuals only for the Pmax-available trials. ..........................................50
Figure 2-10: Individuals demonstrated a greater cost for moving away from a
preferred strategy on a particular trial. ...............................................................................54
Figure 2-11: Normalized gaze durations indicated a significant bias in processing
for cells associated with the final choice. ..........................................................................57
Figure 3-1: Schematic of the fMRI value allocation task. .................................................65
Figure 3-2: Distinct sets of brain regions predicted choices. .............................................76
Figure 3-3: Dorsomedial prefrontal cortex predicted strategy use during decision
making................................................................................................................................77
Figure 3-4: DmPFC showed differential functional connectivity with choice-related
regions. ...............................................................................................................................78
Figure 3-5: Ventral striatal sensitivity to rewards predicted strategic variability. .............81

xiii

<-----Page 13----->Figure 4-1: Schematic of (A) Experimental Stimuli, (B) Trial types and (C)
Outcome phase. ..................................................................................................................91
Figure 4-2: Sleep deprivation biased neural systems underlying decision making. ..........97
Figure 4-3: Changes in magnitude of activation predicted shifts in preferences
following sleep deprivation................................................................................................98
Figure 4-4: Sleep deprivation increased neural sensitivity to gain outcomes ....................99
Figure 4-5: Sleep deprivation diminished neural sensitivity to loss outcomes ................100
Figure 6-1: Schematic of Experimental Tasks .................................................................127
Figure 6-2: Definition of response-, decision- and strategy-related control. ...................128
Figure 6-3: Posterior dmPFC activation predicted response-related control demands....135
Figure 6-4: Activation in middle dmPFC predicted decision-related control
demands ...........................................................................................................................137
Figure 6-5: Activation in anterior dmPFC predicted strategy-related control
demands ...........................................................................................................................138
Figure 6-6: Summary of a functional topography in the dmPFC based on varying
control demands ...............................................................................................................139
Figure 7-1: Selected seed regions in the medial and lateral PFC ....................................149
Figure 7-2: The dmPFC exhibited a topographically organized connectivity pattern
with dlPFC .......................................................................................................................153
Figure 7-3: Pairwise connectivity between dmPFC and dlPFC functional regions.........154
Figure 7-4: Individual participants’ maximally correlated dmPFC-dlPFC pairs
reveal parallel topography................................................................................................156

xiv

<-----Page 14----->Acknowledgements
I would like to thank my advisor, Dr. Scott Huettel, for his support and guidance
throughout my graduate program at Duke University. Scott has been a constant source of
inspiration and encouragement and this thesis would not have been possible without his
unwavering support. I would also like to thank Dr. John Payne for his constant support,
advice and encouragement over the past few years. My thanks are also due to Drs. James
Bettman, Mary Frances Luce, Tanya Chartrand and Roberto Cabeza for their valuable
insights, assistance and feedback on various projects and this dissertation. Lastly, I would
also like to thank Dr. Michael Chee for all the opportunities and training prior to graduate
school, and his continued support and collaboration in the sleep deprivation projects.
My special thanks are also due to the members of the Huettel lab for making
graduate school an enjoyable and memorable experience. I would like to especially
acknowledge the contributions of David V. Smith, John Clithero, McKell Carter, Ben
Hayden and Sarah Donohue. I would also like to thank Dharol Tankersley, who was of
immense help when I first moved to Durham. My thanks are also due to Darcy Lewis,
Emily Clark, Karen Bernier, Amanda Edwards, Fonda Anthony and other staff members
at Center for Cognitive Neuroscience for all their administrative support.
I would like to express my gratitude to my wonderful mom, family and friends for
always encouraging me, supporting me and standing by me. Lastly, special thanks are
reserved for my son Vrishab Kaushik for the numerous special moments, which have
helped make life truly wonderful.

xv

<-----Page 15----->1 Decision Making: Models and Strategies
We make thousands of decisions each day, from simple choices about where to
look in the environment to social judgments about strangers. In making these decisions,
we synthesize a variety of information quickly and devise strategies to navigate the
challenges and make appropriate decisions. It is becoming increasingly evident that
people construct preferences when required instead of having stable, well-defined beliefs
that generalize across all contexts (Payne, 1976, 1982; Payne et al., 1992b). Additionally,
different individuals vary in their decision preferences even when faced with exactly the
same task demands (Epstein et al., 1996a; Weber et al., 2002). Therefore, a thorough
understanding of decision strategies requires the need to focus on the processes
underlying the decision, rather than just the final outcome. Simon argued that a theory of
human decision rationality “must be as concerned with procedural rationality – the ways
in which decisions are made – as with substantive rationality – the content of those
decisions” (Simon, 1981). The traditional focus in economics, on the other hand, has
been on what decisions are made rather than how they are made. There is also much
research in psychology that makes no pretense of describing the actual decision processes
used by people; for example see (Luce et al., 2000). Models describing the relationships
between the inputs and outputs of a decision are proposed without claiming to be
anything other than “as-if” models. That is, the mechanisms of judgment and choice are
treated as a “black box”. In contrast, one could focus on the processes of judgment and
choice (the how of decisions) and the use of various methods to trace processing beyond
the insights provided by more traditional input-output analyses. In recent years, there has
1

<-----Page 16----->been an increasing concern with the processes of decision due to increasing awareness
that judgments and choices are highly sensitive to seemingly minor changes in tasks and
contexts (Weber and Johnson, 2009).

1.1 Multi-attribute Decision Making
Real-world decision making often involves choosing between multiple
alternatives that differ along multiple attributes. For instance, buying a house would
involve trade-off between several attributes: price, safety, size and distance to work;
houses that are safe and close to work might tend to be small and more expensive
compared to ones that involve a daily commute of several miles in heavy traffic to work.
There are a variety of strategies available to a decision maker for integrating information
about each of the attributes before deciding on the best alternative. How then do we go
about this information acquisition process and what is the role of context and emotions in
shaping decisions? Answering these questions requires insight into the decision process
and mechanisms underlying decision making and not merely studying the final outputs.
Research on multi-attribute decision making can be broadly classified into
paradigms that look at preferences between alternatives, and paradigms that make
inferences about the best alternative. While preference paradigms are typically focused
on deciding between alternatives that vary qualitatively on several attributes such as
choosing between apartment to rent or job candidates (Payne et al., 1992b; Payne et al.,
1993), the inference paradigms focus more on inferences between alternatives based on
cue validities whose accuracy can be assessed, such as which soccer team would perform
better or which city is bigger (Gigerenzer and Goldstein, 1996; Gigerenzer et al., 1999).
2

<-----Page 17----->Therefore, there is a lack of an objective accuracy measure in the preference paradigms,
and the gold standard against which the performance of a strategy is compared is a
compensatory weighted additive model. On the other hand, the inference paradigms pit
all the strategies against each other by comparing them to external real-world criteria.
Feedback and learning play a crucial role in the prediction paradigms with the validities
of the cues being updated based on feedback from the previous decision (Gigerenzer et
al., 1999). The main focus of the dissertation is on decision preferences and not
inferences.

1.1.1 Process Tracing Methods
In one of the first experiments looking at decision process, participants acquired
information about the various attributes for each of the alternatives in the decision task
(Payne, 1976). The information was hidden in cards placed inside sealed envelopes that
we then pinned to an information board. By examining the pattern of information
acquisition, one could obtain a better understanding of the underlying decision process
and strategies. Several techniques have been used since for information monitoring
including verbal protocol analyses, MOUSELAB and more sophisticated eye tracking
methods (Russo and Dosher, 1983).
A popular method for understanding decision processes involves verbal protocols,
which encourages participants to “think aloud” and reveal their thought process when
making decisions (Payne, 1976). An advantage of verbal protocol analysis as a processtracing method is that it can provide information on meta-cognitive processing. For
example, verbal protocols provide some evidence that people adapt their processing in a
3

<-----Page 18----->top-down fashion. The following two excerpts from verbal protocols of two decision
makers illustrate this point: 1) “Well, with these many apartments (six) to choose from,
I’m not going to work through all the characteristics. Start eliminating them as soon as
possible” (Payne, 1976). 2) “With just two (gambles) to choose from, I’m going to go
after all the information, it won’t be that much trouble” (Payne and Braunstein, 1978).
Researchers have since used verbal protocols to study environmental valuation judgments
and to understand juror and jury judgments in civil cases involving punitive damages
among others (Schkade and Payne, 1994; Hastie et al., 1999). One strength of the verbal
protocol method is its ease of use in more natural (field) type settings. On the other hand,
it is important to note that verbal protocol methods can be difficult to use. They are labor
intensive, require considerable transcription and coding effort, and involve difficult, and
sometimes controversial, analysis.
Perhaps the most commonly used information acquisition technique in the
literature is MOUSELAB, a Java based computer software that presents a matrix of
rectangular boxes on the screen. Each box can be opened by moving a mouse pointer to
reveal information (Payne et al., 1993). The information in that box remains exposed as
long as the pointer is held on the box, after which it closes. The responses and timings are
recorded and available to the experimenter for further detailed analysis. One of the
common criticisms of mouselab is that the information acquisition process is unnatural as
participants have to move the mouse over a particular box to acquire information. Yet, it
has been a tremendously useful and popular tool for understanding decision process over
the past few decades.
4

<-----Page 19----->Another process-tracing method that should find greater use in more applied
decision research is eye-tracking. Eye tracking has been used as a tool to investigate
decision processes for the past few decades (Russo and Rosen, 1975; Lohse and Johnson,
1996; Rayner, 1998). Process methods like verbal protocols and Mouselab may interact
with decision behavior and hinder participants from relying on automatic processing due
to the unnatural nature of information presentation and acquisition, i.e. pressing mouse to
sequentially acquire information (Glockner and Herbold, 2011). Eye tracking on the other
hand has the advantage of providing more natural environment for studying decision
processes, thereby not hindering automatic processing when required. One can also
obtain a measure of pupil dilation using eye tracking which in turn provides information
about emotional and cognitive processing (Siegle et al., 2003a; Siegle et al., 2003b).
There is no “perfect” process-tracing method for decision research with each
having its own pros and cons. Therefore, one approach to this problem is to match the
method to the type of problem being investigated. For instance, tools like Mouselab,
Active Information Search, and the collection of verbal protocols may be best suited for
decision problems that represent more serial processing. On the other hand, tools like
eye-tracking together with response times and skin conductance may be useful in
dissociating between decisions that are based on intuition and heuristic processing against
those based on more deliberative processing (System 1 vs. System 2). Another approach
that has long been advocated is to combine methods. For instance, one converging
evidence using the same paradigm across more than one process-tracing technique to
make inferences (Payne et al., 1978; Payne and Venkatraman, 2011).
5

<-----Page 20----->1.2 Strategies in Multi-attribute Decision Making
The term “strategy” has different meanings in different fields and contexts.
Within game theory it usually refers to a particular choice option available to a player
(Camerer, 2003b). In an outcome-oriented definition in decision making, a decision
strategy can be defined as the average preference across trials for a particular decision
outcome (Venkatraman et al., 2009b). In a more process-oriented approach, strategy
refers to the sequence and content of information that people acquire and process to reach
a decision (Cope and Murphy, 1981; Payne et al., 1993). I contend that these definitions
are related (increased preference for a particular choice across trials will be a result of
systematic differences in information acquisition process). Hence, these two decisionmaking definitions of strategy will be used interchangeably through the course of this
dissertation.
In the context of multi-attribute decision making, information acquisition and
processing strategies can be broadly classified into compensatory and non-compensatory
strategies.

1.2.1 Compensatory Decision Making
Decisions that involve explicit trade-off between competing alternatives are
referred to as compensatory decisions since alternatives that are deficient in certain
attributes are compensated by their superiority on other attributes. The most popular
among compensatory decision making strategies is the weighted additive (WADD)
strategy. According to this strategy, the utility of a multi-attribute option is the weighted
sum of subjective utilities of its components. Therefore, a WADD process would
6

<-----Page 21----->typically involve examining each alternative on each of the attributes, determining the
subjective value of each of the attributes and multiplying it with the relative importance
of that attribute, and finally summing across all the attributes to obtain an overall value
for that alternative. The final step involves comparing the value across all alternatives and
the one with the highest value gets selected.
The WADD strategy is hence characterized by extensive alternative-based
processing of information as well as explicit trade-offs in dealing with conflicts, making
it an appropriate choice for normative decision strategy. The WADD model also has
several parallels with the expected utility model of risky choices discussed later (Payne et
al., 1988).
Another commonly used compensatory decision strategy is the equal weight
(EQW) strategy, which is a simplification of the WADD in the sense that all attributes are
considered to be of equal importance (Payne et al., 1988). As a result, the net value of
each alternative is obtained by merely summing the individual subjective values of each
of the attributes for that alternative.

1.2.2 Heuristics and Non-Compensatory Decision Making
Limitations in human cognitive capacities suggest that people cannot process all
the available information in a particular situation or even if they could, there would be a
large overhead in terms of cognitive costs. This necessitates selective processing of
information. A heuristic is a decision strategy in which only a subset of relevant
information is processed prior to making a decision. Heuristic strategies are usually noncompensatory in the sense that they do not involve explicit trade-offs between attributes.
7

<-----Page 22----->Heuristics, by their very nature, are fast and frugal due to the limited information
processing.
Herbert Simon, in 1955, introduced the notion of Satisficing (SAT) where people
choose an alternative, that though not optimal, is good enough (Simon, 1955). Therefore,
alternatives are considered sequentially in the order they occur in the choice set. The
subjective values for each attribute of that alternative is then compared against a predetermined cutoff value and the first alternative for which all attributes pass the cutoff
value is selected as winner. The satisficing strategy is selective across alternatives and
non-compensatory. The extent of processing depends largely on the cutoff values, which
in some instances can be adaptive based on the values of the first few alternatives
examined.
The simplest form of heuristic for multi-attribute decisions is the Lexicographic
(LEX) strategy, which involves identifying the most important attribute and selecting the
alternative with the highest value on that attribute (Payne et al., 1988). If multiple
alternatives are tied on the most important attribute, then their value on the next most
important attribute is considered to break the tie. A LEX strategy, therefore, is selective
across attributes, involves limited information processing and is clearly noncompensatory.
Elimination by Aspects (EBA) is a combination of the LEX and SAT strategies.
First, the attributes are ranked in the order of importance, similar to LEX and each is
associated with a cutoff rating (Tversky, 1972). Then, the alternatives are compared on
the most important attributes and the alternatives which fail to reach a minimum cutoff
8

<-----Page 23----->level for that attribute are eliminated. This process is repeated with the second most
important attribute and the remaining alternatives, until only one alterative remains. Thus,
EBA focuses on attributes as a means of processing information.
There are several other heuristics that can be used for multi-attribute decision
making like majority of conforming dimensions (MCD), least important minimum (LIM)
heuristic, least variance (LVA) heuristic, multi attribute utility (MAU) model and so on
(see (Riedl et al., 2008) for details). Therefore, decision makers have access to a
“toolbox” of strategies (both compensatory and non-compensatory) available at their
disposal, which can then be used in an adaptive manner depending on decision context
and individual variability as discussed below.

1.3 Contextual Effects on Multi-attribute Decision Making
The contingent nature of decision behavior has been one of the most important
findings of behavioral decision research. It has also become clear that not only do people
change what they decide based on task and context variations but also they change how
they decide. Thus, to understand what judgments and choices will be made in various
decision environments we must have an understanding of task demands, an understanding
of the processes of judgment and choice, and an understanding of how task demands and
psychological processes interact. Again, in the words of Simon, “Human rational
behavior is shaped by a scissors whose two blades are the structure of task environments
and the computational capabilities of the actor” (Simon, 1990). Recent research in
decision making has sought to extend Simon’s insight to include all of the psychological
processes of the decision maker.
9

<-----Page 24----->A related point is that decision researchers increasingly believe that preferences
for and beliefs about objects or events of any complexity are often constructed – not
merely revealed – in the generation of a response to a judgment or choice task (Payne et
al., 1992a; Slovic, 1995; Lichtenstein and Slovic, 2006). That is, people are seen as
constructing preferences and beliefs on the spot when needed, instead of having known,
well-defined, and stable preferences or beliefs that are retrieved from memory. Further,
preferences and beliefs are not generated by some invariant algorithm such as Bayesian
updating or expected utility calculations when memory is insufficient, but instead are
generated by the contingent use of a variety of different decision heuristics or
simplification mechanisms. Understanding when, and why, a task variable elicits a
particular process for constructing a solution to a decision problem will be facilitated by
data that reflect more than just the end product of the processing.
More specifically, a constructed response to a decision problem will often involve
the highly selective use of information in judgment and choice processes. Simon has
argued that attention is the scarce cognitive resource in decision making (Simon, 1978).
Consequently, understanding what drives selective attention in decision making is one of
the most critical tasks for a researcher. Many of the process-tracing methods discussed
above are very useful in identifying the selective use of information during decision
making. In particular, methods that trace information acquisition behavior such as
Mouselab, eye fixations, and active information search are well suited to studies of
attention and decision making.

10

<-----Page 25----->Factors that influence decision strategy can be classified as: (i) task variables (like
complexity of the problem, timing constraints, response mode) that are related to the
general characteristics of the decision problem, (ii) and context variables (like interattribute correlation and presence or absence of dominated alternatives) that reflect the
particular values of the alternatives (Bettman et al., 1993). Task difficulty represents the
best example of contingent strategy use: people typically switch from the usage of a
compensatory strategy for simple two or three alternative decision problems to more noncompensatory and heuristic based strategies for complex decision tasks (Payne, 1976).
These findings similarly extend to task environments involving time pressure (Payne et
al., 1996) and additional cognitive load (Drolet and Luce, 2004).
Even something as subtle and independent as variations in information display
could lead to changes in decision strategies. Individuals tend to acquire information in a
fashion that is consistent with the format of display (Bettman and Kakkar, 1977).
Consistent with the cost/benefit framework, any information display that involves storage
of information or transformation and additional processing will be discounted or ignored
from the decision process.
Another robust effect of context in decision literature refers to the attraction
effect. Here, the addition of a new dominated alternative increases the preference for the
original alternative that dominates it. The introduction of the “decoy” makes the original
alternative more attractive. A possible explanation for this effect is that the introduction
of a decoy reduces the negative emotion typically associated with the original
impoverished trade-off choice set (Hedgcock and Rao, 2008). Framing effect is similar to
11

<-----Page 26----->attraction effect, where the manner in which the decision problem is framed or
instructions are presented can lead to changes in decision strategies (Tversky and
Kahneman, 1981, 1986).
Inter-attribute correlation is another factor that affects decision strategies. Unlike
the general characteristics of the decision problem, inter-attribute correlation refers to the
conflict that arises due to the correlation between different attributes based on their
values for each given alternative. A greater negative correlation between attributes
implies a greater conflict in the decision process. Bettman and colleagues show that
decision contexts with increased negative correlation between attributes lead to an
alternative-based extensive processing of information in an effort to confront the conflict
(Bettman et al., 1993).

1.4 Individual Differences in Strategy Use
It is obvious that individuals differ in what judgments or choices they will make
when faced by the same task demands. For example, some people save more for
retirement, some less. Some people put more of their savings into bonds while others put
more of their savings into stocks. How should such individual differences in decisions be
modeled? A common view underlying many studies of individual differences is captured
by Birnbaum’s argument that the principle “that every individual is represented by the
same model in which different people can have different parameters in that model” (p.
497) should be retained for risky decisions until researchers have a clear reason to
abandon it (Birnbaum, 2008a). Nonetheless, it is becoming increasingly clear that
individuals differ in how judgments or choices are made (processes) as well as in the
12

<-----Page 27----->content of their decisions, e.g., amount of risk-taking. Understanding individual
differences in both behavior and processes is an ongoing challenge in decision research,
and will be facilitated by considering the interaction of tasks and processes. For instance,
Bishara and colleagues argued that understanding how two complex tasks designed to
measure the same individual trait, e.g., risk-taking, may relate across individuals depends
on examining the component processes involved in performing those tasks (Bishara et al.,
2009). Individual-difference analysis is also a key means through which neuroscience
methods can aid in the study of choice behavior. There is a clear need to go beyond the
traditional focus on individual differences in the content of decisions to a better
understanding of individual differences in the processes of decisions.
One popular area of research that has played an important role in decision
sciences literature is risky choice involving monetary gambles (Slovic and Lichtenstein,
1968; Payne and Braunstein, 1978; Kahneman and Tversky, 1979). Risky choice studies
are popular because they are easy to administer in laboratory settings, can be made
incentive-compatible to reveal true preferences and yet share similarities to real-world
decisions due to its probabilistic nature.

1.5 Risky Choice as a Prototype for Studying Decision Making
Most decisions involve situations with imperfect knowledge about the associated
outcomes, a notion termed as uncertainty in decision making. One specific aspect of
uncertainty that has been extensively studied by researchers is risk, where the decision
maker has some knowledge about the distribution of outcomes (Wu et al., 2007; Platt and
Huettel, 2008). Risky choice research involving monetary gambles has played an
13

<-----Page 28----->important role in decision sciences literature (Slovic and Lichtenstein, 1968; Kahneman
and Tversky, 1979; Payne et al., 1992a). Following Blaise Pascal’s formulation of the
notion of expected value through his famous wager argument in the 17th century, several
economists have proposed normative and descriptive models to explain risky choice
behavior. Some of these models are reviewed in this section.

1.5.1 Compensatory Models of Risky Choice
Expected Utility
At the heart of risky choice models is the expected utility model, first proposed by
Daniel Bernaulli in 1738, which is still a popular and dominant theory for explaining how
people choose between two choices under uncertainty (Bernoulli, 1738). According to
this normative model, people evaluate options based on their desirability or “utility” of
each of the outcomes weighted by the probability of the event occurring and choose the
option with the greatest value of this product. The utility function in itself is logarithmic
(rather than linear) and concave: a small increase in money should mean more to a poor
man than a millionaire. In the mid twentieth century, Von Neumann and Morgenstern
axiomatized the expected utility theory by providing a set of conditions that were
necessary and sufficient for expected utility (von Neumann and Morgenstern, 1944). One
such axiom is the Independence Axiom that was subsequently revised by Samuelson in
1952 (Samuelson, 1952). According to this axiom, if you prefer gamble A to gamble B,
then you should prefer the mixture of A and some other gamble C (in some probabilistic
proportion) to the mixture of B and C in the same proportion.

14

<-----Page 29----->Expected Utility theory assumes that the utility of a particular outcome is not
simply based on that outcome, but on the integration of that outcome with all wealth
accumulated till that point. Several anomalies have been associated with the predictions
of EU theory. The most common known examples is the Allais paradox, which
demonstrate clear violations of the independence axiom (Wu et al., 2004). The utility
function in EU models also cannot explain both gambling and purchasing of insurance,
simultaneous phenomenon demonstrated by most people in everyday life (Wu et al.,
2004).
Prospect Theory
Prospect theory consists of two components: a value function and probability
weighting function (Kahneman and Tversky, 1979).. The value function is concave over
gains and convex for losses with the slope being steeper in the loss domain, a feature
termed as loss aversion. It is important to highlight that the value function in prospect
theory is defined over relative changes in wealth rather than absolute wealth levels,
unlike the utility function in expected utility that is defined over finite wealth states. The
probability weighting function captures how different probability levels contribute to the
gamble. Specifically, prospect theory proposes that people tend to overweight smaller
probabilities and underweight medium and larger probabilities.
Prospect theory, therefore, suggests that people are risk seeking for gains
involving small probabilities and risk averse for medium to large probabilities. In the loss
domain, people are risk averse for small probabilities and risk seeking for medium to
large probabilities. This dichotomy can explain gambling and insurance purchasing
15

<-----Page 30----->behavior, both of which are associated with overweighting of lower probabilities.
However, prospect theory suffers from possible violations of stochastic dominance. A
gamble of the form (p, x; q, x-ε) could exceed (p+q, x) even though the later
stochastically dominates the first gamble, due to the shape of the weighting curves in
prospect theory. Prospect theory was also designed mainly for two-outcome gambles and
could not be readily extended to gambles with multiple outcomes. This forced researchers
to look for alternatives to prospect theory in the form of rank-dependent utility models
(Tversky and Kahneman, 1992).
Cumulative Prospect Theory
Many important risky decisions involve multi-outcome and mixed gambles,
consisting of both gains and losses, a key area that is not well addressed using Prospect
Theory. Also the evaluation of mixed gambles is more than just the sum of evaluation of
the individual gain and loss components. To address some of these concerns as well as
the violations of stochastic dominance, Tversky and Kahnemann proposed the
Cumulative Prospect theory (CPT), a rank-dependent utility model. While using the same
basic framework of the prospect theory, CPT involves application of a separate rankdependent transformation to the probabilities of the gain and loss portions of a gamble
(Tversky and Kahneman, 1992). Therefore, CPT can be applied to gambles that involved
an arbitrary number of outcomes unlike prospect theory, which was restricted to only two
non-zero outcomes. Several researchers have since focused on parameterizing the
weighting functions (Gonzalez and Wu, 1999). However, several new experiments have
shown violations of CPT in risky choice (Payne, 2005; Birnbaum, 2007, 2008b).
16

<-----Page 31----->Transfer of Attention Model
The Transfer of Attention (TAX) model represents the utility of a gamble as a
weighted average of the utilities of the consequences (or outcomes). The key idea is that
branches (multiple outcomes) compete for attention (Birnbaum and Bahra, 2007). In the
simplest scenario, the attention (weight) allocated to each branch will be directly
proportional to their probabilities, with the more probable outcomes getting more weight.
The model allows for transfer of attention from branch to branch according to the ranks
and consequences of the branches. Therefore, if a participant is risk-averse, branches
leading to lower valued outcomes can get enhanced weighting at the expense of attention
to the higher valued outcomes. The net sum of weight transfers is zero; that is, weight is
neither created nor destroyed but only transferred between branches (Birnbaum, 2008a).

1.5.2 Non-compensatory Models of Risky Choice: Priority Heuristic
The Priority Heuristic is a framework adapted from the fast and frugal heuristics
framework for inferences (introduced in detail in the next section) to explain people’s
preferences in risky choice (Brandstatter et al., 2006). The priority heuristic consists of (i)
a priority rule that involves going through several reasons (minimum gain, probability
of minimum gain, maximum gain) in order; (ii) a stopping rule that stops examination if
the minimum gain differs by 1/10 (or more) of the maximum gain or if the probabilities
differ by 1/10 (or more); and (iii) a decision rule that involves choosing the gamble with
the more attractive gain (or probability). The same rules can also be extended to the loss
domain for gambles involving gambles (Brandstatter et al., 2006).

17

<-----Page 32----->The proponents of the priority heuristic demonstrate its effectiveness in
outperforming CPT and TAX models. They argue that the complicated mathematics
behind the alternative CPT and TAX models makes them unlikely candidates for
explaining risky behavior. However, more recent analysis suggest that the priority
heuristics may not explain certain classes of data involving multi-outcome gambles and
shows systematic violations of stochastic dominance and distribution independence using
priority heuristic (Birnbaum, 2008b).

1.6 Risky Choice: Single or Multiple Strategies?
As introduced above, decision making differs across contexts and across
individuals. Different individuals will often respond differently to the same problem. The
same individual will respond differently to what appear to be subtle changes in problem
descriptions and environment. An ongoing debate in decision research is how to account
for these individual and contextual differences. One perspective argues for a single
decision strategy, with the observed differences in behavior explained in terms of
differences in parameter values. An alternative perspective is the multiple strategy view
which argues that individuals have access to a set of heuristic strategies that will be used
contingently as a function of problem type, individual’s prior experience, and individual
differences in capabilities and tendencies.
Over the years, theoretical perspectives have changed on this issue. Initially,
models like expected utility for risky choice, weighted additive models for multi-attribute
decision making, and Bayesian models for subjective probability judgments, all
supported the single strategy perspective. In these compensatory models, differences in
18

<-----Page 33----->choices across individuals and decision contexts are often explained by differences in the
parameter values associated with the corresponding model. Birnbaum (2008a) argues
strongly that every individual should be represented by the same expectation model in
which both individual differences and context differences across different problems types
are all explained by differences in parameters within that model. More recently, Newell
has argued for a more general purpose compensatory evidence accumulation process
where people are seen as acquiring information sequentially, forming updated valuations
of options based on the information, and then responding (making a decision) once a
threshold of evidence has been reached (Newell et al., 2004; Newell, 2005). The key
source of individual and problem differences is in the thresholds, and therefore the
amount of information acquired before a decision is reached.
The other general perspective on differences across individuals and problems is
captured by the adaptive toolbox metaphor (Payne et al., 1993; Gigerenzer and Goldstein,
1996). Under this view, it is believed that people have a large adaptive toolbox of
strategies available to them and they adaptively draw upon these heuristics depending on
context, individual differences and task structure (Payne et al., 1988; Gigerenzer and
Goldstein, 1996). Therefore, a large part of variability in decision making can be
explained by adaptive use of these heuristics, consistent with use of multiple strategies.
There is still considerable debate between the single and multiple strategy
approaches among judgment and decision-making researchers (Payne et al., 1992b;
Newell et al., 2004; Birnbaum, 2008a; Glockner and Betsch, 2010; Glockner et al., 2010;
Marewski, 2010). In the next chapter, I will address this debate and demonstrate the use
19

<-----Page 34----->of multiple strategies in decision making using converging experimental data from choice
proportions, eye tracking, response times and fMRI.

1.6.1 Demonstrating the use of Multiple Strategies in Risky Choice
When an individual solves a decision problem, how can one demonstrate that
multiple strategies are used in the process? One approach is to examine the outcomes of
the decision episode. However, differences in outcomes are neither necessary nor
sufficient. For example, different parameter values for a constant strategy could lead to
different choices. Similarly, different strategies could lead to the same decision for many
problems. A different approach is to focus on response times. Response times, however,
are only suggestive but not definitive regarding strategy differences. Different people
might use the same strategy but exhibit faster (slower) response times based on the
degree of confidence required or verification needed (see Montgomery (1983) for a
model of choice based on cycling through decision structuring) or simply differences in
the execution of a strategy (Lemaire, 2010).
Measuring information acquisition behavior using tools like Mouselab and eye
tracking has become a popular approach to investigating strategy differences in decision
making (Russo and Dosher, 1983; Payne et al., 1988). Yet, this approach is still only
suggestive and not definitive. One problem is that information acquisition often involves
two, and perhaps three, distinct phases. First, people essentially read or scan a problem to
get a sense of what the problem is all about. Second, people acquire information (often in
a selective fashion) as part of the evaluation of the information, a phase that is generally
seen as most relevant for strategy use (Johnson et al., 2008). Finally, there can also be a
20

<-----Page 35----->verification phase, where information related to the tentatively selected option is reexamined.
Recently, the nascent field of neuroeconomics (studying the neural bases of
decision preferences) has provided tremendous promise for advancing our understanding
of decision making (Glimcher, 2003; Platt and Huettel, 2008). Neuroscience can help
illuminate the neural mechanisms underlying decision preferences, particularly with
respect to individual variability in decision preferences (Venkatraman et al., 2011). By
carefully evaluating the underlying neural mechanisms, one can make inferences about
whether different choices arise from the use of same or different strategies. Additionally,
neuroscience can also provide insights into strategy selection and help answer the
metacognitive question of how people decide to decide. However, it is still a correlative
method with the activated regions being associated with and not necessarily essential for
the task. This often necessitates the need for additional follow-up behavioral experiments
to validate the findings (Huettel and Payne, 2009).
In summary, there is no one perfect method for detecting the use of multiple
strategies. Instead, there is a need for integrating evidence from multiple methodologies
to develop a complete understanding of decision strategies and individual variability. In
the next few chapters, I will present evidence in favor of a multiple strategy view of
decision making under risk using a multi-outcome risky choice task where participants
had the option to improve a mixed gamble by adding value to one of the outcomes. I will
use risky choice as it is one area of research where the evidence in favor of the single
strategy approach is strongest. Using data integrated across multiple experiments
21

<-----Page 36----->involving behavioral, neuroimaging and eye tracking methods, I will argue that there is
sufficient data to abandon the assumption of a single underlying calculus or strategy for
risky choice and replace it with the assumption of multiple strategies that are used
contingent upon the decision context and individual differences.

1.7 Summary
Several decades of research in the field of behavioral decision making and economics
have advanced our understanding about how people make decisions under uncertainty.
These studies also highlight the adaptive nature of these decisions. However, they leave
unanswered the question about the mechanisms that underlie these behavioral
phenomena. Understanding mechanisms provide a better understanding of how
judgments and choices are made. This is particularly true when the approach to
improving decisions is one of nudging people towards better judgments and choices
(Thaler and Sunstein, 2008). The central idea is that by knowing how people think we
can design choice environments that make it easier for people to choose what is best for
themselves, their families, and their society, without restricting freedom of choice. Weber
and Johnson (2009) make the similar argument that knowledge about the psychological
processes provides entry points for interventions designed to help people overcome
judgments or choices considered undesirable. Psychological process explanations of
decision behaviors are likely to be of increasing interest to policy makers and business
leaders. Therefore, the next few chapters are focused on experiments that seek to
elucidate the mechanisms underlying variability in decision making using multiple
methodologies like choice data, response times, eye tracking and neuroscience.
22

<-----Page 37----->2 Contextual and Individual Variability in Risky Choice
Most studies of risky choice use simple gambles of the form ($x, p; 0, 1 – p),
where one receives $x with probability p or $0 with probability 1-p (for reasons of
experimental control and simplicity, Luce (2010) refers to such gambles as “unitary”
gambles). Yet, more complex gambles with multiple gain and loss outcomes are needed
to simulate real-world decision scenarios (Lopes, 1995; Lopes and Oden, 1999). Complex
mixed gambles with more than two outcomes also inform researchers about underlying
models and strategies that guide behavior. The focus of this chapter is on a series of
behavioral and eye-tracking experiments that use a complex multi-attribute multiplealternative value allocation task. The findings from these experiments demonstrate
systematic variability in preferences across individuals and across what appear to be
subtle changes in problem descriptions and environments (decision context).

2.1 Value Allocation Task
In the original version of this task (Payne, 2005), participants were presented with
a five-outcome mixed gamble of the form G = [x1, p1; x2, p2; x3, p3; x4, p4; x5, p5], where
pi indicates the probability of monetary outcome xi. The outcomes were rank-ordered x1 >
x2 > x3 > x4 > x5, where at least two outcomes were strict gains (x1 > x2 > $0) and two
were strict losses (x5 < x4 < $0). The value of the middle, referent outcome (x3) varied
across trials, but is typically $0 or slightly negative. Participants then chose to improve
the base gamble by adding (allocating) a fixed amount of money (δ) to either one of the
extreme outcomes (x1 or x5), or the middle outcome (x3).

23

<-----Page 38----->Many of the models introduced in the earlier chapter make specific predictions to
the value allocation problem above (see section on consistency with economic models
below). For instance, the classic, compensatory, expected utility (EU) model predicts that
people would generally choose to add value to the lowest ranked (in terms of preference)
outcome, assuming that people are generally risk averse (i.e., a concave utility function).
CPT predicts that greater weight will be placed on both the extreme worst (x5) and best
outcomes (x1) that could occur, with the greater focus on the worse outcome, if the worst
outcome is a loss and the best outcome is a gain due to loss aversion. The transfer of
attention exchange (TAX) model makes a similar prediction as EU if the individual is
risk averse and the gambles have at least one gain outcome (Birnbaum and Bahra, 2007).
The order of attention is assumed to be reversed for strictly negative outcome gambles.
Even the non-compensatory priority heuristic predicts that people will select the option
that is better in terms of the extreme loss outcome. If there is no difference on loss
outcomes and probabilities, then people will select the option that is better on extreme
gain outcome (Brandstatter et al., 2006).
Yet, by adding amount to the intermediate ranked outcome, one can maximize the
overall probability of winning (Pmax)1. In the original study, more than 2/3 of the
participants preferred this option (Payne, 2005). The Pmax heuristic represents a clear
computational simplification for multi-outcome risky choice problems that can be
construed as responding to the “gist” (gain vs. loss) of an outcome value as compared to

1

The overall probability of winning (not losing) is defined across all outcomes and is not the probability of a single
outcome.

24

<-----Page 39----->aspiration or target level (Simon, 1955; Payne et al., 1980; Lopes and Oden, 1999; Shah
and Oppenheimer, 2008). This heuristic also ignores payoff magnitude information.

2.2 Variability in Preference for Probability-maximizing Heuristic
In two experiments, we modified the value allocation paradigm to explore, in
greater detail, individual differences in the bias toward maximizing the probability of
winning compared to losing (i.e., a probability-maximizing strategy). To match the
procedure of Payne (2005), participants chose among two of the above ways to improve
five-outcome mixed gambles, but those gambles were not resolved and participant
compensation was unrelated to their decisions.

2.2.1 E1: Individuals Demonstrate Bias towards Pmax Option
One hundred twenty eight young adults participated in this behavioral experiment
conducted at the Fuqua School of Business. All participants were compensated for their
participation in this study, and their payout was fixed ($8) and not related to their
choices. All participants provided informed consent as a part of a protocol approved by
the Institutional Review Board of Duke University.
Participants were presented with eight five-outcome mixed gambles on a
computer using the Psychophysics Toolbox program in MATLAB. Cognitive load was
also manipulated between participants by asking them to memorize 3 or 7-letter pseudowords for each trial. For all analyses, data was collapsed across both the load conditions
since we did not find any effect of load. First, each participant was presented with a risky
gamble and asked to rate its attractiveness. Subsequently, they were given two choices
for modifying the gamble, one of which always involved adding a fixed amount to the
25

<-----Page 40----->reference to change the overall probability of winning or losing (Pmax option) and
another which involved adding the same amount to either the extreme loss or gain
outcome (Vmax option). Participants were shown both versions of the modified gamble
on the screen beside each other and were asked to choose one of the options. There was
no time constraint for making the choice. In four gambles, the probabilities of the two
outcomes were matched (equal expected value) while for the remaining four gambles, the
probability associated with Pmax choice was less than the probability of the Vmax choice
by 5 or 10% (unequal expected value).
Results: As hypothesized, there were significant biases towards Pmax choice
(choice proportion = 0.69) when expected value was matched. Even when choosing the
Pmax option required sacrificing expected value (i.e., when the alternative option resulted
in a bigger increase in value and/or probability), individuals preferred the Pmax option in
59% of the trials. We also observed substantial inter-individual variability: some
individuals nearly always preferred the Pmax option; others nearly always preferred the
alternative Vmax option while still others switch based on both individual traits and
decision variables (Figure 2-1). Finally, the Pmax choices were also associated with
faster response times (Figure 2-2).

26

<-----Page 41----->E1: Prop. Pmax choices

Figure 2-1: Individuals demonstrated variability in bias towards Pmax
choices.

2.2.2 E2: Pmax Bias is Modulated by Decision Context
The second behavioral experiment (E2) manipulated the basic paradigm in three
ways – to maintain, eliminate, or exaggerate the probability-maximizing choice – to rule
out potential confounding factors and establish that these effects were indeed driven by
the need to maximize the overall probability of winning. Seventy one young adults
participated in a second behavioral experiment conducted at the Fuqua School of
Business. Compensation for participants was similar to the previous experiment. All
participants provided informed consent as a part of a protocol approved by the
Institutional Review Board of Duke University.
Participants were presented with eight five-outcome mixed gambles similar to the
first experiment on a computer. Four of these gambles were matched for expected value
and the other four were not. Additionally, participants were also presented with eight
gambles where adding value to the middle option did not involve a change in overall
27

<-----Page 42----->probability. In these Pmax-unavailable trials, we made one very subtle change to the
experimental design: we added or subtracted a small amount from the central choice
option (e.g., adding value to an option that was already $5 and not $0; or adding money
to an option that changes it from -$20 to -$5). Thus, there were no options in the gamble
whose selection would change the overall probability of success.
Finally, participants were presented with four additional trials where adding
values to the extreme loss or gain outcomes changed the overall probability of the
gamble. In these Pmax-exaggerated trials, we altered the basic gambles so that one of
options, if selected, would translate a certain loss gamble to an uncertain loss gamble (by
modifying an all loss-outcome gamble to a gamble with one gain outcome) or translate an
uncertain gain gamble to a certain gain gamble (by modifying a gamble with one loss
outcome to an all gain-outcome gamble). These gambles were created by selecting two
basic gambles from the set of four equal expected value core problems above and
transposing them by adding or subtracting a constant value from all outcomes. For e.g.,
the core gamble: [60, 0.2; 45, 0.2; -20, 0.2; -40, 0.2; -80, 0.2] was transposed it to the new
gamble: [130, 0.2; 115, 0.2; 50, 0.2; 30, 0.2; -10, 0.2] and participants were given a
choice between adding $30 to the -$10 option (making it a certain win gamble) or to the
$50 reference option (which would correspond to the Pmax option in the untranslated
version).
Results: In the control trials, which replicate the design of the first behavioral
experiment, participants still showed a systematic bias (65%) towards the Pmax choices.

28

<-----Page 43----->Again, the preference for Pmax response reduced slightly (58%, but was still the majority
response) when it was associated with lower expected value.

Figure 2-2: Participants were faster for overall probability maximizing
choices
In the critical Pmax-unavailable trials, we found a significant shift in the pattern
of participants’ choices: participants now chose the option nearest to $0 only 39% of the
time. This result provides confirmation that many participants do preferentially select the
choice that improves the overall probability of winning when it is available, but readily
switch to magnitude-sensitive choices otherwise. Moreover, these results also indicate
that the choices of participants for these mixed gambles cannot be explained solely by
parameters within standard descriptive economic models, because the addition of $5 to
one option of a complex, large-magnitude gamble should have negligible effects upon the
predictions of those models. Finally, in the Pmax-exaggerated trials, participants
overwhelmingly preferred the probability-maximizing option (83%). Thus, our
behavioral data not only demonstrate the robustness of the preferences toward the Pmax
29

<-----Page 44----->choices, but more importantly that this bias can be reversed or accentuated by
experimental manipulations.
Consistent with our first behavioral experiment, we also found substantial interindividual variability in this participant population. Again, Pmax choices were associated
with faster response times (Figure 2-2). To identify potential individual trait correlates of
this strategic variability, we collected psychometric data that included tendency toward
satisficing (Schwartz et al., 2002) and emotional sadness (Fordyce, 1988). Across our
participant sample, increased maximizing trait responses predicted a decreased bias
toward probability-maximizing choices (r = -0.26; p < 0.05). In other words, satisficers
preferred the probability-maximizing choices more than maximizers, consistent with
these choices representing a simplifying strategy. Similarly, an increase in the sadness
trait measure also predicted a decreased bias towards probability maximizing (r = -0.29;
p < 0.05). Sadness has also been typically associated with reduced certainty, increased
elaboration and reduced heuristic processing (Schwarz et al., 1991; Bodenhausen et al.,
1994).

2.2.3 Pmax Choices are Consistent with a Simplifying Strategy
Across both experiments, we find four lines of evidence that support the view that
Pmax choices represent an effort-reduction simplifying strategy. First, Pmax choices
were significantly faster in terms or response times, as would be expected of a less
effortful strategy. Second, individual differences in the preference for Pmax were
significantly and negatively correlated with a trait measure of maximizing in E2,
consistent with effort-reduction. Third, individual variability in proportion of Pmax
30

<-----Page 45----->choices also significantly and negatively correlated with a trait measure of sadness in E2,
consistent with sadness being associated with reduced heuristic processing (Schwarz et
al., 1991; Bodenhausen et al., 1994). Finally, the proportion of Pmax choices decreased
with increasing cost in terms of expected value. Together, these findings are consistent
with Pmax representing a simplifying strategy. Additionally, as discussed below in the
comparison of choice models, these choices were also inconsistent with compensatory
models like expected utility and cumulative prospect theory.
In summary, we show a consistent strong bias towards probability-maximizing
choices across two independent experiments. Within participants, we demonstrate that
this bias is indeed related to the overall probability of winning and that it can be
attenuated or exaggerated by subtle manipulations in decision context. Across
participants, we show that differences in decision strategies can be explained by
individual variability in trait measures like satisficing. Taken together, these strategy-trait
relationships suggest that the robust individual differences in these risky choice
paradigms (and, presumably, other settings) may reflect measurable cognitive or affective
differences across individuals. This bias towards probability-maximizing choices is also
consistent with a recent dual-criterion model for risky choice (Diecidue and van de Ven,
2008), in which an overall probability criterion can be traded off against other decision
variables.

2.3 Evaluations of Consistency with Economic Models
Given the overall bias towards the probability-maximizing strategy in the
previous experiments, we next sought to explicitly evaluate whether choices associated
31

<-----Page 46----->with this response strategy were consistent with traditional economic models such as
Expected Utility (EU) maximization and Cumulative Prospect theory (CPT). For this test,
we used data from 72 trials of the value allocation task, collected during an fMRI study
with 23 participants (the neural data and details about the gambles are discussed in
greater detail in the next chapter). Unlike the two behavioral experiments, the fMRI
experiment used an incentive-compatible payment method such that participants were
provided an initial unknown but fixed endowment and were later paid for a subset of their
improved gambles, selected randomly. Despite the large number of trials and incentivecompatible nature, we still found a strong bias for Pmax option with participants
choosing this option in about 70% of the trials when expected value was balanced.
Our model comparisons used both standard and free parameters for the EU and
CPT models. All gambles used in this study were of the form G = [x1,p1; x2,p2; x3,p3;
x4,p4; x5,p5]. The expected utility (EU) of each gamble is given by:

 xi β , xi ≥ 0

EU = ∑ u ( xi ) pi , where u ( xi ) = 
.
− | xi |1+(1− β ) , xi < 0
i =1
5

The cumulative prospect theory (CPT) predictions were obtained using:
 xi β , xi ≥ 0

CPT = ∑ v( xi )c(i ) where v( xi ) = 
,
− λ | xi | β , xi < 0
i =1
5

32

<-----Page 47----->w + ( pi ), i = 1



i −1


 +  i

+



w  ∑ p j  − w  ∑ p j , i = 2,.., k ( gains) 
  j =1 

 j =1 
c(i ) = 
,
5



 −  5

−



w  ∑ p j  − w  ∑ p j , i = k + 1,..,4 (losses)
 j =1+1 
  j =i 

−
w ( pi ), i = 5

pγ

+

w ( p) =

+

+

pγ

−

+

[ p γ + (1 − p ) γ ]

1 +

γ

and w ( p ) =

−

−
−

[ p γ + (1 − p ) γ ]

1 −

γ

For the first level of model comparisons, we used parameters drawn from the
prior literature. The EU model used a concave utility function with β = 0.88. For the CPT
model, we used parameter values of γ+ = 0.61, γ- = 0.69 and λ = 2.25 (Tversky and
Kahneman, 1992; Tversky and Fox, 1995). Despite these standard parameters, neither
model was a good predictor of participants’ aggregate choices. As one example, consider
a trial on which a participant chooses whether to add a fixed amount of money either to a
large negative outcome (e.g., -$75) or to a middle outcome of $0, each of which is
equally likely to occur. Both EU and CPT models predict that participants should always
add the money to the large negative outcome (i.e., minimizing the worst loss). However,
participants showed an opposite effect, adding money to the middle outcome 68% of the
time (i.e., typically making a probability-maximizing choice). This and other
observations indicated that participants’ behavior in these experiments was inconsistent
with standard model predictions.

33

<-----Page 48----->To account for potential individual differences in model parameter values, we
performed a robustness check using a split-sample analysis. We used one half of the
choices of each participant to estimate model parameters: for EU, β; and for CPT, β and
γ, keeping λ fixed at 2.25. We also simplified the equation for CPT in our estimation by
assuming γ+ = γ-. We then assessed the performance of the EU and CPT models by
estimating the reliability of the fitted model in predicting the other half of that
participant’s data. We found that parameters estimated from one half of the sample
showed poor reliability in predicting choices in the complementary sample (EU:
Cronbach α=0.37; CPT: α=0.39). However, the proportion of probability-maximizing
choices was much more reliable across the two samples (α=0.78), indicating that
participants remained highly consistent in their strategy preference across the experiment
(Figure 2-3).

Figure 2-3: Robustness of various models in predicting choices across trials

We stress that these results should not be interpreted to imply that the probabilitymaximizing strategy provides a new, better, and general model of risky choice behavior.
34

<-----Page 49----->On the contrary, this particular simplifying strategy only applies to a subset of decision
problems – those that involve comparisons between similar gambles that differ in their
overall probability of winning – and cannot be used for choice problems that involve only
gains or only losses, or that involve constant probability of winning. In such cases, people
may use other heuristic strategies such as the Priority heuristic (Brandstatter et al., 2006)
that focuses more on the outcomes of the gambles. We do suggest that, under certain
contexts, most individuals adopt heuristic decision strategies not encapsulated in standard
models (but see Birnbaum, 2008a).

2.4 E3: Eye-tracking Evidence for Multiple Strategies†
As discussed in Chapter 1, eye tracking provides a more natural environment for
studying decision processes, thereby not hindering automatic processing when required.
Fixation durations obtained using eye tracking provide additional insights into underlying
cognitive processes: shorter fixations are typically associated with implicit and automatic
processing while longer fixations are associated with deeper processing (Glockner and
Herbold, 2011). One can also obtain a measure of pupil dilation using eye tracking which
in turn provides information about emotional and cognitive processing (Siegle et al.,
2003a; Siegle et al., 2003b). For these reasons, we chose to use eye tracking as the
primary process tool to understand decision strategies.
In this study, we focused primarily on the following eye-tracking variables:
number of data acquisitions (a fixation longer than 60mecs on the same cell was

†

The contents of this chapter are part of a working paper “Venkatraman V, Payne JW and Huettel SA. Contextual and
individual variability in risky choice: eye-tracking evidence for multiple strategies.”

35

<-----Page 50----->considered a data acquisition), duration of time spent on each of the decision variables,
and the sequence of information acquisition for each trial. To account for differences in
response times across trials and individuals, we normalized the amount of time spent on
each of the cells by the response time for that trial. Therefore, our normalized gaze
duration measure represents the proportion of time participant spent on a particular cell,
relative to the others within a trial.
Participants and Procedures
A total of thirty six young adults participated in this study. We obtained eye gaze
information as participants made a series of choices on value allocation problems of the
kind introduced above. All stimuli were created using the Psychophysics toolbox in
Matlab and were presented to the participant sitting in front of a Tobii 1750 eyetracker
system. We used a dual computer set up where stimulus was presented using Matlab
running on one computer while eye gaze information was collected using Tobii’s
Clearview software running on an independent computer. Time stamp information stored
in both programs was then used to synchronize the stimulus presentation with the eye
gaze information for subsequent data analysis. Participants used a standard computer
keyboard to indicate their responses. We positioned the participants’ fingers on the
appropriate keys at the beginning of the experiment to minimize eye movements to the
key board on every trial. Each experimental session lasted an hour and participants were
compensated $10 in exchange for their participation. All participants gave written
informed consent as part of the experimental protocol approved by the Institutional
Review Board of Duke University.
36

<-----Page 51----->In the first part of the experiment, participants were presented with a total of
thirty-two three-outcome gambles. Each gamble typically consisted of one large gain
outcome, one large loss outcome and a third intermediate outcome that was either a small
gain, $0 or a small loss. Each outcome was associated with its own probability ranging
from 0.15 to 0.4 across trials. On each trial, participants first rated each gamble on a scale
of 1 to 5, with 1 corresponding to “least preferred” and 5 corresponding to “most
preferred”. Participants could take as long as they needed to rate the gamble. After rating
the gamble, participants were presented with a fixed amount of money that they could
add to any one of the three outcomes to improve the gamble. In other words, on each
trial, participants could choose to increase the magnitude of the highest gain (gainmaximizing, Gmax), decrease the magnitude of the worst loss (loss-minimizing, Lmin) or
improve the overall probability of winning money compared to losing money
(probability-of-winning maximizing, Pmax).
During the decision phase, the resulting three modified gambles were displayed in
the form of a 4x4 grid matrix, where the first row corresponded to the probabilities and
the remaining three rows correspond to the three modified gambles, labeled G1, G2 and
G3 (Figure 2-4). For each trial, the mapping of these labels to Gmax, Pmax and Lmin
choices was performed in a pseudo-random manner. However, the three outcomes were
always presented in a rank-ordered manner with the first column representing gains and
last column representing losses. Participants indicated their response by pressing the keys
corresponding to their preferred choice. There were no time constraints for indicating
their choice, and no feedback was provided at the end of each trial.
37

<-----Page 52----->Figure 2-4: Schematic of stimuli and sample of eye-gaze movements (box
numbers represent sequence and size represents normalized gaze duration).
Experimental Stimuli
The first two trials were kept constant across all participants. These problems
were essentially practice trials that allowed the participants to familiarize with the
decision environment and were excluded from all subsequent analyses. The remaining
thirty trials were randomized across participants. These trials fell into the following five
categories:
•

Twelve gambles, where all three outcomes were associated with the same
probability (Equal expected value).

38

<-----Page 53----->•

Six gambles, where probabilities differed across the different outcomes,
leading to differences in expected value (Unequal EV). The intermediate
outcome was always associated with a lower EV, compared to the other two
alternatives.

•

Eight Pmax-unavailable gambles, where the adding money to the intermediate
option did not change the overall probability of winning. Four of these trials
had equal probabilities across all attributes, whereas the remaining four had
unequal probabilities.

•

Four Pmax-exaggerated trials, which were obtained by first translating the
initial gamble by adding or subtracting a fixed amount to each of the
outcomes. Since there were very few of these trials for full analysis, they are
not discussed further here.

Since the natural reading order is from left-to-right, we randomized the format in
which gambles were presented between participants. For one half of the participants,
stimuli were presented in a horizontal format where rows (alternatives) represent the
gambles and columns (attributes) the probabilities. For the other half, stimuli were
presented in a vertical format where gambles were represented along columns and
probabilities along the rows. Finally, to prevent fatigue-related effects towards the end of
the experiments, participants were provided with an option to take a break after
completing half of the trials.

39

<-----Page 54----->Analysis
We had two primary objectives in this study. First, we sought to evaluate the
performance of several popular models of risky choice like CPT and PH in predicting
choice preferences and process measures in the value allocation task. Second, we sought
to dissociate between the use of single or multiple strategies in risky choice.
For each eye-tracking variable, we ran individual GLM analyses for each of our
variables of interest. On each trial, participants were presented with a 4x4 matrix of
information. We restrict most of our analyses to the three unique cells (cell Cwin which
contains the highest gain outcome, Cinter which contains the highest intermediate outcome
and Closs which contains the lowest loss). Therefore, we analyzed the effect of OPtype
(Pmax-available and Pmax-unavailable), EVtype (equal probabilities and unequal
probabilities), Choice (Gmax, Pmax, Lmin), Strategy Type (Pmax-Preferring or non
Pmax-Preferring participants), Presentation format (Horizontal, Vertical) and their
interactions on the following factors: Response times, normalized duration on the three
unique cells (Cwin, Cinter, Closs), total number of acquisitions and Payne Index (which
measures the pattern of transitions).
Hypothesis
Choice Hypothesis
H1a (CPT, PH): Across all trials, participants should show a greater preference for
alternatives that improve the extreme gain or extreme loss outcomes. There should be
no difference in preferences between Pmax-available and Pmax-unavailable trials.

40

<-----Page 55----->H1b (Pmax-heuristic): Participants will show a greater preference for Pmax
alternative for trials where the option is available. But their preference should shift to
other alternatives in the Pmax-unavailable trials.
Response Time Hypothesis
H2a (PH): Since the number of reasons to be considered does not change across trials
(there is always an option in our stimuli that is significantly better on the worst loss
outcome), the response times should be similar across all trials.
H2b (CPT): Since participants are employing the same computations in all cases, the
response times should be same across all trials.
H2c (Pmax): Participants should be faster in the Pmax-available trials since they can
easily apply the heuristic compared to Pmax-unavailable trials. Decisions should also
be faster in the Equal EV trials compared to Unequal EV due to reduced conflict
between multiple strategies. Finally, participants should be faster when choosing the
Pmax alternative relative to other choices, consistent with a heuristic strategy.
Information Processing Hypothesis
H3a (PH): The total amount of information inspected should be similar across all
trial types for the same reasons discussed under response times. Within each trial, the
fixations are biased towards the loss attributes.
H3b (CPT): The total amount of information inspected should be similar across all
trial types and the fixations should be distributed across all cells.
H3c (Pmax): The amount of information inspected changes as a function of trial
types. Participants process more information in the Pmax-unavailable trials.
41

<-----Page 56----->Participants process more information for the equal EV trials, particularly relying
more on probability information in these trials. Finally, the total proportion of time
spent on each cell will be correlated with the final choices.
Sequence of Processing
H4a (PH): Information processing is mainly attribute-based. Participants use a
reasoning rule and choose the gamble that is better in terms of that rule. Processing
does not vary as a function of trial types.
H4b (CPT): Information processing is mainly alternative-based. Since participants
are trying to estimate weighted additive information about each gamble, transitions
are mostly within alternatives. Processing does not vary as a function of trial types.
H4c (Pmax): Information processing is mainly alternative-based. Participants are
trying to determine the probabilities of all the good and bad outcomes before
choosing the alternative with the best chance of good outcomes. For Pmaxunavailable trials, since this rule does not distinguish between the gambles, additional
information is acquired using other strategies.
Single vs. Multiple Strategy
H5a (Single): Under the single strategy view, participants should acquire all
problems in a similar manner and choose based on computational differences.
Therefore, we should see no significant differences in eye tracking measures when
participants shift from preference for one alternative to another across trials.

42

<-----Page 57----->H5b (Multiple): There would be a significant cost associated with shifting away
from a preferred strategy across trials. Such a cost will be present in terms of response
times and amount of information acquisition.
Pattern Changes across Time
H6a (PH): Participants will start with an initial screening and continue with a more
thorough inspection of information.
H6b (CPT): Participants will make decisions based on a thorough inspection of all
information provided in a systematic manner.
H6c (Pmax): Participants will make decisions based on an initial screening of key
cells followed by increased processing of additional information as a function of
problem type. Therefore we should see a shift from short to long fixations across the
course of each trial.
Results
Choice Data and Response Times
Table 2-1: Choice proportions varied as a function of experimental
conditions.
Condition Type

Pmax_Available

Pmax_Unavailable

Equal EV

Unequal
EV

Equal EV

Unequal
EV

Proportion of Pmax Choices

0.69

0.52

0.41

0.36

Proportion of Lmin Choices

0.23

0.36

0.44

0.44

43

<-----Page 58----->We found a significant effect of EVtype (χ2 = 12.97, p<0.001) and OPtype (χ2 =
47.65, p<0.001) on choice proportions as well as an EVtype x OPtype interaction (χ2 =
7.81, p=0.02). For the Pmax-available trials, the bias for Pmax choices was greater in the
Equal EV trials, but was still the preferred choice even in the Unequal EV trials (Table 21). Therefore, like previous experiments, participants preferred the Pmax option, even
when it involved sacrificing expected value. There was no significant effect of
presentation format on choice preferences. Importantly, the preference to add value to the
intermediate outcome was not present in the Pmax-unavailable trials, suggesting that
participants were willing to switch to a different strategy based on decision context. In
fact, we found a inverted-U shaped preference for the middle outcome as a function of
the change in valence, with smallest preference when there is no change in valence and
greatest preference for a complete change in valence from a loss to a gain (Figure 2-5).
These findings are inconsistent with predictions of CPT and PH, leading us to reject
hypothesis H1a in favor of H1b.
We also found significant variability in preference for the Pmax-heuristic across
individuals with some participants always preferring to use this heuristic and others
almost never (Figure 2-6). To investigate the effects of individual differences further, we
split our participants into two groups based on the proportion of Pmax choices in the
Pmax-available trials. Participants who preferred the Pmax choices in more than 2/3rd of
the trials were classified as Pmax-preferring and the rest as non Pmax-preferring strategy
type. Next, we sought to explore the interaction between individual variability (Strategy
type) and problem type (EVtype and OPtype) on preference for Pmax-heuristic.
44

<-----Page 59----->Specifically, under the multiple strategy view, the Pmax-preferring individuals should be
more sensitive to OPtype and less sensitive to EVtype. Similarly, the non Pmaxpreferring individuals should be more sensitive to EVtype and less sensitive to OPtype.
Consistent with these predictions, we found a significant Strategy Type (individual
difference) x OPtype (problem type) x EVtype (problem type) interaction (Table 2-2).

Table 2-2: Proportion of Pmax choices varied as a function of both individual
variability and problem type.
Pmax_Available

Pmax_Unavailable

Equal EV

Unequal EV

Equal EV

Unequal EV

Pmax-Preferring

0.96

0.83

0.56

0.63

Non Pmax-Preferring

0.52

0.31

0.39

0.24

Figure 2-5: Preference for the Pmax-heuristic was modulated by valence
changes.
45

<-----Page 60----->Figure 2-6: Variability in preference for Pmax choices across individuals.
Response Times
The analysis of choice proportions showed evidence for differences in strategy
use differences as a function of problem type and individual differences. In terms of
response times, we found a main effect of EVtype (F=6.32, p = 0.01) and OPtype
(F=4.40, p = 0.03). As expected, participants were slower for unequal EV compared to
equal EV trials and slower for Pmax-unavailable trials relative to Pmax-available trials
(Figure 2-7). Interestingly, we also observed a main effect of Choice on response times
(F=3.06, p < 0.05). Overall, participants were slowest for Pmax relative to Lmin and
Gmax choices. There was also a significant OPtype x Choice interaction (F = 2.93, p <
0.05) with participants being significantly faster for Pmax choices only in the Pmaxavailable trials (Figure 2-7). Together, these findings are again consistent with
hypothesis H2c and inconsistent with hypotheses H2a and H2b.

46

<-----Page 61----->Figure 2-7: Response times showed a significant effect of EVtype, OPtype,
Choice and a significant OPtype x Choice interaction.
Measuring Information Acquisitions
Number of Acquisitions: We found a main effect of OPtype on information acquisition:
individuals acquired lesser information for the Pmax-available trials compared to Pmaxunavailable, rejecting both hypotheses H3a and H3b (Table 2-3). Pmax choices were also
associated with lesser number of acquisitions, particularly for the Pmax-available trials
though the interaction was not statistically significant. We did not find any significant
interactions of this effect with EVtype.
Table 2-3: Average number of acquisitions varied as a function of choice and
OPtype
Choice

Gmax

Pmax

Lmin

# Acquisitions (Pmax-available)

18.13

14.81

16.45

# Acquisitions (Pmaxunavailable)

17.95

18.03

16.71

47

<-----Page 62----->Normalized Duration: Overall, valid fixations accounted for about 80% of the response
times within a given trial. In terms of normalized durations, we found that participants
spent very little time processing the probabilities during the decision-making phase,
relative to the values (less than 5% of total trial time). This is because the probabilities
are introduced in the first stage and do not change subsequently. Yet, there was a
significant main effect of EVtype on the gaze duration of probability values, with
participants acquiring more information about probabilities in the unequal EV trials
relative to equal EV trials.
We also found that choices on each trial were predicted by the magnitude of gaze
duration for each of the corresponding unique attributes. In other words, Gmax choices
were associated with increased processing of the cell that had the greatest gain value,
Lmin choices with the cell that had the lowest loss value and Pmax with the intermediate
cell that was different in valence from the other two (Figure 2-8). Not surprisingly, there
was in general greater amount of time spent on the intermediate attributes, which could
be a function of the fact that these were always in the middle and hence participants had
to pass through this column when moving from gains to losses. These findings are
inconsistent with PH hypothesis H3a (which states that the loss attributes receive the
greatest amount of processing) as well as CPT hypothesis H3b (which states that
processing is distributed equally across all cells).

48

<-----Page 63----->Figure 2-8: Normalized Gaze durations indicated a significant bias in
processing for cells that had the most unique information for the final choice.
Sequence of Acquisitions (Payne Index): One of the primary advantages of using eye
tracking is that it provides access to the sequence (path) in which information is acquired,
in addition to magnitude of processing. We simplified the sequence of acquisitions by
estimating the Payne Index, which is defined as the normalized difference between the
numbers of alternative- and attribute-based information acquisitions for the nine-payoff
cells. A positive value for this index indicates more alternative-based processing and a
negative value indicates more attribute-based processing. We found a main effect of
OPtype (F = 6.03, p=0.01) and Choice (F = 10.99, p<0.001) on the Payne Index. We
found that participants make relatively more alternative-based transitions for Pmaxavailable than Pmax-unavailable trials, as well as when selecting the Pmax option relative
to the other choices (Table 2-4). More importantly, we found that an overall estimate of
the Payne Index for each participant was significantly correlated with the proportion of
49

<-----Page 64----->Pmax choices made by that participant (r2=0.43, p<0.05, Figure 2-9). Importantly, this
correlation was true only for the Pmax-available trials and not for the Pmax-unavailable
trials (r2=0.3, n.s.). These results suggest that Pmax choices represent some form of a
counting strategy, where participants are estimating the probabilities of good relative to
bad outcomes in Pmax-available trials. However when such a strategy does not
distinguish between the choices, as in the Pmax-unavailable trials, participants shift to
other strategies to decide on an alternative.
Table 2-4: Significant effect of OPtype and Choice on Payne Index
Choice

Gmax

Pmax

Lmin

Payne Index (Pmax-available)

0.05

0.22

0.04

Payne Index (Pmax-unavailable)

0.11

0.10

0.05

Figure 2-9: Payne Index was significantly correlated with the proportion of
Pmax choices across individuals only for the Pmax-available trials.
50

<-----Page 65----->Due to a strong bias in everyday reading order (left to right), one explanation for
the increased alternative-based processing is a bias due to natural reading order.
However, to address this concern, we randomized the presentation of gambles between
participants with half the participants receiving alternatives along rows and other half
along columns. When we analyzed these groups separately, we did find a main effect of
presentation format (F = 83.7, o < 0.001) with participants in the alternatives-along-rows
(horizontal) group making more alternative-based transitions (Table 2-5). However, this
effect did not interact significantly with choices (F = 2.1, n.s.). In other words,
independent of presentation format, the Pmax choices were associated with more
alternative-based processing than the other choices.

Table 2-5: The presentation format did not interact with Choices.
Pmax-available trials

Gmax

Pmax

Lmin

Payne Index: Horizontal

0.21

0.32

0.20

Payne Index: Vertical

-0.13

0.12

-0.13

Combining choice and information acquisition measures
We performed a stepwise trial-by-trial logistic regression analysis using PROC
LOGISTIC in SAS to see if the eye tracking variables improved the prediction of choices
on each trial. For this analysis, we tried to predict whether or not the participant made a
Pmax choice on a given trial. We assessed the effect of decision context variables like
EVtype and OPtype, as well as eye tracking variables like normalized durations of the
51

<-----Page 66----->three unique cells (Cwin, Cinter and Closs) and the Payne Index on trial-by-trial choices. We
found, not surprisingly, that OPtype and EVtype were significant predictors of choice (R2
= 0.09). When we then introduced the normalized durations into the model, these
variables lead to a significant improvement in the model (R2 = 0.15). Importantly, the
relative duration of time spent on the unique intermediate cell (Cinter) was a significant
predictor of Pmax choices and the unique loss attribute cell (Closs) was a significant
negative predictor of Pmax choices. The unique gain cell (Cwin) did not predict choice,
presumably due to the smaller proportion of Gmax choices overall. Finally, when we
introduced the Payne Index, the overall model fit improved further (R2 = 0.18) with the
Payne Index also significantly predicting choices. (Note that the results were the same
when Payne Index was introduced before the normalized durations.) All results are
summarized in Table 2-6.
It could be argued that the results above are confounded by correlated data arising
from repeated trials within a participant. This prevents the observations from being truly
independent, leading to invalid statistical inferences. To address this concern, we
repeated the same analysis using PROC GENMOD in SAS which allows for repeatedmeasures, but not in a stepwise manner. Using this procedure, we still found that all
variables that we significant earlier were still significant, validating our findings from
before.

52

<-----Page 67----->Table 2-6: Results from stepwise logistic regression of trial-by-trial choice
preferences.
Parameter
Estimate

Wald Chisquare

P-value

Participant

-0.008

1.64

0.2

EVtype

-0.25

12.03

0.0005

OPtype

-0.46

36.27

<0.0001

Duration (Cwin)

-1.58

3.06

0.144

Duration (Cinter)

2.44

13.43

0.0002

Duration (Closs)

-3.29

17.25

<0.0001

Payne Index

0.71

18.05

<0.0001

Strategy Type
Here, we sought to explore how differences in strategic preferences across
individuals related to process measures obtained from eye tracking. We found a
significant Choice x Strategy type interaction on response times (F = 5.39, p=0.02),
number of acquisitions (F = 6.18, p=0.01), as well as the Payne Index (F = 17.83,
p<0.001, Table 2-7). Particularly, the Pmax-preferring participants took longer, and
acquired more information when making a non Pmax choice (Figure 2-10). Similarly, the
non Pmax-preferring participants took longer, and acquired more information when
making Pmax choices. The non Pmax-preferring participants were also more alternativebased when switching to a Pmax choice. Taken together, these findings are inconsistent
with the single strategy hypothesis H5a and instead argue for a multiple strategy
53

<-----Page 68----->viewpoint hypothesis H5b. We also found similar evidence in our neuroscience study
using a similar paradigm, with increased activation in the dorsomedial prefrontal cortex
region of the brain when individuals switched away from their preferred strategy
(Venkatraman et al., 2009b). We will return to the implications of these findings for
strategy selection in the later chapters when talking about neural data.
Table 2-7: Significant Choice x Strategy Type interaction on response times,
number of acquisitions and Payne Index
All Trials

Pmax-preferring

Non Pmax-preferring

Pmax

Non Pmax

Pmax

Non Pmax

Number of acquisitions

15.1

20.87

16.39

15.11

Response Times (s)

5.97

8.29

6.83

6.42

Payne Index

0.17

0.20

0.23

-0.01

Figure 2-10: Individuals demonstrated a greater cost for moving away from
a preferred strategy on a particular trial.
54

<-----Page 69----->Acquisition Patterns across Time within and across trials
To explore how eye-tracking variables change as a function of time within each trial, we
divided each trial into four phases based on the total number of fixations for that trial. We
restricted our analyses to Pmax-available trials only. One conjecture is that participants
employ a more exploratory strategy at the beginning of the trial and a more accumulative
or analytic strategy towards the end. As expected, we found that the dwell times
increased during the course of the trial, consistent with hypotheses H6a and H6c and
inconsistent with CPT hypothesis H6b. In other words, the average duration of each
fixation was greater during the later part of each trial, consistent with a shift from
exploratory information gathering phase (shorter duration) to an information processing
and analysis phase. Both the priority heuristic and Pmax-heuristic predict such a pattern
of information acquisition. We also observed that participants shifted towards more
alternative-based processing later in the trial (Table 2-8), again consistent with the
overall probability focused strategy. Note however that this later result is inconsistent
with PH hypothesis H6a, which suggests that individuals should still process information
based on attributes.
Table 2-8: Dwell times indicated a shift from exploratory to deliberative
processing
Bin

Q1

Q2

Q3

Q4

Dwell Time (msec)

279

293

304

371

Payne Index

0.03

0.14

0.21

0.30

55

<-----Page 70----->2.5 E4: Replication of Eye-tracking Results
A total of fifteen young adults participated in this study. Most experimental
procedures were similar to experiment 3 (E3). The key change from the first experiment
was that the columns were no longer rank-ordered. Instead, the locations of gain, loss and
intermediate outcomes were randomized across trials in addition to randomizing the
alternatives. Therefore, there were a total of pre-determined nine orders in which the
three three-outcome gambles were presented to each participant across trials. This
explicitly avoids the attentional bias to the intermediate outcomes by virtue of them
always being in the middle column. The number of problems in each category was also
slightly varied (ten equal EV Pmax-available trials, 12 unequal EV Pmax-unavailable
trials, 4 Equal Pmax-unavailable trials and 4 unequal EV Pmax-unavailable trials).
We were primarily interested in investigating the effect of complete
randomization on the amount of processing for each of the three unique cells. Specifically
for this replication, we hypothesized that there will no longer be a bias on the
intermediate cells for trials where participants were not making the Pmax choices. We
also sought to replicate the effects of trial-by-trial logistic regression analyses, to confirm
that eye-tracking variables do indeed improve the overall model prediction.
Results
Behavior in this experiment was consistent with previous findings with
individuals showing a strong bias for Pmax choices (53% overall; 67% for equal EV and
40% for unequal) in the Pmax-available trials, followed by Gmax (24%) and Lmin
(23%). We found a stronger preference for Gmax choices in this experiment relative to
56

<-----Page 71----->E3. Like E3, we found that choices on each trial were correlated with the magnitude of
gaze duration for each of the corresponding unique attributes. In other words, Gmax
choices were associated with increased processing of the cell that had the greatest gain
value, Lmin choices with the cell that had the lowest loss value and Pmax with the
intermediate cell that was different in valence from the other two (Figure 2-11).
However, as hypothesized, there was no longer a greater bias for the intermediate
outcome.

Figure 2-11: Normalized gaze durations indicated a significant bias in
processing for cells associated with the final choice.
We also performed a stepwise trial-by-trial logistic regression analysis, similar to
E1. We sought to predict whether or not the participant made a Pmax choice on a given
trial. We assessed the effect of decision context variables like EVtype and OPtype, as
well as eye-tracking variables like normalized durations of the three unique cells (Cwin,
Cinter and Closs) and the Payne Index on trial-by-trial choices, controlling for repeated57

<-----Page 72----->measures across participants. Consistent with E1, we found that OPtype and EVtype were
significant predictors of choice (R2 = 0.13). When we then introduced the normalized
durations into the model, these variables lead to a significant improvement in the model
(R2 = 0.37). Importantly, duration of processing on Cinter was a significant predictor of
Pmax choices, while duration on cells Cwin and Closs were significant negative predictors
of Pmax choices. Note that the unique gain cell Cwin was also a significant predictor in
this experiment unlike E1, possibly due to an increase in Gmax choices in this group of
individuals. Finally, when we introduced the Payne Index, the overall model fit improved
further (R2 = 0.39) with the Payne Index also significantly predicting choices. (Note that
the results were the same when Payne Index was introduced before the normalized
durations.) All results are summarized in Table 2-9.
Table 2-9: Result summary from stepwise logistic regression for E4
Parameter
Estimate

Wald Chisquare

P-value

Participant

0.02

6.02

0.01

EVtype

-0.58

26.09

<0.0001

OPtype

-0.27

4.61

0.03

Duration (Cwin)

-3.06

10.18

0.001

Duration (Cinter)

7.04

32.01

<0.0001

Duration (Closs)

-2.55

8.50

0.003

Payne Index

0.75

10.29

0.001

58

<-----Page 73----->2.6 General Discussion
Using choice proportions, response times and process measures obtained using
eye tracking, we demonstrate that individuals shift between multiple strategies as a
function of decision context and individual variability. We also showed that the process
information obtained using eye tracking helped significantly improve choice predictions
on a trial-by-trial level, over and above what was predicted by simple problem
characteristics. These results also replicated in a second independent experiment. We
reconcile these results with earlier findings from neuroscience and discuss the
implications of these findings for models of risky choice and strategy selection below.
Validity of Risky Choice Models in Value Allocation Task
The bulk of experimental work on decision making under risk has been concerned
with the relative descriptive fit of a single model of strategy for decision making like the
classic expected utility maximization model along with measurement of individual
difference parameters like the degree of risk aversion. A common view underlying many
studies of individual differences is captured by Birnbaum’s argument that the principle
“that every individual is represented by the same model in which different people can
have different parameters in that model” (p. 497) should be retained for risky decisions
until researchers have a clear reason to abandon it (Birnbaum, 2008a).
Several models have been proposed for risky choice, including the compensatory
ones like EU, CPT and TAX and non-compensatory ones like PH. Yet, there is still
considerable controversy over the suitability of any of these models in explaining process
measures in risky choice. For instance, Glockner and Betsch (2008) demonstrate using
59

<-----Page 74----->information-search paradigms that choices in their study support weighted compensatory
models like CPT, and are largely inconsistent with predictions of PH. In contrast,
Birnbaum and colleagues demonstrate choices that violate both PH and CPT (Birnbaum,
2008b) and argue in favor of TAX. Similarly, Payne (2005) demonstrates systematic
violations of the predictions of CPT and EU using multi-outcome mixed gambles. Even
in instances where choices are consistent with compensatory strategies like CPT, process
data corroborates the assumption that people may not apply them by deliberately
calculating weighted sums (Glockner and Herbold, 2011).
Choice data using the value allocation task in our studies was largely inconsistent
with the predictions of EU, CPT and PH. Neither of these models predicts the large
amount of emphasis paid to the intermediate outcome in the Pmax-available trials.
Similarly, all these models should be unaffected by the subtle changes made to the
intermediate outcomes in the Pmax-unavailable trials. Yet, our data indicates a huge bias
towards Pmax choices in Pmax-available trials that is not present in the Pmax-unavailable
trials. We also demonstrate variability across individuals in the extent of the bias. Though
the variability across individuals could be accounted for by parameter changes to the
models, the shift between Pmax-available and Pmax-unavailable trials cannot. Our
process data, including response times and information search measures, corroborate our
choice data about the validity of these models in this particular task.
Therefore, the validity of any descriptive model of decision behavior may depend
on the class of problems to which it is applied; and different models may be more or less
successful only in certain scenarios (Loomes, 2010). We go further and argue that these
60

<-----Page 75----->different models represent different strategies available to people and they adaptively
select between these and other heuristic strategies based on appropriate interactions
between task context and individual traits. One again, we emphasize that the Pmaxheuristic cannot be viewed as a general process model for risky choice, but rather just one
of the processing strategies that might be used to solve a complex risky choice problem.
Comparison to Single Strategy based on Parallel Constraint Satisfaction (PCS) Models
Another class of compensatory models that has been discussed extensively in
recent times is a network-mode based PCS model. We discuss these models separately
because of recent eye-tracking evidence for compensatory strategies based on automatic
processing that is consistent with these models (Glockner and Herbold, 2011). In their
study, Glockner and Herbold made explicit hypotheses about eye-tracking data that
would be consistent with PCS models. We used data from E1 to validate those
hypotheses. Glockner and Herbold argued that:
H1b: Choices should follow a compensatory integration of subjective utilities
H4c: In the entire decision process, information search is mainly based on screening
H6d: Fixations are concentrated on the outcomes of the favored gambles and on the
most attractive outcomes.
Our behavioral data provide evidence against hypothesis H1b. Under any
compensatory integration strategy, a small difference in the magnitude of intermediate
outcomes between Pmax-available and Pmax-unavailable trials should not lead to
changes in choice preferences. Similarly, increasing dwell times (fixation durations)
during the course of the trial indicates that screening is not the main basis of information
61

<-----Page 76----->search, rejecting hypothesis H4c. Our data though are consistent with hypothesis H6d,
with fixations being concentrated on the unique outcomes for alternatives that were
subsequently selected. Yet, the inability to validate the other two hypotheses suggests that
the PCS model cannot always explain decision processes in the value allocation task here.
These data therefore argue against their push for a single strategy view for decision
preferences and instead support the use of multiple strategies in risky choice.
Clarifying the neural mechanisms that support such strategies will be the focus of
the next chapter. Specifically, we sought to elucidate the mechanisms underlying
different choice preferences and strategic variability across individuals using fMRI.
Consistent with the multiple strategy perspective, we were also interested in identifying
brain region(s) that play a key role in facilitating strategy switching, as a function of task
and individual variability.

62

<-----Page 77----->3 Neural Correlates of Choice and Strategic Variability
in Risky Choice†
The neuroscience of decision making under risk has focused on identifying brain
systems that shape behavior toward or against particular choices (Hsu et al., 2005;
Kuhnen and Knutson, 2005; Platt and Huettel, 2008). These studies typically involve
compensatory paradigms that trade two decision variables against each other, as when
individuals choose between a safer, lower-value option and a riskier, higher-value option
(Coricelli et al., 2005; De Martino et al., 2006; Huettel, 2006; Tom et al., 2007).
Activation in distinct regions reliably predicts the choices that are made: increased
activation in the anterior insula follows risk-averse choices (Paulus et al., 2003;
Preuschoff et al., 2008) and increased activation in the ventromedial PFC and striatum
predicts risk-seeking choices (Kuhnen and Knutson, 2005; Tobler et al., 2007). In
contrast, prefrontal and parietal control regions support executive control processes
associated with risky decisions, as well as the evaluation of risk and judgments about
probability and value (Paulus et al., 2001; Sanfey et al., 2003b; Barraclough et al., 2004;
Huettel et al., 2005a). These and other studies have led to a choice-centric neural
conception of decision making: tradeoffs between decision variables, such as whether
someone seeks to minimize potential losses or maximize potential gains, reflect similar
tradeoffs between the activation of brain regions (Sanfey et al., 2003b; Kuhnen and

†

The contents of this chapter have been published as “Venkatraman V, Payne JW, Bettman JR, Luce MF, Huettel SA
(2009) Separate neural mechanisms underlie choices and strategic preferences in risky decision making. Neuron
62:593-602.”

63

<-----Page 78----->Knutson, 2005; Loewenstein et al., 2008). Accordingly, individual differences in decision
making have been characterized neurometrically by estimating parameters associated
with a single model of risky choice and identifying regions that correlate with individual
differences in those parameters (De Martino et al., 2006; Huettel et al., 2006; Tom et al.,
2007).
Yet, following a purely compensatory approach to decision making would require
substantial computational resources, especially for complex decision problems that
involve multiple decision variables. It has become increasingly apparent that people
employ a variety of strategies to simplify the representations of decision problems and
reduce computational demands (Tversky and Kahneman, 1974; Payne et al., 1988; Payne
et al., 1992b; Gigerenzer and Goldstein, 1996; Kahneman and Frederick, 2002; Camerer,
2003b). For example, when faced with a complex decision scenario that could result in a
range of positive or negative monetary outcomes, some individuals adopt a simplifying
strategy that de-emphasizes the relative magnitudes of the outcomes but maximizes the
overall probability of winning. Other individuals emphasize the minimization of potential
losses or the maximization of potential gains in ways consistent with more compensatory
models of risky choice such as expected utility maximization (Payne, 2005). Adaptive
decision making in real-world settings typically involves multiple strategies that each
may be adopted based on the context and computational demands of the task (Payne et
al., 1993; Gigerenzer and Goldstein, 1996). As noted above, there has been considerable
research on identifying brain systems that shape behavior toward or against particular
choices (risky or safer gambles); however, much less is known about the neural
64

<-----Page 79----->mechanisms that underlie inter- and intra-individual variability in decision strategies. We
sought to address this limitation in the present study by dissociating choice-related and
strategy-related neural contributors to decision making.

Figure 3-1: Schematic of the fMRI value allocation task.
We used an incentive-compatible value allocation task similar to the one
introduced in earlier chapter that contained economic gambles with five rank-ordered
outcomes, ranging from large monetary losses to large monetary gains (Figure 3-1).
There were three types of choices: gain-maximizing, loss-minimizing or probabilitymaximizing. Making a gain-maximizing (Gmax) choice increased the magnitude of the
largest monetary gain (i.e., the most money that could be won), whereas making a lossminimizing (Lmin) choice reduced the magnitude of the largest monetary loss (i.e., the
most money that could be lost). The gambles in this study were constructed so that these
two choices (Gmax and Lmin) were generally consistent with a compensatory strategy,
such as following expected utility and/or rank-dependent expectation models like
65

<-----Page 80----->cumulative prospect theory (Tversky and Kahneman, 1992; Payne, 2005; Birnbaum,
2008a). On the other hand, making a probability-maximizing (Pmax) choice increases the
overall probability of winning money compared to losing money. Therefore, such choices
would be consistent with a simplifying strategy (e.g., “maximize the chance of winning”)
that ignores reward magnitude. Finally, we characterized our participants’ strategic
preferences according to their relative proportion of simplifying (Pmax) versus
compensatory (Gmax and Lmin) choices. Such a definition positions the two strategies as
the end points of a continuum with a high value indicating an individual’s preference for
a simplifying strategy and a low value indicating a preference for a compensatory
strategy. We emphasize that, as defined operationally here, strategies for decision making
may be either explicit or implicit.
To distinguish neural mechanisms underlying choices from those underlying the
strategies that generate those choices, we collected several forms of behavioral and
functional magnetic resonance imaging (fMRI) data. Consistent with many previous
studies (Sanfey et al., 2003b; De Martino et al., 2006), we characterized brain regions as
choice-related if the magnitude of their activation predicted a specific behavior (e.g.,
select the option providing the largest gain) throughout our participant sample. In
contrast, we characterized brain regions as strategy-related based on their association
with individual difference measures; i.e., if the magnitude of their activation depended on
whether or not an individual engages in their preferred strategy, regardless of which of
the two strategies that entails. Moreover, strategy-related regions should exert a
modulatory influence on choice-related regions. A strong candidate for a strategy-related
66

<-----Page 81----->region is the dorsomedial prefrontal cortex, which has been shown to play an important
role in tasks involving decision conflict as well as in making decisions that run counter to
general behavioral tendencies (De Martino et al., 2006; Pochon et al., 2008). Moreover,
this region exhibits distinct patterns of functional connectivity to affective and cognitive
networks (Meriau et al., 2006), making it a candidate for shaping activation in those
networks based on context and computational demands (Kennerley et al., 2006; Behrens
et al., 2007).

3.1 Experimental Methods
Twenty-three healthy, neurologically normal young-adult volunteers (13 female;
age range: 18-31y; mean age: 24y) participated in the fMRI session. All participants gave
written informed consent as part of protocols approved by the Institutional Review
Boards of Duke University and Duke University Medical Center. All participants
acclimated to the fMRI environment using a mock MRI scanner and participated in two
short practice runs consisting of six trials each, one inside and one outside of the fMRI
scanner. Three participants were excluded from some analyses involving strategy effects
due to lack of variability in their response (two participants always chose the Pmax
option while the third participant never chose the Pmax option), leaving a total of 20
participants in the complete analyses of the decision-making trials. One additional
participant was excluded from the outcome-delivery trials due to a computer error in
saving the timing associated with the trials.
At the outset of the experiment, participants were provided detailed instructions
about the payment procedures. They were then given a sealed envelope that contained an
67

<-----Page 82----->endowment to offset potential losses; this envelope was sufficiently translucent that they
could see that there was cash inside, even though the quantity could not be determined.
Participants were also told that there was no deception in the study and were given an
opportunity to question the experimenter about any procedures before entering the
scanner. All participants expressed that they understood and believed in the procedures.
Experimental Stimuli. All participants were presented with a total of 120 fiveoutcome mixed gambles in a completely randomized order. Each of the gambles
comprised two positive outcomes (an extreme outcome of $65 to $80; an intermediate
outcome of $35 to $50), two negative outcomes (an extreme outcome of -$65 to -$85; an
intermediate outcome of -$35 to -$50), and a central, reference outcome. The reference
outcome was $0 in half the trials and a negative value ranging from -$10 to -$25 in
remaining half of the trials. Probabilities of each of the five outcomes varied between 0.1
and 0.3 in units of 0.05, and always summed to 1 across the five outcomes.
On each trial, participants could choose between two options for adding money to
one of the outcomes. Adding to the reference outcome increased the overall chance of
winning money compared to losing money and hence was called the probabilitymaximizing (Pmax) choice. Alternatively, adding money to an extreme option either
increased the magnitude of the best monetary outcome or decreased the magnitude of the
worst monetary outcome, and hence were referred to as gain-maximizing (Gmax) and
loss-minimizing (Lmin) choices respectively. The amount of money that participants
could add to the outcomes ranged between $10 and $25 and could differ between the two
outcomes. For trials with negative reference values, one of the options for adding money
68

<-----Page 83----->always changed the reference option to $0. All outcome values used in this experiment
were multiples of $5.
Expected value relations between the two choices were systematically
manipulated by changing the amount and/or probabilities associated with each of the
options. Only trial types that placed the two choices in maximal conflict (72 gambles per
participant) were included in the primary imaging analyses; other trials were included in
the model as separate regressors, but not further analyzed. Note that the trials were
counterbalanced for valence of the extreme outcome (i.e., gain or loss) and for valence of
the reference outcome (i.e., neutral or loss).
Experimental Design. Each trial began with the display of a five-outcome
gamble for 4 or 6s (Figure 3-1). Participants were instructed to examine each gamble as
it was presented. Subsequently, participants were given a choice between two ways of
improving the gamble. The amount that could be added and the resulting modified
outcome values were displayed in red for both choices, to minimize individual
differences resulting from calculation or estimation biases. The modified gamble
remained on the screen for 6s, whereupon two arrows appeared to specify which button
corresponded to which choice. The association of the buttons to choice was random.
Participants then pressed the button corresponding to their choice. Response times were
coded as the time between the appearance of arrows and the button press response (Note
that this may not be a true representation of the actual decision times in this task).
Participants were instructed to arrive at their decision during the 6s interval and to press
the button corresponding to their choice as soon as the arrows appeared. The decision and
69

<-----Page 84----->response phases were explicitly separated to prevent the contamination of decision effects
with response-preparation effects. During the inter-trial interval of 4-8 seconds, a fixation
cross was displayed on the screen. Notice that no feedback was provided at the end of
each trial and hence there was no explicit learning during the decision phase of the task.
Participants participated in six runs of this decision task, each containing 20
gambles and lasting approximately 6 minutes. Before those runs, participants had the
opportunity to practice the experimental task (without reward) in two six-gamble blocks,
one presented outside the MRI scanner and the other presented within the MRI scanner
but prior to collection of the fMRI data. All stimuli were created using the Psychophysics
Toolbox (Brainard, 1997; Pelli, 1997) for MATLAB (Mathworks, inc.) and were
presented to the participants via MR-compatible LCD goggles. Participants responded
with the index fingers of each hand via a MR-compatible response box.
Following completion of the decision phase, there was a final 6-minute run in
which 40 of the improved gambles were resolved to an actual monetary gain or loss.
These gambles were selected randomly from the gambles presented during the decision
phase and were presented in modified form based on that participant’s choices. On each
trial, participants passively viewed one of these improved gambles on the screen for 2s
(anticipation phase), during which time random numbers flashed rapidly at the bottom of
the screen before stopping at a particular value. A text message corresponding to the
amount won or lost was then displayed for 1s, followed by an inter-trial fixation period of
3-7s before the onset of the next trial.

70

<-----Page 85----->Imaging Methods. We acquired fMRI data on a 4T GE scanner using an inversespiral pulse sequence (Glover and Law, 2001; Guo and Song, 2003) with parameters: TR
= 2000ms; TE = 30ms; 34 axial slices parallel to the AC-PC plane, with voxel size of
3.75*3.75*3.8mm. High resolution 3D full-brain SPGR anatomical images were acquired
and used for normalizing and co-registering individual participants’ data.
Analysis was carried out using FEAT (FMRI Expert Analysis Tool) Version 5.63,
part of FSL (FMRIB's Software Library, www.fmrib.ox.ac.uk/fsl) package (Smith et al.,
2004). The following pre-statistics processing steps were applied: motion correction
using MCFLIRT, slice-timing correction, removal of non-brain voxels using BET, spatial
smoothing with a Gaussian kernel of FWHM 8mm, and high-pass temporal filtering.
Registration to high resolution and standard images was carried out using FLIRT. All
statistical images presented were thresholded using clusters determined by z > 2.3 and a
whole-brain corrected cluster significance threshold of p < 0.05.
We used separate first-level regression models to analyze decision effects and
outcome effects. The decision model comprised two regressors modeling the magnitudesensitive compensatory choices (Gmax and Lmin were combined for additional power)
and simplifying Pmax choices in the conflict conditions, one regressor modeling the
responses in the remaining conditions, one regressor for the initial presentation of the
gamble, and one regressor to model the participant responses. (An additional post-hoc
analysis on a subset of fifteen participants separated the magnitude-sensitive choices
according to whether they were gain-maximizing or loss-minimizing.) Analysis for the
outcome phase consisted of three regressors: one to model the anticipation phase (as
71

<-----Page 86----->participants were waiting for the corresponding outcome to be revealed), one for positive
outcomes (gain), and one for negative outcomes (loss). All regressors were generated by
convolving impulses at the onsets of events of interest with a double-gamma
hemodynamic response function. Second-level analysis for condition and decision effects
within each participant was carried out using a fixed-effects model across runs. Randomeffects across-participants analyses were carried out using FLAME (stage 1 only). When
evaluating the effects of behavioral traits (transformed into z-scores) upon brain function,
we included our participants’ trait measures as additional covariates in the third-level
analysis.
Logistic Regression Models of Trial-to-Trial Choices. For obtaining the
parameter estimates from individual trials for trial-by-trial prediction analysis, we used
data that were corrected for motion and differences in slice scan timing but were not
smoothed. The data were also transformed into standard space, on which the individual
regions-of-interest (ROI) were defined. We used seven different ROIs for this analysis:
the right anterior insula and ventromedial prefrontal cortex, which show greater
activation for Lmin and Gmax choices respectively; the right posterior parietal cortex, the
right precuneus, and right dorsolateral prefrontal cortex, which show greater activation
for Pmax choices; and finally the dorsomedial prefrontal cortex and right inferior frontal
gyrus, which track strategic variability across participants. All ROIs were defined
functionally based on the third-level activation maps. Activation amplitude was defined
as the mean signal change (in percent) over the 6s time-interval from 4s to 10s after the
onset of decision phase (i.e., when participants are shown the two alternative choices).
72

<-----Page 87----->This time window was chosen to encompass the maximal signal change of the fMRI
hemodynamic response. A summary measure was obtained for each ROI by averaging
over all constituent voxels.
We then performed a hierarchical logistic regression using SPSS to predict the
choices made by participants on each individual trial based on strategic preference
(proportion of Pmax choices), brain activation, and interactions between trait and
activation. The complete model included a total of 1440 trials (72 trials for each of 20
participants). Parameters were entered into the model in a stepwise manner, starting with
just the behavioral trait measure, then brain activations from the seven ROIs, and finally
an interaction term consisting of activation in dmPFC multiplied by strategic tendency.
Functional-Connectivity Analyses. We used a modified version of the decision
model described above to perform task-related connectivity analysis. A seed region was
defined using activation in the dmPFC that covaried with the strategic variability across
participants. For each run for each participant, we then extracted the time-series from this
region. A box-car vector was then defined for each condition of interest, with the “on”
period defined from 4s-10s after the onset of the decision phase for each trial in that
condition. These box-car vectors were then multiplied with the extracted time-series to
form the connectivity regressors. This allowed us to examine brain connectivity as a
function of strategy, specific to the decision phase. These regressors were then used as
covariates in a separate GLM analysis, which included the original variables of interest,
from the decision-model described above (Cohen et al., 2005). Group activation maps
were then obtained in the same way as the traditional regression analysis. A positive
73

<-----Page 88----->activation for the connectivity regressors indicate that the region correlates more
positively with the seed region during the experimental condition of interest.

3.2 Results
Consistent with our two behavioral experiments, participants made Pmax choices
on approximately 70% of the trials when the choices were matched for expected value.
Moreover, the proportion of Pmax choices was systematically modulated by the tradeoff
in expected value between the choices, indicating that participants were not simply
insensitive to expected value (Appendix Table A-1). Finally, the proportion of Pmax
choices decreased with increasing self-reported tendency to maximize (r = -0.67, p <
0.001).

Neural Predictors of Choices. Our initial analyses identified brain regions whose
activation was driven, across participants and trials, by the selected choice. There was
greater activation in anterior insular cortex (aINS) and ventromedial prefrontal cortex
(vmPFC; Figure 3-2A) for the compensatory magnitude-sensitive choices (combined
across Gmax and Lmin). These regions are typically associated with emotional function,
particularly the affective evaluation of the outcome of a choice in decision-making tasks
(Bechara et al., 2000b; Paulus et al., 2003; Sanfey et al., 2003a; Dalgleish, 2004). We
subsequently performed a region of interest analysis to explore specifically the
differences in activation between Gmax and Lmin. Note that this analysis was restricted,
a priori, to a subset of fifteen participants with a sufficient number of choices in each
condition of interest. We found a clear double dissociation between aINS and vmPFC:
74

<-----Page 89----->Gmax choices were predicted by greater activation within vmPFC while Lmin choices
were predicted by increased activation in aINS (Figure 3-2B,C). Conversely, Pmax
choices were associated with increased activation in the dorsolateral prefrontal cortex
(dlPFC) and posterior parietal cortex (PPC; Figure 3-2A, Appendix Table A-2), regions
typically associated with executive function and decision making under risk and
uncertainty (Paulus et al., 2001; Bunge et al., 2002; Huettel et al., 2005b; Huettel et al.,
2006). These regions showed greater activation for Pmax choices compared to both
Gmax and Lmin, but no difference between Gmax and Lmin options (Figure 3-2D).

Neural Predictors of Strategic Variability across Individuals. We next investigated
whether there were brain regions whose activation varied systematically with individual
differences in strategic preferences. To do this, we entered each participant’s strategic
preference as a normalized regressor into the across-participants fMRI analyses of the
contrast between choices. Strategic variability predicted individual differences in
activation in two clusters (Figure 3-3): the dorsomedial prefrontal cortex (dmPFC) and
the right inferior frontal gyrus (rIFG). Within these regions, there was no significant
difference in activation between the choices. However, there was a significant
interaction: activation increased when an individual with preference for the more
compensatory strategy made a simplifying Pmax choice and vice versa. We focus on the
dmPFC in the rest of this manuscript, based on our prior hypothesis about the role of this
region as well as the fact that only this region significantly predicted trial-by-trial choices
(as discussed later).
75

<-----Page 90----->Figure 3-2: Distinct sets of brain regions predicted choices.
We next evaluated whether dmPFC activation might shape activation in those
regions that predicted specific choices (i.e., Pmax: dlPFC and PPC; Lmin: aINS and
Gmax: vmPFC), using seed-voxel-based whole-brain functional connectivity analyses.
This would provide additional converging evidence for the role of this region in
determining choice behavior, contingent on preferred strategies. We found a double
dissociation in the functional connectivity of dmPFC depending upon the choice made by
the participant (Figure 3-4). When participants made Pmax choices, connectivity with
dmPFC increased in dlPFC and PPC, whereas when participants made more magnitudesensitive compensatory choices, connectivity increased in the aINS (and amygdala, but
76

<-----Page 91----->not in vmPFC). Moreover, the relative strength of the connectivity between dmPFC and
these regions was significantly associated with individual differences in strategy
preferences across participants (Appendix Figure A-1). Finally, we also conducted
additional analysis to rule out the possibility that dmPFC activation was related to
response conflict, as has been found in several previous studies (Botvinick et al., 1999;
Kerns et al., 2004).

Figure 3-3: Dorsomedial prefrontal cortex predicted strategy use during
decision making.
Thus, we provide a broad range of converging results – drawn from overall
activation, functional connectivity, factor analysis of behavioral data (see Appendix A),
association with individual differences in strategy and trial-by-trial analysis (below) –
that together indicate that dmPFC supports strategic considerations during decision
making, shaping behavior toward or against individual’s strategic preferences.

Integrating Choices and Strategies to Predict Behavior. We used the brain regions
implicated above as choice-related (aINS, vmPFC, dlPFC, PPC) or strategy-related
(rIFG, dmPFC) to predict choices on individual trials. We extracted, for every trial for
77

<-----Page 92----->every participant, the activation amplitude in each of these regions of interest, along with
the decision made on that trial. We used a hierarchical logistic regression approach to
evaluate which of these regions were significant and independent predictors of trial-totrial decisions (Table 3-1).

Figure 3-4: DmPFC showed differential functional connectivity with choicerelated regions.
We first entered into the model participants’ overall preference for the simplifying
strategy (proportion of Pmax choices). We found, unsurprisingly, that this was a highly
significant predictor of trial-to-trial choices. Next, we used activation values from our
brain regions of interest, considering them both in isolation and with strategic preference
already entered into the model. We found that activation in insular cortex was a
significant predictor of magnitude-sensitive choices, while parietal activation was a
significant predictor of Pmax choices. Critically, activation in these brain regions
improved the fit of the model even when the behavioral data had already been included.
None of the other regions, including dmPFC, predicted either type of choice. Yet, when
we weighted dmPFC activation with each participant’s strategy preference, the resulting
78

<-----Page 93----->variable became a significant and robust predictor of behavior, and overall model error
was reduced (Table 3-1). Thus, dmPFC activation does not predict either type of choice,
but instead predicts choices that are inconsistent with one’s preferred decision strategy.
Table 3-1: Results from logistic regression predicted trial-by-trial Pmax
choices.
Coefficient

Model Variables

(S.E.)

Wald

Model Significance

Model Fit

(Significance)

(χ )

( Nagelkerke R2 )

76.09

0.069

18.05

0.017

90.26

0.081

97.66

0.088

Trait
Constant
Proportion of Pmax choices

-0.14 (0.05)

6.19 (0.13)

1.02 (.12)

70.79 (.000)

Brain
Constant

-0.21 (0.06)

13.10 (.000)

Right Posterior Parietal Cortex

32.41 (8.43)

14.80 (.000)

-40.52 (13.28)

9.31 (.002)

Right Anterior Insula

Trait ( + Brain)
Constant

-0.22 (0.06)

13.38 (.000)

Proportion of Pmax choices

1.00 (0.12)

67.23 (.000)

Right Posterior Parietal Cortex

30.54 (8.62)

12.56 (.000)

-33.32 (13.69)

5.93 (.012)

Right Anterior Insula

Trait + Brain + (Trait*Brain)
Constant

-0.23 (0.06)

13.78 (.000)

Proportion of Pmax choices

1.10 (0.13)

71.75 (.000)

Right Posterior Parietal Cortex

31.96 (8.70)

13.49 (.000)

Right Anterior Insula

-33.00 (13.77)

5.74 (.017)

dMPFC * Strategic Variability

-70.58 (26.28)

7.21 (.007)

2

All χ2 values were highly significant (p < 10-4)

79

<-----Page 94----->We emphasize that the brain-behavior relations reported here were highly
significant even though the behavioral choice data across trials for each participant (a
behavioral strategy indictor) were already included in the logistic regression model. That
is, we could use the fMRI activation evoked within key brain regions to improve our
predictions of participants’ decisions on individual trials over what was predicted from
behavioral data alone.

Neural Reward Sensitivity Predicts Individual Differences in Strategy. Finally, we
evaluated whether an independent neural measure of reward sensitivity could predict the
strategic preferences outlined in the previous sections. At the end of the scanning session,
each participant passively viewed a subset of their improved gambles, which were each
resolved to an actual monetary gain or loss. While participants were anticipating the
outcome of each gamble, there was increased activation in the ventral striatum (vSTR), a
brain region commonly implicated in learning about positive and negative rewards
(Schultz et al., 1997; Yacubian et al., 2006; Seymour et al., 2007). Then, when the
gamble was resolved, vSTR activation increased to gains but decreased to losses (Figure
3-5). Moreover, there were striking and significant correlations between strategic
variability and vSTR activation: those individuals who showed the greatest vSTR
increases to gains and decreases to losses both preferred the simplifying Pmax strategy
(Figure 3-5) and scored low on a behavioral measure of maximizing reward magnitudes
(Appendix Figure A-2). These results suggest that the use of a simplifying strategy that

80

<-----Page 95----->improves one’s overall chances of winning (Pmax) may result from increased neural
sensitivity to reward outcomes.

Figure 3-5: Ventral striatal sensitivity to rewards predicted strategic
variability.

3.3 Discussion
When facing complex decision situations, many individuals engage in simplifying
strategies – such as choosing based on the overall probability of a positive outcome – to
reduce computational demands compared to compensatory strategies. Here, we
demonstrated two neural predictors of strategic variability in decision making. First,
during the decision process, the dmPFC shapes choices (in a manner depending on
strategic tendency) through changes in functional connectivity with insular and prefrontal
cortices. Second, independent neurometric responses to rewards predicted strategic
preferences: those individuals with the greatest striatal sensitivity to reward valence are
most likely to use a simplifying strategy that emphasizes valence, but ignores magnitude.
These results provide clear and converging evidence that the neural mechanisms of
choice reflect more than competition between decision variables; they additionally
involve strategic influences that vary across trials and individuals.
81

<-----Page 96----->A large literature suggests that decisions between simple gambles can be
predicted by compensatory models like expected utility and Cumulative Prospect Theory
(Fennema and Wakker, 1997; Huettel et al., 2006; Wu et al., 2007; Preuschoff et al.,
2008). Individual differences in sensitivity to the parameters within these models lead to
distinct patterns of choices, even when the same model is applied to all individuals
(Huettel et al., 2006; Tom et al., 2007). As decision problems become more complex,
however, the assumption of a single canonical decision strategy becomes more and more
problematic. As suggested by Tversky and Kahneman (1992) and Payne et al. (1993),
people employ a variety of strategies to represent decision problems and evaluate options.
Some of those strategies will be consistent with traditional models like expected utility
maximization, whereas other strategies will be more heuristic or simplifying. Further,
depending on the decision context, people shift among multiple strategies to maintain a
balance between minimizing cognitive effort or maximizing decision accuracy, among
other goals (Payne et al., 1993). Finally, strategy use to solve the same decision problem
differs across individuals, perhaps reflecting such trait differences as a tendency towards
satisficing versus maximizing. Our findings, involving a complex risky choice task,
across both behavioral and neuroimaging experiments, provide evidence in favor of intraand inter-participant variability in the use of strategies across participants. Importantly,
we show that the parameters estimated using traditional economic models of risky choice
were poor predictors of choices in our paradigm, providing possible evidence for
differences in decision strategy within and across participants.

82

<-----Page 97----->One influential conjecture in decision making is that people frequently use a
variety of simplifying heuristics that reduce effort associated with the decision process
(Simon, 1957; Shah and Oppenheimer, 2008). Pmax choices in the current task are
consistent with such an effort-reduction framework, given that they were associated with
faster response times in the behavioral experiments (note that we do not have accurate
estimates of response times in the imaging experiment as we sought to explicitly separate
the decision and response phases in our design), and that the proportion of Pmax choices
decreased adaptively with increasing cost in terms of expected value in all experiments.
We suggest, therefore, that strategic preferences in the current task reflects tradeoffs –
resolved differently by individual participants and over trials – between one strategy that
simplifies a complex decision problem by using a simple heuristic of maximizing the
chances of winning (Pmax) and another, more compensatory strategy that involves
consideration of additional information as well as the emotions associated with extreme
gains (Gmax) or losses (Lmin).
To the extent that the Pmax choices reflect a more simplifying strategy, the
pattern of activations seen in this study seems counterintuitive: the regions
conventionally associated with automatic and affective processing (aINS and vmPFC)
predicted magnitude-sensitive choices that were more consistent with traditional
economic models such as expected utility maximization, whereas the regions
conventionally associated with executive functions (dlPFC and PPC) predicted choices
more consistent with a simplifying strategy. The lateral prefrontal cortex has been shown
in previous studies to be active during probabilistic decision-making (Heekeren et al.,
83

<-----Page 98----->2004; Heekeren et al., 2006) as well as sensitive to individual differences in the
processing of probability (Tobler et al., 2008). Neurons within this region have also been
shown to track reward probabilities (Kobayashi et al., 2002) and process reward and
action in stochastic situations (Barraclough et al., 2004). Similarly, the parietal cortex
also plays an important role in tracking outcome probabilities (Dorris and Glimcher,
2004; Huettel et al., 2005a). Given that Pmax choices are based on the overall probability
of winning, activation in dlPFC and PPC could be associated with tracking subjective
probabilities in these gambles.
Conversely, the Gmax and Lmin choices increase the chances of an aversive
outcome, relative to a neutral aspiration level (Lopes and Oden, 1999). Supporting this
interpretation, we found a clear double dissociation with activation in vmPFC predicting
Gmax choices and activation in aINS predicting Lmin choices. The contributions of
vmPFC to gain-seeking behavior (at the expense of potential losses) have been
documented in both patient (Bechara et al., 2000a) and neuroimaging studies (Tobler et
al., 2007). Conversely, there has been substantial recent work demonstrating the
importance of aINS for aversion to negative consequences, even to the point of making
risk-averse mistakes in economic decisions (Paulus et al., 2003; Kuhnen and Knutson,
2005; Preuschoff et al., 2008; Rolls et al., 2008). Together, these findings suggest that the
conventional notion that decisions reflect compensatory balancing of decision variables is
an oversimplification. In addition, different brain regions bias how people approach
decision problems, which may in turn lead to one form of behavior or another depending
on the task context.
84

<-----Page 99----->Furthermore, the balance between cognitive and affective brain regions did not,
by itself, explain individual differences in strategy preferences. Activation in another
region, dmPFC, predicted variability in strategic preferences across participants. We note
that the role of dmPFC in complex decision making remains relatively unknown. One
very recent experiment found increased activation in this region when participants faced
greater decision-related conflict (Pochon et al., 2008), as dissociable from the more
commonly reported response conflict (Botvinick et al., 2001). A similar region of dmPFC
was implicated by de Martino and colleagues (De Martino et al., 2006), again when
participants made decisions counter to their general behavioral tendency (i.e., against
typical framing effects). However, it is important to note that all participants in their
study exhibited a bias toward using the framing heuristic, while in the current study,
participants varied in their relative preference for two different strategies. Therefore, a
parsimonious explanation for the function of this region of dmPFC is that it supports
aspects of decision making that are coded in relation to an underlying strategic tendency,
not effects specific to framing. Further support for this hypothesis is provided by the
differential functional connectivity of the dmPFC to dlPFC and aINS for simplifying and
compensatory choices respectively. These findings are consistent with interpretation that
dmPFC shapes behavior by modulating choice-related brain regions, with the strength of
this modulatory effect dependent on an individual’s preferred strategy.
We additionally observed a striking relationship between neurometric sensitivity
to reward and strategic biases across individuals. Our initial analyses found that
activation of the vSTR increased when anticipating the outcome of a monetary gamble,
85

<-----Page 100----->increased further if that gamble was resolved to a gain, but decreased if that gamble was
resolved to a loss. This pattern of results was consistent with numerous prior studies
using human neuroimaging (Delgado et al., 2000; Breiter et al., 2001; Seymour et al.,
2007) and primate electrophysiology (Schultz et al., 1997). However, we additionally
observed the novel result that the magnitude of the vSTR response was a strong predictor
of individual strategic preferences. Specifically, the sensitivity to gains and losses in the
vSTR is greatest for individuals who prefer the Pmax choices; consistent with their
strategy of maximizing their chances of winning. We emphasize that the gambles were
not resolved until after all decisions were made, so this effect could not be attributed to
learning from outcomes. Although we cannot be certain about the direction of causation,
these results suggest that an increased sensitivity to reward valence may lead to simple
decision rules that overemphasize the probability of achieving a positive outcome.
Our results demonstrate that decision making reflects an interaction among brain
systems coding for different sorts of computations, with some regions (e.g., aINS,
vmPFC) coding for specific behaviors and others (e.g., dmPFC) for preferred strategies.
Depending upon the circumstances and state, organisms may adopt strategies that
emphasize different forms of computation, whether to obtain additional information
(Daw et al., 2006), to improve models of outcome utility (Montague and Berns, 2002), or
to simplify a complex decision problem. Sleep deprivation is one such state that has
received a lot of interest in recent years, particularly in the realm of decision making. In a
follow-up study presented in next chapter, we sought to understand how 24 hours of total
sleep deprivation biases economic decision making within the same individual.
86

<-----Page 101----->4 State Effects on Risky Choice: Sleep Deprivation
Biases the Underlying Neural Mechanisms†
Many persons living in developed societies sleep inadequately (Institute of
Medicine, 2006; Centres for Disease Control, 2009), believing that sustained wakefulness
has no untoward effects. Several functional neuroimaging studies have revealed how
short-term sleep deprivation (SD) can negatively affect attention (Chee et al., 2008;
Tomasi et al., 2009), working memory (Chee and Choo, 2004; Habeck et al., 2004; Mu et
al., 2005) and learning (Drummond et al., 2005; Sterpenich et al., 2009). Yet, it remains
unclear whether and how SD shapes the very preferences that guide decision-making,
independently of these more general effects on cognition.
Behavioral studies suggest that SD-generated impairments in cognition lead to
deficits in the overall quality of decision-making (Harrison and Horne, 1999; Linde et al.,
1999). More recent studies that involve making decisions under uncertainty have found
that sleep-deprived persons tend towards riskier options (Harrison and Horne, 2000;
Killgore et al., 2006; McKenna et al., 2007), mirroring the behavior of patients with
medial frontal damage (Bechara et al., 2000a). In the sole functional neuroimaging study
on risky decision-making with feedback, 24 hours of SD resulted in increased nucleus
accumbens activation for anticipated monetary gains, and attenuated insula activation for
experienced monetary losses (Venkatraman et al., 2007).

†

The contents of this chapter have been published as “Venkatraman V, Huettel SA, Chuah YM, Payne JW, Chee MW
(2011) Sleep deprivation biases the mechanisms underlying economic decision making, Journal of Neuroscience,
31(10):3712-8.”

87

<-----Page 102----->Here, we sought to study SD-induced changes in risk preferences by using a
novel, incentive-compatible, decision-making task (Payne, 2005; Venkatraman et al.,
2009b) where participants evaluated a series of complex mixed gambles, each consisting
of probabilistic outcomes that spanned monetary losses and gains (Figure 4-1A).
Volunteers were given an opportunity to improve each gamble by adding money to one
of the outcomes in one of three ways: increasing the magnitude of the highest gain
(Gmax), decreasing the magnitude of the worst loss (Lmin), or by improving the overall
probability of winning (Pmax) by adding money to a central reference outcome
(Venkatraman et al., 2009b) (Figure 4-1B).
To assess changes in risk preference in the absence of learning, participants first
made their decisions without feedback. Then, to ascertain changes in response to reward
(or loss), a subset of gambles was resolved for real monetary rewards or losses at the end
of the experiment (Figure 4-1C). Separating the decision and outcome phases could be
important as sleep deprivation might interact with task context to influence neural
responses and behavior. For example, the propensity to take higher risks in a gambling
task was found to be modulated by decision frames (McKenna et al., 2007) and task
differences may contribute to lowered (Killgore et al., 2008) or increased (Killgore et al.,
2006; Venkatraman et al., 2007) risky decisions.
Finally, we evaluated the extent to which sleep deprivation jointly alters sustained
attention along with risky decision-making. Although SD may have reproducibly
different effects on subjective measures of fatigue, vigilance and other cognitive
functions (Van Dongen et al., 2004), decision-making has not been evaluated together
88

<-----Page 103----->with other cognitive functions in the same experiment. Existing countermeasures against
SD have only been shown to consistently benefit vigilant attention (Wesensten et al.,
2005; Killgore et al., 2007). If decision-making were to be affected independent of effects
on vigilance, prevailing beliefs concerning the generalized utility of existing
countermeasures would merit reappraisal.

4.1 Experimental Methods
Twenty-nine healthy young adults (mean age 22.34 years, stdev. 1.23 years, 15
males) participated in this neuroimaging study. All participants provided informed
consent, and the study was approved by the Singapore General Hospital Institutional
Review Board.
Participants visited the lab three times over 2 weeks. On the first visit, participants
provided informed consent and practiced the in-scanner task. At the end of this session,
participants were instructed to maintain regular sleeping hours throughout the study
duration, verified using wrist actigraphy (Philips Respironics, USA). Participants
returned to the lab weekly for two fMRI sessions: a rested-wakefulness (RW) session and
a sleep-deprivation (SD) session (order counterbalanced).
Scans at RW took place at 8:00 AM. For the SD session, participants were
monitored in the laboratory from 6:00 PM onwards, and scanning took place at 6:00 AM
the next day. They were allowed to engage in non-strenuous activities such as reading,
watching videos and conversing.
Prior to each scan, participants confirmed that they had not smoked or consumed
any medications, stimulants, alcohol or caffeine for at least 24 hours prior to the scan. For
89

<-----Page 104----->10 minutes every hour from 7:00 PM until 5:00 AM, participants completed the
Psychomotor Vigilance Task (Dinges et al., 1997; Doran et al., 2001), an extensively
used test of sustained attention.
Within each scanning session, participants performed three different tasks. First,
they completed six runs of a risky decision-making task, each run comprising 20 gambles
and lasting 6 minutes. Following these decision runs, they completed one run of a
Counting Stroop task (data not discussed here). Finally, to evaluate neural sensitivity to
rewards, participants watched passively while a subset of modified gambles from the
decision runs was resolved to gains and losses during a single outcome run, lasting 7
minutes.
Stimuli were created using the Psychophysics Toolbox for MATLAB
(Mathworks, Inc.). At the beginning of the experiment, participants were briefed on the
incentive-compatible payment procedure and were told that the study did not involve
deception. Two outcomes (one from each session, RW and SD) were randomly selected
and scaled for bonus payment (see Appendix B). All participants acknowledged their
understanding and acceptance of these procedures.
Experimental Tasks and Stimuli. In the risky decision-making task, participants
evaluated a series of 120 five-outcome gambles, each of which posed choices that ranged
from large monetary losses to large monetary gains (Figure 4-1A). These gambles were
identical to the ones used in the fMRI study introduced in Chapter 3.
Each trial began with the display of a five-outcome gamble for 4 or 6 s.
Participants were instructed to examine each gamble as it was presented. In the gain90

<-----Page 105----->focus (GF) trials, participants could make one of two possible choices: a gainmaximizing (Gmax) choice that involved increasing the magnitude of the highest gain,
and a probability-maximizing (Pmax) choice that improved the overall probability of
winning money compared to losing money. Conversely, in the loss-focus (LF) trials,
participants decided between a loss-minimizing (Lmin) choice that involved decreasing
the magnitude of the worst loss, and the Pmax choice (Figure 4-1B). The relative change
in expected value associated with the two choices was varied across trials.

Figure 4-1: Schematic of (A) Experimental Stimuli, (B) Trial types and (C)
Outcome phase.
91

<-----Page 106----->The amount that participants could add to the outcomes ranged between $10 and
$25 and could differ between the two outcomes. All outcome values used in this
experiment were multiples of $5. Expected values of the two choices were systematically
manipulated by changing the amount and/or probabilities associated with each of the
options. The amount that could be added and the resulting modified outcome values were
displayed in red for both choices, to minimize individual differences that could arise from
calculation or estimation biases.
Participants viewed the two options without any response cues for 6 s, whereupon
arrows appeared on the screen to indicate which button corresponded to each option.
They were instructed to respond as quickly as possible when the arrows appeared. The
next trial appeared after a variable inter-trial interval of 4, 6, or 8 s. No feedback was
given after each trial, thus precluding any SD-related changes in trial-to-trial learning
from influencing behavior.
In the final run, 40 of the gambles from the decision phase were randomly
selected and resolved to an actual monetary gain or loss. These gambles were presented
in modified form based on the participants’ earlier decisions (Figure 4-1C). On each
trial, participants passively viewed a gamble on the screen for 2-6 s (anticipation phase)
while random numbers flashed at the bottom of the screen before stopping at a particular
value. The amount won or lost was displayed for 2 s, followed by an inter-trial fixation
period of 2, 4 or 6 s before the onset of the next trial.

92

<-----Page 107----->Participants viewed the stimuli using MR-compatible LCD visual goggles
(Resonance Technologies, California) and responded using a button box held in their
right hand.
Imaging Procedure. MR imaging was performed using a 3T Siemens Tim Trio
system (Siemens, Erlangen). For all runs, a single-shot, gradient-echo EPI sequence was
used (TR 2000 ms, TE 30 ms, flip angle 90°, FOV 192 X 192 mm, Matrix 64 X 64).
Parallel imaging (GRAPPA) was enabled. 180 volumes were collected in each decision
run and 220 in the outcome run. Thirty-six oblique axial slices (3 mm thick with 0.3 mm
interslice gap) approximately parallel to the intercommisural plane were acquired. Highresolution coplanar T1 anatomical images were also obtained. For the purpose of image
display on Talairach space, 3D high-resolution anatomical reference images were
acquired using a T1-weighted MPRAGE sequence.
Data Analysis. The proportions of Gmax or Lmin decisions, relative to Pmax
decisions, were computed for the gain-focus and loss-focus trials respectively. Effects of
condition, state and their interaction were investigated using a 2 by 2 repeated-measures
ANOVA with factors of choice (Gmax, Lmin) and state (RW, SD).
Imaging analysis was carried out using FEAT (FMRI Expert Analysis Tool)
Version 5.63, part of the FSL (FMRIB's Software Library, www.fmrib.ox.ac.uk/fsl)
package (Smith et al., 2004). The following pre-statistics processing steps were applied:
motion correction using MCFLIRT, slice-timing correction, removal of non-brain voxels
using BET, spatial smoothing with a Gaussian kernel of FWHM 8mm, and high-pass

93

<-----Page 108----->temporal filtering. Registration to high resolution and standard images was carried out
using FLIRT.
Analysis of the decision phase focused on two regressors for each state that
modeled the two types of decision trials: gain-focus and loss-focus. We included
additional predictors that modeled the initial presentation of the wager as well as the
response period (scaled by reaction time). Data from multiple runs collected for each
participant were used to generate participant-specific contrast maps using fixed-effects
analysis.
Analysis of the outcome phase involved the use of three regressors in each state to
model the anticipation phase (as participants were waiting for the corresponding outcome
to be revealed), non-negative outcomes (gain and zero gain), and negative outcomes
(loss).
Each of the three regressors was generated by convolving the impulse at the onset
of events of interest with a double-gamma function. Higher level across-participants
statistical maps were generated using FSL’s linear analysis of mixed effects (FLAME
stage 1 only) tool, using a cluster threshold of z > 2.3 and a whole-brain corrected cluster
significance threshold of p < 0.05. We used two-sample paired t-tests at the higher level
FLAME analysis for estimating state effects. Regions of interest (ROI) were functionally
defined based on the thresholded statistical maps. The parameter estimates from these
ROIs were then correlated with the behavioral measures.

94

<-----Page 109----->4.2 Results
4.2.1 Behavioral Findings
A 2 (choice: Gmax, Lmin) by 2 (state: RW, SD) repeated-measures ANOVA
showed no main effects of state or choice, but a significant state-by-choice interaction
(F(1, 28) = 8.71, p < 0.01). Sleep-deprived participants exhibited an increased tendency
to seek gain, as evidenced by an increased proportion of Gmax vs. Pmax choices in gainfocus trials (t(28) = 2.18, p < 0.05), together with a lower proportion of Lmin vs. Pmax
choices in loss-focus trials (t(28) = 2.05, p < 0.05, Appendix Figure B-1). SD also
resulted in increased response times during the response phase of the decision-making
task (t(28) = 5.61, p < 0.001). Importantly, participants remained sensitive to the
expected-value relationship between the two choices in both states, indicating that SD led
to a change in preferences, not a simple increase in decision variability (Appendix
Figure B-2).
SD also resulted in reduced psychomotor vigilance, a measure of sustained
attention, as indexed by increased average response times (t(28) = 2.7, p < 0.05) and
lapses (t(28) = 3.42, p < 0.01) in the Psychomotor Vigilance Task. Critically, this decline
in sustained attention did not correlate with changes in economic preference.
We next estimated a risk parameter (alpha) and loss-aversion parameter (lambda)
for each participant in each state. Participants were more risk-seeking following SD (αRW
= 0.95, αSD = 1.10, t(28) = 2.16, p<0.05), consistent with an increased tendency to chase
large gains. Importantly, this parameter was positively correlated with proportion of
Gmax choices (rRW = 0.6, rSD = 0.46) and negatively correlated with proportion of Lmin
95

<-----Page 110----->choices in both states (rRW = -0.62, rSD = -0.58). There was no significant difference in the
loss-aversion parameters across state. Thus, we emphasize that these effects of SD can be
considered either as changes in decision parameters or as an overall shift in choice bias
(without recourse to any specific model). We note that previous studies using similar
multi-attribute risky choice task suggest that using standard decision parameters to
predict behavior leads to specific errors; e.g., not accounting for the high proportion of
Pmax choices (Payne, 2005; Venkatraman et al., 2009b). Thus, we hereafter use
proportions of choices as covariates in subsequent analyses, while noting that these
specific effects may be consistent with an overall increase in a risk-seeking parameter.

4.2.2 Neuroimaging Findings: Decision Phase
Across both states, consistent with prior studies of risky decision making (Huettel
et al., 2006; Platt and Huettel, 2008; Rangel et al., 2008), we observed task-related
increases in bilateral intraparietal sulcus, dorsolateral prefrontal cortex (dlPFC), anterior
insula (aINS) and dorsomedial prefrontal cortex (dmPFC) activation (Appendix Table
B-1).
After a night of normal sleep, higher activity in the right aINS for loss-focus trials
correlated with increased preference for the Lmin option (r = 0.43, p < 0.05), while
increased activity (in this case, reduced deactivation) in the ventromedial prefrontal
cortex (vmPFC) for gain-focus trials correlated with an increased proportion of Gmax
choices (r = 0.43, p < 0.05, Appendix Figure B-3). These findings concur with previous
studies associating aINS activation with loss-averse behavior (Paulus et al., 2003;
Kuhnen and Knutson, 2005; Venkatraman et al., 2009b) and vmPFC activation with gain96

<-----Page 111----->seeking behavior (Bechara et al., 2000b; Tobler et al., 2007; Venkatraman et al., 2009b).
Additionally, we also observed that activation in the vmPFC for gain-focus trials
following normal sleep correlated positively with risk parameter αRW (r = 0.45, p < 0.001)
suggesting that our choice-based interpretations would be largely consistent even when
using a parametric approach.
Sleep deprivation resulted in reduced activation of bilateral intraparietal sulci, and
increased activation in vmPFC (Figure 4-2A, B) and right thalamus (Appendix Table B2). SD-related reduction of task-related parietal cortex activation has been extensively
reported (Bell-McGinty et al., 2004; Chee and Chuah, 2007; Chee et al., 2008; Tomasi et
al., 2009) and is not discussed further in this manuscript.

Figure 4-2: Sleep deprivation biased neural systems underlying decision
making.
97

<-----Page 112----->In addition to the main effects described above, sleep deprivation led to reduced
activation in the right anterior insula (Figure 4-2C) and dorsomedial prefrontal cortex
(dmPFC) during loss-focus trials (Appendix Table B-2). Notably, these SD-induced
changes in activation correlated with SD-induced changes in behavior. A reduced
propensity to make Lmin choices when sleep deprived correlated with reduced right
anterior insula activation during these trials (r = 0.38, p < 0.05 Figure 4-3A). There was
also a significant negative correlation between state-related changes in the proportion of
Lmin choices and changes in vmPFC activation (r = 0.46, p < 0.01, Figure 4-3B), driven
possibly by the increased focus on the higher ranked Pmax choices during these trials
following SD. The SD-related decrease in activation in the right anterior insula for lossfocus trials correlated positively, across participants, with an increase in activation in the
vmPFC for the gain-focus trials (r = -0.44, p < 0.01, Figure 4-3C). SD did not affect
dorsolateral prefrontal cortex (dlPFC) activation, even at an uncorrected threshold of p <
0.005.

Figure 4-3: Changes in magnitude of activation predicted shifts in
preferences following sleep deprivation

98

<-----Page 113----->4.2.3 Neuroimaging Findings: Outcome Phase
After making a series of decisions about risky gambles, each participant passively
viewed a subset of those gambles being resolved to an actual monetary gain or loss.
Activity in the ventral striatum (vStr) and ventromedial prefrontal cortex (vmPFC)
increased for gains relative to losses across both sessions, consistent with the association
of these regions with reward processing (Breiter et al., 2001; Knutson et al., 2003;
Seymour et al., 2007). No region showed significantly greater activation for losses over
gains in either session.

Figure 4-4: Sleep deprivation increased neural sensitivity to gain outcomes
Following SD, there was a significant increase in gain-related activity in the vStr
and vmPFC compared to after a normal night of sleep (Figure 4-4). Conversely, SD was
associated with marked attenuation of loss-related activation within the left anterior
insula (Figure 4-5). Changes in anterior insula activation occurred at the identical
location to where sleep-deprived persons showed attenuated responses to losses in an
earlier study (Venkatraman et al., 2007). Finally, the decrease in activation of the left

99

<-----Page 114----->anterior insula for losses correlated with the increase in activation in ventral striatum for
gains (r = -0.45, p < 0.05).
Notably, there were no significant correlations between state-induced changes in
the decision and outcome phases in any region of interest, suggesting that SD affects the
processes underlying these two phases differently across individuals.

Figure 4-5: Sleep deprivation diminished neural sensitivity to loss outcomes

4.3 Discussion
Using a risky decision-making task, we showed that sleep deprivation shifted
most persons’ bias from avoiding loss to pursuing gain. This behavioral change
accompanied congruent alterations of activation in brain regions associated with reward
anticipation and emotional processing. Additionally, we observed altered neural
sensitivity to received gains and losses that were directionally similar to but uncorrelated
with altered activation associated with decision making. Finally, the magnitude of SD-

100

<-----Page 115----->induced shifts in risky decision-making strategies was not correlated with SD-induced
reductions in psychomotor vigilance.
Sleep deprivation favors the pursuit of gain
The current study is the first to link SD-induced changes in economic behavior
with changes in brain activation. A previous study found that SD altered activation in
reward-related regions in the absence of any significant differences in choice preferences
(Venkatraman et al., 2007). Since that study only contrasted gambles with positive
outcomes to mixed gambles involving both positive and negative outcomes, the SDrelated alteration of risk preferences could have been masked by the tendency to
maximize the overall probability of winning (Payne, 2005; Venkatraman et al., 2009b).
The present study exclusively used mixed gambles and separated decision and outcome
phases, facilitating the identification of state-related alterations in economic preferences.
While well-rested participants sought to minimize the effect of the worst loss, SD
caused the same individuals to be less concerned about losses and to shift to a strategy
that improved the magnitude of the best gain. In the absence of explicit feedback, this
behavioral change suggests an unfounded rise in expectation for gain as reflected in a
systematic bias in economic preferences following sleep deprivation.
Sleep deprivation altered vmPFC responses in both decision and outcome phases
of the present study. The vmPFC has been shown to be instrumental in computing value
as well as in supporting processes related to learning from reward and punishment (Rolls
et al., 1994; Bechara et al., 2000b; Rangel et al., 2008). One explanation for the effects of
SD on vmPFC activation is that SD could hamper the integration of feedback when
101

<-----Page 116----->making decisions, consistent with the role of this region in learning. However, this seems
unlikely, given that there was no explicit feedback at the end of each trial, and given the
relative preservation of dlPFC engagement during SD.
A more likely alternative is that SD influences valuation. Though several studies
associate vmPFC activation with the implicit overall value of the gamble (Tom et al.,
2007; Levy et al., 2010), participants in this task may frequently be making decisions
without computing an integrative value signal that incorporates all aspects of the gamble.
Instead, there may be systematic biases in the attention paid to different aspects of the
gamble like gains and losses. In this context, we argue that elevated vmPFC activation is
predictive of biases placed on the higher-ranked outcomes (Venkatraman et al., 2009b).
Our findings here fit well with this latter viewpoint, since the SD-related change in
vmPFC activation during decision-making also correlated with an increased focus on the
highest gains. Further, during loss-focus trials, an increase in vmPFC activation following
SD correlated with a decreased preference for the Lmin choices, suggesting a reduced
focus on the lower-ranked Lmin options in favor of higher-ranked Pmax choices within
these trials. Together, these findings suggest that SD-induced increases in vmPFC
activation might underlie the bias towards selecting higher-ranked outcomes when one is
sleep-deprived.
Sleep deprivation reduces the minimization of loss
SD led to decreased activation in the right anterior insula and dmPFC during
decisions that involved loss-focus trials. Activation in these regions has been widely
observed in studies involving emotional awareness, particularly those relating to negative
102

<-----Page 117----->affect (Dalgleish, 2004; Craig, 2009; van Veen et al., 2009). Consistent with these
observations, we found that activation in anterior insula was positively correlated with
Lmin choices in well-rested participants. SD lowered right anterior insula activation, and
this correlated with a decrease in preference for the Lmin choices.
A natural alternative hypothesis is that SD introduces noise into the decision
process, given that under SD participants were equally likely to make Lmin or Pmax
choices on loss-focus trials. However, several aspects of the data make such an
explanation unlikely: (i) Under SD, the proportion of Gmax choices increased and was
significantly greater than chance (χ2 = 16, p < 0.001), (ii) participants showed significant
variability in choice preferences; yet the proportion of Lmin choices varied
systematically between states across participants (r=0.36, p<0.06), (iii) preferences
following sleep deprivation remained sensitive to the expected-value relationship
between the two choices, and (iv) activation levels in dorsolateral prefrontal cortex
(associated with cognitive control and executive function) did not vary as a function of
sleep deprivation. Thus, changes in preferences provide a more parsimonious explanation
for the observed results.
Considered together, SD appears to create an optimism bias; for example,
participants behave as if positive consequences are more likely (or more valuable) and as
if negative consequences are less likely (or less harmful). In support of this general
interpretation, we found that the SD-related decrease in anterior insula activation
associated with loss-focus trials correlated with SD-related increases in vmPFC activation
during gain-focus trials. As activation in these regions are typically associated with
103

<-----Page 118----->salience of negative and positive outcomes respectively (Kuhnen and Knutson, 2005;
Preuschoff et al., 2008; Venkatraman et al., 2009b), it appears that SD biases valuation
by bringing about an increased attentional bias towards higher-ranked positive outcomes
while concurrently reducing concern for losses.
Effects of SD: Choices or Parameters?
In this study, we identified brain systems whose activation correlated with
different choices or with choice tendencies. An alternative yet popular approach in
decision neuroscience involves estimating parameters using decision theoretic models
like prospect theory and identifying brain functions that track changes in that parameter
across individuals. However, in several studies using a similar multi-outcome risky
choice task (but without a state manipulation), participants’ show a strong bias towards
Pmax choices, which is often inconsistent with traditional economic models like expected
utility theory and prospect theory. Instead, individuals appear to adopt an aspiration level
that emphasizes selected aspects of the decision problems that in turn bias choices
(Payne, 2005; Venkatraman et al., 2009b; Venkatraman et al., 2011).
Since sleep deprivation did not lead to changes in the proportion of Pmax choices,
the results in the current experiment are agnostic to model-based and model-free
methods. Not surprisingly, analyzing choices using a parametric approach indicates that
SD still changes risk but not loss-aversion parameter. Moreover, SD-induced changes in
choices were highly correlated with SD-induced changes in the risk parameter across
participants. Thus, SD alters underlying decision preferences, whether expressed in
increased tendency for gain-seeking choices or in a change in parameter of models of
104

<-----Page 119----->risk. One conjecture is that SD modulates these preferences by changing the relative
emphasis paid to different aspects of the complex problem presented; specifically
increasing the biases towards gains relative to losses. This would be consistent with prior
work showing that framing a risky decision as a gain or as a loss leads to different
patterns of choice following SD (McKenna et al., 2007).
SD independently amplifies optimism bias during the outcome phase
When a subset of gambles was resolved to gains or losses at the end of the
experiment, sleep-deprived participants showed increased activation of ventral striatum
and vmPFC following gain outcomes and decreased activation in anterior insula when
gambles were resolved to losses. The attenuated anterior insula activation for losses
mirrors previous findings concerning neural responses at the outcome phase
(Venkatraman et al., 2007). Notably, in the present experiment, the effects of SD on
decision and outcome phases of the task were not correlated.
In a real-world parallel, sleep-deprived gamblers and traders, already saddled with
an optimism bias during decision-making, could further compound gain-seeking, highrisk behavior by being disproportionately incentivized toward reward-seeking while
concurrently being desensitized to ongoing losses. More positively, because SD has
dissociable effects on decision-making and response to outcomes, some sleep-deprived
persons may transcend the state-induced optimism bias and respond more appropriately
to losses as they occur.

105

<-----Page 120----->Potential mechanisms underlying SD-related optimism bias
Risky choice often involves weighting potential gains against potential losses.
Our findings suggest that SD might bias value computations by increasing the emphasis
on the gain outcomes, relative to losses (Kuhnen and Knutson, 2005; Liu et al., 2007).
Strikingly, the shifts in economic preferences were independent of the effects of SD on
vigilance, suggesting that SD’s influence on behavior could vary according to cognitive
domain (Van Dongen et al., 2004). This is particularly relevant in light of increasing
number of persons seeking to maintain performance when sleep-deprived by taking
stimulants. Stimulants may improve vigilance but their influence on other aspects of
cognition, such as decision-making, is less clear (Gottselig et al., 2006; Killgore et al.,
2007; Huck et al., 2008; Killgore et al., 2008). Our findings that SD shapes decision
preferences independent of its effects on vigilance suggest that the traditional
countermeasures may be ineffective in ameliorating the decision biases engendered by
limited sleep.
Future experiments should consider potential cross-sectional heterogeneity in the
effects of SD upon preferences as inter-individual variation in the effect of sleep
deprivation on attention has been shown to be trait like (Van Dongen et al., 2004). The
behavior-imaging correlates of such variation has also been shown in several imaging
studies (Mu et al., 2005; Lim et al., 2007; Chuah and Chee, 2008; Chee and Tan, 2010).
Here, on top of significant main effects of SD, closer inspection also reveals substantial
variability in its effects on individuals’ choices as well as brain activation (Figure 4-3).

106

<-----Page 121----->While there was an overall increase in preference for Gmax choices following SD, there
was a subset of participants who were biased in the other direction.
We conjecture that changes in dopamine neurotransmission following SD may
affect decision making in that state. In a recent study, healthy sleep-deprived persons
showed elevations in dopamine levels in the striatum and thalamus, thought to contribute
to maintaining wakefulness, albeit in a somewhat maladaptive way given the concurrent
decline in visual attention as volunteers engaged in task performance (Volkow et al.,
2008; Volkow et al., 2009). As L-Dopa administered to healthy young adults can
transiently elevate subjective ratings of pleasantness (Sharot et al., 2009), we speculate
that the optimism bias observed in SD could be a byproduct of attempts to sustain
wakefulness by elevating dopamine levels. The varying extent to which this is successful
in a given individual might then account for the dissociation between vigilance and shift
in risk preference.

107

<-----Page 122----->5 Strategic Control in Decision Making: Implications for
Neuroanatomy of Cognitive Control†
In the previous three chapters, the mechanisms underlying variability in risky
choice were elucidated using a complex multi-outcome value allocation task across
multiple methodologies and states. Across all these experiments, choice patterns varied as
a function of problem type, individual variability and state (sleep deprivation) in a
manner that is inconsistent with predictions of most canonical economic models. The
variability in preferences was also associated with systematic changes in the pattern of
information acquisition and processing, and could be predicted by activation in
dorsomedial prefrontal cortex. Together, these findings are consistent with a multiple
strategy perspective in decision making. It is important to reiterate here that the Pmaxheuristic is not a comprehensive model for explaining all decision making under risk.
Instead, it is another tool in the toolbox of strategies that are applicable to a certain class
of problems. Individuals consider it when it is available and readily switch to other ones,
including compensatory strategies consistent with EU and CPT in other situations. The
threshold at which the shifts occur varies as a function of individual variability and traits,
and is indexed by activation in control-related brain regions like the dmPFC.
The multiple strategy perspective for risky choice has been much less common till
date in part due to the fact that risky choice studies have often used very simple stimuli
where subtle changes in decision strategies are more difficult to detect. For example,

†

The contents of this chapter are part of a working paper “Venkatraman, V and Huettel, SA. Strategic control in
decision making under uncertainty.”

108

<-----Page 123----->most experimental studies have used gambles (lotteries or prospects) that have only a few
positive (or zero) monetary amounts to be won. Generally there are no more than two
non-zero outcomes that are possible and the number of alternatives to be considered at
any one time is limited to two (a paired comparison choice problem) or one (a valuation
problem where one rates or assigns a monetary value to a single gamble at a time).
Surprisingly, very few studies exist that involve gambles with a mix of gain and loss
outcomes (Wu & Markle, 2008). There are also very few studies that have investigated
gambles with multiple outcomes or choices between more than two gambles at any one
time (Lopes, 1995; Lopes & Oden, 1999).
The use of simple gamble stimuli plays into the hands of single strategy models as
preferences in these trials are often explained by constructs (parameters) like risk
aversion and loss aversion across individuals (Tom, Fox, Trepel, & Poldrack, 2007). Yet,
these results often do not generalize to more complex gambles with multiple gain and
loss outcomes, which are needed to simulate real-world choice scenarios. The complex
gambles also often encourage the use of multiple strategies that vary across individuals
and task contexts.
Results from studies presented earlier demonstrate that individuals shift strategies
as a function of both problem type as well as individual variability. Individuals with a
strong preference for Pmax heuristic were more sensitive to aspects of the problem that
are related to whether or not this strategy is available; while people who were more
focused on magnitudes and probabilities were more sensitive to changes in expected
value. The variability in choice preferences was also associated with systematic
109

<-----Page 124----->differences in response times and patterns of information acquisition. These findings are
consistent with the use of multiple strategies, with the appropriate strategy selected
contingent on contextual factors.
Multiple Strategy Perspective: The Issue of Strategy Selection
One common criticism of the multi-strategy approach is that the strategy toolbox
essentially represents a flexible storage device, where one can simply launch another new
heuristic to account for decision processes not accountable by the existing set of tools in
the box (Glockner, et al., 2010). The problem is further exacerbated by the lack of wellconstrained conditions for strategy selection, which makes the flexible toolbox approach
an anything-goes model (Glockner, et al., 2010). However, other researchers have
developed a number of approaches that detail how people select between different
heuristics (Marewski, 2010; Payne, et al., 1988; Rieskamp & Otto, 2006). For instance,
cognitive models of strategy selection argue that strategy selection occurs through a
simple cost/benefit analysis (Payne, et al., 1988). In other words, an adaptive decision
maker often evaluates costs (effort and computational resources) and benefits (outcomes,
potential regret, ease of justification) before selecting and applying a strategy. Like other
aspects of decision making, strategic preferences can vary both as a function of the
decision context (like complexity of the problem and timing constraints) and the decision
maker. Alternatively, strategy selection may represent a learned response that is based on
past experiences with different strategies (Rieskamp, 2008; Rieskamp & Otto, 2006),
such that the decision-maker merely chooses the most efficient strategy for each situation
based on prior experience (e.g., reward history).
110

<-----Page 125----->Using fMRI, we sought to find converging evidence for brain regions that are
associated with strategy selection (Venkatraman, et al., 2009). A region that is associated
with strategy selection should (i) show greater activation during trials where individuals
shift from one strategy to another, and (ii) should be able to control activation in brain
regions that are associated with implementing the selected strategy on any given trial.
The dorsomedial PFC (dmPFC) fulfilled both these conditions. Activation in dmPFC
increased when participants switched away from their preferred strategy on a particular
trial (i.e., greater activation when people with a strong preference for Pmax heuristic in
general made non-Pmax choices, and vice versa). Additional analysis revealed
differential choice-related functional connectivity (correlation) of dmPFC to dlPFC and
anterior insula, regions that were associated with the different types of choices above.
Together, these findings support the interpretation that control signals from dmPFC
modulate the activation of choice-related brain regions, with the strength and
directionality of this influence dependent on an individual’s preferred strategy.
These findings, though correlative, are consistent with findings from eye-tracking,
where we find that the Pmax-preferring individuals are more sensitive to whether the
Pmax option is available in a given trial while the non Pmax-preferring individuals are
not. Similarly, the Pmax-preferring individuals also take longer and acquire more
information when making non Pmax choices and vice versa. This increased processing
may be associated with increased level of executive control that is necessary for
switching strategies, as a function of problem type and individual traits. As would be
expected in the case of strategy shifts, we also show differences in the Payne Index with
111

<-----Page 126----->the non Pmax-preferring individuals shifting from an attribute-based information
acquisition approach to a more alternative-based approach. In other words, same
individuals shift their pattern and magnitude of information acquisition across trials due
to changes in decision context. And different individuals demonstrate differences in
information acquisition patterns when making the same choice (e.g., Pmax-preferring
participants make more alternative-based processing for Lmin choices than non Pmaxpreferring participants). Activation in the dmPFC may facilitate these strategy shifts as a
function of decision context and individual variability.
Our neural results are consistent with the growing consensus that dmPFC reflects
a mechanism for identifying and responding adaptively to changes in the environment.
Notably, complex aspects of behavior, like full consideration of decision problems,
require a wide range of processes of executive control. Therefore, one conjecture is that
the dmPFC plays an important role in complex decision making: it signals changes in
how a decision problem is represented, and thus shapes computational processing
elsewhere in the brain based on the current decision strategy.
The rest of this chapter is focused on reviewing existing literature related to the
neural correlates of cognitive control. Specifically, there is considerable evidence in favor
of an important role for both dorsolateral and dorsomedial prefrontal cortex in exerting
executive control. Yet, these do not incorporate strategic control of the form discussed in
our previous experiments. The focus here, and in the remaining experiments presented in
the subsequent chapters, is on developing a neuroanatomical model for cognitive control
that also integrates aspects of strategic control involved in complex decision making.
112

<-----Page 127----->5.1 Cognitive Control
The term cognitive control broadly describes the ability to shape behavior in an
adaptive manner, as a function of current goals and constraints. Different theoretical
models and definitions have emphasized different aspects of control: (i) the ability of the
human cognitive system to configure itself for the performance of specific tasks
(Botvinick et al., 2001); (ii) the ability to coordinate thoughts or actions in relation with
internal goals (Koechlin et al., 2003); (iii) a system that can acquire and implement the
‘rules of the game’ needed to achieve a given goal in a given situation (Miller and Cohen,
2001) or (iv) a system that supports flexible behavior by selecting actions that are
consistent with our goals and appropriate for our environment (Badre, 2008).
Consolidating across these definitions, one can argue that three properties are
fundamental to any system associated with cognitive control: it must be selective, it must
engage in optimization, and it must be hierarchical.
•

Selection: Cognitive control involves selection of actions that are consistent
with present goals and context (Badre, 2008). This selection can occur at
several levels ranging from simple response selection to complex strategy
selection and task switching. An effective control system is therefore one that
facilitates processing in volatile environments, as well as supports
multitasking in the pursuit of multiple goals simultaneously.

•

Optimization: A cognitive control system should have the ability to monitor
and compare actual performance with internal goals and standards and use this
information to optimally and adaptively organize behavior. Therefore, such a
113

<-----Page 128----->system should detect errors and unfavorable outcomes and use this errorrelated feedback to guide subsequent performance adjustments.
•

Hierarchy: Similar to an organization hierarchy that consists of superiors,
subordinates and well-defined lines of communication, a hierarchical control
system is one that operates at multiple levels with each level controlled by a
higher level and exerting control on representations in lower levels. For
example, the lowest level of control could be associated with sensory
processing and selection of motor actions while the highest level of control
might involve multi-tasking and selecting between several concurrent actions.
Information within this hierarchy typically flows in a top-down manner.

5.2 Role of Lateral PFC in Cognitive Control
Historically, the lateral prefrontal cortex has been associated with subserving
cognitive control or the flexible control of behavior (Miller, 2000; Koechlin et al., 2003;
Ridderinkhof et al., 2004b; Badre, 2008; Egner, 2009). The frontal neurons assimilate
and process contextual information, and bias subsequent selection of appropriate action
pathways in other brain regions. These functions become particularly important when
inputs are ambiguous; involve uncertainty or when one has to choose flexibly between
multiple responses depending on task context. The prefrontal cortex can facilitate these
functions due to its strong connections to other sensory regions in the brain (Barbas and
Pandya, 1989; Petrides, 2005), its capacity for actively maintaining task and goal-related
representations and its ability to learn and update these representations over time (Miller
and Cohen, 2001).
114

<-----Page 129----->Several recent lines of research also suggest a strong hierarchical organization
within the lateral prefrontal cortex, with the more rostral regions involved in contextual
control and more caudal regions associated with sensory control (Koechlin et al., 2003;
Badre, 2008). For example, the cascade model proposed by Koechlin and colleagues
argues for a hierarchy of executive processes from premotor to more anterior prefrontal
regions that control behavior according to the stimuli (sensory control), current
environmental constraints (contextual control) and the temporal episode (branching
control) in which the stimulus occurs respectively (Koechlin et al., 2003). Along similar
lines, Badre and colleagues posit that the rostral-caudal hierarchy can be better
understood in terms of levels of abstractions in representations of rules for action
selection (Badre and D'Esposito, 2007). Yet another proposal argues for a rostral-caudal
hierarchy in the prefrontal cortex based on relational complexities (Christoff and
Gabrieli, 2000; Christoff et al., 2001). Although these models differ in the details of their
hypotheses about specific regions, what is common to all of them is a posterior-toanterior gradient characterized by increasing complexity.
In summary, most of the postulated functions for the lateral PFC involve the
implementation of cognitive control. However, when there is a need to monitor and
detect changes in the environment, the lateral PFC still relies on feedback inputs from
other brain systems, most notably the dorsomedial PFC. For this reason, the dmPFC has
also been consistently associated with an active role in cognitive control, particularly in
terms of performance monitoring as well as in shaping behavior in a flexible manner
based on context, goals and motivation.
115

<-----Page 130----->5.3 Role of Dorsomedial PFC in Cognitive Control
The interest in dorsomedial prefrontal cortex arise from several lines of research
that implicate this region with functions that are integral to cognitive control like error
monitoring (Carter et al., 1998; Brown and Braver, 2005b), conflict monitoring
(Botvinick et al., 1999; Barch et al., 2000; Kerns et al., 2004), reward processing and
outcome evaluation (Hadland et al., 2003; Rogers et al., 2004), reinforcement learning
(Kim et al., 2006) and decision making under risk and uncertainty (Hadland et al., 2003;
Rushworth et al., 2004; Kennerley et al., 2006). More importantly, the dmPFC satisfies
all three characteristics of a control system: selection, optimization and hierarchy as
discussed in detail below.
Selection: DmPFC exerts control preferentially in volatile environments
The dorsomedial prefrontal cortex has been associated with the detection of
conflict in tasks that require overriding of prepotent responses as well as selection among
a set of mutually incompatible response processes (Carter et al., 1998; Botvinick, 1999).
The detected conflict signal then triggers strategic adjustments in cognitive control which
serve to prevent conflict in subsequent performance. Many such studies have used
variants of the Stroop paradigm (MacLeod, 1992), which requires individuals to inhibit a
fast, prepotent response (e.g., color word reading) and instead engage in a slower, less
common process (e.g., naming an ink color). Under such task conditions, a very large
number of studies have reported activation in dmPFC (Bush et al., 1998; Derrfuss et al.,
2005), as reviewed by (Bush et al., 2000). Similar findings have also been observed with
other tasks that involve response incompatibilities like the flanker task (Bugg, 2008),
116

<-----Page 131----->Simon task (Kerns, 2006) and go/no-go paradigms (Kawashima et al., 1996; Tsujimoto et
al., 1997).
Given that conflict can occur at various levels, a key question that arises then is
whether the involvement of dmPFC is specific to conflicts at the level of response
selection or whether it extends to other types of conflict. While vast majority of initial
studies suggest a specificity for response-related conflict especially given the strong
connectivity of this region to motor structures including premotor cortex, more recent
studies posit a more broader functional role for dmPFC in detecting conflict at other
levels including stimulus evaluations and task representation (Botvinick et al., 2004).
Several other studies have also found increased activation in the dmPFC for complex
decisions, though these could have been confounded with activation related to response
preparation (Paulus et al., 2002; Walton et al., 2003; Rushworth et al., 2004; Zysset et al.,
2006; Botvinick and Rosen, 2008; Pochon et al., 2008).
Pochon and colleagues explicitly investigated whether the conflict monitoring
role extended to complex decisions that involve the integration of higher-order beliefs
and preferences. In their study, male participants chose the more attractive of two female
faces. The similarity of the two faces was modulated such that some trials invoked higher
decision conflict while others evoked lower-levels of decision conflict. Activity in the
dmPFC was greater for trials involving higher decision conflict. Importantly, this
increased activation was found even for trials where participants did not have to respond,
suggesting that it was specific to decision conflict and not due to selecting between
multiple motor responses (Pochon et al., 2008).
117

<-----Page 132----->Activation in the dmPFC has also been associated with conflict arising from
subjective decision preferences, particularly when choices run counter to general
behavioral tendencies or strategies. We define the conflict arising in these instances as
strategy-related control demands. For instance, in a study involving the framing task, all
participants exhibited a strong tendency towards the framing heuristic, driven by
increased activation in the emotional amygdala system. Participants also showed
increased activation in the dmPFC for choices that were inconsistent with framing
effects. The authors argued that increased activation in dmPFC in this study represents a
conflict between the generally preferred emotional heuristic response and a more rational
analytical choice (De Martino et al., 2006). In other words, increased activation in this
region helps control the automatic activation of the emotional system and hence leads to
more rational choices. Here, all participants exhibited the same bias towards using the
framing heuristic. However, it is becoming increasingly evident from the studies
presented in the earlier chapters that individuals use a variety of strategies in representing
and solving complex decision problems (Payne et al., 1988; Gigerenzer et al., 1999;
Venkatraman et al., 2009b). Importantly, people switch between these strategies in an
adaptive manner as a function of decision context and individual traits (Payne et al.,
1993) and dmPFC may play an important role in exerting strategic control.
For instance, in the fMRI study using risky choice paradigm in Chapter 3, we
found that activation in dmPFC predicted whether an individual adaptively made a choice
that was inconsistent with their overall preferred strategy. In other words, activation in
this region was greater when people who normally prefer the simplifying strategy made a
118

<-----Page 133----->compensatory choice and vice versa (Venkatraman et al., 2009b). Since our experimental
design explicitly separated the decision and response components, one could rule out the
alternative explanation of activation being related to response selection (see Appendix
A). Therefore, a parsimonious explanation for dmPFC function could be that it supports
aspects of decision making that are coded in relation to an underlying strategic tendency.
We validated this hypothesis further in an independent experiment using a different
decision making task, as discussed in the next chapter.
Optimization: DmPFC regulates other brain regions
As introduced above, one of the key aspects of a control system is the ability to
monitor and evaluate the performance of various systems and make appropriate
adjustments as necessary. The dorsomedial prefrontal cortex performs such a function in
cognitive control, as supported by evidence from neuropsychological studies where
lesions to the anterior cingulate cortex lead to deficiencies in the ability to exert cognitive
control (Ochsner et al., 2001; Swick and Jovanovic, 2002).
The dmPFC has been shown to play an important role in the continuous
assessment of ongoing actions and their corresponding outcomes. Of particular interest is
the postulated role of the dmPFC in commission of errors, demonstrated both using the
transient potential known as the error-related negativity (ERN) in EEG (Gehring et al.,
1995) as well as fMRI (Kiehl et al., 2000; Menon et al., 2001). Subsequent studies also
demonstrate an increase in dmPFC activity when actions specifically lead to errors
(Ullsperger and von Cramon, 2003).

119

<-----Page 134----->A slightly different perspective argues for a more general error-likelihood
estimation function within the dmPFC, of which conflict monitoring and error detection
are special cases (Brown and Braver, 2005a). Brown and Braver demonstrate, using
integrated computational neural modeling and neuroimaging experiments, that activation
in dmPFC might predict error likelihood in a given context, even when these trials have
no error or response conflict. According to this model, activation in dmPFC to a given
task condition will be proportional to the perceived likelihood of an error in that
condition, even before any external feedback is provided. The authors further speculate
that this signal may be dopaminergic in nature and hence could play an important role in
reinforcement learning and recruitment of cognitive control (Brown and Braver, 2005a).
Another proposal for the role of dmPFC in cognitive control is that it plays a more
general role in representing and updating action values (Behrens et al., 2007). For
instance, non-human primates could no longer use the most recent outcome to guide
choice following lesions to the anterior cingulate sulcus (Kennerley et al., 2006). In a
recent study, Behrens and colleagues demonstrate that humans have the ability to assess
volatility in an optimal manner and adjust decision making accordingly. More
importantly, this volatility is reflected by fMRI activation in the dmPFC when each trial
outcome is observed. When a new piece of information becomes available, activity in this
region increases proportional to its salience for predicting future events (Behrens et al.,
2007). Since prediction error signals are often associated with dopaminergic regions and
ventral striatum, the authors speculate that the projection from dmPFC to ventral striatum
might allow the volatility-based learning rate to modulate the influence of current
120

<-----Page 135----->prediction error on the next value estimate. This model could also explain the increased
activation in this region during task switching, as the environment is highly volatile in
these situations and hence outcomes are especially informative.
Any region that plays an optimizing role for cognitive control should also detect
the need for greater control and subsequently signal this need for reactive adjustments to
other regions of the brain. As discussed above, the lateral PFC has been postulated to
play an important role in implementing cognitive control. Consistent with this notion,
Kerns and colleagues hypothesized that increased activation in dmPFC should lead to
greater implementation of cognitive control in the subsequent trial, as manifest in
increased lateral PFC activation (Kerns et al., 2004). They found that when incongruent
trials were associated with strong activity in the dmPFC, relatively low interference was
observed in the next trial. More importantly, they demonstrated that the magnitude of
activation change in the dmPFC for the current trial predicted subsequent change in
dorsolateral PFC activation on the next trial, suggesting that dmPFC may engage
executive control regions based on task demands (Kerns et al., 2004).
In our study involving risky choice discussed in Chapter 3, we showed that the
dmPFC demonstrates differential task-specific functional connectivity with choicerelated brain regions. Specifically, we found increased functional connectivity between
dmPFC and dorsolateral PFC only for simplifying choices and increased functional
connectivity between dmPFC and anterior insula for compensatory choices. Though these
effects were correlative, we hypothesize that dmPFC shapes decision-making at a
strategic level by switching between appropriate brain systems as a function of decision
121

<-----Page 136----->context and individual traits. Such strategic considerations are unlikely to be limited to
economic contexts; they are likely to extend to emotional and social contexts. For
instance, evidence across primate lesion and neuroimaging studies suggest a spatial
topography within dmPFC such that distinct subregions support volatility associated with
social and non-social contexts, and that those subregions have distinct functional
connectivity to regions in ventral PFC (Rushworth et al., 2007; Rudebeck et al., 2008).
In another recent study, Kouheiner and colleagues argue that the activation in the
medial prefrontal cortex for errors, conflict situations, rewards and penalties across
several studies represents its role in monitoring motivationally salient events (Kouneiher
et al., 2009). Further, they argue that the motivational processes in the medial prefrontal
cortex energize a cascade of top-down control processes in the lateral prefrontal cortex,
along the lines demonstrated by Kerns and colleagues. Importantly, they also argue that
motivational processes in the dmPFC operate according to the rewarding values of the
actions rather than demands of cognitive control (Kouneiher et al., 2009). We return to
the connectivity between medial and lateral prefrontal cortex and its role in cognitive
control in Chapter 7.
Hierarchical: DmPFC exerts control in a topographic manner
The findings from several studies involving the dmPFC argue for a functional
specialization within this region. An early form of specialization divided the dmPFC into
a dorsal aspect involved in cognitive control and an anterior aspect associated with
emotional processing (Bush et al., 2000; Bush et al., 2002).

122

<-----Page 137----->Kouheiner and colleagues found an anterior-to-posterior organization of
motivational processes in the dmPFC (Kouneiher et al., 2009). The posterior regions,
specifically the pre-SMA, showed transient responses to immediate contextual incentives
signaling the rewards and penalties at stake in immediate action. Similarly, the middle
regions, particularly the dorsal anterior cingulate cortex, showed sustained activations
that were associated with the rewards and penalties at stake in the ongoing behavioral
episode, regardless of immediate contextual incentives (Kouneiher et al., 2009). Overall,
these findings indicate that the dmPFC implements, from the posterior to the anterior
regions, two levels of motivation processes, namely contextual and episodic motivation.
Along similar lines, Beckmann and colleagues used magnetic resonance diffusion
tractography to delineate probabilistically the anatomical connectivity of the cingulate
cortex to other brain regions (Beckmann et al., 2009). The authors first identified nine
distinct subregions within the cingulate cortex based on its probabilistic connectivity
profiles with the rest of the brain. Specifically, the authors found three distinct subregions
within the dmPFC based on differential probabilistic connectivity to lateral PFC,
premotor and precentral cortices respectively, strongly suggesting functional
specialization within the region.
Based on the anatomical connectivity profiles (Beckmann et al., 2009), one
hypothesis is that the posterior regions would be more involved in response-related
control while the anterior regions would be associated with more decision-related control.
In the first of two experiments, we sought to explicitly test this functional organization
using two tasks in the same participants that evoke different levels of control, namely
123

<-----Page 138----->response, decision and strategy related control. In the second experiment, we used
resting-state data to test whether the topography in the dmPFC might even extend to the
connectivity with corresponding regions in the lateral PFC. Based on the findings across
these two experiments, which are discussed in detail in the next two chapters, a novel
hypothetical model for cognitive control is proposed that is based on hierarchical
interactions between the medial and lateral prefrontal cortex as a function of varying
control demands.

124

<-----Page 139----->6 Evidence of Topography in Dorsomedial Prefrontal
Cortex†
As introduced in the previous chapter, many neuroscience studies have implicated
the medial prefrontal cortex in a variety of cognitive functions like conflict monitoring
(Botvinick et al., 2001; Pochon et al., 2008), error detection (Carter et al., 1998), outcome
evaluation (Bush et al., 2002; Gehring and Willoughby, 2002), reinforcement learning
(Kennerley et al., 2006), decision-making under risk and uncertainty (Rushworth et al.,
2005; Behrens et al., 2008), emotions (Etkin et al., 2006) and social interactions (Amodio
and Frith, 2006; Behrens et al., 2008; Behrens et al., 2009). Meta-analyses have
suggested that these functions are supported by brain regions along the anterior cingulate
sulcus and extending dorsally, hereafter collectively referred to as dorsomedial prefrontal
cortex (dmPFC) (Ridderinkhof et al., 2004a; Beckmann et al., 2009).
There are important reasons to posit that functional specialization exists within
the dmPFC. First, there exists long-standing evidence for topographic organization within
the medial prefrontal cortex, considered more generally. As one related example, research
on executive function has investigated the anterior cingulate cortex (ACC), which
typically denotes a swath of medial prefrontal cortex that is broader and more ventral to
dmPFC (e.g., including more rostral areas but not regions around the paracingulate
gyrus). Reviews have divided ACC into a dorsal aspect associated with cognitive control
and an anterior aspect associated with emotional function (Bush et al., 2000). Second,

†

The contents of this chapter have been published as “Venkatraman V, Rosati AG, Taren AA, Huettel SA (2009a)
Resolving response, decision, and strategic control: evidence for a functional topography in dorsomedial prefrontal
cortex. J Neurosci 29:13158-13164.”

125

<-----Page 140----->there is evidence that regions within dmPFC differ in their patterns of anatomical
connectivity with other brain regions (Beckmann et al., 2009). Third, recent converging
evidence from primate lesion studies and functional neuroimaging data indicates a
dissociation between contributions of the anterior cingulate sulcus and the anterior
cingulate gyrus to non-social and social behavior, respectively (Behrens et al., 2008).
Finally, there is strong evidence for a topographic organization within the lateral
prefrontal cortex (Koechlin et al., 2000; Christoff et al., 2003; Koechlin et al., 2003).
Given the postulated role of dmPFC in shaping activation in lateral PFC (Kerns et al.,
2004; Meriau et al., 2006), a similar pattern of functional specialization may exist within
the dmPFC.
Here, we evaluated whether dmPFC evinces a functional topography associated
with the form of task-related cognitive control. We hypothesize that posterior regions of
dmPFC, which show greater connectivity to motor and pre-motor regions, would be
associated with response-related control while more anterior regions, which show greater
connectivity to dorsolateral prefrontal cortex, would predict control demands related to
complex decision-making. Moreover, based on initial suggestions that dmPFC is also
recruited when individuals make choices that run counter to general behavioural
tendencies or strategies (Paulus et al., 2002; De Martino et al., 2006; Hampton and
O'Doherty J, 2007; Venkatraman et al., 2009b), we also hypothesize that this strategyrelated control would evoke activation in the most anterior aspect of dmPFC. Such a
result would parallel the demonstrated topographic pattern in lateral PFC.

126

<-----Page 141----->Figure 6-1: Schematic of Experimental Tasks
We tested these hypotheses in an fMRI study that evoked these three distinct
forms of control demands – response, decision, and strategy – within the same
participants and with distinct behavioral covariates. To evoke response-related control
demands, we used a counting Stroop task (Figure 6-1A), using the participant-byparticipant response-incongruency effect as a measure of response-related control
(Figure 6-2A). For decision and strategic control demands, we used an attributebalancing task (Figure 6-1B) where participants had to decide between two stocks based
on their attribute ratings: the balanced stock had equal ratings on both attributes, while
the extreme stock had a high rating on one attribute but lower rating on other. Participants
showed a strong bias for the balancing strategy (choosing the balanced option), consistent
with previous studies (Chernev, 2004, 2005). On each trial, the decision-related control
demand was characterized by the difference in relative desirability of the two options
(Figure 6-2B). Strategic control demands were characterized according to the degree of
bias toward the balancing strategy within each individual (Figure 6-2C). Should these
127

<-----Page 142----->three forms of control evoke activation in distinct regions of dmPFC, and moreover if
that activation scales with different behavioral covariates, there would be strong evidence
in support of a functional topography within dmPFC.

Figure 6-2: Definition of response-, decision- and strategy-related control.

6.1 Methods
Twenty-three young adults (7 males, mean age = 21.9) participated in this study.
All participants acclimated to the scanning environment using a mock MRI scanner and
participated in two short practice runs consisting of six trials each, one inside and one
outside of the MRI scanner. Three participants were excluded prior to data analysis – two
due to excessive motion and one for poor behavioral performance – leaving a total of 20
participants in the final analyses. We used an incentive-compatible design in which
participants received monetary compensation both for participation and for their
128

<-----Page 143----->performance in the experiment (see Appendix C for details). All participants gave
written informed consent as part of protocols approved by the Institutional Review
Boards of Duke University and Duke University Medical Center.
Stimuli and Experimental Conditions. Response-related control demands were
evoked using a counting Stroop task (Bush et al., 1998). We employed a block design for
this task. In the Neutral condition, participants were presented with multiple repetitions
of animal words (e.g. dog, cat) and asked to count the number of times the word was
presented. In the Incongruent condition, they were presented with multiple repetitions of
number words (one, two, three or four) and asked to count the number of times the word
was presented. However, the number of repetitions was always incongruent with the
number word itself (for e.g., “two” presented four times). Each word was repeated
between 1-4 times and participants responded by pressing the corresponding button on a
4-button response box. We calculated, for each participant, the magnitude of the Stroop
incongruency effect as a measure of response-control demands.
Decision-related and strategy-related control demands were evoked using an
attribute-balancing task where all participants were presented with a total of 90 sets of
three real stocks, each rated on two attributes that provided real metrics of stock
performance (Figure 6-1B). To minimize the influence of participants’ prior knowledge
or financial biases, the identity of the stocks and the nature of the attributes were
concealed from the participants until after the experiment. On each trial, the three stocks
were labeled as “A”, “B”, and “C”, and the two attributes were labeled as “a1” and “a2”

129

<-----Page 144----->and shown as percentile rankings. The participants’ task was to predict the betterperforming stock based only on these attributes.
All choice trials involved one stock that had balanced values for both attributes,
one stock that had a good rating on attribute a1 but a poorer rating on attribute a2, and a
third stock in which this pattern was reversed with slightly varying attribute ratings (see
Appendix C for more details). In each trial, participants had to choose between a
balanced stock and an extreme stock that was randomly selected from the other two
alternatives for that trial. Choosing the balanced stock was consistent with the simple
attribute-balancing heuristic identified in previous studies using similar paradigms
(Chernev, 2004, 2005).
In addition, we randomly interspersed six catch trials, where the extreme
alternative had higher ratings than the balanced option for both attributes and thus was
the more desirable option. These trials thus served to ensure that participants followed
instructions and attended to the task. One participant who performed contrary to
expectations in the catch trials was excluded from further analysis.
We manipulated the decision-related control demands across trials by varying the
expected-value relationship (defined as the sum of two attributes for each stock) between
the balanced and extreme choices (Figure 6-2B). In 36 trials (Congruent condition), the
balanced stock had a higher expected value compared to the alternative option. In another
36 trials (Incongruent condition), the balanced stock had a lower expected value
compared to the alternative option. In the remaining 18 choice trials (Equal condition),
the expected value for the balanced stock was equal to the expected value of the
130

<-----Page 145----->alternative option. Decision-related control demands were minimal (i.e., where decisions
were easiest) in the congruent condition, followed by the incongruent condition, and
were maximal in the equal condition (i.e., where both choices have similar expected
value).
Finally, we defined strategy-related control demands according to the degree to
which a given choice (i.e., balanced or extreme, on each trial) deviates from the
individual’s empirical strategy preferences (i.e., the proportion of balanced choices across
all trials). That is, strategic control demands are maximal when a participant who has a
strong bias toward one type of choice makes the opposite choice, but minimal when
participants make choices consistent with the strong bias (Figure 6-2C). To obtain a
measure of activation evoked by strategy-related control, we introduced each
participant’s strategic tendency into the analyses as a between-participants covariate.
Experimental Design and Task Timing. Participants first participated in four
runs of the attribute-balancing decision task, each containing 24 gambles and lasting
approximately 6 minutes. Each trial began with the display of all three stocks for 4 or 6s.
Participants were instructed previously to examine the stocks as presented. Subsequently,
two of the three stocks were highlighted in red (one involving balanced attributes and
other extreme attributes). Participants were instructed to choose between one of these two
stocks and incentivized with a monetary bonus for picking the better performing stock.
They had 6s to make their choice, whereupon two arrows appeared specifying which
button corresponded to which choice. The association of the buttons to choice was
random. Participants were instructed to arrive at their decision during the 6s interval and
131

<-----Page 146----->to press the button corresponding to their choice as soon as the arrows appeared.
Response times were defined as the interval between the appearance of arrows and the
button-press response. The decision and response phases were explicitly separated to
prevent the contamination of decision effects with response-preparation effects. During
the inter-trial interval of 4-8 seconds, a fixation cross was displayed on the screen. Notice
that no feedback was provided at the end of each trial and hence there was no explicit
learning during the decision phase of the task.
After four runs of the decision task, all participants completed one run of the
Counting Stroop task. To maximize power for the contrast between Neutral and
Incongruent trials, our design alternated between blocks of 6 trials of each type (3s
between trial onsets, 18s blocks, 17 blocks/run), without any fixation or non-task blocks.
A final 6-minute run, whose data are not discussed in this manuscript, resolved a subset
of the trials from the decision phase to actual stock labels and attributes. The winning
stock was then identified based on data we collected on the real performance of these
stocks (see Appendix C), and participants received a monetary bonus based on the
performance of their selected stock on two randomly chosen trials.
Before the fMRI data collection, participants had the opportunity to practice the
experimental task (without reward) in two six-trial blocks, one presented outside the MRI
scanner and the other presented within the MRI scanner but prior to collection of the
fMRI data. All stimuli were created using the Psychophysics Toolbox for MATLAB
(Brainard, 1997; Pelli, 1997) and were presented to the participants via MR-compatible

132

<-----Page 147----->LCD goggles. Participants responded with the index fingers of each hand via a MRcompatible response box.
Imaging Methods. We acquired fMRI data on a 4T GE scanner using an inversespiral pulse sequence with parameters: TR = 2000ms; TE = 30ms; 34 axial slices parallel
to the AC-PC plane, with voxel size of 3.75*3.75*3.8mm. High-resolution 3D full-brain
SPGR anatomical images were acquired and used for normalizing and coregistering
individual participants’ data.
Analysis was carried out using FEAT (FMRI Expert Analysis Tool) Version 5.63,
part of FSL (FMRIB's Software Library, www.fmrib.ox.ac.uk/fsl) package (Smith et al.,
2004). The following pre-statistics processing steps were applied: artifact removal using
MELODIC and in-house scripts, motion correction using MCFLIRT, slice-timing
correction, removal of non-brain voxels using BET, spatial smoothing with a Gaussian
kernel of FWHM 8mm, and high-pass temporal filtering. Registration to high resolution
and standard images was carried out using FLIRT. All statistical images were thresholded
using clusters determined by z > 2.3 and a whole-brain-corrected cluster significance
threshold of p < 0.05. The same analysis procedures and thresholding were used for
analyses involving a between-participants covariate. The MRIcron package was used for
visualizing brain images (Rorden et al., 2007).
GLM Analysis. For the response-related control analysis, we used one regressor
to model activation in the incongruent blocks of the Stroop task (i.e., treating the neutral
blocks as baseline). We introduced the response-time difference between Incongruent and
Neutral trials as a covariate in the across-participants analysis to determine the focus of
133

<-----Page 148----->activation. The decision-related control analysis used six total regressors to model
activation in the attribute-balancing task: three task regressors for the three conditions
(congruent, incongruent and equal), one regressor for the initial presentation of the
stocks, one regressor for catch trials, and one regressor for the response period (scaled by
response time). We defined active voxels using a conjunction analysis of [equal >
incongruent] and [incongruent > congruent]. The model used for the strategy-related
control analysis contained five total regressors: two regressors modeling the balanced
and extreme choices of participants in conditions that cause the greatest decision conflict,
one regressor modeling the responses in the remaining conditions, one regressor for the
initial presentation of the stocks, and one regressor to model the participant responses.
We introduced each participant’s relative bias towards the balancing strategy (ztransformed proportion of balancing choices) as a covariate in the contrast between the
balanced and extreme choice regressors.
Event-related regressors were generated by convolving impulses at the onsets of
events of interest with a double-gamma hemodynamic response function. Second-level
analysis for condition and choice effects within each participant was carried out using a
fixed-effects model across runs. Random-effects across-participants analyses were
carried out using FLAME Stage 1.

6.2 Results
For the Stroop task, participants were significantly more accurate in the Neutral
compared to the Incongruent condition [t(19)=2.46, p<0.05]. Similarly, participants also
took significantly longer in the Incongruent condition compared to the Neutral condition
134

<-----Page 149----->[t(19)=3.88, p<0.001]. Taken together, these findings are consistent with increased
demands for response-related control in the Incongruent condition.
For the attribute-balancing task, participants showed a significant bias toward the
balanced alternative, preferring it in 58% of the trials. Within the equal condition, they
preferred the balanced alternative in 65% of the trials [t(19) = 3.9, p<0.005]. Despite this
overall bias, participants’ choices were still sensitive to changes in expected value.
Consistent with our predictions for decision-related control demands, we found that
participants’ response times were slowest for the equal trials, intermediate for
incongruent trials, and fastest for congruent trials (Appendix Table C-1). Finally,
participants also showed substantial individual variability in their choice preferences,
providing a foundation for our analyses of strategic control (Appendix Figure C-1).

6.2.1 Response-related Control

Figure 6-3: Posterior dmPFC activation predicted response-related control
demands

135

<-----Page 150----->We found increased activation in the dorsomedial PFC, dorsolateral PFC and
parietal cortex for the Incongruent condition in the Stroop task (Appendix Table C-2,
Appendix Figure C-2). When we used the difference in response time between
Incongruent and Neutral conditions as a covariate, we found that activation in left
dorsolateral prefrontal cortex and a posterior region of the dmPFC (pDMPFC) increased
linearly with increasing response conflict (Figure 6-3). The pDMPFC activation cluster
was localized to the posterior part of the cingulate sulcus (BA 32). Activation within this
cluster also correlated with an independent trait measure of motor impulsiveness (Patton
et al., 1995) across participants (r=0.49, p<0.05, Appendix Figure C-3).

6.2.2 Decision-related Control
We next sought to identify brain regions whose activation was driven by the
decision phase (when participants deliberated between the two stock options) in the
attribute-balancing task. We performed a conjunction analysis to identify regions
showing significant effects for each of the two individual decision-related contrasts:
equal > incongruent and incongruent > congruent. We found increased activation in right
dorsolateral prefrontal cortex, right inferior parietal lobule, and a region of dmPFC
anterior to that observed for response-related control (Appendix Figure C-4, Appendix
Table C-3). The dmPFC activation cluster for this contrast was also along the cingulate
sulcus (BA32), anterior to the cluster for response-related control, and we refer to it as
mDMPFC. Within this region, activation increased in a stepwise manner for our three
levels of decision-related control (Figure 6-4). Notably, these effects cannot be attributed

136

<-----Page 151----->to response conflict, given that they are time-locked to the decision phase that occurs
before response mappings had been indicated to the participant.

Figure 6-4: Activation in middle dmPFC predicted decision-related control
demands

6.2.3 Strategy-related Control
Next, we sought to identify regions that indexed strategic control demands across
participants, using individuals’ preference for the balancing strategy as a covariate in our
between-participant analysis. Analysis of the main-effect of choice is presented in
Appendix C; see Appendix Figure C-4). We found that individual differences in
strategic preferences across participants predicted the relative activation evoked by
balanced and extreme choices in only one region: anterior dorsomedial prefrontal cortex
(aDMPFC; Figure 6-5), along the paracingulate region (BA 9). People who expressed a
greater preference for the balanced option exhibited a greater increase in dmPFC
activation for the extreme option compared to the balanced option, and vice versa. The

137

<-----Page 152----->difference in activation also correlated with an independent trait measure of need for
cognition (Epstein et al., 1996b), which measures the relative cognitive effort associated
with decision making (r=0.60, p<0.005, Appendix Figure C-5).

Figure 6-5: Activation in anterior dmPFC predicted strategy-related control
demands
To verify that the clusters implicated in strategy- and decision-related control
were functionally distinct, we conducted a post hoc ROI analysis within the aDMPFC
and mDMPFC regions. We found that aDMPFC did not show a linear relationship with
increasing decision conflict, nor did mDMPFC show a significant correlation with
strategic variability across participants (Appendix Figure C-6). Thus, we conclude that
these regions made distinct functional contributions to performance of our experimental
tasks.

6.2.4 Evidence for a Functional Topography in Dorsomedial PFC
The results presented above provide strong evidence for a functional topography
within the dmPFC: the most anterior cluster tracked strategy-related control, a middle
138

<-----Page 153----->cluster predicted decision-related control, and a more posterior cluster tracked responserelated control (Figure 6-6). To ascertain the consistency of these results with the prior
literature, we conducted a meta-analysis of 53 studies that reported dmPFC activation in
tasks involving decision making and/or cognitive control. We classified each study as
involving either decision-related or response-related control, based on task properties,
and included every reported coordinate of medial frontal cortex activation in an
Activation Likelihood Estimation (ALE) analysis (see Appendix C). We exclude
strategy-related control in this meta-analysis due to lack of prior work in this area (but
see De Martino et al., 2006; Venkatraman et al., 2009b).

Figure 6-6: Summary of a functional topography in the dmPFC based on
varying control demands
Our meta-analysis revealed a strong spatial dissociation within dmPFC between
activations related to decisions and to responses, with more anterior regions being
involved in decision-making and more posterior regions with response-related cognitive
control (Appendix Figure C-7). The centroids of maximum likelihood overlapped with
139

<-----Page 154----->the observed activations for decision-related and response-related control demands in our
study (Figure 6-6, solid squares), and both are posterior to the focus for strategy-related
control in aDMPFC.

6.3 Discussion
We used tasks that evoked three distinct forms of control demands – response,
decision, and strategy – and found strong evidence for a posterior to anterior topography
within the dmPFC. Three distinct foci of activation were identified based on separate
behavioral measures using data from the same individuals. These results both provide
new insight into the functional organization of dmPFC and suggest a reconciliation of
recent controversies about that region’s role in complex decision-making and cognitive
control.
Control demands play an important role in adaptive decision-making, particularly
since decision preferences are strongly influenced by context (Simonson and Tversky,
1992; Tversky and Simonson, 1993). For example, people avoid decision options that
seem extreme, whether compared to their alternatives or whether having attributes with
highly disparate values (Chernev, 2004, 2005). Options that are balanced (e.g., their
scores on various attributes are more equal) thus frequently serve as a desirable
compromise relative to options containing attributes with high dispersion. We introduced
a similar biasing context in the current study, which used an abstract market environment
with anonymized options to control for participants’ differential prior exposure to stocks.
This task allowed us to manipulate the degree of decision-related and strategy-related

140

<-----Page 155----->control independently, the former by varying the relative desirability of the choices and
the latter by measuring individual variability in strategic bias.
Several aspects of our experimental design allow us to conclude that these distinct
forms of control were represented in distinct regions within dmPFC. First, we explicitly
separated the decision phase from the response phase so that activations related to
decision control cannot be attributed to confounding effects from response selection or
motor preparation (Pochon et al., 2008). Second, participants received no immediate
feedback about their decisions when choosing between different stocks; instead, feedback
was provided in a separate, later run. This allowed us to rule out effects of outcome
history when characterizing our participants’ decision preferences, while also precluding
alternative explanations for the observed dmPFC activation like error detection,
reinforcement learning, and signaling reward prediction errors (Kiehl et al., 2000; Kerns
et al., 2004; Kennerley et al., 2006; Kim et al., 2006). We do not claim that dmPFC plays
no role in these functions, but note that they did not contribute to the activations observed
in this experiment. Third, we used an independent counting Stroop task to elucidate
neural mechanisms of response-related control. Fourth, all analyses were conducted
within the same set of participants, as critical for making clear spatial comparisons. And,
finally, our distinct forms of control demands were each associated with a unique and
independent behavioral covariate.
Several studies have found increased activation in the dmPFC associated with
complex decision making (Paulus et al., 2002; Walton et al., 2003; Rushworth et al.,
2004; Zysset et al., 2006; Botvinick and Rosen, 2008; Pochon et al., 2008), though these
141

<-----Page 156----->findings could be confounded by activation related to response preparation (Pochon et al.,
2008). A more recent study using a perceptual decision-making task sought to explore the
role of dmPFC in decision conflict, defined as the difficulty arising from choosing
between two equally likely choices, while accounting for response-related activation
(Pochon et al., 2008). They demonstrated greater dmPFC activation for decisions
involving alternatives that were equally attractive, even in the absence of an explicit
response (e.g., precluding an explanation in terms of response-related control). Activation
within this region also varied with subjective ratings of decision difficulty. While Pochon
and colleagues did not include additional conditions to allow testing of topographic
organization, the manipulation of decision conflict in that study led to activation in
regions of the dmPFC similar to those associated with decision-related control in our
current study.
Moreover, there are initial suggestions that dmPFC is also recruited when
individuals make choices that run counter to general behavioural tendencies or strategies
(Paulus et al., 2002; De Martino et al., 2006; Hampton and O'Doherty J, 2007), although
these have heretofore been discussed in terms of decision preferences. Studies involving
complex decision making have often focused on identifying brain systems that shape
behaviour towards or against particular choices. Yet, it is becoming increasingly apparent
that people employ a variety of strategies to simplify the representations of decision
problems and reduce computational demands (Tversky and Kahneman, 1974; Payne et
al., 1988; Payne et al., 1992b; Gigerenzer and Goldstein, 1996). In this study, we show
that activation in a similar region of the dmPFC predicts variability in strategy-related
142

<-----Page 157----->control across participants. Specifically, individuals with greater bias for the balancing
strategy exhibited a greater increase in activation for the extreme choices compared to the
balanced choices, and vice versa. Strikingly, the cluster within dmPFC associated with
strategy-related control was anterior to and functionally distinct from the clusters
associated with decision-related control and response-related control. Therefore, a
parsimonious explanation for the role of dmPFC in complex decision making is that
distinct functional clusters might be associated with distinct aspects of decision making,
including strategy preferences and response preparation.
One potential conjecture for functional specialization within the dmPFC is related
to differences in connectivity of these clusters to other regions in the brain. A commonly
held framework, one advanced in different guises by different theorists, suggests that
lateral prefrontal cortex contains a topographic organization along its posterior to anterior
axis (Koechlin et al., 2000; Koechlin et al., 2003). More posterior regions, those
immediately adjacent to premotor cortex, are associated with setting up general rules for
behavior. Conversely, more anterior regions support the instantiation of rules for
behavior based on the current context. Findings from functional neuroimaging studies
argue for further divisions within anterior prefrontal cortex, such that regions around the
frontal pole support relational integration, or the combination of disparate information
into a single judgment (Christoff et al., 2001). We speculate that the different regions of
dmPFC differ in their lateral prefrontal targets.
Initial evidence for such a functional organization stems from a recent study that
demonstrates choice-specific changes in the functional connectivity of the dmPFC with
143

<-----Page 158----->other regions involved in decision-making (Venkatraman et al., 2009b). Similarly,
Beckmann and colleagues used magnetic resonance diffusion tractography to delineate
probabilistic anatomical connectivity of the cingulate cortex to other brain regions
(Beckmann et al., 2009). The authors found that the lateral prefrontal cortex exhibited the
highest probability of anatomical connectivity with a cluster that corresponds spatially to
the region that predicts decision-related control in our study, while the premotor and
precentral cortices showed highest probability of connection with a cluster that predicted
response-related control in the present study. Under this perspective, the current results
point to a generalized role for the dmPFC in cognitive control, but specific computational
roles for its subregions depending upon the task demands and current context.
Elucidating the functional connectivity of the different clusters in the dmPFC with
corresponding lateral prefrontal cortex may hold the key to fully understanding its role in
decision-making. In a follow-up study discussed in the next chapter, we sought to explore
this connectivity using resting-state fMRI data from three independent datasets across
different scanners.

144

<-----Page 159----->7 A Parallel Functional Topography between Medial and
Lateral Prefrontal Cortex†
A hallmark of the cerebral cortex is its topographic organization. Topographies
have been long-recognized within sensory and motor systems, whose spatial and
somatotopic maps were elucidated in early animal and subsequent human research (Udin
and Fawcett, 1988; Reep et al., 1996; Swindale, 1996; Kaas, 1997; Schneider et al., 2004;
Silver and Kastner, 2009). Other cortical regions, however, have less obvious large-scale
structure. While early conceptions of the prefrontal cortex (PFC) were shaped by the lack
of clear functional deficits associated with specific lesions (Ferrier, 1886; Lashley, 1929,
1950; Tizard, 1959), recent theoretical models have argued that all of PFC conjointly
supports the adaptive control of behavior (Fuster et al., 2000; Miller and Cohen, 2001).
Within the last decade, functional neuroimaging has generated models of dlPFC
that contain a topographic organization (Christoff and Gabrieli, 2000; Koechlin et al.,
2000; Koechlin et al., 2003; Christoff and Keramatian, 2007; Koechlin and Summerfield,
2007; Badre and D'Esposito, 2009). Although the specific mapping of regions to
functions differs across models, all share some familial properties: posterior dlPFC
controls relatively simple mappings of stimuli to actions, anterior dlPFC shapes complex
conditional relationships among behavioral rules, and information flows between regions
in a largely hierarchical fashion from anterior to posterior regions.

†
The contents of this chapter have been published as “Venkatraman V, Taren AA, Huettel SA (In press). A parallel
functional topography between medial and lateral prefrontal cortex: Evidence and implications for Cognitive Control, J.
Neurosci”.

145

<-----Page 160----->Considerably less is known about the organization of dorsomedial PFC (dmPFC).
It contributes to a welter of cognitive processes, including monitoring performance,
selecting actions based on goals, anticipating rewards, and signaling errors and adverse
outcomes (Bush et al., 2000; Ridderinkhof et al., 2004a; Ridderinkhof et al., 2004b). One
popular view is that this functional diversity parallels apparent structural heterogeneity,
with the above processes considered to be intercalated throughout this region
(Ridderinkhof et al., 2004b). Yet, recent evidence from neuroimaging studies suggests
that dmPFC has functional, and potentially topographic, subdivisions. Direct comparison
of three distinct types of cognitive control demands – response-related, decision-related,
and strategy-related – revealed a posterior-to-anterior gradient reflecting the transition
from simple to higher-order rules for control (Venkatraman et al., 2009a). Moreover,
recent structural analyses indicate that subdivisions of cingulate cortex have distinct
white-matter connectivity profiles (Beckmann et al., 2009), particularly with respect to
the lateral PFC.
We hypothesized that the dlPFC and dmPFC share a common topographic pattern
of functional connectivity, consistent both with the known anatomical connections
between these regions (Petrides and Pandya, 1999; Petrides, 2005) and their putative joint
contributions to cognitive control (Ridderinkhof et al., 2004a; Egner, 2009; Kouneiher et
al., 2009). Here, we mapped functional connectivity within prefrontal cortex using
resting-state fMRI (Fransson, 2005; Damoiseaux et al., 2006; De Luca et al., 2006;
Margulies et al., 2007), drawing data from a large primary dataset and from two
independent replications collected on different scanners. Our results demonstrated a clear
146

<-----Page 161----->posterior-to-anterior gradient in connectivity: posterior dmPFC regions were maximally
connected to posterior dlPFC regions, whereas anterior dmPFC regions were maximally
connected to anterior dlPFC regions. This parallel topography supports an integrative and
hierarchical view of PFC, such that its medial and lateral aspects jointly contribute to the
adaptive control of behavior.

7.1 Methods
Participants and Data Collection: Primary Dataset. Sixty-four young adults
(32 female, mean age = 24, range 18-43) participated in the primary experiment. All
participants received monetary compensation for their participation in the study. Twelve
participants were excluded before data analysis due to excessive motion (>2 mm), leaving
a total of 52 participants (26 female) in the final analyses. All participants gave written
informed consent as part of protocols approved by the Institutional Review Board of
Duke University Medical Center.
We report data from a 6-minute resting-state scan, which was obtained at the end of
a 90-minute experimental session. During this scan, participants were instructed to keep
their eyes open, to focus on the fixation cross that was presented in the center of the
screen, to remain alert, and to refrain from directing their thoughts toward anything
specific.
Data were acquired on a 4T GE scanner using an inverse-spiral pulse sequence
(Guo and Song, 2003) with the following parameters: TR = 2000 ms; TE = 27 ms; 34
axial slices parallel to the AC-PC plane, with voxel size of 3.75 × 3.75 × 3.8 mm. High-

147

<-----Page 162----->resolution 3D full-brain SPGR anatomical images were acquired and used for
normalizing individual participants’ data.
Participants and Data Collection: Replication Datasets. We replicated all
analyses in resting-state data from two additional datasets collected on different scanners,
with different pulse sequences, and with different groups of participants. Twenty-two
young adults (11 female, mean age = 23, range 19-32) participated in Replication 1.
Fifteen young adults (5 female, mean age = 22, range 20-24) participated in Replication
2. All participants gave written informed consent as part of protocols approved by the
Institutional Review Boards of Duke University Medical Center or of the Duke-NUS
Graduate Medical School, Singapore.
Replication 1 data were acquired on a 3T GE scanner using a SENSE spiral pulse
sequence with the following parameters: TR = 2000 ms; TE = 27 ms; 34 axial slices
parallel to the AC-PC plane, with voxel size of 3.75 × 3.75 × 3.8 mm. High-resolution 3D
full-brain SPGR anatomical images were acquired and used for normalizing individual
participants' data. Replication 2 data were acquired on a 3T Siemens scanner using an
inverse spiral pulse sequence with the following parameters: TR = 2000 ms; TE = 30 ms;
34 axial slices parallel to the AC-PC plane, with voxel size of 3.75 × 3.75 × 3.8 mm.
High-resolution T1-weighted MPRAGE anatomical images were acquired and used for
normalizing individual participants' data.
Data Analyses. We used FEAT (FMRI Expert Analysis Tool) Version 5.92, part
of FSL (FMRIB’s Software Library; www.fmrib.ox.ac.uk/fsl) package (Smith et al.,
2004). Preprocessing consisted of 1) motion correction using MCFLIRT (Motion
148

<-----Page 163----->Correction using fMRIB’s Linear Registration Tool), 2) slice timing correction, 3)
removal of non-brain voxels using BET (Brain Extraction Tool), 4) spatial smoothing
using a Gaussian kernel with full-width at half maximum 6mm, and 5) high pass
temporal filtering (cutoff = 100s). Normalization to MNI standard space was carried out
using FLIRT.

Figure 7-1: Selected seed regions in the medial and lateral PFC
Functional Connectivity: Selection of Seed Regions. We identified 5 seed
regions in the dmPFC, hereafter described using the nomenclature DM1 through DM5
(i.e., posterior to anterior). The peak coordinates of these seeds were taken from previous
work indicating distinct foci for response-, decision-, and strategy-related control
(Venkatraman et al., 2009a), which became DM1, DM3, and DM5, respectively. The
remaining two seeds, DM2 and DM4, were defined by linear interpolation between the
above pairs of neighboring coordinates (Figure 7-1, Table 7-1).
149

<-----Page 164----->Table 7-1: MNI coordinates for dmPFC and dlPFC seed regions
MNI
X

Functional Contrast

y

Source

z

DM1

-4

10

50

Response conflict

(Venkatraman et al., 2009a)

DM2

-4

16

45

-

Interpolated (DM1 and DM3)

DM3

-6

23

39

Decision conflict

(Venkatraman et al., 2009a)

DM4

-4

30

37

-

Interpolated (DM3 and DM5)

DM5

-6

35

34

Strategy conflict

(Venkatraman et al., 2009a)

DL1

-32

-11

60

Stimulus effect

(Koechlin et al., 2003)

DL2

-51

-2

39

-

Interpolated (DL1 and DL3)

DL3

-44

7

22

Context effect

(Koechlin et al., 2003)

DL4

-46

22

14

-

Interpolated (DL3 and DL5)

DL5

-42

45

7

Episode effect

(Koechlin et al., 2003)

DL6

-30

56

-2

Branching effect

(Koechlin et al., 1999)

We also identified 6 seed regions in the dlPFC, hereafter labeled as DL1 through
DL6 (i.e., posterior to anterior). We identified three of the seed regions’ peak coordinates
based on prior work delineating a dlPFC topography based on stimulus, context and
integrative demands (Koechlin et al., 2003); these became seeds DL1, DL3, and DL5
(Table 1). The intermediate seeds DL2 and DL4 were defined by linear interpolation
between neighboring coordinates and coordinates for DL6 were determined based on
prior work associating activation in the anterior prefrontal cortex with cognitive
branching (Koechlin et al., 1999). Each seed consisted of 33 2mm x 2mm x 2mm voxels
(defined using a sphere of radius 2 voxels around the peak coordinate described in Table
150

<-----Page 165----->1). Time-series signal for all subsequent analyses was obtained by averaging data across
all voxels within each seed.
Functional Connectivity: Data Analysis. To map the pattern of functional
connectivity between medial and lateral PFC, we began with a dmPFC mask that
included the anterior cingulate gyrus and the medial superior frontal gyrus. Following
normalization of each participant’s data to the standard MNI space, we extracted the
time-series from each dmPFC voxel and measured the functional connectivity with each
of the six dlPFC seed regions. This provided a voxel-by-voxel map, for each participant,
of the correlation between each point in dmPFC with each of the seed regions in the
dlPFC. The corresponding analysis was also performed to obtain a voxel-by-voxel map
of the correlation between each point in dlPFC with each of the seed regions in the
dmPFC. We used a dlPFC mask, extracted the time-series from each dlPFC voxel, and
measured the functional connectivity with each of the five dmPFC seed regions.
The above analysis provides a visual representation of topography in dlPFC based
on the seeds in dmPFC, and vice versa. To next evaluate the parallel connectivity
between hierarchical regions in the dmPFC and dlPFC, we extracted the preprocessed
mean time-series from each of the five dmPFC seed regions and six dlPFC seed regions
defined above for every participant. We demeaned all dmPFC and dlPFC time series by
subtracting the mean whole-brain time series (extracted from a whole-brain mask for
every participant). To obtain a measure of point-to-point connectivity, we computed
Pearson correlations between the five dmPFC time series and each of the six dlPFC time
series, which were then combined across all participants (significance tests: Pearson
151

<-----Page 166----->product-moment correlation coefficient, p < 0.05, two-tailed). All analyses were repeated
independently for the left and right hemispheres.
Functional Connectivity: Specificity Analysis. For each dmPFC seed, we
calculated the standard deviation of the correlation values to each of the six dlPFC seeds.
A lower standard deviation would indicate broad, similar connectivity of voxels within
that seed to different regions in the dlPFC, while a higher standard deviation would
indicate greater specificity such that connectivity strength varies across seeds. To
statistically test the presence of an anterior-posterior gradient in specificity, we ran an
ANOVA of the standard deviation values for each of the five different dmPFC seeds
across participants, followed by post hoc tests of specific seed pairs.
Regression Analyses. Each dlPFC/dmPFC correlation for each participant was
entered as an observation (i.e., 30 pairwise correlations per participant) into an OLS
regression analysis (JMP Version 7; SAS Institute Inc., Cary, NC). Each dlPFC/dmPFC
correlation was served as a dependent variable, and explanatory variables included
dmPFC region (normalized posterior to anterior as -1 to 1), dlPFC region (-1 to 1), a
dmPFC*dlPFC interaction term, and a categorical variable coding for the data set from
which each observation originated (primary, Replication 1, or Replication 2). Using
spatial locations as predictors allowed us to answer the question of whether interaction
between spatial locations predicts dmPFC-dlPFC correlation (i.e. our measure of
connectivity). This analysis was run using the aggregate observations from all three data
sets, and was replicated using only the primary data set.

152

<-----Page 167----->Figure 7-2: The dmPFC exhibited a topographically organized connectivity
pattern with dlPFC

7.2 Results
We measured the unique, non-directional functional connectivity between
locations within dmPFC and dlPFC using two independent methods, each controlling for
the common fMRI signal covariation between the regions as a whole. First, we examined
the connectivity between each of the six dlPFC seed regions and every voxel in dmPFC,
defined anatomically. The results demonstrate a posterior-to-anterior gradient in
connectivity, with posterior dlPFC having maximal connectivity to posterior dmPFC and
anterior dlPFC having maximal connectivity to anterior dmPFC (Figure 7-2). The
corresponding analysis of connectivity between each of the five dmPFC seed regions and
every voxel in dlPFC produces a similar gradient. Second, we examined point-to-point
connectivity between the pre-selected seed regions in dlPFC and dmPFC. We found a
similar topographic pattern when focusing on just the connectivity between seed regions,
independently for both the left (Figure 7-3A, Table 7-2) and right hemispheres (Figure
153

<-----Page 168----->7-3B, Table 2). This topography was replicated in two additional data sets collected on
different scanners, with different participants, and using different imaging parameters.

Figure 7-3: Pairwise connectivity between dmPFC and dlPFC functional
regions.
We next evaluated the spatial pattern of functional connectivity using a regression
analysis. Point-to-point connectivity values, for all pairs of dmPFC and dlPFC regions
and for all participants, were included as dependent variables in the model. Predictor
variables were dmPFC spatial location (i.e., 5 levels), dlPFC spatial location (i.e., 6
levels), and their interaction. Note that this analysis controls for any overall effects of
increased connectivity in either posterior or anterior regions; of primary interest would be
a significant interaction, such that connectivity is maximal between regions matched
spatially. We found that the dmPFC*dlPFC interaction term was highly significant in
both the left and right hemispheres (all ps < 10-10; Table 7-3). This effect held both for
the primary data set (when considered alone) and for the combination of all three data

154

<-----Page 169----->sets, when including data set as an additional categorical predictor variable (all ps < 10-10
in similar analyses to those of Table 7-3).
Table 7-2: Pairwise correlations between each dmPFC and dlPFC seed
region for each hemisphere.
Primary Dataset
Left Hemisphere

Right Hemisphere

DM1

DM2

DM3

DM4

DM5

DM1

DM2

DM3

DM4

DM5

DL1

0.45

0.24

0.19

0.10

0.08

0.26

0.19

0.11

0.04

-0.00

DL2

0.34

0.31

0.26

0.15

0.13

0.47

0.39

0.20

0.18

0.12

DL3

0.24

0.37

0.32

0.25

0.21

0.30

0.29

0.15

0.18

0.15

DL4

0.11

0.25

0.21

0.24

0.25

0.17

0.12

0.14

0.17

0.16

DL5

0.04

0.26

0.30

0.28

0.24

0.17

0.21

0.20

0.28

0.28

DL6

0.02

0.05

0.07

0.16

0.17

-0.04

-0.01

0.12

0.17

0.22

Finally, we evaluated whether these findings held for individual participants. We
determined, for each participant and each dmPFC seed, the seed in dlPFC to which there
was maximal functional connectivity. This provides a conservative measure of point-topoint connectivity, in that it collapses the entire distribution of connectivity values to a
single maximum. As hypothesized, these maxima clustered along the diagonal, consistent
with a parallel topography at the individual level in both hemispheres (left hemisphere is
shown in Figure 7-4). A similar pattern was seen in our two replications.

155

<-----Page 170----->Table 7-3: Summary of regression analysis using data pooled from all
experiments.
Left Hemisphere

Right Hemisphere

β

p

β

P

Intercept

0.21

<10-20

0.18

<10-20

dmPFC

-0.02

0.01

-0.04

<10-7

dlPFC

-0.02

0.01

0.01

<0.04

dmPFC*dlPFC

0.18

<10-20

0.19

<10-20

Figure 7-4: Individual participants’ maximally correlated dmPFC-dlPFC
pairs reveal parallel topography
We additionally observed that the specificity of the functional connectivity
decreased when moving along the posterior-to-anterior gradient (cf. Figure 7-4) within
the dmPFC. We computed the standard deviation of connectivity values from each
dmPFC seed to the set of the six dlPFC seeds. There was a significant decrease from
156

<-----Page 171----->posterior to anterior dmPFC seeds (F(4,255) = 2.77, p = 0.02). Voxels in posterior
dmPFC exhibited greater specificity (mean = 0.23) in connectivity to dlPFC seeds than
did voxels in anterior dmPFC (mean = 0.18, t(51) = 3.20, p = 0.002).

7.3 Discussion
Several lines of empirical evidence have suggested a hierarchical rostral-to-caudal
organization within the dlPFC, with neurons in the more rostral regions processing more
abstract goals and neurons in the more posterior regions processing more concrete
information related to corresponding motor actions (Fuster et al., 2000; Fuster, 2001,
2004; Koechlin and Summerfield, 2007). More recent evidence also suggests a similar
anterior-to-posterior topography within the dmPFC, with the more anterior regions being
associated with more complex and abstract levels of cognitive control (Venkatraman et
al., 2009b; Venkatraman et al., 2009a). Given the strong anatomical evidence for
reciprocal connections between these regions based on studies in non-human primates
(Bates and Goldman-Rakic, 1993; Petrides and Pandya, 1999), a natural hypothesis is
that monitoring-related activity in dmPFC engages regulatory processes in the dlPFC that
shape behavior (Botvinick et al., 2001; Kerns et al., 2004; Botvinick, 2008). Yet, despite
the striking similarity in their hierarchical organization, it has been unclear whether a
similar gradient also exists in the functional connectivity between these regions.
In one recent study, Kouneiher and colleagues demonstrate that the medial
prefrontal cortex regulates processing resources in the lateral PFC according to
motivational incentives. Specifically, there is increased effective connectivity between
posterior dmPFC (pre-SMA) and posterior dlPFC for contextual incentives and increased
157

<-----Page 172----->connectivity between middle dmPFC and mid-dlPFC for episodic incentives. However,
there was no increased connectivity during control conditions that lacked such incentives.
Therefore, the authors argue for a posterior-to-anterior hierarchical system of executive
processes in the medial and lateral PFC with the functional interactions between them
conveying motivational incentives rather than simple control demands (Kouneiher et al.,
2009).
In the current study, we used spontaneous fluctuations in BOLD activity to
characterize further the functional connectivity between the medial and lateral prefrontal
regions in the absence of task-associated cognitive processes. This task-free approach
using resting-state data relies on correlations among low-frequency BOLD changes to
identify regions that function in tandem. Using such an approach, we demonstrated a
posterior-to-anterior gradient in connectivity between the medial and lateral prefrontal
regions, with posterior dlPFC having maximal connectivity to posterior dmPFC and
anterior dlPFC to anterior dmPFC. This pattern replicated in three independent datasets
collected using three different MR scanners and was evident even in individual
participants.
This pattern of resting-state functional connectivity is consistent with prior
mappings of structural connectivity between these regions in both non-human primates
(Petrides and Pandya, 1999) and humans (Beckmann et al., 2009). Petrides and Pandya
used florescent tracers placed in selected areas of the dorsolateral frontal cortex of
monkeys to study their connectivity to the rest of the brain (Petrides and Pandya, 1999).
They found that injections placed in posterior dlPFC (similar to DL1 in our study)
158

<-----Page 173----->revealed labeled neurons in posterior dmPFC regions of the SMA, pre-SMA, and
cingulate sulcus (similar to DM1 in our study). On the other hand, injections placed in
mid-dlPFC (corresponding roughly to DL3 seed in our study) revealed labeled cells in a
more anterior part of cingulate cortex (here, roughly DM3). Similar connection patterns
in the medial regions were also observed for injections placed in rostrolateral dlPFC
(corresponding to DL6 seed in our study). These findings suggest strong intrinsic
structural connectivity between lateral and medial prefrontal regions in the macaque
cortex.
In another study involving magnetic resonance tractography-based parcellation of
the human cingulate cortex (Beckmann et al., 2009), the dorsolateral prefrontal regions
(consistent with seeds DL3 and DL4 in our study) showed greatest connectivity with
anterior cingulate sulcus (similar to DM4 in our study), while the premotor regions
(overlapping with our seeds DL1 and DL2) showed greatest connectivity with the preSMA and more posterior regions within the cingulate (overlapping with seeds DM1 and
DM2). Therefore, these studies provide independent evidence across different modalities
about the robustness of the functional connections between these regions. Though these
methods are largely agnostic about the directionality of these interactions, the findings of
Kouneiher and colleagues suggests that the medial frontal regions may regulate the
cognitive control resources in the lateral regions according to motivational incentives
(Kouneiher et al., 2009). Therefore, we speculate that dmPFC exerts a regulatory or
modulatory influence on dlPFC (Wood and Grafman, 2003; Egner, 2009; Kouneiher et
al., 2009).
159

<-----Page 174----->8 Conclusions
8.1 Neuroeconomics: From Variables to Strategies
Neuroeconomic research will, for the foreseeable future, continue to be focused
on identifying neural mechanisms that underlie decision variables and the operators that
process those variables. While elucidating the many factors that contribute to even simple
decisions is important, findings across a series of risky choices experiments across
different modalities presented earlier suggest that identifying the factors that shape how
people differentially represent decision problems, both across contexts and across
individuals, will become an increasingly critical topic.
Such an increased focus on strategic variability would have several salutary
consequences. First, it would provide an avenue by which neuroscience data could be
extended to modeling in economics (and other social sciences). A common criticism of
neuroeconomics, at least among economic theorists, is that neuroscience data is simply
irrelevant for core models in economics. Where such theories cannot be derived from first
principles, it is argued, they can be identified based on expressed behavior without
recourse to internal neural mechanisms. This criticism, which we have labeled the
“behavioral sufficiency” argument, can be countered on several grounds (Clithero et al.,
2008). Most relevant for the current topic, economic models of behavior are disconnected
from the substantial psychological and neuroscientific literature on individual differences.
Because of this disconnect, a model may well describe behavior of young adults making
decisions in a relaxed setting, but nevertheless have little predictive validity when applied
to older adults making decisions under time pressure. To the extent that neuroscience can
160

<-----Page 175----->illuminate the mechanisms underlying individual choice biases and strategic preferences,
it may become critical for creating robust and flexible models of real-world decision
behavior.
Second, there will be substantial value in moving descriptions of decision
mechanisms – within neuroeconomics, cognitive psychology, behavioral economics, and
even the lay public – away from the oft-claimed interaction between competing decision
systems. Clearly, there has been substantial process in mapping specific decision
variables to specific brain regions. Yet, considering decisions to reflect the simple
interactions between sets of these regions would be, much like hydraulic theories of
personality, an unnecessary and misleading oversimplification. No one region, nor any
set of regions, can be unambiguously claimed to implement a rational decision-making
process. Instead, specific brain regions contribute to particular computations, which may
or may not be consistent with models for rational behavior. Some such regions may even
exert context-dependent influences, like that shown for dmPFC in the final experiment,
making it impossible to categorize them within a two-systems framework (Frank et al.,
2009).
Third and finally, results also indicate that an important direction for
neuroeconomics will be to strengthen its connections to the broader cognitive
neuroscience literature. For example, findings presented here are consistent with the
growing consensus that dmPFC reflects a mechanism for identifying and responding
adaptively to changes in the environment. Notably, complex aspects of behavior, like full
consideration of decision problems, require a wide range of processes of executive
161

<-----Page 176----->control. By adopting simplifying rules for behavior, and only changing those rules when
environmental conditions change, the brain can operate with a much-reduced metabolic
demand. The dmPFC plays such a role in complex decision making, signaling changes in
how a decision problem is represented and thus shaping computational processing
elsewhere in the brain based on the current decision strategy. Such strategic
considerations are unlikely to limited to abstract economic decisions; they are also likely
to be critical for interpersonal interactions in social contexts (Camerer, 2003a) and other
social behaviors (Behrens et al., 2008; Behrens et al., 2009).
This role of dmPFC in strategic control during complex decision making can be
integrated into a broader role for this region in cognitive control. In other words, there is
now evidence both for generalized contributions of the dmPFC to cognitive control, and
for specific computational roles for its subregions depending upon the task demands and
context. Specifically, there is a hierarchical functional organization within this region,
such that the posterior dmPFC supports response-related control, middle dmPFC supports
decision-related control and the anterior dmPFC supports more abstract strategic control.
Strikingly, such a hierarchical role extends also to the connections between the functional
nodes in the medial and lateral prefrontal cortex, leading to a new neuroanatomical model
of cognitive control.

8.2 A Hierarchical Model for Cognitive Control
Based on findings across several studies discussed in this dissertation, it is evident
different regions of dmPFC and dlPFC interact to guide the adaptive control of behavior
according to the computational demands of the task (Figure 8-1). The proposed model
162

<-----Page 177----->extends the hierarchical organization postulated for dlPFC to include a parallel
organization in dmPFC, whose subregions shape processing in their lateral counterparts.
That is, the anterior dmPFC regulates activity in the anterior dlPFC when the control
demands are associated with high levels of abstraction (e.g., implementing strategic
planning in a decision-making task), while the posterior dmPFC works in concert with
posterior dlPFC and premotor cortices when the control demands are limited to choosing
between two competing responses.

Figure 8-1: A hypothetical hierarchical model for cognitive control
While the emphasis here is primarily on potential medial-to-lateral effects,
bidirectional influences are likely: dmPFC activity may be biased by dlPFC inputs,
163

<-----Page 178----->consistent with the former’s role in monitoring reward-value of action sets according to
outcomes (Daw et al., 2006; Kennerley et al., 2006). Moreover, whether these regions
interact in a hierarchical fashion remains a provocative question. Anterior regions of
dlPFC influence processing in posterior regions of dlPFC in a task-dependent manner
(Koechlin et al., 2003; Kouneiher et al., 2009), and damage to more anterior portions of
prefrontal cortex leads to deficits on a wider array of tasks, including abstract processing
(Badre and D'Esposito, 2009). The finding that the more anterior regions in the dmPFC
demonstrate more diffuse projections to the lateral PFC, relative to the posterior regions,
provides converging evidence toward a hierarchical perspective.
The new framework proposed here provides empirical evidence for a
longstanding conjecture: that the PFC contributes to the temporal integration of behavior
by simultaneously maintaining context and goal-related information at several levels
(Fuster, 2001, 2004). Fuster argued that automatic behaviors only require integration at
lower levels – sensory areas in the posterior perceptual hierarchy and motor areas in the
frontal executive hierarchy – while more complex behaviors require integration at higher
levels of perceptual and executive hierarchies. This influential conjecture has recently
gained significant supporting evidence in the lateral PFC (Koechlin and Summerfield,
2007; Badre et al., 2009). We show that this topography extends to the functional
interactions between the medial and lateral PFC. Such a functional gradient in
connectivity could reflect a dynamic mechanism for identifying and responding
adaptively to contextual changes in behavior.

164

<-----Page 179----->Appendix A: Supplementary Material for Chapter 3
Stimuli: Trial Types
There were a total of five different types of conditions: (i) the value (amount
added to the option) and probability were higher for the reference outcome (Ref_EV+),
(ii) the value and probability were the same for both reference and extreme outcomes
(Ref_EV=), (iii) the value was the same but the probability of the reference outcome was
lower (Ref_P-), (iv) the probability was the same but value added to the reference
outcome was lower (Ref_V-) and (v) both the probability and the value were lower for
the reference option (Ref_EV-). The proportion of Pmax choices was systematically
modulated by the tradeoff in expected value of the two types of choices, indicating that
participants were not simply insensitive to expected value (Table A-1). As seen from the
table, the greatest conflict existed when the expected values were equal or close (when
only one of value or probability was lower). Therefore, only these trials were included for
analyzing the neural correlates of decisions.

Participant Payments
Participants were informed at the beginning of the fMRI session that a portion of
their earnings would depend on their choices. Specifically, they would gain or lose
money based on the outcomes of two randomly selected gambles (plus a fixed $40
participation payment). They were told that the outcome of each trial would be multiplied
by an unknown, but fixed percentage, and that they could lose some or all of a monetary
165

<-----Page 180----->endowment that was given to them at the start of the experiment. To ensure that choices
were incentive-compatible, we gave each participant (before they entered the scanner) a
sealed envelope containing both a cash endowment and a message indicating the payment
multiplier. The values of the endowment and multiplier were both unknown to the
participants. For all participants, the endowment was set at $20 and the multiplier was set
at 10%. The final total payoffs ranged from $46 to $76 (mean = $61, s.d. = $8.66).

Behavioral Trait Measures.
At the end of the scanning session, participants completed a series of
questionnaires. These included:
1. A Maximization Scale that consists of 13 questions aimed at distinguishing
people based on those who try to get the best out of a situation from those who
settle for something good enough(Schwartz et al., 2002),
2. Barratt’s Impulsiveness Scale (BIS) that consists of 30 questions categorized
into cognitive, planning and motor subscales(Patton et al., 1995),
3. A cognition-intuition questionnaire, where the two subscales are faith-inintuition that leads to more heuristic experiential processing and need-forcognition that leads to more analytic rational processing(Epstein et al., 1996a),
4. A decision-making styles inventory (DMSI) with sub-scales as rational,
intuitive, avoidant, dependent and spontaneous(Scott and Bruce, 1995) and
5. A second decision styles inventory (WN_DMSI) with the sub-scales as
analytical, intuitive and regret(Nygren and White, 2002).
166

<-----Page 181----->Factor Analysis.
Individual participant responses from all subscales of these five questionnaires,
along with the behavioral measure of choice tendency from the fMRI experiment, were
then subjected to a factor analysis using SPSS. We used principal components analysis to
extract the factors and performed varimax rotation of the resulting loading matrices to
facilitate interpretation. The extraction criterion was set to an eigenvalue of one or
greater.
The behavioral data loaded onto four factors which together accounted for
approximately 75% of the total variance; these can be broadly labeled as impulsiveness,
magnitude-focus, intuitiveness, and regretfulness in decreasing order of explained
variance. The rotated factor matrix for each of the four factors is summarized in Table A3. Loading values with absolute value of 0.5 and greater are shown in the table. We then
calculated scores for each factor for each participant, which were then used as covariates
in the third-level fMRI analyses to evaluate the robustness and specificity of our findings
to strategic variability.
We included participants’ scores on each of these factors as across-participants
regressors in our third-level analysis looking at differences between magnitude-sensitive
compensatory and simplifying Pmax choices. We found that the difference in activation
between the two choices within the dmPFC was significantly negatively correlated with
the magnitude-focus factor (the preference for simplifying strategy loaded negatively on
this factor) but not with any other factor, replicating the interaction effect in Fig 3 in the
main text of the manuscript (Figure A-3).
167

<-----Page 182----->Dorsomedial Prefrontal Cortex: Strategy or Response Conflict?
We conducted two additional analysis to rule out the possibility that dmPFC
activation was related to response conflict, as has been found in several previous
studies(Botvinick et al., 1999; Kerns et al., 2004). First, we evaluated whether there was
any correlation, across participants, between response time and dmPFC activation, as
would be expected in the case of response conflict. No such correlations were found,
whether considering each strategy independently or their interaction (Figure A-4).
Second, participants who selected were indifferent to compensatory and simplifying
strategies (hence having maximal response conflict as they choose both options equally
often) exhibited low dmPFC activation that was equal for both choices, a finding that is
inconsistent with a response-conflict explanation (Figure A-5).

Supplementary Tables
Appendix Table A-1: Proportion of Pmax choices and response times across
trial types.
Proportion of Pmax Choices (%)

Response Time (s)

Mean

S.E

Mean

S.E.

Ref_EV+

90.58

2.63

0.883

0.068

Ref_EV=

69.38

5.18

0.994

0.083

Ref_V-

45.65

5.45

1.091

0.118

Ref_P-

33.70

5.47

1.031

0.117

Ref_EV-

29.17

5.45

0.992

0.088

168

<-----Page 183----->Appendix Table A-2: Peak coordinates of regions that were significantly
activated in contrasts of interest.
MNI Coordinates

Brodmann

z-value

Area

x

y

z

Right anterior Insula

38

28

0

13

3.42

Right ventromedial PFC

16

21

-23

11

2.74

Right Posterior Parietal Cortex

20

-76

57

40

3.40

Precuneus

3

-72

57

7

2.79

Right dorsolateral Prefrontal
Cortex

44

44

27

46

2.99

Right Inferior Frontal Gyrus

47

42

8

46

3.64

Right dorsolateral Prefrontal
Cortex

42

25

22

44

3.14

Dorsomedial Prefrontal Cortex

10

22

45

32

2.99

10

42

29

32

2.77

Compensatory > Simplifying

Simplifying > Compensatory

(Compensatory - Simplifying)
* Strategy Preference

169

<-----Page 184----->Appendix Table A-3: Behavioral data from questionnaires loaded onto four
main factors
Factor 1

Factor 2

Factor 3

Factor 4

Inferred Factor Label Impulsiveness Magnitude- Intuitiveness Regretfulness
focus
BIS
Nonplanning

0.76

-

-

-

-

0.67

-

-

0.87

-

-

-

-0.78

-

-

-

Intuitive

-

-

0.90

-

Regret-based

-

-

-

0.56

0.86

-

-

-

Avoidant

-

0.75

-

-

Dependent

-

0.51

-

0.55

Intuitive

-

-

0.91

-

Rational

-0.80

-

-

-

Need for Cognition

-

-

-

-0.88

Faith in Intuition

-

-

0.76

-

Maximizing Scale

-

0.78

-

-

Pmax Preference

-

-0.71

-

-

Cognitive
Motor
WN-DMSI
Analytical

DMSI
Spontaneity

Cognitive-Intuitive

170

<-----Page 185----->Supplementary Figures

Appendix Figure A-1: Differences in dmPFC connectivity strength predict
participant choices

171

<-----Page 186----->Appendix Figure A-2: Activation in ventral striatum is correlated with
maximization trait measure.

Appendix Figure A-3: Areas of activation associated with specific decision
factors from Table A-3.

172

<-----Page 187----->Appendix Figure A-4: Activation in dmPFC is not correlated with response
times.

Appendix Figure A-5: Activation in dmPFC is related to strategic control
and not response conflict.

173

<-----Page 188----->Appendix B: Supplementary Material for Chapter 4
Experimental Procedure
Scanning took place at approximately 9:00 AM for the RW session. Prior to the
scan, compliance to a regular sleep schedule was verified by inspecting the volunteer’s
sleep diary and wrist actigraph (Actiwatch, Philips Respironics). Participants also
completed a 10-minute psychomotor vigilance task (PVT). For the SD session,
participants came to the laboratory at no later than 7:00 PM on the test night after staying
awake the whole day. An inspection of their sleep habits was conducted as described for
the RW session. Participants were monitored throughout the night and were allowed to
engage only in non-strenuous activities such as reading, working on a computer and
conversing. Every hour, from 8:00 PM to 5:00 AM, participants completed the 10-minute
PVT task and the Karolinska Sleepiness Scale (KSS). Scanning took place at
approximately 6:30 AM, close to, or at, the cognitive performance nadir for most
persons.
The scanning times were chosen as they represent the start times of a regular
workday and the low-point of cognitive performance after a night of sleep deprivation
(Doran et al., 2001; Graw et al., 2004). However, we note that this schedule does not
align the RW and SD sessions to the same circadian phase and does not allow a
decomposition of the effects of sleep deprivation into 'circadian' and 'homeostatic'
components. We acknowledge that small circadian phase differences may modulate, but
not overcome, large sleep homeostatic effects.

174

<-----Page 189----->Stimuli: Trial Types
There were a total of five different types of conditions: (a) lower expected value
(due to lower amount added as well as lower probability) for Gmax/Lmin choices, (b)
equal expected value for both choices, (c) greater expected value for Gmax/Lmin choices
due to greater probability of this outcome, (d) greater expected value for Gmax/Lmin due
to greater amount being added to this outcome and (e) greater expected value for
Gmax/Lmin due to both greater probability and higher amount being added to this
outcome. The proportion of choices were systematically modulated by the tradeoff in
expected value of the two types of choices, indicating that participants were not simply
insensitive to expected value in both states (Figure B-2). Conditions (a) and (e) acted as
control conditions, with expected values heavily skewed towards one of the choices. The
greatest conflict in choice preference existed when the expected values were equal or
similar (when only one of value or probability was lower). Therefore, only trials from
conditions (b), (c) and (d) were included for analyzing the neural correlates of decisions.

Incentive-compatible Payment Instructions
At the beginning of the experiment, participants were provided detailed instructions about
the payment procedures (see (Venkatraman et al., 2009b) for additional details). Briefly,
before the first scan session, participants were instructed that their overall payment for
the study was dependent on the outcomes of two randomly selected trials in the outcome
phase, one from each scan session. Participants were given a sealed envelope at the first
session with instructions that the envelope contained an endowment to offset any
175

<-----Page 190----->potential losses, but they were not informed about the actual amount. As the final
payment was made only at the end of the entire experiment, participants were instructed
that the envelope would be kept by the experimenters and would be opened only at the
end of the study. Participants were asked to sign across the seal of the envelope to ensure
that it was later identifiable. Participants were also told that there was no deception in the
study and were given an opportunity to question the experimenter about any procedures
before entering the scanner. All participants expressed that they understood and believed
in the procedures.

Parametric Model Analysis
We estimated parameters that best fit participants’ responses using Cumulative
Prospect Theory (CPT). We chose CPT (Tversky and Kahneman, 1992) over the original
Prospect Theory (Kahneman and Tversky, 1979) because the latter was primarily
introduced for simple two-outcome gambles and violates first-order stochastic
dominance. This is a particularly important consideration in multi-outcome gambles like
the ones used in this study. The gambles used in this study were of the form G = [x1,p1;
x2,p2; x3,p3; x4,p4; x5,p5] with xi representing the outcomes and pi the associated
probabilities The outcomes are ordered so that x1 is the largest gain, x5 is the largest loss,
and k is the index of the smallest gain. The CPT value for each gamble is given by:
5
 x α , xi ≥ 0

CPT = ∑ v( xi )c(i ) where v( xi ) =  i
,
− λ | xi |α , xi < 0
i =1

176

<-----Page 191----->w + ( pi ), i = 1



i −1


 +  i

+



w  ∑ p j  − w  ∑ p j , i = 2,.., k ( gains) 
  j =1 

 j =1 
c(i ) = 
,
5



 −  5

−



w  ∑ p j  − w  ∑ p j , i = k + 1,..,4 (losses)
 j =1+1 
  j =i 

−
w ( pi ), i = 5

pγ

+

w ( p) =
[p

γ+

+

pγ

−

γ+

+ (1 − p ) ]

1 +

γ

and w ( p ) =

−

−
−

[ p γ + (1 − p ) γ ]

1 −

γ

To control for the number of parameters, For the cumulative prospect theory
model, we only estimated the risk (α) and loss-aversion (λ) parameters for each
participant, while keeping the other values fixed based on previous experimental studies:
γ+ = 0.61 and γ- = 0.69 (Tversky and Kahneman, 1992; Birnbaum, 2005).

177

<-----Page 192----->Supplementary Tables
Appendix Table B-1: Regions significantly activated during the decision
phase in both RW and SD sessions.
MNI Coordinates
RW

BA

z-value

SD

x

y

z

x

y

z

RW

SD

R. Intraparietal sulcus

8

-70

43

30

-65

44

7

7.64

7.23

L. Intraparietal sulcus

-26

61

43

-28

59

42

7

7.19

7.42

R. Inf. Occipital
gyrus

24

-94

-10

23

-92

-12

17

7.44

7.09

L. Inf. Occipital gyrus

-30

-90

-10

-30

-90

-9

17

7.27

6.70

L. Fusiform

-42

-63

-20

-41

-67

-17

19

7.22

6.26

R. Mid. Frontal gyrus

32

2

49

34

-1

49

6

6.79

5.71

L. Mid. Frontal gyrus

-31

1

49

-26

-4

48

6

5.96

6.07

L. Inf. Frontal gyrus

-48

9

29

-50

12

29

9

6.72

6.67

R. Inf. Frontal gyrus

48

14

29

46

12

25

9

6.32

5.83

Anterior Cingulate

1

18

46

-6

19

44

8/32

6.55

5.85

R. Anterior Insula

32

24

-2

31

20

0

13

5.41

4.50

L. Anterior Insula

-30

21

-2

-30

22

-4

13

5.32

4.61

R. Mid Frontal Gyrus

45

31

18

45

31

19

46

5.84

4.59

Decision Phase

178

<-----Page 193----->Appendix Table B-2: Regions whose activation was modulated by state
during decision phase
MNI Coordinates

Brodmann

z-value

Area

x

y

z

R. Intraparietal sulcus

20

-74

50

7

3.30

L. Intraparietal sulcus

-14

-73

50

7

2.39

R. Thalamus

14

-8

-3

-

2.92

R. Fusiform gyrus

45

-70

-15

19

2.95

L. Fusiform gyrus

-45

-50

-18

19

2.82

-1

18

-14

25

3.59

-3

33

-24

25

3.45

L. Middle frontal gyrus

-36

40

-10

11

3.30

R. Middle frontal gyrus

37

37

-16

11

2.70

R. anterior insula

39

19

2

13

2.95

L. anterior insula

-34

19

2

13

2.68

1

33

48

8/32

2.56

Decision Phase (RW > SD)

Decision Phase (SD > RW)
Medial Frontal gyrus

Loss-focus Trials (RW > SD)

Dorsomedial prefrontal cortex

179

<-----Page 194----->Supplementary Figures

Appendix Figure B-1: Sleep deprivation changes economic preferences.

Appendix Figure B-2: Preferences following sleep deprivation were sensitive
to expected value relationship.

180

<-----Page 195----->Appendix Figure B-3: After normal sleep, activation in vmPFC predicted
Gmax choices and activation in insula predicted Lmin choices.

181

<-----Page 196----->Appendix C: Supplementary Material for Chapter 6
Attribute-Balancing Task
Participants completed a total of 96 trials of the attribute-balancing task, split
across four runs. The task was framed as a decision among stocks that varied in two
attributes. The attribute values were shown by the to the percentage rankings of that stock
within the set of all stocks on the major US markets. The identities of the stocks and of
the attributes were hidden from the participants until the end of the experiment, so that
prior knowledge about stocks and market behavior could not influence the results.
Each trial began by showing the participant three stocks. One stock was a
balanced option whose attribute ratings were similar (i.e., they were either equal or
differed by fewer than three points). The other two stocks were extreme options which
had a better rating on one attribute and a poor rating on the other. Then, following a brief
delay, one of the extreme options was eliminated, and the participant chose between the
balanced option and the remaining extreme option.
There were three types of conditions: congruent, incongruent, and equal, defined
based on the expected value relationship (i.e., the sum of the two attributes) between the
balanced and extreme options. In the incongruent condition, the expected value of the
balanced option was 8 (low-incongruence) or 16 (high-incongruence) points lower than
that of the alternative extreme option while in the congruent condition, the expected value
of the balanced option was 8 (low-congruence) or 16 (high-congruence) points higher. In
the equal condition, the balancing and extreme options had equal expected value.

182

<-----Page 197----->Stock attribute rankings for the balanced option ranged from 16 to 79 and the
extreme alternative varied from 7 to 98, depending on trial type. For the choice trials, the
extreme alternatives always had a higher score on one of the attributes and a lower score
on the other compared to the balanced option. The attribute ratings for the two extreme
alternatives were not identical but reversed: the numbers always varied slightly such that
no two stocks on any given trial had identical ratings on any attributes. Participants
completed 18 equal trials, 36 congruent trials (half low-congruence, half highcongruence), and 36 incongruent trials (half low-incongruence, half high-incongruence)
for a total of 90 main choice trials. For the strategy-control analysis, we included the lowcongruent and low-incongruent trials in addition to the equal trials for greater
experimental power. Finally, there were 6 randomly intermixed catch trials in which the
extreme alternative had higher ratings than the balanced option on both attributes and
thus was the more desirable option. These trials thus served to ensure that participants
attended to the task.

Participant instructions
Prior to the scanning session, participants were informed that they would make a
series of choices between different stocks and their task was to predict the stock that is
likely to be more profitable based on the normalized ratings on the two attributes. It was
emphasized that each trial involved information about real stocks, and the attributes
represented information that a financial analyst might use when making investing
decisions (e.g., normalized ratings of a company’s financial reserves). Participants were
183

<-----Page 198----->told that the particular stock or attribute in each trial would not be identified while they
made decisions to ensure that their prior knowledge did not influence their choice.
However, as an incentive to perform well, participants were informed that a portion of
their payment would depend on their performance (see Participant Payments below).

Stock Selection
All stock information presented in the task represented real stocks and their
performance in a historical market (October, 2007). Stocks and their attribute rankings
were identified using the website “The Motley Fool CAPS” (http://caps.fool.com/)”.
For each stock, the two attribute rankings were their 30-day and one-year performance,
among all stocks on US markets; these corresponded to normalized attributes a1 and a2,
respectively. At the end of the session, we revealed the ticker name for each available
stock as well as the more profitable of the two stocks, based on its performance at the end
of the identified market period. Participants received a monetary bonus if they had
selected the more profitable of the two stocks (see below).

Participant Payments
Participants were informed at the beginning of the session that they would be paid
a fixed amount for participation ($40) plus a variable component that would depend on
their choices. For this variable component, they were given a hidden cash endowment
($10) in a sealed envelope prior to the scan; its value was unknown to the participant until
the end of the session. For each of two randomly selected trials from the attribute184

<-----Page 199----->balancing task, an additional $5 was added to the endowment if they successfully
predicted the higher performing stock. If they did not select the higher performing stock,
$5 was subtracted from the endowment. Finally, participants had the opportunity to win
an additional $5 based if their performance on the counting Stroop task reached a
criterion level: accuracy greater than 95% and average response time faster than 600 ms.

Behavioral Results
Participants’ choices were sensitive to manipulations of expected value. In the
congruent condition, where the balanced alternative was associated with higher expected
value, the proportion of balanced choices was the greatest at 0.89 (Table C-1). In the
incongruent condition, however, this value dropped to 0.23 indicating that participants
preferred the extreme alternative when it was associated with significantly greater
expected value. For the equal condition, participant still showed a small, but significant,
bias towards the balanced alternative preferring it in 65% of the trials. Post-experiment
questionnaires indicated that participants treated our manipulations of expected value in a
logical manner consistent with our experimental design.

185

<-----Page 200----->Meta Analysis
Studies for use in the meta-analyses were identified by keyword searches through
comprehensive databases (e.g., PubMed). Keywords included “cingulate”, “response”,
“conflict”, “neuroimaging”, and “Stroop” for response-related control studies and
“cingulate”, “decision”, “choice”, “medial frontal”, and “fMRI” for decision-related
control studies. We emphasize that this meta-analysis was not intended to be a
comprehensive review of all prior literature, but a way to corroborate the loci of
activation identified in our experiments.
Studies selected from the search results met the following criteria. The cognitive
control studies (a) utilized a task considered to elicit robust response-related control
demands, such as the Stroop or Go/No-Go tasks; (b) provided three-dimensional
coordinates of peak voxel activation during the response portion of the task; (c) showed
peak activation in the dmPFC (BA 6, 9, 24, or 32); and (d) used fMRI or PET to acquire
functional brain images from neurologically healthy individuals. The decision-related
control studies (a) engaged participants in a task requiring them to decide between
multiple options, (b) provided three-dimensional coordinates of peak voxel activation
during the decision-making portion of the task, (c) reported areas of activation in the
dmPFC (BA 6, 9,24, or 32), and (d) used fMRI to acquire functional brain images from
neurologically healthy individuals. This process resulted in the selection of 28 studies for
inclusion in the response-related control condition (Table C-4) and 25 studies for
inclusion in the decision-related control condition (Table C-5), yielding 48 and 38
activation foci, respectively.
186

<-----Page 201----->Three separate activation likelihood estimate (ALE) based meta-analyses were
carried out using the GingerALE software (Turkeltaub et al., 2002; Laird et al., 2005).
The first consolidated response-related control studies, the second consolidated decisionrelated control studies, and the third generated a contrast between the first two analyses.
All activation foci originally reported as MNI coordinates in the manuscript tables were
converted to Talairach coordinates. ALE values were computed in Talairach space and
activation foci were plotted using a full-width half maximum (FWHM) of 10.0 mm. To
evaluate statistical significance, permutation testing was subsequently performed with
5000 iterations. A false discovery rate level of 0.05 was used to compute the ALE map
threshold. The subtraction meta-analysis provided a map of regions where the two groups
of foci are significantly different. Thresholded ALE maps were overlaid onto the
colin1.1.nii anatomical template (Figure C-7) provided by BrainMap (Turkeltaub et al.,
2002). We also transformed the peak activations for each contrast to MNI coordinates to
allow direct comparisons with the functional activations in our current study (Figure 6-6,
squares).

187

<-----Page 202----->Supplementary Tables
Appendix Table C-1: Mean proportion of balanced choice and response
times.
Prop. of Balanced Choices (%)

Response Time (s)

Mean

S.E

Mean

S.E.

Congruent

88.81

1.77

0.72

0.04

Incongruent

22.65

3.51

0.87

0.08

Equal

64.95

3.56

1.13

0.13

Appendix Table C-2: Regions activated during counting stroop task.
MNI Coordinates

Brodmann

z-value

Area

x

y

z

0

17

51

8

4.34

-46

13

33

9

4.61

-40

11

24

9

4.49

L. Superior Parietal Lobule

-28

-67

43

7

4.22

L. Posterior Parietal Cortex

-37

-47

48

40

4.31

L. Middle Frontal Gyrus

-39

1

54

6

4.21

R. Middle Frontal Gyrus

36

5

54

6

3.71

Main Effect: Incongruent > Neutral
Dorsomedial Prefrontal Cortex
L. Dorsolateral Prefrontal
Cortex

Response-related control: (Incongruent – Neutral) * (Response Time)
Dorsomedial Prefrontal Cortex

-5

10

51

32

3.41

L. Dorsolateral Prefrontal Cortex

-55

9

34

9

3.06

188

<-----Page 203----->Appendix Table C-3: Summary of regions activated during the attributebalancing task.
MNI Coordinates

Brodman
n

zvalue

X

y

z

R. Dorsolateral Prefrontal Cortex

42

38

32

9

2.81

R. Posterior Parietal Cortex

46

-41

37

40

2.91

Dorsomedial Prefrontal Cortex

-6

24

38

32

2.62

R. Inferior Frontal Gyrus

44

50

10

46

2.50

R. Inferior Frontal Gyrus

44

31

14

46

2.99

R. Precuneus

30

-50

44

9

3.42

Dorsomedial Prefrontal Cortex

-10

28

34

32

2.50

Anterior Insula

33

25

1

13

3.01

-36

26

8

13

2.97

L. Lateral Prefrontal Cortex

-46

24

12

46

3.01

R. Lateral Prefrontal Cortex

42

26

22

46

2.73

R. Anterior Insula

26

27

6

13

2.86

R. Precuneus

28

-59

54

7

2.71

L. Precuneus

-31

-50

42

7

2.51

Area

Decision: Equal > Incongruent

Decision: Incongruent >
Congruent

Choices: Extreme > Balanced

189

<-----Page 204----->Appendix Table C-4: Summary of response-related control studies used in
ALE meta-analysis.
Talairach Coordinates

Response-related Control Studies
1.

Bench et al. 1993

2.
3.

George et al. 1994
Carter et al. 1995

4.

Kawashima et al. 1996

5.
6.
7.
8.

George et al. 1997
Bush et al. 1998
Carter et al. 1998
Derbyshire et al. 1998

9.
10.

Botvinick et al. 1999
Brown et al. 1999

11.

Bush et al. 1999

12.
13.
14.
15.
16.
17.

Konishi et al. 1999
Peterson et al. 1999
Carter et al. 2000
Casey et al. 2000
Macdonald et al. 2000
Barch et al. 2001

18.

Kerns et al. 2004

190

x

y

z

4
10
18
20
22
-22
10
12
6
-4
8
8
-4
-4
-22
12
4
-2
0
-2
8
-4
6
6
-3
-5
-7
0
-8
4
8
8
11
5
1

-4
-4
40
42
42
24
8
44
-11
-44
-23
6
9
5
8
9
25
14
2
28
23
14
0
15
21
29
18
15
22
1
9
21
3
15
10

20
24
4
8
12
32
48
20
52
33
49
42
38
30
28
34
43
40
48
31
35
35
40
43
37
32
26
41
32
43
42
24
42
39
40

<-----Page 205----->19.
20.
21.
22.
23.
24.

Erickson et al. 2004
Egner and Hirsch, 2004
Milham and Banich, 2005
Critchley et al. 2005
Weissman et al. 2005
van Veen and Carter, 2005

2
18
0
6
-2
7
1

18
8
30
22
5
18
26

40
46
22
38
43
42
28

25.
26.
27.

Evers et al. 2006
Kerns, 2006
Lau et al. 2006

28.

Roelofs et al. 2006

0
-3
6
10
-4
-8

36
8
16
24
30
36

22
41
34
34
36
28

191

<-----Page 206----->Appendix Table C-5: Summary of decision-related control studies used in
ALE meta-analysis.
Talairach Coordinates
x
y
z

Decision-related Control Studies
1.

Elliot and Dolan, 1998

2.

Critchley et al. 2001

3.
4.

Bush et al. 2002
Paulus et al. 2002

5.

Sanfey et al. 2003

6.

O'Doherty et al. 2003

7.
8.

Volz et al. 2003
Rogers et al. 2004

9.

Volz et al. 2004

10.

Walton et al. 2004

11.
12.
13.
14.

Ernst et al. 2004
Cohen et al. 2005
Coricelli et al. 2005
Deppe et al. 2005

15.
16.

Huettel et al. 2005
Fishbein et al. 2005

17.
18.
19.
20.

Paulus and Frank, 2005
Blair et al. 2006
De Martino et al. 2006
Hampton et al. 2006

21.
22.
23.
24.
25.

Krain et al. 2006
Marsh et al. 2006
Moll et al. 2006
Behrens et al. 2007
Pochon et al. 2008

-4
8
-6
-2
8
1
6
4
-3
6
4
-3
1
1
4
-7
0
-6
5
-3
-7
6
7
-8
14
8
3
0
6
-3
-20
2
-4
-6
-3
-6

192

28
28
28
23
44
27
39
20
21
21
30
37
38
33
21
16
12
24
36
25
38
46
14
34
32
23
16
17
22
25
39
25
20
26
20
39

30
24
20
20
3
31
10
36
39
39
46
15
19
41
47
38
36
42
29
41
17
11
39
15
17
28
46
46
40
26
14
37
43
34
43
23

<-----Page 207----->Supplementary Figures

Appendix Figure C-1: Variability in preference for the balanced option in
the attribute-balancing task

Appendix Figure C-2: Incongruent trials in the Stroop task activated lateral
frontal, medial frontal, and parietal regions

193

<-----Page 208----->Appendix Figure C-3: Activation in pDMPFC predicts individual differences
in motor impulsiveness across participants

Appendix Figure C-4: Activation associated with decision-related control
demands.

194

<-----Page 209----->Appendix Figure C-5: Activation in aDMPFC predicts individual differences
in the need for cognition trait across participants

Appendix Figure C-6: Anterior and middle dmPFC are associated with
strategy and decision-related control respectively

Appendix Figure C-7: Functional topography in dmPFC based on metaanalysis
195

<-----Page 210----->References
Amodio DM, Frith CD (2006) Meeting of minds: the medial frontal cortex and social
cognition. Nature Reviews Neuroscience 7:268-277.
Badre D (2008) Cognitive control, hierarchy, and the rostro-caudal organization of the
frontal lobes. Trends in Cognitive Science 12:193-200.
Badre D, D'Esposito M (2007) Functional Magnetic Resonance Imaging Evidence for a
Hierarchical Organization of the Prefrontal Cortex. J Cogn Neurosci.
Badre D, D'Esposito M (2009) Is the rostro-caudal axis of the frontal lobe hierarchical?
Nat Rev Neurosci 10:659-669.
Badre D, Hoffman J, Cooney JW, D'Esposito M (2009) Hierarchical cognitive control
deficits following damage to the human frontal lobe. Nature Neuroscience
12:515-522.
Barbas H, Pandya DN (1989) Architecture and intrinsic connections of the prefrontal
cortex in the rhesus monkey. J Comp Neurol 286:353-375.
Barch DM, Braver TS, Sabb FW, Noll DC (2000) Anterior cingulate and the monitoring
of response conflict: Evidence from an fMRI study of overt verb generation.
Journal of Cognitive Neuroscience 12:298-309.
Barraclough DJ, Conroy ML, Lee D (2004) Prefrontal cortex and decision making in a
mixed-strategy game. Nat Neurosci 7:404-410.
Bates JF, Goldman-Rakic PS (1993) Prefrontal connections of medial motor areas in the
rhesus monkey. Journal of Comparative Neurology 336:211-228.
Bechara A, Tranel D, Damasio H (2000a) Characterization of the decision-making deficit
of patients with ventromedial prefrontal cortex lesions. Brain 123:2189-2202.
Bechara A, Damasio H, Damasio AR (2000b) Emotion, decision making and the
orbitofrontal cortex. Cerebral Cortex 10:295-307.
Beckmann M, Johansen-Berg H, Rushworth MFS (2009) Connectivity-Based
Parcellation of Human Cingulate Cortex and Its Relation to Functional
Specialization. Journal of Neuroscience 29:1175-1190.
Behrens TE, Hunt LT, Rushworth MF (2009) The computation of social behavior.
Science 324:1160-1164.

196

<-----Page 211----->Behrens TE, Woolrich MW, Walton ME, Rushworth MF (2007) Learning the value of
information in an uncertain world. Nat Neurosci 10:1214-1221.
Behrens TE, Hunt LT, Woolrich MW, Rushworth MF (2008) Associative learning of
social value. Nature 456:245-249.
Bell-McGinty S, Habeck C, Hilton HJ, Rakitin B, Scarmeas N, Zarahn E, Flynn J,
DeLaPaz R, Basner R, Stern Y (2004) Identification and differential vulnerability
of a neural network in sleep deprivation. Cereb Cortex 14:496-502.
Bernoulli D (1738) Specimen theoriae novae de mensura sortis. Commentarii Academiae
Scientarum Imperialis Petropolitanae 5:175-192.
Bettman JR, Kakkar P (1977) Effects of Information Presentation Format on Consumer
Information Acquisition Strategies. Journal of Consumer Research 3:233-240.
Bettman JR, Johnson EJ, Luce MF, Payne JW (1993) Correlation, Conflict, and Choice.
Journal of Experimental Psychology-Learning Memory and Cognition 19:931951.
Birnbaum MH (2005) Three New Tests of Independence That Differentiate Models of
Risky Decision Making. Management Science 51:1346-1358.
Birnbaum MH (2007) Tests of branch splitting and branch-splitting independence in
Allais paradoxes with positive and mixed consequences. Organizational Behavior
and Human Decision Processes 102:154-173.
Birnbaum MH (2008a) New paradoxes of risky decision making. Psychological Review
115:463-501.
Birnbaum MH (2008b) New tests of cumulative prospect theory and the priority
heuristic: Probability-outcome tradeoff with branch splitting. Judgment and
Decision Making Journal 3:304-316.
Birnbaum MH, Bahra JP (2007) Gain-loss separability and coalescing in risky decision
making. Management Science 53:1016-1028.
Bishara AJ, Pleskac TJ, Fridberg DJ, Yechiam E, Lucas J, Busemeyer JR, Finn PR, Stout
JC (2009) Similar Processes Despite Divergent Behavior in Two Commonly Used
Measures of Risky Decision Making. Journal of Behavioral Decision Making
22:435-454.
Bodenhausen GV, Sheppard LA, Kramer GP (1994) Negative Affect and Social
Judgment - the Differential Impact of Anger and Sadness. European Journal of
Social Psychology 24:45-62.
197

<-----Page 212----->Botvinick M, Nystrom LE, Fissell K, Carter CS, Cohen JD (1999) Conflict monitoring
versus selection-for-action in anterior cingulate cortex. Nature 402:179-181.
Botvinick MM (2008) Hierarchical models of behavior and prefrontal function. Trends in
Cognitive Science!2:201-208.
Botvinick MM, Rosen ZB (2008) Anticipation of cognitive demand during decisionmaking. Psychol Res.
Botvinick MM, Cohen JD, Carter CS (2004) Conflict monitoring and anterior cingulate
cortex: an update. Trends in Cognitive Sciences 8:539-546.
Botvinick MM, Braver TS, Barch DM, Carter CS, Cohen JD (2001) Conflict monitoring
and cognitive control. Psychol Rev 108:624-652.
Botvinick MN, L.E.; Fissell, K.; Carter, C.S.; Cohen, J.D. (1999) Conflict monitoring
versus selection-for-action in anterior cingulate cortex. Nature 402:179-181.
Brainard DH (1997) The Psychophysics Toolbox. Spatial Vision 10:433-436.
Brandstatter E, Gigerenzer G, Hertwig R (2006) The priority heuristic: Making choices
without trade-offs. Psychological Review 113:409-432.
Breiter HC, Aharon I, Kahneman D, Dale A, Shizgal P (2001) Functional imaging of
neural responses to expectancy and experience of monetary gains and losses.
Neuron 30:619-639.
Brown JW, Braver TS (2005a) Learned predictions of error likelihood in the anterior
cingulate cortex. Science 307:1118-1121.
Brown JW, Braver TS (2005b) Learned prediction of error likelihood in the anterior
cingulate cortex. Science 207:1118-1121.
Bugg JM (2008) Opposing influences on conflict-driven adaptation in the Eriksen flanker
task. Mem Cognit 36:1217-1227.
Bunge SA, Hazeltine E, Scanlon MD, Rosen AC, Gabrieli JD (2002) Dissociable
contributions of prefrontal and parietal cortices to response selection. NeuroImage
17:1562-1571.
Busemeyer JR, Townsend JT (1993) Decision Field-Theory - a Dynamic Cognitive
Approach to Decision-Making in an Uncertain Environment. Psychological
Review 100:432-459.

198

<-----Page 213----->Bush G, Luu P, Posner MI (2000) Cognitive and emotional influences in anterior
cingulate cortex. Trends Cogn Sci 4:215-222.
Bush G, Whalen PJ, Rosen BR, Jenike MA, McInerney SC, Rauch SL (1998) The
counting Stroop: an interference task specialized for functional neuroimaging-validation study with functional MRI. Hum Brain Mapp 6:270-282.
Bush G, Vogt BA, Holmes J, Dale AM, Greve D, Jenike MA, Rosen BR (2002) Dorsal
anterior cingulate cortex: A role in reward-based decision making. Proceedings of
the National Academy of Sciences of the United States of America 99:523-528.
Camerer C (2003a) Behavioral Game Theory: Experiments in Strategic Interaction.
Princeton, NJ.: Princeton University Press.
Camerer CF (2003b) Behavioural studies of strategic thinking in games. Trends Cogn Sci
7:225-231.
Carter CS, Braver TS, Barch DM, Botvinick M, Noll D, Cohen JD (1998) Anterior
Cingulate Cortex, Error Detection, and the Online Monitoring of Performance.
Science 280:747-749.
Centres for Disease Control U (2009) Perceived insufficient rest or sleep among adults United States, 2008. MMWR Morb Mortal Wkly Rep 58:1175-1179.
Chee MW, Choo WC (2004) Functional imaging of working memory after 24 hr of total
sleep deprivation. J Neurosci 24:4560-4567.
Chee MW, Chuah YM (2007) Functional neuroimaging and behavioral correlates of
capacity decline in visual short-term memory after sleep deprivation. Proc Natl
Acad Sci U S A 104:9487-9492.
Chee MW, Tan JC (2010) Lapsing when sleep deprived: neural activation characteristics
of resistant and vulnerable individuals. Neuroimage 51:835-843.
Chee MWL, Tan JC, Zheng H, Parimal S, Weissman DH, Zagorodnov V, Dinges DF
(2008) Lapsing during sleep deprivation is associated with distributed changes in
brain activation. J Neurosci 28 5519-5528.
Chernev A (2004) Extremeness aversion and attribute-balance effects in choice. Journal
of Consumer Research 31:249-263.
Chernev A (2005) Context effects without a context: Attribute balance as a reason for
choice. Journal of Consumer Research 32.

199

<-----Page 214----->Christoff K, Gabrieli JDE (2000) The frontopolar cortex and human cognition: Evidence
for a rostrocaudal hierarchical organization within the human prefrontal cortex.
Psychobiology 28:168-186.
Christoff K, Keramatian K (2007) Abstraction of mental representations: Theoretical
considerations and neuroscientific evidence.
Christoff K, Ream JM, Geddes LP, Gabrieli JD (2003) Evaluating self-generated
information: anterior prefrontal contributions to human cognition. Behavioral
Neuroscience 117:1161-1168.
Christoff K, Prabhakaran V, Dorfman J, Zhao Z, Kroger JK, Holyoak KJ, Gabrieli JD
(2001) Rostrolateral prefrontal cortex involvement in relational integration during
reasoning. Neuroimage 14:1136-1149.
Chuah LY, Chee MW (2008) Functional neuroimaging of sleep deprived healthy
volunteers and persons with sleep disorders: a brief review. Ann Acad Med
Singapore 37:689-694.
Clithero JA, Tankersley DT, Huettel SA (2008) Foundation of Neuroeconomics: From
Philosophy to Practice. PLOS Biology 6.
Cohen MX, Heller AS, Ranganath C (2005) Functional connectivity with anterior
cingulate and orbitofrontal cortices during decision-making. Brain Res Cogn
Brain Res 23:61-70.
Cope DE, Murphy AJ (1981) The Value of Strategies in Problem-Solving. Journal of
Psychology 107:11-16.
Coricelli G, Critchley HD, Joffily M, O'Doherty J P, Sirigu A, Dolan RJ (2005) Regret
and its avoidance: a neuroimaging study of choice behavior. Nature Neuroscience
8:1255-1262.
Craig AD (2009) How do you feel--now? The anterior insula and human awareness. Nat
Rev Neurosci 10:59-70.
Dalgleish T (2004) The emotional brain. Nature Reviews Neuroscience 5:582-589.
Damoiseaux JS, Rombouts SARB, Barkhof F, Scheltens P, Stam CJ, Smith SM,
Beckmann CF (2006) Consistent resting-state networks across healthy subjects.
Proceedings of the National Academy of Sciences 103:13848-13853.
Daw ND, O'Doherty JP, Dayan P, Seymour B, Dolan RJ (2006) Cortical substrates for
exploratory decisions in humans. Nature 441:876-879.
200

<-----Page 215----->De Luca M, Beckmann CF, De Stefano N, Matthews PM, Smith SM (2006) fMRI resting
state networks define distinct modes of long-distance interactions in the human
brain. NeuroImage 29:1359-1367.
De Martino B, Kumaran D, Seymour B, Dolan RJ (2006) Frames, biases, and rational
decision-making in the human brain. Science 313:684-687.
Delgado MR, Nystrom LE, Fissell C, Noll DC, Fiez JA (2000) Tracking the
hemodynamic responses to reward and punishment in the striatum. Journal of
Neurophysiology 84:3072-3077.
Derrfuss J, Brass M, Neumann J, von Cramon DY (2005) Involvement of the inferior
frontal junction in cognitive control: meta-analyses of switching and Stroop
studies. Hum Brain Mapp 25:22-34.
Diecidue E, van de Ven J (2008) Aspiration level, probability of success and failure, and
expected utility. International Economic Review 49:683-700.
Dinges DF, Pack F, Williams K, Gillen KA, Powell JW, Ott GE, Aptowicz C, Pack AI
(1997) Cumulative sleepiness, mood disturbance, and psychomotor vigilance
performance decrements during a week of sleep restricted to 4-5 hours per night.
Sleep 20:267-277.
Doran SM, Van Dongen HP, Dinges DF (2001) Sustained attention performance during
sleep deprivation: evidence of state instability. Arch Ital Biol 139:253-267.
Dorris MC, Glimcher PW (2004) Activity in posterior parietal cortex is correlated with
the relative subjective desirability of action. Neuron 44:365-378.
Drolet A, Luce MF (2004) The rationalizing effects of cognitive load on emotion-based
trade-off avoidance. Journal of Consumer Research 31:63-77.
Drummond SP, Meloy MJ, Yanagi MA, Orff HJ, Brown GG (2005) Compensatory
recruitment after sleep deprivation and the relationship with performance.
Psychiatry Res 140:211-223.
Egner T (2009) Prefrontal cortex and cognitive control: motivating functional hierarchies.
Nature Neuroscience 12:821-822.
Epstein S, Pacini R, Denes-Raj V, Heier H (1996a) Individual differences in intuitiveexperiential and analytical-rational thinking styles. Journal of Personality and
Social Psychology 71:390-405.

201

<-----Page 216----->Epstein S, Pacini R, DenesRaj V, Heier H (1996b) Individual differences in intuitiveexperiential and analytical-rational thinking styles. Journal of Personality and
Social Psychology 71:390-405.
Etkin A, Egner T, Peraza DM, Kandel ER, Hirsch J (2006) Resolving emotional conflict:
a role for the rostral anterior cingulate cortex in modulating activity in the
amygdala. Neuron 51:871-882.
Fennema H, Wakker P (1997) Original and cumulative prospect theory: A discussion of
empirical differences. Journal of Behavioral Decision Making 10:53-64.
Ferrier D (1886) The functions of the brain, 2nd Edition. London: Smith Elder.
Fordyce MW (1988) A Review of Research on the Happiness Measures - a 60 Second
Index of Happiness and Mental-Health. Social Indicators Research 20:355-381.
Frank MJ, Cohen MX, Sanfey AG (2009) Multiple Systems in Decision Making: A
Neurocomputational Perspective. Current Directions in Psychological Sciences
18:73-77.
Fransson P (2005) Spontaneous low-frequency BOLD signal fluctations: An fMRI
investigation of the resting-state default mode of brain function hypothesis.
Human Brain Mapping 26:15-29.
Fuster JM (2001) The prefrontal cortex - An update: Time is of the essence. Neuron
30:319-333.
Fuster JM (2004) Upper processing stages of the perception-action cycle. Trends in
Cognitive Science 8:143-145.
Fuster JM, Bodner M, Kroger JK (2000) Cross-model and cross-temporal association in
neurons of frontal cortex. Nature 405:347-351.
Gehring WJ, Willoughby AR (2002) The medial frontal cortex and the rapid processing
of monetary gains and losses. Science 295:2279-2282.
Gehring WJ, Coles MG, Meyer DE, Donchin E (1995) A brain potential manifestation of
error-related processing. Electroencephalogr Clin Neurophysiol Suppl 44:261272.
Gigerenzer G, Goldstein DG (1996) Reasoning the fast and frugal way: models of
bounded rationality. Psychol Rev 103:650-669.
Gigerenzer G, Todd PM, Group TAR (1999) Simple heuristics that make us smart. New
York: Oxford University Press.
202

<-----Page 217----->Glimcher PW (2003) Decisions, uncertainty, and the brain: The science of
neuroeconomics. Cambridge, Massachusetts: MIT Press.
Glockner A, Betsch T (2008) Do people make decisions under risk based on ignorance?
An empirical test of the priority heuristic against cumulative prospect theory.
Organizational Behavior and Human Decision Processes 107:75-95.
Glockner A, Betsch T (2010) Accounting for Critical Evidence While Being Precise and
Avoiding the Strategy Selection Problem in a Parallel Constraint Satisfaction
Approach: A Reply to Marewski (2010). Journal of Behavioral Decision Making
23:468-472.
Glockner A, Herbold A-K (2011) An eye-tracking study on information processing in
risky decisions: Evidence for compensatory strategies based on automatic
processes. Journal of Behavioral Decision Making 24:71-98.
Glockner A, Betsch T, Schindler N (2010) Coherence Shifts in Probabilistic Inference
Tasks. Journal of Behavioral Decision Making 23:439-462.
Glover GH, Law CS (2001) Spiral-in/out BOLD fMRI for increased SNR and reduced
susceptibility artifacts. Magn Reson Med 46:515-522.
Gonzalez R, Wu G (1999) On the shape of the probability weighting function. Cogn
Psychol 38:129-166.
Gottselig JM, Adam M, Retey JV, Khatami R, Achermann P, Landolt HP (2006) Random
number generation during sleep deprivation: effects of caffeine on response
maintenance and stereotypy. J Sleep Res 15:31-40.
Graw P, Krauchi K, Knoblauch V, Wirz-Justice A, Cajochen C (2004) Circadian and
wake-dependent modulation of fastest and slowest reaction times during the
psychomotor vigilance task. Physiol Behav 80:695-701.
Guo H, Song AW (2003) Spiral-in-and-out functional image acquisition with embedded
z-shimming for susceptibility signal recovery. Journal of Magnetic Resonance
Imaging 18:389-395.
Habeck C, Rakitin BC, Moeller J, Scarmeas N, Zarahn E, Brown T, Stern Y (2004) An
event-related fMRI study of the neurobehavioral impact of sleep deprivation on
performance of a delayed-match-to-sample task. Brain Res Cogn Brain Res
18:306-321.
Hadland KA, Rushworth MFS, Gaffan D, Passingham RE (2003) The anterior cingulate
and reward-guided selection of actions. Journal of Neurophysiology 89:11611164.
203

<-----Page 218----->Hampton AN, O'Doherty J P (2007) Decoding the neural substrates of reward-related
decision making with functional MRI. Proc Natl Acad Sci U S A 104:1377-1382.
Harrison Y, Horne JA (1999) One Night of Sleep Loss Impairs Innovative Thinking and
Flexible Decision Making. Organ Behav Hum Decis Process 78:128-145.
Harrison Y, Horne JA (2000) The impact of sleep deprivation on decision making: a
review. J Exp Psychol Appl 6:236-249.
Hastie R, Schkade DA, Payne JW (1999) Juror judgments in civil cases: Hindsight
effects on judgments of liability for punitive damages. Law and Human Behavior
23:597-614.
Hedgcock W, Rao AR (2008) Trade-off Aversion as an Explanation for the Attraction
Effect: A Functional Magnetic Resonance Study. Journal of Marketing Research
In press.
Heekeren HR, Marrett S, Bandettini PA, Ungerleider LG (2004) A general mechanism
for perceptual decision-making in the human brain. Nature 431:859-862.
Heekeren HR, Marrett S, Ruff DA, Bandettini PA, Ungerleider LG (2006) Involvement
of human left dorsolateral prefrontal cortex in perceptual decision making is
independent of response modality. Proc Natl Acad Sci U S A 103:10023-10028.
Hsu M, Bhatt M, Adolphs R, Tranel D, Camerer CF (2005) Neural systems responding to
degrees of uncertainty in human decision-making. Science 310:1680-1683.
Huck NO, McBride SA, Kendall AP, Grugle NL, Killgore WD (2008) The effects of
modafinil, caffeine, and dextroamphetamine on judgments of simple versus
complex emotional expressions following sleep deprivation. Int J Neurosci
118:487-502.
Huettel SA (2006) Behavioral, but not reward, risk modulates activation of prefrontal,
parietal, and insular cortices. Cognitive, Affective, and Behavioral Neuroscience
6:141-151.
Huettel SA, Payne JW (2009) Integrating Neural and Decision Sciences: Convergence
and Constraints. Journal of Marketing Research 46:14-17.
Huettel SA, Song AW, McCarthy G (2005a) Decisions under uncertainty: Probabilistic
context influences activity of prefrontal and parietal cortices. Journal of
Neuroscience 25:3304-3311.

204

<-----Page 219----->Huettel SA, Song A, McCarthy G (2005b) Decisions under Uncertainty: Probabilistic
Context Influences Activation of Prefrontal and Parietal Cortices. Journal of
Neuroscience 25:3304-3311.
Huettel SA, Stowe CJ, Gordon EM, Warner BT, Platt ML (2006) Neural signatures of
economic preferences for risk and ambiguity. Neuron 49:765-775.
Institute of Medicine (2006) Sleep disorders and sleep deprivation: an unmet public
health problem. Washington DC: The National Academies Press.
Johnson EJ, Schulte-Mecklenbeck M, Willemsen MC (2008) Process models deserve
process data: Comment on Brandstatter, Gigerenzer, and Hertwig (2006).
Psychological Review 115:263-272.
Kaas JH (1997) Topographic Maps are Fundamental to Sensory Processing. Brain
Research Bulletin 44:107-112.
Kahneman D, Tversky A (1979) Prospect theory: An analysis of decision under risk.
Econometrica 47:263-291.
Kahneman D, Frederick S (2002) Representativeness revisited: Attribute substitution in
intuitive judgement. In: Hurestics and biases: The psychology of intuitive thought
(Gilovich T, Griffin D, Kahneman D, eds), pp 49-81. New York: Cambridge
University Press.
Kawashima R, Satoh K, Itoh H, Ono S, Furumoto S, Gotoh R, Koyama M, Yoshioka S,
Takahashi T, Takahashi K, Yanagisawa T, Fukuda H (1996) Functional anatomy
of GO/NO-GO discrimination and response selection--a PET study in man. Brain
Research 728:79-89.
Kennerley SW, Walton ME, Behrens TE, Buckley MJ, Rushworth MF (2006) Optimal
decision making and the anterior cingulate cortex. Nat Neurosci 9:940-947.
Kerns JG (2006) Anterior cingulate and prefrontal cortex activity in an FMRI study of
trial-to-trial adjustments on the Simon task. Neuroimage 33:399-405.
Kerns JG, Cohen JD, MacDonald AW, 3rd, Cho RY, Stenger VA, Carter CS (2004)
Anterior cingulate conflict monitoring and adjustments in control. Science
303:1023-1026.
Kiehl KA, Liddle PF, Hopfinger JB (2000) Error processing and the rostral anterior
cingulate: an event-related fMRI study. Psychophysiology 37:216-223.
Killgore WD, Balkin TJ, Wesensten NJ (2006) Impaired decision making following 49 h
of sleep deprivation. J Sleep Res 15:7-13.
205

<-----Page 220----->Killgore WD, Lipizzi EL, Kamimori GH, Balkin TJ (2007) Caffeine effects on risky
decision making after 75 hours of sleep deprivation. Aviat Space Environ Med
78:957-962.
Killgore WD, Grugle NL, Killgore DB, Leavitt BP, Watlington GI, McNair S, Balkin TJ
(2008) Restoration of risk-propensity during sleep deprivation: caffeine,
dextroamphetamine, and modafinil. Aviat Space Environ Med 79:867-874.
Kim H, Shimojo S, O'Doherty JP (2006) Is avoiding an aversive outcome rewarding?
Neural substrates of avoidance learning in the human brain. PLoS Biol 4:e233.
Knutson B, Fong GW, Bennett SM, Adams CM, Hommer D (2003) A region of mesial
prefrontal cortex tracks monetarily rewarding outcomes: characterization with
rapid event-related fMRI. NeuroImage 18:263-272.
Kobayashi S, Lauwereyns J, Koizumi M, Sakagami M, Hikosaka O (2002) Influence of
reward expectation on visuospatial processing in macaque lateral prefrontal
cortex. J Neurophysiol 87:1488-1498.
Koechlin E, Summerfield C (2007) An information theoretical approach to prefrontal
executive function. Trends in Cognitive Science 11:229-235.
Koechlin E, Ody C, Kouneiher F (2003) The architecture of cognitive control in the
human prefrontal cortex. Science 302:1181-1185.
Koechlin E, Corrado G, Pietrini P, Grafman J (2000) Dissociating the role of the medial
and lateral anterior prefrontal cortex in human planning. Proc Natl Acad Sci U S
A 97:7651-7656.
Koechlin E, Basso G, Pietrini P, Panzer S, Grafman J (1999) The role of the anterior
prefrontal cortex in human cognition. Nature 399:148-151.
Kouneiher F, Charron S, Koechlin E (2009) Motivation and cognitive control in the
human prefrontal cortex. Nature Neuroscience 12:939-947.
Kuhnen CM, Knutson B (2005) The neural basis of financial risk taking. Neuron 47:763770.
Laird AR, Fox PM, Price CJ, Glahn DC, Uecker AM, Lancaster JL, Turkeltaub PE,
Kochunov P, Fox PT (2005) ALE meta-analysis: controlling the false discovery
rate and performing statistical contrasts. Hum Brain Mapp 25:155-164.
Lashley KS (1929) Brain mechanisms and intelligence: A quantitative study of injuries to
the brain. Chicago: University of Chicago press.
206

<-----Page 221----->Lashley KS (1950) In search of engram. In: Society of experimental biology, pp 454-482.
Lemaire P (2010) Cognitive Strategy Variation during Aging. Current Directions in
Psychological Sciences 19:363-369.
Levy I, Snell J, Nelson AJ, Rustichini A, Glimcher PW (2010) Neural representation of
subjective value under risk and ambiguity. J Neurophysiol 103:1036-1047.
Lichtenstein S, Slovic P (2006) The Construction of Preference. New York, NY:
Cambridge University Press.
Lim J, Choo WC, Chee MW (2007) Reproducibility of changes in behaviour and fMRI
activation associated with sleep deprivation in a working memory task. Sleep
30:61-70.
Linde L, Edland A, Bergstrom M (1999) Auditory attention and multiattribute decisionmaking during a 33 h sleep-deprivation period: mean performance and betweensubject dispersions. Ergonomics 33:696-713.
Liu X, Powell DK, Wang H, Gold BT, Corbly CR, Joseph JE (2007) Functional
dissociation in frontal and striatal areas for processing of positive and negative
reward information. J Neurosci 27:4587-4597.
Loewenstein G, Rick S, Cohen JD (2008) Neuroeconomics. Annu Rev Psychol 59:647672.
Lohse GL, Johnson EJ (1996) A comparison of two process tracing methods for choice
tasks. Organizational Behavior and Human Decision Processes 68:28-43.
Loomes G (2010) Modeling Choice and Valuation in Decision Experiments.
Psychological Review 117:902-924.
Lopes LL (1995) On modeling risky choice: Why reasons matter. Contributions to
Decision Making - I:29-50
Lopes LL, Oden GC (1999) The role of aspiration level in risky choice: A comparison of
cumulative prospect theory and SP A theory. Journal of Mathematical Psychology
43:286-313.
Luce MF, Payne JW, Bettman JR (2000) Coping with unfavorable attribute values in
choice. Organizational Behavior and Human Decision Processes 81:274-299.
Luce RD (2010) Behavioral assumptions for a class of utility theories: A program of
experiments. Journal of Risk and Uncertainty 41:19-37.
207

<-----Page 222----->MacLeod CM (1992) The Stroop task: The "gold standard" of attentional measures.
Journal of Experimental Psychology: General 121:12-14.
Marewski JN (2010) On the Theoretical Precision and Strategy Selection Problem of a
Single-Strategy Approach: A Comment on Glockner, Betsch, and Schindler
(2010). Journal of Behavioral Decision Making 23:463-467.
Margulies DS, Kelly AMC, Uddin LQ, Biswal BB, Castellanos FX, Milham MP (2007)
Mapping the functional connectivity of anterior cingulate cortex. NeuroImage
37:579-588.
McKenna BS, Dicjinson DL, Orff HJ, Drummond SP (2007) The effects of one night of
sleep deprivation on known-risk and ambiguous-risk decisions. J Sleep Res
16:245-252.
Menon V, Adleman NE, White CD, Glover GH, Reiss AL (2001) Error-related brain
activation during a Go/NoGo response inhibition task. Human Brain Mapping
12:131-143.
Meriau K, Wartenburger I, Kazzer P, Prehn K, Lammers CH, van der Meer E, Villringer
A, Heekeren HR (2006) A neural network reflecting individual differences in
cognitive processing of emotions during perceptual decision making. Neuroimage
33:1016-1027.
Miller EK (2000) The prefrontal cortex and cognitive control. Nature Reviews
Neuroscience 1:59-65.
Miller EK, Cohen JD (2001) An integrative theory of prefrontal cortex function. Annual
Review of Neuroscience 24:167-202.
Montague PR, Berns GS (2002) Neural economics and the biological substrates of
valuation. Neuron 36:265-284.
Montgomery H, Svenson O (1983) A Think Aloud Study of Dominance Structuring in
Decision-Processes. Lecture Notes in Economics and Mathematical Systems
213:366-383.
Mu Q, Mishory A, Johnson KA, Nahas Z, Kozel FA, Yamanaka K, Bohning DE, George
MS (2005) Decreased brain activation during a working memory task at rested
baseline is associated with vulnerability to sleep deprivation. Sleep 28:433-446.
Newell BR (2005) Re-visions of rationality? Trends in Cognitive Sciences 9:11-15.

208

<-----Page 223----->Newell BR, Rakow T, Weston NJ, Shanks DR (2004) Search strategies in decision
making: The success of "Success". Journal of Behavioral Decision Making
17:117-137.
Nygren TE, White RJ (2002) Assessing Individual Differences in Decision Making
Styles: Analytical vs. Intuitive. In: Human Factors and Ergonomics Society 46th
Annual Meeting, pp 953-957. Baltimore, MD.
Ochsner KN, Kosslyn SM, Cosgrove GR, Cassem EH, Price BH, Nierenberg AA, Rauch
SL (2001) Deficits in visual cognition and attention following bilateral anterior
cingulotomy. Neuropsychologia 39:219-230.
Patton JJ, Stanford MS, Barratt ES (1995) Factor structure of the Barratt Impulsiveness
Scale. Journal of Clinical Psychology 51:768-774.
Paulus MP, Hozack N, Frank L, Brown GG (2002) Error rate and outcome predictability
affect neural activation in prefrontal cortex and anterior cingulate during decisionmaking. NeuroImage 15:836-846.
Paulus MP, Rogalsky C, Simmons A, Feinstein JS, Stein MB (2003) Increased activation
in the right insula during risk-taking decision making is related to harm avoidance
and neuroticism. NeuroImage 19:1439-1448.
Paulus MP, Hozack N, Zauscher B, McDowell JE, Frank L, Brown GG, Braff DL (2001)
Prefrontal, parietal, and temporal cortex networks underlie decision-making in the
presence of uncertainty. NeuroImage 13:91-100.
Payne JW (1976) Task Complexity and Contingent Processing in Decision-Making Information Search and Protocol Analysis. Organizational Behavior and Human
Performance 16:366-387.
Payne JW (1982) Contingent Decision Behavior. Psychological Bulletin 92:382-402.
Payne JW (2005) It is whether you win or lose: The importance of the overall
probabilities of winning or losing in risky choice. Journal of Risk and Uncertainty
30:5-19.
Payne JW, Braunstein ML (1978) Risky Choice - Examination of Information
Acquisition Behavior. Memory & Cognition 6:554-561.
Payne JW, Venkatraman V (2011) Opening the Black Box. In: A Handbook of Process
Tracking Methods for Decision Research (Schulte-Mecklenbeck M, Kuhberger A,
Ranyard R, eds). New York, NY: Psycology Press.

209

<-----Page 224----->Payne JW, Braunstein ML, Carroll JS (1978) Exploring Pre-Decisional Behavior Alternative Approach to Decision Research. Organizational Behavior and Human
Performance 22:17-44.
Payne JW, Laughhunn DJ, Crum R (1980) Translation of Gambles and Aspiration Level
Effects in Risky Choice Behavior. Management Science 26:1039-1060.
Payne JW, Bettman JR, Johnson EJ (1988) Adaptive Strategy Selection in DecisionMaking. Journal of Experimental Psychology-Learning Memory and Cognition
14:534-552.
Payne JW, Bettman JR, Johnson EJ (1992a) Behavioral Decision Research - a
Constructive Processing Perspective. Annual Review of Psychology 43:87-131.
Payne JW, Bettman JR, Johnson EJ (1993) The Adaptive Decision Maker. New York:
Cambridge University Press.
Payne JW, Bettman JR, Luce MF (1996) When time is money: Decision behavior under
opportunity-cost time pressure. Organizational Behavior and Human Decision
Processes 66:131-152.
Payne JW, Bettman JR, Coupey E, Johnson EJ (1992b) A Constructive Process View of
Decision-Making - Multiple Strategies in Judgment and Choice. Acta
Psychologica 80:107-141.
Pelli DG (1997) The VideoToolbox software for visual psychophysics: Transforming
numbers into movies. Spatial Vision 10:437-442.
Petrides M (2005) Lateral prefrontal cortex: architectonic and functional organization.
Philosophical Transactions of the Royal Society B 360:781-795.
Petrides M, Pandya DN (1999) Dorsolateral prefrontal cortex: comparative
cytoarchitectonic analysis in the human and the macaque brain and corticocortical
connection patterns. European Journal of Neuroscience 11:1011-1036.
Platt ML, Huettel SA (2008) Risky business: the neuroeconomics of decision making
under uncertainty. Nat Neurosci 11:398-403.
Pochon JB, Riis J, Sanfey AG, Nystrom LE, Cohen JD (2008) Functional imaging of
decision conflict. Journal of Neuroscience 28:3468-3473.
Preuschoff K, Quartz SR, Bossaerts P (2008) Human insula activation reflects risk
prediction errors as well as risk. J Neurosci 28:2745-2752.

210

<-----Page 225----->Rangel A, Camerer C, Montague PR (2008) A framework for studying the neurobiology
of value-based decision making. Nat Rev Neurosci 9:545-556.
Rayner K (1998) Eye movements in reading and information processing: 20 years of
research. Psychological Bulletin 124:372-422.
Reep RL, Corwin JV, King V (1996) Neuronal connections of orbital cortex in rats:
topography of cortical and thalamic afferents. Experimental Brain Research
111:215-232.
Ridderinkhof KR, Ullsperger M, Crone EA, Nieuwenhuis S (2004a) The role of the
medial frontal cortex in cognitive control. Science 306:443-447.
Ridderinkhof KR, van den Wildenberg WP, Segalowitz SJ, Carter CS (2004b)
Neurocognitive mechanisms of cognitive control: the role of prefrontal cortex in
action selection, response inhibition, performance monitoring, and reward-based
learning. Brain Cogn 56:129-140.
Riedl R, Brandstatter E, Roithmayr F (2008) Identifying decision strategies: a processand outcome-based classification method. Behav Res Methods 40:795-807.
Rieskamp J (2008) The importance of learning when making inferences. Judgment and
Decision Making Journal 3:261-277.
Rieskamp J, Otto PE (2006) SSL: A theory of how people learn to select strategies.
Journal of Experimental Psychology-General 135:207-236.
Rogers RD, Ramnani N, Mackay C, Wilson JL, Jezzard P, Carter CS, Smith SM (2004)
Distinct portions of anterior cingulate cortex and medial prefrontal cortex are
activated by reward processing in separable phases of decision-making cognition.
Biological Psychiatry 55:594-602.
Rolls ET, McCabe C, Redoute J (2008) Expected value, reward outcome, and temporal
difference error representations in a probabilistic decision task. Cerebral Cortex
18:652-663.
Rolls ET, Hornak J, Wade D, McGrath J (1994) Emotion-related learning in patients with
social and emotional changes associated with frontal lobe damage. Journal of
Neurology, Neurosurgery & Psychiatry 57:1518-1524.
Rorden C, Karnath HO, Bonilha L (2007) Improving lesion-symptom mapping. J Cogn
Neurosci 19:1081-1088.

211

<-----Page 226----->Rudebeck PH, Bannerman DM, Rushworth MFS (2008) The contribution of distinct
subregions of the ventromedial frontal cortex to emotion, social behavior, and
decision making. Cognitive Affective & Behavioral Neuroscience 8:485-497.
Rushworth MF, Kennerley SW, Walton ME (2005) Cognitive neuroscience: resolving
conflict in and over the medial frontal cortex. Curr Biol 15:R54-56.
Rushworth MFS, Walton ME, Kennerley SW, Bannerman DM (2004) Action sets and
decisions in the medial frontal cortex. Trends in Cognitive Sciences 8:410-417.
Rushworth MFS, Behrens TEJ, Rudebeck PH, Walton ME (2007) Contrasting roles for
cingulate and orbitofrontal cortex in decisions and social behaviour. Trends in
Cognitive Sciences 11:168-176.
Russo JE, Rosen LD (1975) Eye Fixation Analysis of Multialternative Choice. Memory
& Cognition 3:267-276.
Russo JE, Dosher BA (1983) Strategies for Multiattribute Binary Choice. Journal of
Experimental Psychology-Learning Memory and Cognition 9:676-696.
Samuelson PA (1952) Spatial price equilibrium and linear programming. American
Economic Review 42:283-303.
Sanfey AG, Hastie R, Colvin MK, Grafman J (2003a) Phineas gauged: decision-making
and the human prefrontal cortex. Neuropsychologia 41:1218-1229.
Sanfey AG, Rilling JK, Aronson JA, Nystrom LE, Cohen JD (2003b) The neural basis of
economic decision-making in the Ultimatum Game. Science 300:1755-1758.
Schkade DA, Payne JW (1994) How People Respond to Contingent Valuation Questions
- a Verbal Protocol Analysis of Willingness-to-Pay for an EnvironmentalRegulation. Journal of Environmental Economics and Management 26:88-109.
Schneider KA, Richter MC, Kastner S (2004) Retinotopic organization and functional
subdivisions of the human lateral geniculate nucleus: A high-resolution functional
magnetic resonance imaging study. The Journal of Neuroscience 24:8975-8985.
Schultz W, Dayan P, Montague PR (1997) A neural substrate of prediction and reward.
Science 275:1593-1599.
Schwartz B, Ward A, Monterosso J, Lyubomirsky S, White K, Lehman DR (2002)
Maximizing versus satisficing: happiness is a matter of choice. Journal of
Personality and Social Psychology 83:1178-1197.

212

<-----Page 227----->Schwarz N, Bless H, Bohner G (1991) Mood and Persuasion - Affective States Influence
the Processing of Persuasive Communications. Advances in Experimental Social
Psychology 24:161-199.
Scott SG, Bruce RA (1995) Decision making style: the development of a new measure.
Educational and Psychological Measurements 55:818-831.
Seymour B, Daw N, Dayan P, Singer T, Dolan R (2007) Differential encoding of losses
and gains in the human striatum. J Neurosci 27:4826-4831.
Shah AK, Oppenheimer DM (2008) Heuristics made easy: An effort-reduction
framework. Psychological Bulletin 134:207-222.
Sharot T, Shiner T, Brown AC, Fan J, Dolan RJ (2009) Dopamine Enhances Expectation
of Pleasure in Humans. Curr Biol.
Siegle GJ, Konecky RO, Thase ME, Carter CS (2003a) Relationships between amygdala
volume and activity during emotional information processing tasks in depressed
and never-depressed individuals - An fMRI investigation. Amygdala in Brain
Function: Bacic and Clinical Approaches 985:481-484.
Siegle GJ, Steinhauer SR, Carter CS, Ramel W, Thase ME (2003b) Do the seconds turn
into hours? Relationships between sustained pupil dilation in response to
emotional information and self-reported rumination. Cognitive Therapy and
Research 27:365-382.
Silver M, Kastner S (2009) Topographic maps in human frontal and parietal cortex.
Trends in Cognitive Science 13:488-495.
Simon HA (1955) A Behavioral Model of Rational Choice. Quarterly Journal of
Economics 69:99-118.
Simon HA (1957) Models of Man: Social and Rational. New York: Wiley.
Simon HA (1978) Rationality as Process and as Product of Thought. American Economic
Review 68:1-16.
Simon HA (1981) The sciences of the artificial. Cambridge, MA: MIT Press.
Simon HA (1990) Invariants of Human-Behavior. Annual Review of Psychology 41:119.
Simonson I, Tversky A (1992) Choice in context: tradeoff contrast and extremeness
aversion. Journal of Marketing Research 29:281-295.
213

<-----Page 228----->Slovic P (1995) The Construction of Preference. American Psychologist 50:364-371.
Slovic P, Lichtenstein S (1968) The relative importance of probabilities and payoffs in
risk-taking. Journal of Experimental Psychology Monograph Supplement 72:1-18.
Smith SM, Jenkinson M, Woolrich MW, Beckmann CF, Behrens TE, Johansen-Berg H,
Bannister PR, De Luca M, Drobnjak I, Flitney DE, Niazy RK, Saunders J,
Vickers J, Zhang Y, De Stefano N, Brady JM, Matthews PM (2004) Advances in
functional and structural MR image analysis and implementation as FSL.
Neuroimage 23 Suppl 1:S208-219.
Sterpenich V, Albouy G, Darsaud A, Schmidt C, Vandewalle G, Dang Vu TT, Desseilles
M, Phillips C, Degueldre C, Balteau E, Collette F, Luxen A, Maquet P (2009)
Sleep promotes the neural reorganization of remote emotional memory. J
Neurosci 29:5143-5152.
Swick D, Jovanovic J (2002) Anterior cingulate cortex and the Stroop task:
neuropsychological evidence for topographic specificity. Neuropsychologia
40:1240-1253.
Swindale NV (1996) The development of topography in the visual cortex: a review of
models. Network: Computation in Neural Systems 7:161-247.
Thaler RH, Sunstein CR (2008) Easy does it - How to make lazy people do the right
thing. New Republic 238:20-22.
Tizard B (1959) Theories of brain localization from Flourens to Lashley. Medical History
3:132-145.
Tobler PN, O'Doherty JP, Dolan RJ, Schultz W (2007) Reward value coding distinct
from risk attitude-related uncertainty coding in human reward systems. Journal of
Neurophysiology 97:1621-1632.
Tobler PN, Christopoulos GI, O'Doherty JP, Dolan RJ, Schultz W (2008) Neuronal
distortions of reward probability without choice. J Neurosci 28:11703-11711.
Tom SM, Fox CR, Trepel C, Poldrack RA (2007) The neural basis of loss aversion in
decision-making under risk. Science 315:515-518.
Tomasi D, Wang RL, Telang F, Boronikolas V, Jayne MC, Wang GJ, Fowler JS, Volkow
ND (2009) Impairment of attentional networks after 1 night of sleep deprivation.
Cereb Cortex 19:233-240.
Tsujimoto T, Ogawa M, Nishikawa S, Tsukada H, Kakiuchi T, Sasaki K (1997)
Activation of the prefrontal, occipital and parietal cortices during go/no-go
214

<-----Page 229----->discrimination tasks in the monkey as revealed by positron emission tomography.
Neuroscience Letters 224:111-114.
Turkeltaub PE, Eden GF, Jones KM, Zeffiro TA (2002) Meta-analysis of the functional
neuroanatomy of single-word reading: method and validation. Neuroimage
16:765-780.
Tversky A (1972) Elimination by Aspects: A Theory of Choice. Psychological Review
79:281-299.
Tversky A, Kahneman D (1974) Judgment under uncertainty: Heuristics and biases.
Science 185:1124-1131.
Tversky A, Kahneman D (1981) The framing of decisions and the psychology of choice.
Science 211:453-458.
Tversky A, Kahneman D (1986) Rational choice and the framing of decisions. Journal of
Business 59:5251-5278.
Tversky A, Kahneman D (1992) Advances in prospect theory: Cumulative representation
of uncertainty. Journal of Risk and Uncertainty 5:297-323.
Tversky A, Simonson I (1993) Context-dependent preferences. Management Science
29:1179-1189.
Tversky A, Fox CR (1995) Weighing risk and uncertainty. Psychological Review
102:269-283.
Udin S, Fawcett J (1988) Formation of Topographic Maps. Ann Rev Neurosci 11:289327.
Ullsperger M, von Cramon DY (2003) Error monitoring using external feedback: specific
roles of the habenular complex, the reward system, and the cingulate motor area
revealed by functional magnetic resonance imaging. J Neurosci 23:4308-4314.
Van Dongen HP, Baynard MD, Maislin G, Dinges DF (2004) Systematic interindividual
differences in neurobehavioral impairment from sleep loss: evidence of trait-like
differential vulnerability. Sleep 27:423-433.
van Veen V, Krug MK, Schooler JW, Carter CS (2009) Neural activity predicts attitude
change in cognitive dissonance. Nat Neurosci 12:1469-1474.
Venkatraman V, Payne JW, Huettel SA (2011) Neuroeconomics of Risky Decisions:
From Variables to Strategies. In: Decision Making, Affect and Learning (Delgado
MR, Phelps EA, Robbins TW, eds): Oxford University Press.
215

<-----Page 230----->Venkatraman V, Chuah YM, Huettel SA, Chee MW (2007) Sleep deprivation elevates
expectation of gains and attenuates response to losses following risky decisions.
Sleep 30:603-609.
Venkatraman V, Rosati AG, Taren AA, Huettel SA (2009a) Resolving response,
decision, and strategic control: evidence for a functional topography in
dorsomedial prefrontal cortex. J Neurosci 29:13158-13164.
Venkatraman V, Payne JW, Bettman JR, Luce MF, Huettel SA (2009b) Separate neural
mechanisms underlie choices and strategic preferences in risky decision making.
Neuron 62:593-602.
Volkow ND, Tomasi D, Wang G-J, Telang F, Fowler JS, Wang RL, Logan J, Wong C,
Jayne M, Swanson JM (2009) Hyperstimulation of striatal D2 receptors with sleep
deprivation: Implications for cognitive impairment. Neuroimage 45:1232-1240.
Volkow ND, Wang GJ, Telang F, Fowler JS, Logan J, Wong C, Ma J, Pradhan K,
Tomasi D, Thanos PK, Ferre S, Jayne M (2008) Sleep deprivation decreases
binding of [11C]raclopride to dopamine D2/D3 receptors in the human brain. J
Neurosci 28:8454-8461.
von Neumann J, Morgenstern O (1944) Theory of Games and Economic Behavior.
Princeton, NJ: Princeton University Press.
Walton ME, Bannerman DM, Alterescu K, Rushworth MFS (2003) Functional
specialization within medial frontal cortex of the anterior cingulate for evaluating
effort-related decisions. Journal of Neuroscience 23:6475-6479.
Weber EU, Johnson EJ (2009) Mindful judgment and decision making. Annual Review
of Psychology 60:53-85.
Weber EU, Blais AR, Betz E (2002) A Domain-specific risk-attitude scale: Measuring
risk perceptions and risk behaviors. Judgment and Decision Making 15:263-290.
Wesensten NJ, Killgore WD, Balkin TJ (2005) Performance and alertness effects of
caffeine, dextroamphetamine, and modafinil during sleep deprivation. J Sleep Res
14:255-266.
Wood JN, Grafman J (2003) Human prefrontal cortex: Processing and representational
perspectives. Nature Neuroscience 4:139-147.
Wu G, Markle AB (2008) An empirical test of gain-loss separability in prospect theory.
Management Science 54:1322-1335.

216

<-----Page 231----->Wu G, Zhang J, Gonzalez R (2004) Decision Under Risk. In: Handbook of Judgment and
Decision Making (Koehler D, Harvey N, eds): Blackwell Publishing.
Wu G, Zhang J, Gonzalez R (2007) Decision Under Risk. In: Handbook of Judgment and
Decision Making (Koehler D, Harvey N, eds): Blackwell Publishing.
Yacubian J, Glascher J, Schroeder K, Sommer T, Braus DF, Buchel C (2006) Dissociable
systems for gain- and loss-related value predictions and errors of prediction in the
human brain. J Neurosci 26:9530-9537.
Zysset S, Wendt CS, Volz KG, Neumann J, Huber O, von Cramon DY (2006) The neural
implementation of multi-attribute decision making: a parametric fMRI study with
human subjects. Neuroimage 31:1380-1388.

217

<-----Page 232----->Biography
I was born on April 9, 1978 in Chennai, India. After finishing my schooling in
Chennai, I received a scholarship to pursue further studies in Singapore. I completed my
Bachelor of Applied Science (Computer Engineering) degree with First Class Honors at
Nanyang Technological University (NTU), Singapore in 1999. Subsequently, I received a
Master of Engineering degree from NTU in 2001 for my thesis titled “Nonlinear
Response in Functional MRI”. After working as a Research Scientist at the Cognitive
Neuroscience lab in Singapore studying the neural mechanisms underlying number
processing and sleep deprivation, I moved to Duke University in August 2006 to pursue
my PhD in Cognitive Neuroscience.
My primary research interest is in understanding the processes and mechanisms
underlying decision making. I have co-authored two book chapters in the “Handbook of
Process Tracing Methods in Decision Making” and “Decision Making, Affect and
Learning”. I have also published extensively in several leading peer-reviewed journals
including Neuron, Journal of Neuroscience, Journal of Cognitive Neuroscience, Pain,
Neuropsychologia, Human Brain Mapping and Sleep. Findings from my studies have
been featured in leading newspapers and radio stations around the world. I was invited to
be a part of a special press conference on decision making at the annual meeting of
Society of Neuroscience in 2008. I was a discussant for a round table discussion on the
role of neuroscience in marketing at the Association of Consumer Research Meeting in
2008. I am currently an active member of the Society of Neuroscience, Society for
Neuroeconomics and Society for Judgment and Decision Making.
218

