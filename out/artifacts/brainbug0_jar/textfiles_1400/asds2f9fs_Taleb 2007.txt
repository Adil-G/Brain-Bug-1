<-----Page 0----->Black Swans and the Domains of Statistics
Author(s): Nassim Nicholas Taleb
Source: The American Statistician, Vol. 61, No. 3 (Aug., 2007), pp. 198-200
Published by: American Statistical Association
Stable URL: http://www.jstor.org/stable/27643893 .
Accessed: 14/09/2014 12:15
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at .
http://www.jstor.org/page/info/about/policies/terms.jsp

.
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of
content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms
of scholarship. For more information about JSTOR, please contact support@jstor.org.

.

American Statistical Association is collaborating with JSTOR to digitize, preserve and extend access to The
American Statistician.

http://www.jstor.org

This content downloaded from 155.247.166.234 on Sun, 14 Sep 2014 12:15:43 PM
All use subject to JSTOR Terms and Conditions

<-----Page 1----->Black Swans and theDomains
Nassim

Taleb

Nicholas

1. INTRODUCTION
The Black Swan: The Impact of theHighly Improbable (hence
TBS) is only critical of statistics, statisticians,or users of statistics
in a very narrow
written
sion

set of circumstances.

(but consequential)
a veteran
practitioner

by

(a mixture

of quantitative

of uncertainty

whose

derivatives

research,

It was
profes
and

pricing,

riskmanagement) estimates and deals with exposures to higher
order

statistical

ear function

Derivatives

properties.

of random

variables

on

depend

(often

some

square

and

success

of

as

statistics

an

of

engine

As put directly inTBS, it is about how "not to be a sucker."My
aim of thebook is "how to avoid being the turkey."It cannot get
more practical (and less "philosophical" in the academic sense)
than

deemed

are

errors,

theory,

gambling

rors

is small.

lems

Indeed,

statistics

based

applications
on
probability,

In psychological

has
as

such

not

been

in "low
for prob

testing"

"significance
or

expectation
for instance,

experiments,

successful

very

higher

as

counts

the outlier

to replace
should

use

of statistics,

to force

to be

ourselves

probability
conse
lead us tomake

of

suspicious

low probabilities.

inference

about

psychological effects of statistical numbers in
risk
consciousness and the suspension of healthy
lowering
skepticism?in spite of theunreliability of thenumbers produced
low-probability

it

words,

rather

to say "I don't

the courage

it tells

you

know,"

we

where

or "I know

less."

2. CONFIDENCE ABOUT SMALL PROBABILITIES
I will next outline the "inverse problem" of the real world.
Life is not an artificial laboratory inwhich we are supplied with
probabilities. Nor is it an urn (alas) as in elementary statistics
is it a casino

Nor

some

where

3. Finally TBS is critical of theuse of commoditized metrics

(i.e.,

transparency

probabilistic

monitor

authorities

try to eliminate

(/ am

payoffs.

or lower

bound

not assuming,
not exist, only

does

which

is key, that

that we

do not know

Suppose that you are deriving probabilities of future occur
rences from the data, assuming (in the "rosy" case) that thepast
is representative
a

of the future. An

crisis,

banking

a

loss

for an

in an epidemic,

affected

event

insurance

can

be

a market

company,

an act of terrorism,

crash,

a riot, peo

and

so on. The

severity of the event here will be inversely proportional to its
expected frequency: the so-called 10-year flood will be more
frequent than the 100-year flood, and the 100-year flood will be

more

events.

the state

theuncertainty about theprobabilities). Empirical estimation of
probabilities poses a problem in domains with unbounded or

ple

2. The

about

In other

rigorous.

model;

precise

where it is.)

on

and reliance
can

the current methods

where

need

have

an upper

quential mistakes (the "high impact") where, on logical grounds,
we

another

near-unbounded

TBS is critical of some statistics in the following areas:
unrigorous

is not

knowledge

offers a way to live safely in a world we do not quite understand.
It does not get into the trap of offering another precise model

and enforce

its frequency.

in domains

our

where

textbooks.

moments.

a single observation, and does not cause a high impact beyond

1. The

impacts.

quantum

mechanics (these fall under the designation of "mild random
ness"), or (2) some applications inwhich our vulnerability to er
moment"

extreme

scientific

and

thermodynamics,

can have

tail events

and where

fragile,

It presents methods to avoid such events by not venturing into

knowledge in (1) some well-charted domains such as measure
ment

that.

Accordingly, TBS ismeant to provide a roadmap fordealing
with tail events by exposing areas where our knowledge can be

areas

nonlin

or cubes)

thereforeextremely sensitive to estimation errors of the higher
moments of probability distributions. This is the closest to ap
plied statistician one can possibly get. Furthermore, TBS notes
the astonishing

of Statistics

In these

devastating.

problem-style

closed

urn

we

events,
of known

are not
composition

sampling
and

a

from
impacts.

We don't even know if there is a 200-year flood, and what im
such
"standard
deviation,"
ratio," "mean-variance,"
"Sharpe
pact itmay have.We are now subjected to the classical problem
and so on in fat-tailed domains where these terms have little
of induction:making bold claims about the unknown based on
practical meaning, and where reliance by theuntrained has been assumed
properties of theknown. So (1) the smaller the proba
unchecked
and, alas, consequential.
significant,
bility, the largerwe need the sample size to be in order tomake
as

Let me

summarize

the aims

one

of TBS. What

of the review

ers calls "philosophy" (a term thatgenerally alludes to the ster
ile character of some of thepursuits inphilosophy departments),
owing perhaps to the lack of quantitativemeasures inTBS, I tend
to call

That

"risk management."

is, practical

wisdom

and

transla

tionof knowledge into responsible decision making. Again, fora
practitioner "philosophy" is, literally,"wisdom," not empty talk.

inferences, and the smaller theprobability, thehigher the relative
error in estimating thisprobability. (2) Yet in these domains, the
smaller theprobability, themore consequential the impact of the
absolute probability error on themoments of the distribution.

Estimation errors for tailprobabilities are very importantwhen
their large impact is considered. The pair probability times im
pact is a rectangle that gets thinner as probabilities becomes
smaller,

Nassim

Nicholas

London

Business

gamma @fooledby

198

Taleb
School

is a
and

veteran

derivatives

Empirica
randomness, com).

The American

trader and

Laboratory

Statistician, August 2007, Vol. 61,

researcher,

Limited

(E-mail:

No.

3

but

its area

can become

more

stochastic

if the probabil

ities do not drop too quickly as the impact becomes larger.This
is clearly

intractable.

It can be

solved

on paper,

of course,

by

as

suming a priori a certain class of distributions. Indeed the choice

?American

Statisticial Association

This content downloaded from 155.247.166.234 on Sun, 14 Sep 2014 12:15:43 PM
All use subject to JSTOR Terms and Conditions

DOI:

10.1198/000313007X219996

<-----Page 2----->of distributions

characteristic

with
as "mild

brot defined

scale?that
more

randomness,"

is, what Mandel

on

True

fat-tailed

that later?appears

to conveniently push such problems under the rug.

financial

This problem has been seemingly dealt away with the use
of "off-the-shelf"probability distributions. But distributions are
self-referential.Do we have enough data? If the distribution is,
then yes, we may

Gaussian,

be able

to say that

we have sufficientdata?for instance, theGaussian itselftells us
how much data we need. But if the distribution is not from such
a well-bred

family,

then we may

a scale-free

have

or fractal

prop

is a monthly

X

say, where

securities,

is

there

return,

no reason for P[X > 20%]/P[X > 10%] to be differentfrom
P[X > 15%]/P[X > 7.5%]. This self-similarity at all scales

3. SELF-REFERENCE

say, the traditional

distributions

erty that I can simplify as follows: forX large enough, (i.e., "in
> x] depends on n, not on x. In
the tails"), P[X > nx]/P[X

not have

enough

data.

But

how

do we know which distribution we have on our hands? Well,
from thedata itself.

generates

power-law,

or Paretian,

tails;

that is, above

is a known

value

of x beyond

a crossover

= Kx~a.
(Note that the same properties hold
point, P[X > x]
forP[X < x] in the negative domain.)
The standard Poisson and stochastic volatilitymodels are not
scale-invariant.

There

these

which

distributions become thin-tailed?when in reality we do not
know what the upper bound is. Further, the Poisson lends it
self to in-sample

can

you

overfitting:

use

always

a Poisson

jump

tofit, inpast samples, the largest realization of a fractal fat-tailed
process. But itwould fail out of sample. For instance, before the
can state the
of self-reference
of statistical
So we
problem
23% drop in the stockmarket crash of 1987, theworst previous
distributions in the following way. If (1) one needs data to obtain
move was close to 10%. Calibrating a Poisson jump of
a probability distribution to gauge knowledge about the future in-sample
10% would not have prepared the riskmanager for the ensuing
behavior of the distribution from its past results, and if, at the
large
drop. On theother hand, for someone using the framework
same time, (2) one needs a probability distribution to gauge data
ofMandelbrot (1963), the crash of 1987 would not have been
sufficiencyand whether or not it is predictive outside its sample,
moves
would
hundreds
had in
of
we've
then we

are

facing

a severe

regress

do not know

loop. We

what

weight to put on additional data. And unlike many problems of
this one

regress,
about

can

have

severe

consequences

when

we

talk

risk management.

surprising?nor

currencies

large

and

stocks

ture on dozens

an overview
of
presents
across
tests
socioeconomic

(TBS

of empirical

the litera
random

variables).
there are

Unless

reasons

logical

to assume

or

"Mediocristan,"

mild randomness, TBS advocates using a fractal distribution for
the tails as a default, which is the opposite of what I've seen
4. NOT ANY FAT TAILS WOULD DO
practiced. Why? There is a logical asymmetry: a true fat-tailed
Although they do not share some aspects of the style of the distribution can camouflage as thin-tailed in small samples; the
is not true. If I see a "20-sigma"
I can be con
event,
message, the four discussants appear to agree with TBS about opposite
over
are
not Gaussian. If I see no such deviation
vinced that the data
the role of outliers and theirprimacy
the ordinary in deter
statements
that the tails are necessarily
thin?in
mining the statistical properties. The discussants advocate the I cannot make
following: robust statistics, stochastic volatility or G ARCH, or fat-tailed distributions, nothing eventful takes place most of the
Extreme Value Theory. These approaches either do not solve the time.The burden of proof is not on a fat-tailed distribution.
are
Decision
makers
concerned
about
the cost of mis
problem of confidence about small probability, or they create
mostly
new

ones:

many

of these

are

tools,

not

solutions.

Robust

statis

tics are certainlymore natural tools (Goldstein and Taleb 2007),
but I fail to see how robust statisticswill produce more informa
tion about theprobability of events thatare not in the sample of
thepast realizations (see Freedman and Stark 2003). Moreover,
there is a major methodological difference between our stand
points: I do not believe in using any distribution that naively

takes,

rather

erties.We

than

tails as a way

power-law

a

the parameter
decisions.
First,

exact

knowledge

about

the

statistical

prop

are dealing with plenty of invisibles, so I do not use
to estimate

is not easily

precise

computed?rather

probabilities?since
as an aid to make

How?
we

use

power

laws

as

tools;

risk-management

they al

low us to quantify sensitivity to left-and right-tailmeasurement
one from past data).
some extreme
event (or calibrates
errors and rank situations based on thefull effectof the unseen.
produces
From an operational (and riskmanagement) standpoint,not any We can effectivelyget informationabout our vulnerability to the
fat tailswould do.
tails by varying the power-law exponent a and looking at the
The central
the all-too-common
idea of TBS concerns
effecton themoments or the shortfall (expected losses in excess
logical
asso
with evidence
of some threshold). This is a fully structured stress testing, as
confusion
ofabsence
of absence,
of evidence
ciated with the errorof confirmation. It tries to avert this logical
the tail exponent a decreases, all possible states of theworld are
error in the interpretationof statistical information.As it is im encompassed. And skepticism about the tails can lead to action
possible

to make

that lie outside

precise

statements

the sample

set, we

about
need

unseen

to make

events,

those

the richest

pos

and allow ranking situations based on the fragilityof knowledge;

as these

errors

are

less consequential

in some

areas

than others.

I

sible scenarios about them. For this TBS uses, on both logical explain as follows. Ifyour lefttail is "organically" truncated (i.e.,
and empirical grounds, the classification made byMandelbrot
the state of theworld is not possible or cannot affect you), then
events
and
(1963) between two classes of probability distributions: those you may not worry about negative
low-probability
thathave "true fat tails" and others thatdo not. I had difficulty look forward to positive ones. In a business thatbenefits from
understanding why the statistical literaturehas neglected for so the rare event (bounded left-tailexposure, unbounded rightone),
rare events that thepast did not reveal are almost certainly going
long theMandelbrotian classification.
The American Statistician, August 2007, Vol. 61, No.

This content downloaded from 155.247.166.234 on Sun, 14 Sep 2014 12:15:43 PM
All use subject to JSTOR Terms and Conditions

3

199

<-----Page 3----->to be good for you. When

you look at past biotech revenues,

for example,
you do not see the superblockbuster
to the potential
for a cure for a disease,
owing

in them,
there

and

is a small

I discuss

consequential.
to minimize

probability that the sales in that industrymay turnout to be far
larger thanwhat was revealed frompast data. This is illuminated
by thickening the right tail: varying the a to gauge the effectof

my

operational

reasons

to select

scalable

laws, that is, "true fat tails" as default distributions and as tools

these

cases

exposure
of lessened

to such

consequential

tail dependence

errors.

that statistics

It is only in
are safe?

and that iswhere its strengthlies.
Finally Iwould like to thank thediscussants and The American
the unseen.
Statistician for their open-mindedness and for giving me the
On the other hand, consider businesses negatively exposed to opportunity to explain myself. This makes me extremely proud
rare events (bounded right tails). The track record you see is to be an applied statistician.
likely to overestimate theproperties?and any thickening of the
lefttail lowers your expectation. TBS discusses the 1982 blowup
REFERENCES
of banks that lost a century of profits in a single episode: on the
eve of the episode, they appeared to the na?ve observer to be Freedman, D. A., and Stark, P. B. (2003), "What is the Probability of an Earth

more

than

profitable

The second reason I advocate the "true fat tails" method of
Mandelbrot (1963) infinance and economics is, as I said, empiri
cal. As we

saw with

the crash

of 1987,

events

have

remained

con

sistentwith statistics since then?unlike othermethods (Poisson
or stochastic volatility) thatfailed us out of sample. But methods
allowing

for "wild

quake?" inEarthquake Science and Seismic Risk Reduction, NATO Science
Series IV: Earth and Environmental Sciences, vol. 32, eds. F. Mulargia and
R. J.Geller, Dordrecht, The Netherlands: Kluwer.

they seemed.

are

randomness"

not popular

in economics

Goldstein, D. G., and Taleb, N. N. (in press), "We Don't Quite Know What We
are Talking About When We Talk About Volatility," Journal of Portfolio
Management.
Mandelbrot,

and the disciplines that rely on times series analyses because
-(1997),
theydo away with themeasure called "variance," embedded in
the consciousness,

and

so necessary

for many

5. CONCLUSION

applications.

-(2001),

Special

(1963), "The Variation of Certain Speculative
36, 394-419.

Fractals and Scaling inFinance:
Risk, New York: Springer-Verlag.

Prices," Journal

Discontinuity, Concentration,

"Scaling inFinancial Prices," Quantitative Finance,
124-130, 427^140, and 641-649.

Taleb, N. N. (1997), Dynamic Hedging: Managing
New York: Wiley.

To conclude, I am exposing the fragilityof knowledge about
-(2007),
the tails of the distributions in domains where errors can be

200

B.,

of Business,

The Black
York: Random House

Vanilla and Exotic Options,

Swan: The Impact of theHighly

and London:

Penguin.

Section: Reviews of The Black Swan

This content downloaded from 155.247.166.234 on Sun, 14 Sep 2014 12:15:43 PM
All use subject to JSTOR Terms and Conditions

1,113-123,

Improbable, New

