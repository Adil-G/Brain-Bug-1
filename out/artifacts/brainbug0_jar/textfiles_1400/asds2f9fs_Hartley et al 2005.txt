<-----Page 0----->Who Really Wants to be a Millionaire?
Estimates of Risk Aversion from Gameshow Data*
Roger Hartley, University of Manchester, Manchester M13 9PL
Gauthier Lanot, Queen’s University, Belfast, BT7 1NN
and
Ian Walker, University of Warwick, Coventry CV4 7AL
02 February 2005
Keywords: Risk aversion, gameshow
JEL Class: D810, C930, C230
Abstract
There is a considerable variation in estimates of the degree of risk aversion in the
literature. This paper analyses the behaviour of contestants in one of the most popular TV
gameshows ever to estimate a CRRA model of behaviour. This gameshow has a number
of features that makes it well suited for our analysis: the format is extremely
straightforward, it involves no strategic decision-making, we have a large number of
observations, and the prizes are cash and paid immediately, and cover a large range – up
to £1 million. Our data sources have the virtue that we are able to check the
representativeness of the gameshow participants. While the game requires skill, which
complicates our analysis, the structure of the game is very simple so that complex
probability calculations are not required of participants.
The CRRA model is complex despite its restrictiveness because of the sequential
nature of this game – answering a question correctly opens the option to hear the next
question and this has a value that depends on the stage of the game and the player’s view
about the difficulty of subsequent questions.
We use the data to estimate the degree of risk aversion and how it varies across
individuals. We investigate a number of departures from this simple model including
allowing the RRA parameter to vary by gender and age. Even though the model is
extremely restrictive, in particular, it features a single RRA parameter we find that it fits
the data across a wide range of wealth remarkably well and yields very plausible
parameter values.
* We are grateful to Celador PLC, the gameshow’s creators and the UK production company, for their help
with gathering the data, and their permission to use it. We are particularly grateful to Ruth Settle who
provided detailed advice that helped our understanding of the game. The research was supported by grant
R000239740 from the Economic and Social Research Council. We are also indebted to seminar
participants at the Institute for Fiscal Studies, Her Majesty’s Treasury, the Welsh Assembly, CAM
Copenhagen, the Universities of Bristol, Melbourne and Durham, and the Cardiff Business School.
However, the views expressed herein are those of the authors alone.
Corresponding author: Professor Ian Walker, Department of Economics, University of Warwick, Coventry CV4 7AL
Email i.walker@warwick.ac.uk
Fax +44/0 24765 23032
Tel: +44/0 24765 23054

<-----Page 1----->1. Introduction
The idea that utility is concave and increasing in wealth is both a fundamental
presumption in economics and important for a range of applied economic issues. For
example, the extent of concavity, measured, say, by the degree of relative risk
aversion has implications for any decisions that concern uncertainty – most obviously
decisions such as insurance and portfolio choice, but less obviously decisions over
phenomena such as self-employment, R&D, education, crime, smoking, and
substance abuse1.
This paper provides estimates of the degree of risk aversion using gameshow
data, and addresses the main weaknesses of the existing literature. In particular, we
provide estimates obtained from circumstances where the wealth of the same
individuals varies dramatically and where individuals face very simple gains and
losses. Thus, our evidence is well suited to addressing the question of whether
expected utility theory can be applied across a wide range of wealth and whether
constant relative risk aversion can be used to characterise behaviour in these
circumstances.
The existing empirical literature that addresses the degree of risk aversion is
distinguished by the breadth of its estimates and the literature is particularly sparse on
attitudes towards large gambles. This is particularly troubling because an important
deduction has been made by Rabin (2000) and Rabin and Thaler (1999) which could
not be easily refuted with the available evidence. In particular they argue that
expected utility maximising individuals are risk averse over small gambles and that
any reasonable degree of risk aversion over small gambles would imply absurd
choices over large gambles. Thus, they argue that it is not possible to characterise
behaviour over a wide range of gambles using a CRRA Expected Utility function.
Indeed, the authors use the argument to cast doubt on the very idea of expected utility
maximisation.
This paper analyses the information on contestants in one of the most popular
TV gameshows ever to estimate a CRRA model of behaviour. This gameshow has a
number of features that makes it well suited for our analysis: the format is extremely
straightforward and it involves no strategic decision-making, we have a large number
1

Moreover, the cardinalisation of utility is important for public policy relating to optimal redistributive
taxation (see Atkinson (1977)).

1

<-----Page 2----->of observations, and the prizes are in cash paid immediately and cover a large range –
up to £1 million. We use the data to estimate the degree of risk aversion and show
how it varies across individuals. In particular, we investigate the extent to which the
RRA parameter varies by gender and age. We also test the extent to which RRA may
not be constant across wealth. Even though the model is extremely restrictive, in
particularly it features a constant RRA parameter across a wider range of wealth, we
find that it fits the data remarkably well and yields very plausible parameter values.
Our data comes from the world’s most popular TV gameshow of all time, Who
wants to be a millionaire? (hereafter WWTBAM), which is played and broadcast
under license in many countries but originated in the UK. Notwithstanding that
gameshow data has a number of drawbacks for the purpose of estimating attitudes to
risk, this particular game has a number of design features that make it particularly
well-suited to our task. In this gameshow the player is faced with a sequence of 15
multiple-choice questions. At each stage she can guess the answer to the current
question and stands to double her current winnings but at the risk of losing a stagespecific amount, or she can quit and leave the game with her winnings to date. The
mechanism of the game is well known and very simple. Although there is no strategic
element, contestants simply play against the house, it is a game where skill matters,
which complicates our analysis, the structure of the game is very simple so that
complex probability calculations are not required of participants.
At each stage of the game contestants are reminded that their winnings so far
belong to them - to risk, or walk away with. The prizes start at a very modest level
but, in many countries, reach very high levels. This wide spread of possible outcomes
makes WWTBAM a considerable challenge for a simple expected utility CRRA
model.
The data was transcribed from the original videotapes of the population of
contestants. We further established the representativeness of the data by surveying the
population of potential contestants (individuals who were invited to appear on each
show and from which actual contestants were selected) to obtain information about
their characteristics, which we could compare with population surveys such as the
Labour Force Surveys.

2

<-----Page 3----->We focus on CRRA preferences, despite its restrictiveness, because the
sequential nature of the game gives rise to an important complication – in all but the
last stage of the game, answering a question correctly gives an option to hear the next
question and this itself has a value, over an above the value of the addition to wealth
associated with the question,. This option value depends on the stage of the game, the
player’s view about the difficulty of subsequent questions, and the degree of risk
aversion. This option value characteristic would complicate the econometric analysis
considerably and the assumption of CRRA allows us to construct a model that can be
estimated.
The paper is structured as follows. In section 2 we outline the existing
evidence, including other work that relies on gameshow data. Section 3 explains the
operation of the game. In section 4 we provide a simple model of the game2 that
captures its formal structure so we can show the mechanics of the game in a
straightforward way. We go on, in Section 5, to generalise this to embrace all the
practical details of the game. In section 6 we present the econometric details and the
likelihood.. In section 7 we give some summary details of the UK data and explain
how we estimate risk aversion using this data. In section 8 we present some results
and consider possible shortcomings of the work. In section 9 we concludes and draw
together some conclusions, and outline some extensions of the work for the future.
2. Existing evidence
There are several distinct strands to the empirical literature. Firstly, because
the coefficient of risk aversion enters into decisions that do not explicitly involve
uncertainty but require cardinal utility, considerable attention has been given to the
estimation of Euler equations derived from lifecycle models of consumption and
savings (see Hall (1988) and Attanasio and Weber (1989)) where the coefficient on
the interest rate in a log-linearised model is the elasticity of substitution. If utility is
time separable and exhibits constant relative risk aversion (CRRA) then this interest
rate coefficient is also the inverse of the degree of relative risk aversion, ρ. The typical
result in such analyses, usually based on macro data, is that consumption and savings
are relatively insensitive to interest rates so the elasticity of intertemporal substitution

2

The game originates in the UK and the main difference across countries is in the units for the prizes
and in their tax treatment. We hope to exploit the differences in prizes across countries, and across time
within some countries, in future work.

3

<-----Page 4----->is small. Thus, the macro-econometric literature largely suggests that the degree of
risk aversion is large. Some of this literature3 considers two assets and backs out risk
aversion from the excess returns on equities. Since individual portfolios are typically
highly concentrated in relatively safe assets this work implies that the degree of risk
aversion is implausibly large. Indeed, the survey of the “equity premium puzzle” by
Kocherlakota (1996) suggest estimates of the degree of relative risk aversion that
exceed 504.
However, this method, that relies on portfolio allocations, has only ever been
applied to microdata in a handful of studies. Attanasio, Banks and Tanner (2002)
provides a very plausible estimate of the coefficient of relative risk aversion of just
1.44 using a large UK sample survey (for the sub-sample at an interior solution (i.e. of
shareholders)), and appears to be unique in failing to reject the overidentifying
restrictions implied by economic theory.
Jianakopolos and Bernasek (1998) use US survey data on household portfolios
of risky assets to examine gender differences. They find that find that single women
are more relatively risk aversion than single men - a ρ close to 9 compared to 6.
Further differences by age, race, and number of children were also found.
Palsson (1996) uses Swedish 1985 cross-section data on portfolios using tax
registers for more than 7,000 households for. This study also recognizes the existence
of real as well as financial assets and accounts the gains from diversification that
arises when real assets and financial assets are both held. The estimated risk aversion
was found to be even higher than Jianakopolos and Bernasek but, in this case, not
systematically correlated with characteristics apart finding that risk aversion increases
with age.
If utility is intertemporally separable then the extent to which utility varies
with income is related not just to consumption and savings, but also to labour supply.
This idea has been exploited by Chetty (2003) who derives estimates of risk aversion
from evidence on labour supply elasticities. He shows that the coefficient of CRRA,
in the atemporally separable case, depends on the ratio of income and wage
3

Notable contributions to this area are Epstein and Zin (1989, 1991).

4

A number of ideas have been put forward to reconcile the equity premium with estimates of risk
aversion obtained by other methods – most plausibly, that the premium is correlated with labour
income risk.

4

<-----Page 5----->elasticities and that the estimates in the labour supply literature implies a CRRA
coefficient of about 1 and that a positive uncompensated wage elasticity is sufficient
to bound CRRA to be below 1.25.
A second, albeit small, strand of the empirical literature exploits data on the
purchase of insurance cover. Szpiro (1986) is an early example which estimates ρ
from time series data on insurance premia and the amount of domestic insurance
cover purchased, and finds ρ to be close to 2. Cicchetti and Dubin (1994) consider a
large microdataset on insurance for domestic phone wiring. This paper acknowledges
that this insurance is expensive (a monthly premium of $0.45 on average) relative to
the expected loss (just $0.26 on average) and yet they found that 57% of customers
were enrolled in the insurance scheme. They estimate a hyperbolic absolute risk
aversion model and estimate an average small degree of ARA. The implied estimate
of ρ is of the order of 0.6.
A third, more substantial, strand to the literature takes an experimental
approach where participants are offered either real or hypothetical gambles. The best
example that uses hypothetical questions is Barsky et al (1997) where respondents to
the US Health and Retirement Survey were asked if they would accept or reject huge
gambles (a 50% chance of doubling lifetime income together with a 50% change of
reducing it by one-fifth/one-third/one-half). Two further distinctive features of this
work are that it suggests that there is considerable variation in relative risk aversion,
around the mean of about 12, and that relative risk aversion is actually correlated with
risky behaviour in the data such as smoking, insurance and home ownership.
Donkers et al (2001) is a good example that uses data on preferences over
hypothetical lotteries in a large household survey to estimate an index for risk
aversion. Their econometric method is semi-parametric, it allows for generalisations
of expected utility, and they make weak assumptions about the underlying decision
process. They go on to estimate a structural model based on Prospect Theory (see
Kahneman and Tversky (1980)). They strongly reject the restrictions implied by
expected utility theory and they find that both the value function and the probability
weighting function vary significantly with age, income, and the wealth of the
individual.

5

<-----Page 6----->A further example of this strand of the literature is Hartog et al (2000) which
uses questionnaire evidence on reservation prices for hypothetical lotteries to deduce
individual risk aversion. They use three different datasets and find that the mean
CRRA are extremely large (more than 20) in each which might suggest that the
questionnaire method is contaminating true risk aversion with some response bias.
However recent work by Holt and Laury (2002) compares estimates from
hypothetical lotteries with the same lotteries where the prize is really paid. The
authors check whether preferences differ across real and hypothetical lotteries and
find that they are similar only for small gambles. The analysis features prizes that
range up to several hundreds of dollars which they feel allows them to address the
critique raised in Rabin and Thaler (2001) and Rabin (2000). However, there remains
a worry that responses to hypothetical gambles are contaminated and do not reflect
risk attitudes alone.
The present paper belongs firmly to the final strand to the empirical literature that relies on data generated by gameshow contestants. The earliest example, by
Metrick (1993), uses the television gameshow Jeopardy! as a natural experiment to
estimate a non-linear probit of play that depended on the expected value of the gamble
from which he could deduce the degree of risk aversion. Given the rather small stakes
involved, he found that the implied preferences5 were not significantly different from
risk neutrality.
Similarly, Hersch and McDougall (1997) use data from the Illinois Instant
Riches television gameshow, a high stakes game based on the Illinois State Lottery, to
regress the probability of accepting a bet on the bet’s expected value and (a proxy for)
household income. The estimated structural model is used to infer the coefficient of
relative risk aversion, and the data again suggests that contestants are near risk
neutral. Gertner (1993) analyses contestants in Card Sharks who enter a bonus round
which involves a sequence of bets where the stakes are drawn from winnings in an
earlier round that depends on the relative skill of contestants. He uses data on just the
final bet in the bonus round and finds evidence of a high degree of risk aversion

5

They also model the ability of players to choose strategic best-responses. The results suggest that
failure to choose the best-response increases as the complexity of the bet increases. Consistent with
much psychological experimental literature, he also finds that the choices that contestants make are
affected by the “frame” of the problem.

6

<-----Page 7----->(perhaps as high as 15), although he also found evidence of behaviour that contradicts
expected utility theory.
More recently Fullenkamp et al (2003) uses the Hoosier Millionaire television
gameshow to analyze decision-making. Unlike earlier gameshows this involves
relatively high stakes. They use a large sample of simple gambling decisions to
estimate risk-aversion parameters. One difficulty with this game is that prizes are
annuities and so their value to players will depend on time preference. They find,
assuming a discount rate of 10%, that contestants display risk-aversion with the mean
ρ range from 0.64 to 1.76.

Finally, and closest to this study, Beetsma and Schotman (2001) use a Dutch
game called Lingo. Like WWTBAM this is a game of skill. They use data from a
television game show involving elementary lotteries as if it were a natural experiment
so as to measure risk attitudes. Their dataset is large but the monetary stakes are, on
average, relatively small. CRRA and CARA utility specifications are found to
perform approximately equally well and they find robust evidence of a substantial
degree of risk aversion with estimates of ρ in the range from 3 to 7. Extensions of the
basic model, which allow for a separate utility flow purely from playing the game or
for decisions based on decision weights instead of actual probabilities, raise the
estimated degree of risk aversion.
3.

The WWTBAM Gameshow
WWTBAM has proved to be the most popular TV gameshow ever. The game

has been licensed to more than one hundred countries and has been played in more
than 60. In many of these countries the show was originally the most popular show on
TV for some time. The game features a sequence of fifteen “multiple-choice”
questions with associated prizes that, in the UK, start at £100 and (approximately)
doubles each question so that the final question results in overall winnings of £1m.
After being asked each question the contestant has the choice of quitting with her
accumulated winnings or gambling by choosing between the four possible answers
given. If the chosen answer is correct the players doubles her existing winnings and is
asked another question. If the chosen answer is incorrect she gets some “fallback”
level and leaves the game. The difficulty of questions rises across the sequence of

7

<-----Page 8----->questions6 and the fallback level also rises (in two steps). Contestants are endowed
with three “lifelines” which are use-once opportunities to improve their odds – so,
when faced with a difficult question, players may use one or more lifelines to improve
their odds.
Contestants are not selected randomly onto the show. The details of how this
is done varies across countries but in the UK aspiring contestants ring a premium rate
phone number and get asked a medium difficulty question. If correct their names get
entered into a draw to appear in the studio. Ten names are drawn for each show.
Aspiring contestants can improve their odds of appearing by ringing many times so
having many entries in the draw. Once at the recording studio, aspiring contestants
compete with each other to provide the fastest correct answer to a single question and
the winner is selected to enter the main game.
During play the compère is careful to ensure that players are sure they want to
commit themselves at every stage – contestants have to utter the trigger phrase “final
answer” to indicate commitment. At each of the two fallback stages, the compère
hands a cheque to the contestant for that level of winnings and ensures that the
contestant understands that this money is now theirs and cannot be subsequently lost.
4. A simple version of WWTBAM and a bound on risk aversion
It is useful to begin by considering a very simple model where utility exhibits
constant relative risk aversion, there is only one question (think of this, for the
moment, as being the last question in the sequence of questions faced by a contestant)
and no lifelines (imagine they have all been used on earlier questions), and where the
fallback level of winnings is fixed at some value, b. The purpose of this simple model
is to introduce the game, highlight the issues, and use it to provide a crude idea of
what the degree of risk aversion might be, before we attempt to construct, and
estimate formally, a model that captures all of the complexities of the actual game.
This stylised game can be characterised by

6

What “difficulty” means here is, of course, subjective. Many early questions are concerned with
popular culture and sport. The details differ slightly from country to country but for the UK data used
here the production staff divide questions into bins of what they regard as rising difficulty and
contestants face a sequence of questions drawn randomly from successive bins. In early shows there
were fewer than 15 bins because the production team did not have the experience to rank questions
precisely. However, in recent shows there have been 15 such bins, one for each prize level.

8

<-----Page 9----->1
W 1− ρ
1− ρ
1
1− ρ
1− ρ
P 2 W
+ (1 − P ) b1− ρ 
U ( Gamble ) =
1− ρ 
U ( Quit ) =

(1)

where W is the level of winnings in previous questions and P is the subjective
probability of choosing the correct answer. We assume that the questions (i.e. the
question itself as well as all candidate answers) are drawn randomly from a pool, such
that, for any question, individuals are able to assign to each answer some subjective
probability of being the correct answer.

Hence P is a random variable with a

distribution which is known to the individual. The decision problem of the contestant
can be couched as a simple stopping rule: choose to answer the question if the
subjective probability of being correct, P exceeds some critical value p given by

p=

W 1− ρ − b1− ρ
21− ρ W 1− ρ − b1− ρ

(2 )

and otherwise quit and take the accumulated winnings W. The comparative statics of
this simplified model suggests that individuals are more likely to quit the higher is ρ,
and the lower (higher) is b according to ρ>(<)1.
In the UK game, b is zero for the first 5 questions, £1000 for the next 5, and
£32000 for the last five. In practice there are very few instances of quits or failures
below £1000. Two probabilities are of particular interest: the probability of failure
when the last question asked is worth £2,000 and the probability of failure when the
last question asked is £64,000. In both cases these questions should be attempted by
all individuals reaching that stage of the game because there is no downside risk at
those stages of the game. Thus, straightforward estimates of the probability of a
correct answer provide a measure the average difficulty of the questions. We focus
here on the probability of failing at the £64,000 question which, in our data, is about
1/3rd .
To simplify matters further we assume that the £125,000 prize is 128,000
(=27) and we assume that the probability of failing this question can be approximated
by the probability of failing the £64,000 question. In keeping with the simplified
model outlined above a contestant will tackle this question whenever the expected
utility of the gamble is greater than the utility of quitting with £64,000.

9

<-----Page 10----->Two cases arise: ρ > 1 and 0 < ρ < 1 . If ρ > 1 the condition that determines
the decision to answer this question becomes

1 − ρ < 0 this is equivalent to

2 1281− ρ 1 321− ρ
641− ρ
. Since
.
+ .
≥
3 (1 − ρ ) 3 (1 − ρ ) (1 − ρ )

2
1
.1281− ρ + .321− ρ ≤ 641− ρ . Furthermore, since
3
3

128 = 27 , 64 = 26 , and 32 = 25 this implies

(

)

1 2(1− ρ ) +1
2
+ 1 ≤ 2(1− ρ ) . Substituting
3

21− ρ = θ , with θ varying from 1 to 0 as ρ varies from 1 to ∞ , we require
1
1
2θ 2 + 1) ≤ θ . Note that the equation ( 2θ 2 + 1) − θ = 0 has one unique solution,
(
3
3

θ * , in the interval [ 0,1] . To the right of this solution the inequality above is satisfied,
to the left it is not. Obviously, θ * = 1 2 . Hence ρ must be such that 2(1− ρ ) ≥ 1 2 ,

which gives 1 < ρ ≤ 2 . That is, if ρ > 1 it must be the case that contestants cannot be
too risk averse.
In the second case, 0 < ρ < 1 , and from the calculations above we find that ρ
must be such that

(

)

1 2(1− ρ )+1
2
+ 1 ≥ 2(1− ρ ) . Substituting 21− ρ = θ , with θ varying from
3

1
2 to 1 as ρ varies from 0 to 1 we get ( 2θ 2 + 1) ≥ θ , which is satisfied for θ > 1
3

and in turn implies ρ < 1 suggesting even more modest risk aversion.
On the basis of these bounds, and bearing in mind that the simplified model
here ignores the option values of continuing, we conclude that it must be the case that

ρ < 2 for play to continue beyond this level. The fact that many individuals are
observed to play beyond the £64,000 question suggests that risk aversion is, in fact,
quite low.
5. Extensions to the simplified version of WWTBAM
5.1. Dynamics

The model of participation we present now accounts for the potential future
stages of the game, we focus on a simplified version of the game in which players are
risk neutral and hence are expected income maximisers. We also ignore the “lifelines”
of “asking the audience”, “phoning a friend” or “50:50” (which randomly discards 2

10

<-----Page 11----->of the 3 incorrect answers) and assume that questions are selected by independent
random drawing from a pool of questions of identical difficulty.
Let p denote the probability that the player (of some given ability) is able to
answer correctly a question, where p is a realisation of the random variable P whose
cdf is

F

: [ 0, 1 ]

֏

[ 0,1 ]

(we provide, in the next sections, a model for this

distribution). Rounds of the game are denoted by the number of questions remaining,
i.e. n=N,……1. Let an be the accumulated winnings after the player has successfully
completed N-n questions and there are n questions remaining. In the televised game
N=15 and the prizes are given by the sequence

{an }n =1 = {1000,500, 250,125, 64,32,16,8, 4, 2,1, 0.5, 0.3, 0.2, 0.1, 0} .
16

Similarly, let bn be the value of the winnings that are “protected” , i.e. the winnings
that can be kept in the event of an incorrect answer. In the televised game the
sequence of protected prizes is given by,

{bn }n=1 = {32,32,32,32, 32,1,1,1,1,1, 0, 0, 0, 0, 0} .
15

Now consider the decision problem at the start of the game when the player is faced
with the first of 15 questions. The value of playing the game, and therefore answering
the first question, is given by

V15 ( p ) = max {a16 , p ( f14 − b14 ) + b15 }

where

f14 = E V14 ( P )  is the optimal expected value of the next questions and, at this stage

a16

= b15 = 0 . This

is the first stage of a recursion, such that when there are n

questions to go and the question asked can be answered with probability p, the value
of the game is
Vn ( p ) = max {an +1 , p ( f n −1 − bn ) + bn } ,

(3)

where f n −1 = E Vn−1 ( P )  and we set f0=a1. Note that the decision to quit or not to quit

is made after the question has been asked.
At

any

pn = ( an +1 − bn )

round

( f n −1 − bn )

of

the

game,

there

exists

a

critical

value

such that if p ≤ pn the individual abandons the game and

therefore Vn ( p ) = an+1 . Otherwise p > pn and the individual offers an answer to the
question and the value of the game is Vn ( p ) = p ( f n−1 − bn ) + bn . Hence the immediate

11

<-----Page 12----->value of answering correctly is an −1 and the expected difference p ( fn −1

− an −1 )

represents the “option value” of continuing. These dynamic programming equations
lead to the following relationship for the { fn } :

−

fn 1

− n = ( n−1 −
f

f

bn

)

1

∫pn F ( p )dp .

(4)

To obtain the likelihood we need to evaluate the probability of winning. The
probability of continuing to participate through offering an answer to the nth question,
but prior to seeing the questions, is
Pr ["Play"] = 1 − F ( pn ) ≡ F ( pn ) .

(5)

The probability of giving a correct answer, having decided to answer, is given by
1

Pr [" Win " | "Play"] =

∫ pn

p dF ( p )

1 − F ( pn )

≡

G ( pn )
.
F ( pn )

(6)

Hence the probability of answering correctly is simply Pr [" Win"] = G ( pn ) .
The likelihood of a contestant reaching round k and then quitting (i.e. refusing
to give an answer to question k) is

L ( k,0 ) = {1 − F ( pk ) }

∏
15

G ( pn ) .

n =k +1

(7)

The probability of a contestant reaching round k and then giving an incorrect answer
is

L ( k,1 ) = { F ( pk ) − G ( pk ) }

∏
15

G ( pn ) .

n =k +1

(8)

Finally, the probability of a contestant reaching round 1 and then winning (£1m) is :

L ( 1,. ) =

∏G p
15

n =1

( n ).

(9)

The model can be adapted easily to allow for risk averse behaviour, indeed prizes
simply need to be measured in utility terms, i.e. for some concave increasing utility

12

<-----Page 13----->{ }

function u ( x ) , consider {aɶn }i =1 = {u ( an )}i =1 and bɶn
16

16

15
i =1

= {u ( bn )}i =1 instead of {an }i =1
15

16

and {bn }i=1 .
15

5.2. Questions, Answers and Beliefs
The purpose of this section is to propose a model for the distribution of the
beliefs that an individual hold each time a question and several answers (in the real
game, four) are presented to her. In this section and in the next, we take as a given
that the player chooses (if she decided to participate) the answer with the highest
subjective probability of being correct. Hence once the distribution of that probability
is defined it becomes, in principle, straightforward to describe the probability
distribution of the maximum belief and, more generally, of the order statistics.
The question/answer setting process we have in mind can be described as
follows: first a given question and its possible answers in some specific order are
drawn uniformly (at each stage of the game) from a pool of questions and
corresponding candidate answers. The question and its possible answers (possibly in a
different order) are presented to the candidate who is then endowed with a draw from
the belief distribution concerning the likelihood of each answer. The formation of
beliefs for all candidates is assumed to follow this process in an identical and
independent manner. Hence, given a particular question, two identical individuals can
hold distinct beliefs concerning the likelihood of each answer. Furthermore, any given
individual can evaluate the distribution of her possible beliefs over the population of
questions involved at any given stage of the game.
Formally, suppose that X is an n-dimensional random vector with a continuous
distribution on the simplex

∑

n


∆ n = x : xi ≥ 0 ∀i = 1..n, xi = 1 .

i =1


We assume that X has the probability density function ψ n ( x ) , and we require it to
exhibit the following symmetry property :
Let x, xɶ ∈ ∆ n , such that xɶ is obtained from x by any permutation of two
distinct elements, then ψ n ( x ) = ψ n ( xɶ ) .

13

<-----Page 14----->For our purposes we limit our investigation to the cases where n ≤ 4 . Our construction

starts by considering a symmetric probability density function φ on [ 0,1] , i.e. such
that φ ( x1 ) = φ (1 − x1 ) for all x1 in [ 0,1] . Note that φ ’s symmetry implies
1

∫0 φ

1
and
2

( x )(1 − x ) dx =

1

∫0 φ

( x )(1 − x )

2

dx = ∫ φ (1 − x )( x ) dx = µ 2
1

2

0

(10)

where µ 2 is the second moment of φ . Note Φ the distribution function corresponding
to φ . It is then straightforward to show that Φ [1 − z ] = 1 − Φ [ z ] .
Our construction of a class of belief distribution is based on φ . In the three
cases of interest, we propose the following

ψ 2 ( x1 , x2 ) =

1
φ ( x1 ) + φ ( x2 ) 
,
2

ψ 3 ( x1 , x2 , x3 ) =

(11)

∑

 x

1
φ ( xk ) φ  j ,
3 {i , j ,k}∈P3
 1 − xk 

(12)

∑

(13)

ψ 4 ( x1 , x2 , x3 , x4 ) =

xj
 x  

1
φ ( xl ) φ  k  φ 
,
12 µ 2 {i , j , k ,l}∈P4
 1 − xl   1 − xl − xk 

where, for any n, Pn is the set of all permutations of {1,..., n} , and µ 2 = ∫ x 2φ ( x ) dx .
1

0

In each case the role of the summation of the set of permutations arises
because of the unobserved random (uniform) order in which the candidate answers are
presented to the participant. Because φ is itself symmetric some (more or less
obvious) simplifications are possible, we have

ψ 2 ( x1 , x2 ) = φ ( x1 ) ,

ψ 3 ( x1 , x2 , x3 ) =

(14)

 x1  
 x2 
 x3 
2
φ ( x2 ) φ 
  , (15)
 + φ ( x2 ) φ 
 + φ ( x3 ) φ 
3
 1 − x1 
 1 − x2 
 1 − x3  

ψ 4 ( x1 , x2 , x3 , x4 ) =

1
6µ2

∑

l , k =1,...,4
k ≠l

xj

xk  
φ 
,
 1 − xl   1 − xl − xk 


φ ( xl ) φ 

(16)

These simplifications are useful in practice since the number of terms involved is
halved. Note that in each case it can be verified that the integral of ψ n over ∆ n is

14

<-----Page 15----->unity, and that ψ n satisfies the symmetry property required above. In all cases if φ is
the density of the uniform distribution between 0 and 1, then ψ n is the uniform
distribution over ∆ n .
This specification of the beliefs distribution is of course restrictive even
among the distributions satisfying the imposed symmetry property. It leads, however,
to simple specifications for the distribution of the ordered statistics and for the
distributions of the maximum amongst ( x1 ,..., xn ) .
5.3. Distribution of the maximum belief
The dynamic model outlined above involves the distribution, F, of the
individual assessment on her chances of answering the question successfully. In the
case without life lines, F ≡ Fn is the distribution of max ( X ) if X has the probability
X∈∆ n

density function ψ n ( x ) . Indeed max ( X ) measures the individual assessment of her
X∈∆ n

likelihood of answering the question correctly when faced with n alternatives. Hence,
in this section we describe formulae for the distributions

∩

Fn ( z ) ≡ Pr 


n
i =1

{ X i < z} ,

(17)

given that X is distributed with density function ψ n . In particular we can show (see
appendix A for the details) that :
if z ≤ 1 2
0

F2 ( z ) =  2Φ [ z ] − 1 if 1 2 ≤ z ≤ 1,
1
otherwise.


(18)

and as a consequence the density function f 2 ( z ) , z ∈ [ 0,1] , is such that
if z ≤ 1 2
0
f2 ( z ) = 
1

 2φ [ z ] if 2 ≤ z ≤ 1

(19)

The distribution function at higher orders can be obtained from F2 recursively.
Whenever z ∈ ( 0,1) , we have


F3 ( z ) = 2∫ F2 
1

1− z



z
 yφ ( y ) dy ,
y

(20)

15

<-----Page 16----->F4 ( z ) =

1

µ2

1

∫1− z F3 


z 2
 y φ ( y ) dy ,
y

(21)

and the relevant density functions, say f3 and f 4 , can be shown to exist and to be
continuous everywhere inside

( 0,1) .

For example, in the uniform case where

φ ( x ) = 1 for x ∈ [ 0,1] , and 0 elsewhere, we find that
0

3
( 4 z − 1)
F4 ( z ) = 
3
2
−44 z + 60 z − 24 z + 3
3

1 − 4 (1 − z )

if 0 ≤ z ≤

≤z≤

1

3

≤z≤

1

2

≤ z ≤1

if

1
1

4

4

if

1

if

1

3

(22)

2

In this latter case it is easy to verify that the density function is continuous and that
the derivatives match at the boundaries of each segment.
Although the formula above tends to hide it, the distribution functions Fn do
depend on the density φ in an important fashion. We interpret φ as a description of
the individual’s knowledge. When φ is diffuse over [ 0,1] (i.e. uniform) all points on
the simplex ∆ n are equally likely and in some instances the individual will have the
belief that she can answer the question correctly while in some cases the beliefs will
be relatively uninformative, while if φ is concentrated around, or in the limit at, ½ the
individual is always indecisive. Finally, when φ ’s modes are located around 0 and 1,
the individual is always relatively informed about the correct answer.
5.4. Lifelines
Extending the model above to allow for the life lines makes the analysis more
difficult but also enables us to exploit more aspects of the data. We first show how the
model can be modified when only one life line is allowed for, and in a second subsection we show how the model is modified when all three life lines are included. We
then present the precise assumptions that allow the modelling of each life line in
particular.
5.4.a. A simplified game

Let us first consider the game with only one life line (say “50:50”, although
the discussion does not depend on the properties of “50:50”). To clarify the difference

16

<-----Page 17----->figure 1 presents the decision trees at stage n and to stage with or without the life
lines.
Hence, to account for the life line, the state space has to be extended. We will
write Wn ( p; γ ) for the expected value of the game to a contestant faced with a
question with belief vector p, when γ = 0 if the lifeline has been used and γ = 1 if it is
still available. Whether to use a lifeline or not may depend on all components of p so
the value is a function of the whole vector of subjective probabilities. However

p = max i pi is a sufficient statistic for p in the contestant’s decision problem with no
life line left and we will write the value function as Vn ( p; 0 ) .
In what follows we assume that the life line is a draw of a new belief, say q ,
given p the current belief. For example the use of the “50:50” reduces two
components of the belief to 0. For the other lifelines the audience and/or one among
several friends will provide some information which is then combined with the initial
belief p . The new belief is the outcome of this process, and q is then used instead of
p in the decision problem. We therefore assume that the conditional distribution

function of q given p is well defined. Finally we define
kn ( p ) ≡ Eq|p Vn ( q, 0 ) | p  ,

(23)

the value of playing the lifeline at stage n where q = max i qi .
The values, Wn ( p,1) and

Vn ( p, 0 ) , are then related according to the

following dynamic programming equations. When no lifeline is left we have the
familiar equation:

{

}

Vn ( p, 0 ) = max an +1 , p ( f n −1 ( 0 ) − bn ) + bn ,

(24)

where f n ( 0 ) = E Vn ( P;0 )  . With the life line left the contestant will choose the largest
of the three options in the first choice line in Figure 1b, where :

{

}

Wn ( p,1) = max an +1 , kn ( p ) , p ( f n −1 (1) − bn ) + bn ,

f n (1) ≡ E Wn ( P,1)  and f 0 (1) = f 0 ( 0 ) = a1 .

17

(25)

<-----Page 18----->Figure 1a

Without Life Line

Stage n

Quits
Plays
Loses

Wins
Stage n-1

Figure 1b

With Life Line

Stage n, γ

Quits

Plays

Uses LifeLine if γ=1,
p→
→q
γ=0
Stage n, γ

Wins
Stage n-1, γ

Loses

Note that contestants will never strictly prefer to quit with a lifeline left
unused. However, it is still possible that for some p a contestant may be indifferent
between quitting and using the lifeline if she would subsequently choose to quit for
any realisation of q contingent on p. For example, if p = ( 1 4 ,

1

4

,

symmetry the possible realisations of q after using “50:50” are q = ( 1 2 ,

1

4

1

,

2

1

4

) , by

, 0, 0 ) .

A contestant who would reject such a “50:50” gamble would place no value on the
lifeline. Except in these circumstances, the life line will be used if an +1 ≤ kn ( p ) ,
otherwise the contestant will answer and retain the lifeline for future use.
5.4.b. The complete game

We now assume that the three life lines are available but each can be played at
most once. As above each life line generates a new belief q which is used in the
18

<-----Page 19----->decision process instead of the individual’s initial belief. Given the initial belief p, the
new belief is drawn from a separate distribution for each life line, say H1 ( q; p ) for
“50:50”, H 2 ( q; p ) for “Ask The Audience” and H 3 ( q; p ) for “Phone A Friend”.
We write γ

= ( γ1 γ2 γ3 )
,

,

for the “lifeline state” vector where γi

lifeline has been played and 1 otherwise. Then,

W

n ( p; γ )

=0

if the i’th

denotes the optimal

expected value of the game at stage n, when the probability vector of the current
question is p and the lifeline state is

Wn

shorthand for

( p; ( 0, 0, 0 ) )

( γ1, γ2 , γ 3 ) .

Vn ( p )

and

As above,

Vn ( p )

is used as a

satisfies the recursive dynamic

programming equations set out in section 5.1 above. Below we write the dynamic
programming equations using the notation:
fn

, γ2 , γ 3 )) = E [Wn ( Pn ; ( γ1, γ2, γ 3 )) ],

( ( γ1

(26)

where the expectation is with respect to Pn , the distribution of the belief vector p at
stage n.
When there are one or more lifeline left, i.e. γ1

+ γ2 + γ3 ≥ 1, the contestant

has three options: (i) quit, (ii) answer the question, (iii) use one of the remaining
lifelines. The recursive equation is

W p; γ = max a − , p f −
n(

)

{ n 1

( n 1(γ )

− bn ) + bn , kn ( p; γ )}

(27)

where kn ( p; γ ) denotes the maximum expected value from using a lifeline when the
belief is p and the lifeline state vector is γ . Here,

;

kn ( p γ )

=

max { E Wn ( Q ; γ

e ∈S ( γ )

where S ( ( γ1, γ2 , γ 3 )) = { e



e



∈ R3

:

e

i

−

∈{

e ) | p },

(28)




0,

γi }

for

i

=

1, 2, 3 and

e

≠ 0 } and Qe

is the distribution of the belief vector when e is the indicator vector of the lifeline
chosen. Note that S ( ( γ1, γ2, γ 3 ) ) has γ1

+ γ2 + γ 3

elements all of which are unit

vectors If the r’th unit vector achieves the maximum in (a), then the contestant does
best to choose the r’th lifeline and the distribution of

Qe

is

H

r

( q; p ) .

This

formulation does not preclude an individual from using more than one lifeline on the
same question, a behaviour we observe in some contestants.

19

<-----Page 20----->5.4.c. “50:50”

This is the simplest life line to model. It provides the candidate with “perfect
information” since two incorrect answers are removed. Ex-ante (i.e. before the life
line is played) the contestant believes that the correct answer is i (=1,…,4) with
probability pi . The “50:50” lifeline removes two of the incorrect answers, retaining
j ≠ i , say, with equal probability (1/3). By Bayes Theorem, the probability that

answers i,j survive this elimination process is pi 3 . The answers i and j can also be
retained if j is correct and i survives elimination. This occurs with probability p j 3 .
Applying Bayes Theorem gives the updated belief vector q{i , j} , where

q{k

i , j}

 pi
 p + p if k = i,
j
 i

p

j
=
if k = j
p
+
 i pj
0 otherwise.




(29)

{ }{

Hence H1 ( q; p ) is a discrete distribution with support q{i , j}

(

i , j}∈{1,2,3,4}

and such that

)

H1 q{ } ; p = ( pi + p j ) 3 , and 0 elsewhere.
i, j

5.4.d. “Ask the Audience”

Modeling the “Ask the Audience” life line requires more than simply applying
Bayes’ rule to the current belief draw. In particular we must allow the candidate to
learn from the information provided by the life line, i.e. here the proportions of the
audience’s votes in favour of each alternative answer. The difficulty here is to
understand why and how should a “perfectly informed” rational individual revise
his/her prior on the basis of someone else’s opinion?
The route we follow here was proposed by French (1980) in the context of
belief updating after the opinion of an expert is made available. French suggests that
the updated belief that some event A is realised after some information inf has been
revealed should be obtained from the initial belief, Pr [ A] , the marginal probability
that a given realisation of the information is revealed, Pr [inf ] , and the individual’s

20

<-----Page 21----->belief about the likelihood that the information will arise if A subsequently occurs,
Pr[inf | A] according to the following rule, related to Bayes theorem:
Pr [ A | inf ] = Pr [inf | A] Pr[ A]/ Pr[inf] .

(30)

In this expression Pr[inf | A] is understood as another component of the individual’s
belief, his/her assessment of the likelihood of the signal given that the relevant event
subsequently occurs.
Introducing A , A’s alternative event, this is rewritten as
Pr [ A | inf ] =

Pr [inf | A] Pr[ A]

Pr [inf | A] Pr[ A] + Pr inf | A  Pr[ A]

.

(31)

In our context we understand the appeal to the audience as an appeal to an expert, and
assume that the events of interests are the four events “answer k is correct”, k=1,2,3,4.
We assume that contestants “learn” some information about the quality of the expert
in particular the distribution of the quantities
Pr q = ( q1 , q2 , q3 , q4 ) | answer k is correct  ≡ θ k ,

(32)

where qk is the proportion of votes allocated to the kth alternative. Following French’s
proposal, the kth component of the updated belief π given the information q is:
π k = θ k pk

∑θ p .
4

j =1

j

(33)

j

Let us assume for now that each contestant knows the joint distribution of the vector
θ = (θ1 ,θ 2 ,θ3 ,θ 4 ) . In fact the above expression implies that, without loss of generality,

we can normalise the θ k to sum to one. Denote I (θ ) the density function of θ given
some initial belief p. Given p, the density of the updated belief H 2 ( π ; p ) can be
calculated as:
H 2 (π ; p ) = I (θ ( π ; p ) )

with θi (π ; p ) = π i pi

−1





∑π p
4

k =1

k

4

∏p
k =1

−1
k

k





∑π p
4

k =1

. The term

change of variable from θ to π .

21

k

−1 

,




k





4

4

∏p
k =1

k

(34)





∑p
4

k =1

πk
k





4

arises because of the

<-----Page 22----->The quantities Pr q = ( q1 , q2 , q3 , q4 ) | answer k is correct  ≡ θ k represent the added
information obtained from using the life line and are estimable from the data provided
we assume a form of conditional independence. In particular we require that the
candidate’s choice to ask the audience does not influence the audience’s answer.
Furthermore, our assumptions concerning the generation of the questions
imply that there is no information contained in the position of the correct answer,
hence we expect the following symmetry restrictions to hold :

(
= Pr q = ( q

= Pr q = ( q


)

Pr q = ( q1 , q2 , q3 , q4 ) | answer 1 is correct  = Pr q = qσ (1) , q1 , qσ ( 2 ) , qσ ( 3) | answer 2 is correct 


where (σ (1) , σ ( 2 ) , σ ( 3 ) ) , (σ ′ (1) , σ ′ ( 2 ) , σ ′ ( 3 ) )



)


( ) q , ) | answer 4 is correct  ,

σ ′ (1)

, qσ ′( 2 ) , q1 , qσ ′( 3) | answer 3 is correct 

σ ′′ (1)

, qσ ′′( 2 ) , qσ ′′ 3

1

and (σ ′′ (1) , σ ′′ ( 2 ) , σ ′′ ( 3 ) )

are some

permutations of ( 2,3, 4 ) .
The symmetry restrictions, the conditional independence assumption, and the
uniform random allocation of the correct answer among four alternative answers
allow us to estimate the likelihood of the information given the position of the correct
answer,

and

therefore

provide

empirical

estimates

for

Pr q = ( q1 , q2 , q3 , q4 ) | answer k is correct  .

In practice we assume that, given answer k is correct, information q has a
Dirichlet density D ( q; γ k ( λ ,ν ) ) , k=1…4, defined over ∆ 4 such that
D ( q; γ k ( λ ,ν ) ) =

Γ ( 3ν + λ )





4

qν
∏
Γ ( λ ) Γ (ν )
3

−1

i

i =1

 λ −ν
,
 qk


where the symmetry assumption is imposed through the parameter vector
γ k ( λ ,ν ) = ν + e k ( λ − ν ) with ek is a vector of zeros with a 1 in position k. This vector

of parameters for the Dirichlet density depends on two free parameters only, λ and

ν . These two parameters can be estimated (independently from the other parameters
of the model) by maximum likelihood from the observation of the information
obtained from the audience (i.e. the histograms) whenever the life line is used, and the
observation of the correct answer. For completeness note that θ k can be defined in
terms of the elements of q as θ k = qk λ −ν

∑q
4

j =1

22

λ −ν
j

. The information density which the

<-----Page 23----->candidate expects is therefore the mixture D ( q; p, λ ,ν ) of the previous densities
D ( q; γ k ( λ ,ν ) ) , k=1…4, conditional on a given answer being correct, we have:

D ( q; p, λ ,ν ) =

∑ p D ( q;γ ( λ ,ν ) ) = ΓΓ((λ3ν) Γ+(νλ))
4

i =1

i

i

3





4

∏qν

−1

i

i =1





∑pq
4

i =1

i i

λ −ν


,


(35)

where the mixing weights are the initial beliefs pi , i = 1...4 .
5.4.e. “Phone a Friend”

To use this lifeline the candidate determines ahead of the game six potential
experts, “friends”, and when she plays the life line she chooses one in this list of six.
Obviously one imagines that the candidate engages in some diversification when
drawing the list (i.e. the range and quality of “expert knowledge” of the friends on the
list is in some way optimised), and at the time of the choice of a particular friend the
candidate is likely to assign the expert optimally. There is however little information
available to us about this process. As a consequence our model for this particular life
line is somewhat crude.
We assume that the entire process can be modelled as an appeal to an expert
who knows the answer with some probability κ , and is ignorant with the probability
1 − κ . We assume that the expert informs the candidate of his confidence. Hence

either the candidate knows the answer and his/her opinion “swamps” the candidate’s
belief, or the expert is ignorant and conveys no information and the candidate’s belief
is left unchanged. The density of the updated belief is therefore:

H 3 (π ; p ) = κ 1π =(1,0,0,0) + (1 − κ ) 1[π =p] .




(36)

6. Econometric specification and estimation
6.1. Specification of the belief distribution

The distribution of the beliefs is one of the main element of the model since it
describes the distribution of the unobservables. Under the assumptions we make
above (see section 5.2) the joint density ψ 4 ( ) can be constructed from some

23

<-----Page 24----->symmetric density φ over the unit interval. We assume that φ ( x ) is the density of a
symmetric Beta random variable, B (α ,α ) 7, i.e.:
φ ( x) =

Γ ( 2α )
Γ (α )

2

xα −1 (1 − x )

α −1

1 x∈[0,1] ,


(37)



with α some positive parameter, and where Γ ( u ) is the gamma function. For any
random variable following a symmetric beta distribution the expectation is ½ and
µ2 =

Γ ( 2α ) Γ (α + 2 )

Γ (α ) Γ ( 2α + 2 )

=

1  α +1 

.
2  2α + 1 

In what follows, it will prove necessary to obtain ordered draws from the joint
distribution of ordered statistics of the belief distribution. Because of the symmetry
assumptions that we impose on ψ 4 ( ) , the joint density function of the order statistics
(i.e. the vector of beliefs ordered in decreasing order) is simply 4!ψ 4 ( pɶ ) , where pɶ is
a vector of values ordered in decreasing order. From the definition of ψ 4 (

) note that

it is a mixture with equal weights of 4!=24 densities of the form:

χ 4 ( x1 , x2 , x3 , x4 ) =

2

µ2




x3
x2  
φ 
 ,
 1 − x1   1 − x1 − x2 

φ ( x1 ) φ 

(38)

and the mixture is taken over all permutations of the argument. Note however that
ψ4 (

) and χ 4 ( ) share the same density for the order statistics. Clearly any 4!

permutations of any given draw will lead to the same order statistics. Hence a given
draw x = ( x1 , x 2 , x3 , x4 ) from the order statistics for χ 4 ( ) occurs with probability:

2

∑



µ2 {i, j ,k ,l}∈P

4

xj

φ ( xi ) φ 

 1 − xi

 
xk
φ 
 1− x − x
i
j
 


,



(39)

and this is exactly equal to 4!ψ 4 ( x ) .
Since it is straightforward to rank four numbers in decreasing order, the last
issue is to draw from a multidimensional random variable with joint density χ 4 ( ) .

7

The density of a random variable following a general Beta distribution is :

β ( z; a , b ) =

Γ (a + b)

Γ ( a ) Γ (b )

(1 − z )b−1 ( z )a−1 1 z∈[0,1] , with a, b > 0





24

<-----Page 25----->The result shown in Appendix 1 shows how this can be done straightforwardly since
χ4 (

) can be factorised as follows

χ4 ( x1, x 2, x 3, x 4 )
=

β ( x1; a, a + 2 )

1
1

− x1

x2
1

;a, a + 1 


 1 − x1
 1 − x1 − x 2

β 

which suggest that a draw from χ 4 (

x3

; a, a 
,

 1 − x1 − x 2


β 

) can be obtained from three independent draws

from distinct Beta distributions with parameters ( a, a

+

2)

, ( a, a

+

1)

and ( a, a )

respectively.
6.2. Probabilities and Simulated Likelihood
In this section we describe the evaluation of some of the probabilities that lead to the
log likelihood. A complete description of the calculations can be obtained online8
6.2.a. Calculating the probabilities when only one life line is available.

When the candidate has used all his/her life lines before stage n, the events of
interest are the occurrences of the candidate quitting or losing, and for the last
question the event that the candidate wins the million prize. The probabilities of these
events can be calculated directly from the analytical expressions given in section 5.1
using the formulation for F we derive in section 5.3.
When one (or more than one) life line is available the calculations are made
more complicated because of the information which is gained when the lifeline is
used and which allows the candidate to update their belief. Hence given the initial
draw of the belief we are required to define whether this particular draw leads to the
use of the (a) life line and then whether the updated belief (if the life line is played),
or the original belief (if the life line is not played) is informative enough to lead the
candidate to attempt an answer. Finally we evaluate the probability that the answer is
correct (under the original or the updated belief).
We will write Ωijk
k , n ( p ) as the probability that given p at stage n event k is
observed (which is defined precisely below) given that the candidate is in the life line
state ijk, where i, (respectively j or k) is one if the first (respectively second or third)
lifeline is yet to be played and zero otherwise. Moreover, Ωijk
k , n is the expected value
8

http://www.qub.ac.uk/schools/SchoolofManagementandEconomics/Staff/LanotGauthier/

25

<-----Page 26----->ijk
ijk


of Ωijk
k , n ( p ) over all possible values of realisations of p, i.e. Ω k , n = E  Ω k , n ( P )  .

Finally

,i ′j ′k ′
Ωijk
( p ) stand for the probability that given p at stage n event k is
k ,n

observed (which is defined precisely below) given that the candidate starts the
question in the life line state ijk and transit to life line state i’j’k’. We consider below
representative events for each life line.
6.2.a.i) “50:50” is the only life line available at stage n.

The candidate uses “50:50”, plays and wins (moves to the next stage or wins the
million prize).
Define first the probability for the candidate to use “50:50”, play and win
given a draw (ordered in decreasing order) p from the belief :
Pr {use "50:50"} ∧ {plays} ∧ {wins} | {stage n} , p  ≡ Ω100
1, n ( p ) =
1k1 ( p,0,0,0 )≥ p
 n

1

( f n−1 (1,0,0 ) −bn ) + bn 

where Ω100,000
(p) =
1, n

1
3

∑p ∑ 1
3

j =1

4

j

(40)

Ω100,000
(p ) ,
1, n

k = j +1

(

)

π
p f
0,0,0 ) − bn + bn ≥ an +1 
 jk ( ) n −1 (

, with π jk =

pj
p j + pk

.

This

last

expression is the probability that given p the candidate answers correctly after using
the life line, i.e. wins. Hence the unconditional probability is such that
Pr {use "50:50"} ∧ {plays} ∧ {wins} | {stage n} ≡ Ω100
1, n =
∫∆ɶ 4

ɶ
Ω100
1, n ( p )ψ 4 ( p ) dp

(41)

∫∆ɶ 4 1k1n ( p ,0,0,0 )≥ p1 ( f n−1 (1,0,0 ) −bn ) + bn  Ω1,n

100,000

( p )ψɶ 4 ( p ) dp,

where p = ( p1 , p2 , p3 , p4 ) , ∆ɶ 4 is the subset of the 4-simplex where p1 ≥ p2 ≥ p3 ≥ p4 ≥ 0 .
In order to determine the probabilities we have used the fact that a candidate
with a life line available will either use it (or perhaps then quit) or play. It is then
straightforward to verify that these five expressions above sum to unity, in particular
the sum of the first three expression sum to the probability that the candidate uses the
life line, i.e. the complement to the sum of the last two probabilities.
100
Each term of the sum that determine Ω100
1 ( p ) (and similarly Ω2 ( p ) and

Ω100
3 ( p ) ) is the product of the probability that a given two of the four options remain

26

<-----Page 27----->after the life line is played, with probability

1
( p j + pk ) , multiplied by the probability
3

that the remaining alternative with the largest updated belief is correct, with
probability π jk ( p ) =

pj

with p j ≥ pk , multiplied by the indicator that, given the

p j + pk

updated belief, the candidate decides to play.
6.2.a.ii)

“Ask the Audience” is the only life line left at stage n.

The candidate uses “Ask the Audience”, plays and loses,
Pr {use "Ask the Audience"} ∧ {plays} ∧ {loses} | {stage n} ≡ Ω010
2, n =
∫∆ɶ 4

(42)

ɶ
Ω010
2, n ( p )ψ 4 ( p ) dp,

where Ω010
2, n ( p ) = 1k

(

)

p ,0,0,0 ) ≥ p1 f n −1 ( 0,1,0 ) − bn + bn 
 n(

Ω010,000
(p ) = ∫
2, n

∆4

2

(1 − π (q; p ))1 π (

(

Ω010,000
(p ) ,
2, n
)

 1 q ;p ) f n −1 ( 0,0,0 ) −bn + bn ≥ an +1 



1

and

D ( q; p, λ ,ν ) dq where π ( q; p ) stands

for the revised belief after information vector q is made available and π1 ( q; p ) is the
largest element in π ( q; p ) .
6.2.a.iii)

“Phone a Friend” is the only life line left at stage n.

The candidate uses “Phone a Friend” and quits,
001
ɶ
Pr {uses "Phone a Friend"} ∧ {quits} | {stage n}  ≡ Ω001
3, n = ∫ Ω 3,n ( p )ψ 4 ( p ) dp,
∆ɶ 4

Ω3,001n ( p ) = 1k 3 ( p ,0,0,0 )≥ p ( f
 n

1

n−1

( 0,0,1) − bn )+ bn 

Ω3,001,000
( p ) and Ω3,001,000
( p ) = (1 − κ ) 1 p ( f
n
n
 1

n −1

where

( 0,0,0 )− bn )+ bn < an+1 

.

6.2.b. General Case: all the life lines are available

When more than one life line is available at stage n the number of elementary
events of interest increases since not only the candidates can decide to play one life
line among many but the candidate can decide to play several life lines to answer any
given question. Hence while there is only five elementary events of interest when only
one given life line is available there are nine such events when two particular life lines
are available and seventeen when the three life lines are available, ignoring the order
in which the candidate uses the life-line and not counting events with zero probability
ex-ante (for example observing an event such as quitting while the three life lines are

27

<-----Page 28----->available)9. In this section we present the relevant expressions needed to obtain the
probabilities of few selected elementary event, all other probabilities can be obtained
in a similar fashion.
The candidate uses the three life lines (in any order), plays and loses.
Pr {uses all life lines} ∧ {plays} ∧ {loses} | {stage n}  ≡ Ω111
2, n =
∫∆ɶ 4

1k1
 n

( p ,0,1,1)≥ max{ p1 ( f n −1 (1,1,1) −bn ) + bn ,kn2 (p ,1,0,1),kn3 (p ,1,1,0 )}

1k 2

{ (

1k 3

{ (

( p ,1,0,1) ≥ max p1 f n −1 (1,1,1)
 n

)

−bn + bn , k n1

(p ,0,1,1)

)

, k n3

Ω111,011
(p )
2, n

}

Ω111,101
(p) +
2, n

}

Ω111,110
(p)
2, n

(p ,1,1,0 ) 

( p ,1,1,0) ≥ max p1 f n −1 (1,1,1) −bn + bn ,k1n (p ,0,1,1),kn2 (p ,1,0,1) 
 n

(43)

ψɶ 4 ( p ) dp.

where Ω111,011
(p) =
2, n

1
3

∑ ∑ Ω ( (π
3

4

j =1 k = j +1

011
2, n

j,k

( p ) ,π k , j ( p ) ,0,0 ) ) ,

(44)

,
Ω111,101
(p ) = ∫ Ω101
2, n
2, n (π ( q; p ) ) D ( q; p , λ ,ν ) dq

(45)

110
Ω111,110
( p ) = κΩ110
2, n
2, n (1,0, 0, 0 ) + (1 − κ ) Ω 2, n ( p ) .

(46)

∆4

Inspection of these expressions reveals that the probabilities of events such that more
than one life line is available, here Ω111
2,n , can be defined recursively in terms of the
conditional probability of events with one life line less, given the initial belief draw,
101
110
here Ω 011
2,n ( p ) , Ω 2,n ( p ) and Ω2,n ( p ) . In turn each of these conditional probabilities can

be calculated from conditional probabilities involving only one life line, i.e. Ω 001
2,n ( p ) ,
010
Ω100
2,n ( p ) and Ω 2,n ( p ) . This property is clearly a consequence of the recursive

definition of the value function over the life-line part of the state space (see section
5.4.b).
9

In the case of two life lines left : 1) Uses the two life lines, plays and wins; 2) Uses the two life lines,
plays and loses; 3) Uses the two life lines, plays and loses; 4) Uses one of two life lines, plays and
wins; 5) Uses one of two life lines, plays and loses; 6) Uses other life line, plays and wins; 7) Uses
other life line, plays and loses; 8) Does not use any life line, play and win; 9) Does not use any life line,
play and loses; ….
In the case of three life line left: 1) Uses the three life lines, plays and wins; 2) Uses the three life lines,
plays and loses; 3) Uses the three life lines, plays and loses; 4) Uses “50:50” and “Phone a Friend”,
plays and wins; 5) Uses “50:50” and “Phone a Friend”, plays and loses; 6) Uses another “50:50” and
“Ask the Audience”, plays and win; 7) Uses “50:50” and “Ask the Audience”, plays and loses;… ; 10)
“Uses “50:50”, plays and win; 11) Uses “50:50”, plays and loses; …16) Does not use any life line, play
and win; 17) Does not use any life line, play and loses;

28

<-----Page 29----->Recall, however, that the number of events of interest when the three life lines are
available is larger than when only two or less are available. Hence the definition of 17
probabilities with three life line at stage n, i.e. Ω111
m ,n , m=1…17, will involve the 27
101
110
conditional probabilities with two life lines, i.e. Ω011
m , n ( p ) , Ω m , n ( p ) and Ω m , n ( p ) ,

m=1…9. In turn each of these conditional probabilities will depend on the 15
probabilities with one life line as defined in the previous section, i.e. Ω100
m ,n ( p ) ,
001
Ω010
m ,n ( p ) and Ωm ,n ( p ) m=1…5.

The three life lines are available, the candidate uses “50:50” , plays and wins.
Pr {uses "50:50" only among 3 life lines} ∧ {plays} ∧ {wins} | {stage n} ≡ Ω111
10, n
= ∫ 1k1
∆ɶ 4

( p ,0,1,1) ≥ max{ p1 ( f n −1 (1,1,1)− bn )+ bn , kn2 ( p ,1,0,1), kn3 ( p ,1,1,0 )} 

 n

with Ω111,011
(p) =
10, n

1
3

∑ ∑ Ω ( (π
3

4

j =1 k = j +1

011
8, n

j ,k

Ω111,011
( p )ψɶ 4 ( p ) dp.
10, n

( p ) ,π k , j ( p ) ,0,0 ) ) where

011
Ω8,n
( p ) is the probability

that with “Ask the Audience” and “Phone a Friend” available, for some belief p, the
individual plays and wins.
Three life lines are available, the candidate does not use any, plays and loses.
Pr {does not use any of the 3 life lines} ∧ {plays} ∧ {loses} | {stage n} ≡ Ω111
17, n
= ∫ 1 p
∆ɶ 4

 1

( fn−1 (1,1,1)− bn )+ bn ≥ max {k1n ( p ,0,1,1), kn2 ( p ,1,0,1), kn3 ( p ,1,1,0)}

(1 − p1 )ψɶ 4 ( p ) dp.

6.3. Simulation and smoothing

The

evaluation

of

the

probabilities

3
( r , s, t ) ∈{0,1} and of the conditional expectations

( r , s, t ) ∈{0,1}

3

Ωrst
m ,n ( p ) ,

n=1..15,

m=1..1710,

knj ( p, r , s, t ) , n=1..15, j=1..3, and

requires the use multidimensional integration techniques. Under the

specification of the belief we describe above simulation methods (as described in
Gouriéroux and Monfort (1996) and Train (2003)) that are well suited and have been
applied successfully in similar context (see the examples discussed in Adda and
Cooper, (2003)).
Clearly the specification of the belief lends itself perfectly to a simulation
based likelihood methodology since simulations of Beta variates are obtained simply
10

rst
If Ωrst
m ,n is not defined for some m, and some r,s,t we assume Ωm ,n = 0 .

29

<-----Page 30----->from Gamma variates (see for example Poirier (xxxx)). In turn Gamma variates
themselves can be obtained directly using the inverse of the incomplete Gamma
function. Numerically accurate methods to evaluate the inverse of the incomplete
Gamma function are detailed in Didonato and Morris (1996)11. The main advantage of
their results is that it allows for simulations that are continuous in the parameters of
the Gamma distributions. Evaluation by simulations of an integral involving the
density of a 4 dimensional Dirichlet random vector, D ( q; p, λ ,ν ) , is obtained directly
by the simulation of each of its component. For example
100
ɶ
Ω100
1, n = ∫ Ω1, n ( p )ψ 4 ( p ) dp = ∫ 1 k 1 ( p ,0,0,0) ≥ p ( f
∆ɶ 4

∆ɶ 4

 n

1

n−1

(1,0,0) − bn ) + bn 

Ω100,000
( p )ψɶ 4 ( p ) dp,
1,n

(47)

can be approximated by

1, n ( S ) =
Ω
100

1
S

∑Ω
S

s =1

100
1, n

( ps ) =

1
S

∑1
S

s =1

(

)

k 1 ( p ,0,0,0) ≥ p

1,s f n −1 (1,0,0 ) − bn + bn 
 n s

Ω100,000
( p s ),
1, n

(48)

where p s is one of S (the number of simulations) independent draws from the
distribution of the order statistics of the belief,

ψɶ 4 (.) . In fact the accuracy of this

simulated probability (and of all others which involve draws from ψɶ 4 (.) ) can be
improved upon through antithetic variance reduction techniques which involve the
permutations of the gamma variates used to generate each individual beta variate12 (as
explained for example in Davidson and McKinnon (2004) or in Train (2003)).
Moreover the quantity
Ω111
10,n = ∫ 1 k 1
∆ɶ 4

 n

( p ,0,1,1)≥ max{ p1 ( f n−1 (1,1,1) −bn ) + bn ,kn2 (p ,1,0,1),kn3 (p ,1,1,0 )}

Ω111,011
( p )ψɶ 4 ( p ) dp.
10,n

(49)

can be evaluated simply by
ˆ 111 ( S ) = 1
Ω
10,n
S

11
12

∑1
S

s =1

k 1
 n

( p s ,0,1,1)≥ max { p1,s ( f n−1 (1,1,1)− bn )+ bn , kn2 ( p s ,1,0,1), kn3 ( p s ,1,1,0 )}

Ω111,011
( ps ) ,
10,n

(50)

This is implemented in Gauss in the procedure gammaii (contained in the file cdfchic.src)
For example to simulate a draw from a Β (α , α + 2 ) , one can draw two independent realisations of a

random variable distributed according to a γ (α ) , say z1 and z2 , and one realisation from a γ ( 2 ) ,
say z3 . Then both z1 ( z1 + z 2 + z3 ) and z 2 ( z1 + z 2 + z3 ) are draws from a Β (α , α + 2 ) ,
furthermore they are negatively correlated, so that the variance of their mean is smaller than the
variance of the mean of two uncorrelated draws from a Β (α , α + 2 ) (in fact the relative efficiency
 3α + 2   3 + 3α 
measured by the ratio of the variances is 
 
 < 1 for
 4α + 2   3 + 4α 
2

30

α > 0 ).

<-----Page 31----->or any improvement of it. Similarly Ω111,101
can be
(p ) = ∫∆ Ω101
2, n
2, n (π ( q; p ) ) D ( q; p , λ ,ν ) dq
4

evaluated by Ωˆ 111,101
( p; S ) =
2, n

1
S

∑p ∑ Ω
4

S

i =1

i

s =1




101
2, n

(π ( q

s ,i

)

; p )  , where

is one of S

q s ,i

independent draws from D ( q; γ i ( λ ,ν ) ) .
Finally all quantities kn2 ( p, r , s , t ) ≡ Eπ 2 |p Wn ( Π, r , s, t ) | p  which involve a
ɶ

multi dimensional integral and the joint density D ( q; p, λ ,ν ) can be obtained in a

1
similar fashion, for example using kˆn2 ( p, r , s, t ; S ) =
S

∑ ∑W ( q
4

S

pi

i=1

s =1

n

s,i

, r , s, t ) , where

q s ,i is one of S independent draws from D ( q; γ i ( λ ,ν ) ) .

In practice these expression are modified in order to smooth out the
discontinuities that are created by the indicators terms. Hence the terms 1v ≥ max{v ,v , v } ,
 1

1v ≥ max{v
 1

}

2 , v3 


or

,

are

1[v1 ≥ v2 ] ,

replaced

by

1

smoothed

versions,

2

3

4 

respectively,

1

,

1 + exp (η ( v2 − v1 ) ) + exp (η ( v3 − v1 ) ) + exp (η ( v4 − v1 ) ) 1 + exp (η ( v2 − v1 ) ) + exp (η ( v3 − v1 ) )

, and

1

1 + exp (η ( v2 − v1 ) )

where η is a smoothing constant. In the limit as η → +∞

the smoothed versions tend to the indicators.
6.4. Likelihood.

The contribution to the likelihood for some individual history is the product of
the probabilities of success and of the particular pattern of use for the life lines for that
individual history up to and including the penultimate question, multiplied by the
probability that for his/her last question the candidate wins a million, loses or quits
and the observed use of the life-lines for this last question.
We

assume

U (c) = ( c + γ )

1− ρ

that

the

expected

utility

function

takes

the

form

(1 − ρ ) which features the CRRA assumption and treats initial

wealth, γ , as a parameter to be estimated13.
Hence the contribution to the likelihood of candidate i’s history which ends at
stage ni* , has the general form
13

Later we also consider a generalisation of the CRRA function that encompasses both CRRA and
CARA.

31

<-----Page 32----->{


}

ɵ S ,i  ( LL ( k , i ) , ll ( k , i ) )
L


n*i
k =1


; (α , ρ , γ ,κ ) ; λɵ ,νɵ  = 

ni* −1

( )  ∏ Ω (
 k =1

LL ( k , i )
ll k , i ) , k

  LL( ni* ,i )
 Ωll ( ni* ,i ), ni* ,


(51)

where LL ( k , i ) indicates the number and nature of the life lines available to the
candidate i at stage k, and ll ( k , i ) selects the relevant probability depending on the life
line used by candidate i at stage k. (α , ρ , γ , κ ) is the vector of parameters of interest,
i.e. α is the parameters of the belief distribution, ρ is the coefficient of relative risk
aversion, γ is a scaling factor in the utility function, and κ is the unknown parameter
in the distribution of the updated belief which results from the use of “phone a

( )

friend”. Finally λɵ ,νɵ are the independent estimates of the parameters of the density
of the updated belief which results from the use of “Ask the Audience”.
7. The Data
For each broadcast show the operator, Celador PLC, selected 10 names at
random from a (large) list of entrants who had successfully answered a simple
screening question over a premium rate phone line. These 10 individuals attended the
recording session for their show where they would compete against each other to be
quickest to correctly answer a general knowledge question in a simple first round
game known as the Fastest Finger. The winner of this initial round then competes,
against the house, in the second round sequence of multiple choice questions.
Typically each show would have time for two or three second round contestants.
Contestants still playing at the end of the show would continue at the start of the next
show.
Our data comes from two sources. We have data extracted from videotapes of
the broadcast shows, kindly made available to us by Celador. These tapes cover all
shows in the eleven series from its inception to June 2003. This gives us information
on the behaviour of 515 contestants14 who played the second round sequence of
multiple choice questions.

14

We drop the shows that featured couples (including twins, father/sons, professors/freshers) and
celebrities. One show, where a contestant was the subject of litigation, was not available to us.

32

<-----Page 33----->However, a major concern about the findings of the gameshow literature is
that the data is generated by selected samples15. To investigate this issue a
questionnaire was sent to all of the 2374 potential contestants (except one) who had
ever been invited to the studio for all UK shows in the first eleven series of shows
broadcast. The questionnaire was designed to identify differences between players
and the population as a whole. The questions aimed to provide data that was
comparable to that available from official social surveys of large random samples of
the population16.
Questionnaire replies were received by 791 cases, a response rate of 33% ,
where 243 (32%) of these cases were Fastest Finger winners and so played the
second round game. These 243 represent a response rate of 47% of the population of
second round players. Not surprisingly, these second round players were more likely
to respond to the survey because they were well disposed towards Camelot, having
had the opportunity to win considerable amounts of money. It was immediately
obvious that men were heavily overrepresented in both datasets – something that is
consistent with previous papers which have found that men to be less risk averse than
women. Table 1 shows the means of the data for the second round competitors and for
the non-competitors. The Fastest Finger winner who go on to become WWTBAM
competitors are more likely to be male, are a little younger, and have slightly longer
education than those that failed at this first round.
The one very clear difference between WWTBAM entrants and the population
sample survey data is that they are much more likely to be male. Attempting to enter
the gameshow is risky and this would be consistent with the finding, in some of the
earlier literature, that women are more risk averse. Of course, it would be consistent
with other hypotheses too and no specific inferences can be made from this gender
difference. The table also shows the corresponding information from various social
surveys, re-weighted to match the gender mix in the questionnaire data.

15

In fact, Hersch and McDougall (1977) and Fullenkamp et al (2003) do report some comparisons
between players and the population and finds no significant differences on observable characteristics
except for lottery play. This latter difference is unsurprising since all contestants have had to have
played the lottery and won in order to appear on these shows. In the UK, lottery players do seem to
have different characteristics than non-players (see Farrell and Walker (1999)).
16
To protect confidentiality, we were not able to match the questionnaire data to the gameshow
videotape information so we ensured that the questionnaire also contained information about play
during the game

33

<-----Page 34----->Table 1

Questionnaire Sample and Population Data

Male

Population survey
data*
Mean
Std Dev
0.52
0.40

WWTBAM
competitors
Mean
Std Dev
0.76
0.43

WWTBAM
non-competitors
Mean
Std Dev
0.66
0.48

Age

44.41

10.21

43.14

9.36

47.86

11.67

Married

0.80

0.44

0.79

0.41

0.76

0.43

13.88

4.10

13.71

3.99

12.82

3.22

0.25

0.42

0.22

0.41

0.26

0.44

0.25

0.33

0.144

0.35

0.177

0.38

0.09

0.26

0.07

0.27

0.06

0.31

178.9

157

190.8

127

184.8

188

Employed

0.652

0.44

0.638

0.48

0.593

0.49

Self-employed

0.155

0.38

0.193

0.40

0.189

0.39

Not working

0.194

0.40

0.160

0.37

0.195

0.40

27.08

23.0

31.17

24.0

28.67

22.7

0.67

0.40

0.63

0.41

0.65

0.41

Education years
Smoker

++

Renter
Contents uninsured +
House value (£k) **

++

Gross earnings (£k pa) ***
Regular lottery player
Observations

+++

various

243

548

Notes: * the survey datasets have been re-weighted to reflect the gender mix in the WWTBAM data. Population
data comes from the 2002 Labour Force Survey with the exception of: + from Family Expenditure Survey 2002
data, ++ from British Household Panel Study 2001 wave, and +++ from the Gambling Prevalence Survey 2002. **
if owner occupier. *** if employed.

Once the population datasets are re-weighted the observable differences
between the questionnaire data and the population survey data tend to be quite small.
Two variables are particularly worthy of note: the proportion of individuals who
report that their household’s contents are not insured is similar to the population value
(in fact slightly smaller suggesting more risk aversion ); and the proportion who
report being regular lottery ticket purchasers is also quite similar. Thus, our
questionnaire dataset does not suggest that those that play (in the second round of)
WWTBAM are heavily selected according to observable variables – except gender.
Indeed, for those variables which might be expected to reflect risk attitudes we find
no significant differences with our population surveys.
However, whether the same can be said about the videotape information which
is the population of WWTBAM contestants depends on the questionnaire respondents
being representative of this underlying population. Thus, in Table 2, we compare the
questionnaire data for the sample of 243 contestants with the population of 515 actual
contestants. We have no consistent information on the characteristics of players in the

34

<-----Page 35----->population apart from what we see on screen. Thus, Table 2 records on gender and the
outcomes of play. There are no significant differences in gender and although the
outcomes information shows, as might be expected, that the questionnaire respondents
were bigger winners on average, these differences are not significant. Thus, we can
have some confidence that the representativeness of players (in the questionnaire
data) carries over to the population data in the videotapes.
Table 2

Questionnaire Contestant Sample and Population of Contestants
Questionnaire sample of
contestants
Mean
Std Dev
0.76
0.43

Male

Population of contestants on
videotapes
Mean
Std Dev
0.77
0.43

Winnings £,000

61.96

104.1

54.26

105.9

% quit last Q

0.68

0.47

0.67

0.47

N

243

515

Note: We categorise players who won the maximum £1m as quitters.

The distribution of winnings, for the second round contestants, depends on
whether the player quit or failed to answer the last question asked. Figure 1 illustrates
using the videotape data where a small amount of jitter has been added to the data to
show the nature of the joint distribution of quitting and stage of the game. Almost all
players who survived beyond £125,000 quit rather than failed – only one player failed
at £500,000 and so went away with just £32,000 instead of quitting and going away
with £250,000.

Those that failed to answer correctly the last question that they were

asked went away with their corresponding value of b, the reserve level of winnings.
Only three contestants failed at a sub £1000 question and went away with nothing.
Three players won the £1m prize. Two-thirds of players quit and one-third failed.
“Failures” left the studio with an average of £17,438 (£15,000 for women and
£18,244 for men) while “quitters” went away with an average of £72,247 (£68,182 for
women and £73,411 for men)17.
Finally, the use of lifelines is an important part of observed behaviour that our
model attempts to explain. There was a systematic tendency for lifelines to be played
in order. ATA was played, on average, with 8.5 questions remaining; 50:50 was
played with, on average, 7.0 questions left; and PAF was uses with just 6.9 questions
remaining, on average.
17

Here we categorise those that won the maximum £1m as quitters.

35

<-----Page 36----->Distribution of winnings (% £ ,000)

0

200

last question SEEN
400
600

800

1000

Figure 1

0

Figure 2

200

400
600
amound actually won

Observed Fails and Quits Frequencies and Rates

36

800

1000

<-----Page 37----->8. Estimation and Results
To estimate the parameters of the model, we first estimate our model for the
histograms that are produced by the life line “Ask the Audience” using the data we
have collected on this histogram and on our knowledge of what the correct answer
was. The parameters estimates are presented in Table 3. Assume that the first
candidate answer is the correct one, these estimates imply that on average we expect
the life line “Ask the Audience” to produce the histogram (0.63, 0.12, 0.12, 0.12).
These parameters allow us to evaluate the quality of the lifeline in the manner
described in section 5.4.d above.
Table 3

Maximum Likelihood Estimates of the Parameters of the Distribution
of Histograms (ATA)
Parameter

Estimate

Std. err.

λ

4.754

0.210

ν

0.914

0.030

Number of observations

501

Log-Likelihood

1526.41

Treating these parameters as constants we then proceed to estimate the
remaining parameters of the model. Table 4 presents the preference parameters as
well as the estimate of the probability that the chosen friend, in the PAF lifeline,
knows the correct answer is κ ≃ 0.41 .
Our preferred estimated value for the coefficient of relative risk aversion is
remarkably close to 1 (although statistically significantly different from 1). The
parameter γ , which can be interpreted as initial wealth measured in thousands of
pounds, is significantly estimated at 0.41 (i.e. an initial “wealth” of £410).
Two additional parameters which allow for the distribution of the initial belief
to change with each round of the game are estimated. To illustrate how the

distribution of the beliefs changes as the game progresses we have calculated, in
Figure 3, the distribution of the maximum belief when one (respectively 3, 5, 8, 10)
question(s) remain to be played. We can contrast this distribution at the beginning of
the game, where the maximum belief is relatively concentrated around 1, to the later

37

<-----Page 38----->rounds of the game, where the maximum belief is in fact concentrated away from 1.
To see this compare the slopes of the distribution functions to the left of 1 - in the
former case the slope is large while in the latter case the slope is close to zero.
Table 4

Maximum Likelihood Estimates

Parameters

Estimates

Std. err.

ρ

1.018

0.001

γ

0.410

0.077

-0.325

0.112

515

-

-4543.8141

-



− ln 

1

κ



− 1


Number of observations
Log-Likelihood

Note: Two further parameters are estimated. These parameters specify the dependence of
the belief distribution on the question round.

Figure 4 describes the value of playing the game as a function of the number
of questions remaining (on the x-axis) and the number and the nature of the lifelines
left. As we would expect the value of playing rises as the number of remaining
questions falls and lifelines add positive value to playing. “Ask the Audience” appears
to be the most valuable lifeline while “5050” and “Phone a Friend” have almost
identical values. In fact, the model predicts that “Ask the Audience” is almost as
valuable as “5050” and “Phone a Friend” together.
In Figure 5 we use the estimates to compute the predicted probabilities of
quitting and failing at each question and compare these with the observed
distributions. There are many fails and no quits when there are four more questions to
come – i.e. when confronted with the £64,000 question – since there is no risk at this
point. We broadly capture the peak in quits immediately before this point but
underestimate the number immediately afterwards.
Finally, in Table 5, we compute the certainty equivalent of the gambles taken
at each stage of the game for three different types of individual. The top third of the
table corresponds to a very able player, the middle third is about a typical individual,
while the bottom third is for a low ability player. The certainty equivalents measure in
money terms the value of being able to play the game and take into account the value

38

<-----Page 39----->of being able to play further if the player is successful at the current stage. Moreover
we present similar calculations for the value of playing the lifeline (again given a
particular draw). Clearly the belief has a substantial effect on the certainty
equivalents. Indeed our model predicts that if faced with either of the second or third
belief draw, candidates would be prepared to pay sizeable amounts (amounts larger
than £300,000 in the case of the million pounds question) to avoid having to answer
the question. Lifelines are clearly valuable when the belief draw is not an extreme
one.
Figure 3

39

<-----Page 40----->Figure 4

Value of playing the game at stage n, given the life line state.

Figure 5

Observed versus Predicted Frequencies of Fails and Quits

40

<-----Page 41----->Table 5

Certainty Equivalents (£ ,000)

5050
CE CE of LLb
a

p=(0.9,0.05,0.03,0.02)
500
32
701.85
250
32
409.16
125
32
232.61
64
32
139.39
32
32
89.86
16
1
47.12
8
1
26.08
4
1
14.04
2
1
8.95
1
1
6.46
0
0
4.35
p= (0.6,0.2,0.15,0.05)
500
32
174.40
250
32
130.14
125
32
95.63
64
32
72.21
32
32
56.70
16
1
9.29
8
1
6.66
4
1
4.68
2
1
3.60
1
1
2.97
0
0
1.19
p= (0.4,0.3,0.2,0.1)
500
32
123.81
250
32
98.08
125
32
76.73
64
32
61.33
32
32
50.56
16
1
6.16
8
1
4.70
4
1
3.52
2
1
2.84
1
1
2.43
0
0
0.81
a
−1
: u ( p ( f n −1 − bn ) + bn )

CE

a

PAF
CE of LLb

ATA
CE CE of LLb
a

848.12
435.58
225.51
121.47
73.34
46.08
19.72
11.05
7.22
5.38
4.04

701.85
604.16
335.19
187.43
114.35
54.37
35.06
19.70
12.70
8.78
5.62

912.84
484.06
241.31
120.31
74.13
53.63
22.49
12.15
7.69
5.64
4.29

701.85
522.76
282.85
157.20
91.43
46.91
26.44
13.88
9.30
6.78
4.47

845.07
438.82
229.18
123.14
73.95
47.35
20.22
11.30
7.35
5.46
4.15

544.80
282.30
152.25
92.07
61.84
22.75
11.19
7.01
4.97
3.91
2.31

174.40
160.81
116.75
84.96
64.76
10.06
7.87
5.68
4.41
3.56
1.41

789.05
438.58
222.49
114.14
72.74
46.06
18.06
10.83
7.44
5.31
4.05

174.40
148.67
106.42
77.14
57.24
9.27
6.71
4.65
3.68
3.06
1.21

719.35
360.24
180.99
93.78
62.56
31.15
14.05
7.33
5.10
4.00
2.41

499.10
254.91
133.95
81.53
57.46
18.08
9.22
5.73
4.22
3.40
1.80

123.81
116.07
89.95
69.82
56.22
6.57
5.38
4.12
3.35
2.81
0.94

780.24
396.12
217.27
110.96
72.13
46.92
18.65
10.81
7.31
5.29
3.85

123.81
109.05
83.55
64.65
50.94
6.14
4.73
3.50
2.89
2.49
0.82

719.35
360.24
181.05
93.03
59.99
31.15
14.05
7.37
4.64
3.70
2.09

: u −1 ( k n ( p,.,.,.) )

b

41

<-----Page 42----->9.

Conclusions and Extensions

This paper provides new evidence about the degree of individual risk aversion.
The analysis is firmly embedded in the expected utility paradigm. Surprisingly, we
find the model is broadly effective in explaining behaviour in this simple, and
popular, gameshow - Who Wants to be a Millionaire? A feature of our analysis is that
it is based on data that appears to be representative of the UK population, both in
terms of observable characteristics and in terms of other aspects of risk-taking
behaviour. Our headline result is that expected utility is approximately logarithmic the CRRA is 1, with a high degree of precision.
We also use our data to estimate the value of additional information to players
in this game of skill. Our headline result is consistent with the results of recent work
on the Hooster Millionaire gameshow which is the only other game which features,
like WWTBAM, such large stakes and involves no complex probability calculations
by players.
In part, the paper addresses the challenge to expected utility made by Rabin
(2000) who suggests that, since individuals are risk averse when faced with small
gambles the implied behaviour with respect to large gambles would be perverse. We
indeed find that, in this model with constant CRRA across the huge range of stakes in
the game, we do underpredict the extent to which individuals take risk when the
stakes are low.
A deficiency of the current work is that we assume that risk aversion does not
vary across individuals. We view this as an approximation and we plan to conduct
further work that relaxes this by exploiting our questionnaire data which is rich in
information about the individuals who played this game, and has been used in this
paper only to confirm the representativeness of the videotape data. In particular, we
wish to explore the extent to which risk aversion varies with observable
characteristics and whether unobserved heterogeneity in risk aversion is correlated
with observable risk-taking behaviour.

42

<-----Page 43----->References

Adda, J. and R. Cooper (2003), Dynamic Economics, MIT Press: Cambridge, Mass.
Atkinson, A.B. (1977), “Optimal Taxation and the Direct versus Indirect Tax
Controversy, Canadian Journal of Economics, 10, 590-606.
Attanasio, O., J. Banks and S. Tanner (2002), “Asset Holding and Consumption
Volatility”, Journal of Political Economy, 110(4), 771-92
Attanasio, O. and G. Weber (1989), “Intertemporal Substitution, Risk Aversion and
the Euler Equation for Consumption”, Economic Journal, 99 (Supplement
to 395), 59-73.
Barsky, R.B. et al (1997), “Preference Parameters and Behavioural Heterogeneity: An
Experimental Approach in the Health and Retirement Study”, Quarterly
Journal of Economics, 112(2): 537-79
Beetsma, R.M. and P.C. Schotman (2001), “Measuring Risk Attitudes in a Natural
Experiment: Data from the Television Game Show Lingo”, Economic
Journal, 111(474), 821-48
Camerer, C. F. (1989), “An Experimental Test of Several Generalized Utility
Theories”, Journal of Risk and Uncertainty, 2(1), 61-104.
Chetty, R. (2003), “A New Method of Estimating Risk Aversion”, NBER Working
Paper 9988.
Ciccheti, C.J. and J.A. Dubin (1994), “Microeconometric Analysis of Risk Aversion
and the Decision to Self-Insure”, Journal of Political Economy, 102(1), 16986
Didonato, A. and A.H. Morris (1986), “Computation of the Incomplete Gamma
Function Ratios and their Inverse”, ACM Transactions on Mathematical
Software, 12, 377-393.
Donkers, B., B. Melenberg and A. van Soest (2001), “Estimating risk attitudes using
lotteries - a large sample approach”, Journal of Risk and Uncertainty, 22(2),
165-95
Epstein, L.G. and S.E. Zin (1989), “Substitution, Risk Aversion, and the Temporal
Behavior of Consumption and Asset Returns: A Theoretical Framework”,
Econometrica, 57(4), 937-69
Epstein, L.G. and S.E. Zin (1991), “Substitution, Risk Aversion, and the Temporal
Behavior of Consumption and Asset Returns: An Empirical Analysis”,
Journal of Political Economy, 99(2), 263-86
Farrell, L. and I. Walker (1999), “The Welfare Effects of Lotto: Evidence from the
UK”, Journal of Public Economics, 72, 99-120.
French, S. (1980), “Updating of Belief in the Light of Someone Else’s Opinion”,
Journal of the Royal Statistical Society, 143, 43-48.
Fullenkamp, C., R. Tenorio and R. Battalio (2003), “Assessing Individual Risk
Attitudes using Field Data from Lottery Games”, Review of Economics and
Statistics, 85(1), 218-26

43

<-----Page 44----->Gertner, R. (1993), “Game Shows and Economic Behavior: Risk-Taking on Card
Sharks”, Quarterly Journal of Economics, 108(2), 507-21.
Gouriéroux, C. and A. Monfort (1996), Simulation-Based Econometric Methods,
Oxford University Press: Oxford.
Hall, R.E. (1988), “Intertemporal Substitution in Consumption”, Journal of Political
Economy, 96(2), 339-57.
Hartog, J., A. Ferrer-i-Carbonell and N. Jonker (2000), “On a Simple Measure of
Individual Risk Aversion”, Tinbergen Institute Discussion Paper TI 2000074/3.
Hersch, P.L. and G.S. McDougall (1997), “Decision Making under Uncertainty When
the Stakes Are High: Evidence from a Lottery Game Show”, Southern
Economic Journal, 64(1), 75-84.
Holt, C.A. and S.K. Laury (2002), “Risk Aversion and Incentive Effects”, American
Economic Review, 92(5): 1644-55.
Jianakoplos, N.A.. and A. Bernasek (1998), “Are Women More Risk Averse?”,
Economic Inquiry, 36(4), 620-30
Kahneman, D. and A. Tversky (1979), “Prospect theory: An analysis of decision
under risk”, Econometrica, 47, 263-291.
Kocherlakota, N.R. (1996), “The Equity Premium: It's Still a Puzzle”, Journal of
Economic Literature, 34(1), 42-71.
Metrick, N. (1995), “A Natural Experiment in Jeopardy!”, American Economic
Review, 85(1), 240-53
Palsson, A-M. (1996), “Does the Degree of Relative Risk Aversion Vary with
Household Characteristics?”, Journal of Economic Psychology, 17(6), 77187.
Poirer, D. (1995) Intermediate Statistics and Econometrics: A Comparative
Approach, Cambridge, MA: MIT Press.
1995).Rabin, M. (2000), “Risk Aversion and Expected-Utility Theory: A Calibration
Theorem”, Econometrica, 68(5), 1281-92
Rabin, M. and R.H. Thaler (2001), “Anomalies: Risk Aversion”, Journal of
Economic Perspectives, 15(1), 219-32
Szpiro, G.G. (1986), “Measuring Risk Aversion: An Alternative Approach,” The
Review of Economics and Statistics , 68(1), 156-159.
Train, K.E. (2003) Discrete Choice Methods with Simulation, Cambridge
University Press: Cambridge.

44

<-----Page 45----->Appendix A
Proposition (factorisation of
The joint density:

χ4 ( x1, x 2, x 3 , x 4 ) ):

χ4 ( x1, x 2, x 3, x 4 ) =

∑=
4

with ( x1, x 2 , x 3 , x 4 ) such that

i

1

xi

2

x 2  
x3


φ 

,

 1 − x1   1 − x1 − x 2 

φ ( x1 ) φ 

µ2

= 1 , x ≥ 0 for all i, can be factorised as
i

follows:

χ4 ( x1, x2, x 3, x 4 ) = fU1 ( x1 ) fU 2 |U1 ( x2; x1 ) fU 3 |U1,U2 ( x 3 ; x1, x2 ) ,
with fU1 ( u ) , fU 2 U1 ( v; u ) , fU 3 U1 U2 ( w; u, v ) , (conditional) densities such that
|

fU1 ( u ) =

(1

− u )2 φ ( u ) 1
µ2

fU2 U1 ( v; u ) = 2
|

fU

UU

3 | 1, 2

(

|

(1

[

,

0≤u ≤1 ] ,

µ2

with

− u − v)φ v 1
− u ) (1 − u )

(1

w; u, v ) =

[0

2

1

1−u −v

φ(

= ∫0 ( 1 − x )2 φ ( x )dx ,
1

≤v ≤ −u ,
]

1

w
1
1 − u − v ) ≤w ≤ −u −v
[0

1

]

.

Proof:
It is easy to verify by simple integration for fU1 ( u ) , fU2 U1 ( v; u ) , and by
construction for fU 3 U1 U 2 ( w; u, v ) , all three are well defined densities over the
|

|

,

relevant ranges. Moreover their product is equal to
This implies that if
densities

U1 U 2
,

and

U3

U 1 ( u ) , fU 2 U 1 ( v ; u ) ,

f

|

are three random variables each distributed with
and

U 3 U1 U 2 ( w; u, v ) , then the random vector

f

|

,

P = (U 1 U 1U 2 U 1U 2U 3 U 1U 2U 3 ) , with U = 1 − U
i

with joint density:
that by construction
Since

χ4 ( x1, x2, x 3, x 4 ) =

P e=
'

1

, and

χ4 (. ) .

2

µ2

for all i=1..3, is distributed

x 2  
x3
 
 1 − x1   1 − x1 − x 2

φ ( x1 ) φ 

P ≥ 0.

i

φ



.


Note

χ4 ( x ) and ψ4 ( x ) share the same joint density for the order statistics, i.e.

ɶ ) where x
ɶ is such that its element are sorted in descending order, to sample
4 ! ψ4 ( x
ɶ ) we propose to sample first from
from 4 ! ψ4 ( x
vector in descending order.

45

χ4 ( . ) and then to sort the resulting

