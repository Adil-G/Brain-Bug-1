<-----Page 0----->Journal of Experimental Psychology:
Learning, Memory, and Cognition
2009, Vol. 35, No. 5, 1296 –1305

© 2009 American Psychological Association
0278-7393/09/$12.00 DOI: 10.1037/a0016565

Ignorance- Versus Evidence-Based Decision Making:
A Decision Time Analysis of the Recognition Heuristic
Benjamin E. Hilbig and Rüdiger F. Pohl
University of Mannheim
According to part of the adaptive toolbox notion of decision making known as the recognition heuristic
(RH), the decision process in comparative judgments—and its duration—is determined by whether
recognition discriminates between objects. By contrast, some recently proposed alternative models
predict that choices largely depend on the amount of evidence speaking for each of the objects and that
decision times thus depend on the evidential difference between objects, or the degree of conflict between
options. This article presents 3 experiments that tested predictions derived from the RH against those
from alternative models. All experiments used naturally recognized objects without teaching participants
any information and thus provided optimal conditions for application of the RH. However, results
supported the alternative, evidence-based models and often conflicted with the RH. Recognition was not
the key determinant of decision times, whereas differences between objects with respect to (both positive
and negative) evidence predicted effects well. In sum, alternative models that allow for the integration
of different pieces of information may well provide a better account of comparative judgments.
Keywords: recognition heuristic, fast-and-frugal heuristics, evidence accumulation, parallel constraint
satisfaction, decision time

overview, see Hilbig & Pohl, 2008), we are not aware of any work
that has specifically tested alternative models. This, therefore, was our
central aim in the current article. Also, because fast-and-frugal heuristics and alternative models are often indistinguishable when choices
are studied, we instead consider decision times. We first briefly
introduce two alternative views: evidence accumulation and parallel
constraint satisfaction. Next, we derive predictions for decisions times
from the RH and the alternative models and finally present three
experiments that tested these predictions.
Outside the adaptive toolbox metaphor, alternative models have
recently been put forward, for example, evidence accumulation
models that correspond to an “adjustable spanner” metaphor (Lee
& Cummins, 2004; Newell, 2005; Newell, Collins, & Lee, 2007):
The general idea is that evidence for each of the to-be-compared
objects is sequentially sampled and accumulated on a common
counter. This notion stems from work on automatic processing as
formalized in decision field theory (Busemeyer & Townsend,
1993), which centrally assumes that options are repeatedly compared until the resulting preference state reaches a certain threshold (Busemeyer & Johnson, 2004). So, in the case of comparative
judgments, a decision is made as soon as the given evidence
threshold is reached. This evidence threshold can be interpreted as
the desired level of confidence (Hausmann & Läge, 2008) and can
thus be helpful for modeling individual differences. In short, the
decision process is determined by the evidence threshold and the
accessibility and validity of evidence. The more the sampled
evidence favors one object above the other, the faster— or more
consistently—the process will lead to choice of the superior object.
In this respect, evidence accumulation models are similar to
parallel constraint satisfaction approaches (PCS; Glöckner &
Betsch, 2008a, 2008b), which model the decision process by
means of a neural network operating to maximize consistency:

A currently well-recognized notion of human decision making,
the fast-and-frugal heuristics approach, posits that humans possess
a so-called adaptive toolbox, which—metaphorically—stands for a
collection of simple and efficient rules of thumb (Gigerenzer,
2001). A heuristic can be selected from this toolbox for any given
environment, and this capability leads to many correct judgments.
Although closely related to the established notion of adaptive
decision making (Payne, Bettman, & Johnson, 1988, 1993), this
idea emphasizes that simple strategies need not necessarily yield
less accuracy, despite their simplicity. One quintessential strategy
from this toolbox is the recognition heuristic (RH; Goldstein &
Gigerenzer, 2002), which allows humans to make comparative
judgments based on object recognition only. In particular, the RH
assumes that people will choose the recognized of two objects in
paired comparisons regardless of any further knowledge they
possess; thus, it represents a noncompensatory, or one-reason,
decision-making strategy. In essence, the (speed of the) decision
process is determined by whether recognition discriminates between objects.
Although numerous studies have revealed that one-reason decision
making based on recognition is not a paramount strategy (for an

Benjamin E. Hilbig and Rüdiger F. Pohl, Psychology III, University of
Mannheim, Mannheim, Germany.
The research presented herein was supported by a grant from the
University of Mannheim to Rüdiger F. Pohl. Thanks are due to Meike
Kroneisen and Tina Tanz for support in data collection. Also, we are
grateful to Andreas Glöckner for many helpful comments and suggestions.
Correspondence concerning this article should be addressed to
Benjamin E. Hilbig, Psychology III, Schloss Ehrenhof Ost, University
of Mannheim, D-68131 Mannheim, Germany. E-mail: hilbig@
psychologie.uni-mannheim.de
1296

<-----Page 1----->DECISION TIME ANALYSIS OF THE RECOGNITION HEURISTIC

Evidence is amplified or attenuated over time to form a coherent
representation of the decision. So, larger a priori differences in
evidence for the compared objects will lead to coherent representations (and thus choices) more speedily. However, unlike evidence accumulation models, PCS views decision making as a
holistic process comprising parallel integration of multiple pieces
of information. Also, PCS implies bidirectional processing
(Holyoak & Simon, 1999) and thus predicts coherence shifts
(changes in subjective cue validity), which would not be expected
by evidence accumulation models (Glöckner, Betsch, & Schindler,
2008).
For the current investigation, however, such differences between evidence accumulation and PCS models were not vitally
important. Instead, we focused on the fact that both approaches
predict decision times to be largely determined by the accessibility
and validity of information (cues) for each of the objects and, more
importantly, by the a priori difference in evidence between the
objects. The larger this difference, the less conflict arises and the
faster a choice is made—an effect that has also been observed for
preferential choices (Hilbig, 2008b). We will thus subsume these
notions under the label “evidence-based models.” Their common
focus on (differences in) evidence sets them apart from the fastand-frugal heuristics approach, in which further evidence beyond
the currently decisive single cue is completely irrelevant. Note,
however, that evidence-based models do not imply that recognition
information is not influential. By contrast, they would consider
recognition to be one cue among others and its influence to depend
mainly on the (subjective) validity it encompasses.
Recent investigations comparing PCS and the fast-and-frugal,
take-the-best heuristic (TTB) showed that PCS predicted participants’ choices and decision times more accurately (Glöckner &
Betsch, 2008b). This result was further replicated in memorybased judgments (Glöckner & Hodges, 2008), which are a central
niche of fast-and-frugal heuristics, as they usually afford less
information to be retrieved (Bröder & Schiffer, 2003). Likewise,
Lee and Cummins (2004; see also Newell & Lee, 2007) let an
evidence accumulation model compete with TTB and provided
results indicating that decisions and individual differences are
captured better by evidence accumulation than by TTB (but see
Bergert & Nosofsky, 2007).
This article is meant to extend such model comparisons to the
RH (Goldstein & Gigerenzer, 2002). To this end, some methodological issues should receive attention: Most important, in the
previously outlined studies comparing TTB and evidence-based
models, cue learning methods were used to teach participants the
information on which they then based their judgments (i.e., either
by adhering to TTB or by integrating information). However, it has
recently been argued that teaching participants additional information is not adequate for studying the RH, because such information
may cause demand effects (Pachur, Bröder, & Marewski, 2008). In
sum, Pachur et al. (2008; see also Pachur & Hertwig, 2006) argued
that the RH should be investigated in tasks of natural recognition
(i.e., using objects known to participants from their real-world
experiences) without teaching participants further cues. As is obvious, little control over participants’ knowledge beyond recognition exists in such tasks, and it is therefore difficult to determine
from choice data which strategies participants may have used (for
different attempts, see Hilbig, Erdfelder, & Pohl, 2009; Hilbig &
Pohl, 2008; Pachur & Hertwig, 2006). Nevertheless, the RH and

1297

evidence-based models can be compared with respect to decision
times, as they make different predictions for certain paired comparisons of objects.
In principle, objects can be unrecognized (labeled U), merely
recognized (mR), or recognized as comprising some further
knowledge (R⫹; Pohl, 2006).1 For example, a decision maker may
never have heard of the French city Angers (U), may have heard
of Nice but know nothing about the city (mR), and may recognize
Marseille and know that it possesses a large harbor on the Mediterranean Sea (R⫹). So, in paired comparisons, three general cases
can occur: First, it is possible that neither of the objects is recognized (U_U); this represents a guessing case. Second, exactly one
of the two objects may be recognized (U_mR or U_R⫹); this
represents a case in which the RH is applicable (recognition case).
Finally, both objects may be recognized (mR_mR, mR_R⫹, or
R⫹_R⫹). This possibility is denoted the knowledge case by
Goldstein and Gigerenzer (2002), as some further information
beyond recognition is necessary for the judgment. In the following
sections, we derive four sets of hypotheses for these different
cases, in which predictions from the RH are contrasted with those
from evidence-based models.

Recognition Hypotheses (1a vs. 1b)
The first two hypotheses refer to decision time differences
between recognition cases (U_mR or U_R⫹) and knowledge cases
(mR_mR, mR_R⫹, or R⫹_R⫹), as derived from the RH and
evidence-based models, respectively. The RH was proposed to be
a lexicographic strategy (Goldstein & Gigerenzer, 2002) in which
recognition is considered first, because “recognition precedes the
arrival of any other probabilistic cue” (Pachur & Hertwig, 2006, p.
999). Consequently, considering further information beyond this
first cue is tantamount to adding steps in the cognitive process,
which should inflate the decision time (Payne et al., 1988). The
idea is that “search works in a step-by-step way; cues are looked
up one by one, until the stopping rule is satisfied” (Gigerenzer &
Goldstein, 1999, p. 79). In the case of the RH, the stopping rule is
satisfied whenever one object is recognized but the other is not. So,
the general prediction derived from the RH states that the decision
process and, thus, decision times depend on whether recognition
discriminates between objects. If it does, “search terminates as
soon as recognition has been assessed for both objects” (Goldstein
& Gigerenzer, 1999, p. 57). Consequently, decision times in all
recognition cases (U_mR and U_R⫹) should be shorter than those
in all knowledge cases (mR_mR, mR_R⫹, and R⫹_R⫹) in which
recognition is not sufficient for making a decision and further cues
must be taken into account, which inflates decision times (Bröder
& Gaissmaier, 2007). Stated differently, “shorter response times
are needed for recognition-based inferences” (Pachur & Hertwig,
2006, p. 986). This is Hypothesis 1a.
By contrast, evidence-based models would predict not that decision times depend on whether recognition discriminated between
objects but rather that they depend on the accessibility of evidence
and, more important, the a priori difference in evidence between
objects. In effect, cases comprising such a difference should allow
1

Note that Goldstein and Gigerenzer (1999) used the labels not-R, R,
and R⫹.

<-----Page 2----->HILBIG AND POHL

1298

for faster decisions than should cases in which there is more
conflict between the options. Note that, according to the above
distinction, unrecognized (U) objects should comprise practically
no evidence, merely recognized (mR) objects may yield little
evidence beyond recognition (e.g., the fluency of recognition;
Hertwig, Herzog, Schooler, & Reimer, 2008), and R⫹ objects
should incorporate most evidence.
So, in contrast to Hypothesis 1a, it is assumed that recognition
cases will lead to faster decisions than knowledge cases, if and
only if their a priori difference in evidence is large. This will occur
in U_R⫹ cases, which should thus yield shorter decision times
than any of the knowledge cases (mR_mR, mR_R⫹, and
R⫹_R⫹). By contrast, in U_mR cases the a priori difference in
evidence is much less pronounced. So, U_mR cases need not lead
to faster decisions than do knowledge cases. In particular, U_mR
cases should not yield faster decisions than do mR_R⫹ knowledge
cases, because the latter provide a comparable or larger a priori
difference in evidence. Stated differently, the evidential difference
between U and mR can never become very large, whereas the
difference between mR and R⫹ can, depending on how much
valid evidence is available for the R⫹ object. So, in fact, it is
possible that mR_R⫹ cases afford less time than do U_mR cases.
These differential effects are subsumed as Hypothesis 1b.

Further Knowledge Hypotheses (2a vs. 2b)
Next, we contrast predictions of the RH against those of
evidence-based models with respect to differences within recognition cases (i.e., U_mR vs. U_R⫹ cases). According to the RH,
all recognition cases should lead to similar decision times. As
Goldstein and Gigerenzer (1999, 2002) put forward a binary understanding of recognition and as any knowledge beyond recognition is claimed to be ignored, objects merely recognized (mR)
and recognized objects comprising further knowledge (R⫹) are
claimed to be treated identically (Newell & Fernandez, 2006; Pohl,
2006). Thus, U_mR and U_R⫹ cases should afford similar decision times (Hypothesis 2a) because the number of cognitive steps
necessary is the same in the two cases.
Evidence-based models, on the other hand, predict that recognition cases comprising large differences in a priori evidence
(U_R⫹) should yield faster decisions than do other recognition
cases (U_mR). We denote this prediction Hypothesis 2b. In U_R⫹
cases only, additional evidence is available for the recognized
object but there is no evidence for the unrecognized one. The
evidence threshold (evidence accumulation) or a coherent mental
representation (PCS) should thus be reached speedily. In U_mR,
however, there is very little further evidence for the recognized
object, so there will be more conflict between the options. In
effect, U_mR cases should afford more time than do U_R⫹ cases.

Accuracy Hypotheses (3a vs. 3b)
Further, the RH and evidence-based models make contrary
predictions concerning differences between cases in which the
recognition cue leads to a correct (C) or a false (F) judgment.
According to the RH, whether further knowledge (in a U_R⫹
case) contradicts or confirms the prediction of the recognition cue
should be inconsequential, given that any such knowledge is
ignored. As a consequence, cases in which recognition leads to a

correct judgment (C case) or to a false judgment (F case) should be
treated identically (Hilbig & Pohl, 2008). In effect, U_R⫹C and
U_R⫹F should yield similar decision times (Hypothesis 3a).
Evidence-based models, on the other hand, predict that it should
make a difference in recognition cases comprising further knowledge (U_R⫹) whether the R⫹ object represents the correct (C) or
false (F) choice (Hilbig & Pohl, 2008; Pohl, 2006). In the latter
case, evidence is more likely to contradict recognition and thus to
yield more conflict, thereby affording more time to reach the
desired threshold (evidence accumulation) or to form a coherent
mental representation (PCS). Consequently, decisions in U_R⫹C
cases should be faster than those in U_R⫹F cases (Hypothesis 3b).

Adherence Hypotheses (4a vs. 4b)
Finally, some differential predictions can be derived concerning
choices that are not in line with the recognition cue (i.e., choices
of the unrecognized object). Following a deterministic understanding of the RH, any decision against the recognition cue (also
denoted nonadherence to the RH) must represent an error. However, because the speed of errors is not predictable, it is not clear
whether choices in line with the RH should be performed faster or
slower than choices against the RH. Despite this ambiguity, Pachur
and Hertwig (2006) predicted that “inferences that agree with the
recognition heuristic require less response time than choices that
are inconsistent with the recognition heuristic” (p. 986). This
prediction hinges on the assumption that choices of unrecognized
objects represent nonuse of the RH in the sense of consideration of
further information or cues beyond recognition (rather than errors),
which should afford more time. However, because different positions can be taken here, we did not make a prediction concerning
the speed of choices of unrecognized objects. This notwithstanding, it is possible to predict that—independent of whether choices
following the RH are performed faster or slower than choices of
unrecognized objects—any such effect should be the same for
U_mR and U_R⫹ cases. Stated differently, there should be no
interaction between choice (recognized vs. unrecognized object)
and case (U_mR vs. U_R⫹). This is Hypothesis 4a.
Note that evidence-based models, unlike a deterministic version
of the RH, actually predict that cases of nonadherence to recognition (choice of the unrecognized object) occur. This is possible
either by retrieving evidence that speaks against the recognized
object (e.g., knowing that a city does not have an international
airport) or by constructing evidence in favor of the unrecognized
object (e.g., inferring from the sound of its name that it is located
in a country with many extremely large cities). In line with Pachur
and Hertwig’s (2006) view of the RH, evidence-based models
would predict that choices of the unrecognized object should take
longer than choices of the recognized one, as evidence to overrule
the recognition cue is necessary. However, unlike the RH, these
models would also predict that this effect of adherence (choice of
the recognized object) versus nonadherence (choice of the unrecognized object) on decision times should be substantially larger for
U_R⫹ than for U_mR cases, because accumulating sufficient
evidence to act against the larger a priori difference in evidence
must take longer. That is, an interaction between case (U_mR vs.
U_R⫹) and choice (choice of the recognized vs. the unrecognized
object) would be additionally expected (Hypothesis 4b).

<-----Page 3----->DECISION TIME ANALYSIS OF THE RECOGNITION HEURISTIC

Summary of Hypotheses
The hypotheses can be summarized as follows: First (recognition hypotheses), concerning differences between recognition and
knowledge cases, the RH predicts that all recognition cases should
yield faster decisions than do all knowledge cases (Hypothesis 1a).
By contrast, evidence-based models predict that this is only consistently the case if recognition is accompanied by further knowledge (Hypothesis 1b). Second (further knowledge hypotheses),
with respect to differences between recognition subcases, the RH
predicts that these should all yield comparable decision times
(Hypothesis 2a). Evidence-based models, on the other hand, predict that recognition cases lead to faster decisions whenever recognition is accompanied by further knowledge (Hypothesis 2b).
Third (accuracy hypotheses), when comparing cases in which
recognition yields a correct versus a false judgment, the RH
predicts no difference between these cases (Hypothesis 3a),
whereas evidence-based models predict that decision times should
be faster whenever recognition yields a correct judgment (Hypothesis 3b). Fourth (adherence hypotheses), concerning effects of
adherences (choice of the recognized object) versus nonadherence
(choice of the unrecognized object), the RH asserts that any such
effect should be comparably large in all recognition cases (Hypothesis 4a). Evidence-based models, by contrast, predict that
nonadherence affords more time and that this effect is more
pronounced whenever recognition comprises further knowledge
(i.e., a main effect of adherence and an interaction with recognition
subcase are expected; Hypothesis 4b).
These hypotheses were tested in three experiments in which
natural recognition was used and participants were taught no
further cues. In all experiments, participants performed the citysize task (Goldstein & Gigerenzer, 2002), in which they inferred
which city in each pair was more populous.

Experiment 1
Method
Twenty-four participants (17 female) were recruited from the
University of Bonn. They were 19 to 30 years of age (M ⫽ 23.9
years, SD ⫽ 3.1). The 20 largest cities in Switzerland were
exhaustively paired as materials, resulting in 190 comparisons.
Participants were instructed to indicate which city in each pair was
more populous and to decide speedily while trying to achieve as
many correct decisions as possible. Next, participants received all
paired comparisons in random order on a computer screen and
answered by pressing one of two keys. Choices and reaction times
were recorded. After the paired-comparison task, participants were
again shown all cities in alphabetical order and were asked to
indicate for each city whether they recognized its name (“Have
you ever heard of this Swiss city before the experiment?”; mR)
and, if so, if they possessed any further knowledge about it (“Do
you know anything about this city beyond having heard its
name?”; R⫹; cf. Pohl, 2006).2 Participants were then debriefed,
and they received partial course credit for their participation.

Results
Participants recognized 10.2 (SD ⫽ 3.4) of the 20 to-becompared cities on average, and this resulted in a high discrimi-

1299

nation rate (M ⫽ 0.47) of recognition. The mean recognition
validity (proportion of correct judgments possible from strictly
following the RH) was 0.86 (SD ⫽ 0.08), which was significantly
above chance level, t(23) ⫽ 23.2, p ⬍ .001, and also significantly
greater than the mean knowledge validity (proportion of correct
judgments in knowledge cases) of 0.75 (SD ⫽ 0.10), t(23) ⫽ 3.5,
p ⫽ .002. In sum, preconditions for applying the RH were optimal,
given the discrimination rate, very high recognition validity, and
lower knowledge validity.
To analyze decision times and test the hypotheses outlined
above, we computed each participant’s median decision time
across the relevant cases (provided in the Appendix). Note that all
analyses reported in the following were double-checked using
log-transformed decision times; however, results were stable in all
instances. Testing the recognition hypotheses (1a vs. 1b), we
compared participants’ median decision times in each of the two
recognition cases (U_mR and U_R⫹) against those in all knowledge cases (mR_mR, mR_R⫹, R⫹_R⫹; see Figure 1). As can be
seen, recognition cases yielding only small a priori differences in
evidence (U_mR) were not faster than mR_mR or R⫹_R⫹ cases
( ps ⬎ .10, ds ⬍ 0.35). In fact, they were actually significantly
slower than mR_R⫹ cases, which provided the largest a priori
difference in evidence of all knowledge cases. By contrast, U_R⫹
cases yielded significantly faster decision times than did any of the
knowledge cases and comprised medium-to-large effect sizes
(Cohen, 1988) throughout. The results of the statistical tests are
summarized in Table 1. So, the differential pattern predicted by
evidence-based models (Hypothesis 1b) was corroborated.
With respect to the further knowledge hypotheses (2a vs. 2b),
we compared decision times within recognition cases. As can be
seen in Figure 1, decisions in U_R⫹ cases were substantially faster
than those in U_mR cases, t(21) ⫽ 5.1, p ⬍ .001, d ⫽ 1.1. This
result is in line with Hypothesis 2b. So, recognition cases yielded
different decision times depending on whether the recognized
object comprised further knowledge (R⫹) or did not (mR). Stated
differently, cases yielding less conflict between options led to
faster decisions.
Moreover, in testing the accuracy hypotheses (3a and 3b), we
subdivided U_R⫹ cases depending on whether or not the recognized object was the correct choice. Analyses revealed that decision times were shorter for the former than for the latter cases,
t(15) ⫽ 2.6, p ⫽ .019, d ⫽ 0.65. Thus, recognition cases yielded
different decision times depending on whether further knowledge
was in line with recognition (R⫹C) or was not (R⫹F). So, Hypothesis 3b was supported. Unfortunately, analyses of the adherence hypotheses (4a and 4b), comparing recognition cases in
which the recognized object was chosen to cases in which participants did not adhere to recognition, were not feasible due to the
small sample size and, thus, an insufficient number of cases.

2
Note that simply asking participants for the status of objects (U, mR,
and R⫹) may seem questionable. However, if mR objects were sometimes
“incorrectly” judged to be R⫹ (or vice versa), this would work against the
differential predictions of only the evidence-based models but would
increase the chances of the RH.

<-----Page 4----->HILBIG AND POHL

1300

which is more likely whenever a set comprises a few very large (or
small) objects that are recognized for their extreme position on the
criterion dimension (Hilbig et al., in press; Pachur & Hertwig,
2006). Second, we increased the sample size in Experiment 2 to
obtain sufficiently large cell sizes for the more detailed analyses.

Median decision time [ms]

2500

2250

2000

Method

1750

1500
U_R+

U_mR

mR_mR

mR_R+

R+_R+

Case

Figure 1. Median decision times in milliseconds for all recognition
(U_R⫹ and U_mR) and knowledge (mR_mR, mR_R⫹, and R⫹_R⫹)
cases in Experiment 1. Error bars represent 1 standard error of the mean.

Seventy-four participants (44 female) were recruited from the
University of Mainz and University of Mannheim. They were 18
to 50 years of age (M ⫽ 24.1 years, SD ⫽ 5.7). We selected 17
cities randomly from a list of the largest cities of the world (cf.
Hilbig, 2008a; Hilbig & Pohl, 2008). These were paired exhaustively, resulting in 136 paired comparisons for the city-size task.
Before the judgment task, participants were shown all cities in
alphabetical order to ensure that the current reference class was
fully defined for participants. Thereafter, the experiment commenced exactly as in Experiment 1. Participants were paid or
received partial course credit for their participation.

Discussion
In Experiment 1 we found support for the hypotheses derived
from evidence-based models of comparative judgments. The predictions made by the RH, on the other hand, could not be corroborated even though preconditions for applying the RH were optimal. Recognition cases yielded faster decision times than did
knowledge cases only when recognition cases comprised a large a
priori difference in evidence. Second, recognition cases were
treated differently, depending on whether the recognized object
comprised further knowledge and, if so, depending on whether or
not this object represented the correct choice.
However, Hypothesis 4 could not be tested due to the small
sample size. Also, the materials used (Swiss cities) might have
comprised some criterion knowledge; that is, participants may well
have known some cities to be very large or small, and such
knowledge could render any probabilistic judgment obsolete
(Hilbig, Pohl, & Bröder, in press; Pachur et al., 2008). We thus
aimed to remedy both limitations in a second experiment.

Experiment 2
We chose as materials a random selection of large cities worldwide. This was done to reduce the danger of criterion knowledge,

Results
Participants recognized a mean of 9.9 (SD ⫽ 2.2) of the 17
cities, and this again resulted in a high discrimination rate (M ⫽
0.48). The mean recognition validity of 0.78 (SD ⫽ .08) was both
larger than chance, t(72) ⫽ 29.8, p ⬍ .001, and greater than the
mean knowledge validity of 0.68 (SD ⫽ 0.10), t(72) ⫽ 7.4, p ⬍
.001. Again, preconditions for the RH were optimal. Participants’
median decision times for all relevant cases are provided in the
Appendix. As in Experiment 1, all analyses were repeated, on the
basis of log-transformed response latencies, and revealed the same
exact pattern of results. Moreover, it is of interest that the rank
order of the relevant cases was exactly the same as in Experiment
1 (see Appendix). This result confirmed the stability of the data.
With respect to the recognition hypotheses, we found that
U_mR cases did not yield faster decisions than did any of the
knowledge cases ( ps ⬎ .10, ds ⬍ 0.30; see Table 1), whereas
U_R⫹ trials were performed significantly faster throughout ( ps ⬍
.001, ds ⬎ 0.50). So, support for Hypothesis 1b was obtained.
Also, Hypothesis 2b was corroborated, as U_R⫹ cases yielded
faster decisions than did U_mR cases, t(63) ⫽ 6.0, p ⬍ .001, d ⫽
0.75. Moreover, and supporting Hypothesis 3b, decision times

Table 1
Results of Testing Median Decision Times in Recognition Cases (U_mR and U_R⫹) Against
Knowledge Cases (mR_mR, mR_R⫹, and R⫹_R⫹) Using Paired t Tests
Experiment 1
Test
U_mR
vs. mR_mR
vs. mR_R⫹
vs. R⫹_R⫹
U_R⫹
vs. mR_mR
vs. mR_R⫹
vs. R⫹_R⫹
a
ⴱ

Experiment 2

t statistica

Effect size

t statistica

Effect size

t(21) ⫽ 0.8
t(21) ⫽ ⫺1.9ⴱ
t(20) ⫽ 1.6

d ⫽ 0.16
d ⫽ 0.41
d ⫽ 0.35

t(53) ⫽ 1.7
t(63) ⫽ ⫺0.7
t(62) ⫽ 1.3

d ⫽ 0.23
d ⫽ 0.09
d ⫽ 0.16

t(20) ⫽ 3.5ⴱⴱⴱ
t(21) ⫽ 3.6ⴱⴱⴱ
t(21) ⫽ 4.2ⴱⴱⴱ

d ⫽ 0.75
d ⫽ 0.77
d ⫽ 0.92

t(52) ⫽ 5.3ⴱⴱⴱ
t(63) ⫽ 5.4ⴱⴱⴱ
t(70) ⫽ 7.2ⴱⴱⴱ

d ⫽ 0.73
d ⫽ 0.67
d ⫽ 0.85

Positive t values indicate that the recognition case yielded faster decision times than the knowledge case.
p ⬍ .10. ⴱⴱⴱ p ⬍ .001.

<-----Page 5----->DECISION TIME ANALYSIS OF THE RECOGNITION HEURISTIC

were shorter for cases in which the R⫹ object was the correct
versus the false choice, t(68) ⫽ 3.7, p ⬍ .001, d ⫽ 0.45. As such,
the results of Experiment 1 were all replicated.
Finally, with respect to the adherence hypotheses (4a vs. 4b), we
compared recognition cases in which participants chose the recognized object with cases in which participants did not adhere to
recognition. Note that only the evidence-based models predicted
an interaction between adherence and recognition subcase (U_mR
vs. U_R⫹). To test these effects, we conducted a two-way
repeated-measures analysis of variance with case (U_mR vs.
U_R⫹) and adherence (vs. nonadherence) as independent variables and median decision times as the dependent variable. The
descriptive statistics for all cases can be found in the Appendix.
First, we found a main effect of recognition subcase, F(1, 44) ⫽
4.9, p ⫽ .03, ␩2p ⫽ .10; this was in line with the effects reported
above. We also found a large main effect of adherence, F(1, 44) ⫽
25.5, p ⬍ .001, ␩2p ⫽ .36, which confirmed that choosing the
unrecognized object required more time (cf. Pachur & Hertwig,
2006). However, we also obtained an interaction supporting Hypothesis 4b, such that the effect of adherence was substantially
larger for U_R⫹ cases than for U_mR cases, F(1, 44) ⫽ 11.3, p ⫽
.002, ␩2p ⫽ .21. In other words, deciding against the recognized
city took longer than deciding for it, but the corresponding difference in decision times was larger in U_R⫹ cases than in U_mR
cases.

Discussion
In Experiment 2 we remedied two limitations of the first experiment, namely, the small sample size and the potential caveat of
criterion knowledge. However, all findings from Experiment 1
could be replicated, and this lent additional support for the hypotheses derived from evidence-based models. Moreover, we
found an interaction between choosing the recognized versus unrecognized object in U_mR versus U_R⫹ cases. So, as implied by
evidence based-models only, the effect of adherence versus nonadherence was more pronounced whenever there was a larger a
priori difference between objects, as this resulted in more conflict
when deciding against the recognized object.
However, there is a caveat pertaining to both Experiments 1 and
2 that needs to be addressed: Potentially, some of the results were
driven by differences in the time needed to recognize different
objects rather than the time of the actual decision process. That is,
there is evidence that participants take longer to judge an object to
be unrecognized than recognized (Hertwig et al., 2008). Moreover,
and more critically, it seems at least plausible that objects comprising further knowledge (R⫹) could be recognized faster than
objects known only by their name (mR). Such differences between
objects may have driven the results reported above.
On the other hand, the median decision times in both experiments (see the Appendix) render it unlikely that such effects are
behind the reported results. In particular, mR_R⫹ cases would
have to yield longer response latencies than would R⫹_R⫹ cases,
if R⫹ objects were generally recognized faster and this had driven
the results. In both experiments, the opposite was the case.3 However, admittedly, these are merely post hoc arguments. So, we
addressed this problem in a third experiment with the aim of
strictly controlling for effects of recognition times.

1301

Experiment 3
The 14 largest cities in Switzerland, excluding the largest,
Zurich, were paired in the city-size task. Due to exclusion of the
largest object and given the typically very high recognition validity
in this domain, distortions based on criterion knowledge were
unlikely in this experiment (Hilbig et al., in press). The design was
the same as in Experiments 1 and 2, with the addition that we
assessed and controlled for recognition times.

Method
Sixty-eight participants (56 female) were recruited from the
University of Mannheim. They were 18 to 46 years of age (M ⫽
22.2 years, SD ⫽ 5.3). The Swiss cities were paired exhaustively,
resulting in 91 paired comparisons. The city-size task commenced
exactly as in the first two experiments. We measured recognition
times after all paired comparisons had been performed and in the
same manner as Hertwig et al. (2008): Objects were individually
presented to participants (in random order), and participants were
instructed to indicate—as speedily as possible—whether or not
they had known the object before the experiment. The time from
the onset of an object’s name to the participant’s response was
assessed. If a participant judged an object to be unrecognized, the
next trial came up (after a blank screen for 1,000 ms and a fixation
cross for 500 ms). By contrast, whenever an object was recognized, it remained on the screen and the participant was instructed
to indicate whether he or she knew the object only by its name
(mR) or possessed any further knowledge about it (R⫹). Participants were paid or received partial course credit for their participation.

Results
Participants recognized 9.0 (SD ⫽ 2.4) of the 14 cities on
average, resulting in an acceptable discrimination rate (M ⫽ 0.43).
Across participants, the mean recognition validity of 0.79 (SD ⫽
0.10) was above chance level, t(63) ⫽ 23.3, p ⬍ .001, and greater
than the mean knowledge validity (M ⫽ 0.71, SD ⫽ 0.11), t(63) ⫽
4.2, p ⬍ .001. Overall, preconditions for applying the RH were
comparable to those in the previous experiments.
For each participant, we computed the median recognition time
(response latency when judging whether an object was recognized)
for U, mR, and R⫹ objects. Across participants, the median
recognition times for these objects were MU ⫽ 970 (SD ⫽ 305),
MmR ⫽ 1,145 (SD ⫽ 497), and MR⫹ ⫽ 886 (SD ⫽ 338), respectively. Participants took longer when judging an object to be
merely recognized (mR) than unrecognized (U), t(59) ⫽ 3.2, p ⫽
.002, d ⫽ 0.42. Likewise, participants needed more time to “recognize” an object that was merely recognized (mR) versus recognized plus further knowledge (R⫹), t(62) ⫽ 4.7, p ⬍ .001, d ⫽
0.60. By contrast, U and R⫹ judgments did not differ significantly,
t(62) ⫽ 1.7, p ⫽ .09. However, the recognition time differences
between objects indicate that it is necessary to control for these
differences when analyzing paired-comparison judgments.
In fact, this effect (mR_R⫹ ⬍ R⫹_R⫹) was significant in Experiment
2, t(63) ⫽ 3.1, p ⫽ .003, d ⫽ 0.40.
3

<-----Page 6----->HILBIG AND POHL

1302

To control for the effect of recognition times on response
latencies in the judgment task, we computed a multiple regression
separately for each participant that predicted the response latency
in each trial from the recognition times for each of the two objects
as predictors. From the unstandardized residuals, we then computed each participant’s median decision time across the relevant
cases for the further analyses and tests of the hypotheses. So,
recognition times were strictly controlled for, and any variance in
the remaining response latencies cannot be explained by differences in recognition times between objects. That is, the residuals
can be interpreted as decision times when recognition times are
held constant.4 Finally, note that when we controlled for recognition times in this way, the evidence-based models were given an
additional disadvantage, namely, that one possibly important piece
of evidence—the fluency of recognition or the accessibility of
knowledge—was now held constant. Again, we corroborated all
results using log-transformed rather than median decision times.
The median decision times (before recognition times were partialed out) can be found in the Appendix. Note that the rank order
of relevant cases was exactly the same as in the previous two
experiments.
The analyses referring to the recognition hypotheses (1a vs. 1b)
are shown in Table 2. The results with respect to U_R⫹ cases
mirrored those of the previous experiments. By contrast, U_mR
cases now yielded shorter decision times than did some of the
knowledge cases (i.e., mR_mR and R⫹_R⫹). However, mR_R⫹
cases—which comprise the largest a priori difference in evidence
of all knowledge cases—again involved shorter response latencies
than did U_mR cases. This result can be explained only by
evidence-based accounts. A look at the effect sizes in Table 2
additionally reveals that the speed advantage of U_R⫹ cases over
knowledge cases was clearly larger than the difference between
U_mR and knowledge cases. This is inconsistent with the RH,
especially given that analyses controlled for recognition times.
With respect to the further knowledge hypotheses (2a vs. 2b),
we found that U_R⫹ trials were performed faster than U_mR
trials, t(58) ⫽ 5.0, p ⬍ .001, d ⫽ 0.66. This result corroborated
Hypothesis 2b. Similarly, Hypothesis 3b was supported, as response latencies were shorter in recognition cases in which the R⫹
Table 2
Results of Testing Median Residual Decision Times in
Recognition Cases (U_mR and U_R⫹) Against Knowledge
Cases (mR_mR, mR_R⫹, and R⫹_R⫹) After Controlling for the
Effects of Recognition Times for Both Objects (Individually per
Participant), Using Paired t Tests (Experiment 3)
Test
U_mR
vs. mR_mR
vs. mR_R⫹
vs. R⫹_R⫹
U_R⫹
vs. mR_mR
vs. mR_R⫹
vs. R⫹_R⫹
a

t statistica

Effect size

t(49) ⫽ 4.3ⴱⴱⴱ
t(58) ⫽ ⫺1.8ⴱ
t(55) ⫽ 2.0ⴱⴱ

d ⫽ 0.60
d ⫽ 0.22
d ⫽ 0.27

t(48) ⫽ 6.1ⴱⴱⴱ
t(58) ⫽ 5.3ⴱⴱⴱ
t(59) ⫽ 6.8ⴱⴱⴱ

d ⫽ 0.95
d ⫽ 0.71
d ⫽ 0.90

Positive t values indicate that the recognition case yielded faster decision
times than the knowledge case.
ⴱ
p ⬍ .10. ⴱⴱ p ⬍ .05. ⴱⴱⴱ p ⬍ .001.

object was, in fact, the correct choice, t(51) ⫽ 2.7, p ⫽ .009, d ⫽
0.66. Both findings support the evidence-based models.
Finally, testing the adherence hypotheses (4a vs. 4b), we again
computed the repeated-measures analysis of variance with recognition subcase (U_mR vs. U_R⫹) and adherence (vs. nonadherence) as independent measures and median residual decision times
as the dependent variable. Although there was no main effect of
recognition subcase, F(1, 28) ⫽ 0.1, p ⫽ .77, we again obtained a
large main effect of adherence, F(1, 28) ⫽ 16.9, p ⬍ .001, ␩2p ⫽
.38. This revealed that decisions were generally faster when participants followed the recognition cue. Moreover, and in line with
Hypothesis 4b, there was an interaction, F(1, 28) ⫽ 4.2, p ⫽ .05,
␩2p ⫽ .13, such that the difference in decision times between
adherence and nonadherence was larger in U_R⫹ than in U_mR
cases.

Discussion
Experiment 3 was conducted to test whether the effects found in
Experiments 1 and 2 would need to be attributed to recognition
time differences between objects, rather than to decision processes.
We therefore controlled for the influence of recognition times—
partialing out their effect on decision times individually for each
participant—and repeated all hypotheses tests. Note that this procedure also clearly lessens the chances of the evidence-based
models, which would consider recognition times (which are proxy
of knowledge accessibility) a potentially important piece of evidence.
The majority of results again contradicted the hypotheses derived from the RH and supported evidence-based models. However, we obtained the novel finding that recognition cases that
comprised only a small difference in evidence (U_mR) were now
performed faster than were those knowledge cases that also
yielded relatively small a priori differences in evidence (mR_mR
and R⫹_R⫹, respectively). This finding is, of course, in line with
both the RH and evidence-based models, but it reveals that the
results concerning Hypotheses 1a versus 1b from Experiments 1
and 2 should be interpreted cautiously. On the other hand, those
knowledge cases that should often yield the largest a priori differences in evidence (mR_R⫹) were again performed faster than
were U_mR cases. This finding corroborates Hypothesis 1b and
cannot be explained by the RH. All other effects found in Experiments 1 and 2 (confirming Hypotheses 2b, 3b, and 4b) were
replicated while controlling for the influence of objects’ recognition times on response latencies.

General Discussion
In three experiments, we tested decision time predictions derived from the recognition heuristic (RH; Goldstein & Gigerenzer,
1999, 2002) and from evidence-based models for judgments between pairs of objects. Whereas the RH treats recognition of
to-be-compared objects as binary and claims that the decision
4
Following the suggestion of an anonymous reviewer, we repeated this
procedure regressing decision times on the signed difference between
recognition times individually for each participant and, again, using the
residuals for all hypotheses tests. However, the results of the analyses
reported below remained unchanged.

<-----Page 7----->DECISION TIME ANALYSIS OF THE RECOGNITION HEURISTIC

process is determined by whether recognition discriminates between objects, evidence-based models assume that evidential information beyond recognition is taken into account. The pattern of
decision times found in all experiments supported predictions from
the evidence-based models and mostly contradicted predictions
from the RH. Put more precisely, recognition cases (whenever
only one object was recognized) yielded consistently faster decisions than did knowledge cases (both objects recognized), if and
only if the recognized object comprised further knowledge. Second, for recognition cases, decision times were notably faster when
the recognized object comprised further knowledge, and this finding provides support for the impact of the amount of evidence
available for an object (cf. Hertwig et al., 2008; Newell & Fernandez, 2006). Moreover, decisions were made faster whenever
the recognized object was, in fact, the correct choice—that is,
when further knowledge was aligned with recognition (Hilbig &
Pohl, 2008)—than when knowledge was likely to conflict with
recognition. Again, this can be taken as support for evidence-based
models. Both effects contradict the RH, according to which all
recognition cases should be treated similarly.
Finally, in Experiments 2 and 3, it was shown that nonadherence
to the recognition cue (choice of the unrecognized object in a
recognition case) was generally slower than adherence, as predicted by some interpretations of the RH (Pachur & Hertwig,
2006) and by the evidence-based models. However, as predicted
by the latter only, this effect was more pronounced for cases in
which the recognized object comprised further knowledge. So, the
pattern obtained is in line with evidence-based models but cannot
be explained by the RH.
Additionally, Experiment 3 strictly controlled for the potential
influence of differences in recognition times between objects.
Because it need not take equally long to judge an object to be
recognized (Hertwig et al., 2008), results might have been biased
against the RH. However, the majority of effects contradicting the
RH were replicated when recognition times were held constant. At
the same time, all hypotheses derived from evidence-based models
were again confirmed.
With these experiments, we extended previous findings—
indicating that evidence-based models outperform fast-and-frugal
heuristics in explaining comparative judgments—to the RH. To
test the different predictions, we adhered closely to methodological
preconditions for studying the RH (Pachur et al., 2008). We used
naturally recognized objects and did not provide any additional
information. Also, the validity and discrimination rate of recognition were high, and this provided optimal conditions for applying
the RH. Nevertheless, predictions derived from the RH were
seldom supported.
We considered two types of models as alternatives to the RH.
First, evidence accumulation models (Lee & Cummins, 2004;
Newell et al., 2007) assume sequential sampling and accumulation
of evidence until an evidence threshold is reached (cf. decision
field theory; Busemeyer & Johnson, 2004; Busemeyer &
Townsend, 1993). Such models claim that the time needed to
accumulate sufficient evidence and, thus, a priori differences in
evidence for objects are determinants of decision times. Similar
predictions can be derived from parallel constraint satisfaction
models (PCS; Glöckner & Betsch, 2008a, 2008b), which assume a
neural network that modifies evidence in a holistic and parallel
process to achieve consistency. Although evidence accumulation

1303

and PCS models differ in some respects— especially concerning
sequential versus parallel processing of information and whether
evidence is actually changed during the decision process—they
were herein treated similarly, as both predict that decision times
will increase with increasing conflict between options. That is,
larger differences in evidence between objects should feed into
shorter decision times. Therefore, we refer to these models as
evidence based.
In sum, and in line with previous findings on PCS (Glöckner &
Betsch, 2008a, 2008b; Glöckner & Hodges, 2008) and evidence
accumulation models (Lee & Cummins, 2004; Newell & Lee,
2007), support was obtained for the integration of information and
the impact of differences in evidence between objects. Decision
times in different cases supported the notion that the (speed of the)
decision process is determined by the degree to which one object
is superior and thus by the degree of conflict (Hilbig, 2008b),
rather than by recognition alone.
Note, however, that these findings do not rule out the possibility
that decision processes resembling noncompensatory adherence to
recognition may occur in some instances. Indeed, we have argued
elsewhere that some decision makers behave in accordance with
the RH (Hilbig, 2008a; Hilbig & Pohl, 2008). So, optimally, a
model of comparative judgments should be able to integrate both
compensatory and noncompensatory use of recognition. Evidencebased models, which are related to Newell’s (2005) “adjustable
spanner” metaphor, may offer such a solution. Without needing to
assume different strategies or heuristics, these unimodels can account for the exclusive use of single cues just as parsimoniously as
they explain how different cues may be integrated. Stated differently, evidence-based models allow for one-reason decision making based on recognition and additionally explain patterns inconsistent with the RH, as demonstrated in this article.

References
Bergert, F. B., & Nosofsky, R. M. (2007). A response-time approach to
comparing generalized rational and take-the-best models of decision
making. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 33, 107–129.
Bröder, A., & Gaissmaier, W. (2007). Sequential processing of cues in
memory-based multiattribute decisions. Psychonomic Bulletin & Review, 14, 895–900.
Bröder, A., & Schiffer, S. (2003). Take the Best versus simultaneous
feature matching: Probabilistic inferences from memory and effects of
representation format. Journal of Experimental Psychology: General,
132, 277–293.
Busemeyer, J. R., & Johnson, J. G. (2004). Computational models of
decision making. In D. J. Koehler & N. Harvey (Eds.), Blackwell
handbook of judgment and decision making (pp. 133–154). Malden,
MA: Blackwell Publishing.
Busemeyer, J. R., & Townsend, J. T. (1993). Decision field theory: A
dynamic– cognitive approach to decision making in an uncertain environment. Psychological Review, 100, 432– 459.
Cohen, J. (1988). Statistical power analysis for the behavioral sciences
(2nd ed.). Hillsdale, NJ: Erlbaum.
Gigerenzer, G. (2001). The adaptive toolbox. In G. Gigerenzer & R. Selten
(Eds.), Bounded rationality: The adaptive toolbox (pp. 37–50). Cambridge, MA: MIT Press.
Gigerenzer, G., & Goldstein, D. G. (1999). Betting on one good reason:
The take the best heuristic. In G. Gigerenzer, P. M. Todd, & the ABC
Research Group (Eds.), Simple heuristics that make us smart (pp. 75–
95). New York: Oxford University Press.

<-----Page 8----->1304

HILBIG AND POHL

Glöckner, A., & Betsch, T. (2008a). Modeling option and strategy choices
with connectionist networks: Toward an integrative model of automatic
and deliberate decision making. Judgment and Decision Making, 3,
215–228.
Glöckner, A., & Betsch, T. (2008b). Multiple-reason decision making
based on automatic processing. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 34, 1055–1075.
Glöckner, A., Betsch, T., & Schindler, N. (2008). Construction of probabilistic inferences by constraint satisfaction. Manuscript submitted for
publication.
Glöckner, A., & Hodges, S. D. (2008). Parallel constraint satisfaction in
memory-based decisions. Manuscript submitted for publication.
Goldstein, D. G., & Gigerenzer, G. (1999). The recognition heuristic: How
ignorance makes us smart. In G. Gigerenzer, P. M. Todd, & the ABC
Research Group (Eds.), Simple heuristics that make us smart (pp. 37–
58). New York: Oxford University Press.
Goldstein, D. G., & Gigerenzer, G. (2002). Models of ecological rationality: The recognition heuristic. Psychological Review, 109, 75–90.
Hausmann, D., & Läge, D. (2008). Sequential evidence accumulation in
decision making: The individual desired level of confidence can explain
the extent of information acquisition. Judgment and Decision Making, 3,
229 –243.
Hertwig, R., Herzog, S. M., Schooler, L. J., & Reimer, T. (2008). Fluency
heuristic: A model of how the mind exploits a by-product of information
retrieval. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 34, 1191–1206.
Hilbig, B. E. (2008a). Individual differences in fast-and-frugal decision
making: Neuroticism and the recognition heuristic. Journal of Research
in Personality, 42, 1641–1645.
Hilbig, B. E. (2008b). One-reason decision making in risky choice? A
closer look at the priority heuristic. Judgment and Decision Making, 3,
457– 462.
Hilbig, B. E., Erdfelder, E., & Pohl, R. F. (2009). One-reason decisionmaking unveiled: A measurement model of the recognition heuristic.
Manuscript submitted for publication.
Hilbig, B. E., & Pohl, R. F. (2008). Recognizing users of the recognition
heuristic. Experimental Psychology, 55, 394 – 401.

Hilbig, B. E., Pohl, R. F., & Bröder, A. (in press). Criterion knowledge: A
moderator of using the recognition heuristic? Journal of Behavioral
Decision Making.
Holyoak, K. J., & Simon, D. (1999). Bidirectional reasoning in decision
making by constraint satisfaction. Journal of Experimental Psychology:
General, 128, 3–31.
Lee, M. D., & Cummins, T. D. (2004). Evidence accumulation in decision
making: Unifying the “take the best” and the “rational” models. Psychonomic Bulletin & Review, 11, 343–352.
Newell, B. R. (2005). Re-visions of rationality? Trends in Cognitive
Sciences, 9, 11–15.
Newell, B. R., Collins, P., & Lee, M. D. (2007). Adjusting the spanner:
Testing an evidence accumulation model of decision making. In D.
McNamara & G. Trafton (Eds.), Proceedings of the 29th Annual Conference of the Cognitive Science Society (p. 533–538). Austin, TX:
Cognitive Science Society.
Newell, B. R., & Fernandez, D. (2006). On the binary quality of recognition and the inconsequentially of further knowledge: Two critical tests of
the recognition heuristic. Journal of Behavioral Decision Making, 19,
333–346.
Newell, B. R., & Lee, M. D. (2007). The right tool for the job? Testing an
evidence accumulation model of decision making. Manuscript submitted
for publication.
Pachur, T., Bröder, A., & Marewski, J. (2008). The recognition heuristic in
memory-based inference: Is recognition a non-compensatory cue? Journal of Behavioral Decision Making, 21, 183–210.
Pachur, T., & Hertwig, R. (2006). On the psychology of the recognition
heuristic: Retrieval primacy as a key determinant of its use. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 32, 983–
1002.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1988). Adaptive strategy
selection in decision making. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 14, 534 –552.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1993). The adaptive
decision maker. New York: Cambridge University Press.
Pohl, R. F. (2006). Empirical tests of the recognition heuristic. Journal of
Behavioral Decision Making, 19, 251–271.

<-----Page 9----->DECISION TIME ANALYSIS OF THE RECOGNITION HEURISTIC

1305

Appendix
Response Latencies in the Judgment Task
Table A1
Median Decision Times in Milliseconds, Averaged Across Participants (Standard Deviations in
Parentheses), and Number of Participants Providing Data for Each Case
Experiment 1

Experiment 2

Experiment 3

Case

RT (SD)

n

RT (SD)

n

RT (SD)

n

Recognition all
U_mR
U_R⫹
Knowledge all
mR_mR
mR_R⫹
R⫹_R⫹
Guessing

1,959 (359)
2,100 (439)
1,869 (283)
2,046 (418)
2,228 (598)
2,020 (342)
2,199 (501)
2,386 (608)

24
23
23
24
22
22
22
24

1,374 (473)
1,621 (648)
1,317 (457)
1,639 (593)
1,815 (940)
1,558 (599)
1,741 (661)
1,946 (816)

73
65
72
74
55
56
72
72

1,266 (329)
1,492 (531)
1,168 (291)
1,512 (501)
1,850 (883)
1,372 (417)
1,601 (602)
1,770 (629)

64
60
63
68
54
63
64
62

Note. RT ⫽ reaction time.

Table A2
Median Decision Times in Milliseconds, Averaged Across Participants (Standard Deviation in
Parentheses), and Number of Participants Providing Data for Recognition Cases Depending on Whether
the Recognized Object Represents the Correct (C) vs. False (F) Choice and Depending on Whether the
Recognized Object Was, in Fact, Chosen (Adherence) or Not (Nonadherence)
Experiment 1

Experiment 2

Experiment 3

Case

RT (SD)

n

RT (SD)

n

RT (SD)

n

U_R⫹C
U_R⫹F
U_mRadherence
U_mRnonadherence
U_R⫹adherence
U_R⫹nonadherence

1,856 (278)
2,061 (449)
2,068 (416)
2,346 (696)
1,862 (277)
2,130 (872)

23
16
23
22
23
15

1,296 (468)
1,417 (480)
1,634 (657)
1,874 (855)
1,316 (558)
1,962 (860)

72
69
64
58
72
57

1,155 (318)
1,455 (690)
1,445 (507)
2,220 (1424)
1,149 (278)
2,132 (1644)

63
52
60
48
63
36

Note. RT ⫽ reaction time.

Received October 8, 2008
Revision received March 27, 2009
Accepted April 28, 2009 䡲

