<-----Page 0----->Computational Models 1

Computational models of decision making
Jerome R. Busemeyer
&
Joseph G. Johnson
Indiana University
April 7, 2003

To appear in D. Koehler & N. Harvey (Eds.) Handbook of Judgment and Decision
Making, Blackwell Publishing Co.

Send Correspondence to:
Jerome R. Busemeyer
Psychology Department
Indiana University
Bloomington In, 47405
voice: 812 855 4882
fax: 812 855 4691
email: jbusemey@indiana.edu

<-----Page 1----->Computational Models 2

Abstract
This chapter presents a connectionist or artificial neural network approach to
decision making. An essential idea of this approach is that decisions are based on the
accumulation of the affective evaluations produced by each action until a threshold
criterion is reached. This type of sequential sampling process forms the basis for decision
making in a wide variety of other cognitive tasks such as perception, categorization, and
memory. We apply these concepts to several important preferential choice phenomena,
including similarity effects, attraction effects, compromise effects, loss aversion effects,
and preference reversals. These analyses indicate that a relatively complex model of an
individual’s choice process reveals a relatively simple representation of the individual’s
underlying value structure.

<-----Page 2----->Computational Models 3
What are computational models of cognition?
In his classic book on computational vision, Marr (1982) proposed three levels of
theories about cognitive systems. At the highest level, theories aim to understand the
abstract goals a sys tem is trying to achieve; at an intermediate level, theories are designed
to explain the dynamic processes used to achieve the top level goals; and at the bottom
level, theories attempt to describe the neurophysiologic substrate of the second level.
Judgment and decision-making researchers have generally been concerned with
theorizing at the higher and more abstract levels. From this higher point of view,
explanations based on principles such as context dependent weights, loss aversion, and
anchoring-adjus tment are considered satisfactory. This chapter presents arguments for
viewing decision making from the perspective of a lower level microanalysis. By doing
so, we can try to answer deeper questions such as: why decision weights change across
contexts, why people are loss averse, and why anchors are more influential than
adjustments.
Computational models are constructed from simple units that conform to a small
number of elementary principles of cognition, but a large number of these simple units
are connected together to form a dynamical system. Although the properties of the
individual units are simple, the emergent behavior of the ensemble becomes fairly
complex. Computational models appear in a variety of forms, but this chapter focuses on
a class known as artificial neural networks, connectionist networks, or parallel distributed
processing systems (see Grossberg, 1988; and Rumelhart & McClelland, 1986, for
general overviews of these models). This class of computational models is designed to
form a bridge that mediates between the neural and behavioral sciences.

<-----Page 3----->Computational Models 4

How does the brain make decisions?
A decade ago, the brain was an impenetrable black box, but with recent advances
in neuroscience, we can start to look inside. It is informative to point out a conclusion
arising from converging evidence obtained through neuroscience research on decisionmaking. Neuroscientists have examined decision-making processes in the brains of
Macaque monkeys using single cell recording techniques (for reviews, see Gold &
Shadlen, 2001, 2002; Platt, 2002; Schall, 2001), as well as from the brains of humans
using evoked response potentials (Gratten, Coles, Sirevaag, & Donchin, 1988). A simple
but important conclusion from this work is that decisions in the brain are based on the
dynamic accumulation of noisy activation for each action, and the action whose
activation first exceeds the threshold is chosen. This process is illustrated in Figure 1, for
three actions, with each trajectory representing the cumulative activatio n (i.e., preference
state) for an action. The horizontal axis represents deliberation time and the vertical axis
indicates the activation for each action at each moment in time. In this figure, action A
reaches the threshold first, and is chosen at time T = 425.

<-----Page 4----->Computational Models 5
Figure 1: The decision process for a choice among three actions
2
Threshold Bound
A

1.5
B

Preference State

1
0.5

B
A

0
-0.5
C

-1

C

-1.5
-2
0

100

200
300
Deliberation Time

400

500

This dynamic decision process is known as a sequential sampling process
(DeGroot, 1970). It forms the basis of decision models used in a wide variety of cognitive
applications including sensory detection (Smith, 1995), perceptual discrimination
(Laming, 1968; Link & Heath, 1975; Usher & McClelland, 2001; Vickers, 1979),
memory recognition (Ratcliff, 1978); categorization (Nosofsky & Palmeri, 1997; Ashby,
2000), probabilistic inference (Wallsten & Barton, 1982) and preferential choice
(Aschenbrenner, Albert, & Schmalhofer, 1984; Busemeyer, 1985).
Computational models for Decision Making.
Several artificial neural network or connectionist models have been recently
developed for judgment and decision tasks: some placing more emphasis on the neural
processing aspects (Grossberg & Gutowski, 1987; Levin & Levine, 1996; Usher &
McClelland, 2002), and others placing more emphasis on applications to judgment and
decision making (Holyoak & Simon, 1999; Guo and Holyoak, 2002; Busemeyer &

<-----Page 5----->Computational Models 6
Townsend, 1993; Roe Busemeyer, & Townsend, 2001). Here we will initially focus on
our own, known as decision field theory, but we will also compare this to others later in
this chapter.
Decision field theory uses a sequential sampling process to make decisions,
consistent with the other areas of cognition. This theory has been applied to a variety of
traditional decision making problems including decision making under uncertainty
(Busemeyer & Townsend, 1993), selling prices and certainty equivalents (Busemeyer &
Goldstein, 1992; Townsend & Busemeyer, 1995), multi-attribute decision making
(Diederich, 1997), and multi-alternative decision making (Roe et al., 2001), and decision
rule learning (Johnson & Busemeyer, in press).
To introduce decision field theory, it will be helpful to consider an example
problem. Suppose you have to choose a penalty program for a young offender, convicted
of a serious crime, from one of three options: (A) a mild 5 year imprisonment, with a
population of inmates that only have minor convictions, and a possibility for parole in 2
years; (B) a moderate 15 year imprisonment, with a population of inmates with
moderately serious convictions, and a possibility for parole in 7 years; or (C) a severe 30
year imprisonment with a population of hardcore criminals with no possibility for parole.
If we assume that the offender may be either corrigible (labeled event g for good) or
incorrigible (labeled event b for bad), then Table 1 displays the six types of possible
consequences for this decision. For example, if a mild penalty is chosen (option A) but
the criminal is incorrigible (state b), then the outcome is the release of a dangerous man
who will very likely repeat the crime.

<-----Page 6----->Computational Models 7

Table 1: Hypothetical Decision about Penalty for a Crime
Action

Event g: Corrigible

Event b: Incorrigible

A: Mild Penalty

c11 : Reform to normal life

c12 : Release dangerous man

B: Moderate Penalty

c21 : Damage the man

c22 : Delay danger

C: Severe Penalty

c31 : Destroy a life

c32 : Safely incarcerate

According to decision field theory, the decision maker deliberates over these
courses of action by thinking about the various possible consequences of each action.
From moment to moment, different consequences come to mind over a period of time.
For example, at one moment the decision maker may remember something (e.g., the kind
face of the offender) that makes her think the offender can be reformed, and then she is
appalled by the thought wasting his life, locked behind bars for 30 years. But at another
moment, she may recall a recent story in which a parolee committed a horrible crime, and
she may feel a cold fear arise from the idea of releasing another on the streets in a few
years. At each moment, the affective reactions to the consequences of each action are
evaluated and compared, and these comparisons are accumulated over time to form a
preference state. The preference state for an action represents the integration of all the
preceding affective reactions produced by thinking about that action during deliberation.
This deliberation process continues until the accumulated preference for one action
reaches a threshold, which determines the choice and the deliberation time of the decision
(refer back to Figure 1).

<-----Page 7----->Computational Models 8
The threshold bound for the decision process, symbolized θ, is a key parameter
for controlling speed and accuracy tradeoffs. If θ is set to a low threshold, then only a
weak preference is required to make a choice. In this case, decisions are made very
quickly, which may be reasonable for trivial decisions of small consequence. However, a
low threshold would cause the decision to be based on little thought about the
consequences, which is likely to lead to a choice with bad unforeseen outcomes. For
more serious decisions, θ is set to a very high threshold, so that a very strong preference
is required to make a decision. In this case, deliberation takes longer, but the decision is
based on a more thoughtful evaluation of all the consequences, producing a choice that is
more likely to result in a positive outcome. Impulsive individuals may tend to use lower
thresholds, while perspicacious individuals may tend to use higher thresholds.
The dynamical system used to generate this deliberation process is presented next,
and the connectionist network is represented in Figure 2. The three actions
corresponding to the mild, moderate, and severe penalty option are labeled A, B, and C,
in this figure. The network has three layers of simple units that perform the following
computations.

<-----Page 8----->Computational Models 9
Figure 2: Connectionist Network Representation of Decision Field Theory

Weights

Contrasts

Valences

Preferences

m11
A

A

A

B

B

B

C

C

C

m21
m31
m12
m22
m32
m

The inputs into this network, shown on the far left, represent the affective
evaluations of the possible consequences of a decision. These values are assumed to be
generated by a motivational system (hence the symbol mij ), which is not explicitly
represented here (but see Busemeyer, Townsend, & Stout, 2002). For example, m11
represents the positive evaluation of the consequence produced by reforming the offender
and allowing him to return to society as a productive citizen, and m12 represents the
negative evaluation of the consequence produced by releasing a dangerous man back into
society.
The connections, linking the inputs to the first layer of nodes, are designed to
represent an attention process. At any moment in time, the decision maker is assumed to
attend to one of the possible events leading to consequences for each action. For example,
if the decision maker thinks the criminal is incorrigible, then at that moment, option A is
evaluated at m12 , option B is evaluated at m22 , and option C is evaluated at m32 . However,
if something comes to mind which makes the decision maker switch her attention and

<-----Page 9----->Computational Models 10
think that the offender can be reformed, then at that later moment, option A is evaluated
at m11 , option B is evaluated at m21 , and option C is evaluated at m31 . Thus, the inputs to
the first layer fluctuate from one moment (time t) to another moment (time t+h) as the
decision maker’s attention switches from one possible event to another. The probability
of attending to a particular event at each moment reflects the decision maker’s underlying
subjective probability or belief that the offender is corrigible. To formalize these ideas,
we define Wg (t) and Wb (t) = 1- Wg(t) as stochastic variables, called the attention weights,
which fluctuate across time. For example, attention may be focused at time t on the
corrigible event so that W g(t) > W b(t), but a moment later at time t+h, attention may
switch to the incorrigible event so that Wb(t+h) > W g(t+h). The first layer of the network
computes a weighted value for each option i within a set of n options as follows
Ui(t) = Wg(t)⋅mi1 + Wb(t)⋅mi2 + ε i(t),

(1)

The last ‘error’ term, ε i(t), represents the influence of irrelevant features (e.g., in an
experiment, these are features outside of an experimenter’s control). The above equation
looks like the classic weighted additive utility model, but unlike the classic model, the
attention weights are stochastic rather than deterministic (see Fisher, Jia, & Luce, 2000,
for a related model). The mean values of the attention weights correspond to the
deterministic weights used in the classic weighted additive model.
The connections linking the first and second layers are designed to perform
comparisons among weighted values of the options, to produce what are called valences.
A positive valence for one option indicates that the option has an advantage under the
current focus of attention, and a negative valence for another option indicates that the
option has a disadvantage under the current focus of attention. For example, if attention is

<-----Page 10----->Computational Models 11
currently focused on event g (corrigible), then action A has an advantage over other
options, and option C has a disadvantage under this state. But these valences reverse
when attention is switched to event b (incorrigible). The second layer computes the
valence for each option i within a set of n options by comparing the weighted value for
option i with the average of the of the other (n -1) options:
v i(t) = Ui(t) – U(t) ,

(2)

where U(t) = Σ k≠ i Uk (t) / (n-1). Valence is closely related to the concept of advantages
and disadvantages used in Tversky’s (1969) additive difference model. Note, however,
that the additive difference model assumed complete processing of all features, whereas
the present theory assumes a sequential sampling process that stops when a threshold is
crossed.
The connections, between the second and third layers, and the interconnections
among the nodes in the third layer, form a network that integrates the valences over time
into a preference state for each action. This is a recursive network, with positive selfrecurrence within each unit, and negative lateral inhibitory connections between units.
Positive self- feedback is used to integrate the valences produced by an action over time,
and lateral inhibition produces negative feedback from other actions. The third layer
computes the preference state for option i from a set of n options according to the linear
dynamic system:
Pi(t+h) = s⋅Pi(t) + v i(t+h) – Σ k ≠i sik ⋅Pk (t) .

(3)

Conceptually, the new state of preference is a weighted combination of the previous state
of preference and the new input valence. The initial preference state, Pi(0), at the start of
a decision problem, represents a preference recalled from past experience. This is used to

<-----Page 11----->Computational Models 12
explain carry over effects from previous decisions or past experience, such as the status
quo effect (Samuelson & Zeckhauser, 1988).
Inhibition is also introduced from the competing alternatives. We assume that the
strength of the lateral inhibition connection is a decreasing function of the dissimilarity
between a pair of alternatives. For example, in Table 1, options A and C are more
dissimilar than options A and B, and so the lateral inhibition between A and C would be
smaller than that between options A and B. Lateral inhibition is commonly used in
artificial neural networks and connectionist models of decision making to form a
competitive system in which one option gradually emerges as a winner dominating over
the other options (cf. Grossberg, 1988; Rumelhart & McClelland, 1986). As shown later
in this chapter, this concept serves a crucial function for explaining seve ral paradoxical
phenomena of preferential choice.
In summary, a decision is reached by the following deliberation process: as
attention switches from one event to another over time, different affective values are
probabilistically selected, and these values are compared across actions to produce
valences, and finally these valences are integrated into preference states for each action.
This process continues until the preference for one action exceeds a threshold criterion, at
which point in time the winner is chosen. Formally, this is a Markov process, and matrix
formulas have been mathematically derived for computing the choice probabilities and
distribution of choice response times (for details, see Busemeyer & Townsend, 1992;
Busemeyer & Diederich, 2002; Diederich & Busemeyer, 2003). Alternatively, Monte
Carlo computer simulation can be used to generate predictions from the model.

<-----Page 12----->Computational Models 13
(However, all of the predictions presented below were computed from the matrix
formulas).
To illustrate the dynamic behavior of the model, consider a simple binary choice
between a gamble and a sure thing. Suppose values for options A and B in Table 1 are set
equal to the following: m11 = .96, m12 =0, m21 = .40, m22 = .40. With these values, option A
can be viewed as a risky gamble, and option B can be viewed as a sure thing. Also
assume an equal probability of attending to events g and b, i.e., Pr[Wg (t) = 1] = Pr[Wb(t) =
1] = .50. The variance of irrelevant dimensions (variance of ε ) was set to zero, the self
feedback was set to s = 1, and the lateral inhibition was set to sAB = sBA = .01.
Under these assumptions, we computed the choice probabilities and the mean
deliberation times, for a wide range of threshold parameters (θ ranged from .20 to 8.0).
Figure 3 plots the relation between choice probability and mean decision time for option
A, the gamble, as a function of the threshold parameter. Both decision time and choice
probability increase monotonically with the threshold magnitude. Busemeyer (1985)
presents empirical evidence supporting these dynamic predictions for choices between a
gamble and a sure thing under various time pressure conditions.

<-----Page 13----->Computational Models 14
Figure 3: Predictions from decision field theory for binary choice

What do computational models contribute to decision theory?
Computational models are a lot more complex than the algebraic models
commonly used by decision theorists. One could argue that computational models are too
microscopic in their view, and they have little to show for their increased cost in
complexity. Can computational models provide a gain in explanatory power that has not
been achieved by the algebraic models? To answer this question, we will review a set of
empirical phenomena that have resisted a coherent explanation by their algebraic
counterparts.
To review these empirical phenomena within a common framework, it will be
helpful to place the example decision problem, shown in Table 1, into a two dimensional
representation, shown in Figure 4 below. The first dimension represents the evalua tion of

<-----Page 14----->Computational Models 15
the options from the perspective that the offender is corrigible, and the second dimension
represents the evaluation of the options from the perspective that the offender is
incorrigible. Consider option A from Table 1: From the perspective that the offender is
corrigible, then option A has a very high value; but from the perspective that the offender
is incorrigible, then option A has a very low value. Thus option A is high on the first
dimension and low on the second. Alternatively, option C has a low value from the
corrigible perspective, but option C has a high value from the incorrigible perspective.
Similarly, option B is midway between options A and C. We can also imagine other
possible options in this space, which are variations of those shown in Table 1. Option D
is another penalty program that is even more severe than option C; and option F is severe
Figure 4: Two dimensional Representations of Actions

Incorrigible

D
F C

B

A

Corrigible

like option C, but it is deficient, perhaps because there is less security at that institution.
These examples will be used to illustrate the essential properties of the empirical
phenomena reviewed below.

<-----Page 15----->Computational Models 16
Similarity effect. This refers to the effect, on choice probabilities, produced by
adding a competitive option D to an earlier choice set containing only A and C, where
option D is very similar to option C. Suppose that in a binary choice between A and C,
options A and C are chosen equally frequently so that Pr[ C | {A,C} ] = Pr[ A | {A,C}].
Adding a new option D to this choice set, mainly takes away probability from the nearby
option C, and leaves the probability of choosing option A unaffected. The empirical
result is that the probability ordering for A and C changes from equality with the binary
choice set, to Pr[ A | {A,C,D} ] > Pr[ C | {A,C,D} ] for the triadic choice set, producing a
violation of a choice principle called independence of irrelevant alternatives (see
Tversky, 1972, for a review). This robust empirical finding eliminates a large class of
probabilistic choice models called simple scalability models, which includes for example,
Luce’s (1959) ratio of strength model. Tversky (1972) elegantly explained these results
with a theory he called the elimination by aspects model of choice. Tversky (1972) also
proved that the elimination by aspects model satisfies another important choice principle
called regularity, which is considered next.
Attraction effect. This refers to the effect, on choice probabilities, of adding a
decoy option F to an earlier choice set containing only options A and C, where the decoy
F is similar to, but also dominated by, option C. Suppose, once again, that in a binary
choice between A and C, options A and C are chosen equally frequently so that
Pr[C|{A,C}] = .50. A second robust finding is that adding the decoy option F to this
choice set enhances the probability of the nearby dominant option C, so that
Pr[C|{A,C,F}] > Pr[C|{A, C}], which produces a violation of the regularity principle
(Huber, Payne, & Puto, 1982; see Heath & Chatterjee, 1995, for a review). Consequently,

<-----Page 16----->Computational Models 17
this result cannot be explained by Tversky’s (1972) elimination by aspects model. This
violation of regularity also rules out a large class of random utility models of choice
(Luce & Suppes, 1965), including Thurstone’s (1959) preferential choice theory.
Compromise effect. This refers to the effect, on choice probabilities, of adding an
intermediate option B to an earlier choice set containing only two extreme options A and
C, where the compromise B is midway between the two extremes. Suppose, that all the
binary choices are equal so that Pr[ A | {A,B) ] = Pr[ A | {A,C) ] = Pr[ B | {B,C) ] = .50.
A third robust finding is that adding the compromise option B to a set containing A and C
enhances the probability of the compromise option so that Pr[ B | {A,B,C} ] >
Pr[A|{A,B,C}] = Pr[ C | {A,B,C}], which is another violation of the independence
between irrelevant alternatives principle (Simonson, 1989; see Tversky & Simonson,
1993 for a review). Tversky and Simonson (1993) proposed a context-dependent
preference model based on the principle of loss aversion to explain the attraction and
compromise effects. However, the context-dependent preference model cannot account
for the similarity effect (see Roe et al., 2001, for a proof). Thus no model was proposed
to account for all three simultaneously.
A common explanation. Decision field theory provides an explanation for all
three phenomena using a common set of principles (see Roe et al., 2001, for details). In
other words, we do not need to change any of the assumptions of the model across
phenomena, and neither do we need to change any of the model parameters. The same
assumptions always apply, and the same parameters can be used to predict all three
effects. The mathematical basis for these predictions is derived elsewhere (see Roe et al.,
2001; Busemeyer & Diederich, 2002), and here we only present an intuitive discussion.

<-----Page 17----->Computational Models 18
First consider the similarity effect -- that is, the effect of adding option D to an
earlier set containing A and C. The attention-switching property is essential for
explaining this effect. On the one hand, whenever attention is focused on the corrigible
event (corresponding to the first dimension in Figure 4), then option A alone gets a large
positive advantage, while options C and D both have negative valences; on the other
hand, whenever attention is focused on the incorrigible event (corresponding to the
second dimension in Figure 4), then both options C and D have positive valences, while
option A gets a large negative valence. If an individual happens to pay more attention to
the corrigible event, then option A will tend to be chosen; but if an individual happens to
pay more attention to the incorrigible event, then either option C or option D tend to be
chosen. Therefore, option D only takes away probability from its neighboring option, C,
and it does not affect the probability of choosing the more distant option, A.
Next consider the attraction effect. In this case the lateral inhibition mechanism
serves a crucial purpose. Neuroscientists long ago established the fact that the strength of
lateral inhibitory connections decrease as a function of distance, and this property is
responsible for generating contour and edge enhancement effects in vision (cf.
Cornsweet, 1970). According to decision field theory, lateral inhibition produces an
attraction effect for preference in the same way that it produces an edge enhancement
effect for vision. During deliberation, the preference state for the dominated alternative F
is driven toward a negative state because it competes with the nearby dominant
alternative C. The negative preference state associated with option F feeds back through a
negative inhibitory connection to option C, producing a bolstering (disinhibitory) effect
on option C. This bolstering effect is not applied to option A because it is too distant from

<-----Page 18----->Computational Models 19
F, and the lateral inhibitory link is too weak. Thus option C shines out by being close to
an unattractive alternative, F.
Note that the attention switching and lateral inhibition processes are assumed to
be operating all the time for both the similarity and attraction effects. These two
components operate in synchrony to generate both effects. As a matter of fact, it is the
interaction between these two processes that is essential for producing the compromise
effect. In this case, if attention happens to focus on some irrelevant features favoring the
compromise option, B, then this sends lateral inhibition to the neighboring extreme
options A and C, decreasing their strength, which then builds up an advantage for the
compromise option.
The predictions for all three effects were computed from decision field theory as
follows. We simply set the values (mij in Equation 1) proportional to the coordinates
shown in Figure 4, and the probabilities of attending to each dimension were equal
(Pr[Wg (t) = 1] = Pr[Wb (t) = 1] = .50). The self feedback loop coefficient was set to s =
.94, the lateral inhibitory coefficient for nearby options (e.g., sCD ) was set to .04, and the
lateral inhibitory coefficient for distant options (e.g., sAC ) was set to .001. The standard
deviation of the error, ε, due to irrelevant dimensions was set equal to 1.25. Figure 5
shows the predictions for the triadic choice probabilities plotted as a function of
deliberation time, separately for each effect. As can be seen in this figure, a common set
of assumptions, and exactly the same parameters, reproduces all three effects.

<-----Page 19----->Computational Models 20

Figure 5: Predictions computed from decision field theory

An interesting prediction that follows from the above explanations for the
attraction and compromise effects is that they should become stronger as deliberation
time increases. In other words, if decision makers are encouraged to deliberate longer,
then the attraction and compromise effects will increase. This is because lateral inhibitory
effects grow in strength during deliberation. Two experiments have now been reported
that confirm these dynamic predictions of the model (Simonson, 1989; Dhar, Nowlis, &
Sherman, 2000).
Loss Aversion. An influential article by Tversky and Kahneman (1991) provides
the most compelling evidence for loss aversion. The basic ideas are illustrated in Figure
6, where each letter shown in the figure represents a choice option described by two

<-----Page 20----->Computational Models 21
attributes; such as for example, consumer products that vary in size and quality, or jobs
that vary in salary and interest. In this case, option X is high on dimension 1 but low on
dimension 2, whereas option Y is low on dimension 1 but high on dimension 2.
Figure 6: Options used to examine loss aversion

Sy

Dimension 2

Y
Ry

Rx

X
Sx

Dimension 1

The first study manipulated a reference point, using either option Rx or Ry . Under
one condition, participants were asked to imagine that they currently owned the
commodity Rx , and they were then given a choice of keeping Rx or trading it for either
commodity X or commodity Y. From the reference point of Rx , option X has a small
advantage on dimension 1 and no disadvantage on dimension 2, whereas Y has both large
advantages (dimension 2) and disadvantages (dimension 1). Under these conditions, Rx
was rarely chosen, and X was strongly favored over Y. Under another condition,
participants were asked to imagine that they owned option Ry , and they were then given a
choice of keeping Ry or trading it for either X or Y. From the reference point of Ry , Y has
a small advantage and no disadvantages, whereas X now has both large advantages and

<-----Page 21----->Computational Models 22
disadvantages. Under this condition, Ry was rarely chosen again, but now Y was slightly
favored over X. (The smaller effect using Ry may indicate that dimension 2 was less
important than dimension 1.) Tversky and Kahneman (1991) interpreted this pair of
results as a loss aversion effect, because X was favored when Y entailed large losses
relative to the reference point Rx , but the opposite occurred when X entailed large losses
relative to the reference point Ry .
Decision field theory provides an explanation for this loss aversion effect through
the lateral inhibition mechanism. To derive predictions from decision field theory, we
simply set the values (mij in Equation 1) proportional to coordinates of the options in
Figure 6. We set the probability of attending to the first dimension equal to .55, and the
probability of attending to the second dimension equal to .45. The remaining parameters
were the same as used to generate Figure 5. These predictions are shown in Figure 7,
which shows the probability of the triadic choices as a function of deliberation time,
separately for the two reference point conditions. As can be seen in this figure,

<-----Page 22----->Computational Models 23
Figure 7: Decision field theory predictions for loss aversion effect.

decision field theory reproduces the loss aversion effect  that is, the change in
preference for option X relative to Y depending on the reference point. It is important to
note that exactly the same parameters are used for both reference point conditions. This
reversal of preference does not depend on the probability of attending to each dimension
if we set the probabilities equal to .50 then the reversal becomes even stronger,
although symmetric in size. In fact, the result depends primarily on the lateral inhibition
parameter if it is set to zero, then the effect disappears.
The second study also manipulated a reference point, but in this case, using either
option Sx or Sy . In one condition, participants were asked to imagine that they trained on

<-----Page 23----->Computational Models 24
job Sx , but that job would end, and they had to choose between two new jobs X or Y.
From this reference point, job X has small advantages and disadvantages over Sx ,
whereas Y has large advantages and disadvantages. Under these conditions, option X was
strongly favored over option Y. In a second condition, participants were asked to imagine
that they trained on job Sy , and in this case, preferences reversed, and option Y was
strongly favored over option X. Tversky and Kahneman (1991) also interpreted these
results as a loss aversion effect.
To apply decision field theory to this study, we assume that each option is
described by three dimensions: the values of the first two dimensions (e.g., salary and
interest) are taken from the positions of the options shown in Figure 6, and the third
dimension represents job availability. Jobs X and Y both have a positive value on
dimension 3 (they are available), whereas jobs Sx and Sy both have negative values on
dimension 3 (they are no longer available). For example, option Sx is assigned a slightly
higher value on dimension 1 than option X, a slightly lower value on dimension 2 than
option X, and it has a large negative value on dimension 3. We assumed an equal
probability of attending to each of the three dimensions, and the remaining parameters
were the same as used to generate Figure 5. The asymptotic choice probability results,
predicted the theory, are summarized in Table 2, below.

<-----Page 24----->Computational Models 25
Table 2: Predictions Computed from Decision Field Theory
Sx Reference Point

Sy Reference Point

Option

Choice Probability

Choice Probability

X

.87

.13

Y

.13

.87

S

0

0

As can be seen in the table, decision field theory again reproduces the reversal in
preference as a function of the reference point. In sum, we find that both loss aversion
effects, as well as attraction and compromise effects, all can be derived from the lateral
inhibitory mechanism of decision field theory.
Endowment effect. There are other phenomena that are often interpreted in terms
of loss aversion (cf. Tversky & Kahneman, 1991), including both the endowment effect
as well as differences between willingness to buy versus willingness to pay. Kahneman,
Knetsch, and Thaler (1990) gave one group of subjects a mug and asked them how much
they would be willing to pay to give up the mug, whereas another group was simply
given some money and asked how much they would be willing to pay to buy the mug.
They found that subjects were willing to buy the mug for only about $3, but they were
asking a much higher price of $7 to sell the mug. This price difference is interpreted as
the loss aversion effect produced by an owner giving up his or her mug. As Tverksy &
Kahneman (1991) noted, the endowment effect can be viewed a special case of a more
general finding of disparities between the price individuals are willing to accept to sell

<-----Page 25----->Computational Models 26
something they own (WTA or selling prices), versus the price they are willing to pay to
acquire something do not own (WTP or buying prices).
At first glance, one might argue that differences between buying and selling
prices are simply a strategic effect: a person may deliberately underestimate the buying
price and overestimate the selling price to gain an advantage. But this simple explanation
implies that buying and selling prices would still produce the same rank orders. In fact,
this is not the case. Birnbaum, Yeary, Luce, & Zhou (2002) review several studies that
report preference reversals between buying versus selling prices. For example, Birnbaum
and Sutton (1992) presented subjects with the following two gambles: gamble G gives a
.5 probability of winning $96, otherwise $0; gamble F gives a .5 probability of winning
$48, otherwise $36 dollars. On the average, subjects gave a higher buying price to
gamble F than gamble G, but at the same time they gave a higher selling price to gamble
G than gamble F. Birnbaum and Sutton (1992) explained these effects as a change in
decision weight that depends on the buyer or seller point of view.
This type of preference reversal is predicted by decision field theory even when
the inputs to the process used to produce buying and selling prices are based on a
common set of weights and values. The reversals emerge from the dynamic process used
to select the prices. A brief presentation of the computational model used in decision field
theory to select prices for gambles is presented below (see Busemeyer & Goldstein, 1992;
and Townsend & Busemeyer, 1995, for more details).
The basic idea is that prices are selected by a series of covert comparisons (refer
to Figure 8). To find a price equivalent to a gamble, the decision maker must search for a
candidate that produces an indifference response. During each step of this search process,

<-----Page 26----->Computational Models 27
the decision maker compares a candidate price to the gamble, and this comparison may
result in one of three judgments: if the candidate price is preferred, then the price is
decremented by a small amount and the search continues (a left transition in Figure 8); if
the gamble is preferred, then the price is incremented by a small amount and the search
continues (a right transition in Figure 8); if the comparison produces an indifference
judgment, then the search stops and the candidate price is reported as the price (a
downward transition in Figure 8). We simply use decision field theory to perform this
comparison process, which provides the probabilities for the three judgments at each
stage of the search process (see Busemeyer & Goldstein, 1992, for details). Then
Markov chain theory is used to determine the distribution of prices generated by the
search process (see Busemeyer & Townsend, 1992, for the mathematical derivations).
Figure 8: Illustration of the search process for finding the price of a gamble.

Start search for buying price

36

38

40

42

44

46

48

Exit search for buying price

When asked to find a certainty equivalent for a gamble, we assume that the search
process starts near the middle of the feasible set of prices in an attempt to minimize the
number of steps needed to find the price equivalent. When asked to find a maximum
buying price for a gamble, we assume that the search process starts near the minimum of

<-----Page 27----->Computational Models 28
the feasible set of prices, biased away from paying excess money. Finally, when asked to
find a minimum selling price, we assume that the search process starts near the maximum
of the feasible set of prices, biased toward saving extra money.
This simple scheme was used to find buying and selling prices for gambles F and
G used by Birnbaum and Sutton (1992). In this case, we simply set the values (mij in
Equation 1) equal to the stated dollar values of the gambles, and we simply set the
probability of attending to each event equal to the stated probabilities. Figure 9 shows the
distribution of prices produced by this model for buying prices (top panel) and selling
prices (bottom panel).

<-----Page 28----->Computational Models 29
Figure 9: Predicted Buying Prices (top panels) and Selling Prices (bottom panels)

As can be seen in Figure 9, the predicted buying prices (or WTP) are lower than
the predicted selling prices (or WTA), accounting for the well known disparity between
these measures. More importantly, preference reversals occur for buying and selling
prices: referring to the top panels, the mean buying price for gamble F is larger than the
buying price for gamble G; referring to the bottom panels, the mean selling price for
gamble G is greater than the mean selling price for gamble F.
There is an intuitive explanation for these computational results. The price for
gamble F is restricted to a small range, which makes the price insensitive to changes in
the starting position produced by the selling or buying price task. However, the price for
gamble G has a wide range of possible values, and it is more strongly affected by the

<-----Page 29----->Computational Models 30
starting position produced by buying and selling tasks. This idea is similar to earlier
anchoring and adjustment models of preference reversal (e.g., Goldstein & Einhorn,
1987). However, unlike these earlier anchoring and adjustment theories, the amount of
adjustment is not a free parameter in decision field theory, because it is derived from the
dynamics of the search process.
Preference reversals also occur between prices and choices (Lichtenstein and
Slovic, 1971; see Slovic and Lichtenstein, 1983, for a review). Decision field theory can
also reproduce these types of preference reversals by using a common set of weights and
values as inputs into the choice and price processes (Busemeyer & Goldstein, 1992).
Decision field theory can also explain discrepancies reported by Hershey and Shoemaker
(1985) between certainty equivalents and probability equivalents for gambles (Townsend
& Busemeyer, 1995).
Preference reversals under time pressure. Up to this point we ha ve argued that
computational models, such as decision field theory, provide a deeper level analysis of
several traditional effects from the decision- making literature. Now we turn to new
predictions that arise from the dynamic nature of the model.
There is a growing body of evidence showing that it is possible to reverse an
individual’s preference by changing the amount of time given to make the decision. For
example, Svenson and Edland (1987) asked people to choose among apartments under
short vs. long time deadlines. Under the short time deadlines, the lower rent apartment
was chosen more frequently; but under longer time deadlines, they preferred apartments
with higher rents that provided other attractive features. Diederich (2003) extended these
findings by asking individuals to choose between two gambles, and each gamble could

<-----Page 30----->Computational Models 31
yield either a monetary reward or a blast of noise punishment. Several individuals
reversed their preferences under time pressure. For example, if avoiding noise was more
important than winning money, then the low noise gamble was chosen more frequently
under short deadlines, but the high monetary payoff gamble was chosen more frequently
under the longer deadlines.
A common explanation for these effects is that decision makers switch strategies
(Payne, Bettman, & Johnson, 1993). Under short deadlines, it is hypothesized that
decision makers use a non-compensatory heuristic strategy such as a lexicographic rule or
an elimination by aspects rule. These strategies are quick and easy to execute but are not
very accurate in the sense of maximizing weighted additive utility. Under longer
deadlines, decision makers can use the more time consuming compensatory strategy such
as a weighted additive rule which increases accuracy.
Sequential sampling models provide an alternative view, which simply assumes
that individuals reduce their threshold criterion under time pressure. Diederich (1997)
developed a multi –attribute version of decision field theory, which assumes individuals
sequentially sample information over time, but they begin processing the more important
dimension, and later switch to process the other less important dimensions. Under short
deadlines, a low threshold is used, only the most important dimension tends to get
processed, and so this dimension alone determines the choice. Under long deadlines, a
high threshold is used, and now there is sufficient time to process additional attributes. If
these additional attributes disagree with the most important attribute, then this additional
processing can reverse the direction of the evolving preference state. Diederich (1997)

<-----Page 31----->Computational Models 32
showed that this model provided a very accurate quantitative account of her preference
reversals under time pressure.
Are computational models testable?
One might argue that computational models are so complex that they cannot be
empirically tested. On the contrary, it is possible to rigorously test these models both
quantitatively as well as qualitatively. For example, to quantitatively test decision field
theory, one can estimate all of the model parameters from a set of binary choice
probabilities, and then use these same parameters to predict other measures of preference
including choice response times, triadic choice probabilities, and buying/selling prices
(see, for examples, Dror, Busemeyer, & Basola, 1999; Diederich & Busemeyer, 1999;
Diederich, 2003a; and Diederich, 2003b). Qualitative tests of the theory are also possible:
on the one hand, decision field theory predicts violations of strong stochastic transitivity,
but on the other hand it predicts that weak stochastic transitivity will be satisfied
(Busemeyer & Townsend, 1993). In agreement with the first qualitative prediction,
violations of strong stochastic transitivity frequently occur (see Mellers & Biagini, 1994,
for a review); but contrary to the second qualitative prediction, violations of weak
stochastic transitivity also have been reported under special conditions (see Gonzalez –
Vallejo, 2002, for a recent review and explanation for this result).
What are some alternative computational models?
Up to this point we have highlighted one computational model, decision field
theory, but there are a growing number of new computational models for decision
making. Three of these are briefly described below.

<-----Page 32----->Computational Models 33
Competing accumulator model. Usher and McClelland (2001, 2001) have recently
proposed a competing accumulator model that shares many assumptions with decision
field theory, but departs from this theory on a few crucial points. The connectionist
network of the competing accumulator model is virtually the same as shown in Figure 2.
However, this model makes different assumptions about (a) the evaluations of advantages
and disadvantages (what we call valences in Equation 2), and (b) the dynamics of
response activations (what we call preference states in Equation 3). First, they adopt
Tversky and Kahneman’s (1991) loss aversion hypothesis so that disadvantages have a
larger impact than advantages. Using our own notation, the valence for alternative i ∈
{A,B,C}, and i ≠ j ≠ k, is computed as follows:
v i(t) = F[Ui(t) – Uj(t)] + F[Ui(t) - Uk (t)] + c

(4)

Where F(x) is a nonlinear function that satisfies the loss aversion properties presented in
Tversky & Kahneman (1991). Thus, rather than deriving loss aversion effects indirectly
from the dynamics as we have done, they build this effect directly into the model.
Second, they use a nonlinear dynamic system that restricts the response activation to
remain positive at all times, whereas we use a linear dynamical system that permits
positive and negative preference states. The non-negativity restriction was imposed to be
consistent with their interpretation of response activations as neural firing rates.
Usher and McClelland (2002) have shown that the competing accumulator model
can account for the main findings concerning the similarity effect, the attraction effect,
and the compromise effect, using a common set of parameters. Like decision field theory,
this model uses an attention switching mechanism to produce similarity effects, but
unlike decision field theory, this model uses loss aversion to produce the attraction and

<-----Page 33----->Computational Models 34
compromise effects. Further research is needed to discriminate between these two
models.
ECHO model. Guo and Holyoak (2002; see also Glockner, 2002) proposed a
different kind of connectionist network, called ECHO, adapted from Thagard and
Millgram (1995). Figure 10 illustrates the model for two attributes and three options. At
the far left in this figure, there is a special node, called the external driver, representing
the goal to make a decision, which is turned on when a decision is presented. The driver
node is directly connected to the attribute nodes, with a constant connection weight. Each
attribute node is connected to an alternative node with a bidirectional link, which allows
activation to pass back and forth from the attribute node to the alternative node.
Figure 10: Illustration of the Echo Model for 2 dimensions and 3 alternatives

A
d1

B

D

d2
C

<-----Page 34----->Computational Models 35
The connection weight between an attribute node and an alternative node is determined
by the value of the alternative on that attribute (our mij). There are also constant lateral
inhibitory connections between the alternative nodes.
The decision process works as follows. Upon presentation of a decision problem,
the driver is turned on and applies constant input activation into the attribute nodes, and
each attribute node then activates each alternative node (differentially depending on
value). Then each alternative node provides positive feedback to each attribute node, and
negative feedback to the other alternative nodes. Activation in the network evolves over
time according to a nonlinear dynamic system, which keeps the activations bounded
between zero and one. The decision process stops as soon as the changes in activations
fall below some threshold. At that point, the probability of choosing an option is
determined by a ratio of activation strengths.
Guo and Holyoak (2002) used this model to explain the similarity and attraction
effects. To account for these effects, they assumed that the system first processes the two
similar alternatives, and during this time, the lateral inhibition produces a competition
between these two options. After this initial comparison process is completed, the system
processes all three options, including the dissimilar option. In the case of the similarity
effect, the initial processing lowers the activation levels of the two similar options; in the
case of the attraction effect, the initial processing enhances the activation level of the
dominating option. Thus lateral inhibition between alternatives plays a crucial role for
explaining both effects. Although the model has been shown to account for the similarity
and attraction effects, at this point, it has not been shown to account for the compromise
effect or loss aversion effects.

<-----Page 35----->Computational Models 36
The ECHO model makes an important prediction that differs from both decision
field theory and the competing accumulator model. The ECHO model predicts that as one
option becomes dominant during deliberation, this will enhance the activation of the
attribute nodes favored by the dominant alternative. The enhancement is caused by the
feedback from the alternative node to the attribute node, which tends to bias the
evaluation of the attributes over time. This property of the model is related to the
dominance-seeking principle included in other decision- making theories (Montgomery,
1989; Svenson, 1992). Holyoak and Simon (1999) tested this hypothesis by asking
individuals to rate attribute importance at various points during deliberation, and they
report evidence for increases in the importance of attributes that are favored by the
dominant alternative during deliberation.
Affective Balance Theory. Grossberg and Gutowski (1987) presented a dynamic
theory of affective evaluation based on an opponent processing network called a gated
dipole neural circuit. Habituating transmitters within the circuit determine an affective
adaptation level, or reference point, against which later events are evaluated. Neutral
events can become affectively charged either through direct activation or antagonistic
rebound within the habituated dipole circuit. This neural circuit was used to provide an
explanation for the probability weighting and value functions of Kahneman and
Tversky’s (1979) prospect theory, and the affective dynamics of addiction and
withdrawal symptoms hypothesized by Solomon and Corbit (1974).
Computational models of inference. Although this chapter focused on
computatio nal models of preference, there are also new developments for probabilistic
inference and prediction. Dougherty, Gettys, and Ogden (1999) developed an instance-

<-----Page 36----->Computational Models 37
based memory model for probability judgments that accounts for overconfidence effects
and conjunctive fallacies. Read, Vanman, and Miller (1997) developed a connectionist
model for social inference judgments which is closely related to the ECHO model used
by Holyoak and Simon (1999). Busemeyer, Byun, Delosh, and McDaniel (1997)
proposed a connectionist model for cue - criterion prediction tasks.
Concluding Comments
During the past 40 years, decision theorists have let the utility function do most of
the work of explaining choice results. By positing the simplest possible hypotheses about
the choice processes, all the explanatory power falls upon the utility function itself.
Consequently, during this 40-year span of time, the forms of utility functions have
become increasingly complex (see Luce, 2000, for a review). However, it is possible that
if theorists work harder in understanding the complexities inherent in the choice
processes, then the underlying utility representations may become simpler and more
coherent. As others have argued (cf. Plott, 1996), it may be too early for decision
theorists to accept the conclusion that utilities are constructed on the fly for every
variation of task and context, and instead it may be possible to retain a stable underlying
value system that is expressed through a very complex choice process.

<-----Page 37----->Computational Models 38

References
Aschenbrenner, K. M., Albert, D., & Schmalhofer, F. (1984). Stochastic choice
heuristics. Acta Psychologica, 56(1-3), 153-166.

Ashby, F. G. (2000). A stochastic version of general recognition theory. Journal of
Mathematical Psychology, 44, 310-329.

Birnbaum, M. H., Yeary, S., Luce, R. D., & Zhou, L. (2002, submitted). Contingent
Valuation, Endowment, or Viewpoint Effects: Testing properties in judgments of buying
and selling prices of lotteries.

Birnbaum, M. H., & Sutton, S. E. (1992). Scale convergence and utility measurement.
Organizational Behavior and Human Decision Processes, 52, 183-215.

Busemeyer, J. R. (1985). Decision making under uncertainty: Simple scalability, fixed
sample, and sequential sampling models. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 11, 538-564.

Busemeyer, J. R. & Diederich, A. (2002). Survey of decision field theory. Mathematical
Social Sciences, 43, 345-370.

<-----Page 38----->Computational Models 39
Busemeyer, J. R. & Goldstein, W. M. (1992). Linking together different measures of
preference: A dynamic model of matching derived from decision field theory.
Organizational Behavior and Human Decision Processes, 52, 370-396.

Busemeyer, J. R. & Townsend, J. T. (1992). Fundamental derivations from decision field
theory. Mathematical Social Sciences, 23, 255-282.

Busemeyer, J. R. & Townsend, J. T. (1993). Decision Field Theory: A dynamic cognition
approach to decision making. Psychological Review, 100, 432-459.

Busemeyer, J. R., Townsend, J. T., & Stout, J. C. (2002). Motivational underpinnings of
utility in decision making: Decision field theory analysis of deprivation and satiation. To
appear in S. Moore (Ed.) Emotional Cognition. Amsterdam: John Benjamins.

Cornsweet, T. N. (1970) Visual Perception. New York: Academic Press.

DeGroot, M.H. (1970). Optimal statistical decisions. New York: McGraw-Hill.

Dhar, R., Nowlis, S. M. & Sherman, S. J. (2000). Trying hard or hardly trying: An
analysis of context effects in choice. Journal of Consumer Psychology, 9, 189-200.

Diederich, A. (1997). Dynamic stochastic models for decision making under time
constraints. Journal of Mathematical Psychology, 41(3), 260-274.

<-----Page 39----->Computational Models 40

Diederich, A. (2003). Multi-attribute decision field theory account for decision making
under time pressure. Psychonomic Bulletin and Review.

Diederich, A. (2003). Decision making under conflict: Decision time as a measure of
conflict strength. Psychonomic Bulletin and Review.

Diederich, A. & Busemeyer, J. R. (1999). Conflict and the stochastic dominance principle
of decision making. Psychological Science, 10, 353-359.

Diederich, A. & Busemeyer, J. R. (2003). Simple matrix methods for analyzing diffusion
models of choice probability, choice response time, and simple response time. Journal of
Mathematical Psychology.

Dougherty, M. R. P., Gettys, C. F., & Ogden, E. E. (1999). MINERVA-DM: A memory
process model for judgements of likelihood. Psychological Review, 106, 108-209.

Dror, I. E., Busemeyer, J. R., & Basola, B. (1999). Decision making under time pressure:
An independent test of sequential sampling models. Memory and Cognition, 27, 713-725.

Fischer, G. W., Jia, J. & Luce, M. F. (2000). Attribute conflict and preference
uncertainty: The RandMAU model. Management Science, 46, 669-684.

<-----Page 40----->Computational Models 41
Glockner, A. (2002). The maximizing consistency heuristic: Parallel processing in human
decision making. Diplomarbeit, Universitat Heidelberg.

Gold, J. I., & Shadlen, M. N. (2001). Neural computations that underlie decisions about
sensory stimuli. Trends in Cognitive Neuroscience, 5, 10-16.

Gold, J. I., Shadlen, M. N. (2002) Banburismas and the brain: Decoding the relationship
between sensory stimuli, decisions, and reward. Neuron, 36, 299-308.

Goldstein, W. & Einhorn, H. J. (1987). Expression theory and the preference reversal
phenomena. Psychological Review 94, 236-254.

Gonzalez-Vallejo, C. (2002). Making trade-offs: A probabilistic and context-sensitive
model of choice behavior. Psychological Review, 109(1), 137-155.

Gratton, G. Coles, M. G., Sirevaag, E. J., Erickson, C. J., & Donchin, E. (1988). Pre- and
poststimulus activation of response channels: A psychophysiological analysis. Journal of
Experimental Psychology: Human Perception and Performance, 14, 331- 344.

Grossberg, S. (1988). Neural Networks and Natural Intelligence. Cambridge, MA: MIT
Press.

<-----Page 41----->Computational Models 42
Grossberg, S. & Gutowski, W. E., (1987). Neural dynamics of decision making under
risk: Affective balance and cognitive-emotional interactions. Psychological Review,
94(3), 300-318.

Guo, F. Y. & Holyoak, K. J. (2002). Understanding similarity in choice behavior: A
connectionist model. Proceedings of the Cognitive Science Society Meeting.

Heath, T. B. & Chatterjee, S. (1995). Asymmetric decoy effects on lower - quality versus
higher-quality brands: Meta analytic and experimental evidence. Journal of Consumer
Research, 22, 268-284.

Hershey, J.C. & Schoemaker, P.J.H. (1985). Probability versus certainty equivalence
methods in utility measurement: Are they equivalent? Mangement Science, 31, 12131231.

Holyoak, K. J. & Simon, D. (1999). Bidirectional reasoning in decision making by
constraint satisfaction. Journal of Experimental Psychology: General, 128(1), 3-31

Huber, J., Payne, J. W., & Puto, C. (1982). Adding asymmetrically dominated
alternatives: Violations of regularity and the similarity hypothesis. Journal of Consumer
Research, 9(1), 90-98.

<-----Page 42----->Computational Models 43
Johnson, J. G. & Busemeyer, J. R. (in press). Rule-based Decision Field Theory: A
dynamic computational model of transitions among decision-making strategies. To
appear in T. Betsch (Ed.) The routines of decision making. Mahwah, NJ: Erlbaum.

Kahneman, D., Knetsch, J., & Thaler, R. (1990). Experimental tests of the endowment
effect and the Coase theorem. Journal of Political Economy, 98(6), 1325-1348.

Kahneman, D. & Tversky, A. (1979). Prospect Theory: An analysis of decision under
risk. Econometrica 47(2), 263-297.

Laming, D. R. (1968). Information theory of choice-reaction times. New York: Academic
Press.

Levin, S. J., & Levine, D. S. (1996). Multiattribute decision making in context: A
dynamic neural network methodology. Cognitive Science, 20, 271-299.

Lichtenstein, S. & Slovic, P. (1971). Reversals of preference between bids and choices in
gambling decisions. Journal of Experimental Psychology, 89, 46-55.

Link, S. W. & Heath, R. (1975). A sequential theory of psychological discrimination.
Psychometrika, 40,77-111.

<-----Page 43----->Computational Models 44
Luce, R. D. (1959). Individual choice behavior: A theoretical analysis. New York:
Wiley.

Luce, R. D. (2000). Utility of gains and losses. Mahwah, NJ: Erlbaum.

Luce, R. D. & Suppes, P. (1965). Preference, utility, and subjective probability. In R. D.
Luce, R. R. Bush, & E. Galanter (Eds.) Handbook of Mathematical Psychology (Vol. 3,
pp. 249-410). New York: Wiley.

Marr, D. (1982) Vision. Cambridge, MA: MIT Press.

Montgomery, H. (1989). From cognition to action: The search for dominance in decision
making. In H. Montgomery, & O. Svenson (Eds.), Process and structure in human
decision making (pp. 23 - 49), New York: Wiley.

Nosofsky, R. M. & Palmeri, T. J. (1997). An exemplar based random walk model of
speeded classification. Psychological Review, 104, 266-300.

Payne, J. W., Bettman, J. R., & Johnson, E. J. (1993). The adaptive decision maker.NY:
Cambridge University Press.

Platt, M. L. (2002) Neural correlates of decisions. Current Opinion in Neurobiology,
12(2), 141-148.

<-----Page 44----->Computational Models 45
Plott, C. R. (1996) Rational individual behavior in markets and social processes: The
discovered preference hypothesis. In K. Arrow, E. Collombatto, M. Perlaman, & C.
Schmidt (Eds.) The Rational Foundations of Economic Behavior London: MacMillian.

Ratcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85, 59-108.

Read, S. J., Vanman, E. J., & Miller, L. C. (1997). Connectionism, parallel constraint
satisfaction and gestalt principles: (Re)introducting cognitive dynamics to social
psychology. Personality and Social Psychology Review, 1, 26 – 53.

Roe, R., Busemeyer, J. R., & Townsend, J. T. (2001) Multi- Alternative Decision Field
Theory: A Dynamic Connectionist Model of Decision-Making. Psychological Review,
108, 370-392.

Rumelhart, D., & McClelland, J. L. (1986) Parallel distributed processing: Explorations
in the microstructure of cognition. (Vol. 1) Cambridge, MA: MIT Press.

Samuelson, W. & Zeckhauser, R. (1988). Status quo bias in decision making. Journal of
Risk and Uncertainty, 1, 7-59.

Schall, J. D. (2001) Neural basis of deciding, choosing, and acting. Nature Reviews:
Neuroscience, 2, 33-42.

<-----Page 45----->Computational Models 46
Simonson, I. (1989) Choice based on reasons: The case of attraction and compromise
effects. Journal of Consumer Research, 16, 158-174.

Slovic, P., and S. Lichtenstein. (1983). Preference reversals: A broader perspective.
American Economic Review, 73, 596-605.

Smith, P. L. (1995). Psychophysically principled models of visual simple reaction time.
Psychological Review, 102(3), 567-593.

Solomon, R. L. & Corbit, J. D. (1974) An opponent process theory of motivation : 1.
Temporal dynamics of affect. Psychological Review, 81, 119-145.

Svenson, O. (1992). Differentiation and consolidation theory of human decision making:
A frame of reference for the study of pre- and post-decision processes. Acta
Psychologica, 80, 143-168.

Svenson, O. & Edland, A. (1987). Change of preferences under time pressure: Choices
and judgments. Scandinavian Journal of Psychology, 28, 322-330.

Thagard, P. & Millgram, E. (1995). Inference to the best plan: A coherence theory of
decision. In A. Ram & D. B. Leake (Eds.), Goal-driven learning (pp. 439-454).
Cambridge, MA: MIT Press.

<-----Page 46----->Computational Models 47
Thurstone, L. L. (1959). The measurement of va lues. Chicago: University of Chicago
Press.

Townsend, J. T., & Busemeyer, J. R. (1995). Dynamic representation of decision- making.
In R. F. Port and T. van Gelder (Eds.) Mind as Motion. Cambridge, MA: MIT press.
Tversky, A. (1969). Intransitivity of preferences. Psychological Review, 76, 31-48.

Tversky, A. (1972). Elimination by aspects: A theory of choice. Psychological Review,
79(4), 281-299.

Tversky, A. & Kahneman, D. (1991) Loss aversion in riskless choice: A reference
dependent model. Quarterly Journal of Economics, 106, 1039-1061.

Tversky, A. & Simonson, I. (1993). Context dependent preferences. Management
Science, 39, 1179-1189.

Usher, M. & McClelland, J. L. (2001) On the time course of perceptual choice: A model
based on principles of neural computation. Psychological Review, 108, 550-592.

Usher, M. & McClelland, J. L. (2002) Decisions, decisions: Loss aversion, information
leakage, and inhibition in multi-attribute choice situations. Unpublished Note.

<-----Page 47----->Computational Models 48
Vickers, D. (1979). Decision Processes in Visual Perception. New York: Academic
Press.

Wallsten, T. S. & Barton, C. (1982). Processing probabilistic multidimensional
information for decisions. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 8, 361-384.

