<-----Page 0----->ORGANIZATIONAL

BEHAVIOR

Competence

AND HUMAN

DECISION

PROCESSES

53, 252-266 (1992)

in Experts: The Role of Task Characteristics
JAMES

SHANTEAU

Kansas State University, Manhattan, Kansas 66506
The previous literature on experts presents two contrasting views. Judgment
and decision research has shown that experts make flawed decisions due, in
part, to the biasing effects of judgmental heuristics. Cognitive science research, in contrast, views experts as competent and different from novices in
nearly every aspect of cognitive functioning. An alternative view developed
here, the Theory of Expert Competence, suggests that both analyses are correct, but incomplete. In particular, the theory assumes competence depends
on five components: (1) a sufficient knowledge of the domain, (2) the psychological traits associated with experts, (3) the cognitive skills necessary to make
tough decisions, (4) the ability to use appropriate decision strategies, and (5) a
task with suitable characteristics. The latter is the focus of this paper. Insufficient attention has been paid to task and domain characteristics in prior
research. Decision researchers have looked primarily at experts in behavioral
domains (e.g., clinical psychology), whereas cognitive investigators have concentrated on experts in static domains (e.g., physics). Thus, the discrepancy in
the conclusions drawn from the two literatures appears to be a function of the
different domains studied. Although similar to approaches such as Cognitive
Continuum Theory, the proposed theory contains several new components. In
addition, the theory has implications both for the analysis of experts and for
the design and use of expert systems. o 1992 Academic press, IIIC.

“Expert0 credito” (Virgil, 19 B.C.).
“No lesson seems to be so deeply inculcated by the experience of life
as that you never should trust experts” (Lord Salisbury, 1877).
These quotes illustrate two facts: First, the topic of experts has been of
interest to writers over the centuries. Second, there is considerable disagreement about the competence of experts. The purpose of this proposal
is to explore expertise from an alternative perspective and to use that
perspective to provide new insights on the competence of experts.
The paper is organized into five sections. The first section summarizes
The research described in this paper was supported in part by grants from the Army
Research Institute, the Department of Health and Human Services, and the Bureau of
General Research at Kansas State University. I thank Geri Dino, Richard Ettenson, and
Gary Gaeth for their insightful contributions during the initial stages of this project. The first
draft of this paper was prepared while the author was serving as Program Director of the
Decision, Risk, and Management Science program of the National Science Foundation.
Address reprint requests to James Shanteau, Department of Psychology, Bluemont Hall,
Kansas State University, Manhattan, KS 66506-5302.
252
0749-5978192$5.00
Copyright 0 1992 by Academic Press, Inc.
AlI rights of reproduction in any form reserved.

<-----Page 1----->COMPETENCE

IN

EXPERTS

253

the prevailing views of experts in the judgment/decision making and cognitive science literatures. The second presents proposed definitions of
“expert” and “competence.” The next develops a new Theory of Expert
Competence, with an emphasis on task characteristics. The fourth section
compares the proposed approach to Cognitive Continuum Theory (Hammond, 1966). The final section considers implications of these observations for analyses of experts and for design of expert systems.
BACKGROUND
Decision-Making

Research

With some exceptions, the judgment and decision-making literature
paints a dismal picture of the ability of experts. Deficiencies have been
reported in nearly every type of decision analysis. The following provides
a brief overview of the literature; for more a detailed account, see Shanteau (1989).
Psychometric analyses revealed that judgments by experts are lacking
in validity (Oskamp, 1965) and reliability (Trumbo, Adams, Milner, &
Schipper, 1962). Similar findings have been reported for a variety of experts, such as agricultural judges (Foss, Wright, & Coles, 1973, medical
doctors (Einhom, 1974), clinical psychologists (Oskamp, 1962), parole
board members (Carroll & Payne, 1976), and court judges (Ebbesen &
Konecni, 1975). Moreover, the experience of experts is not related to
their judging ability (Meehl, 1954).
Studies of probabilistic judgments have reported deficiencies in calibration (Christensen-Szalanski
& Bushyhead, 1981) and coherence
(Chan, 1982). Comparable deficiencies have been reported for various
experts, including physicians (DeSmet, Fryback, & Thombury, 1979),
clinical psychologists (Lichtenstein & Fischhoff, 1977), meteorologists
(Williams, 1951), forecasters (Lichtenstein, Fischhoff, & Phillips, 1982),
and nurses (Grier, 1976).
Another approach to analyzing expert judgment is to examine the
amount of information used in making decisions; presumably, experts
should use all relevant information. Various studies, however, have reported that models of experts reflect surprisingly low information use
(Goldberg, 1970). Underuse of available information has been reported
for criminal court judges (Ebbesen & Konecni, 1975), medical pathologists (Einhom, 1974), and clinical psychologists (Goldberg, 1970).
Not only do experts make use of little information, but also the evidence suggests that their judgments can be described by simple linear
models. After reviewing studies from a variety of domains, Dawes and
Corrigan (1974) concluded “the whole trick is to decide what variables to
look at and then to know how to add.” Thus, expert judgments lack the

<-----Page 2----->254

JAMES

SHANTEAU

complexity expected from superior decision makers. Moreover, experts
apparently are unaware of their shortcomings (Meehl, 1954).
A common explanation for this low level of performance is that experts
often rely on heuristics, which in turn lead to systematic biases (Kahneman, Slavic, 8z Tversky, 1982). Because of heuristic decision strategies,
experts apparently are limited in the sameway as naive subjects (Tversky
dz Kahneman, 1971). “Numerous studies show that intelligent people
have great difficulty judging probabilities, making predictions, and otherwise, attempting to cope with uncertainty. Frequently these difficulties
can be traced to the use of judgmental heuristics” (Slavic, Fischhoff, &
Lichtenstein, 1985).
There have been some exceptions to the general trend of expert incompetence. Weather forecasters’ predictions were reported by Murphy and
Winkler (1977) to be well calibrated. Phelps and Shanteau (1978) found
that livestock judges were capable of using large amounts of information.
Medical doctors were observed by Christensen-Szalanski, Diehr, Bushyhead, and Wood (1982) to make good decisions. Research with auditors
has produced many examples of competent performance (Ashton, 1983).
These instances of strong performance, however, have been largely ignored in the judgment literature (Christensen-Szalanski & Beach, 1984).
Altogether, previous decision making research presents a discouraging
view of the abilities of experts. Kahneman (1991) stated a widely held
conclusion: “There is much evidence that experts are not immune to the
cognitive illusions that affect other people.”
Cognitive-Science Research

A quite different view of experts has emerged from research in cognitive psychology. Studies within this tradition have shown expert superiority over novices in nearly every aspect of cognitive functioning, from
memory and learning to problem solving and reasoning (Anderson, 1981).
Chess masters, for instance, have been found to perceive patterns of play
more effectively (deGroot, 1965) and to have better memory for chess
positions (Chase & Simon, 1973). Experts in physics, mathematics, and
computer programming reveal similar superior skills (Mayer, 1983).
Several themes have emerged from this body of research. First, expertise is domain specific. The special skills of an expert are diminished
outside his/her area of expertise: “Chess experts do not appear to be
better thinkers for all their genius in chess” (Anderson, 1990).Thus, the
thinking of experts is “domain adapted” @latter, 1987).
Second, expertise is acquired through stages of development, somewhat akin to the mental development of children. According to Fitts and
Posner (1967), the first is the “cognitive stage,” where specific facts are
memorized to perform the task. The next is the “associative stage,”

<-----Page 3----->COMPETENCE

IN EXPERTS

255

where connections between successful elements are strengthened. The
last is the “autonomous stage,” where the skills become practiced and
rapid.
Third, experts use different thinking strategies. For instance, novices
have been found to reason backward from the unknowns to the givens in
solving physics problems. Expert physicists, in contrast, reason forward
using stored “functional units” from the givens to the goal (Larkin, 1979).
Therefore, expertise produces more efficient approaches to thinking
about problem solving and decision making (Anderson, 1990).
Fourth, the thinking of experts is more automated (Shiffrin & Schneider, 1977). These automated processes generally operate in parallel and
function somewhat like visual perception or pattern recognition. Novices,
in contrast, rely on controlled processes, which are linear and sequential,
more like deductive reasoning (Larkin, McDermott, Simon, & Simon,
1980).
Because of their special abilities, expert processes are reflected by and
can be studied through verbal protocols. By asking experts to think aloud,
qualitatively rich accounts of an expert’s reasoning processes become
accessible (Ericsson & Simon, 1980). Although other methods have been
proposed (Hoffman, 1987), protocol analyses are commonly used to provide the raw data for building expert systems @latter, 1987).
In total, the cognitive science view is that experts within their domains
are skilled, competent, and think in qualitatively different ways than novices (Anderson, 1981; Chi, Glaser, & Fat-r, 1988). This skill can be tapped
to provide a sufficient basis for building an expert system (Coombs, 1984).
SOME DEFINITIONS
Before trying to resolve these different views of expertise, it is necessary to define several key terms. The definition of expert is an obvious
precondition to any analysis of expertise. Unfortunately, efforts to provide objective definitions have proved elusive. There are almost as many
definitions of “expert” as there are researchers who study them (Hoffman, Shanteau, Burton, Shadbolt, & Akerstrom, 1991). Moreover, numerous hierarchies have been proposed to describe lower and intermediate levels of expertise (e.g., Benner, 1984; Dreyfus & Dreyfus, 1986).
My suggestion (Shanteau, 1987a) is to let those in a domain define the
experts. In every field, there are some who are considered by their peers
to be best at what they do. In some domains this is reflected by official
recognition or job titles. In others, it comes from consensual acclamation.
In my research, experts are operationally defined as those who have been
recognized within their profession as having the necessary skills and abilities to perform at the highest level.
In contrast, a naive decision maker has little or no skill in making

<-----Page 4----->256

JAMES

SHANTEAU

decisions in a specific area. For instance, undergraduate students generally
are naive about the kinds of decisions made by experts. Novices are
intermediate in skill and knowledge; they frequently have studied for
years and may even work at subexpert levels. However, novices lack one
or more of the abilities needed to function as experts. Typically, advanced
(graduate) students are novices in making skilled decisions.
From this view, much research on “experts” in fact has used novices.
Thus, many “expert-novice”
studies are better described as “novicenaive” studies. In addition, it appears that at least some functioning expert systems mistakenly have been based on novices instead of experts
(Levitt, 1991).
Defining the quality or competence of a decision is also difficult. This
would be easy if standards existed for determining what is a good decision
and what is not. Unfortunately, external standards are seldom available
for expert domains-that is why experts were needed in the first place.
Even where objective criteria exist, they can be elusive and subject to
debate. The problem is that standards are defined from subjective opinions of experts (not the other way around). These opinions can shift over
time because circumstances change or experts adopt new standards.
My resolution is to rely on the views of acknowledged experts about
what is a competent decision and what is not. These opinions are backed
up by professional guidelines and commonly accepted standards in the
field. Although there is some danger of circularity, this approach has been
used successfully in many studies of experts.
THEORY OF EXPERT COMPETENCE
In my research, the primary research question has been: What factors
lead experts to do well and what factors lead them to do poorly? My view
is that experts are neither as deficient as suggested in the decision making
literature nor as unique as implied by the cognitive science perspective.
Instead, according to the Theory of Expert Competence, the skills and
abilities that emerge (or do not emerge) in experts depend on five factors:
domain knowledge, psychological traits, cognitive skills, decision strategies, and task characteristics. The specifics of this theory are described
elsewhere (Shanteau, in press); an overview of the key ideas is presented
here.
Having an adequate grasp of domain knowledge is obviously a prerequisite for being an expert. This represents not only textbook knowledge,
but also insights gained from experience in working on real problems.
Based on conversations with experts, their knowledge is generally accessed through stories about past cases (Shanteau, 1984). These anecdotal accounts appear to provide both a mnemonic to remember and a
convenient way to organize vast amounts of information. As such, they

<-----Page 5----->COMPETENCE

IN

EXPERTS

257

are consistent with efforts to build expert systems through “case-based
reasoning” (Kolodner, 1984).
Although knowledge of the domain is necessary, it is not sufficient for
expertise. Many novices know a great deal, maybe even as much as
experts. In other respects, however, they lack what it takes to behave as
experts.
In previous papers (e.g., Shanteau, 1988), I argued that experts often
display a common set of psychological traits. These reflect what Goffman
(1959) describes as “self presentation”-the
creation and maintenance of
a public image. The traits are part of a personal style found in many
experts. These traits include strong self-confidence, excellent communication skills, the ability to adapt to new situations, and a clear sense of
responsibility. In short, to be accepted as an expert, it is necessary to act
like one.
In prior papers (e.g., Shanteau, 1988), I described various cognitive
skills commonly possessed by experts. (Previously, these skills were
combined with the psychological traits under the label “psychological
characteristics”; I now believe that they should be considered separately.) Some of these skills exhibited by experts are highly developed
attention abilities, a sense of what is relevant, the ability to identify exceptions to rules, and the capability to work effectively under stress.
My observation of experts also has revealed the use of a variety of
formal and informal decision strategies (Shanteau, 1989). These strategies
help systematize decision making and have the effect of helping experts
overcome cognitive limitations. Although many strategies are unique to
given domains, there are several that are widely used. They include making use of dynamic feedback, relying on decision aids, decomposing complex decision problems, and prethinking solutions to tough situations.
There is a final factor which is crucial, but often overlooked. The tusk
characteristics determine whether it is possible for experts to behave
competently or not. Even with the appropriate knowledge, traits, skills,
and strategies, the competence observed in an expert depends on the
task. There are some tasks that experts do well, even in the face of
considerable difficulty, e.g., weather forecasters (Murphy & Winkler,
1977). In other tasks, experts seem incapable of performing much above
the level of novices, e.g., clinical psychologists (Oskamp, 1962). The
remainder of this section is devoted to discussion of task variables.
Task Characteristics
The relationship between domains and decision performance is illustrated in Table 1. The left side of the table lists judgment domains in which
competent performance has been reported in the literature. The right side
lists domains in which deficient performance has been reported. Except

<-----Page 6----->258

JAMES

SHANTEAU

TABLE 1
DOMAINS IN WHICH GOOD AND POOR EXPERT PERFORMANCE HAVE BEEN OBSERVED

Good performance

Poor performance

Weather forecasters
Livestock judges
Astronomers
Test pilots
Soil judges
Chess masters
Physicists
Mathematicians
Accountants
Grain inspectors
Photo interpreters
Insurance analysts
Nurses
Physicians
Auditors

Clinical psychologists
Psychiatrists
Astrologers
Student admissions
Court judges
Behavioral researchers
Counselors
Personnel selectors
Parole officers
Polygraph (lie detector) judges
Intelligence analysts
Stock brokers
Nurses
Physicians
Auditors

for nurses, physicians, and auditors (listed on both sides),’ the literature
in each field is clear about the level of competence. The question is: What
do the domains on each side have in common?
My original answer (see Table 2) was that domains with competent
performance involve static objects or things (Shanteau, 1987b). That is,
the experts are being asked to evaluate and make decisions about stimuli
that are relatively constant; consequently, judges are faced with a stationary target. Where poor performance is observed, the stimuli are dynamic and generally involve human behavior. Because experts are being
asked to evaluate and decide about what is in effect a moving target, they
do less well.
Other insights have been offered about this table. Dawes (1987) observed that predictability is different for the two sides: human behavior is
inherently less predictable than physical stimuli. Dawes also noted that
the competence expected by clients (or the public) varies for the two
sides. Clinical psychologists, for example, are expected to be always
correct, whereas weather forecasters are allowed to make occasional mistakes. Paradoxically in the less predictable behavioral domains, experts
are held to higher standards of performance.
Another difference is that left-side tasks tend to be repetitive-similar
conditions arise from time to time. Right-side tasks, in contrast, are more
changeable-conditions
differ frequently. This has implications for the
r The domains placed on both sides reflect literatures where there is evidence of both
competent and less-competent performance. Apparently, the different tasks performed by
these experts lead to wide variation in performance level.

<-----Page 7----->COMPETENCE

IN EXPERTS

259

TABLE 2
TASK CHARACTERISTICS ASSOCIATED WITH GOOD AND POOR PERFORMANCE IN EXPERTS

Good performance

Poor performance

Static stimuli
Decisions about things
Experts agree on stimuli
More predictable problems
Some errors expected
Repetitive tasks
Feedback available
Objective analysis available
Problem decomposable
Decision aids common

Dynamic (changeable) stimuli
Decisions about behavior
Experts disagree on stimuli
Less predictable problems
Few errors expected
Unique tasks
Feedback unavailable
Subjective analysis only
Problem not decomposable
Decision aids rare

opportunity to receive and respond to feedback. With domains on the left
side, there are more chances to learn from past decisions. Based on
previous successes and failures, an expert can better his/her decisions.
With right-side domains, however, there appear to be fewer chances to
learn.
An insightful observation was offered by Gigerenzer (1989), who noted
that historically most left-side domains began as right-side domains. As
understanding of meteorology developed, for example, weather forecasters moved from relying on intuitions and guesswork to using detailed
climatic information. With the advancement of science, therefore, many
unstructured right-side tasks performed by less-competent experts eventually become structured left-side tasks performed by competent experts.
This distinction is supported by the widespread presence of decision
aids for left-side tasks (Shanteau, 1989). Sometimes these aids are formal,
such as the “soil triangle” used by agronomy judges to define soil classification boundaries (Gaeth & Shanteau, 1984). At other times, the aids
are informal, such as the written records kept by livestock judges (Phelps,
1977) to help in learning and to prevent hindsight biases (Fischhoff, 1975).
As Edwards and von Winterfeldt (1986) point out, the “unaided expert
may be an oxymoron since competent experts will adopt whatever aids
are needed to assist their decision making.”
In summary, my view is that expert performance is neither uniformly
good nor bad. Rather, their competence depends on the task characteristics. The same expert may behave competently in some settings and not
in others. That means experts cannot be described generically. Instead,
any conclusions must take task into account.
Theoretical Hypotheses
Although the ideas behind the theory are primarily qualitative, it is
possible to propose several testable hypotheses. These concern condi-

<-----Page 8----->260

JAMES

SHANTEAU

tions under which experts will or will not make competent decisions.
Three hypotheses are described here.
The first hypothesis relates to tusk characteristics which lead to competent performance. The more a task contains left-side characteristics,
the greater the competence that should be seen in experts. Conversely,
the more right-side characteristics a task contains, the lesser the competence expected in experts. That means the performance by experts in a
given situation should be a function of the number of task characteristics
associated with each side.
The second hypothesis involves the decision strategies associated with
different tasks. According to the theory, use of left-side strategies, such
as problem decomposition with decision aids and feedback, should be
greater for left-side tasks. On the other hand, right-side strategies, such as
making unaided decisions without use of decomposition or feedback,
should be more frequent in right-side tasks. Thus, there should be a direct
relation between the strategies used and the type of task.
The final hypothesis involves prescriptive procedures for producing
more (or less) competent decisions. Performance in right-side tasks
should improve if they can be made more like left-side tasks. This might
be done either by changing task characteristics or by encouraging the use
of left-side strategies. That means it should be possible to prescriptively
improve expert competence, even when there are no objectively veriliable correct answers.
COGNITIVE CONTINUUM THEORY
The left-side, right-side distinction has parallels to Cognitive Continuum Theory (CCT) developed by Hammond (1966) from the ideas of
Brunswik (1956). Hammond and Brehmer (1973) define the continuum as
follows: “The ANALYTICAL
end of the continuum is characterized by
a form of thinking that is explicit, sequential, and recoverable. That is, it
consists of a series of steps that transform information according to certain rules . . . (which) can be reported by the thinker. . . . INTUITIVE
thinking, on the other hand, is implicit, nonsequential, and nonrecoverable. Usually, the thinker can report no more than the outcome of his
thinking (p. 340).” They go on to define a middle category: “Most instances of thinking will have both intuitive and analytic components. We
will refer to this composite as QUASI-RATIONAL thought.”
In applying CCT to expertise, Hammond, Hamm, Grassia, and Pearson
(1987) identify several cognitive properties that distinguish between intuition and analysis. Intuition is seen as having little cognitive control, rapid
processing, and low conscious awareness. In contrast, analysis has high
cognitive control, slow processing, and high awareness.
Hammond et al. (1987) distinguish analysis-inducing and intuition-

<-----Page 9----->COMPETENCE

IN

EXPERTS

261

inducing task characteristics. The former includes reliably measured
cues, task decomposition, presence of organizing principles, and sequential display of cues. The latter includes unreliably measured cues, nondecomposable task, lack of organizing principles, and simultaneous display of cues.
These task characteristics are consistent with the differences outlined
in Table 2. However, the present approach differs from CCT in at least
three respects. First, the continuum in CCT represents cognitive style,
with analytic and intuitive thinking at the extremes and quasirationality
between. In contrast, the theory proposed here has competence and incompetence of expert performance at the two extremes, with no classitiable middle ground. It is unclear how to make the connection between
these two continua.
Second, Hammond et al. (1987) argue that accuracy of judgment will be
greatest when there is a correspondence between task properties and
cognitive properties: “At some point on the cognitive continuum, performance will be best and accuracy will fall off as the expert becomes either
more analytic or more intuitive. ” The present theory, in contrast, is based
on a conceptualization of competence that goes from low to high as a
function of task characteristics.2
Third, CCT is based on a general approach to human judgment applicable to all people, whether expert or naive. The origin of the continuum
comes from Brunswik’s (1956) analysis of general perceptual processes.
In comparison, the present analysis is concerned only with experts and
the tasks they perform. It is unclear how to make extensions to naive
subjects, since they are incapable of doing or even understanding most
expert tasks.
IMPLICATIONS

FOR EXPERT SYSTEMS3

Using techniques from artificial intelligence, expert systems are increasingly being proposed to aid or even replace skilled decision makers.
According to Kolodner (1984), the goal is to build systems which “contain
all or most of the compiled knowledge an expert has.” Some argue that
eventually expert systems will provide “replacements for humans” (Cebrzynski, 1987).
However, getting experts to interact with expert systems has often
proved difficult (Michie, 1982). There are several potentially valuable
’ As argued in Shanteau (1989), experts often work on tasks that do not have correct
answers. For instance, there are no external criteria available to evaluate the quality of
decisions make by livestock judges.
3 Much of the material in this section is drawn from the discussion in Shanteau (1989).

<-----Page 10----->262

JAMES

SHANTEAU

systems, such as MYCIN, that are either unused or misused by the very
people that the systems were designed to help (Ham, 1984). In other
cases, extended efforts to develop expert systems had to be abandoned,
in part because of the lack of cooperativeness of experts (Rose, 1988).
At the same time, there has been a debate whether computer systems
can mimic experts (e.g., Graubard, 1988). Many investigators see great
potential for expert systems (Barrett & Beerel, 1988; Slatter, 1987), although others question whether that potential can ever be realized (Dreyfus & Dreyfus, 1986; Haugeland, 1985).
The present analyses of experts may contribute to a greater understanding of when and where expert systems are likely to be useful. Domain
knowledge and experience are clearly necessary for expertise; having the
facts and relevant experience are essential for any expert (Naylor, 1987).
Nonetheless, knowledge is not sufficient for expertise. By concentrating
on knowledge and production rules, other aspects of expertise have been
overlooked by builders of expert systems.
I believe the psychological insights described here may improve the
design, construction, and use of expert systems. The difficult cases are
what distinguish experts from those less skilled and the present analyses
suggest how competent experts deal with these cases.
Can an expert system be built that incorporates the present approach?
Not enough is known yet to answer this question. However, the following
would, at least, seem necessary to build such a system. First, expertise
must be looked at from the perspective of experts, not as something to be
defined within the constraints of available hardware and software. Expert
systems should reflect the physical and psychological worlds of experts,
not the other way around.
Second, experts cannot be expected to explain everything about what
they do. Verbal protocols typically are used to capture the information
needed to build an expert system. However, at best verbal protocols are
inefficient and at worst they may be misleading for representing expertise
(Hoffman, 1987). Instead, greater attention should be paid to alternative
methods for analyzing experts, such as those used in judgment and decision making research.
Third, more emphasis should be placed on the traits, skills, and strategies of human experts when building computer systems. Traits such as
communication ability, skills such as identifying exceptions, and strategies such as dynamic feedback should be incorporated into expert systems. Rigidity is a characteristic of novices (Shanteau, 1989) and most
systems, unfortunately, are rigid. Systems should be as flexible as the
experts they are designed to simulate.
Last, as suggested by Table 1, different types of expert systems may be
needed to reflect left-side and right-side expertise. The traditional expert

<-----Page 11----->COMPETENCE

IN

EXPERTS

263

systems may be adequate for the former; these systems generally work
best on well-structured problems (Mumpower, Phillips, Renn, & Uppuluri, 1987). However, linear judgment models may be better suited for the
latter; the ability of linear approximations to provide good fits to noisy
data is well established (Dawes & Corrigan, 1974).
CONCLUDING

COMMENTS

Five factors associated with the competence of experts have been identified: domain knowledge, psychological traits, cognitive skills, decision
strategies, and task characteristics. The stress here is on the last factor.
The importance of understanding task characteristics has been emphasized repeatedly in judgment and decision research (Hammond et al.
1987). The previous analyses (e.g., Beach, 1990; Howell & Kerkar, 1982;
Keller, 1985; Payne, 1982; von Winterfeldt & Edwards, 1986) have focused primarily on contingencies in ongoing decision behavior. As Payne
(1982) argues, subjects often invent short-term decision strategies as they
go along in an experimental task.
In contrast, the present analysis highlights the connection between task
characteristics and asymptotic expert behavior. The competence seen in
experts depends on having stable strategies developed in response to their
environment. Thus, the concern here is with the long-term instead of
short-term influence of task characteristics.
There are many questions remaining to be answered about the effect of
task variables on experts. The present research has supplied some tentative answers that hopefully will stimulate further research.
REFERENCES
Anderson, J. R. (1981). Cognitive skills and their acquisition. Hillsdale, NJ: Erlbaum.
Anderson, J. R. (1990). Cognitive psychology and its implications (3rd ed.). New York:
Freeman.
Ashton, R. H. (1983). Research in audit decision making: Rationale, evidence and implications. (Monograph No. 6). Vancouver: Canadian Certitied General Accountants.
Barrett, M. L., &. Beerel, A. C. (1988). Expert systems in business: A practical approach.
Chichester, UK: Halsted.
Beach, L. R. (1990). Image theory: Decision making in personal nnd organizational contexts. Chichester, UK: Wiley.
Benner, P. (1984). From novice to expert: Excellence and power in clinical nursing practice.
Reading, MA: Addison-Wesley.
Brunswik, E. (1956). Perception and the representative design ofpsychological
experiments
(2nd ed.). Berkeley: University of California Press.
Carroll, J. S., & Payne, J. W. (1976). The psychology of parole decision processes: A joint
application of attribution theory and information-processing psychology. In J. S. Carroll & J. W. Payne (Eds.), Cognitive and social psychology (pp. 13-32). Hillsdale, NJ:
Erlbaum.
Cebrzynski, C. (1987, February 27). Expert systems are seen as replacements for humans.
Marketing News, p. 1.

<-----Page 12----->264

JAMES

SHANTEAU

Chan, S. (1982). Expert judgments made under uncertainty: Some evidence and suggestions.
Social Science Quarterly,

63, 42M.

Chase, W. G., & Simon, H. A. (1973). Perception in chess. Cognitive Psychology, 4, U-81.
Chi, M. T. H., Glaser, R., & Farr, M. J. (1988). The nature of expertise. Hillsdale, NJ:
Erlbaum.
Christensen-Szalanski, J. J. J., & Beach, L. R. (1984). The citation bias: Fad and fashion in
the judgment and decision making literature. American Psychologist, 39, 75-78.
Christensen-Szalanski, J. J. J., & Bushyhead, J. B. (1981). Physician’s use of probabilistic
information in a real clinical setting. Journal of Experimental Psychology: Human
Perception

and Performance,

7, 928-935.

Christensen-Szalanski, J. J. J., Diehr, P. H., Bushyhead, J. B., & Wood, R. W. (1982).
Two studies of good clinical judgment. Medical Decision Making, 2, 275-284.
Coombs, M. J. (1984). Developments in expert systems. London: Academic Press.
Dawes, R. M. (1987, November). Personal communication.
Dawes, R. M., & Corrigan, B. (1974). Linear models in decision making. Psychological
Bulletin, 81, 95-106.
deGroot, A. D. (1965). Thought and choice in chess. The Hague: Mouton.
DeSmet, A. A., Fryback, D. G., & Thombury, J. R. (1978). A second look at the utility of
radiographic skull examination for trauma. American Journal ofRadiology.
132,95-99.
Dreyfus, H. L., & Dreyfus, S. E. (1986). Mind over machine. New York: Free Press.
Ebbesen, E., & Konecni, V. (1975). Decision making and information integration in the
courts: The setting of bail. Journal of Personality and Social Psychology, 32, 805-821.
Edwards, W., & von Winterfeldt, D. (1986). On cognitive illusions and their implications.
Southern California Law Review, 59(2), 401451.
Einhom, H. (1974). Expert judgment: Some necessary conditions and an example. Journal
of Applied Psychology, 59, 562-57 1.
Ericsson, K., 62 Simon, H. A. (1980). Verbal reports as data. Psychological Review, 87,
215-251.
Fischhoff, B. (1975). Hindsight # foresight: The effect of outcome knowledge on judgment
under uncertainty. Journal of Experimental Psychology: Human Perception and Performance, 1, 288-299.
Fitts, P. M., & Poison, M. I. (1967). Human performance. Belmont, CA: Brooks Cole.
Foss, J. E., Wright, W. R., & Coles, R. H. (1975). Testing the accuracy of field textures.
Soil Science Society of America

Proceedings,

39, 800-802.

Gaeth, G. J., & Shanteau, J. (1984). Reducing the influence of irrelevant information on
experienced decision makers. Organizational Behavior and Human Performance, 33,
263-282.
Gigerenzer, G. (1989, May). Personal communication.
Goffman, E. (1959). The presentation of selfin everyday life. Garden City, NJ: DoubledayAnchor.
Goldberg, L. R. (1970). Man vs. model of man: A rationale, plus some evidence, for a
method of improving clinical inferences. Psychological Bulletin, 73, 422-432.
Graubard, S. R. (1988). The artificial intelligence debate: False starts, real foundations.
Cambridge, MA: MIT Press.
Grier, M. R. (1976). Decision making about patient care. Nursing Research 25, 105-I 10.
Ham, M. (1984, January). Playing by the rules. PC World, pp. 34-41.
Hammond, K. R. (1966). Probabilistic functionalism: Egon Brunswik’s integration of the
history, theory, and method of psychology. In K. R. Hammond (Ed.), The psychology
of Egon Brunswik. New York: Holt, Rinehart, and Winston.
Hammond, K. R., & Brehmer, B. (1973). Quasi-rationality and distrust: Implications for

<-----Page 13----->COMPETENCE IN EXPERTS

265

international conflict. In L. Rappoport & D. Summers (Eds.), Human judgment and
social interactions. New York: Holt, Rineholt, & Winston.
Hammond, K. R., Hamm, R. M., Grassia, J., & Pearson, T. (1987). Direct comparison of
the efficacy of intuitive and analytic cognition in expert judgment. IEEE Transactions
on Systems, Man, and Cybernetics, SMC 17(5), 753-770.
Haugeland, J. (1985). Artificial intelligence: The very idea. Cambridge, MA: MIT Press.
Hoffman, R. R. (1987, Summer). The problem of extracting the knowledge of experts from
the perspective of experimental psychology. AI Magazine, pp. 53-67.
Hoffman, R. R., Shanteau, J., Burton, A. M., Shadbolt, N. R., & Akerstrom, R. A. (1991).
The cognitive psychology of expertise: A review of theories andfindings. Unpublished
manuscript. Adelphi University.
Howell, W., & Kerkar, S. (1982). A test of task influence in uncertainty measurement.
Organizational Behavior and Human Performance, 30, 365-390.
Kahneman, D. (1991). Judgment and decision making: A personal view. Psychological
Science, 2(3), 142-145.
Kahneman, D., Slavic, P., & Tversky, A. (Eds.). (1982). Judgment under uncertainty:
Heuristics and biases. New York: Cambridge Univ. Press.
Keller, L. R. (1985). The effects of problem representation on the sure-thing and substitution principles. Management Science, 31, 738-75 1.
Kolodner, J. L. (1984). Towards an understanding of the role of experience in the evolution
from novice to expert. In M. J. Coombs (Ed.), Developments in expert systems (pp.
95-116). London: Academic Press.
Larkin, J. H. (1979). Information processing and science instruction. In J. Lochhead & J.
Clement (Eds.), Cognitive process instruction. Philadelphia, PA: Franklin Institute
Press.
Larkin, J. H., McDermott, J., Simon, D. P., & Simon, H. A. (1980). Expert and novice
performance in solving physics problems. Science, 208, 1335-1342.
Levitt, T. (1990, February). Personal communication.
Lichtenstein, S., & Fischhoff, B. (1977). Do those who know more also know more about
how much they know? Organizational Behavioral and Human Performance, 20, 159183.
Lichtenstein, S., Fischhoff, B., & Phillips, L. D. (1982). Calibration of probabilities: The
state of the art to 1980. In D. Kahneman, P. Slavic, & A. Tversky (Eds.), Judgment
under uncertainty: Heuristics and biases. Cambridge, UK: Cambridge Univ. Press.
Mayer, R. E. (1983). Thinking, problem solving, cognition. New York, Freeman.
Meehl, P. (1954). Clinical versus statistical prediction: A theoretical analysis and a review
of the evidence. Minneapolis: University of Minnesota Press.
Michie, D. (1982). Zntroductory readings in expert systems. New York: Gordon and Breach.
Mumpower, J. L., Phillips, L. D., Renn, O., & Uppuluri, V. R. R. (Eds.). (1987). Expert
judgment and expert systems. Berlin: Springer-Verlag.
Murphy, A. H., & Winkler, R. L. (1977). Can weather forecasters formulate reliable forecasts of precipitation and temperature? National Weather Digest, 2, 2-9.
Naylor, C. (1987). Build your own systems (2nd ed.). New York: Halsted Press.
Oskamp, S. (1962). The relationship of clinical experience and training methods to several
criteria of clinical prediction. Psychological Monographs, 76.
Oskamp, S. (1965). Overconfidence in case-study judgments. Journal of Consulting Psychology, 29, 261-265.
Payne, J. (1982). Contingent decision behavior. Psychological Bulletin, 92, 382-402.
Phelps, R. H. (1977). Expert livestock judgment: A descriptive analysis of the development
of expertise. Doctoral dissertation, Kansas State University.

<-----Page 14----->JAMES

266

SHANTEAU

Phelps, R. H., & Shanteau, J. (1978). Livestock judges: How much information can an
expert use? Organizational Behavior and Human Performance, 21, 209-219.
Rose, F. (1988, August 12). Thinking machine: An ‘electronic clone’ of a skilled engineer is
very hard to create. The Wall Street Journal, p. 14.
Shanteau, J. (1984). Some unasked questions about the psychology of expert decision makers. In M. E. El-Hawary (Ed.), IEEE Conference on Systems, Man, and Cybernetics,
New York: IEEE.
Shanteau, J. (1987a). Psychological characteristics of expert decision makers. In J. L.
Mumpower, 0. Renn, L. D. Phillips, & V. R. R. Uppuluri (Eds.), Expertjudgment and
expert systems (pp. 289-304). Berlin: Springer-Verlag.
Shanteau, J. (1987b). What about experts? Paper presented at the meeting of JudgmentlDecision Making Society. Seattle, WA.
Shanteau, J. (1988). Psychological characteristics and strategies of expert decision makers.
Acta Psychologica,
68, 203-215.
Shanteau, J. (1989). Psychological characteristics and strategies of expert decision makers.
In B. Rohrmann, L. R. Beach, C. Vlek, & S. R. Watson (Eds.), Advances in decision
research (pp. 203-215). Amsterdam: North Holland.
Shanteau, J. (Ed.). (In press). Expert decision making: Psychological explorations of competence. New York: Cambridge Univ. Press.
ShitTrin, R. M., & Schneider, W. (1977). Controlled and automatic human information processing: II. Perceptual learning, automatic attending, and a general theory. Psychological Review, 84, 127-190.
Slatter, P. E. (1987). Building expert systems: Cognitive emulation. Chichester, UK: Ellis
Horwood.
Slavic, P., Fischhoff, B., & Lichtenstein, S. (1985). Regulation of risk: A psychological
perspective. In R. No11(Ed.), Social science and regulatory policy. Berkeley: University of California Press.
Trumbo, D., Adams, C., Milner, M., & Schipper, L. (1962). Reliability and accuracy in the
inspection of hard red winter wheat. Cereal Science Today, 7, 62-71.
Tversky, A., & Kahneman, D. (1971). The belief in the ‘law of small numbers.’ Psychological Bulletin, 76, 105-l 10.
von Winterfeldt, D., & Edwards, W. (1986). Decision analysis and behavioral research.
Cambridge, England: Cambridge Univ. Press.
Williams, P. (1951). The use of confidence factors in forecasting. Bulletin of the American
Meteorological

Society,

32, 27%281.

RECEIVED: November 14, 1991

