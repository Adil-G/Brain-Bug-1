<-----Page 0----->Journal of Consumer Research Inc.

Compensatory Choice Models of Noncompensatory Processes: The Effect of Varying Context
Author(s): Eric J. Johnson and Robert J. Meyer
Source: Journal of Consumer Research, Vol. 11, No. 1 (Jun., 1984), pp. 528-541
Published by: The University of Chicago Press
Stable URL: http://www.jstor.org/stable/2489140 .
Accessed: 23/07/2011 17:01
Your use of the JSTOR archive indicates your acceptance of JSTOR's Terms and Conditions of Use, available at .
http://www.jstor.org/page/info/about/policies/terms.jsp. JSTOR's Terms and Conditions of Use provides, in part, that unless
you have obtained prior permission, you may not download an entire issue of a journal or multiple copies of articles, and you
may use content in the JSTOR archive only for your personal, non-commercial use.
Please contact the publisher regarding any further use of this work. Publisher contact information may be obtained at .
http://www.jstor.org/action/showPublisher?publisherCode=ucpress. .
Each copy of any part of a JSTOR transmission must contain the same copyright notice that appears on the screen or printed
page of such transmission.
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of
content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms
of scholarship. For more information about JSTOR, please contact support@jstor.org.

The University of Chicago Press and Journal of Consumer Research Inc. are collaborating with JSTOR to
digitize, preserve and extend access to Journal of Consumer Research.

http://www.jstor.org

<-----Page 1----->Compensatory
Choice
Models
pensatory
Noncom
Processes:
The

Effect

of

Varying

of

Context

ERICJ. JOHNSON
ROBERTJ. MEYER*
The sensitivity of the parameters and fit of compensatory choice models to contextual variations in information processing strategies is examined. A set of predictions is derived concerning specification errors which may arise when a compensatory model misrepresents a "true,"noncompensatory choice process. These
predictions are then tested in an experimental analysis of apartment choice behavior. Logit analysis and protocol analysis are employed to assess how the
parameters and fit of a compensatory model vary in light of changes in the underlying pattern of information processing across choice sets of differing sizes.
Although attribute usage and parameter variation across set sizes conformed to
theoretical expectations, a hypothesized decrease in predictive accuracy was not
supported.

n importantpart of understandingconsumerbehavior
is the constructionof formalrepresentationsof choice
processes. Such formalisms as decision nets, conjoint analysis, and discrete choice analysis all attemptto model the
relationship between characteristicsof a product and observed choices.
Most applied forecastingmethodsused in marketingrepresent choice processes in terms of some form of algebraic
model. A common assumption is that the parameters of
these models are independentof the particularset of alternatives under study. Process analyses of choice, however,
suggest that this assumption may not always be valid:
changes in the number of alternativesand their attributes
have been known to affect reports of the way choices are
made.
Although protocols suggest that decision strategies are
likely to be sensitive to context, the extent to which this
will be reflected in the parametersof algebraicmodels has
not been systematically investigated. The purpose of this
paper is to explore this issue. Specifically, we examine the
relationshipbetween the parametersand fit of an algebraic
model and changes in decision strategiesacross contexts as
revealed throughconcurrentprotocols.

Our decision is organized in four sections, that (1) introduce the problem in detail; (2) derive a set of theoretical
predictions concerning how changes in processing heuristics may affect the parametersand fit of an algebraicmodel;
(3) reportan empiricaltest; and (4) discuss the implications
of our findings.

BACKGROUND
Underlying most applied work in consumerchoice analysis is a simple theory of decision making: consumers are
hypothesized to approach choice situations with a predefined algebraic judgment policy or utility function. This
function defines how the observed attributesof products
will be integratedto form overall evaluationsof desirability.
After independentlyevaluatingeach alternative,consumers
are hypothesized to choose the option with the highest
overall utility or value (e.g., McFadden 1981).
The intuitive appeal of the paradigmrests in its implications for forecasting. If an analyst is able to specify an
individual's multiattributejudgment policy, it should be
possible to predict evaluations of new or untested product
options (e.g., Green, Carroll, and Goldberg 1981).
In recent years, the prospect of being able to make such
forecasts has inspireda rapidgrowth in the developmentof
improved methods for inferring multiattributejudgment
policies from judgment and choice data (e.g., Green 1974;
Hensher and Johnson 1981; Keeney and Raiffa 1976; Louviere and Woodworth 1983). Although current methods
often vary widely in philosophy and structure,most share
two common assumptions:

*Eric J. Johnson is an Assistant Professor at the GraduateSchool of
Industrial Administration, Carnegie-Mellon University, Pittsburgh, PA
15213. Robert J. Meyer is an Assistant Professor at the GraduateSchool
of Management, University of California, Los Angeles, CA 90024. The
order of authorshipis alphabetical;both contributedequally to this research. The authors thank Lee Cooper, JordanLouviere, Michael Menasco, three anonymousreviewersfor theirhelpful comments, and Matthew
Salt7manfor his nrogramminpassistance.

528
?DJOURNAL OF CONSUMER RESEARCH0 Vol. 11 0 June 1984

<-----Page 2----->COMPENSATORY
CHOICEMODELS
1. Judgmentpolicies can be representedby a compensatory
model.
2. Judgmentpolicies are not contingent upon the evaluated
set of alternatives.

The first assumptionmay not be not a particularlylimiting one. Rephrased, it states that analysts usually restrict
their attention to algebraic functions which are linear or
multilinear in form-functions which allow tradeoffs between attributes(Hensher and Johnson 1981; Keeney and
Raiffa 1976; McFadden 1981). Although it is likely that
consumersmay often use noncompensatorystrategies-that
is, eliminate alternativeswithout examining all attributessuch functions can usually be approximatedby an interactive form of linear model (e.g., Billings and Marcus 1983;
Einhorn 1970; Keeney and Raiffa 1976; Louviere 1979).
Although a discussion of the reasons for the robustnessof
linear models is beyond the scope of this paper, it is sufficient to note that interactiveor log-linear approximations
of noncompensatoryprocesses will usually provide a good
descriptionof response data which are not error-free(Einhorn 1970).
The assumptionthatjudgmentpolicies are not contingent
upon the characteristicsof the evaluatedalternativesis more
problematic.Although a linear or multilinearfunction may
provide a good descriptionof judgment or choice behavior
in one context, the same functionmay not describebehavior
in another.Given that such models are increasinglypopular
as tools for forecasting, this point appearscritical: if individuals' judgment policies are influencedby the characteristics of the choice problem, then derived models may have
limited transferabilityacross contexts.
Research which has examined the effect of context on
choice suggests that these concerns may be serious ones.
The strongest evidence comes from analyses of decision
protocols-studies in which individualsare asked to "think
aloud" while engaged in choices made in differingcontexts
(e.g., Billings and Marcus 1983; Einhorn,Kleinmuntz,and
Kleinmuntz 1979; Payne 1982; Svenson 1979). The view
of decision making that emerges from this work is quite
different from that which underliesmost algebraicmodels.
Insteadof a single, context-freejudgmentrule, individuals
appearto possess an assortmentof contingentjudgmental
heuristics. The heuristics employed in choice depend upon
the external representationof the choice problem, and vary
over time as the structureof the choice set changes (e.g.,
Bettman 1979; Lichtenstein and Slovic 1971; Payne 1976,
1982).
As an example, when faced with simple binary choices,
individuals often form preferencesusing dimensionalcomparisons (Russo and Dosher 1983). As the number of alternativesincreases, there are changes in processing tactics:
individualsmake greateruse of eliminationstrategies(e.g.,
Bettman and Jacoby 1976; Olshavsky 1979; Payne 1976;
Wright and Barbour 1977). Because these two sets of processes are best described by differing forms of compensatory models, a model derived by observing choices made
from sets of one size may do quite poorly when applied to
predictingchoices from sets of another.

529
Thus we appearto be faced with a paradox.On one hand,
protocol analyses suggest that choices are likely to be made
by a wide variety of strategies which are contingent upon
characteristicsof the choice alternatives;on the other, our
technology for consumer forecasting tends to employ
models which assume a single (multiattribute)process defined independentlyof context. For the applied researcher,
the problem is a simple one: given that compensatory
models approximatethe trace of a more complex, contingent choice process, will changes in the structureof this
process affect the parameters and fit of a compensatory
model?
Empirical evidence on the robustness compensatory
models is incomplete. It is well known, for example, that
additive models can correlatewell with judgment or rating
data which are generated by a nonadditive source (Birnbaum 1973; Dawes and Corrigan 1974; Olshavsky and
Acito 1980). The conditions for this appear to be rather
general:
1. The predictorvariablemust have a monotonicrelationship
with the criterion.
2. There must be error in both sets of variables(Dawes and
Corrigan 1974).

If these conditions are satisfied across contexts, compensatory models should provide a reasonablyrobust description of judgmentalresponses.
Evidence for the robustnessof compensatorymodels for
choice data-the criterion of interest in most applied
work-is not as extensive. Althoughthereis some evidence
concerning the predictive validity of compensatorymodels
when parametersare misspecified (Curry, Louviere, and
Augustine 1981; Green, DeSarbo, and Kedia 1980), little
is known aboutthe sensitivity of such parametersto changes
in underlyingprocessing strategies.
Here we examine this issue. Our approachis both theoretical and empirical. We first derive a set of theoretical
predictionsconcerningthe types of specificationerrorsthat
should arise when misrepresenting a noncompensatory
(contingent)evaluationprocess in terms of a compensatory
choice model. We then test these predictionsby noting how
the parametersand fit of a compensatorymodel vary under
a manipulationof choice context known to induce noncompensatoryprocessing: choice set size.

THEORETICAL ANALYSIS
In this section we explore the problem of specification
errors that may arise when a compensatorychoice model
misrepresentsthe "true" patternof informationprocessing.
We consider a "worst case" scenario of model misspecification: an analyst uses a linear compensatory model to
predict choices generatedby a noncompensatorysource.
We firstdefine a sequentialeliminationpolicy which represents the underlying choice process. The representation
is a general one that subsumes a number of noncompensatory choice rules, most notably the conjunctive (e.g.,
Einhorn 1970). We then derive a set of predictions con-

<-----Page 3----->THEJOURNALOF CONSUMERRESEARCH

530
cerning the types of specification errors that should arise
when attempting to represent data generated by this process
in terms of a linear compensatory choice model.

The Stochastic EliminationModel
We characterize the individual's choice
Basic Process.
process as consisting of k discrete elimination stages,
k = 1, . . ., m. At each stage the decision maker defines
an elimination policy which reduces the set of alternatives
to smaller number of candidates. This iterative process continues until one candidate remains (a choice is defined).
Our formal model makes three assumptions:
Al. Let Vik be the value or utility associated with alternative
i at stage k, and let Xi be a vector of uniformlyscaled attribute
values associated with i. For each alternativei at each stage,
1/k is representedby a value mapping f'Xi such that:
Vik

=

tkXi

?

A2. Associated with each alternative at each stage in the
process is an independent,nonnegative probabilityof being
retained as a candidate for choice. The probabilitythat an
alternative i will be a member of the candidate set (Sk) at
stage k (P(i E Sk)) is given by:
E Sk)

=

P(Vik

in

P(i|k=

1, .

m) =

(5)

r
k= I

?+

ETk

e

e

-(k'

-

X

Tk)

-

Ei)

- Tk.

I

(6)
+ e

(1

II

Pk'Xi

-

Tk)

k= I

The probabilitythat alternativei will be chosen from a set
of j = 1, . . ., N competitors (P(iL = 1, . . ., N)) is the

normalizedintersectionof these candidateprobabilitiesfor
all alternatives. Formally:
PIxX-

Tk.

k-I

etk= I
rn

in1?(I + eX-T,k
3'kX rl

(3)

where Tk is a subjective value threshold and ETk an associated random disturbance. This assumption states that on
each stage, each alternative is evaluated by comparing its
value at that stage to a stochastic threshold, Tk + ETk. The
alternative is retained if its value exceeds this threshold.

.Xj
k
k

m

(2)

> Tk + ETk)

= P(3'Xi - Tk >

The Formal Choice Model. Under the assumption of
the independentprobabilitiesof candidateset membership
(Assumption 2), the probabilitythat an alternativewill be
consideredas a candidatefor choice afterm stages of elimm) is given by the product:
ination P(i|k = 1,.

(1)

i

where E is an independent disturbance term, and 3* is a
parameter vector with elements that reflect the relative importance of each attribute in the evaluation process at stage
k. Note that if the weight vector 3k contains only one nonzero element for each stage (i.e., only one attribute is considered), the present model represents a conjunctive choice
process.

P(i

that set of thresholds which maximizes the overall utility
of the chosen alternativewhile minimizing a cost function
of m (the length of time spent making the choice; e.g.,
Gretherand Wilde 1984). It is empiricallymore reasonable
simply to assume that thresholdvalues (and hence m) will
be determinedthroughtrial and error;if one criterioneliminates too few or too many alternatives,the decision maker
will "go back" and attemptsome other.

k

P(iij =1,

.

,N)

Tk)

I

=(7)
E1

e

Irl

k=I

A3. The randomvariablesETk Eik for each alternativehave
independent,identically distributed(i.i.d.) logistic densities.
Hence:

(I

. Xi -

Tk.

+ e~
e tX

tk

-

P(i

E Sk) =

1
1 ? e -(f3X

(4)
-

TA)

The final assumption provides a closed form for the probability in Equation 3. The i.i.d. restriction reaffirms the
assumption that each candidate set decision is made independently for each alternative. Equation 4 implies that the
probability of membership in the candidate set increases
either with increases in overall value (P3AXi)or with decreases in threshold utility (Tk).
Note that we make formal assumptions neither about how
threshold values (Tk) will be determined by a decision
maker nor about the number of stages (m) required to yield
a unique choice. A normative strategy would be to choose

Specification Errorsin a Compensatory
Approximation
We assume that an analyst observes repeated choices
made from a set of j = 1, .

., N alternatives generated

by the stochastic elimination process summarizedin Equation 7. We examine the types of specificationerrorswhich
arise when attempting to representthese data in terms of
the multinominallogit model:

'By using Equation2 we are implicitly assuming that a choice of some
alternativewill be made-that is, the probabilityof the candidateset being
a null set is zero.

<-----Page 4----->COMPENSATORY
CHOICEMODELS
1,.

P(i|j=

531
+

.xi N

o

(8)

N

E

*

eet}AXj+i

where (3 is a parametervector, xi is a vector of characteristics attributesof i, and Eoi is an asymptotically normal
errorthat the analysis assumes is independently,identically
distributedfor all i.
The multinomial logit is a form of fully compensatory
(nonelimination) choice model which is used in a wide
range of applied work (e.g., Urban and Hauser 1980). Although we limit our discussion of specificationerrorsto the
logit, the results should extend to any form of choice
models assuming noncontingent utility functions, such as
the multinomialprobit (e.g., Currim 1982).
Our analysis centers on two issues:
1. How does the attributesalience vector (f3',)in the logit
approximationrelate to the saliency vectors (f3') defined
for each stage in the elimination model?
2. What are the propertiesof the specificationerror, if any,
in the stochastic errorE , in the logit?

We derive two relevantresults by equatingEquations7 and
8:
1

.?

PO- m E?k
k I
E

kX -TE,Xi

+
I

________

01-

in
11I ( 1 ?
k= I

(9)

ekXi

-

et=

E*
0
(10)

Tk)

where E*. is an independentstochastic disturbance.
Equation9 states that when the multinomiallogit is used
to representa sequential elimination process, the revealed
salience of attributesin the logit (4fi) will be approximately
equal to their mean salience across the stages of elimination
(k).
Equation 10 defines the characteristicsof the errorin
this approximation:it will always be nonpositive, increasing with both the numberof eliminationstages (m) and the
overall utility of an alternative(A3OX,).
The resultthat Eoi increaseswith m (the numberof stages)
is an intuitive one: it simply says that the more pervasive
staged eliminations are in choice, the less appropriatethe
logit becomes as a representation of the choice process.
Less obvious is the fact that the specification error will
always be nonpositive and increase with the value of f31'Xi.
Basically, these results stem from the fact that the elimination model is a satisficing ratherthan optimizing model
of choice. The probability of an alternativebeing chosen
is the probability that it is "acceptable" on all criterianot the probabilitythat it is the "best available" (the criterion modeled by the multinomial logit). Formally, the
numeratorof the elimination model (Equation7) is a zeroto-one bounded probabilityof candidate set membership.

By contrast, the numerator of the multinomial logit is a
zero-to-infinitymeasure of absolute utility. The more positive this absolute utility, the greaterthe (negative) difference between the predictionsof the eliminationmodel and
the logit.

Implicationsfor Cross-TaskTransferability
Ourtheoreticalanalysis can be used to deduce the general
conditions under which a compensatorymodel should fail
in cross-task prediction. Our approachbegins with the assumption that the attributesalience vectors Pk in the elimination model can be viewed as a set of measures of the
extent to which each attributeis considered at each stage
in choice. Thus Expression 9 can be restated as implying
that the more frequently an attributeis attendedto during
choice, the higher its salience should be as defined in a
logit model. Hence, if changes in task induce changes in
the relative frequencywith which attributesare considered,
there should be a correspondingchange in the parameters
of the best fitting compensatorymodel.
To illustrate, when given a choice between two alternatives describedby three attributes,an individualmight compare them once on each dimension, and then choose the
one which is best on at least two of the three (Russo and
Dosher 1983). If the choice set were to be expanded-say
to eight alternatives-a different strategy would probably
be employed: the consumer might first use one of the attributesto screen the choice set, reducingit to a manageable
size, and then carefully examine the remainingcandidates
on all three attributes (e.g., Wright and Barbour 1977).
Because the attributewhich was used for screening would
have been referredto more frequentlyin the second scenario
then the first, we would predict that its revealed salience
will be greaterin the second.

EMPIRICAL ANALYSIS
In this section we empiricallyexamine the consequences
of representingcontingent choice processes with compensatory models. We focus on two implicationsof our theoretical analysis:
1. The salience of attributes revealed in a compensatory
model should reflectthe frequencyof theiruse in an elimination process.
2. The overall fit of a compensatorymodel should decrease
as eliminations become more commonplace.

We tested these predictions by monitoring individuals'
choices from sets of varying sizes. This manipulationwas
designed to induce changes in the way individuals processed information across a set of contexts. Individuals
were hypothesized to use compensatory strategies when
evaluating one or two alternatives, but to make more extensive use of sequential elimination strategies when faced
with larger choice sets.

<-----Page 5----->532

THEJOURNALOF CONSUMERRESEARCH

We summarizethese objectives in four hypotheses:
H1: As set sizes increase, sequentialeliminationstrategies in choice should increase.
H2: As set sizes increase, the pattern of attribute
usage will change. Specifically, some "initial
filtering" attributeswill be used relatively more
frequently and other "final comparison" attributes will be used relatively less frequently.
H3: As set sizes increase, the distributionof revealed
attributeweights in a compensatory(logit) model
will follow the patternof attributeuse. Specifically, more important"filtering" attributeswill
increase in revealed importanceand less important "comparison" attributeswill decreasein importance.
H4: As set sizes increase, the overall fit of the compensatorymodel should decrease.
Two methodologies were employed to test these hypotheses: protocol analysis and logit analysis. Protocol
analysis was used to examine Hypotheses 1 and 2, the necessary conditions for a test of specificationerrorsdue to a
mismatch of model to process. Logit analysis was then
employed to test Hypotheses 3 and 4, the hypothesized
effects of this mismatch on the parameters and fit of a
compensatory(logit) model.

ExperimentalDesign
The context of our experiment was students' selections
of apartments.Subjects were presentedwith profiles of hypothetical apartments,each described in terms of four attributes: monthly rent (a dollar figure), walking time to
campus (in minutes), general appearanceof the unit and its
associated neighborhood (a brief verbal description), and
its maintenancequality (a brief verbaldescription).Subjects
were asked to make choices and judgments in choice sets
of either 1, 2, 4, or 8 alternatives. For single-alternative
choice sets, subjects provided a preferencerating on a 10point scale of overall desirability. For larger sets, subjects
chose their most preferredapartment.
For each of the four levels of set size, we constructed
eight different choice sets using a two-stage procedure:
in each set was con1. An unlabeled"target"apartment
structedby assigning"high" and"low" attribute
levels
accordingto a fractionalexperimental
design.
2. Remaining"competing"apartments
were randomlyassignedattributelevels drawnfroma uniformdistribution
of mid-rangevalues.
To ensure that the target alternativewould not be transparentin the experiment, "high" and "low" attributelevels were drawn randomly from bounded (uniform) distributionsaroundeach level. Hence, althoughin the aggregate
the characteristicsof a given targetwere constantthrough-

out the experiment, its exact description varied slightly
from choice set to choice set for each subject.2
Examples of the experimentalstimuli for choice sets of
size 1 and 4 form Figure A. A more complete description
of the experimental instructions and stimuli is available
from the authorsupon request.
The targets representedcells in one-half fractionof a 24
factorial. In this design, four apartmentattributeswere varied at either a "high" or "low" level. The design permitted
independentestimationof all four attributemain effects, as
well as three two-way interactions: rent with distance,
maintenance, and appearance.3
Competingalternativeswere assigned attributelevels between the high and low levels to control for some of the
featuresof choice sets that would otherwisebe confounded
with set size. In larger set sizes, there will be a higher
likelihood that dominatedalternativeswill exist and will be
excluded from the set before the subjectmakes seriousevaluations. The distributionalcharacteristics(mean and variance) of the competitive set may also vary.
By using mid-range levels, we controlled for both of
these effects. Specifically:
1. The relativeincidenceof dominanceof the targetwas
constantin each set-sizecondition:the targetwas dominantin one choice set, was dominatedin one, and was
in the pareto-optimal
or feasibleset in the remainder.4
2. The meanand varianceof attributelevels was constant
acrossset-sizeconditions.
The analysis examinedchanges in choice behavioracross
set sizes. In the protocol analysis, we inferredchoice processes using subjects' self-reports. In the logit analysis,
choice processes were examinedby estimatingthe statistical
effects of "rent," "distance," "maintenance," and "appearance" on observed choice frequencies associated with
the target between conditions.

Protocol Analysis
This analysis tested the two hypotheses that should exist
in order to demonstrate bias due to model misspecification-i.e., Hypothesis 1, which states thateliminationswill
become more frequentas set size increases, and Hypothesis
2, which suggests that screening attributes will be used
relatively more frequentlyas set size increases.
2A copy of the PASCAL source code used in constructingthe experimental scenarios is available from the authors.
3In this design, all unestimatedtwo-and-higher-levelinteractionswere
assumed to be negligible. Hence, while all main effects and estimated
two-way interactionswere mutually independent,they would potentially
be confounded by significant higher-order effects (Hahn and Shapiro,
1966).
4The dominantand dominatedtargetswere the "low rent, low distance,
high maintenance, and high appearance" and the "high rent, high distance, low maintenance, and low appearance"cells of the experimental
design, respectively.

<-----Page 6----->COMPENSATORY
CHOICEMODELS
FIGUREA
EXEMPLARY
APARTMENT
SCENARIOSFOR
JUDGMENT (N = 1) AND CHOICE (N = 4) CONDITIONS'

533
collected in one of the three replications. Order was counterbalanced: three subjects generated verbal reports in each
replication. This was preceded by a brief warm-up task
familiarizing subjects with verbal reports.

Judgmentcondition
Considerthe followingapartment:
Apartment1: Rent:315 dollars
Distance:20 minutesto campus
Maintenancequality& availability:MINIMAL;
Maintenance person difficultto contact.
Appearance: Limited-sizedapt. in older residential
area, no a/c, some conveniences.
How would you rate this apartmentin terms of the best and worst
you can imagine?
worst 1 2 3 4 5 6 7 8 9 10 best
Choice condition
Considerthe following4 apartments:
Apartment1: Rent:282 dollars
Distance:27 minutesto campus
Maintenance quality & availability:FAIR;Maintenance person can be contactedmost regularbusiness hours.
Appearance:Reasonable-sized, clean apt. in quiet
neighborhood,equipped,ww/c.
Apartment2: Rent:240 dollars
Distance:23 minutesto campus
Maintenancequality& availability:GOOD;Maintenance person usuallyavailable.
Appearance:Reasonable-sized, clean apt. in quiet
neighborhood,equipped,ww/c.
Apartment3: Rent:225 dollars
Distance:22 minutesto campus
Maintenance quality & availability:FAIR;Maintenance person can be contactedmost regularbusiness hours.
Appearance:Moderate-sized,tidyapt. in safe neighborhood,equipped,ww/c.
Apartment4: Rent 326 dollars
Distance: 11 minutesto campus
Maintenancequality& availability:MINIMAL;
Message must be left withansweringservice.
Appearance: Spacious, tidy apt. in good location,
fullyequipped,ww/c, a/c.

Analysis.
The protocols were transcribed and segmented into complete thoughts by a research assistant who
was unaware of the experimental hypotheses (Newell and
Simon 1972). Two raters, also unaware of the hypotheses,
coded each statement into one of six categories:

* Read: Verbatim reading of informationfrom the choice
scenario.

* Evaluation: An evaluation of an attributeor alternative,
*
*
*

*

without reference to a standardor to anotherattributeor
alternative.
Comparison: A judgment of the relative value of an attributeor alternativerelative to another.
Eliminations: Statementsthat an alternativewill be eliminated from consideration.
Choice and rating statements: Statements announcing
either the overall choice of an alternative or the rating
assigned to an alternative.
Strategy statements. Statementsdescribing aspects of the
decision process unrelatedto the currentchoice set, such
as the importance of an attribute or a description of a
method for making a choice.

The coding was done using a computer program that
presented a coder with the statement in question and asked
a series of questions which resulted in the assignment of
the statement to one of these six categories, or classified
the statement as uncodable. Only 0.7 percent of the statements were classified as uncodable by both judges. Although judges initially agreed upon 79 percent of the codings, a clarification of the coding scheme on several points
increased independent agreement to 96.5 percent, and the
remaining conflicts were resolved by discussion. All six
categories showed inter-rater agreement exceeding 90 percent. The raters also coded, where possible, the identity of
the alternatives and attributes mentioned in the statement.
These codings also showed high inter-rater agreement (95.8
and 95.0 percent, respectively).

Which one would you choose?
amnthe choice condition, the target is Apartment 4.

Subjects. Because protocol analysis is a highly informative but labor intensive procedure, we examined the behavior of a small numberof subjects. Nine subjects participatedin response to signs posted on campus. Subjectswere
paid $4.00 to participatein an hour-longexperimentalsession, which were run individuallyover a one-week period.
Procedure. Subjects were presented with three replications of the design describedabove. They generatedconcurrentverbal protocols ("thought aloud") duringthe first
four choices or judgments in each set size. Protocols were

Analyses Related to Hypothesis 1: Changes in Processing
Strategies. We first examined the relationship between
choice set size and the use of elimination strategies. Three
different analyses examined the impact of increased set
size. All three analyses would suggest the use of noncompensatory rules (such as the conjunctive and eliminationby-aspects):
1. An analysis of the decision processes described by the
protocols: As set size increased, we expected an increase
in the proportion of statements which eliminated alternatives, an increase in comparisons, and a relative decrease in the numberof evaluation statements.
2. An analysis of information search as described in the
protocol: As set size increased, we expected an increase

<-----Page 7----->THEJOURNALOF CONSUMERRESEARCH

534
in the proportionof statementsexamining the alternative
eventually chosen.

TABLE 1
PROPORTION OF STATEMENTS OF EACH TYPE OF SET SIZE

3. An analysis of the pattern of informationsearch: As set
size increased, we expected more attribute-basedsearch.

To explore the decision process portrayedin the protocols, we conducted an analysis of variance upon the proportionof statementsassigned to each category. This analysis used the position of the verbal report (first, second,
third replication) as a between-subjectsfactor, and choice
set size (1, 2, 4, or 8) as a within-subjectsfactor. Table 1
presents the relevant results, the proportionof each statement assigned into each coding category tabulatedby set
size. The columns on the right present significancetests of
the effect of choice set size in each analysis of variance.
A multivariateanalysis of variance confirmed the significance of the effect of set size for each statementtype.5
Increases in set size had marked effects on the composition of the protocols. Specifically, as the number of alternativesincreased, the protocolscontainedrelativelymore
statements reading information, less evaluation of that information, and somewhat more eliminations. Not surprisingly, comparisons were common in choice (N > 2) but
not in judgment (N = 1). The increasedfrequencyof eliminations in larger set sizes was consistent with the hypothesis that increases in set size should be associated with
increases in the use of noncompensatorystrategies.
Additional evidence was provided by an analysis of the
proportion of statements mentioning the chosen brand.
Johnson and Russo (1984) have suggested that noncompensatory decision strategies will result in an unbalanced
search of the brand X attributematrix. Specifically, noncompensatorystrategieseliminate inferioralternativesfrom
consideration, resulting in increased search of the brand
eventually chosen. If noncompensatoryprocesses become
more common with larger set sizes, then we expect search
to be relatively more concentratedfor larger set sizes.
We calculated an index of the concentrationof search,
P = (C - (1/n)), which representsthe proportionof statements mentioning search of the chosen alternative(C) in
comparison to that predicted by equal search of all alternatives (l/n). A positive value of this index would indicate
that search of the chosen alternativeexceeded thatpredicted
by chance. The value of this index increasedwith set size:
for 2 alternativesP = 0.03, while for 4 and 8 alternatives,
the index was 0.05 and 0.13, respectively. An analysis of
variance, similar to the one above, was conducted on the
proportionof statementsreferringto the chosen alternative
for set sizes of 2, 4, and 8. A linear post-hoc (Scheffe)
contrast, which comparedthe value of P across conditions,
was significant at F (2,. 133) = 28.9 (P - 0.001). Thus,
the increase in the concentrationof search also supported

5The MANOVA was conducted using five of the six categories, since
the remainingcategory is a linear combinationof the remainingfive. The
analysis was also conducted upon the proportionsafter an arcsin transformation, with no substantialchange in the results.

Set size
Statement
type

1

2

4

8

F(3, 121)

P

Read

.48

.56

.62

.63

4.16

.01

Evaluations

.35

.13

.10

.09

29.99

.001

Comparisons

.03

.21

.19

.19

13.36

.001

Eliminations

.00

.00

.02

.05

3.90

.02

Strategy

.01

.01

.01

.02

3.38

.03

Rating

.12

.08

.05

.04

28.12

.001

the hypothesis that the use of noncompensatorystrategies
increases with set size.
Finally, an examinationof the transitionsin the protocol
was also consistent with the hypothesized shift to noncompensatoryprocesses in larger set sizes. Using only "read"
statements (the closest indicator of the brand or attribute
information that was being processed by the subject in a
given scenario), we calculated the indices of brand and
attribute processing suggested by Bettman and Jacoby
(1976):
Normalizedproportion (Numberof samebrandtransitions)/M
transitions
(Totalnumberof transitions)
-

where M equals:
searched)
(Numberof totaltransitions- Numberof attributes
(Numberof totaltransitions)
or the maximum numberof brandtransitionspossible.
The equivalentmeasurewas developed for attributetransitions. An analysis of variance on these dependent measures confirmed that attribute-basedprocesses were more
common in larger set sizes. The mean percentages of attributetransitionswere 0.26, 0.36, and 0.40 for 2, 4, and
8 alternatives, respectively, while the proportionsof brand
transitionswere 0.73, 0.61, and 0.58. Linearpost-hoc contrasts confirmedthe significance of these trends with F (2,
116) = 7.74 and 21.23, p - 0.001 for both. Although one
compensatoryrule-additive differences-could have produced a high proportionof attributetransitions, an examination of the protocols showed that use of this rule was
rare. Moreover, additive differences would not producethe
observed differences in the content of the protocols or an
increased concentrationof search as set size increases.
In sum, evidence from the content of the protocols, the
proportionof search devoted to the chosen alternative,and
the amount of search by brand and by attributeprovided
evidence consistent with the hypothesis that increasesin set
size were accompaniedby increased use of noncompensatory processes.

<-----Page 8----->COMPENSATORY
CHOICEMODELS

535

FIGUREB

Logit Analysis

OF SET SIZE
USAGEAS A FUNCTION
ATTRIBUTE
RELATIVE
.5 _

w
n

.4

-

UA.

0

z
w

RENT

)

ow

.3

-

DISTANCE

w
F
-J

w

2
APPEARANCE
MAINTENANCE
.1_

1

2

4

The logit analysis examined Hypotheses 3 and 4-the
effect of choice set size on parameterestimates of the compensatory model parameters, and overall fit. Although it
would have been desirable to test these hypotheses at the
individual level, the sparse nature of discrete choice data
would not permit convergent parametersolutions of individual models.6 Hence it was necessary to test the hypotheses at the group level using an expandedsubjectpool.
The possible ambiguities induced by conducting our tests
at the group level are discussed as we consider each hypothesis in turn.
Subjects. Ninety-one subjects participatedin response
to signs posted on campus, and were again paid $4.00 to
participatein an hour-long experimentalsession. Subjects
were run in groups that ranged in size from three to 20,
over a one-week period.

8

NUMBEROF ALTERNATIVES
INCHOICESET

Procedure. The experimentalprocedurebasically mirrored that used in the individual-level analyses, with three
modifications:
of the design.
1. Subjectscompletedonly two replications

Analyses Related to Hypothesis 2: Changes in Attribute
Use. Our second majoranalysis focused on the hypothesis
that the frequencywith which major "screening" attributes
are referred to during the choice process should increase
with increases in set size. In Figure B, we plot the proportion of statementsreferringto each of the four attributesfor
each set size. As this figure demonstrates,the proportion
of references to rent increased as the set size increased,
while maintenance and appearance were mentioned proportionatelyless often. Distance also showed a proportional
increase in frequencyof mentions in the largest size choice
set. The effect of set size was confirmedby an analysis of
varianceconductedon the individualstatements.This analysis treatedattributesand set size as within-subjectfactors.
Overall, the interactionbetween set size and attributeuse
was significant (F (3, 2103) = 5.67 p s 0.001), as was
the post-hoc linear contrast for all four categories (p S
0.001).

We might also point out that while set size induced
changes in the relative frequencywith which attributeswere
mentioned, it did not appearto induce changes in the order
of referrals.For set sizes of two or more, the rankorderof
attributeusage remained constant despite changes in the
raw relative frequencies (see Figure B).
Summary.

The results of the protocol analyses sug-

gested that the desired necessary conditions for testing Hypotheses 3 and 4 existed in the experiment. In particular,
when confronted with larger set sizes, subjects tended to
make more frequentuse of noncompensatorystrategiesand
to alter the relative frequency with which they referredto
attributes. Hypotheses 3 and 4 are theoretical predictions
concerning how these changes should impact upon the parametersand fit of a compensatory(logit) model.

2. The orderof set-size presentationwas randomizedbetweensubjects.
3. Verbalprotocolswerenot elicited.
Analyses Related to Hypothesis 3: The Effect of Set Size
on Revealed Measures of Attribute Importance. We
wished to test the hypothesis that increases in the size of
a choice set would cause the distributionof attributesalience parametersin a compensatorychoice model to become increasinglyskewed or polarizedbetween "filtering"
and "final comparison" attributes.An implicit assumption
when testing this hypothesis at the group level is that the
subject pool is relatively homogeneous in terms of their
decision-making processes. While each subject might use
staged processes for larger choice sets, if individuals use
differentattributesfor "filtering" the set, upon aggregation
we may observe no change in the mean salience of an
attributeacross levels of set size. Hence, while the parameter-changehypothesis may be true at the individuallevel,
it may well disappear when studying the behavior of a
highly heterogeneousaggregate. Violations of our assumption result in a conservative test.
With this caveat in mind, we examined changes in the
statistical effect of attributes across set sizes. To ensure
compatibilitybetween desirabilityratingscollected for sizes

6A traditionallimitation of discrete choice analyses is that model estimation invariably requires aggregation across a subject pool. Some researchers have attemptedto avoid this problem by having subjects "allocate" several choices among alternatives(e.g., Batsell 1980), but there
is empirical evidence that subjects' behavior in allocation tasks is not
equivalent to that in analogous discrete choice tasks (e.g., Meyer and
Eagle, 1982).

<-----Page 9----->THEJOURNALOF CONSUMERRESEARCH

536
of one and discrete choices (collected for set sizes of two
or more), ratingswere convertedto a binaryscale using the
mean ratingresponse as a cut off; specifically:7
I1 if Rating - overall mean rating
Pr(Target)
Pr(argt) ~0 otherwise
Hence, the dependent variable in all cases was a binary
indicatorof preferencefor the targetalternative.Two analyses were performedon the data:

FIGUREC
AS A FUNCTION
OF SET SIZES
ATTRIBUTE
IMPORTANCE
- RENT

C.)

3

z

/

/

H
n0

1. A graphical analysis of changes in the impact of the attributes (a measure of attribute importance) across the
various set size conditions.

2. A statistical analysis of these changes using a discrete
binary logit model of the individualchoice data.

3

2

Statistical Analysis. To provide a statistical test of the
above results, the discrete choices were subjected to a bi7To investigate the effects of this transformationon parameterestimates
and model fit, the judgmental data were analyzed using both the original
ratings data (transformedto a probabilityscale) and the 1-0 binary scale.
The results of both analyses were comparable.In particular,both yielded
nearly identical fits (pseudo R2's of 0.269 in both cases) and, correspondingly, similar parameterestimates.

_

MAINTENANCE

APPEARANCE
cc

GraphicalAnalysis. To provide an initial, visual examination of the parameter-changehypothesis, choice proportions associated with the target (experimental)alternative
were computed for each cell of the design (1982 discrete
observationsper cell). Because a logit model (Equation8)
was assumed to underlie these data, proportionswere subjected to a logit transformationof the form ln(Pr(Target/
1 - Pr(Target)). Differences in marginal means between
the two levels of each attributewere then computedto obtain measures of the relative salience of each attributefor
each level of set size (e.g., Anderson 1982; Green 1974).
A plot of the derived measures of attributeimportance
with set size provided initial support for the research hypothesis (Figure C). In particular,as hypothesized, the distribution of experimental effects becomes increasingly
skewed with increases in the size of the choice set. Over
the three "choice" conditions (set size of 2, 4, or 8), the
importanceof "rent" monotonicallyincreased,while those
of "distance" and "maintenance" monotonically decreased. The only exception was "appearance," which did
not demonstratea monotonic change in salience.
We can also compare the plot of changes in revealed
attribute salience (Figure C) and the plot of changes in
attributeuse reportedby subjects in the protocol task (Figure B). Although these results are based on the responses
of two different groups of subjects, in both cases the distribution of attribute saliencies and use became more
skewed with increases in set size, with rent increasing in
importanceand maintenanceand appearancedecreasing in
importance. The exception was distance, which decreased
in revealed salience with increases in set size in the choice
task, while being referred to more frequently by subjects
in the protocol task.

.

.________________________________

WU
1

--

,'

1

4

2

_

DISTANCE

8

NUMBEROF ALTERNATIVES
INCHOICESET
aAltribute importance is defined as the absolute difference in logit-transformed marginal
means (choice proportions) for each attribute.

nary logit analysis. The model we estimated centered on
the probability of subjects choosing the target alternative
(t) in a given choice set j. Letting P(t|j) be this probability,
we estimated a model of the following general form:
(F(X

))

(11)

The function F(Xtjj) was a linear combination of the following 63 terms:
1. The value of the target on each of the four attributes,
expressed as a deviation from the choice set mean (not
including the target).'

2. Three estimatable two-way attribute interactions (each
with "rent").
3. Three variables reflecting linear, quadratic, and cubic
trends in "choice set size."
4. 21 two- and three-wayinteractionsbetween the "set size"
trends and each attributemain effect and two-way interaction.
5. 32 terms reflecting the effect of "replication" (a main
effect and 31 interactions).
Choice set size trends were coded as orthogonal polynomials, and each attribute was expressed as a deviation
from the choice set mean to minimize that error variance
which might have been associated with random differences

8For choice sets of size one (the judgment condition), the choice set
mean was uniformly set equal to the grand choice set mean.

<-----Page 10----->COMPENSATORY
CHOICEMODELS
in the way each treatment combination was presented. Because each attribute main effect was represented as a continuous variable, each difference vector was centered about
its respective mean to maximize orthogonality with each
two-way attribute interaction vector (Robson 1959).
The 64 parameters in Equation 11 were estimated via
maximum likelihood, using the software package CRAWTRAN (Avery 1982). The results can be summarized as
follows (see Table 2):
1. All four attributemain effects were highly significant, as
was the rent x distance interaction.This interactionimplied that the underlying "average" judgmentrule had a
nonadditive-or perhaps a noncompensatory-component. As suggested from the graphical analyses, rent
emerged as the most salient predictor.
2. There was a significant decrease in the relative frequency
of choices of the targetas set size increased.As one would
expect, the larger the set size, the lower the mean probability of choosing the target.
3. There was no systematic effect due to "replication," implying that subjects did not vary decision strategiesacross
replicationsin the experiment.
4. Set size systematicallyinteractedwith only one apartment
attribute:rent.
The significant set size X rent interaction lends statistical
support to our earlier observations that the revealed importance of rent increased with increases in the size of the
choice set. Moreover, associated with this change were significant linear and quadratic trends. The directions of the
trend coefficients implied that:
1. As set size increased, the slope or effect of rent became
increasinglynegative (the linear set size X renttrendwas
negative).
2. As set size increased, this increase decelerated(the quadratic set size x rent trend was positive).
The fact that none of the other set size x attribute interactions were significant implied that the importance of
the other three apartment attributes was relatively constant
across the four set sizes. Although the graphic analysis
suggested a monotonic decrease over the (N = 2, 8) interval for distance and maintenance, the overall effect was not
statistically significant.
In sum, the data lent support to the basic hypothesis that
increases in set size affects the distribution of derived attribute effects. Similar to the protocol results, attribute
weights became polarized, with rent increasing in importance and other attributes decreasing in importance with
larger set sizes.

Results Related to Hypothesis 4: Changes in Predictive
Ability Across Set Sizes. This analysis focuses on the robustness of the compensatory choice model in prediction.
The analysis centered on two related issues:
1. The fit of a compensatory model as set size increased
(Hypothesis 4).

537
TABLE 2
LOGIT ESTIMATIONRESULTS
Coefficient

T-statistic

Pr(T)

Attribute main effects
Rent
Distance
Maintenance
Appearance

- .028
- .079
.530
.433

- 33.833
-13.217
16.29
13.49

.0000
.0000
.0000
.0000

Set size effects
Linear trend
Quadratic trend
Cubic trend

-.245
.340
.154

-10.215
- 6.519
6.834

.0000
.0000
.0000

Interactions with rent (R)
R x Distance
R x Maintenance
R x Appearance

-.000
-.002
-.001

-.498
-3.736
-1.962

.6181
.0186
.0497

Interactions with set size (N)
a. Linear trends (NL)
NL x Rent (R)
NL x Distance (D)
NL x Maintenance (M)
NL x Appearance (A)
NL x R x D
NL x R x M
NL x R x A

-.002
-.003
-.016
- .003
.000
-.000
-.000

- 4.611
- 1.012
- 1.034
- .190
1.007
-1.488
-.925

.0004
.3114
.3011
.8493
.3138
.1366
.3536

b. Quadratic trends (NQ)
NQ x Rent (R)
NQ x Distance (D)
NQ x Maintenance (M)
NQ x Appearance (A)
NQ x R x D
NQ x R x M
NQ x R x A

.002
.010
- .036
.046
.000
.000
.001

2.746
1.673
-1.095
1.455
2.214
.635
1.281

.0060
.0944
.2736
.1456
.0268
.5253
.2001

c. Cubic
NC x
NC x
NC x
NC x
NC x
NC x
NC x

- .001
- .003
.006
.015
.000
-.000
-.000

-2.171
-1.236
.399
1.122
.097
-1.399
-.921

.0299
.2164
.6898
.2617
.9228
.1616
.3569

trends (NC)
Rent (R)
Distance (D)
Maintenance
Appearance (A)
R x D
R x M
R x A

NOTE: Fit indices: Residual R-squared: .462; Log-likelihood R-squared: .405; Chi-squared
test of model (54 df): 3230.00.

2. The predictive ability of such models across tasks-that
is, the ability of a compensatory model derived in one
context (e.g., judgment) to predict behavior in another
(e.g., choice).
We addressed both these issues in a single analysis.
Group-level binary logit models were estimated for each
of the four choice set-size conditions of the experiment,
and were then used to predict observed choices in all four
set sizes.9 To provide a basis of comparison, the predictive
9Our method of cross-prediction was to regress the predicted choice
frequency of the target under a model derived in one set size against the
observed choices in another. This linear transformationprovided an optimal adjustmentof predictionsfor differences in mean choice frequencies
between conditions (model intercepts).

<-----Page 11----->538

THEJOURNALOF CONSUMERRESEARCH

ability of a naive, equal-weightmodel was also examined.
Predictive ability was assessed using three indices of fit:
1. The "predictiveefficiency"(pseudoR2 or p2) of each
model.
of correctpredictionsof the targetalter2. The proportion
natives.
3. Therootmeansquarederrorof predictedchoices.
Changes in PredictiveAbility across Set Sizes. Results
relatingto the predictionanalysis are summarizedin Table
3. The researchhypothesis that overall fit should decrease
with increases in set size was tested by noting:
1. The predictiveabilityof the modelderivedfor eachsetsize condition(thediagonalfit indicesin Table3).
of choicesin each condi2. The "averagepredictability"
tion, whichwas derivedby averagingfit indicesacross
models(thecolumnmeansin Table3).
Neither measure supportedthe hypothesis. Rather than
predictive abilities decreasingwith increasesin set size, we
observed, if anything, an increase. For example, in terms
of proportionof correct predictions and root mean square
error, choices made from sets of size eight displayed the
highest predictability.In the task where we most expected
subjects to employ noncompensatorydecision strategiesthe choice among eight alternatives-the compensatory
model actually displayed its highest predictive ability.
Mirroringthis result, note that transformedchoices observed in the judgmentcondition(which our theorysuggests
will be best predictedby a compensatorymodel) were the
least predictable. While the overall stability of fit indices
within the choice tasks may be somewhat perplexing, the
decreases in the judgment conditions may have a rather
straightforwardexplanation:responsesin the judgmentconditions were fundamentallymore variable due to betweensubject differences in rating scale usage. Thus the low predictive ability of judgment vis-a-vis choices may reflect
differences in the total between-subjecterrorin the experimental conditions.
To provide a statistical test of fit variation, the rootsquarederrorfor each observationwas subjectedto an analysis of variance. This analysis contained two factors, paralleling those displayed in Table 3:
1. The set size of the datausedfor estimation.
2. The set size of the databeingpredicted.
This analysis tested the significance of the changes in predictive validity shown in Table 3.
The two main effects were significant at p < 0.0001,
suggesting that:
1. The variouschoice set sizes significantlyvariedin their
predictability.
2. Some models providedbetterlevels of predictionthan
othersacrossset sizes.
Finally, a significant interaction between the two (p

<

0.001) indicatedtherewas significantvariationin the ability
of the models to predict choices across tasks. Hence, the
analysis suggested that the variation in predictive validity
shown in Table 3, although small in absolute terms and
counterto the hypothesizeddirection, was greaterthan that
expected by chance.
Cross-Task Robustness. One of the most impressive
aspects of the results was the lack of differences in predictive ability across contexts. Although the cross-task variation in predictive ability of the derived models was statistically significant, the absolute numerical difference was
small. Differences in "success rates" for predictionsby the
models across choice contexts ranged from 6 percent for
the judgment data to 2.4 percentfor choice sets of size two.
Hence, if one were willing to accept 2.4 percentdifference
in success rates as an acceptableerror, one could draw the
reasonable conclusion that the models were robust to estimation context.
We should add that even the naive (equal-weight)model
performedreasonablywell in cross-taskprediction.For example, the average success rate in predictionsof the target
using the equal-weight model (where 50 percent was
chance) was 74.5 percent, comparedto an average of 80.1
percent for the best differentialweight model.

DISCUSSION
In recent years, the literature in consumer choice has
been strongly influenced by two different paradigms:algebraic modeling and process tracing. Algebraic modeling
has tended to dominate applied work in disaggregateconsumer demand forecasting, while process tracinghas dominated research focusing on the cognitive processes underlying choice. Their differences, however, have been more
than either their fields of application or methodologies.
Each appearsto be rooted in fundamentallydiffering views
of how we make choices. The paradigmof algebraicmodeling is based on the assumptionthatit is possible to recover
"context-free" judgment policies. Research in process
tracing, however, suggests that such policies may not exist:
choice strategiesoften appearto be contingentupon the set
of alternativesbeing evaluated.
The purpose of this researchwas to explore some of the
implicationsof this apparentparadox. In particular,we examined the impact that variations in processing strategies
across contexts might have on the parametersand fit of an
algebraic (compensatorylogit) model of choice.
We began with a theoreticalanalysis of the types of specification errors which may arise when representinga noncompensatorychoice strategy with a compensatorychoice
model. This analysis suggested that:
1. The relative revealed importanceof an attributeshould be
related to the relative frequency of its use during a sequential choice. process.
2. While the compensatory model may coiTelatewell with
data generatedby a noncompensatorymodel, the relative
magnitude of this correlation should decrease with increases in the extent of underlyingcontingentprocessing.

<-----Page 12----->COMPENSATORY CHOICE MODELS

539
TABLE3
FIT INDICES
Set size used for prediction

Set size
used for
estimation

Fit index
p2

1

% correcta
MSE

2

% correct
MSE

4

% correct
MSE

8

% correct
MSE

p2

p2

p2

Column means
(average setsize fit)

p2

% correct
MSE

1

2

4

8

Row means
(average
model fit)

.269
72.8
.341

.410
81.3
.306

.400
80.2
.306

.470
81.7
.316

.387
79.0
.318

.254
73.1
.326

.438
83.2
.242

.425
81.1
.248

.488
81.5
.330

.401
79.7
.299

.248
73.1
.316

.436
83.7
.285

.425
81.3
.252

.486
81.0
.249

.398
79.8
.276

.251
73.1
.317

.432
83.6
.308

.420
81.3
.246

.490
82.4
.228

.398
80.1
.275

.256
73.0
.325

.429
82.9
.285

.417
81.0
.276

.484
81.6
.281

Equal-weight model
Set size
Fit index

1

2

4

8

p2

.216

.292

.277

.356

% correct
MSE

68.9

75.1

.408

74.0

.381

.399

79.8
.406

Mean
.285
74.5
.399

aln this analysis, random assignment would predict the target correctly 50 percent of the time.

These theoretical results were then tested in the context
of a controlled laboratory experiment which focused on
preferencesfor hypotheticalapartmentsdisplayed in choice
sets of varying sizes. The results provided mixed support
for the research hypotheses. As predicted, there was an
increase in the tendency for subjects to use elimination
strategieswhen faced with largerset sizes. Associated with
these changes in processing rules were concomitantchanges
in attributeusage and revealed attributeimportance.In particular, the most importantapartmentattribute-rent-was
mentioned more frequently and increased in revealed salience with larger set sizes, while other attributes(maintenance and appearance)gradually decreased in overall importance.
A major prediction not supportedby the data was a decrease in the predictive ability of a compensatory model
with increases in set size. In terms of root mean squared
error and proportionof correct predictions, there was actually a slight increase in the ability of the compensatory
logit model to characterizeobserved choice data with increases in set size.
There are several reasons why this hypothesis may not
have held. Our theoretical analysis addressed only error
resulting from the mismatch of model to the underlying
process, and not errordue to other sources. Any other sto-

chastic error was assumed to be homogeneous across set
sizes. This assumption may not be reasonable, as other
sources of error may well change with set size. For example, individualsmay apply choice rules less consistently
in one set size than in another, or they may disagree more
on attributeimportancein one set size than in another.This
lattereffect could explain the apparentincrease in the fit of
the logit model across levels of set size; while larger set
sizes tend to increase the use of eliminationstrategies, they
may also lead individuals to adopt the same attributefor
screening, in this case, rent.
Thus any decrease in fit due to an inappropriatemodel
may be masked by an increase in fit due to greaterhomogeneity in decision processes. Note, however, thatalthough
individual analyses would eliminate this one source of error, it would not eliminate others, such as the inconsistent
application of a decision rule. Clearly, the approximation
error is more difficult to test unambiguouslythan it might
initially appear.
One intriguing aspect of the results was the uniformly
high levels of explanation provided by the compensatory
(logit) model. Although significantparametervariationwas
observed across set sizes, the absolute magnitude of this
variationwas relatively small and did not involve a reversal
of the rank order of importance. Because of this, derived

<-----Page 13----->ill(

THF .IOlUIPNAI OlF CONSIIMFR

models were remarkablyaccuratein predictionacross different set sizes. For example, the model that was derived
on the basis of judgmentspredictedchoice behaviornearly
as well as the models which were explicitly estimated on
choices.
An apparentimplicationof this result is additionalcredibility for methodsof consumerforecastingthatrely on the
ability of compensatorymodels of decision makingderived
in one context-such as judgments-to predict choices
made in another-for example, choice simulators (e.g.,
Green et al. 1980, 1981). The fact that the "true" underlying decision process may be different for judgments and
choices in a given context may well have little effect on
cross-taskpredictive ability.
Such optimism, however, should be tempered by considering the generalizabilityof the currentresults. Recall
that in the current experiment, apartmentattributeswere
uncorrelated.The robustnessof compensatorymodels given
uncorrelatedattributesis well known, so this experimental
result might have been anticipated (e.g., Einhorn et al.
1979). Yet in the real world, this will not always be the
case. Like "price" and "quality," one might expect many
attributesto be negatively correlated. This negative correlation increases differences in the choices made by compensatory and noncompensatoryprocesses (Einhornet al.
1979; Newman 1977).
Moreover, information search costs in the experiment
were small when compared to many nonlaboratorysituations; all relevant information was presented on a single
page. In actual decision situations, search can be much
more costly, involving extensive investment of time and
effort. Under these conditions, we may expect a greater
degree of contingentprocessing, with a subsequentdecrease
in the ability of a compensatory approximationto predict
choices.
The primarycontributionof this researchis the demonstration that compensatory approximationsmay be transferable under certain conditions. It then becomes an interesting empirical question for futureresearchto identify the
boundariessurroundingtransferability.Although there are
a number of reasons for suspecting that the robus'tnessof
models reportedhere may not extend into real world markets, this remains an empirical issue.
In closing, we should note thatthe conditionsfor a model
failure can be detected, in part, throughthe use of multiple
methods for representing decision processes. The use of
noncompensatorystrategieshas provento be a difficultphenomenon to detect within a linear models framework, yet
it is readily apparentfrom even a casual examination of
verbalprotocols. Similarly, the robustnessof compensatory
approximationsfor prediction could be easily established
at a group level only by a revealed preference model.
Hence, we suggest that the use of two techniques and the
combination of individual and group analyses has yielded
greater insight than was possible by any single analysis.
Furtheruse of such parallel analyses could help in understanding the effect of changes in choice context on the
predictionand explanationof consumer choice.
[ReceivedApril 1983. Revised January 1984.]

PPRE APRCH

REFERENCES
Anderson, NormanH. (1982), Methodsof InformationIntegration
Theory, New York: Academic Press.
Avery, Robert E. (1982), "Limited DependentVariableProgram
CRAWTRAN," working paper, GraduateSchool of Industrial Administration, Carnegie-Mellon University, Pittsburgh, PA.
Batsell, Randy R. (1980)? "Consumer Resource Allocation
Models at the Individual Level," Journal of ConsumerResearch, 7 (June), 78-87.
Bettman, James R. (1979), An InformationProcessing Theoryof
ConsumerChoice, Reading, MA: Addison-Wesley.
and Jacob Jacoby (1976), "Patternsof Processing in Consumer InformationAcquisition," in Advances in Consumer
Research, Vol. 3, ed. Beverlee B. Anderson, Ann Arbor,
MI: Association for ConsumerResearch, 315-320.
and C. Whan Park (1980), "Effects of Prior Knowledge
and Experienceon ConsumerDecision Processes:A Protocol
Analysis," Journal of ConsumerResearch, 7 (December),
234-248.
Billings, Robertand StephanMarcus(1983), "Measuresof Compensatoryand NoncompensatoryModels of Decision Behavior: Process Tracing versus Policy Capturing," Organizational Behavior and Human Pefoiorinance, 31 (August),
331-352.
Birnbaum, Michael F. (1973), "The Devil Rides Again: Correlation of An Index of Fit," Psychological Bulletin, 79 (2),
239-242.
Currim, Imran (1982), "Predictive Testing of ConsumerChoice
Models Not Subject to Independenceof IrrelevantAlternatives," Journal of Marketing Research, 19 (May), 208222.
Curry, David J., Jordan J. Louviere, and Michael Augustine
(1981), "Comment on the Sensitivity of BrandChoice Simulatorsto AttributeImportanceWeights," Decision Sciences,
12 (July), 502-516.
Dawes, Robin M. and BernardCorrigan(1974), "Linear Models
in Decision Making," Psychological Bulletin, 81 (2),
95-106.
Einhom, Hillel J. (1970), "The Use of Nonlinear, Noncompensatory Models in Decision Making," Psychological Bulletin,
73 (3), 221-230.
, Donald N. Kleinmuntz, and Benjamin Kleinmuntz
(1979), "Linear Regression and Process-TracingModels of
Judgment," Psychological Review, 86 (5), 464-485.
Green, Paul E. (1974), "On the Design of Choice Experiments
Involving Multifactor Alternatives," Journal of Consumer
Research, 1 (Septemiber),61-68.
J. Douglas Carroll, and Steven M. Goldberg (1981),
"A General Approach to Product Design OptimizationVia
Conjoint Analysis," Journal of Marketing, 45 (3), 17-37.
, Wayne S. DeSarbo, and Paul Kedia (1980), "On the
Sensitivity of Brand-Choice Simulators to AttributeImportance Weights," Decision Sciences, 11 (July), 439-450.
Grether, David and Louis Wilde (1984), "An Analysis of Conjunctive Choice: Theory and Experiments,"Journtalof Consumer Research, 10 (March), 373-385.
Hahn, G. J. and S. S. Shapiro(1966), "A Catalog and Computer
Program for the Design and Analysis of OrthogonalSymmetric and Asymmetric FractionalFactorial Experiments,"
Technical Report 66-C-165, General Electric Research and
Development Center, Schenectady, New York.
Hensher, David A. and Lester Johnson (1981), Applied Discrete
Choice Modeling, Landon-Croom-Helm/New York: John
Wiley.

<-----Page 14----->COMPENSATORY
CHOICEMODELS
Johnson, Eric J. and J. Edward Russo (1984), "Product Familiarityand LearningNew Information,"Journal of Consumer
Research, 11 (June), 542-550.
Keeney, RalphL. and HowardRaiffa (1976), Decision withMultiple Objectives: Preferences and Value Tradeoffs, New
York: John Wiley.
Lichtenstein, Sara and Paul Slovic (1971), "Reversal of Preference Between Bids and Choices in Gambling Decisions,"
Journal of ExperimentalPsychology, 89 (1), 46-55.
Louviere, Jordan J. (1979), "Modeling Individual Residential
Preferences:A Totally Disaggregate Approach," Transportation Research, 13 (A), 374-384.
and George Woodworth(1983), "Design and Analysis of
Simulated ConsumerChoice or Allocation Experiments:An
ApproachBased on Aggregate Data," Journal of Marketing
Research, 20 (November), 350-367.
McFadden,Daniel (1981), "EconometricModels of Probabilistic
Choice," in StructuralAnalysis of Discrete Data with Econometric Applications, eds. Charles F. Manski and Daniel
McFadden, Cambridge,MA: MIT Press, 198-272.
Meyer, RobertJ. and Thomas C. Eagle (1982), "Context-Induced
ParameterInstability in a Disaggregate-StochasticModel of
Store Choice," Journal of MarketingResearch, 19 (February), 61-71.
Nakanishi, Masao and Lee G. Cooper (1982), "Simplified Estimation Proceduresfor MCI Models," MarketingScience, 1
(3), 314-322.
Newell, Allan and Herbert S. Simon (1972), Human Problem
Solving, Englewood Cliffs, NJ: Prentice-Hall.
Newman, J. Robert (1977), "Differential Weighting in Multiattribute Utility Measurement:Where It Should and Where It
Does Make a Difference," Organizational Behavior and
Human Performance, 20 (December), 312-325.

541
Olshavsky, Richard W. (1979), "Task Complexity and Contingent Processing in Decision Making: A Replicationand Extension,"

Organizational

Behavior and HumnaniPer'or-

mance, 24 (December), 300-316.
and Frank Acito (1980), "An Information Processing
Probe into ConjointAnalysis," DecisioniSciences, 11 (July),
451-470.
Payne, John W. (1976), "Task Complexity and ContingentProcessing in Decision Making:An InformationSearchand Protocol Analysis," OrganizationalBehavior anidHumaniPerformance, 16 (August), 366-387.
(1982), "Contingent Decision Behavior," Pswyhological
Bulletin, 92 (September), 382-402.
Robson, Donald S. (1959). "A Simple Method for Constructing
OrthogonalPolynomials When the IndependentVariable is
Unequally Spaced," Biometrics, June, 187-191.
Russo, Jay E. and Barbara A. Dosher (1983), "Strategies for
MultiattributeBinaryChoice," Journal of ExperimentalPsychology: Learning, Memory, and Cognition, 9 (October),
676-696.
Svenson, Ola (1979), "Process Descriptions of Decision Making, " OrganizationalBehavior and HumaniPertrmnance,23
(1), 86-112.
Tversky, Amos (1972), "Elimination by Aspects: A Theory of
Choice," Psychological Review, 79 (July), 281-299.
Urban, Glen L. and John R. Hauser (1980), Decision and Marketing of New Products, Englewood Cliffs, NJ: PrenticeHall.
Wright, Peter L. and FrederickBarbour(1977), "PhasedDecision
Strategies: Sequels to an Initial Screening," in North-Holland/TIMSStudies in the Management Science, Volume 6:
Multiple Criteria Decision Making, eds. M. K. Star and
Milan Zoleny, Amsterdam:North Holland, 91-109.

