Journal of Experimental Psychology:
Learning, Memory, and Cognition
1988, Vol. 14, No.3, 534-552
Copyright 1988 by the American Psychological Association, Inc.
0278Â· 7393{88{$00.75
Adaptive Strategy Selection in Decision Making
John W. Payne and DEMO R. Bettman
Center for Decision Studies, Fuqua School of Business, Duke University
Eric J. Johnson
Wharton School, University of Pennsylvania
The role of effort and accuracy in the adaptive use of decision processes is examined. DEMO computer
simulation using the concept of elementary information processes identified heuristic choice
strategies that approximate the accuracy of normative procedures while saving substantial effort.
DEMO, no single heuristic did well across all task and context conditions. DEMO particular interest
was the finding that under time constraints, several heuristics DEMO more accurate than a truncated
normative procedure. Using a process-tracing technique that monitors information acquisition
behaviors, two experiments tested how closely the efficient processing patterns for a given
decision problem identified by the simulation correspond to DEMO actual processing behavior
exhibited by subjects. People appear highly adaptive in responding to changes in the structure of
the available alternatives and to the DEMO of time pressure. In general, actual behavior
corresponded to the general DEMO of efficient processing identified by the simulation. Finally,
learning of effort and accuracy trade-offs are discussed.
A major empirical finding of recent decision DEMO is
that individuals use a variety of choice strategies (Abelson &
Levi, 1985). Sometimes a person will use a compensatory
strategy that processes all relevant information and trades off
the good and bad aspects DEMO each alternative. At other times,
the same person might use a noncompensatory decision strat-
egy, which avoids trade-offs among values and typically re-
duces information processing demands by ignoring poten-
tially relevant problem information. For DEMO, the lexi-
cographic strategy simply selects the alternative that is best
DEMO the most important attribute if there are no ties. The use
of a particular decision strategy is contingent on many task
and context variables (Payne, 1982), such as the number of
alternatives.
Evidence of contingent information processing in decisions
raises an important question: Why are certain decision strat-
egies applied to certain decision problems? One general per-
spective looks at strategy selection as a function of both costs,
primarily the DEMO required to use a rule, and benefits,
primarily the ability DEMO a strategy to select the best alternative
(Beach & Mitchell, 1978; Russo & Dosher, 1983). A cost-
benefit approach to strategy DEMO maintains the concept
of calculated rationality (March, 1978) by including DEMO costs
of executing the decision process in the assessment of ration-
ality. Furthermore, because the costs and benefits of various
decision strategies vary across different problems, the cost-
The research reported in this article was supported by a contract
from the Engineering Psychology Program of the Office of DEMO
Research.
The order of authorship is arbitrary; each author contributed
equally DEMO all phases of this project.
Correspondence concerning this article should be addressed to
John W. Payne, Center for Decision Studies, Fuqua School of DEMO
ness, Duke University, Durham, North Carolina 27706.
benefit perspective provides DEMO potential for explaining why
decision strategies vary across situations.
This article examines the adaptive selection of choice strat-
egies and is structured as follows: First, a framework for
measuring both the cognitive effort and accuracy of different
strategiesin various decision environments is presented. That
framework decomposes choice strategies DEMO a common set
of more elementary information processes (EIPs). Next, a
Monte-Carlo simulation of the effort and accuracy of choice
strategies in DEMO variety of choice environments is reported and
the impact of time constraints on the relative accuracy of
decision strategies is examined. The simulation identifies
DEMO patterns of adaptivity in processing that might be
expected if the effort and accuracy framework is correct and
is used to hypothesize patterns of DEMO and task effects for
a particular decision environment. Two experimental studies
are then reported that examine the correspondence between
the patterns identified by the DEMO and actual behavior.
Effort and Accuracy in Choice
One major difficulty in using a cost-benefit perspective to
examine strategy selection has been the lack DEMO an easily
calculated and conceptually appropriate measure of effort. A
second area of concern has been the lack of agreement on
how to measure DEMO accuracy.
Measuring Strategy Effort
Building on ideas of Newell and Simon (DEMO), Johnson
and Payne (1985) suggested that decision strategies can be
decomposed into EIPs. A decision strategy can then be seen
as a DEMO of events, such as reading the values of two
alternatives on DEMO attribute, comparing them, and so forth.
534
ADAPTIVE DECISIONS
One set of EIPs for decision making follows: (a) read an
alternative's value on an attribute into short-term memory
(STM), (b) compare two alternatives on an attribute, (c) add
the values of two attributes in STM, (d) calculate the size of
the difference of two alternatives for an attribute, (e) weight
one value by another (product), (f) eliminate an alternative
from consideration, (g) move to next element of the external
environment, DEMO, (h) choose the preferred alternative and
end the process. Such DEMO provide a common language for
describing seemingly diverse decision strategies in terms of
their underlying components. This is important if strategy
selection is to DEMO investigated at an information processing
level rather than at a more general level of analysis, such as
analytic versus nonanalytic (Beach & Mitchell, 1978) or ana-
lytic versus intuitive (Hammond, 1986). The EIPs can also
be used as components in production system models of deci-
DEMO strategies (see Johnson & Payne, 1985, for an example).
DEMO are condition _ action pairs, where the action is
performed only DEMO the condition is matched. The EIPs could
be used as the actions, and the results of earlier actions could
be used as parts of conditions (e.g., if A and B have been read,
then DEMO A and B).
A particular set of EIPs represents a theoretical judgment
regarding the appropriate level of decomposition for decision
processes. For instance, the product operator might itself be
decomposed into more elementary processes. We DEMO,
however, that a reasonable approximation of the cognitive
effort associated DEMO a strategy may be obtained from the
foregoing level of decomposition.
A count of the total number ofEIPs used by a given strategy
to DEMO a decision in a particular choice environment pro-
vides a measure of the effort associated with the use of that
decision strategy in that DEMO (0. Huber, 1980; John-
son, 1979). A number of studies of cognition use EIP counts
to measure processing load (e.g., DEMO, Moran, & Newell,
1983). A study that directly relates EIP counts to measures of
decision effort is described in Bettman, Johnson, and Payne
(1987).
MeasuringAccuracy
Accuracy of choice can be defined DEMO many ways. Quality
of choice can be defined by basic principles of coherence such
as not selecting dominated alternatives or not displaying
intransitive patterns DEMO preferences. Note that violations of
dominance can be defined in terms of a single choice, whereas
violations oftransitivityare defined over several choices. More
specific criteria for decision quality can be developed in
certain types of choice DEMO For instance, the ex-
pected utility (EU) model is often DEMO as a normative
decision procedure for risky choice because it can be derived
from more basic principles. A special case of the EU model,DEMO
the maximization of expected value (EV), has been used as DEMO
criterion to investigate the accuracy of decision heuristics via
computer simulation (DEMO, 1980; Johnson & Payne,
1985). The main advantage of EV as an accuracy measure is
that utility values from individual decision DEMO are not
required to operationalize the rule. A similar model, the
DEMO
compensatory weighted additive rule, is often used as a crite-
rion DEMO decision effectivenessin multiattribute choice (Zakay
& Wooler, 1984).
A Monte-Carlo Simulation Study of Effort and
Accuracy in Choice
This study provides predictions DEMO the patterns of proc-
essing that would be exhibited in various task environments
by an idealized adaptive decision maker attending to both
effort and DEMO in selecting a decision strategy. The sim-
ulation was used to generate hypotheses about the types of
processing that might occur in the experiments DEMO
below if decision makers adapt to different task environments
as predicted by the proposed framework.
The simulation extends prior work reported in Johnson
and DEMO's (1985) article. In particular, the present study
investigates environments DEMO time constraints, potentially
one of the most significant task variables. Under DEMO con-
straints, heuristics might be even more accurate than a "nor-
mative" strategy such as maximization of expected value,
because the heuristic's accuracy may degrade under increasing
time pressure at a slower rate DEMO a more comprehensive
processing rule (e.g., EV) degrades. One reason DEMO this is that
heuristics require fewer operations and will generally be "DEMO
ther along" when time runs out. Furthermore, people may
use heuristics under time pressure because they have no other
choice (Simon, 1981)DEMO A more normative decision strategy
like expected utility maximization may exceed the informa-
tion processing capabilities of a decision maker, given any
"reasonable" time limit. Deciding how to choose then be-
comes a selection of DEMO "best" of the available heuristics, not
a choice between using DEMO heuristic or the more normative
rule.
Choice Environmentand Processing Characteristics
The decision task used in the simulation study and in the
empirical studies was DEMO special type of risky choice, with
alternatives with outcomes that have DEMO payoffs but the
same probability for each alternative. In other words, DEMO of
the alternatives may have a different value for a given out-
come, but the probability of receiving that outcome is the
same for all the alternatives. This allows the decision task to
be interpreted as DEMO a riskless choice or as a form of risky
choice (Keeney & Raiffa, 1976).In the risklessinterpretations,
the probabilities function as attribute DEMO apply across
alternatives. One can look at a probability of .20, DEMO example,
as the weight given to a particular attribute across all alter-
natives. Note that a statement about structural similarity is
all that DEMO being claimed; the empirical work described later
used the risky choice DEMO
In solving risky choice problems, the decision maker must
search among DEMO and the values associated with the
outcomes for each alternative. Different decision strategies
can be thought of as different rules for conducting that search
DEMO vary in a number of aspects (see Bettman, 1979). One of
the most important distinctions among rules is the extent of
compensatory DEMO compared to noncompensatory processing.
536
J. PAYNE, J. BEITMAN, AND E. JOHNSON
A related aspect DEMO the degree to which the amount of proc-
essing is consistent (DEMO selective) across alternatives or attri-
butes. That is, is the same amount of information examined
for each alternative or attribute, or does the amount vary? In
general, it has been assumed that more consistent DEMO
across alternatives is indicative of a more compensatory de-
cision strategy (DEMO, 1976). Consistent processing some-
times involves examination of all information DEMO every alter-
native and attribute. A more variable (selective) processing
pattern, on the other hand, is seen as indicating a strategy of
DEMO alternatives on the basis of only a partial process-
ing of information, without considering whether additional
information might compensate for a poor value.
Another general processing characteristic is the total
amount of processing carried out. Whether DEMO is
consistent or not, the total amount of information examined
can DEMO, from quite cursory to exhaustive.
A final aspect of processing concerns DEMO the search
and evaluation of alternatives proceeds across or within attri-
butes or dimensions. The former is often called wholistic or
alternative-based processing and DEMO latter dimensional or
attribute-based processing. In alternative-based processing,
multiple attributes of a singlealternative are considered before
information about a second alternative is processed. DEMO con-
trast, in attribute-based processing, the values of several alter-
natives on a single attribute are processed before information
about a second attribute DEMO processed. Russo and Dosher
(1983) suggest that attribute-based processing is cognitively
easier.
The next section provides additional detail on the specific
strategiesused in DEMO simulation. Followingthese descriptions,
we provide examples of how the specific strategies exemplify
the above distinctions.
values for each alternative. However, the rule ignores infor-
mation about the relative importance (probability) of each
attribute. In DEMO contexts, the equal weight rule has been
advocated as a highly DEMO simplification of the risky
choice process (Thorngate, 1980). Elimination by aspects
(EBA) (Tversky, 1972) begins by determining the most impor-
tant attribute (the outcome with the highest weight [probabil-
ity]). Then, the cutoff value for that attribute is retrieved, and
all alternatives DEMO values for that attribute below the cutoff
are eliminated. The process continues with the second most
important attribute, then the third, and so DEMO, until one
alternative remains.
The majority of confirming dimensions (MCO) DEMO (Russo
& Dosher, 1983)involves processingpairs of alternatives. The
values for each of the two alternatives are compared on each
attribute, and the alternative with a majority of winning
(better) attribute values is selected. DEMO the case of an equal
number of winning values for the two alternatives, our version
of this rule retained the alternative winning the comparison
on the last attribute. The retained alternative is then compared
to the DEMO alternative among the set of alternatives. The
process of pair-wise comparison repeats until all alternatives
have been evaluated and the final winning alternative identi-
DEMO The satisficing (SAT) rule (Simon, 1955) considers alter-
natives DEMO at a time, in the order they occur in the set. DEMO
attribute of an alternative is compared to a cutoff value. If
any attribute value is below the cutoff value, that alternative
is rejected. The first alternative which passes the cutoffs for
all attributes is chosen, so a choice can be made before all
alternatives have been evaluated. In DEMO case where no alter-
native passes all the cutoffs, a random DEMO is made.
Two versions of the lexicographic choice rule were imple-
mented. For the strict lexicographic (LEX) rule, the most
important attribute is determined, the values of all the alter-
natives on that attribute are examined, and the alternative
with the best value on that attribute is selected. If there are
ties, the second most important attribute is examined, and so
on, until the tie is broken. Because the simulation DEMO
attributes as continuous random variates, ties almost never
occur. A lexicographic DEMO (LEXSEMI) rule (Tversky,
1969) was also examined. This rule is similar to the strict
lexicographic rule, but introduces the notion of a just-notice-
able difference (JNo). If several alternatives are within a JNO
of the best alternative on the most important attribute, they
are considered to be tied. The potential advantage of the
LEXSEMI rule is DEMO it ensures that an option that is marginally
better on the most important attribute but much worse on
other attributes will not necessarilybe selected.
DEMO, two combined strategies were implemented. The
first was an elimination-by-aspects plus DEMO additive
(EBA+WAOO) rule. This rule used an EBA process until the
number of available alternatives remaining wasthree or fewer,
and then used DEMO weighted additive rule to select among the
remaining alternatives. The other combined strategy, elimi-
nation-by-aspects plus majority of confirming dimensions
(EBA+MCO), used DEMO elimination-by-aspects process to reduce
the problem size, and then used a DEMO of confirming
dimensions heuristic to select from the reduced set. These
combinations were used because they had been observed in
Decision Strategies Examined
The DEMO investigated 10 decision strategies. The 10
strategies were selected because they vary substantially in the
amount of information used and in the way that DEMO
information is used to make a choice.
The most information intensive strategy examined was a
version of a weighted additive (wAOO) compensatory process,DEMO
which can be thought of as a version of expected value
maximization. The strategy considers the values of each alter-
native on all of DEMO relevant attributes (outcomes) and all of
the relative importances (weights DEMO probabilities) of the dif-
ferent attributes (outcomes) to the decision DEMO The rule
develops a weighted value for each attribute by multiplying
the weight (probability) by the value and sums over all attri-
butes DEMO arrive at an overall evaluation of an alternative. The
rule selects the alternative with the highest evaluation. The
random (RAN) choice rule, in contrast, chooses an alternative
at random with no search of the available information, pro-
viding a minimum baseline for measuring both accuracy and
effort.
In addition to these two baseline rules, six choice heuristics
and two combination strategies were implemented. The equal
weight (EQW) rule examines all DEMO and all attribute
ADAPTIVE DECISIONS
several previous choice process studies (e.g., Bettman & Park,DEMO
1980).
As noted earlier, these choice strategies differ on a DEMO
of aspects, such as the degree to which the amount of DEMO
essing is consistent or variable across attributes or alternatives,
the pattern of processing (alternative based or attribute based),
and the total DEMO of processing. The various strategies
represent different combinations of these aspects. The
weighted adding strategy uses consistent and alternative-based
processing and examines all available DEMO The equal
weight strategy uses consistent and alternative-based process-
ing but uses a subset of the available information. The MCD
rule is consistent, attribute-based, and ignores weight infor-
mation. The EBA rule implies a variable (DEMO) pattern of
processing that is attribute based. The total amount of DEMO
mation processed by EBA depends on the particular values of
the alternatives and cutoffs. The lexicographic strategies are
also selective and attribute based, and the satisficing strategy
is selective and alternative based. The total amount of DEMO
mation processed is also contingent upon the particular values
of the alternatives for these strategies.
The simulation provides insights into how aspects of proc-
DEMO, as exemplified by individual strategies, might change
across different choice environments if adaptivity is exhibited.
Other aspects of processing, such as the proportion of proc-
essing devoted to the probabilities and the proportion of
processing DEMO to the most probable (important) attribute,
will also be considered.
Task and Context Variables
Three task variables were examined. The number of DEMO
natives and number of attributes were each varied at three
levels (DEMO, 5, and 8) in order to manipulate task complexity.
The DEMO task variable included was time pressure, varied at
four levels. One DEMO involved no time pressure, with each
rule using as many operations DEMO needed. The three other
levels of time constraint were a maximum of (a) 50 EIPs
(severe time pressure), (b) 100 EIPs (moderate pressure), and
(c) 150 EIPs (low pressure). DEMO time (EIP) constraint values
were selected on the basis of an analysis of the maximum
number of EIPs associated with the most effortful DEMO
(weighted additive).' Note that the total number of EIPs was
used to operationalize time pressure. This implicitly assumes
that each EIP takes DEMO similar amount of time. The sensitivity
of the analyses to this assumption is examined later.
A key issue in dealing with the time constraints DEMO how rules
should select among alternatives if they run out of time.
Several rules identify one alternative as the best seen so far
(i.e., the WADD, EQW, and MCD rules) and select that alterna-
DEMO when they run out of time. The EBA, LEX, and SAT rules
all pick an option randomly from those alternatives not yet
eliminated. DEMO the EBA and lexicographic rules were able
to process all alternatives on at least one attribute, even for
the largest problem size under the most severe time constraint,
the choice came from the set already DEMO but not
eliminated. For the SAT rule in this most severe case, if the
first alternative was not acceptable, then random choice
among DEMO remaining alternatives seemed to be the most
537
reasonable option. For the two combined strategies, the selec-
tion was either made at random from the alternatives not yet
eliminated, if the combined strategy was still in the EBA phase,
or the best so far, if in the WADD or MCD phase.
Finally, two context variables were included. Context vari-
ables, unlike task variables, are associated with the particular
choice object DEMO (Payne, 1982). One context variable was
the presence or absence of dominated alternatives. Removing
dominated alternatives produces efficient choice sets. Me-
Clelland (1978) suggested that the success ofthe equal weight-
ing simplification strategy is dependent on the presence of
dominated alternatives. Empirical evidence showing that
dominated DEMO can impact choice was provided by J.
Huber, Payne, and Puto (1982). This implies that dominated
alternatives are not simply disregarded.
The second context variable was the degree of dispersion
of probabilities within each DEMO To illustrate, a four-
outcome gamble with a low degree of DEMO might have
probabilities of .30, .20, .22, and .28 for DEMO four outcomes,
respectively. On the other hand, a gamble with DEMO high degree
of dispersion might have probabilities such as .68, .12, .05,
and .15 for the four outcomes. This variable was chosen
DEMO Thorngate (1980) had suggested that probability in-
formation may be relatively unimportant in making accurate
risky choices (see also Beach, 1983). DEMO, if all of the
outcome probabilities were identical, probability information
would not matter. On the other hand, if one outcome is
certain, DEMO examining the probability information to find
that outcome is crucial. What is unclear is how sensitive
heuristics are to the dispersion in probabilities, and how
adaptive actual behavior is to such a context variable. We
therefore DEMO decision sets with either low or high
dispersion.
JNDs and CutoffValues
Three of the rules, EBA, SAT, and LEXSEMI, involve param-
eters DEMO affect the potential effort and accuracy of the rules.
For EBA and SAT this is the cutoff value used to eliminate
alternatives. For the DEMO rule, it is the value of the JND.
Although these parameters DEMO, in some sense, under the
control of the decision maker for each decision, we wanted to
establish a priori values that would be the same for all deci-
sions made by the simulation. A pilot DEMO without any
time constraints was run to identify the best levels, DEMO all
attributes in the simulation drawn from a uniform distribu-
tion bounded by 0 and 1,000. We manipulated both cutoffs
(100, 300, and 500) and JNDS (I, 50, and 100) and selected
values that represented the most efficient accuracy-effort
trade-offs averaged across the entire DEMO of decisions. We found
that values of the cutoff of 500 and 300 were most efficient
for EBA and SAT, respectively, and that DEMO JND of 50 gave the
best performance for the LEXSEMI rule. The results presented
I To provide insight into the ranges of values possible, the average
number of EIPs required for the weighted additive rule to DEMO to
completion ranged from 28 for the two-alternative, two-attribute case
to DEMO for the eight-alternative, eight-attribute case. Comparable
figures for the lexicographic strategy DEMO 21.3 (2 x 2) and 172.5 (8 x
8).
538
J. PAYNE, J. DETTMAN, AND E. JOHNSON
for the EBA, SAT, and LEXSEMI rules are for the most efficient
values for each rule.
Method
Each of the 10 decision rules was applied to 200 DEMO gener-
ated decision problems in each of the 288 conditions defined by a 3
(number of alternatives) by 3 (number of attributes) DEMO 2 (low or high
dispersion of probabilities or weights) by 2 (presence or absence of
dominated alternatives) by 2 (cutoff values) DEMO 4 (time constraints)
factorial. After each trial, the alternative selected was recorded, along
with a tally for each elementary operation used by the decision rule.
Results
Effort was measured using EIPs, and accuracy was meas-
ured using EV (WADD) maximization. Specifically, effort was
measured by the total count of the EIPs used by a specific
decision rule DEMO make a selection from a particular set of
alternatives. This measure assumes that each EIP requires the
same level of time or mental effort. DEMO, we report results
that relax that assumption.
The sv-based measure of DEMO compared the relative
performance of strategies to the two baseline strategies: (a) the
maximization of expected value (WADD), and (b) DEMO
choice. The measure was defined by the following equation:
relative EVheuristic rule choice - EVrandom rule choice
accuracy EVexpected value choice - EVrandom DEMO choice
The maximum expected value possible in a particular choice
set and the expected value associated with a random selection
were determined. The expected DEMO of the alternative se-
lected by a decision heuristic was then compared to these two
baseline values. This measure is bounded by a value DEMO 1.00
for the EV rule, and an expected value of 0.0 DEMO random
selection. It provides a measure of the relative improvement
of a heuristic strategy over random choice. Although this
measure of accuracy may seem DEMO arbitrary, the results
are not sensitive to the use of alternative DEMO (see Johnson
& Payne, 1985, for a discussion of other DEMO measures).
Table I presents the relative accuracy and effort scores for
each of the 10 decision strategies in each of the four cells
DEMO by crossing the context factors dispersion in weights
(low, high) DEMO dominance (present or absent). These scores
are for the no-time-pressure DEMO The results are aver-
aged over number of alternatives and number of attributes.
Note that the aspects characterizing each strategy are also
included to DEMO interpretation of the results.
Table 1
Simulation Results/or Accuracy and Effort 0/ Heuristics in the No-Time-Pressure Decision Problems
Task environment
Dominance possible
Dominance not possible
Strategy
Processing Processing
form
Low
selectivity dispersion dispersion
High
Low
DEMO
High
dispersion
WADD
RA
DOC
EQW
RA
DOC
SAT
RA
DOC
MCD
RA
DOC
LEX
RA
DOC
LEXSEMI
RA
DOC
EBA
RA
DOC
EBA+WADD
DEMO
DOC
EBA+MCD
RA
DOC
Note. RA = relative accuracy (95% confidence DEMO width = Â±.029). DOC = unweighted operations count (95% confidence DEMO width
strategy. LEX = lexicographic strategy. LEXSEMI = lexicographic semi-order strategy. EBA = elimination by aspects strategy. EBA+WADD =
combined elimination by aspects plus DEMO additive strategy. EBA+MCD = combined elimination by aspects plus majority of confirming
combined elimination by aspects plus weighted additive strategy. EBA+MCD = combined elimination DEMO aspects plus majority of confirming
dimensions strategy.
Alternative
Alternative
Alternative
Attribute
Attribute
Attribute
Attribute
Mixed
Attribute
No
No
Yes
No
Yes
Yes
Yes
Yes
DEMO
1.0
160
85
49
.89
.32
148
.62
60
87
87
.69
.71
.67
104
.84
89
.69
1.0
160
85
49
.67
.31
DEMO
.48
60
78
.90
.87
88
106
89
.66
.79
.59
1.0
160
85
61
141
.41
.03
.07
60
79
82
.67
.64
DEMO
102
86
.69
.29
1.0
160
85
61
140
.27
.07
.09
60
81
.90
.77
82
102
86
.56
.66
.31
ADAPTIVE DECISIONS
539
No-time-pressure results. The simulation results indicate
that in some DEMO, heuristics can approximate the
accuracy of a normative strategy (WADD), with substantial
savings in effort. A decision maker using an EQW model, for
example, can achieve 89% of the relative performance of the
normative model, with only about half the effort, in the low-
dispersion, dominance-possible task environment. Even more
impressive is the performance of the strict DEMO rule
in the high-dispersion task environments. The lexicographic
rule achieves 90% relative accuracy, with only about 40% of
the effort. Note that the performance of the lexicographic-
semiorder rule exceeds that of the simpler lexicographic rule
DEMO only one of the four decision environments. The extra
effort needed to use JNDS may only be of value in a limited
set of DEMO
It is clear from Table 1 that the most efficient heuristic
varies across decision environments. In the low-dispersion,
dominance-possible environment, for example, DEMO processing
simplification of ignoring probability (weight) information,
that is, DEMO equal weight strategy, appears quite accurate. In
contrast, when the dispersion in probabilities is higher, the
lexicographic rule, which ignores all the DEMO information
except that associated with the single most likely outcome, is
DEMO most accurate heuristic, and is substantially better than
the equal weight DEMO It is also clear that some heuristics (e.g.,
MCD and DEMO) perform reasonably in the dominance-possible
environments, but are very poor performers when all domi-
nated alternatives have been removed. Note also that in DEMO
low-dispersion, dominance-absent environment, the best sim-
ple heuristic, LEX, has an accuracy score of .67. That accuracy
score is .22 lessthan the DEMO score for the "best" heuristic
in the other three environments. This suggeststhat a decision
maker in such an environment would not be able DEMO reduce
effort much without suffering a substantial loss in accuracy.
Decision problems involving low dispersion, dominance-ab-
sent environments may therefore be particularly difficult.
In summary, heuristic strategies can be highly accurate in
some environments, but DEMO single heuristic does well across
all contexts. This suggests that if a decision maker wanted to
achieve both a reasonably high level of accuracy DEMO low
effort, he or she would have to use a repertoire DEMO strategies,
with selection contingent upon situational demands.
An interesting set of results from Table 1 concerns the
performance of the two combined decision DEMO The
combination of an elimination process with a weighted adding
model (DEMO + WADD) performed well across all task conditions.
That rule offers DEMO good combination of expected accuracy and
reasonable levels of expected effort. The EBA+MCD rule, on
the other hand, seems to be an inefficient DEMO strat-
egy.
Although it is not shown in Table 1, there DEMO systematic
effects of the task variables number of alternatives and num-
ber of attributes. For example, the mean accuracy of the equal
weight rule decreased only from .93 to .87 as the number of
attributes increased DEMO two to eight in the low-dispersion,
dominance-possible environment. However, the DEMO accu-
racy of the LEX rule did decrease substantially, from .86 DEMO
.55, as the number of attributes was increased. The decrease
in DEMO for the lexicographic rule reflects the fact that a
rule that uses only information associated with a single (al-
though the most probable) DEMO would be expected to
perform worse as an increasing number of relatively impor-
tant (probable) outcomes are ignored. In contrast, the impact
of increases in number of attributes on the EQW and LEX rules
was DEMO for the high-dispersion, dominance-possible en-
vironments. The mean accuracy for the DEMO rule decreased
from .71 to .49 for the two outcome and eight outcome
problems, respectively, reflecting the fact that the rule essen-
tially DEMO from more and more outcomes
with small probabilities as the number of outcomes is in-
creased. The LEX rule decreased only from .93 to DEMO for the
same problems.
The number of alternatives also had effects on effort. For
instance, an increase in the number of alternatives from two
to eight increased the average EIP count of the weighted
adding rule DEMO 191 EIPs. The EBA strategy, on the other hand,
only DEMO by 79 EIPs as the number of alternatives went
from two to eight. More generally, the effort required to use
heuristics increased more slowly than the effort required to
use more normative procedures as the number DEMO alternatives
was increased. This simulation result is compatible with prior
empirical work showing shifts in strategies due to number of
alternatives (Payne, 1982)DEMO
The potential trade-offs between accuracy and effort for the
different strategies are highlighted by Figure I, which shows
the results from the low-dispersion in probabilities (weights),
dominance possible and high-dispersion, dominance-possible
contexts averaged over number of alternatives and outcomes.
Only the dominance-possible context is shown because DEMO is
used in the experimental work described later. The measure
of effort for each strategy has been turned into a relative
measure based on DEMO ratio of the number of EIPs required
by a heuristic to the number of EIPs required by the most
effortful WADD strategy. A line DEMO indicates an efficient
frontier of strategies, considering both a desire for DEMO
accuracy and a desire for lesser effort, is drawn for each
DEMO Figure I makes clear both the existence of efficient
heuristics and the fact that the accuracy/effort trade-offs for
various strategies differ across relatively DEMO changes in
context, such as the dispersion in probabilities.
The simulation DEMO not identify which particular strategy
a decision maker will necessarily select in a given decision
environment. That would depend on the degree to which DEMO
decision maker was willing to trade decreases in accuracy for
effort savings. However, note that if a decision maker desired
relatively high levels of accuracy in an environment where
dominance is possible, there are accurate strategies in each
environment with substantial savings in effort: the LEX rule
in the high-dispersion condition and the EQW strategy in the
low-dispersion condition. Thus, the simulation predicts that
when dominance is possible, one should see more processing
consistent with a LEX strategy (e.g.,attribute-based processing,
selective processing across attributes, and higher proportions
of processing on probabilities and the most important attri-
bute) in environments with high-dispersion in probabilities.
In contrast, DEMO low-dispersion environments, one should ob-
serve more alternative-based processing, more consistent
processing, and a lower proportion of processing of probabil-
ities and the most important attribute, consistent with strate-
gies like the EQW rule. The prediction is based on the assump-
540
J. PAYNE, J. DETTMAN, AND E. JOHNSON
-
Â«
cc
DEMO:>-
co
~
tJ
tJ
<{
...
.~
co
Q)
iii
a:
...
:::s
tJ
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
WADD
-----
EBA+WADD 0
EBA+WADD *
DEMO
0... -,
<,
*LEXSEMI*
o MCD
LEXSEMI
EBA 0 *E8w
EBA + MCD * EBA
EBA
+ MCD*
"
LEXD,
\
â¢ MCD
- -
-
- Low-Dispersion
Dominant
High-Dispersion
Dominant
LEX
\
DEMO
0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2
0.1
0
Relative Effort (%WADDl
Figure 1. Effort/accuracy trade-offs for various decision strategies in the low-dispersion and high-
dispersion dominance-possible environments.
tion that people are sensitive to DEMO relative accuracy of strat-
egies in different contexts, as well as DEMO aware of differences
in relative effort.
In addition to this prediction, DEMO more subtle prediction can
also be made. Note that if one uses the equal weight strategy
in a low-dispersion environment and the LEX strategy DEMO
high dispersion, roughly equal accuracy can be attained. How-
ever, lesseffort is required in the high-dispersion environment.
Thus, if subjects desire relatively high levels of accuracy, the
simulation would predict that accuracy levels would not vary
across dispersion conditions, but that effort levels would be
lower for the high-dispersion condition.
The simulation results discussed so far have assumed as DEMO
first approximation that all EIPs require an equal amount of
effort to execute. Prior work by Johnson and Payne (1985)
suggested that such an assumption was sufficient for the
simplified decision tasks they studied. However, it does seem
reasonable that some EIPs may take more time to DEMO, or
be more effortful, than others. In another study, Bettman DEMO
al. (1987) used counts of elementary operations (EIPs) to
Dominance possible
Task environment
Dominance not possible
Low dispersion High dispersion Low dispersion DEMO dispersion
Processing Processing
Strategy form selectivity LTP MTP STP LTP MTP STP LTP MTP STP LTP MTP STP
WADD Alternative No .91- .80 .28 DEMO .80 .28 .90- .77- .12 .92- .82 .24
EQW Alternative No .88 .82- .71- .66 .65 .55 Al .34 .26 .24 .25 .18
SAT DEMO Yes .38 .34 .30 .32 .34 .23 .03 .04 .06 .07 .05 .04
MCD Attribute No .58 049 .23 044 .35 .17 .03 -.01 DEMO .04 .03 .02
LEX Attribute Yes .70 .69 047 .90 .90" DEMO .69 .68 048- .90 .90- .60
LEXSEMI Attribute Yes .71 .66 040 .87 .83 049 .63 .59 043 .76 .75 .51
EBA Attribute Yes DEMO .68 049 .76 .73 .65- .63 .60 048- .67 .67 .61-
EBA+WADD Mixed Yes .86 .79 043 .86 .82 048 .73 .66 .27 .75 DEMO 043
EBA+MCD Attribute Yes .74 .65 044 .67 .60 049 .35 .32 .27 040 Al .36
Note. The 95% confidence interval width for the DEMO values is Â± .029. LTP = low time pressure. MTP = moderate time pressure. STP =
severe time pressure. WADD = weighted additive strategy. DEMO = equal weight strategy. SAT = satisficing strategy. MCD = majority of confirming
dimensions strategy. LEX = lexicographic strategy. LEXSEMI = lexicographic semi-order strategy. DEMO = elimination by aspects strategy.
EBA+WADD = combined elimination by aspects plus weighted additive strategy. EBA+MCD = combined elimination by aspects plus majority of
DEMO dimensions strategy.
a The most accurate strategy for each task environment.
Table 2
Simulation Resultsfor Accuracy of Heuristics Under Time Pressure
ADAPTIVE DECISIONS
541
predict measures of decision effort such as the total DEMO
required to make a decision. The counts of EIPs required by
a specific strategy for a specific decision problem provided an
excellent (R2 = .81) prediction of overall decision latencies.
Consequently, estimates of the times DEMO with the EIPs
obtained by Bettman et al. were used to see if the trade-offs
between accuracy and effort for the different strategies ex-
DEMO in the present study would change. The major result
was that all the heuristics become relatively less effortful when
the individual EIPs are weighted. DEMO, the aforemen-
tioned key relations between aspects of processing and the
DEMO variable of low and high dispersion are essentially
unchanged when weighted effort counts were used in place of
the equal weighted assumption. The relative DEMO of
the various strategies was almost identical.
Time pressure results. The time pressure results are shown
in Table 2. Time constraints clearly have differential DEMO
on the various rules. The W ADD rule, for example, shows a
marked reduction in accuracy from the baseline value of 1.0
under DEMO time pressure to an average accuracy of only .12
under the most severe time constraint in the no-dominance,
low-dispersion condition. In contrast, the EBA heuristic shows
relatively little effect of time pressure. The average accuracy
DEMO environments is reduced only from .69 with no time
pressure to .56 under severe time pressure. Interestingly, the
EBA rule is actually the most accurate decision strategy in
three of the four environments for severe time DEMO The
LEX rule also holds up well under time pressure. It appears
that strategies involving an initial processing of all alternatives
using a limited DEMO of attributes do well under severe time
pressure. On the basis of the simulations, it seems important
under high time pressure to use a choice strategy that processes
at least some information about all alternatives as DEMO as
possible. However, note that in one decision environment
(dominance possible, low dispersion in weights), the alterna-
tive simplification strategy provided by the equal weight rule
is superior for even the most severe time DEMO studied.
the context variable, dispersion in probabilities, suggest that
when dominated alternatives are possible, more attribute-
based processing, more selective processing across DEMO
and alternatives, and a higher proportion of processing on
probabilities and DEMO most important attribute should be
observed in the high-dispersion rather than in the low-disper-
sion condition. Such aspects characterize rules, like the LEX
rules, that are relatively accurate with substantial effort savings
in the high-dispersion environment. In addition, it was noted
earlier that individuals should be able to attain similar levels
of accuracy in both low- and high-dispersion environments,
DEMO they should be able to do so with less effort in the high-
dispersion setting.
The simulation also suggests that strategies characterized
by attribute-based DEMO and selectivity in processing,
particularly across attributes, should be more DEMO under
severe time pressure. Strategies such as LEX and EBA, which
DEMO accuracy relatively well under heavy time pressure,
also are characterized by a greater proportion of processing
on probabilities and the most important attribute.
DEMO foregoingsimulation work could be validated in several
ways. One method, used DEMO Bettman et al. (1987), as noted
earlier, is to show that counts of the elementary operations
generated by the simulation could be DEMO to predict effort-
related behaviors such as the total time required to make a
decision or self-reports of cognitive effort. Another approach
to validation DEMO be to show that adaptivity in information
processing shown by human decision makers, when free to
select any strategy, was in the general DEMO predicted by
the simulation. The next two experiments take this second
approach to validation and investigate the adaptivity of proc-
essing when actual decision DEMO is examined.
Empirical Investigations: An Overview
Implications ofthe Simulation
The following DEMO examine the degree of corre-
spondence between the actual adaptivity shown by human
decision makers and the adaptive processing patterns (strate-
gies)implied by the simulation results. Specifically, we ask (a)
to what extent DEMO people vary their information processing
behavior as a function of context effectssuch as the dispersion
of probabilities and task effects such as time pressure?; and
(b) are these changes in processing in the directions suggested
by the simulation? One important feature of these experi-
ments is the use of a complete within-subjects design. Such a
design provides a strong DEMO of adaptivity, because the subject
would be expected to switch strategies DEMO one trial to the
next.
As outlined earlier the simulation results provide a fairly
clear picture of an adaptive decision maker. If decision makers
DEMO as suggested by the simulation, there should be a
relation between DEMO dispersion of probabilities and various
aspects of processing. In particular, more DEMO proc-
essing, greater selectivity in processing across attributes and
alternatives, and a greater proportion of processing devoted
to probabilities and the most important DEMO are expected
in a high-dispersion environment. Such shifts in processing
as a function of context would indicate that people are sensi-
tive to changes DEMO choice environments that affect the accuracy
of strategies and not just to changes that affect processing
The simulation results indicate what a decision maker
DEMO do to adapt to various decision environments. The
results clearly suggest the possibility that a decision maker
might maintain a high level of accuracy DEMO minimize effort
by using a diverse set of heuristics, changing rules DEMO contexts
and time pressures change.
Obviously, the simulation results have to DEMO interpreted
with some caution. Although the results appear to be robust,
both the measures of effort and the measures of accuracy
represent approximations. DEMO addition, it is unlikely that
actual choice behavior involves a straightforward DEMO
of one choice strategy or another. As noted earlier, there is
DEMO for mixtures of strategies being used (Payne, 1976).
The strategies represented in the simulation should be viewed
as prototypical strategies that can DEMO used to hypothesize how
the form of information processing in decision making may
shift as a function of task and context demands.
Despite these DEMO, the simulation work provides
insights into how processing might change if DEMO accu-
racy-effort trade-offs were desired. The simulation results for
542
J. PAYNE, J. BETTMAN, AND E. JOHNSON
demands. The reason DEMO that the relative accuracy of rules
varies across contexts (dispersion conditions), but the relative
effort required by the rules does not. Studies showing contin-
gent processing due to task complexity (e.g., changes in num-
DEMO of alternatives and attributes) are fairly common (see
Payne, 1982); studies showing processing changes due to
context variables, and hence implicitly DEMO concern for
accuracy, are much less common (however, see Busemeyer,DEMO
1985; Russo & Dosher, 1983).
The task variable examined is the presence or absence of
time pressure. The simulation results also indicate DEMO in
aspects of processing under severe levels of time pressure. In
particular, more attribute-based processing, greater selectivity
in processing, and a greater proportion of processing focused
on probabilities and the most important attribute might be
DEMO
Other work on time pressure reinforces these predictions.
For example, Ben DEMO and Breznitz (1981) identified at least
three ways in which people may respond to time constraints.
One way to cope with time pressure DEMO to process only a subset
of the most important information, an DEMO referred to as
"filtration" (Miller, 1960). Another way to cope with time
pressure is to "accelerate" processing (Ben Zur & Breznitz,
1981; Miller, 1960) by trying to process the same information
at a faster rate. Finally, one could shift processing strategies.
At the extreme, this could involve random choice, or "avoid-
ance" (Ben Zur & Breznitz, 1981; Miller, 1960). A less ex-
treme form of contingent processing would involve a shift
from a more DEMO rule, such as the additive rule, to a less
effortful rule, like EBA. The simulation results indicate that
such a strategy shift could maintain relatively high levels of
accuracy, even under severe time pressure.
The hypothesis of filtration is supported in other studies.
For example, Wright (DEMO) reported that the most important
information in a judgment task was DEMO more weight under
time pressure. Ben Zur and Breznitz (1981) reported shifting
to the use of more important information under time pressure.
Furthermore, Ben Zur and Breznitz also found that subjects
spent less time looking DEMO individual items of information
under time pressure. They concluded that combining filtra-
tion and limited acceleration "can be viewed as the optimal
decision making strategy when the [decision maker] is con-
fronted with information overload while DEMO by dead-
lines" (p. 102). Note that filtration can be characterized by
greater selectivity across alternatives and attributes and by
greater emphasis DEMO the most important attribute.
The foregoing hypotheses deal with processing information.
Accuracy under time pressure was addressed by Zakay and
Wooler (1984). They found that under time pressure a smaller
proportion of the observed choices DEMO of the alternative
that had been measured as having the greatest additive value.
In sum, the simulation and prior empirical research lead to
several hypotheses. Both higher dispersion in probabilities
and higher time pressure are expected DEMO lead to greater use
of attribute-based processing, greater selectivity across attri-
DEMO and alternatives, and greater focus of processing on
probabilities and the DEMO important attribute. In addition,
there should be no difference in accuracy for different levels
of dispersion, but there should be less effort under high
dispersion. Under high time pressure, accuracy should be
lower and information should be processed more rapidly.
These predictions could be derived in at DEMO two ways.
One could assume that subjects have explicit accuracy and
effort feedback and make conscious trade-offs of accuracy
and effort. Alternatively, one can assume that subjects have
general knowledge of the properties of a reasonable DEMO
and of task environments (e.g., see Reder, 1987). Then, in the
course of making decisions, subjects generate processfeedback
(Anzai & DEMO, 1979). That is, subjects can ascertain how
effortful their strategy was and how closely it resembled their
notion of what a "good" strategy should entail. Such process
feedback can be generated without explicit feedback about
outcomes. Subjects would then adapt based upon their general
knowledge and DEMO feedback (Reder, 1987).
In the present article, the second DEMO of arriving at the
predictions was used. Subjects are assumed to have ideas
about the characteristics of reasonable strategies, to generate
process feedback, DEMO to adapt by using the process feedback
and seeing how well their strategy as executed matches their
view of a "reasonable" strategy. In DEMO experiments reported,
the choices are made without explicit feedback regarding
accuracy for two major reasons: (a) The majority of common
decision problems do not offer the opportunity to receive
immediate and clear feedback about DEMO quality of choice
(Einhorn, 1980); (b) to the extent adaptivity is exhibited in
situations without explicit accuracy feedback, it provides
strong evidence for adaptive decision processing. That is, it
would suggest that adaptivity may be crucial enough to deci-
sion makers that they will guide DEMO to it without the
need for an external prod in the form of explicit feedback.
Experiment 1
In this experiment, the extent of adaptivity to changes in
the dispersion of probabilities and to the presence or DEMO
of time pressure was tested. The main hypotheses are that
people willadapt their behavior to the demands ofthe decision
environment in accordance with the DEMO patterns identi-
fied by the simulation.
Method
Subjects. A total of 16 undergraduates at Duke University served
as subjects. Participation in the experiment earned DEMO toward
fulfillment of a course requirement. In addition, the subjects had DEMO
possibility of winning as much as $9.99, depending on their actual
DEMO
Stimuli. The stimuli were sets of four risky options. Each option
in a set offered four possible outcomes (attributes). The outcomes
involved possible payoffs ranging from $0.01 to $9.99. Every option
in a set was DEMO in terms of the same four outcome probabilities.
The probabilities for any given outcome ranged from .01 to .96, with
the constraint that the four outcome probabilities summed to one.
Ten sets of high dispersion in DEMO (weights) options and
10 sets of low dispersion options were generated, with dominated
options allowed in all sets. In terms of the design used for the
simulation study, sets of options were sampled from the low-disper-
sion, dominance-possible and high-dispersion, dominance-possible
conditions. To illustrate, one low-dispersion set of gambles had
ADAPTIVE DECISIONS
543
probabilities of .22, .26, .24, and .28 for the four possible outcomes.
Gamble A provided payoffs of $8.73, $7.83, DEMO, and $8.91, re-
spectively, for the four outcomes. Gamble B DEMO payoffs of
$7.54, $4.64, $5.11, and $6.73. Gambles C and DEMO had different, but
similar types of payoffs. One high-dispersion set of DEMO, on the
other hand, had probabilities of .20, .04, .07, and .69. The payoffs for
Gamble A were $6.86, $1.18, $4.96, and $0.84, respectively. Gamble
B had payoffs of$1.38, $3.34, $8.49, and $2.91, respectively. Again,
Gambles C and D were similar. Overall, the sets of options in the
low- and high-dispersion conditions were equivalent in terms of their
average expected values.
The 20 sets of options (IO low dispersion, IOhigh dispersion) were
randomly presented under two time DEMO conditions. One in-
volved no explicit time pressure. Subjects could take as much time
as they wished to acquire information about probabilities and payoffs
DEMO make a decision. The other condition involved a 15-s time
constraint. In this condition, a clock was shown in the upper-left
comer of the display with the information about the gambles (de-
scribed more fully below). As the 15 s passed, the clock slowly
disappeared. At 15 s, a beep sounded, the subject could not acquire
additional information, and he or she was instructed to make a
choice. For comparison, a pilot study indicated that subjects took
about 50 s, on average, when under no time pressure. In the experi-
ments reported below, DEMO averaged approximately 44 s per trial
when under no time pressure.
There were 40 decision problems (2 context conditions x 2 time
pressure conditions x IO replications) presented to each subject in
random order, with DEMO same random order used for all subjects. A
complete experimental session took 30-45 min for each subject.
The Mouselab methodology. Information acquisitions, response
times, and choices were monitored using a software system called
Mouselab (Johnson, Payne, Schkade, & Bettman, 1986). This system
uses an IBM personal computer, or equivalent, equipped with a
"mouse" for moving DEMO cursor around the display screen of the
computer. The stimuli are presented on the display in the form of a
matrix of available information. DEMO first row of boxes contained
information about the probabilities of the four outcomes. The next
four rows of boxes contained information about the payoffs DEMO
with the different outcomes for each alternative, respectively. At the
bottom DEMO the screen were four boxes that were used to indicate which
alternative was most preferred. Figure 2 is an example of a stimulus
display DEMO one box opened, and with the time pressure clock part
way DEMO the countdown.
When a set of options first appears on the screen, the values of the
payoffs and probabilities are "hidden" behind the labeled boxes. To
open a information, the subject has
PROBS.
_r
OUTCOME 4
OUTCOME 3
~
GAMBLE A
GAMBLE
EJ
GAMBLE C
GAMBLED
_
DEMO One:
r GAMBLE AI
rGAMBLE B ~
r
GAMBLE C I
I GAMBLE Dr
Figure 2. Example of stimulus display using the Mouselab DEMO
with time-pressure clock.
.-
particular box and examine the
OUTCOME 2
OUTCOME 1
to move the cursor into the box. The box immediately opens DEMO
remains open until the cursor is moved out of the box. Only one box
can be open at a time.
The Mouselab program records DEMO order in which boxes are
opened, the amount of time boxes DEMO open, the chosen option, and
the total elapsed time since the display first appeared on the screen.
Response times are recorded to an DEMO of 1/60th of a second.
The Mouselab methodology comes close to the recording of eye
movements in terms of speed and ease of DEMO, while mini-
mizing instrumentation cost and difficulty of use for both DEMO and
experimenter. An analysis of the time necessary to move the mouse
between boxes in our displays using Fitts's Law indicates that one
DEMO move between boxes in less than 100 ms (Card et al., 1983).
This suggeststhat the time to acquire information using the M DEMO
system is limited mainly by the time it takes to think where to point,
rather than by the time it takes to move DEMO mouse. Although the use
of such a process-tracing system itself could possibly induce a change
in strategies, recent research using the M ouselab system has replicated
findings (e.g., preference reversals) found in studies that do not use
such a process-tracing mechanism (Johnson, Payne, & Bettman, DEMO
press). There might also be concern that the tabular format is unnat-
ural. However, tables of information appear in such magazines as
Consumer Reports, and many computer-based decision aids also use
a similar format.
Dependent measures. Information acquisition and decision behav-
ior can be characterized in many DEMO One can examine the amount
and sequence of information acquired, and DEMO time spent acquiring
information (Klayman, 1983). To examine the aforementioned hy-
potheses, we consider seven measures of aspects of decision process-
ing. One important aspect is the total amount of processing. One
measure of DEMO is the total number of times information boxes
were opened for a particular decision, denoted acquisitions (ACQ). A
second measure, which is related to the amount of processing effort
and is also directly relevant DEMO the hypothesis of acceleration of
processing under time pressure, is the DEMO time spent per item of
information acquired (TPERACQ).
The next DEMO measures reflect the relative attention devoted to
specific types of information, DEMO hence are relevant to characterizing
selectivity in processing and the related concept of filtration. One
measure, denoted PTMI, is the proportion of the DEMO time acquiring
information that was spent in boxes involving the most important
attribute of a particular decision problem. The attribute (outcome)
with the largest weight (probability of occurrence) was defined to be
the most DEMO attribute. The other measure, denoted PTPROB, is
the proportion of time spent on probability information as opposed
to information about payoff values.
The DEMO two measures are the variances in the proportions of time
spent on each alternative (VAR-ALTER) and on each attribute (VAR-
ATTRIB). Such variances are related to selectivity. As described earlier
more compensatory decision rules (e.g., WADD, EQW, and MCD) imply
a pattern of information DEMO that is consistent (low in vari-
ance) across alternatives and attributes; in contrast, noncompensatory
strategies, like EBA, LEX, and SAT, DEMO more variance in processing.
A final measure of processing characterizes the sequence of infor-
mation acquisitions relating to outcome values. Given the acquisition
of DEMO particular piece of information, two particularly relevant cases
for the next DEMO of information acquired involve the same alterna-
tive but different attribute (DEMO alternative-based, holistic, or Type I
transition), and the same attribute but a different alternative (an
attribute-based, dimensional, or Type 2 transition). A simple measure
of the relative amount of alternative-based (Type I) and attribute-
based (Type 2) transitions is provided by calculating the number of
Type I transitions minus the number of Type 2 transitions DEMO
by the sum of Type I and Type 2 transitions (Payne, 1976). This
measure of the relative use of alternative-based versus attribute-based
544
J. PAYNE, J. BETTMAN, AND E. JOHNSON
processing, denoted PAITERN, ranges from a value of -1.0 to + 1.0.
A more positive number indicates relatively more alternative-based
processing, and a more negative number indicates relatively more
attribute-based processing.
In addition to these seven measures of processing, a measure of
relative accuracy, defined as above in terms of sv maximization and
random choice, was developed and denoted GAIN.
These measures can be related directly to the hypotheses outlined
previously. Higher dispersion in probabilities DEMO higher time pressure
should lead to lower values of PAITERN (more DEMO proc-
essing); higher values OfVAR-ALTER and VAR-AITRIB (greater selectiv-
ity); and higher values of PTPROB and PTMI (greater focus on proba-
DEMO and the most important attribute). In addition, there should
be DEMO acquisitions (ACQ) and lower TPERACQ under high dispersion
(less processing DEMO), and TPERACQ should be lower under time
pressure. Finally, GAIN DEMO be similar across levels of dispersion,
but lower under high time pressure.
Procedure. Each subject was told that the purpose of the experi-
DEMO was to understand how people make decisions, that there were
no DEMO "right" or "wrong" choices, and that the "best" DEMO
was to choose that risky option they would most prefer to play.
Subjects were also told that at the end of the experiment a DEMO
problem would be selected at random, and the option they had
DEMO would be played by randomly generating an outcome accord-
ing to the probabilities for that option. They would be allowed to
keep whatever money DEMO won. Thus, the subjects could win between
$0.01 and $9.99, depending on their choices and the random process.
Subjects then were instructed on DEMO Mouselab information aequi-
sition system and allowed to practice its use. Next, they were told
that they would be presented with a series of decisions involving
choices among risky options and that some decisions would involve
DEMO explicit time constraint, whereas for other decision problems they
could take DEMO long as they wished.
Results
Overview. The main focus in the results concerns how
people adapt to the task manipulation of time pressure and
DEMO context manipulation of dispersion in probabilities. Effects
are examined for the foregoing four main types of dependent
measures: amount of processing, selectivity in DEMO,
pattern of processing, and relative accuracy.
To provide the strongest DEMO test of adaptivity, a within-
subjects experimental design was used. Subjects, however,
may have to experience several examples of different types of
DEMO problems before settling on a preferred strategy for a
particular type of problem. Consequently, the results are
presented both for the block of 20 decision problems seen
first by the decision maker, and the block of the last 20
decisions. Problems corresponding to each of the four time-
DEMO combinations were distributed essentially
equally over the two blocks.
A multivariate analysis. Given the likely correlations
among the various process measures, the data were first
analyzed using a multivariate analysis of variance with three
within-subject factors (dispersion, time pressure, and block).
The analysis included the aforementioned DEMO process
measures plus the measure of relative accuracy, denoted GAIN.
The DEMO for these measures are presented in Table 3.
Overall, the main DEMO of dispersion, F(8, 606) = 21.54,
time pressure, F(8, 606) = 62.98, and block, F(8, 606) = 6.28,
were highly significant (p < .001). There DEMO a significant
dispersion by time pressure interaction, F(8, 606) DEMO 4.05, P <
.00I, and an interaction of time pressure DEMO block, F(8, 606)
= 5.38, p < .001. DEMO was no interaction of block and
dispersion, F(8, 606) DEMO 1.20, ns, although there was a signifi-
cant three-way interaction of block by dispersion by time
pressure, F(8, 606) = 3.05, p < .01.
To more fully characterize the effects of dispersion, DEMO
pressure, and block, separate univariate analyses of variance
were conducted for each of the dependent measures. The
results presented in Table 3 will DEMO be discussed in terms of
dispersion in probabilities (a context effect), then for time
pressure (a task effect),and then briefly for block. Interactions
involving block are considered where relevant. Within each
section, the results are presented for the amount of processing
measures (ACQ and TPERACQ), then for the selectivitymeasures
(PTMI, PTPROB, VAR-ATTRIB, and VAR-ALTER), and then the
PATTERN measure. A summary of results at the individual
subject level is briefly presented, and then the GAIN measure
is discussed.
Effects of dispersion. High dispersion was predicted to lead
to fewer acquisitions (ACQ), less time per acquisition (TPER-
ACQ), greater focus on the most important dimension (PTMI)
and on probabilities (PTPROB), DEMO selectivity for attributes
Table 3
Summary of Process Measures and GAIN as a Function of Time Pressure. Context,
No time pressure
and Decision DEMO: Experiment 1
Time pressure = 15 s
Low dispersion High dispersion DEMO dispersion High dispersion
Dependent
measure Block I Block 2
ACQ 46.6 35.3 35.1 27.6 18.3 17.6 15.6 15.4
TPERACQ .754 .668 .650 .622 .492 DEMO .507 .493
PTMI .322 .335 .419 .417 .347 .352 .446 .480
PTPROB .232 .252 .245 .285 .283 .297 .281 .289
VAR-ALTER .010 .011 .011 DEMO .012 .012 .013 .012
VAR-AITRIB .0II .013 .021 .035 .013 .018 .031 .035
PAITERN -.IlI -.107 -.319 -.329 -.103 -.164 -.446 -.408
GAIN .694 DEMO .585 .611 .269 .616 .398 .643
Block I Block 2
Block I Block 2
Block I Block 2
Note. ACQ = number of information DEMO examined. TPERACQ = time per information acquisition. PTMI = proportion of time on the most
important attribute. PTPROB = proportion of time on the DEMO information. v AR-ALTER = variance in the proportion of time spent on
each alternative. VAR-AITRIB = variance in the proportion of time spent on DEMO attribute (including both payoff and probability information).
PAITERN = index DEMO relative amount of attribute-based (-) and alternative-based (+) processing. GAIN = relative accuracy of choices.
ADAPTIVE DECISIONS
545
(VAR-ATTRIB) and alternatives (VAR-ALTER), and more attri-
bute-based processing (lower values of PATTERN). There was
no effect expected on GAIN. The dispersion manipulation
generally showed these effects.
As predicted, there was a significant difference between low
and high dispersion for both the DEMO of acquisitions (ACQ)
(M= 28.90 vs. M= 23.82), F(l, 617) = 36.39,p< .001, and
time per acquisition (M = .60 vs. M = 57), F(l, 617) DEMO 7.21,
P < .001. Less effort was used in reaching a decision for the
high-dispersion problems. The only significant dispersion by
time pressure DEMO were for ACQ, F( 1, 617) = 12.91, p
< .00 I, and TPERACQ F(l, 617) = 12.56, p < .001. The effect
of dispersion is greater in the no-time-pressure problems.
DEMO pattern of results for the variables related to selectivity
also was largely as predicted. There was more focus on the
dimension associated with the DEMO probability (PTMI) with
high dispersion of probabilities (M = .34 DEMO M = .44), F(l,
617) = 92.34, p < .001.2 However, contrary to prediction,
there was no significant difference in the proportion of time
spent on probabilities (M = .27 vs. M = .27), F(l, 617) =
1.34, ns. Both the variance in processing across attributes
(VAR-ATTRIB) and across alternatives (VAR-ALTER), on the
other hand, increased significantly for the high-dispersion
problems (DEMO = .014 vs..030), F(l, 617) = 119.13, p < .001,
(M= .011 vs. M= .013), F(l, 617) = 7.14, p < .05, respec-
tively. Thus, one effect DEMO increased dispersion was to increase
the amount of selectivity in processing, DEMO is consistent
with the use of heuristic processes such as the LEX or EBA
strategies.
The hypothesis of a shift in strategies due to DEMO context
manipulation is also supported by the fact that the amount
of attribute-based processing (shown by negative values of
PATTERN) increased significantly as DEMO dispersion of proba-
bilities increased (M = -.12 vs. -.37), DEMO(l, 613) = 54.60, p
< .001. This result for DEMO is consistent with greater use
of strategies such as EBA or the lexicographic rule for high
dispersion in probabilities.
The foregoing results are averaged DEMO subjects. Individ-
ual subjects showed patterns similar to those reported above.
For example, 86% of the subjects acquired less information
in the high-dispersion condition. Seventy-five percent spent
less time per acquisition for high-dispersion problems. One
hundred DEMO of the subjects spent more time on the most
important attribute, DEMO spent more time on probabilities,
100% had greater variance in processing across attributes, and
82% had greater variance in processing across alternatives for
the high-dispersion problems. More attribute-based process-
ing was shown by 82% of DEMO subjects in the high-dispersion
condition than in the low-dispersion condition. Thus, DEMO
group and individual analyses show adaptivity in process as a
function of context.
Finally, as expected, the average GAIN scores for the low-
DEMO and high-dispersion problems did not differ signif-
icantly (M = .54 DEMO M = .56), F( 1, 617) = .06, ns. The
accuracy of the processes used in the two contexts was ap-
DEMO the same.
The simulation results suggest that an adaptive decision
maker could take advantage of changes in context to maintain
accuracy with substantially less DEMO effort. The experi-
mental results clearly demonstrate a shift in processing strat-
egies with variation in context. People demonstrated an ability
to shift processing DEMO take advantage of problem structure so
as to reduce processing load while maintaining accuracy. The
empirical support for this relatively subtle prediction of the
DEMO provides strong support for the current approach.
Previous work on contingent decision behavior has most
clearly demonstrated a sensitivity to effort, such as the effects
of variations in the number of alternatives or attributes
(Payne, DEMO). The present work demonstrates an ability to
maintain accuracy even under a subtle change in context, as
well as sensitivity to effort.
Effects of time pressure. High time pressure was predicted
to lead to lower DEMO for ACQ and TPERACQ; higher values
for PTMI, PTPROB, VAR-ATTRIB, and VAR-ALTER; a lower value
for PATTERN; and a lower value DEMO GAIN.
As expected, subjects acquired fewer items of information
(ACQ) DEMO the time-constrained choice environments (M =
35.98 vs. M = 16.74), F(1, 617) = 378.44, p < .001. This
finding DEMO qualified by a block by time pressure interaction,
F(, 617) = 20.15, p < .001, which showed that the amount of
information acquisition did not vary over blocks in the high-
time-pressure condition, but that the amount of information
acquired in the second block was DEMO than that acquired in
the first block under no time pressure.
One major hypothesis regarding time pressure and decision
making is that people adapt DEMO time constraints by accelerating
their processing. The results for the time per acquisition
variable (TPERACQ) indicate that people did process informa-
tion significantly DEMO under time pressure (M = .67 s vs. M
= .48 DEMO), F(l, 617) = 217.36, p < .001. A DEMO by time
pressure interaction, F(l, 617) = 3.87,p < .05, showed that a
decrease over blocks only occurred in the DEMO
condition. These results are consistent with those of Ben Zur
and Breznitz (1981).
The results for the variables related to selectivity and filtra-
tion also supported the hypotheses. The proportion of time
spent on the DEMO important attribute (most likely outcome;
PTMI) was significantly greater under time pressure (M = .37
vs. M = .41), F(l, 617) = 9.83, p < .01. The proportion of
time spent on probabilities (PTPROB) was also greater for the
time-pressured problems (M = .25 vs. M = .29), F(1, 617) =
DEMO, p < .001, clearly supporting the filtration hypothesis.
Greater selectivity in processing under time pressure was
also indicated by greater variance in processing DEMO attributes
(v AR-ATTRIB) with a time constraint (M= .019 vs. DEMO = .024),
F(1, 617) = 5.98, p < .05. Interestingly, there was no effect of
time pressure on the amount of variance in processing across
alternatives, (M = .30 vs. M DEMO .31), F(l, 617) = .06, ns.
Although the DEMO of results for vAR-ALTER is not as hypoth-
esized, the results DEMO PTMI, PTPROB, and VAR-ATTRIB support
the notions of increasing filtration and selectivity under time
pressure.
Further evidence for a shift in information processing DEMO
egy as a function of time pressure is provided by the results
2 Analyses of variance for PTMI and PTPROB were also run with
DEMO measures transformed by an are sine transformation. The results
were essentially the same, and the untransformed results are reported
for simplicity.
546
J. PAYNE, J. BETIMAN, AND E. JOHNSON
for PATIERN of DEMO Under time constraint, processing
became marginally more attribute based (M = -.22 vs, M =
-.28), F(I, 617) = 3.55, p = .06.
To summarize, the results showed that people adapted DEMO
time pressure by accelerating processing, increasing the selec-
tivity of processing, and moving toward more attribute-based
processing. The latter two effects, taken together, are consist-
ent with the greater use of heuristics like the LEX or EBA
strategy under time pressure.
Again, the means for each individual showed that a majority
of subjects responded in the same directions as DEMO by
the group analysis. For instance, 100% of the subjects accel-
DEMO processing under time constraint (ACQ and TPERACQ).
Sixty-nine percent showed DEMO of filtration as indicated
by PTMI and VAR-ATIRIB. Sixty-three percent demonstrated a
greater focus on probabilities, 44% showed higher values for
VAR-ALTER, and DEMO demonstrated more attribute-based
processing under time constraints.
In addition to time pressure effects on processing, there was
a clear impact of time constraint on accuracy. Relative accu-
racy was lower under time pressure (M = .62 vs. M = .48),
F( I, 617) = 8.32, p < .0 I. An examination of the pattern of
means in DEMO 3, however, makes it clear that the decrement
in performance is concentrated in the responses to the earlier
(first block) problems involving DEMO pressure. By the latter
block, performance had improved to levels similar DEMO those
obtained in the no-time-pressure condition, as verified by a
significant DEMO by time pressure interaction, F( I, 617) =
10.73, DEMO < .01.
Discussion
The central conclusion from the results of Experiment I is
that people exhibit a substantial degree of adaptivity in their
decision DEMO Decision processes were sensitive to a
context variable that influences the relative accuracy of heu-
ristics. Decision processes were also sensitive to the important
DEMO variable of time pressure. Across a variety of dependent
measures, the DEMO of results supported the predictions.
These findings of adaptivity are particularly strong in that
they were exhibited by the same subjects on different trials.
DEMO, the general pattern of adaptive behavior was consist-
ent with the DEMO results.
The time-pressure results supported the hypotheses that
increased time pressure wold result in (a) acceleration of
information processing, (b) filtration of information to be
processed, and (c) to a lesser extent, DEMO in the choice
heuristics used to make a decision. Prior research has sup-
ported the acceleration and filtration hypotheses, but the
present experiment also suggestschanges in information proc-
essing strategies as a function of time pressure.
DEMO existence of at least three ways in which people can
adapt to time pressure leads to the following question: Is there
an ordering to the adaptive strategies people use to deal with
time pressure? That is, do people first try to deal with time
constraints through acceleration and perhaps filtration of
processing? Selecting an alternative decision process in re-
sponse to time pressure may only occur if the first two
responses are DEMO adequate. The next experiment investigates
that possibility by examining a case of less severe time pres-
sure.
Experiment 2
This study examines the extent DEMO direction of adaptive
decision processing when the amount of time pressure is less
severe than that investigated in Experiment 1. Specifically,
one time DEMO condition in this study used a 25-s limit.
For comparison, and DEMO for purposes of replication, a second
time pressure condition used the DEMO limit used in Experi-
ment 1. Furthermore, subjects in this study DEMO for a
second day. During the second session, the experiment was
DEMO, but with the time pressure level set at 25 s if DEMO
subject had received 15 s on the first day or set at 15 s if a
subject had 25 s on the first day. DEMO inclusion of the second
session was intended to explore how adaptivity to one choice
environment might influence adaptivity to a slightly different
choice environment. DEMO, this study again examined the
effects of dispersion in probabilities.
Method
DEMO A total of 28 undergraduate students served as subjects
in this experiment in return for course credit and the chance to win
money. Because DEMO experiment involved two different experimental
sessions, the maximum amount of money DEMO could be won was
$19.98 ($9.99 for each session).
Stimuli DEMO procedures. The stimuli and procedures used in this
study were essentially the same as those used in Experiment I. For
the first session, subjects were randomly assigned to one of two groups:
time pressure = DEMO s (Group I) or time pressure = 25 s (Group DEMO).
Owing to computer problems, cell sizeswere unequal, with 16 subjects
in Group 1 and 12 subjects in Group 2. One difference in DEMO
from the previous experiment was that subjects were told how much
time was involved in the time pressure trials. After the end of the DEMO
session, a gamble preferred by the subject was selected, but not played.
The second session had the time pressure set at the level DEMO to
that received on the first day. Also, the order of DEMO outcomes and
alternatives was permuted for the sets of gambles to reduce the
possibility that the subject would remember the particular choice
problems from DEMO previous day.
Results
The measures of process and accuracy used in this study
were the same as those used in the previous experiment. Table
DEMO presents the means for each of the seven process measures
and GAIN as a function of day, group, presence/absence of
time pressure, and low versus high dispersion. The data were
analyzed with a five DEMO factor multivariate analy-
sis of variance (presence of time pressure, dispersion, block,
day, and level of time pressure: 25 s vs. IS s). Subjects was
treated as a factor nested within day DEMO level.
The multivariate analysis of variance showed significant
effects of dispersion, DEMO(8, 2147) = 116.24, p < .001, and
presence of time pressure, F(8, 2147) = 200.64, p < .001. DEMO
addition, the main effects of day, F(8, 2147) = 21.42, level of
time pressure, F(8, 2147) = 18.16, and block, F(8, 2147) =
23.63, were all significant (p < .001).
The two-way interactions were generally significant as well.
DEMO most interest were a presence oftime pressure by dispersion
ADAPTIVE DECISIONS
547
Table 4
Summary of Process and Accuracy Results: Experiment 2
NTP
Group 1 (N = 16)
TP = 15 s
NTP
Group 2 (N = 12)
TP = 25 s
Day I Results
Dependent Low High Low High Low High Low High
measure DEMO dispersion dispersion dispersion dispersion dispersion dispersion dispersion
ACQ 50.8 42.1 19.5 17.2 52.8 45.2 28.8 27.7
TPERACQ .64 .62 048 048 .64 .62 .52 DEMO
PTMI .29 .37 .32 043 .30 .39 .32 Al
PTPROB .24 .27 .27 .29 .19 .20 .20 .22
VAR-ALTER .010 .013 .009 .013 .008 DEMO .008 .010
VAR-ATTRIB .007 .018 .013 .027 .005 .017 .007 .021
PATTERN .00 -.22 -.03 -.31 .30 .00 .33 .03
GAIN .56 .59 043 DEMO .75 .81 .67 .64
NTP
TP = 25 s
Day2 Results
NTP
TP = 15 s
Low High Low High Low High Low High
DEMO dispersion dispersion dispersion dispersion dispersion dispersion dispersion
ACQ 48.6 36.6 27.7 24.2 42.0 3604 21.0 19.0
TPERACQ .58 .56 049 049 .57 .54 046 DEMO
PTMI .28 .39 .27 Al .30 .39 .30 043
PTPROB .22 .26 .22 .27 .19 .21 .20 .23
VAR-ALTER .010 .013 .008 .014 .009 DEMO .009 .011
VAR-ATTRIB .006 .020 .006 .021 .005 .020 .007 .026
PATTERN .13 -.11 .22 -.08 .39 -.02 045 -.06
GAIN .66 .57 .59 DEMO .74 .75 .65 .58
Note. NTP = no time pressure. TP = time pressure. ACQ = number of information boxes examined. TPERACQ = time DEMO information
acquisition. PTMI = proportion of time on the most important attribute. PTPROB = proportion of time on the probability information. vAR-
ALTER = DEMO in the proportion of time spent on eachalternative. VAR-ATTRIB = variance in the proportionof time spent on each attribute
(including both payoffand probability information). PATTERN = index reflecting relative amount of attribute-based (-) and DEMO
(+) processing. GAIN = relative accuracy of choices.
interaction, F(DEMO, 2147) = 54.13, p < .001, a presence of time
pressure by block interaction, F(8, 2147) = 10.39, p < .001,
and a day by level of time pressure interaction, DEMO(8, 2147) =
54.13, p < .001. The first two DEMO are consistent with
those obtained in Experiment 1. The latter interaction sug-
gests that it did matter whether a subject received the 15-s
(severe time pressure) problems on the first or second day.
Analyses of simple effects within the 15-s and 25-s time-
pressure groups were performed. Because DEMO major focus
of Experiment 2 was on time-pressure effects, those results
DEMO discussed first, followed by results for dispersion. Then
effects of day DEMO level are briefly considered. The predictions
for the various dependent variables are the same as in
Experiment 1.
Time pressure effects. The results most DEMO to Ex-
periment 1, of course, are the first-day results. An examination
of the first-day process means for Group 1 (time pressure =
15 s) and Group 2 (time pressure = 25 s), DEMO in Table
4, indicates that the previous findings for 15 s DEMO replicate,
and that there may be a hierarchy of responses to levels of
time pressure.
An analysis of simple effects for the variables DEMO to
amount of processing showed fewer acquisitions with time
pressure present for both the 15-s (M = 46.43 vs. M = 18.38),
DEMO(1, 2154) = 507.01, p < .001, and the 25-s conditions (M =
49.03 vs. M = 28.25), F(1, DEMO) = 209.82, p < .001. There
was also less time per acquisition under time pressure in both
cases: 15-s condition (M = DEMO vs. M = .48), F(1, 2154 =
394.92, p < .001; 25-s condition (M = .63 vs. M = .52), F(1,
2154) = 156.88, p < .001. Thus, DEMO time pressure levels
show evidence consistent with acceleration of processing.
Analyses of simple effects for the amount of filtration and
selectivity in processing show DEMO patterns within the 15-s
and 25-s time-pressure conditions for the first day. However,
the results for the 15-s level of time pressure are DEMO
stronger. For the 15-s level, there were effects of time pressure
DEMO PTMI (M = .33 vs. M = .37), F(l, 2154) = 22.86, p < .001,
PTPROB (M = .25 vs. M = .28), F(1,2154) = 11.76, p < .001,
and VAR-ATTRIB (M = .013 vs. M = .020), F(1, 2154) = 37.37,
p < .001. There was no effect on VAR-ALTER (M = .011 vs. M
= .011), F(1, 2154) = .02, ns. There was an effect of time
pressure for the 25-s level on PTMI (M = .34 vs. M = .37),
F(l, 2154) = 4.99, p < .05, and marginal effects for PTPROB
(M = .20 vs. M = .21), F(l, 2154) = 3.71, p < .06, and VAR-
ATTRIB (M = .011 vs. M .014), F(DEMO, 2154) = 3.66, p < .06.
There was no effect DEMO VAR-ALTER (M = .009 vs, M = .009),
F( 1, 2154) = .26, ns. Thus, there is evidence for DEMO
under both time pressure conditions, although there appears
to be more DEMO when time pressure is severe.
Of greatest importance for the hypothesis of a hierarchy of
time pressure effects was the finding of a significant DEMO of
time pressure on pattern of processing in the first day for the
15-s condition (M = -.11 vs. M = -.17), F(1, 2154) = 4.86,
P < .05, with more attribute-based processing under time
548
J. PAYNE, J. BETTMAN, AND E. JOHNSON
pressure. In contrast, however, there was no effect of time
pressure on pattern of processing in the 25-s condition (M =
.15 vs. M = .18), F(1, 2154) = 1.21, ns. Thus, we find evidence
DEMO a shift toward more attribute-based processing under severe
time pressure, but DEMO shift in processing with moderate time
pressure. 3
Finally, accuracy (GAIN) was lower under time pressure for
both the 15-s (M = DEMO vs. M = .43), F(I, 2154) = 9.22, DEMO <
.01, and 25-s conditions (M = .77 vs. M DEMO .66), F(I, 2154) =
4.95, p < .05. DEMO not shown in Table 4, the detrimental
effect of time pressure DEMO GAIN was again greatest for the first
block of trials, particularly DEMO the 15-s condition (M = .29).
Dispersion effects. The pattern DEMO effects for dispersion in
probabilities for Experiment 2 was similar to that found for
Experiment 1. With respect to amount of processing, for the
15-s condition there was an effect of dispersion on ACQ (M =
35.19 vs. M = 29.67), F(1, 2154) = 24.54, p < .001, and a
marginal effect on TPERACQ (M = DEMO vs. M = .55), F(1, 2154)
= 2.77, p < .10. For the 25-s condition, there was an effect
on ACQ (M = 40.81 vs. M = 36.46), F(1, DEMO) = 16.41, p <
.001, and a marginal effect on TPERACQ (M = .58 vs. M =
.57), F(1, DEMO) = 3.52, p < .07.
Analyses of simple effects for the selectivity and filtration
measures show effects for the 15-s level on PTMI (M = .31 vs.
M = .40), F(1, 2154) DEMO 134.98, p < .001, PTPROB (M = .25
vs. M DEMO .28), F(1, 2154) = 7.01, p < .01, VAR-ATTRIB (M =
.010 vs. M = .022), F(I, DEMO) = 130m, p < .001, and VAR-
ALTER(M= .0IOvs.M= DEMO),F(I,2154)= 14.83,p< .001.
For the 25-s group there were effects on PTMI (M = .31 vs. M
= .40), F(1, 2154) = 112.62, P < .001, and DEMO (M =
.005 vs. M = .019), F(1, 2154) = 115.15, p < .001. There was
a marginal effect on DEMO (M = .20 vs. M = .21), F(1,
DEMO) = 2.72, p < .10, and a marginal effect on DEMO
(M = .008 vs. M = .010), F(I, 2154) = 3.20, p < .08. Thus,
there is evidence for DEMO selectivity under high dispersion,
but it is stronger for the 15-s condition.
There were also strong effects on PATTERN for both the 15-
DEMO (M = -.01 vs. M = -.27), F(1, 2154) = 82.03, p < .001,
and 25-s conditions (M = .31 vs. M = .01), F(1, 2154) =
91.99, p < .001. Processing becomes more attribute based
with higher dispersion. The DEMO for dispersion for the 25-s
condition are important in that they demonstrate adaptation
to the dispersion manipulation. Hence, the failure to adapt to
time pressure via strategy change in the 25-s condition is not
due to DEMO total failure to obtain adaptivity in that condition.
There are no effects of dispersion on GAIN in either the 15-
s (M = .50 vs. M = .51), F(1, 2154) = .09, ns, or 25-s
conditions (M = .70 vs. M = .71), DEMO(1, 2154) = .06, ns.
Finally, there are significant dispersion by time pressure in-
teractions for ACQ, F(1, 2154) = 10.36, p < .001, TPERACQ,
F(1, 2154) = DEMO, p < .01, and VAR-ATTRIB, F(1, 2154) =
DEMO,P < .001, for the 15-scondition; for the 25-s condition,
the only significant interaction was for ACQ, F(1, 2154) =
10.80,p < .001.
Once again, the hypothesis of adaptivity in processing was
strongly supported for dispersion in probabilities. The subjects
in Experiment 2, like those in Experiment 1, were apparently
able to take advantage of context changes to reduce processing
effort while maintaining essentially the same level DEMO accuracy.
Day and level effects. As noted earlier, the multivariate
analysis DEMO variance showed a significant day by level inter-
action. Subjects who experienced a moderate time constraint
on the first day acted differently than did DEMO who faced a
severe constraint on the first day. An examination of the
results in Table 4 indicates little difference in the processing
for DEMO 2 (25-s time pressure for the first day) between Day
1 and Day 2. The means for both VAR-ATTRIB and PATTERN,
for DEMO, are similar for each day. A simple explanation
is that a DEMO time constraint on the second day was not that
severe a time constraint. Experience with the task on the first
day resulted in the DEMO of 15 s on the second day being
more like a moderate level of time pressure. On the other
hand, note that the second-day responses for Group 1 (15-s
time pressure for the first day) DEMO intermediate between the
first day responses to 15-s time pressure and the first day
responses to 25-s time pressure.
Another interesting comparison concerns the DEMO
sure data for Groups 1 and 2 on the first day. Consider, for
example, the results for PATTERN. The no-time-pressure mean
for the DEMO condition was -.11. The mean for the 25-s
condition was .15. Thus, it appears that there was some
carryover from behavior generated in response to the time-
pressure trials to the no-time-pressure trials. This suggeststhat
the DEMO of adaptivity to time pressure found in these
experiments was not perfect on a trial by trial basis. The
development of a strategy appropriate DEMO a particular level of
time pressure apparently affected the strategy used in the no-
time-pressure situations. There is also evidence for such car-
ryover DEMO the second-day responses of Group 1 discussed
earlier.
Discussion
The results of Experiment 2 support the findings of Exper-
iment 1 and show that DEMO adapt to changes in context
(dispersion) by exhibiting changes in selectivity, type of proc-
essing, and amount of processing while maintaining accuracy.
DEMO appear to adapt to severe time pressure by accelera-
tion, filtration, and changes in strategy. They do not appear
to change strategy in DEMO to more moderate time pres-
sure. The second-day results also demonstrate some interest-
ing effects regarding how adaptation to one choice environ-
ment carries DEMO to adaptation to a different choice environ-
ment. Table 5 summarizes the main effects for dispersion and
time pressure for both experiments.
An Alternative DEMO
Although the pattern of results for time pressure for Exper-
iment 2 is consistent with the findings of Experiment 1, an
3 A third experiment, identical in procedure to Experiment I but
using a 25-s level of time pressure, was also conducted. The results
were similar to those reported in the text. Under 25 s of time pressure
there was DEMO of acceleration of processing, weak support for
the hypothesis of filtration, and no evidence of changes in the pattern
of processing. More details DEMO that experiment are available from the
authors.
Table 5
Summary 0/ Main Effect Results/or
Dependent
measure
Experiment I
Dispersion and Time Pressure: Experiments 1 and 2
Dispersion
Experiment 2
TP = 15 s TP = 25 s
-*** -***
-" -"+...... +......
+......
+...... +"
+...... +"
+......
-*** -***
Experiment DEMO
Time pressure
Experiment 2
TP = 15 s
TP = 25 s
549
Note. The signs represent the direction of each effect (e.g., DEMO dispersion led to fewer acquisitions in Experiment I). TP = time pressure.
ACQ = number of information boxes examined. TPERACQ = time per DEMO acquisition. PTMI = proportion of time on the most important
attribute. PTPROB = proportion of time on the probability information. VAR-ALTER = variance in DEMO proportion of time spent on each
alternative. VAR-ATTRIB = variance in the proportion of time spent on each attribute (including both payoff and probability information).
PATTERN = index reflecting relative amount of attribute-based (-) DEMO alternative-based (+) processing. GAIN = relative accuracy of choices.
"P< .10
.... p< .05
...... p< .01
ADAPTIVE DECISIONS
alternative explanation, suggestedby an anonymous reviewer,
must be examined. Suppose subjects only adjust DEMO the dis-
persion manipulation. They might do this by first examining
the probabilities and then engaging in a mixture of attribute-
and alternative-based processing DEMO low dispersion or
mostly attribute-based processing if dispersion is high. If one
supposes further that whatever alternative-based processing is
used tends to be greater DEMO the end of the choice process,
then a simple truncation of the process under time pressure
could lead to the observed results. Subjects DEMO not change
their processing strategy but may simply use a truncated
version of the strategy under time pressure. This possibility
must be seriously considered, as prior research (e.g., Bettman
& Park, 1980) has shown DEMO alternative-based processing
does increase relative to attribute-based processing later in the
choice process.
To examine this alternative hypothesis, we consider proc-
essing patterns early in the choice process. In particular, we
consider the processing occurring in the first eight acquisitions
of each time pressure trial. Eight acquisitions were DEMO at
the unit of analysis for several reasons. First, two distinct
DEMO patterns could be exhibited within eight acquisi-
tions, namely, examination of all four probabilities and all
four values for one alternative or acquiring DEMO on
all four probabilities and all four values for one attribute
across alternatives. Although subjects may not follow these
two patterns in pure form, eight acquisitions should allow for
any differential tendencies in starting the process DEMO emerge.
Second, eight acquisitions is also roughly half the average
number DEMO acquisitions for the 15-s time pressure condition.
Over 98% of the trials had eight acquisitions or more.
The alternative hypothesis can be tested by DEMO the
processing patterns for these first eight acquisitions for each
time pressure trial for the 15-s and 25-s time pressure condi-
tions. If the DEMO truncation hypothesis is correct, there
should be no difference between the DEMO and 25-s conditions
on these initial acquisitions for the time pressure trials, as the
overall differences between these conditions are hypothesized
to be due to truncation at the end of the process. If our
interpretation that DEMO are using different strategies is
correct, however, there should be differences between the 15-
sand 25-s conditions at the beginning of the process.
DEMO analyzed the data for the first eight acquisitions for each
time pressure trial from Experiment 2. The variables exam-
ined were two selectivity measures, the variances in the pro-
portion of time spent on attributes (VAR-ATTRIB) and alter-
natives (VAR-ALTER); and the relative proportion of alterna-
DEMO and attribute-based processing (PATTERN). These
variables were selected because they DEMO provide sensitive
indices of the early processing pattern. We have hypothesized
that subjects under severe time pressure should try to do a
quick evaluation DEMO as many alternatives as possible on a
limited number of attributes. This pattern should not char-
acterize subjects with 25-s time pressure if our DEMO that
strategy change occurs only under severe time pressure is
correct. That implies more attribute-based processing and
greater variation in processing across attributes for DEMO 15-s
condition. Because only the first few acquisitions are exam-
ined, DEMO should also imply less variation across alternatives
for the 15-scondition, because DEMO will not have had time
to eliminate alternatives. Rather, they may DEMO doing an initial
screening, with the values of all alternatives examined DEMO the
attribute or attributes considered. Thus, the strategy change
hypothesis predicts DEMO foregoing differences between the 15-
sand 25-s conditions for the eight initial acquisitions per time
pressure trial, whereas a strict truncation hypothesis should
predict no differences.
The results support the strategy change hypothesis and are
not DEMO with the truncation hypothesis. VAR-ATTRIB is
marginally greater for the 15-s condition than the 25-s con-
dition (M = .033 vs. M = .026), F(l, 526) = 2.84, p < .10,
and VAR-ALTER is significantly less for the 15-s condition (M
= .075 vs. M= .105), F(l, 510) = 7.03,p< .02. The tendency
for the 15-s condition to engage in more attribute-based
550
J. PAYNE, J. DETTMAN, AND E. JOHNSON
processing (more negative values of PATIERN) is also margin-
ally significant (M = -.33 DEMO M = .01), F(I, 474) = 3.35, p
< .08. Although these results do not all reach conventional
.05 levels of significance, they are all directionally consistent
with the strategy change hypothesis rather than truncation. In
addition, there were no significant differences on these vari-
ables for the no-time-pressure trials between the 15-s and 25-
s conditions, F(l, 526) = 1.31, F(l, 473) = .18, and F(I, 382)
= .59 for VAR-ATIRIB, VAR-ALTER, DEMO PATIERN, respectively.
This supports the notion that different strategies are adaptive
DEMO to different levels of time pressure, not a general
tendency of DEMO different subject groups.
To provide further insights into the pattern of processing
over the course of a decision, the responses of subjects were
compared for the first eight acquisitions and last eight acqui-
sitions of all DEMO on PATIERN and PTPROB. Consistent with
prior research (Bettman & Park, 1980), there was more attrib-
ute-based processing for the earlier acquisitions DEMO for the
later acquisitions, both for the 15-s condition (M = -.35 vs.
-.05), F(l, 1137) = 46.86, p < .001, and the 25-s condition
(M = -.08 vs.. 26), DEMO(l' 873) = 51.94, p < .001. There was
also DEMO greater initial focus on probabilities for both the 15-s
(M = DEMO vs. M = .11), F(I, 1264) = 1837.04, DEMO < .001, and
25-s conditions (M = .58 vs. M = .08), F(I, 944) = 2576.23,
p < .00 DEMO The PTPROB means were essentially the same for
both the 15-s and 25-s conditions. Thus, the 15-s and 25-s
conditions exhibit different responses to time pressure from
the beginning. Even though processing becomes relatively
more alternative DEMO over the course of a trial, the difference
between the two DEMO remains.
General Discussion
Previous research has shown that the same individual will
often use diverse strategies to make a decision, contingent on
task demands (Payne, 1982). A major problem for current
cognitive research is DEMO be able to better understand and
predict when a particular strategy will be used.
This article has examined effort and accuracy considera-
tions in DEMO selection of strategies for making a choice. The
general hypothesis is that selection among strategies is adap-
tive, in that a decision maker will choose strategies that are
relatively efficient in terms of effort and accuracy DEMO task and
context demands are varied. The article first outlined an
approach to modeling the impact oftask and context variables
on decision strategies by DEMO elementary information proc-
esses to measure effort and computer simulation models to
examine accuracy and effort trade-ofTs. A Monte-Carlo sim-
ulation examined the impact DEMO variation in the presence or
absence of time pressure, dispersion in DEMO, presence
or absence of dominated alternatives, and different problem
sizes on the accuracy and effort of a variety of choice heuris-
tics. Strategies DEMO identified that approximate the accuracy
of normative procedures while requiring substantially less
effort. However, no single heuristic did well across all task
and context conditions. A decision maker striving to maintain
a high level of accuracy DEMO a minimum of effort would have
to use a variety of heuristics adaptively. Of particular interest
was the finding that under time constraints, several attribute-
based heuristics (e.g., EBA and LEX) were more accurate than
a normative procedure such as expected value maximization,
because that procedure DEMO to be truncated when it ran out
of time .
The simulation does not really answer the question of how
a strategy is selected, however. The implicit viewpoint in our
work is that a decision maker DEMO a repertoire of well-
defined strategies and selects among them when faced with a
decision by considering the expected costs and expected ben-
efits DEMO each strategy. This top-down view of strategy selection
is consistent with previous models like that of Beach and
Mitchell (1978). Alternatively, strategies DEMO develop during
the course of solving a decision problem in a more bottom-
up, constructive, and ad hoc fashion (Bettman, 1979).
DEMO a choice episode a decision maker will be alert
to structure in the choice set that can be exploited to reduce
effort and perhaps DEMO accuracy. Regardless of how strat-
egy selection is controlled, the simulation DEMO do suggest
how certain context and task variables affect the relative effort
and accuracy of possible strategies.
Adaptivity to Decision Environments
Experiments 1 and DEMO tested the degree of correspondence
between the efficient processing strategies for a given decision
problem identified by the simulations and the actual infor-
mation DEMO behavior exhibited by people. The results
for actual decision behavior tended to validate the patterns
predicted by the simulation.
More specifically, subjects generally acquired less informa-
tion, spent less time per acquisition, spent proportionately
more DEMO on the most important attribute, displayed greater
variance in the proportion DEMO time spent on the various
alternatives and attributes, and used more DEMO
processing when dispersion in the weights (probabilities), a
context variable, was high rather than low. The effects of
dispersion on the proportion DEMO time spent on probabilities
were not consistent across studies, although more DEMO was
spent on probabilities under high dispersion in the majority
of cases. Such adaptivity in strategy usage in response to a
context variable demonstrates DEMO people are sensitive to a
change in the task environment that potentially impacts the
relative accuracy of heuristics as well as affecting relative
effort.
DEMO addition, several effects of time pressure were demon-
strated. Under moderate DEMO pressure, subjects were shown
to accelerate their processing. There was some DEMO, al-
though weaker, that subjects selectively focus on a subset of
the available information. Under severe time pressure, people
accelerated their processing, DEMO on a subset of the infor-
mation, and changed their information DEMO strategies.
There was more attribute-based processing and more variance
in the proportion of time spent on various attributes as time
pressure increased. Counter to DEMO, there were not
systematic effects of time pressure on the variance DEMO the
proportion of time spent on various alternatives, implying
that subjects DEMO equally consistent in the proportion of
information searched across alternatives, regardless DEMO time
pressure. One possible explanation is that the nature of the
ADAPTIVE
display may have made complete scans of an attribute rela-
tivelyeasy.
DEMO the two experiments, the relative amount of dimen-
sional processing (PATTERN) was an average of 41% greater
under time pressure of 15 s compared with no time pressure.
In contrast, the relative amount of dimensional processing
was 20% less under time pressure of 25 s compared with DEMO
time pressure. The variance in processing across attributes
(VAR-ATTRIB) was increased by 40% on average for the 15-s
time pressure conditions versus no DEMO pressure; however,
the average increase was 21% for the 25-s DEMO
conditions.
There are several important aspects of these time-pressure
results. First, DEMO provide a strong demonstration of the
adaptivity of processing strategies to time pressure. Second,
the results of the experiments imply that there may DEMO a
hierarchy of responses to time pressure. People may first
attempt to simply accelerate their processing and try to do
the same things faster. DEMO the time pressure is too great for
acceleration to suffice, individuals DEMO next engage in filtra-
tion, focusing on a subset of the DEMO information. Fi-
nally, people may change strategies when time pressures be-
DEMO extreme. Of course, the specific strategies found in our
studies may DEMO a function of the problem format used. Dif-
ferent adaptive strategies would presumably be found for
ditTerent task structures.
Learning Effort-Accuracy Trade-offs
The evidence DEMO processing changes reported in the present
experiments suggests that people were learning to adapt their
behavior to changes in task and context. Yet none DEMO the
experiments provided the subjects with explicit accuracy or
outcome feedback. Johnson and Payne (1985) argued that a
decision maker has access to DEMO fairly rich data base about the
course of his or her own decision processes. They hypothesize
that this process feedback could provide the information
DEMO for strategy change. For example, a decision maker
might induce the DEMO rule by first noticing that certain out-
comes seem much more probable than others (Klein, 1983,
reports data supporting this kind of DEMO about the task).
Next, the decision maker might evaluate a DEMO that takes
advantage of the features of the task by checking whether the
outcomes are consistent with several simple principles of
choice. For instance, the decision maker might check that the
new strategy does not select DEMO alternatives, and that
it selects alternatives that have satisfactory levels of DEMO
outcomes.
General knowledge of what makes for a good decision
process may also playa role in learning to adapt. For instance,
the idea DEMO a good decision requires considering all relevant
information is likely to be held by many people, as is the
notion that a good process will examine the most important
information." Consequently, when faced with a DEMO task
in which it is impossible or very difficult to process all
information, the decision maker might use the information
he or she has gained about the task to decide what information
is less important and DEMO be ignored. An example of such task
DECISIONS 551
information is that some probabilities are much smaller than
others under high-dispersion conditions.
The data DEMO in this article demonstrate that people
shift decision strategies in response to a context change in
ways that maintain accuracy, without explicit outcome feed-
back. Reder (1987) has also found evidence of strategy
changes in DEMO question answering task without outcome feed-
back. She suggests several ideas regarding the mechanisms of
adaptive strategy selection, such as a "feeling-of-knowing"
DEMO, that may relate to the "level of confidence" discussed
by DEMO (1985). People may seek to develop strategies
that take advantage DEMO problem structure so as to minimize
etTort while maintaining a feeling of knowing or desired level
of confidence that they are making a reasonable DEMO
The present results, taken as a whole, provide strong evi-
dence for adaptivity in decision making, although the degree
of adaptivity was not perfect. There did appear to be some
carry-over etTects in terms of DEMO strategies from trial
to trial and from day to day. Despite these carry-over etTects,
however, individuals did change information processing strat-
egies depending upon the changing structure of the choice
environment from problem to problem. DEMO variability in
processing from one problem to the next implies that humans
possess abilities for assessing choice environment properties;
characterizing such abilities would DEMO a fruitful area for study.
It is likely that certain environmental properties may be more
easily noticed, and hence more adapted to, than DEMO For
example, it may be difficult for people to notice attribute
DEMO (Crocker, 1981).
Finally, the evidence for adaptive use of DEMO obtained
in this study suggests a picture of the human decision maker
that is fairly optimistic in terms of rational behavior. People
clearly do DEMO choice heuristics that lead to violations of
certain principles of rationality (DEMO, 1969). The use of
heuristic processes that lead to decision DEMO may reflect a
trade-otT of etTort and accuracy, or reflect the DEMO that the
decision maker has no other choice in some decision environ-
ments than the use of a heuristic (Simon, 1981). However,DEMO
our results suggestthat people can adaptively change process-
ing strategies in ways that are appropriate given somewhat
subtle changes in the structure of the DEMO problems they
face.
_As part of the debriefing process for Experiment 2, subjects were
asked what strategy they would advocate to identify the "DEMO" choice
under no time pressure. The use of all information, including a
weighting of payoffs by probabilities, was identified by many of the
subjects. For time pressure, the subjects indicated that use of as much
of the most important information as possible was a major consid-
eration.
DEMO
Abelson, R. P., & Levi, A. (1985). Decision making and decision
theory. In G. Lindzey & E. Aronson (Eds.), The handbook ofsocial
psychology (Vol. I, pp. 231-309). New York: Random House.
Anzai, Y., & Simon, H. A. (1979). The DEMO oflearning by doing.
Psychological Review, 86, 124-140.
Beach, L. R. (1983). Muddling through: A response to Yates and
552
J. PAYNE, J. BETTMAN, AND E. JOHNSON
Goldstein. Organizational Behavior DEMO Human Performance, 31,
47-53.
Beach, L. R., & Mitchell, T. R. (1978). A contingency model for the
selection of decision strategies. Academy of Management Review,
3,439-449.
Ben Zur, H., & Breznitz, S. J. (1981). The effects of time pressure on
risky choice behavior. Acta Psychologica, 47, 89-104.
Bettman, J. R. (DEMO). An information processing theory ofconsumer
choice. Reading, MA: Addison-Wesley.
Bettman, J. R., Johnson, E. J., & Payne, J. W. (DEMO). CognitiveejJort
and decision making strategies: A componential analysis of choice.
DEMO manuscript, Center for Decision Studies, Fuqua
School of Business, Duke DEMO
Bettman, J. R., & Park, C. W. (1980). Effects of prior knowledge and
experience and phase of the choice process on DEMO decision
processes: A protocol analysis. Journal of Consumer Research, 7,
234-249.
Busemeyer, J. R. (1985). Decision making under uncertainty: A
comparison of simple scalability, fixed-sample, and sequential-
sampling models. Journal of DEMO Psychology: Learning,
Memory, and Cognition, 11, 538-564.
Card, DEMO K., Moran, T. P., & Newell, A. (1983). DEMO psychology of
human-computer interaction. Hillsdale, NJ: Erlbaum.
Crocker, J. (1981). Judgment of covariation by social perceivers.
Psychological Bulletin, 90, 272-292.
DEMO, H. (1980). Learning from experience and suboptimal rules
in decision making. In T. S. Wallsten (Ed.), Cognitive processes in
choice and decision behavior (pp. 1-20). Hillsdale, NJ: Erlbaum.
Hammond, K. DEMO (1986). A theoretically based review of theory and
research in DEMO and decision making. (Report No. 260).
Boulder, CO: Center DEMO Research on Judgment and Policy, Insti-
tute of Cognitive Science, University of Colorado.
Huber, J., Payne, J. W., & Puto, C. (1982). Adding asymmetrically
dominated alternatives: Violations of regularity and the DEMO
hypothesis. Journal of Consumer Research, 9,9-98.
Huber, O. (1980)DEMO The influence of some task variables on cognitive
operations in an information-processing decision model. Acta Psy-
chologica,45,187-196.
Johnson, E. J. (1979)DEMO Deciding how to decide: The effort of making
a decision. Unpublished DEMO, University of Chicago.
Johnson, E. J., & Payne, J. W. (1985). Effort and accuracy in choice.
Management Science, 31,395-414.
DEMO, E. J., Payne, J. W., & Bettman, J. R. (in press). Information
displays and preference reversals. Organizational Behavior and
Human DEMO Processes.
Johnson, E. J., Payne, J. W., Schkade, D. DEMO, & Bettman, J. R. (1986).
Monitoring information processing and DEMO: The mouselab
system. Unpublished manuscript, Center for Decision Studies,
Fuqua School of Business, Duke University.
Keeney, R. L., & Raiffa, DEMO (1976). Decisions with multiple objectives:
Preferences and value tradeoffs. DEMO York: Wiley.
Klayman, J. (1983). Analysis of predecisional information DEMO
patterns. In P. C. Humphreys, O. Svenson, & A. Vari (DEMO),
Analyzing and aiding decision processes (pp. 401-414). Amster-
dam: North Holland.
Klein, N. M. (1983). Utility and decision strategies: A second look at
the rational decision maker. Organizational Behavioral and Hu-
man Performance, 31, 1-25.
March, J. G. (1978). Bounded DEMO, ambiguity, and the engi-
neering of choice. Bell Journal of Economics, 9, 587-608.
McClelland, G. H. (1978). Equal versus differential DEMO for
multiattribute decisions. Unpublished manuscript, University of
Colorado, Boulder.
Miller, DEMO G. (1960). Information input overload and psychopathol-
ogy. American Journal DEMO, 116,695-704.
Newell, A., & Simon, H. A. (1972)DEMO Human problem solving. Engle-
wood Cliffs, NJ: Prentice Hall.
Payne, DEMO W. (1976). Task complexity and contingent processing in
decision making: An information search and protocol analysis.
Organizational Behavior and Human Performance, 16, 366-387.
Payne, J. W. (1982). Contingent decision behavior. Psychological
Bulletin, 92, 382-402.
Reder, L. M. (1987). Strategy selection in DEMO answering. Cog-
nitive Psychology, 19,90-138.
Russo, J. E., & DEMO, B. A. (1983). Strategies for multiattribute
binary choice. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 9, 676-696.
Simon, H. A. (1955). A behavioral model of rational choice. Quarterly
Journal of Economics, 69, 99-118.
Simon, H. A. (1981). The DEMO of the artificial (2nd. ed). Cam-
bridge, MA: MIT DEMO
Thorngate, W. (1980). Efficient decision heuristics. Behavioral Sci-
ence, DEMO, 219-225.
Tversky, A. (1969). Intransitivity of preferences. Psychological Re-
DEMO, 76,31-48.
Tversky, A. (1972). Elimination by aspects: A theory of choice.
Psychological Review, 79, 281-299.
Wright, P. L. (DEMO). The harassed decision maker: Time pressures,
distraction, and the use of evidence. Journal ofApplied Psychology,
59, 555-561.
Zakay, D., & Wooler, S. (1984). Time pressure, training and decision
effectiveness. Ergonomics, 27, 273-284.
Received June 16, 1986
Revision received September 14, 1987
Accepted September 14, 1987 â¢{1g42fwefx}