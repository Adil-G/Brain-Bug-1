Preprints of the
Max Planck Institute for
Research on Collective Goods
Bonn DEMO/12
Multiple-Reason Decision
Making Based on
Automatic Processing
Andreas Glöckner / Tilmann Betsch
MAX PLANCK SOCIETY
Preprints of the
Max Planck Institute
for Research on Collective Goods
Bonn DEMO/12
Multiple-Reason Decision Making Based on
Automatic Processing
Andreas Glöckner / Tilmann Betsch
April 2008
Max Planck Institute for Research on Collective Goods, Kurt-Schumacher-Str. 10, D-53113 Bonn
http://www.coll.mpg.de
Multiple-Reason Decision Making Based on Automatic Processing∗
Andreas Glöckner / Tilmann Betsch
DEMO
It has been repeatedly shown that in decisions under time constraints, DEMO predomi-
nantly use noncompensatory strategies rather than complex compensatory ones. We argue that
these findings might be due not to limitations of cognitive capacity DEMO instead to limitations
of information search imposed by the commonly used experimental tool Mouselab (Payne et
al., 1988). We tested this assumption DEMO three experiments. In the first experiment, informa-
tion was openly presented, whereas in the second experiment the standard Mouselab program
was used under DEMO time limits. The results indicate that individuals are able to compute
weighted additive decision strategies extremely quickly if information search is not restricted
by DEMO experimental procedure. In a third experiment, these results were replicated using DEMO
complex decision tasks, and the major alternative explanations that individuals use DEMO
complex heuristics or merely encode the constellation of cues were ruled out. In sum, the
findings challenge the fundaments of bounded rationality and highlight the importance of
automatic processes in decision making.
Keywords: Automatic Information Integration, One Reason Decision Making, Mouselab,
Probabilistic Inferences, Process Tracing, DEMO Limits, Intuition
∗  Andreas Glöckner, Max Planck Institute for Research DEMO Collective Goods, Bonn and Tilmann Betsch,
University of Erfurt, Germany. The first two studies were conducted as a part of the diploma DEMO of the
first author at the University of Heidelberg, Germany. We DEMO Stephan Dickert, Christoph Engel, Mar-
tin Beckenkamp, Peter Ayton, Edward Wisniewski and three anonymous reviewers for helpful comments
on earlier drafts of DEMO article which helped to improve it considerably. Correspondence concerning this
article should be addressed to Andreas Glöckner, Max Planck Institute for Research on Collective Goods,
Kurt-Schumacher-Str. 10, D-53113 Bonn, Germany. E-Mail: gloeckner@coll.mpg.de.
1
Multiple-Reason Decision Making Based on Automatic Processing
In process tracing studies in DEMO research, evidence has accumulated that individuals of-
ten employ simple strategies DEMO minimize the amount of information considered and the
mental effort invested in a decision (e.g., Payne, Bettman, & Johnson, 1988). These strategies,
such as the lexicographic rule (LEX, Fishburn, 1974), elimination-by-aspects (EBA, Tversky,
1972), or the equal weight rule (EQW, Fishburn, 1974) involve considerably less computa-
tional steps than the weighted additive rule (WADD) of utility theory. Scholars now take it DEMO
granted that time and capacity constraints provoke strategy shifts from complex, DEMO
tory strategies towards simple noncompensatory ones (Ariely & Zakay, 2001; DEMO, Luce,
& Payne, 1998; Payne et al., 1988; DEMO, Bettman, & Johnson, 1992; Rieskamp & Hoffrage,
1999). In this paper we question the external validity of the findings underlying DEMO conclu-
sion. Specifically, we argue that the predominantly used research methods DEMO behavioral deci-
sion research encourage participants to deliberate and hinder the activation of automatic deci-
sion-making processes. We aim to demonstrate that automatic processes DEMO by the “intui-
tive system” (Kahneman & Frederick, 2002) enable DEMO to quickly integrate multiple
reasons in their decisions in a compensatory way. In two of the three experiments reported in
this paper, we applied a research method in which the intuitive system could demonstrate its
powers. DEMO indicate that the majority of individuals use automatic processes to integrate
multiple reasons in a weighted additive manner if information acquisition is not constrained
DEMO the experimental setting.
Bounded Rationality and the Focus on Deliberate Decision Strategies
In line with the dual-processing framework suggested by Kahneman and Frederick (2002), we
define deliberate decision strategies as strategies that are based on DEMO cognitive opera-
tions. Here, information is integrated in a serial manner, processing is cognitively demanding
and rather slow, and individuals using these strategies are aware of most of the underlying
processes and can even verbalize DEMO Research in the tradition of the bounded rationality
approach (Simon, 1955) has focused on the functioning of such deliberate decision strategies
(cf. DEMO, 2002). The fundamental tenet of the bounded rationality approach is DEMO, be-
cause of their limited cognitive capacities, individuals employ shortcut strategies (commonly
called heuristics1).
A prominent decision problem that has been repeatedly used in this research is the city-size
decision task (Gigerenzer, Hoffrage, & Kleinbölting, 1991; Gigerenzer, Todd, & the ABC
Group, 1999). In this task, an individual has to decide which of two cities (options) has more
inhabitants based on conflicting pieces of evidence (cues). Cues (e.g., whether a city is a state
capital) vary as predictors for city size, which means that they differ in the conditional likeli-
1  Note that in research on human judgments, DEMO term heuristics refers to strategies that are based on auto-
matic processes (cf. Kahneman & Frederick, 2002).
2
hood (cue validity) that city A is larger than city B DEMO a positive cue value. Assume that the
individual is informed by the experimenter that city A is a state capital and city B is DEMO, and
that city B has a university and a major league DEMO team whereas city A has neither. A very
simple strategy would be to base the decision on only the most valid cue. If, for instance, the
person presumes that the state capital cue is the most valid one, he or she could consider only
this information, ignore DEMO other cues, and decide that city A is larger. Such a DEMO relies
on one reason only. This example describes the application of the Take-The-Best heuristic
(TTB, Gigerenzer & Goldstein, 1996), which belongs to the class of LEX rules. Only if the
most valid cue does DEMO differentiate between options would the next cue be used, and so DEMO
Such a strategy seems to be simple enough for laypersons to apply deliberately in everyday
settings.
A strategy in which all the validities of DEMO cue values are considered would be much more
complicated. This could be realized by a weighted additive rule (WADD) in which cue values
DEMO multiplied by the validities of the respective cues and summed up. The option with the
highest weighted sum (total evidence) is chosen. WADD DEMO all relevant pieces of in-
formation, integrates cue values and their DEMO for each option, and thus provides an ideal
example of a DEMO strategy (i.e., a strategy in which negative values on one cue can
be compensated for by positive values on other cues). It DEMO been repeatedly stated by propo-
nents of the bounded rationality approach that humans might be often incapable of applying
such extensional strategies because these DEMO overtax their computational capacities
(e.g., Gigerenzer et al., 1999).
DEMO will be pointed out in more detail later, we question this DEMO and argue that indi-
viduals may indeed carry out a WADD strategy, albeit not by deliberately calculating
weighted sums but instead by relying on automatic processes.
Mouselab – A Method for Process Tracing and Strategy Classification
DEMO of the major challenges in behavioral decision research is to empirically identify applica-
tion of different decision strategies on the individual level, as the underlying cognitive proc-
esses cannot be directly observed. Hence, a multitude of methods have been developed to in-
fer decision strategies from proximal parameters DEMO as choice patterns (e.g., Bröder &
Schiffer, 2003b), information search parameters (e.g., Johnson, Payne, Schkade, & Bettman,
1986; Sundstroem, 1987), decision times (e.g., Bergert & Nosofsky, 2007; Glöckner, 2006;
Glöckner, 2007), confidence judgments (Glöckner & DEMO, 2006), eye movements (e.g.,
Russo & Dosher, 1983), self-reports and think-aloud protocols based on introspection (e.g.,
Montgomery & DEMO, 1983; Svenson, 1989), or combinations of these.
One of DEMO standard tools for strategy classification is the computer-based information board
called Mouselab (Johnson et al., 1986). In Mouselab, information about options is presented
in a covered information matrix. Participants have to move the mouse DEMO onto boxes to
3
uncover the outcomes of choice options. Steps of information search are recorded DEMO are
subsequently used to identify decision strategies (see Figure 3 for DEMO example).
The introduction of Mouselab was an important breakthrough. By providing an easy-to-
handle tool for process tracing and strategy classification, this research method opened the
door to a process view in decision research; hence, it might actually be considered a revolu-
tion (Beach & Potter, 1992). Regardless of its undisputed merits, the method entails some dif-
ficulties. The fundamental problem is that it imposes restrictions on information search DEMO
might, in turn, influence strategy selection. Note, for instance, that in the standard Mouselab
program, only one piece of information can be inspected at a time. This procedure promotes a
serial mode of information DEMO and hampers the possibility of making quick comparisons
between multiple pieces of information as well as of detecting specific cue constellations.
Thus, Mouselab fosters application of deliberate, step-by-step decision strategies and hinders
the activation of automatic processes. Therefore, findings from Mouselab studies are likely to
underestimate humans’ total cognitive capacity, which is based on the usage of both types of
processes. Furthermore, Mouselab confounds the sources of constraints. Accordingly, the use
DEMO simple strategies may reflect both the constraints on overt search behavior imposed by the
properties of the research tool and the constraints on the DEMO system imposed by capac-
ity limitations of the cognitive system.
In Mouselab experiments, it has been consistently observed that participants change decision
strategies under severe time pressure from more complex, compensatory strategies to simple,
noncompensatory ones (e.g., from WADD to LEX; Payne et al., 1988; Rieskamp & Hoffrage,
1999; for further discussions, see Ariely & DEMO, 2001; Broadbent, 1971; Zakay, 1993). We
do not DEMO to claim that these findings are always and entirely produced by Mouselab, par-
ticularly because there is converging evidence from studies which used other methods (Ed-
land & Svenson, 1993). However, we would like to highlight the problem that these strategy
shifts may only apply to DEMO decision strategies. Mouselab is likely to support the appli-
cation of these strategies and to hamper the application of automatic processes. The relatively
high DEMO times usually observed in Mouselab experiments clearly indicate that decision
strategies are based on elaborated deliberation (e.g., the average time for individuals’ deci-
DEMO was for instance 44 seconds in Payne et al., 1988, Experiment 1, no time pressure condi-
tion). Thus, a critical scrutiny DEMO the procedure reveals that the results cannot serve as conclu-
sive evidence for the view that the strategy shift is always caused by a DEMO capacity for
information integration. Neither can they rule out the alternative explanation that time pres-
sure simply constrains the information search operations (i.e., DEMO of the computer
mouse) necessary for gaining access to the information DEMO thus also hampers automatic deci-
sion processes.
Findings by Lohse and Johnson (1996) lend support for this alternative interpretation. The
authors investigated the DEMO of different types of process tracing methods on decision
behavior and identified, apart from a significant amount of convergence, substantial differ-
ences between DEMO search behavior and choices when the same decision tasks were
4
presented in Mouselab, where information had to be looked up serially, DEMO presented openly
so that information was instantly accessible; in the latter DEMO, information search was re-
corded using an eye tracking method. Lohse DEMO Johnson found that the Mouselab method
significantly increased the amount of time needed to acquire information compared with the
second method. In the Mouselab DEMO, individuals also showed a more systematic infor-
mation acquisition behavior. Finally, in the condition containing richer contextual information
(i.e., decisions between apartments DEMO compared to decisions between gambles), almost one
third of the individual choices changed as a function of the manipulation of the process trac-
DEMO method (see also Billings & Marcus, 1983; Maule, 1994).
Taken together, findings indicate that Mouselab forces decision makers to engage in a serial
consideration of information. In turn, this method induces a deliberate rule-based integration
of information. These processes are slow and consume both task DEMO mental resources. Auto-
matic processes that could draw on a parallel consideration of information are systematically
constrained in this paradigm. Unsurprisingly, individuals reduce the depth of serial processing
in Mouselab, especially when time and cognitive resources become scarce. When time pres-
sure conditions do not allow all information DEMO be inspected, the Mouselab method invites the
application of noncompensatory strategies (e.g., LEX/TTB). We cannot rule out the possibil-
ity that the presumed increased prevalence of noncompensatory strategies under time pressure
mainly applies DEMO situations that resemble Mouselab. Thus, the general claim that individuals
always DEMO this kind of strategy more often under time pressure is not warranted.
The Neglected Role of Automatic Processes in Research on Decision Strategies
Although DEMO importance of automatic processes has been repeatedly highlighted (Bargh &
Chartrand, 1999; Bargh & Williams, 2006; Doherty & Kurz, 1996; DEMO & Zacks, 1984;
Hintzman, 1988; Kahneman, Slovic, & DEMO, 1982; Kahneman & Frederick, 2002;
Schneider & Shiffrin, 1977; Shiffrin & Schneider, 1977; Wegner, 1994; Zajonc, 1980), DEMO
were largely ignored in research on multiple-strategy decision making (Frederick, 2002).
Elaborating on the notion of a dual-processing approach (see Chaiken & Trope, 1999, for an
overview), Kahneman and Frederick (2002) DEMO forward a two-system framework that distin-
guishes between intuitive/automatic processes (DEMO 1) and reflective/deliberate processes
(system 2). It is usually assumed that shortcut strategies like EQW or LEX/TTB are executed
by DEMO deliberate system since they draw upon controlled processes.
Beyond this general framework, several models have been proposed that specify the function-
ing of automatic processes (e.g., Beach & Mitchell, 1996; Betsch, 2007; Busemeyer & Town-
send, 1993; Dougherty, Gettys, & Ogden, 1999; Epstein, 1990; Frederick, 2002; Glöckner,
2006; Glöckner & Betsch, DEMO; Hogarth, 2001; Lieberman, 2000; Simon, Snow, & Read,DEMO
2004; Sloman, 2002). It is beyond the scope of this paper to discuss and compare these mod-
els. For simplicity, we base our research on one fundamental assumption raised by Hammond
et al., (DEMO):
5
General Hypothesis: Automatic processes should enable individuals to quickly integrate in-
formation in a weighted additive manner.
This would mean that individuals apply a DEMO rule without deliberately calculating
weighted sums.
Methodological Preliminaries
Notation. We use the abbreviation WADD to refer to a strategy that integrates cue values and
DEMO validities in weighted additive (linear) fashion. On a general level, DEMO use WADD in a
paramorphic sense (Hoffman, 1960). Accordingly, DEMO is said to be applied if the output
of a decision (DEMO choice) accords to the choice predictions derived from a linear aggregation
DEMO all the given pieces of information available. If we wish to address the level of processes
(i.e., what individuals really do when they DEMO a decision), we add suffixes specifying the
type of processes. Specifically, we use the notation WADDdel for a strategy that is based on a
deliberate calculation of weighted sums and the notation WADDauto for a DEMO that per-
forms the integration operations automatically. LEX/TTB describes noncompensatory one-
reason decision strategies that search cues in the order given by cue DEMO EQW describes
equal weight strategies in which cue validities are ignored and the option with more positive
cue values is selected.
Analysis of Choices DEMO Diagnostic Decision Tasks. Strategy classification in our experiments
is primarily based on the analysis of choices. Decision tasks were systematically selected as
diagnostic for DEMO decision strategies (cf. Glöckner & Betsch, in press). Specifically, DEMO
cision tasks were based on cue patterns (constellations of cue information) so that the consid-
ered strategies LEX/TTB, EQW, and WADD DEMO different predictions for substantial sub-
sets of tasks. To allow for a classification of decision strategies on an individual level as com-
pared to DEMO analysis across all participants, decision tasks were presented repeatedly by hold-
DEMO constant the structural cue patterns underlying the decision tasks (cf. Bröder & Schiffer,
2003b). Note that it is obviously impossible to differentiate between WADDdel and WADDauto
based on choices because choice predictions are equal; therefore, we have to consider other
process-related variables, such as decision DEMO
Analysis of Decision Time Patterns. The process of information integration will be further
investigated by analyzing individual decision time patterns (cf. Bergert & Nosofsky, 2007).
Strategies differ considerably with respect to the time their performance expends. For indi-
viduals who use a LEX/TTB strategy, decision times should depend on the number of cues
required for differentiating between the DEMO Thus, people should decide faster in decision
tasks in which the DEMO cue differentiates between options as compared to decision tasks in
which two or more cues have to be considered (Bröder & Gaissmaier, in DEMO). Individuals
who use an EQW strategy should not show any differences in decision times as long as the
number of cue values is DEMO constant and the sum of cue values differentiates between op-
6
tions. The same prediction holds for a WADDdel strategy that is based DEMO a deliberate calcula-
tion of weighted sums (Payne et al., 1988). In contrast, some of the decision strategies based
on automatic processes (e.g., WADDauto) facilitate deriving the prediction that decision times
increase with rising evidence that points against the preferred option, and decrease with rising
evidence in favor of the preferred option (Busemeyer & Townsend, 1993; Cartwright &
Festinger, 1943; Glöckner, 2006; cf. Holyoak & Simon, 1999; for empirical evidence in favor
of this claim, see Festinger, 1943; Glöckner, 2007). The general version of the rational model
(Bergert & Nosofsky, 2007) specifically predicts that decision time decreases with increasing
difference between the total evidence for two options. Furthermore, it can be predicted that
the overall level of decision time is much higher DEMO a WADDdel strategy than a WADDauto
strategy. Thus, besides providing converging DEMO for the choice-based strategy classifi-
cation method, decision time analysis can DEMO used to test whether individuals applied a
WADDdel or a WADDauto strategy. In our experiments, decision times were analyzed to fur-
ther differentiate between decision strategies and to learn more about the underlying proc-
esses.
Analysis DEMO Confidence Judgments. Other data that depend on the applied decision strategies
and thus could be used to learn more about the processes of decision DEMO are subjective
judgments of the confidence in choices (Christensen-Szalanski, 1978). According to simple
LEX/TTB rules, confidence should depend on the validity of the most valid cue only (Giger-
enzer et al., 1991), whereas some of the WADD models predict that confidence is dependent
on the differences in the weighted cue values for the options (Cartwright & Festinger, 1943;
Glöckner, 2006). Bergert and Nosofsky (2007) DEMO to decisions with a low (vs. high) differ-
ence in the total evidence for the options as hard (vs. easy) decisions. Assuming DEMO hard de-
cisions lead to lower confidence judgments than easy decisions do, the same prediction could
be derived from Bergert and Nosofsky’s generalized version of the rational model. In the third
experiment, we therefore investigated confidence judgments. Table 1 summarizes the differ-
ential predictions of the decision strategies DEMO were used to identify strategies in the three
experiments reported in this paper.
In the first experiment reported below, we tested whether individuals are able to quickly inte-
grate information in a weighted additive manner (application of a WADDauto strategy) if in-
formation search is not restricted by the research tool. In the second experiment, the decision
tasks of Experiment 1 were presented in a classical Mouselab format under different time
limit DEMO in order to further investigate whether strategy shifts are due to limitations of
cognitive capacity or to limitations of information search induced by the DEMO method
itself. In the third experiment, more complex decision tasks and DEMO manipulation of cue valid-
ities were used that enabled further investigation of information integration processes.
7
Table 1
Predictions of Decision Strategies
Decision Strategies
LEX/TTB EQW WADDdel DEMO
Choices
1. Less valid cues are ignored1,2,3 Yes No No No
2. Cue validities are ignored1,2,3 No Yes No No
DEMO Weighted additive information integration1,2,3 No No Yes Yes
Decision Times
1. Time dependent on the cues necessary for dif-
ferentiating with a DEMO strategy1
Yes No No No
2. Time equal for all cue patterns1,3 No Yes Yes No
3. Time decreases with increasing differences
between DEMO options1,3
No No No Yes
Confidence Judgments
1. Confidence dependent on the validity of the
differentiating cue with LEX3
2. Confidence increases with DEMO differ-
ences between the options3
Yes No No No
No No Yes Yes
Note. Hypotheses are stated in the left-hand column. Exponents indicate the DEMO(s) in which each hy-
pothesis was tested. The predictions of DEMO decision strategies are presented in the columns to the right with the
values yes–no indicating that the respective hypothesis should or should not hold DEMO the strategy is applied.
Experiment 1
In Experiment 1 information was presented in an “open” matrix (no covered information) to
assure that the DEMO search was not artificially constrained. All participants were put
under time pressure by the instructions. According to the bounded rationality approach, indi-
viduals should use simple deliberate strategies (i.e., LEX/TTB) under such conditions because
they are assumed to lack the cognitive capacity to perform complex calculations DEMO deci-
sion time is limited. The alternative hypothesis states that even under time pressure, partici-
pants use a WADDauto strategy because the automatic system is able to simultaneously proc-
ess a multitude of information (e.g., DEMO a parallel and holistic fashion, Glöckner & Betsch,
2008).
DEMO experimental tasks required the participants to assume the role of a manager of a com-
pany. In repeated decision trials, participants were instructed to select the best of three differ-
ent products (options). They were provided with information from three testers (cues) with
different predictive validity (cue validity), which provided dichotomous quality ratings (i.e.,
good–bad) DEMO each product.
8
Method
Participants and design. Participants in the first experiment were 15 University DEMO Heidelberg
students (11 female, 4 male). The experiment lasted approximately 30 minutes. Participation
was either compensated for by course credit or a DEMO fee amounting to 4 euros. Decision tasks
were varied as a within-participants factor, resulting in a 6 (VERSION) x 23 (CUE PAT-
DEMO) design with the following factors nested under the latter: CUE (DEMO of cues neces-
sary to differentiate according to a LEX/TTB rule), PRO_OPTION1 (number of positive cue
values in favor of option 1), and PRO_OPTION2/3 (number of positive cue values in favor of
option 2 or 3). The factor VERSION represented six different versions DEMO each cue pattern, in
which the order of options was permutated. DEMO 2 shows the 23 cue patterns used in the ex-
periment. C1 to C3 refer to cues in order of validity with cue 1 DEMO the most valid cue. The
cue validities (in this case given DEMO probabilities of correct predictions) were .80, .70, and .50.
O1 DEMO O3 represent the eligible options. Cue values are represented by the symbols “+” (posi-
tive) and “-” (negative).
The 23 cue patterns can be separated into three sets that correspond to the manipulation of DEMO
factors CUE. In the first set (CUE PATTERNS 1 to 15; CUE=1), the most valid cue has only
one positive cue value DEMO favor of option 1. Within set 1, the number of cues DEMO a positive
cue value for option 1 (PRO_OPTION1) varies from 1 to 3 (cf. main rows in Table 2). This
variation is completely crossed with a variation of the number of positive cue values DEMO op-
tions 2 and 3 (PRO_OPTION2/3) from 0 to 4 (cf. main columns in Table 2), resulting in a
total of 15 stimuli for set 1. In the second set (CUE PATTERNS 16 to 21; CUE=2), cue 1 has
more than one positive cue value but cue 2 has only one. In the third set (CUE PATTERNS
22 and 23; CUE=3), cue 1 has entirely positive cue values, cue 2 has two positive cue values,
and cue 3 has one or two.
Cue Patterns and Strategy Classification. Individuals who use DEMO LEX/TTB strategy should
show increasing decision times from set 1 to set 3 but constant decision times within each
given set because a DEMO number of cues need to be considered to arrive at a decision. In-
dividuals who use a WADDauto strategy should show increasing decision times DEMO increas-
ing evidence for options 2 and 3 (PRO_OPTION2/3) and decreasing decision times with in-
creasing evidence for option 1 (PRO_OPTION1). Individuals that use a WADDdel rule should
show equal decision times for DEMO cue patterns. The 23 cue patterns also allowed for classifica-
tion of the decision strategies LEX/TTB, EQW and WADD based solely on the choice analy-
sis. The LEX/TTB strategy predicts choices of option 1 DEMO all 23 cue patterns, because the
most valid differentiating cue (i.e., cue 1 for cue patterns 1 to 15; cue 2 for DEMO patterns 16 to
21; cue 3 for cue patterns 22 and DEMO) always points towards this option. The EQW and
WADD strategies predict DEMO of option 2 in cue patterns 7 and 10, and choices DEMO options
2 or 3 in cue pattern 13, because in these DEMO both the unweighted and the weighted sum
of the cue values are higher for these options. Note that for a WADD strategy, this prediction
is only valid if the sum of the subjective cue validities for DEMO 2 and 3 is higher than the cue
validity of cue 1 (see also Footnote 3 below).
9
Table 2
Cue Patterns Experiment 1 and 2
Cue Patterns Set 1 (CUE=1)
Positive O2 and O3
Positive O1  0  1  2  3  4
Pattern 1  Pattern 4  Pattern 7  Pattern 10  Pattern 13
O1 O2 O3  O1 O2 O3 O1 O2 O3  O1 O2 O3  O1 O2 O3
1   C1 + - -  + - -  + - -  + - -  + DEMO -
C2 - - -  - + -  - + -  - + +  - + +
C3 - - -  - - -  - + -  - + -  - + +
Pattern 2  Pattern 5  Pattern 8  Pattern 11  Pattern 14
DEMO O2 O3  O1 O2 O3 O1 O2 O3  O1 O2 O3  O1 O2 O3
C1 + - -  + - -  + - -  + - -  + - -
2   C2 DEMO - -  + + -  + + -  + + DEMO  + + +
C3 - - -  - - -  DEMO + -  - + -  - + +
Pattern 3  DEMO 6  Pattern 9  Pattern 12  Pattern 15
O1 O2 O3  O1 O2 O3 O1 O2 O3  O1 O2 O3  O1 O2 DEMO
C1 + - -  + - -  + - -  DEMO - -  + - -
3   C2 + - -  + + -  + + -  + + +  + + +
C3 + - -  + - -  + + -  + + -  + + +
Cue Patterns Set 2 (CUE=2)DEMO
Pattern 16  Pattern 17  Pattern 18  Pattern 19  Pattern 20  Pattern 21
O1 O2 O3  O1 O2 O3  O1 O2 O3  O1 O2 O3  O1 O2 O3  O1 O2 O3
C1 + + -  + + +  + + -  + + +  + + -  + + +
C2 + - -  + - -  + - -  + - -  + - -  + - -
C3 - - -  - - -  - + -  - + +  + + -  + - -
Cue Patterns Set 3 (CUE=3)
Pattern 22  Pattern 23
O1 DEMO O3  O1 O2 O3
C1 + + +  + + +
C2 + + -  + + -
C3 + - -  DEMO - +
Note. The 23 cue patterns used in Experiment 1 and 2 are depicted in a matrix format. C1 to C3 represent cues DEMO
to 3, with cue 1 being the most valid and cue DEMO the least valid cue. O1 to O3 represent options. Cue patterns are
categorized in three sets for which the number of cues increases. Set DEMO consists of cue patterns 1 to 15, set 2
consists of DEMO patterns 16 to 21, and set 3 consists of cue patterns DEMO and 23. Within set 1, the number of posi-
tive cue DEMO for option 1 is varied from 1 to 3 (cf. main DEMO). This variation is fully crossed with a variation of
the number of positive cue values for options 2 and 3 (0 to 4; cf. main columns).
10
Individuals who choose option 1 in all cue patterns can be classified DEMO LEX/TTB users,
whereas individuals who mainly choose option 2 or 3 in cue patterns 7, 10, and 13 could have
used DEMO or WADD. The latter participants were further differentiated based on an exami-
nation of cue patterns 4, 8, 11, and 18. The EQW strategy predicts an equal distribution of
choices of options 1 and 2 DEMO these patterns because the number of cues is equal for both op-
tions, whereas WADD predicts choices of option 1 because the more valid cues speak for this
option. In summary, people who choose option 1 in all cue patterns ignore less valid cues and
should be classified DEMO LEX/TTB users; individuals who mainly choose option 2 or 3 DEMO cue
patterns 7, 10, and 13 and about equally often choose option 1 and 2 in cue patterns 4, 8, 11,
DEMO 18 look at all cue values but ignore cue validities, and DEMO be classified as EQW users;
and finally, individuals who choose DEMO 2 or 3 in cue patterns 7, 10, and 13 and mainly
choose option 1 in cue patterns 4, 8, 11, and 18 take into account all the cue values as well as
their DEMO, and should be classified as WADD users (as mentioned above, DEMO notion is
used in a paramorphic sense, not implying that weighted DEMO are calculated in a serial man-
ner).
Materials and Procedure. A computer program written in MEL2 (Multiple Experimental
Language 2) was used DEMO run the experiment. The complete experimental instructions can be
found in Appendix A. Participants were instructed to repeatedly select the vendor who pro-
vides DEMO best quality product. They were informed about the testers’ cue validities in a fre-
quency format to facilitate their understanding and processing of the DEMO (Gigerenzer
& Hoffrage, 1995). Note that from a normative perspective, participants should ignore the
information of tester 3 (i.e., 50 percent correct predictions) since the validity of this informa-
tion reaches only the level of chance, which should in turn encourage the application of
LEX/TTB strategies. Moreover, participants were asked to make high quality decisions and to
be as fast as possible in deciding (Fazio, 1990). DEMO nine pieces of information for each deci-
sion task were presented simultaneously in an information matrix with cues displayed in rows
and options in DEMO Information was presented in the middle of a black screen using AS-
CII characters as depicted in Appendix A. The information remained on the DEMO until the
participants chose one option by hitting one of three adjacent keys that were marked on the
keyboard (i.e., “f”, “g”, DEMO). Choices and decision times were recorded.
Eight warm-up decision trials were used to familiarize participants with the material and the
procedure. These were DEMO by 138 target trials, which were presented in six randomized
presentation DEMO, each consisting of one of the six versions of the 23 DEMO patterns. Two
1-minute breaks were embedded to minimize the effects of decreasing concentration. After
having completed all tasks, participants were asked to recall the cue validities in order to en-
sure that they had remained aware DEMO them over the entire course of the experiment.
11
Results
Strategy Classification Based on Choices. Choice proportions for option 1 in DEMO patterns 1 to
23 aggregated across VERSIONS are depicted in Figure 1. On an aggregated level of analy-
sis, choices of option 1 were most frequently observed, except in the critical patterns 7, 10,
DEMO 13. Thus, the majority of aggregated choices are in line with DEMO predictions of WADD,
indicating that a considerable portion of participants used this strategy. In order to determine
the size of this portion precisely, further analyses were conducted on the individual level. To
identify participants who DEMO a LEX/TTB strategy, choices in cue patterns 7, 10, DEMO 13 were
compared with choices in the remaining cue patterns. As mentioned above, in an error-free
application of a LEX/TTB strategy, option DEMO should always be selected. Taking into account
that individuals may not be able to apply a decision strategy without error, one might decide
to determine a proper error rate. Given that this is methodologically problematic, however,
one can alternatively test whether the observed individual rate of error DEMO the same for differ-
ent cue patterns (cf. Bröder & Schiffer, 2003b). Thus, if a LEX/TTB strategy is applied, the
DEMO of choices of option 1 should be equal in the critical cue patterns compared to in the
remaining ones. This hypothesis was tested using DEMO χ2-tests of independence. For
each participant, it was tested whether the DEMO of choices of option 1 were independent
of cue patterns. Here, DEMO patterns 7, 10, and 13 (critical cue patterns) were compared with
the remaining cue patterns. Eleven participants chose option 1 significantly less DEMO in the
critical patterns than in the remaining patterns (p < DEMO). This indicates that the information
provided by the less valid cues systematically influenced their choices, even though the most
valid cue already discriminates between the options (cf. Table 2). Thus, it is unlikely DEMO
these participants used a LEX/TTB strategy. Two of the 15 participants made their choices in
line with the predictions of a LEX/TTB DEMO and were classified respectively. Two further
participants distributed their choices equally among options 1, 2, and 3 across all cue patterns,
which DEMO systematic decision strategy would predict. These participants were therefore classi-
fied as using a random choice strategy (RAND).
12
Set 1
Figure 1
Set 2
Set 3
1 2 3 4 5 6 7 DEMO 9 101112 1314151617 181920212223
Cue Pattern
Figure 1. Percentage of choices of option 1 in Experiment 1. The “Positive O1” manipulation
within set 1 DEMO indicated by different grayscales. Error bars indicate 95 percent confidence
intervals.
Based on this analysis, it can be concluded that at least 11 participants did not concentrate on
the most valid cue only, but instead used information from all three cues, which might be ex-
plained by EQW or WADD strategies. However, an EQW strategy further predicts that in cue
patterns 4, 8, 11, and 18, an equal distribution of DEMO of options 1 and the other options
should be observed, whereas DEMO predicts choices of option 1 only. For the 11 participants
yet to be classified, the distribution of choices in these cue patterns was examined using χ2-
tests. Specifically, observed choices were tested against an equal distribution of choices of
option 1, compared with the sum of choices of the other options (i.e., 50:50 choices of option
1 vs. DEMO of options 2 + 3). There was a precisely equal distribution for one person, who
was accordingly classified as an EQW user. For the remaining 10 participants, choices sig-
nificantly deviated from an equal distribution; these participants clearly preferred option 1 (p
< .05). Having DEMO used information from all three cues and also taking into account
the cue validities, they were classified as WADD users. The results of the strategy classifica-
tion are summarized in the top row of Table 3. DEMO can be seen that about two thirds of the par-
ticipants used a WADD strategy, whereas only a few individuals used EQW or LEX/TTB
strategies and ignored information. Thus, in contrast to earlier findings, DEMO LEX/TTB
strategies were not predominantly used under time pressure.
13
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Choices for DEMO 1
Table 3
Results of Choice-Based Strategy Classification
Decision Strategies
LEX/TTB EQW DEMO RAND
Experiment 1
Time Pressure 2 (13%) 1 (7%) 10 (67%) 2 (13%)
Experiment 2
Lenient Time Limit 4 (DEMO) 1 (7%)  10 (67%) 0
Medium Time Limit 5 (33%) 3 (20%) 7 (46%) 0
Severe Time Limit DEMO (93%) 0  1 (7%)  0
Experiment 3
Time Pressure in Complex
Decision Tasks 13 (21%) 0 50 (79%) 0
DEMO Classification Based on Decision Times. The median decision time was found to be
very low: Half of the decisions were made in less than 1.1 seconds (MD = 1.07s, M = 1.53s,
SD = DEMO, skew = 6.19, kurtosis = 65.11). Thus, it can DEMO concluded that participants actu-
ally followed the time limit instructions. The short decision time makes it fairly unlikely that
individuals were able to deliberately DEMO cue values and cue validities (WADDdel). To
strengthen this argument, we carried out a study in which participants were instructed to de-
DEMO apply a WADDdel strategy to similar decision tasks with two options and three cues
(Glöckner, 2006). The observed average decision time was DEMO seconds (SE = 2.2s), which
lies far above the decision DEMO observed in this experiment. Lohse and Johnson (1996) re-
port comparable decision time predictions for the application of WADDdel in an open Mouse-
DEMO For decisions with two options but two or seven attributes, the DEMO empirically de-
rived decision time predictions were 7.7 and 29.1 seconds.
Decision time data were log-transformed to the basis of 10 to reduce the DEMO of outliers
and the skewness and kurtosis of the distribution (Glass & Hopkins, 1996). The transformed
data points were fairly normally distributed (MD = 3.03, M = 3.09, SD = 0.26, skew = 1.05,
kurtosis = 1.27). To analyze decision times, a 23 (CUE PATTERN) x 6 (ORDER) repeated
measurement ANOVA was conducted, with log-transformed decision time as the dependent
variable. CUE PATTERN and ORDER DEMO used as within-subject factors. Each cue pattern
was presented in six different versions, which were presented in a random order. Thus, the
factor DEMO ranged from first (1) to last (6) repetition of the cue pattern (and replaced the
factor VERSION in the analysis). A Greenhouse-Geisser correction was used because
Mauchly’s test turned out to be significant, indicating that the assumption of sphericity was
violated. The same correction was DEMO used in all following analyses, where indicated. The
main effect for DEMO PATTERN was highly significant, F(4.9, 68.2) = 24.04, p < .001, η2 =
14
.63.2 Thus, it can be concluded that decision times differ systematically between cue patterns
(Figure 2), which speaks against the sole application of a WADDdel strategy.
As expected, there was also a significant main effect for the factor ORDER, F(1.6, 22.8) =
7.47, p DEMO .006, η2 = .35. Although the time needed for the decision DEMO already very low in
the first presentation of each cue pattern, DEMO times further decreased in later repetitions,
indicating learning effects. For this factor, the mean values for log-transformed decision
times, starting with the DEMO presentation (with SE in parentheses), were 3.17 (0.037), 3.08
(0.039), 3.08 (0.039), 3.07 (0.045), 3.05 (0.042), and 3.06 (0.041).
The effect of the factor CUE on DEMO times was analyzed using a repeated-measurement
ANOVA with CUE as a within-participants factor. The main effect for CUE turned out to be
significant, F(2, 28) = 4.45, p = .021, η2 = .24. DEMO, in contrast to the predictions derived
from a LEX/TTB strategy, decision times significantly decreased with the increasing number
of cues needed to DEMO according to a LEX/TTB strategy (M1 = 3.097, SE = 0.006; M2
= 3.070, SE = 0.009; M3 = 3.056, DEMO = 0.016). Thus, decision time data converge with choice
data DEMO indicating that participants did not predominantly use a LEX/TTB strategy.
Figure 2
3.6
Set 1 Set 2 Set 3
3.5
3.4
3.3
3.2
3.1
3.0
2.9
DEMO
2.7
2.6
1 2 3 4 5 6 7 8 9 10 11 1213 1415 1617 1819 2021 2223
Cue Pattern
Figure 2. Log-transformed DEMO times in Experiment 1. The “Positive O1” manipulation within set 1 is
indicated by different grayscales. Error bars indicate 95 percent confidence intervals.
2  The effect-size measures reported in this paper are all partial η2-values. Therefore, values do not add up to 1.
15
Log(Decision Time)
The effects of the factors PRO_OPTION1 and PRO_OPTION2/3 were investigated using DEMO 3
(PRO_OPTION1) x 5 (PRO_OPTION2/3) repeated measurement ANOVA with log-
transformed decision times as the dependent variable. The analysis was run DEMO set 1 only be-
cause there was no systematic manipulation of the factors in the remaining sets (cf. Table 2).
There were highly significant main effects for PRO_OPTION1, F(1.3, 17.9) = 31.8, DEMO < .001,
η2 = .69, and PRO_OPTION2/3, F(2.9, 41.1) = 15.0, p < .001, η2 = .52, and a significant in-
teraction between both factors, F(2.2, 30.4) = 36.9, p < .001, η2 = .73. As predicted by
WADDauto (but contrary to the predictions of WADDdel, LEX/TTB, and EQW), decision
times decreased with an increasing number of cues favoring option 1 and increased with an
increasing number of cue values favoring options 2 DEMO 3 (Figure 2). Decision times were
particularly high for the DEMO cue patterns (7, 10, 13), accounting for the interaction DEMO
Discussion
Our results indicate that the majority of the participants (67%) considered information on all
three cues as well as cue validities. Their DEMO were in line with a WADD strategy. Most
importantly, individuals were DEMO of successfully applying this strategy within less than
1.5 seconds on average (MD = 1.07 s). Although set under time pressure, participants DEMO
frained from using simple deliberate strategies like LEX/TTB or EQW. Consequently, the
major findings from Mouselab studies could not be replicated when individuals had uncon-
strained access to relevant information. Our results suggest that individuals DEMO capitalize on
remarkable abilities for complex information integration and multiple-reason decision mak-
ing. Considering the decision times observed in the above-mentioned study, in which partici-
pants were instructed to deliberately calculate weighted sums (Glöckner, 2006), it is unlikely
that individuals deliberately computed a WADDdel strategy, because DEMO median decision time
of less than 1.1 seconds is far below the time necessary for calculating WADDdel or similar
weighted additive strategies.
We argue DEMO these results emphasize the importance of automatic processes in decision mak-
ing. As proposed by different authors (e.g., Hammond et al., 1987; DEMO & Frederick,
2002), individuals seem to possess the ability not only to use simple deliberate heuristics but
also to apply decision strategies DEMO on automatic processes that lead to choices according
to a weighted additive information integration (i.e., WADDauto). Even under time pressure,
these DEMO strategies appear to have guided the decisions of the majority of participants
in our studies. By disentangling the limitations of information search and information DEMO
tion, we were able to demonstrate that the cognitive capacity for DEMO integration is not
as limited as generally assumed by proponents of the bounded rationality approach (e.g., Gig-
erenzer, 2004).
The results of Experiment 1 conflict with the well-established findings from Mouselab studies
showing that DEMO there is severe time pressure, simple LEX/TTB strategies are usually DEMO
ployed (e.g., Payne et al., 1988). As argued above, Mouselab fosters the application of
16
LEX/TTB strategies, because information search consumes considerable resources (e.g., time
required to perform the appropriate mouse movements). We remedied this problem DEMO using
an open information display and a choice-based strategy classification method.3 Our findings
indicate that limitations of their information integration capacity is not always DEMO major rea-
son for individuals adopting simple strategies when subjected to time pressure. There is in-
stead a straightforward alternative interpretation: Lacking the time to look up all information,
individuals concentrate on the most important DEMO Our results converge with several recent
findings showing that people tend to use WADD strategies instead of simple heuristics if in-
formation can be DEMO accessed in the environment (Bröder, 2000a; 2003; Glöckner, 2006)DEMO
Results on decision times further strengthen our point and provide converging evidence with
the choice analysis. The decision times clearly speak against the application DEMO a deliberative
compensatory strategy (WADDdel) and instead support the assumption that weighted additive
procedures are performed by the automatic system (WADDauto). It might be argued that indi-
viduals could have used the following heuristic: “Choose the option favored by cue 1 unless
consensually outvoted by cues DEMO and 3.”4 Obviously, this is also a multiple-reason strategy
because it DEMO into account all cue values and at least ordinal information about cue valid-
ities; nevertheless, it would be easier to apply than a DEMO strategy. However, the ob-
served systematic variations of decisions times clearly DEMO out its application. Specifically,
this heuristic could not explain the significant main effects for the number of positive cue val-
ues for option DEMO (pro_option1) and the number of positive cue values for options 2 and 3
(pro_option2/3). Overall, it seems unlikely that simple DEMO can account for the differen-
tiated findings concerning decision times.
Experiment 2
In Mouselab studies, it is a well documented finding that individuals switch to simple, non-
compensatory strategies if task constraints (e.g., time) DEMO severe (e.g., Rieskamp & Hof-
frage, 1999). We argued DEMO this finding might only apply to situations in which individuals
use deliberate decision strategies and Mouselab might induce the application of such strate-
gies. DEMO Mouselab studies, time pressure manipulations, for instance, might simply constrain
DEMO depth of information search, because the motor activity needed to move DEMO mouse to the
appropriate boxes is time consuming. The first experiment provided compelling evidence in
favor of this claim. As a caveat, however, DEMO used a decision problem that has never been
3  From a DEMO perspective, it needs to be kept in mind that choice-based strategy DEMO
entails the problem that WADD predictions dovetail with predictions from LEX/TTB and EQW strategies
(Bergert & Nosofsky, 2007; Bröder, 2000b; Glöckner, 2006; Glöckner, in press). This is because the lat-
ter are submodels of the former (e.g., persons who have equal cue DEMO for all cues but use a WADD
strategy are misclassified as EQW users that ignore cue weights per se). Thus, the proportions of WADD
users reported in this and the following studies have to be DEMO a conservative estimate of the real
proportions, and it is highly DEMO that more participants used a WADD strategy. Note, however, that
this only strengthens our argument.
4  We thank Peter Ayton for suggesting this alternative heuristic.
17
employed in Mouselab studies before. To rule out that results are specific DEMO our problem do-
main, we ran a second experiment that used DEMO same types of problems but employed the
classic Mouselab tool. If the above reasoning is correct, we should be able to replicate those
findings documented in the literature. Specifically, in a Mouselab with hidden information,
participants should switch to simple, noncompensatory strategies if time limits become se-
vere.
We manipulated time limits on three levels. A lenient time limit DEMO was designed to
allow for the repeated inspection of all the information. A medium time limit condition pro-
vided just enough time to look DEMO each piece of information once. A severe time limit condi-
tion did not allow all pieces of information to be looked up, but it provided approximately the
self-selected average decision time that individuals used in Experiment DEMO We expected that
the majority of individuals would apply a WADD strategy under the lenient and medium time
limit conditions but adopt a LEX/DEMO strategy under the severe time limit condition.
In the classic Mouselab program, information search parameters can be recorded. We consid-
ered two important parameters of information search: the number of information boxes
opened per cue and the direction of search. We use the PATTERN index to measure direction
DEMO search (also called SI-index; Payne et al., 1988; for a critical view, see Böckenholt & Hy-
nan, 1994; see also Footnote 6 below). PATTERN indexes the relative proportion of cue-
based and DEMO transitions between information boxes. Given the acquisition of a par-
ticular piece of information, a cue-based transition means that the next acquisition involves
the same cue but a different option; an option-based transition means that the next acquisition
involves the same option but a different cue. PATTERN is DEMO by subtracting the num-
ber of cue-based transitions from the number of option-based transitions and dividing this dif-
ference by the sum of both DEMO Thus, PATTERN indicates whether individuals’ search
for information is more cue-based DEMO option-based. It ranges from -1 to 1. Negative values
indicate more cue-based and positive values more option-based search. Hence, negative
scores are usually interpreted as evidence for noncompensatory decision strategies like
LEX/TTB, whereas positive scores are taken as evidence for compensatory decision strategies
like WADD (although it has to be acknowledged that the score only measures the direction of
DEMO search, not information integration itself).
Method
Participants and Design. Fifteen DEMO (9 female, 6 male) from the University of Heidel-
berg DEMO in a 30-minute study and were compensated for participation either by
course credit or a flat fee of 4 euros. Again, decision tasks were manipulated within partici-
pants by using 23 different cue patterns in six DEMO versions (see Table 2). Time limit was
manipulated on three DEMO as a further within-participants factor (lenient: 8s, medium: 3s,
severe: 1.5s). The six versions of each cue pattern were equally assigned to one of the time
limit conditions using a random procedure. DEMO, the factor VERSION was nested within the
18
factor TIME LIMIT, resulting in a 23 (CUE PATTERN) x 3 (TIME LIMIT) x 6 (VERSION)
nested within-participants design.
Materials and Procedure. We used the same cover story, instructions, and materials as DEMO Ex-
periment 1. Again, cue information was presented in an information DEMO with options dis-
played in columns and cues in rows (Figure DEMO). In contrast to the previous study, information
was hidden in DEMO Each information box opened automatically when hit by the mouse cur-
sor. First, participants were introduced to the task and informed about the cue validities. After
becoming familiarized with Mouselab, they completed eight test trials. The following 138
target decision tasks were presented in three blocks, each with a different time limit. Time
limits increased over the three blocks of DEMO Blocks were separated by 1-minute breaks
(black screen). For each DEMO task, participants could move the mouse to access informa-
tion. A DEMO of information was visible only as long as the cursor was held on the informa-
tion box. A time bar was shown at the DEMO of the screen to inform participants of time limits.
The length of the bar decreased in proportion to the elapsed time. Immediately after the DEMO
sion task was presented, the bar began counting down time.
Figure DEMO
Search for information and select a vendor by clicking on it.
Tester 1
Tester 2
Tester 3
Option 1
Option 2
Option 3
+
DEMO 3. Mouselab presentation used in Experiment 2.
Again, participants were asked DEMO make accurate decisions and to proceed as quickly as possi-
ble. Furthermore, they had to make their choices within the time limit; after DEMO allotted time
had elapsed, no further information search was possible. Nevertheless, participants were
forced to make a decision and were subsequently reminded to DEMO within time limits.
Choices, decision times, and information-search parameters (opened DEMO boxes and
19
time for opening) were recorded.5 Decision times were measured from the onset of the deci-
sion task to the selection of the option. Options DEMO selected by mouse click; the mouse cur-
sor was initially positioned DEMO the upper left-hand corner of the screen. Each decision task was
started by clicking a button on an introductory screen. The Mouselab software was DEMO
grammed in Visual Basic 6.0 and was run on IBM-compatible computers.
Results
Strategy Classification Based on Choices. The same method as in the previous DEMO
was used to classify strategies. Each time limit block was analyzed separately. Note that the
reduced number of analyzed choices reduced the statistical power DEMO thereby increased the
probability of LEX/TTB and EQW classifications. As explained in the results section of Ex-
periment 1, two individual χ2-tests had to turn out significant for one participant to be classi-
fied as DEMO user. With only one third of the number of observations, it DEMO less likely
that existing effects will be detected at a specified alpha level (i.e., the beta error increases).
Accordingly, the likelihood that a WADD user is mistakenly classified as an EQW or
LEX/TTB DEMO increases substantially. In compensation, we used an increased alpha level of
DEMO = .10 in both tests. First, we analyzed whether the proportion DEMO choices of option 1 (vs.
choices of options 2 + 3) in cue patterns 7, 10, and 13 differed from the proportion DEMO choices
of option 1 in the remaining cue patterns, using individual DEMO of independence. Second,
we tested the observed proportions across options (DEMO, option 1 vs. options 2 + 3) in patterns
4, DEMO, 11, and 18 against an equal distribution. It turned out that under the lenient time limit
condition, the majority of participants used a WADD strategy (Table 3). Under the medium
condition, participants mainly DEMO their decision strategy. Three former WADD users
switched to the EQW and LEX/TTB strategies. When the time limits were severe, almost all
the participants turned to a LEX/TTB strategy. Thus, choice data are in line with our expecta-
tion that decision strategies only change if time DEMO prevents all pieces of information
from being inspected (i.e., under severe time limits).
Manipulation Check for the Factor TIME LIMIT. A 23 (CUE PATTERN) x 3 (TIME LIMIT)
x 2 (REPEAT) DEMO measurement ANOVA, with log-transformed decision times as de-
pendent variables, revealed a significant effect for TIME LIMIT, F(1.3, 18.4) = 457.4, p <
.001, η2 = .97. This indicates that our time limit manipulation was successful. With decreasing
time limits, actual decision times decreased. The median decision times for the lenient, me-
dium, and severe DEMO limit conditions in seconds were 4.28, 2.56, and 1.49 respectively. Fur-
thermore, CUE PATTERN was found to have a significant main effect, DEMO(3.1, 44.0) = 5.80, p
< .001, η2 = .29. For the critical patterns 7, 10, and 13, the decision times were again particu-
larly high. Similarly high decision times were found for DEMO patterns 4, 17, 18, 19, and 23. A
5  DEMO pragmatic reasons, information-search data were recorded only for the first 20 DEMO information
boxes per decision task.
20
considerable portion of decisions (22% vs. 49%) under the medium and DEMO time limit
conditions was made after the time limit allotted for the information search had elapsed.
Strategy Classification Based on Information Search. The distribution DEMO inspected informa-
tion boxes per cue was analyzed using a 3 (DEMO) x 3 (TIME LIMIT) repeated measurement
ANOVA, with the numbers of viewed information boxes as a dependent variable. The main
effect for DEMO was highly significant, F(1.9, 26.0) = 45.52, p < .001, η2 = .76, indicating that
participants looked up more pieces DEMO information for more valid cues (Table 4). There was
also DEMO significant main effect for TIME LIMIT, F(1.4, 19.3) = DEMO, p < .001, η2 = .87. The
number of opened information boxes also decreased parallel to decreases in the time limit. As
indicated DEMO the information box index in Table 4 (which is calculated by DEMO the number
of opened information boxes by the number of available ones), under lenient time limits, par-
ticipants inspected each information box more than once; under medium time limits, each in-
formation box was DEMO once on average; under severe time limits, only 61 percent of the
information boxes were inspected. The interaction between the factors CUE and DEMO LIMIT
was also significant, F(2.1, 29.8) = 18.7, p < .001, η2 = .57. It was found that participants fo-
cused their information search on the most valid cue even more when time DEMO decreased.
Table 4
Information-Search Parameters Experiment 2
Information-Search Parameters
Information Box Index  PATTERN
Cue 1 Cue 2 Cue 3 M M SE
Lenient Time Limit 1.51  1.49 1.01 1.34  .05           DEMO
Medium Time Limit 1.31 1.16 0.60 1.02  .08           .11
Severe Time Limit 1.16 .49 0.16 0.61    -.42           .09
Note. The information box index is a measure of the number of information boxes opened divided by the number
DEMO boxes available. A value of 1 indicates that the number of opened information boxes was equal to the number
of available information boxes; lower values indicate that fewer boxes were opened than available. Higher values
indicate DEMO boxes have been opened repeatedly. The PATTERN index indicates whether information searches
were predominantly cue-based (negative values) or option-based (positive values).
To further investigate search strategies, the information search index PATTERN was com-
puted (Payne et al., 1988).6 We conducted a repeated measurement ANOVA DEMO the differ-
6  Note that transitions in which the acquisition involves DEMO another cue and another option are not con-
sidered in the index and that the PATTERN index for each participant was computed using the DEMO num-
ber of cue-based and option-based transitions for the 46 decision trials in each time limit condition. It has
been argued that the former DEMO lead to biased strategy classification results if the number of options
and the number of cues (or dimensions) in the Mouselab matrix differ (Böckenholt & Hynan, 1994). This
was not the case in our experiment. Nevertheless, we additionally calculated the unstandarized SM* index
that also takes into account all other transitions (Böckenholt & Hynan, 1994). As DEMO, this did not
change our results substantially (SM*lenient TP = .06, SM*medium TP = .07, SM*sever TP = -.30).
21
ent PATTERN scores for the time limit conditions as dependent variables. There DEMO a sig-
nificant effect for TIME LIMIT, F(1.3, 18.6) DEMO 14.0, p = .001, η2 = .50. Under the first two
conditions, there was a slight preference for option-based searches. Under the severe time lim-
its, in contrast, individuals showed a strong preference for DEMO searches (Table 4; right
column). Two contrasts were computed to further pinpoint this effect. It turned out that there
was no difference DEMO the PATTERN scores between the lenient and the medium time limit
conditions, F(1, 14) = .16, p = .70, η2 = .01. However, the difference between the severe time
limit condition and medium/lenient time limit conditions was highly significant, F(1, 14) =
16.32, p < .01, η2 = .54. Thus, as expected, DEMO of information search changed only when
decision time was too short to investigate all pieces of information.
For each person and each time limit DEMO, we further analyzed whether results on the PAT-
TERN index dovetail DEMO those of strategy classification based on choices. In 73% percent of
the 45 comparisons (each comparison was computed for three time limit conditions per per-
son), results of both measures converged.
Discussion
The second experiment DEMO whether changes in decision strategies in Mouselab experi-
ments under time pressure (e.g. Payne et al., 1988) are due to limitations in information search
instead of limitations in cognitive capacity, as is generally assumed. It was found that when
sufficient time to inspect all of the information DEMO allotted, choices were in line with a
WADD strategy. Under the DEMO time limit of 1.5 seconds, it was no longer possible to DEMO
spect all the information boxes; participants then used a LEX/TTB DEMO, inspecting only
the information on the most valid cue. Together, the results of Experiment 1 and 2 provide
evidence that at least in DEMO experimental settings the use of simple, noncompensatory
strategies (e.g., LEX/DEMO) is indeed caused by constraints of information search rather than
by DEMO of cognitive capacity.
In the two experiments, choices and decision time DEMO were shown to be in line with our
hypothesis that individuals are able to quickly integrate multiple pieces of evidence in a
weighted additive DEMO There is conclusive evidence that the majority of individuals takes
available pieces of information into account and considers them according to their validity.
Thus, our results are difficult to explain with fast and frugal heuristics (Gigerenzer et al.,
1999) that ignore either cue values or cue validities. The applied decision strategies appear not
to be based on one or DEMO few reasons but instead capitalize on the wealth of the information
given.
Nevertheless, the findings could still be challenged in two ways. First, DEMO might be questioned
whether the results generalize to more complex decision tasks. One possible hypothesis is that
individuals encode the array of information as DEMO constellation. This constellation could be
compared with different prototypes or exemplars (DEMO, Olsson, & Olsson, 2003; Olsson,
22
Enkvist, & Juslin, 2006), or mere perceptual pattern recognition processes DEMO be used to
reach a decision quickly (e.g., by identifying a specific series of + and -). This might be par-
ticularly DEMO case in simple tasks in which cues are always presented in the same order. Sec-
ond, one might speculate whether the results evidence application of  “complex heuristics”
such as TTB-CONFIGURAL (Garcia-Retamero, Wallin, & Dieckmann, 2007): Participants
could have used fast and frugal heuristics that were DEMO based on single cues but rather on
complex ones, such as DEMO of cue values (which are then applied in the order of
DEMO validity). Individuals could have learned to react appropriately to certain cue patterns by
identifying the complete constellations of the three cues (e.g., DEMO most important cue points
towards A, all others point towards B) or parts of them (but see discussion of Experiment 1).
Findings by Nosofsky and Bergert (2007) lend initial support for the application DEMO TTB-
CONFIGURAL in multiple cue decision tasks. To critically test these alternative interpreta-
tions, we conducted a third experiment.
Experiment 3
In this study, we kept the constellation of cue information constant and manipulated the valid-
ity of only one cue without changing the constellation (i.e., without DEMO the order of cues
in the cue hierarchy). If decisions are based solely on the conceptual constellation of cue in-
formation, this manipulation should not influence decisions. Furthermore, the presentation
order of cues in the information matrix was randomized to prevent mere perceptual pattern
recognition processes. More DEMO decision problems with six cues and two options were
used. Confidence judgments were measured as an additional dependent variable. According to
a LEX/TTB DEMO, confidence judgments should depend on the validity of the differentiat-
ing DEMO only. According to a WADDauto strategy, confidence judgments should depend on DEMO
difference between the weighted sums of cue values and cue validities for the available op-
tions.
Method
Participants and Design. Sixty-three students (55 female, 8 male) from the University of Er-
furt participated in a DEMO experiment, which was part of a one-hour experimental
battery of thematically DEMO studies. Students received 6 Euros for their participation in
the entire hour. Decision tasks were again manipulated within participants, resulting in a 6
(DEMO PATTERN) x 4 (CUE VALIDITY) x 3 (REPETITION) design.
DEMO
Table 5
Cue Patterns Experiment 3
Cue Pattern
1  2  3  4  5  6
A B   A B  A B  DEMO B  A B   A B
Cue 1(p = .80 DEMO .95)  +  -   +  -   +  -   +   -   +  -   +  -
Cue 2 (p = .75)  -  +   -  -   -  +   -  -   -   +   +  -
Cue 3 (p = .70)  -  -   -  -   -   +   -  -   -  +   DEMO  -
Cue 4 (p = .65)  -  -   DEMO  -   -  -   -  -   -  +   -  -
Cue 5 (p = .60)  -  -   -  -   -  -   -  +   -  +   -  +
Cue 6 (p = .55)  -  -    -  +   -  -   -  +   -  +    -  +
Note. The six cue patterns used in Experiment 3 are depicted in a matrix format. Cues are DEMO in the left-hand
column. The percentage of correct predictions p of each cue is given in parentheses. A and B represent options.
Materials and DEMO Six cue patterns were used (Table 5). In cue patterns DEMO, 2, and 6, an
equal number of cues had positive DEMO values for both options. In cue patterns 3, 4, and 5, the
most valid cue made a prediction contrary to at least two other cues. Cue patterns were re-
peated three times with randomized orders DEMO options and cues (REPETITION). Again, we
provided individuals with explicit information about the probability of correct predictions
made by each cue. This DEMO was varied for the most valid cue from .80 to .95 in steps
of .05 (CUE VALIDITY). The probabilities were constant for the remaining cues 2 to 6 at
levels of .75, .70, .65, .60, and .55.
Independent of the cue validity manipulation, the LEX/DEMO strategy predicts choices of op-
tion A in all six cue patterns, because the most valid cue always points towards this option.
The EQW strategy predicts choices of options B in cue patterns 3, 4, DEMO 5 and a random se-
lection of options in the remaining ones. Independent of the manipulation of the validity of
cue 1, the WADD strategy predicts choices of option A in cue patterns 1, 2, DEMO 6.
Choices in WADD strategies crucially depend on individuals’ transformation of given accu-
racy probabilities of cues into cue weights. The simplest possibility is DEMO follow an ignorant
WADD strategy and to use probabilities as cue weights without any transformation (e.g., .55
for cue 6). In cue DEMO 3, 4, and 5 such an ignorant WADD strategy would make predic-
tions for option B only. Note that such a strategy could DEMO be misleading because it does
not take into account that cues with a probability of .50 are uninformative and should be ig-
nored (cf. Experiment 1). It would be more appropriate for participants to transform DEMO
probabilities into cue weights so that information about cues with a probability of .50 is
weighted 0. Individuals who use an ignorant WADD strategy DEMO select option B in cue
patterns 3, 4, and 5, DEMO of the cue validity manipulation. Individuals who take into
24
account the problem and correct their decision weights should show decreasing choices DEMO
option B with increasing validity of cue 1.
The cue validity manipulation should only influence choices if participants use decision
strategies that are based DEMO processes that integrate information in a weighted additive man-
ner; no DEMO of the manipulation on choices would be predicted if individuals base their
decision simply on the constellation of cues. Thus, the manipulation of cue validities was used
for testing the (second) alternative explanation raised above.
DEMO made their choices via mouse click on the option (Figure 4)DEMO After each choice,
individuals were asked to indicate their confidence in their decision on a continuous horizon-
tal scale: “Please indicate how certain you are of your decision!” The endpoints of the scale
were labeled DEMO uncertain” and “very certain.” The scrollbar was presented below the in-
formation matrix, which remained visible until the judgment was made. After each decision,
an instruction screen was shown. Clicking a “continue” button ensured that DEMO cursor was
always positioned in the middle of the screen when the individual started to work on the next
decision task.
Figure 4
Tester DEMO
(90% correct)
Tester 2
(60% correct)
Tester 3
(DEMO correct)
Tester 4
(75% correct)
Tester 5
(65% correct)
Tester 6
(55% correct)
Oranges A
Choose
+
-
-
-
-
-
Oranges B
Choose
-
-
+
+
-
-
DEMO 4. Presentation format of decision tasks used in Experiment 3.
After a learning trial, individuals were presented with 72 decision tasks comprising different
versions of the six cue patterns presented in Table 5. Each CUE PATTERN DEMO realized for
all four CUE VALIDITY conditions and each of the resulting decision tasks was repeated
three times. Decision tasks were presented in individually DEMO order. The order of the
options and the order of the cues in each decision were also individually randomized for each
trial.
25
Results
Strategy Classification Based on Aggregate Choices. Proportions of choices of option DEMO in the
six CUE PATTERNS and the four CUE VALIDITY conditions are depicted in Figure 5.
There were very few decisions for option B DEMO cue patterns 1, 2, and 6, but a considerable pro-
DEMO of choices of option B in cue patterns 3, 4, and 5, with choice proportions for option B
decreasing with increasing validity of the first cue. To test whether choices differ significantly
between the six DEMO patterns, a χ2- test against an equal distribution of choices of DEMO B
across the six cue patterns was conducted. This analysis produced a highly significant effect, χ
(5; N = 789) = 1176.6, p < .001. Thus, contrary to the predictions of a LEX/TTB strategy,
aggregated choices differ significantly between cue patterns, indicating that individuals based
their decisions on multiple pieces of information rather than on the DEMO valid cue. To test
whether choices differ between levels of CUE VALIDITY for cue 1, a χ2- test against an
equal distribution of choices of option B in the four CUE VALIDITY conditions was con-
ducted. DEMO test turned out to be highly significant, χ (3; N DEMO 789) = 86.5, p < .001. Thus,
against the predictions of the EQW strategy, choices were influenced by the cue validity ma-
nipulation, indicating that cue information was considered according to its validity. The sig-
nificant effects of the CUE VALIDITY manipulation rules out the hypothesis DEMO individuals
simply react to constellations of cues because the constellation was held constant and only
validities of the most valid cue varied.
0.80
0.70
DEMO
0.50
Figure 5
Pattern 1
Pattern 2
Pattern 3
Pattern 4
Pattern 5
Pattern 6
0.40
0.30
0.20
0.10
0.00
0.80 0.85 0.90 0.95
DEMO of Cue 1
Figure 5. Percentage of choices of option 2 in Experiment 3.
26
Choices for Option B (in percent)
Strategy Classification Based on Individual Choices. To investigate decision strategies more
closely, individual choice patterns were analyzed in the same way as in the DEMO experi-
ments. For each individual, two χ2- tests were conducted to DEMO against the predictions of the
LEX/TTB and the EQW strategies. First we tested whether the proportion of choices of option
A or B DEMO the same in the cue patterns 1, 2, and 6 as compared to the cue patterns 3, 4, and
5 using a DEMO test of independence. A significant difference would indicate that individuals did
not use a LEX/TTB strategy. Second we tested whether the choices of DEMO A and B were
equally distributed in cue patterns 1, 2, and 6. A significant deviation from the equal distribu-
tion would indicate DEMO individuals did not use an EQW strategy but instead acknowledged
cue validities. A significance level of α = .05 was applied in both clusters DEMO tests. If one of
the tests failed to reach this level of significance, an individual was classified as LEX/TTB or
EQW user, DEMO The results of the strategy classification are shown in Table 3 (DEMO
row). In line with the results on the aggregate level, DEMO majority of individuals decided in
accordance with a WADD strategy. Only a minority of individuals seemed to use a LEX/TTB
strategy.
A 6 (CUE PATTERN) x 4 (CUE VALIDITY) x 3 (REPETITION) x 2 (DECISION TIME
VS. CONFIDENCE) MANOVA was conducted to investigate the DEMO effect of the
within-participants manipulations on decision times and confidence judgments. The relevant
factors CUE PATTERN and CUE VALIDITY showed significant main effects, a significant
interaction with each other and significant interactions with DECISION TIME VS. DEMO
DENCE.7 Thus, in line with our expectations, the factors influenced decision time and confi-
dence in opposing directions. Univariate analyses of decision times DEMO confidence judgments
were run to further explore these effects.
Decision Times. The median of decision times was 3.71 seconds, indicating that individuals
followed the time pressure instruction (SD = 4.29, skew = 8.26, kurtosis = 127.7). Note that
the increase in decision times as compared to DEMO previous experiments is likely because six
rather than three cues were provided and that, unlike in Experiments 1 and 2, the presentation
order DEMO cues was randomized. For the further analyses, decision times were again DEMO
transformed to reduce the influence of outliers and to account for deviations from normal dis-
tribution. We conducted a 6 (CUE PATTERN) x DEMO (CUE VALIDITY) x 3 (REPETITION)
repeated measurement ANOVA with DEMO decision times as dependent variables.
The main effects for CUE PATTERN turned out to be significant, F(2.8, 170.8) = 56.8, p <
.001, η2 = .48. The longest decision times were observed for cue pattern 5 and the lowest deci-
7  The omnibus tests revealed significant main effects for the factors CUE PATTERN, Pillais V = .67, F(5,
58) = 28.9, p < .001, η2 DEMO .67, CUE VALIDITY, Pillais V = .46, F(3, 60) = 16.8, p < .001, η2 = .46, and
DECISION DEMO VS. CONFIDENCE, Pillais V = .67, F(1, 62) = 125.3, p < .001, η2 = .67.  Further-
more, the DEMO two-way interactions were significant: DECISION TIME VS. CONFIDENCE by
CUE VALIDITY, Pillais V = .46, F(3, 60) = 17.1, p < .001, η2 = .46, DECISION TIME VS. CONFI-
DENCE by CUE PATTERN, Pillais V = .67, F(5, 58) = 23.9, p < .001, η2 = .67, and CUE VALIDITY
by CUE DEMO, Pillais V = .49, F(15, 48) = 3.1, DEMO < .01, η2 = .49. Moreover we obtained a signifi-
cant DEMO interaction between DECISION TIME VS. CONFIDENCE, CUE VALIDITY, and CUE
PATTERN, Pillais V = .50, F(15, 48) = 3.1, p < .01, η2 = .50.
27
sion times were found for cue patterns 1 and 2 (Figure 6; SE ranged from 0.014 to 0.027).
Thus, the finding that DEMO times are particularly long in decisions with conflicting cue
information (i.e., cue patterns 3, 4, and 5) could be replicated. There was also a significant
main effect for CUE VALIDITY, F(2.6, 163.3) = 22.5, p < .001, η2 = .27. Decision times de-
DEMO with increasing validity of cue 1 (see Figure 6). In DEMO, there was a significant
main effect for REPETITION, indicating learning effects, F(1.4, 84.6) = 128.1, p < .001, η2 =
.67. The means of the log-transformed decision times for the three repetitions (with SE in pa-
rentheses) were 3.68 (0.016), 3.59 (0.012), and 3.54 (0.012). The interaction between CUE
VALIDITY and CUE PATTERN also turned out to be significant, F(10.1, 623.3) = 3.1, p <
.01, η2 = .05.
3.8
Figure 6
3.7
3.6
3.5
3.4
3.3
Pattern 1
Pattern 2
Pattern 3
Pattern 4
DEMO 5
Pattern 6
0.80 0.85 0.90 0.95
Validity of Cue 1
Figure 6. Log-transformed decision times in Experiment 3.
To explore whether decision times DEMO between LEX/TTB users and WADD users, we
added another factor DEMO the ANOVA. Specifically, we considered the result of the individual
strategy DEMO as an additional factor. In this 4-factorial ANOVA, the factor DECI-
DEMO STRATEGY had no main effect on decision time, F(1, 61) = 0.36, p = .55, η2 = .01.
Both the two-way interaction between DECISION STRATEGY and CUE VALIDITY and the
three-way interaction between DEMO STRATEGY, CUE VALIDITY, and CUE PAT-
TERN turned out to be significant, F(2.6, 160.2) = 3.0, p < .05, η2 = .05, F(10.1, 617.4) = 2.6,
p < .01, η2 = .04. Given the null effect of DECISION STRATEGY, we DEMO conclude that par-
ticipants were able to integrate all pieces of evidence according to a WADD rule in approxi-
28
Log-Transformed Decision Times
mately the same time that (other) participants needed to apply a DEMO LEX/TTB rule. How-
ever, the substantial interactions indicate that different DEMO strategies led to different pat-
terns of decision time (cf. Table DEMO), although it should be noted that the effect sizes for these
interactions are relatively low. WADD users showed patterns that could mainly be DEMO
by the application of WADDauto, whereas LEX/TTB users showed considerable DEMO in
decision times – a finding that could hardly be explained by LEX/TTB. This could indicate
that a considerable proportion of WADD users DEMO still misclassified as LEX/TTB users (see
Footnote 3).
Confidence DEMO Confidence judgments were analyzed using a 6 (CUE PATTERN) x 4
(CUE VALIDITY) x 3 (REPETITION) repeated measurement ANOVA. The CUE DEMO
TERN produced a significant main effect, F(2.5, 152.4) = DEMO, p < .001, η2 = .44. Confidence
ratings were higher for cue patterns 1, 2, and 6 than for the remaining cue DEMO (Figure 7;
SE ranged from 3.2 to 6.0). We DEMO obtained a significant main effect for CUE VALIDITY,
F(2.0, DEMO) = 34.7, p < .001, η2 = .36. Confidence increased DEMO increasing validity of cue
1 (see Figure 7). There was DEMO significant interaction between CUE VALIDITY and CUE
PATTERN, F(8.3, 516.1) = 7.3, p < .001, η2 = .11. The cue validity manipulation led to a
general increase in confidence in all cue patterns DEMO cue pattern 5, in which a decrease
was observed.
Figure 7
DEMO
90
80
70
60
50
40
30
20
10
0
Pattern 1
Pattern 2
Pattern 3
Pattern 4
Pattern 5
Pattern 6
0.80 0.85 DEMO 0.95
Validity of Cue 1
Figure 7. Confidence judgments in Experiment 3 with high values indicating a high level of con-
fidence. Ratings could DEMO from -100 to 100.
29
Confidence Judgments
To test more specifically the hypothesis that confidence judgments increase with increasing
DEMO between the weighted cue values of options, we computed correlations between
DEMO scores D (i.e., difference between total evidence for options) and DEMO judg-
ments. Difference scores were computed by D = ∑ ci O1 wi O1 − ∑ ci O2 wi O2 in which ci O1 DEMO
ci O2 are cue values of cue i for options A and B (i.e., -1 or 1); wi O1 and wi O2 DEMO decision
weights for options A and B. Decision weights were calculated in two different ways. First,
according to an ignorant WADD strategy, accuracy probabilities (e.g., .75 for cue 2) were
directly used as decision weights (wcue = pcue); second, difference scores were calculated by
DEMO for the fact that cues with an accuracy probability of .50 only (wcue = pcue - .50) are
uninformative. Correlations were calculated between DEMO judgments and difference
scores D based on ignorant WADD and corrected WADD. There was a significantly negative
correlation for difference scores based on ignorant DEMO, r = -.51, t(70) = -5.01, p < .001
(two-tailed), but a significantly positive correlation for corrected difference scores, DEMO = .35,
t(70) = 3.16, p = .002 (DEMO). We did not expect a positive correlation for ignorant
WADD because choice data already indicated that individuals corrected their decision
weights. For the DEMO difference scores, we obtained a substantial positive correlation.
This supports the DEMO derived from WADD strategies that the difference of the
weighted cue values between options influences confidence judgments. Thus, the findings
lend further support to our general hypothesis that individuals integrate information in a
weighted additive manner. DEMO cue validities or cue values were ignored, no correlation would
be DEMO
Discussion
In the third experiment, the general findings of the previous DEMO could be replicated
and strengthened by additional evidence. The majority of individuals took into account cue
values and cue validities. Choices and confidence judgments DEMO that the information was
integrated in a weighted additive manner. The low overall decision times make it likely that
individuals thereby relied on automatic DEMO; the systematic variations of decision time
between cue patterns in line DEMO the predictions of WADDauto further corroborate this hy-
pothesis. Note that the observed decision time of 3.7 seconds is not per se evidence for DEMO
matic processes. There are many cognitive tasks in which such a decision time would indicate
the application of deliberate processes (e.g., simple Stroop DEMO or categorization tasks as
used in the implicit association test; Greenwald, McGhee, & Schwarz, 1998). However, in
decision tasks of the complexity used in our experiment, in which 12 cue values and 6 cue
validities had to be considered, a decision time of 3.7 seconds substantially decreases the like-
lihood that WADDdel strategies were applied.
8  As mentioned above, Lohse and Johnson (1996) estimated the time for applying such a strategy in an
open Mouselab in decision tasks of similar DEMO (i.e., 2 options and 7 attributes) to be 29.1 seconds.
DEMO
8
It could be shown that individuals are sensitive to minor manipulations of DEMO validities that
do not change the general constellation of cue values. This clearly speaks against the idea that
cue information is merely encoded as DEMO constellation and compared with prototypes. Individu-
als integrate information in a weighted additive manner that is sensitive to minor changes in
cue validities. Note DEMO this observation also rules out alternative fast and frugal heuristics
that are all based on ignorance or only ordinal considerations of cue validities (like the one
discussed as an alternative explanation for the findings in Experiment DEMO). Finally, the findings
cannot be explained by the recently proposed DEMO heuristics” like TTB-CONFIGURAL
(Garcia-Retamero et al., 2007) because, according to the heuristic, the minor manipulation of
cue validities should not influence choices. Thus, our findings differ from that of Nosofsky
and Bergert (2007), which found data in line with TTB-CONFIGURAL. It is highly likely
that the many differences in materials and procedures (among other things, Nosofsky DEMO Ber-
gert used materials with interacting cue structures and provided feedback for decisions) might
have caused the differences. Further research will be necessary to investigate the reasons for
these differences more closely.
The analysis of confidence DEMO lends additional support for WADDauto strategies. In
particular, the substantial correlation DEMO confidence judgments and difference scores
makes it unlikely that cue values or validities are ignored in the decision, although we cannot
rule out that confidence judgments might have been based on other information than choices
alone.
DEMO Discussion
Process tracing studies have repeatedly shown that individuals employ simple strategies that
minimize the amount of considered information and the mental effort invested DEMO the decision
(e.g., Payne et al., 1988). Although the DEMO of strategy selection is still subject to theo-
retical debate (e.g., Glöckner & Betsch, 2008; Lee & Cummins, 2004; Newell, 2005; Ri-
eskamp & Otto, 2006), a few models converge in DEMO that time and capacity constraints
provoke strategy shifts towards a LEX/TTB rule (e.g., Bettman, Luce, & Payne, 1998; Ri-
eskamp & Hoffrage, 1999). Moreover, joint evidence from simulations and empirical research
suggests that LEX/TTB rules can lead to quite accurate decisions (Czerlinski, Gigerenzer, &
Goldstein, 1999), especially under time pressure (Payne et al., 1988). Taken together, these
findings seem to corroborate DEMO cornerstone assumptions of the bounded rationality approach
that has been directing and inspiring psychological decision research over the last decades.
One of these is DEMO humans commonly lack the cognitive resources to apply extensional,
compensatory strategies such as the WADD rule, particularly under time pressure. We hy-
pothesized that this assumption does not hold if decision strategies are considered that DEMO
ize on automatic processes for information integration and choice. When introducing the no-
tion of bounded rationality, Herbert Simon (1955) already anticipated that the boundaries he
described might only pertain to the deliberate side of DEMO cognitive system: “My first empiri-
31
cal proposition is that there is a complete lack of evidence that, in actual choice situations of
any complexity, these [EU] computations can be, or are in fact, performed… but we cannot,
of course, rule out the possibility that the unconscious is a better decision-maker than DEMO
conscious” (p. 104, italics added). Unfortunately, the research method DEMO used in study-
ing strategy application, Mouselab, hinders both the operation and the observation of auto-
matic processes. It forces decision makers to DEMO in a step-by-step consideration of infor-
mation, the units of observation DEMO the steps represented by the movements of a computer
mouse. The underlying assumption of this method is that overt information search behavior
mimics hidden DEMO processes. We call this assumption into question, asserting instead
that by DEMO individuals to uncover information one piece at a time, Mouselab binds DEMO
resources such that decision makers expend most of their time and effort on gathering infor-
mation and thus cannot unfold their processing potential. Especially DEMO time constraints,
they are not able to collect as much information as they could process and therefore might
work below their computational capacity. DEMO this reasoning is true, the conclusions drawn from
Mouselab studies would DEMO to be reconsidered. Accordingly, the prevalence of shortcut
strategies under Mouselab DEMO might not provide evidence of limitations in the cogni-
tive apparatus but simply show limitations in information search (i.e., uncovering hidden in-
formation DEMO a matrix). Hence, we suspected that the predominance of LEX/DEMO strategies
under time constraints found in the majority of Mouselab studies was partially induced by the
experimental procedure.
We tested this assumption in three DEMO using choice-based strategy classification with
open information presentation and compared the results with conditions using a standard
Mouselab under different time pressure conditions. The DEMO indicate that individuals are
able to apply WADD rules within an astoundingly narrow time frame if information search is
not restricted by environmental conditions. DEMO were able to replicate prior findings in Ex-
periment 2, where DEMO employed the standard Mouselab program. In such an environment,
participants searched for information in accordance with the LEX/TTB rule when time limits
DEMO too tight to inspect all pieces of information. In a third experiment, we investigated the
cognitive processes that allowed individuals to quickly integrate information according to a
WADD rule. Here we showed that choices were sensitive DEMO even small changes in cue valid-
ities. By keeping the ordinal structure of the cue hierarchy constant in the latter experiment,
we could DEMO out the explanation that individuals only encode constellations of information
and compare them to prototypes, exemplars or use heuristics which are based on complex
configural cues. Taken together, the studies provide evidence that the predominance of sim-
ple, noncompensatory strategies documented in Mouselab studies may well have been caused
by the experimental method and not by cognitive limitations. As demonstrated, Mouselab is
likely to induce the application of deliberate processes and thereby DEMO the application of
automatic processes. Consequently, the total cognitive capacity of DEMO decision makers is
substantially underestimated. Testing the potential of the human mind in Mouselab is like
testing the power of a Ferrari's engine DEMO a parking lot. Obviously, the Ferrari cannot unfold its
32
powers in such a constrained environment. Rather, we need to run it on a speedway before
making a verdict about its performance.
Our results DEMO that individuals are capable of performing decision strategies involving
complex information integration in an astonishingly short time period. Thus, the assumption
that limitations of the cognitive capacity for information integration cause the application of
simple serial DEMO – as proposed by proponents of the bounded rationality approach – has
to be revised. As anticipated by Herbert Simon, there may be another possibility for relieving
humans from the burden of endless, complex mathematical computations. Evolution may
have equipped humans with very powerful cognitive tools that capitalize DEMO the automatic
integration of information (Glöckner, in press). It has been shown that even sticklebacks se-
lect mating partners by a weighted DEMO of multiple pieces of evidence (Künzler &
Bakker, 2001) and that monkeys react to stimuli by considering probabilities and values in a
DEMO additive way (Glimcher, Dorris, & Bayer, 2005). Thus, DEMO an evolutionary per-
spective, it seems rather unlikely that humans lack DEMO cognitive capacity for such operations.
Our conclusions concerning the differential influence of time pressure on automatic and de-
liberate decision strategies converge nicely with DEMO findings by Beilock and DeCaro
(2007), who investigated the influence DEMO working memory capacity, time pressure and struc-
ture of the environment DEMO individuals’ strategies and performance in solving complex
mathematical problems. Individuals’ problem-solving strategies were measured by analyzing
self-reports. Statements were categorized to indicate rule-based strategies DEMO estimations based
on previous associations with problem operands. The former are deliberate strategies, the lat-
ter (at least) contain what we call automatic strategies. In environments in which rule-based
strategies lead to good performance, rule-based deciders showed a worse performance under
high as compared to low time DEMO, whereas the inverse effect was observed for persons
who relied on DEMO automatic strategies. Thus, time pressure hampers deliberate processes
but does not DEMO have a negative effect on automatic processes.
According to our experiments, DEMO strategies are likely to be used if a quick inspection
of information is possible. At the same time, Glöckner and Hodges (2006) also found evi-
dence for automatic strategies in experiments in which information had DEMO be retrieved from
memory (but see Bröder & Schiffer, 2003a). However, further research will be needed to in-
vestigate the application of automatic strategies under different context conditions, including
monetary multi-attributive decisions, which DEMO often been used in classic Mouselab studies.
Based on our data it is not possible to conclusively differentiate between the automatic proc-
essing models DEMO by different authors (e.g., Beach & Mitchell, 1996; Busemeyer &DEMO
Townsend, 1993; Dougherty et al., 1999). Nevertheless, only such models that predict choices
based on weighted additive information integration and systematic DEMO in decision
times and confidence judgments can account for our findings. Particularly, the results nicely
fit predictions derived from connectionist models of decision making (Betsch, 2005; Thagard
& Millgram, 1995; Simon et al., DEMO; Glöckner, 2006; Glöckner & Betsch, 2008). They are
33
also in line with some evidence accumulation models (e.g., Busemeyer & DEMO, 1993;
Usher & McClelland, 2004).
Although Mouselab may not be an appropriate method for studying the limitations of the cog-
nitive DEMO, it has its undisputable merits as a tool for studying search DEMO in envi-
ronments that only allow for serial and effortful acquisition of information. Such situations
can of course be found under natural conditions as DEMO For instance, consider a first-year law
student who checks legal cases DEMO looking up relevant aspects piece by piece in the literature.
Customers who intend to buy a product without any prior knowledge about it will DEMO
behave in a similar way. For these situations, findings from Mouselab DEMO are likely to be
valid. However, generalizations about results based on DEMO specific research paradigm should
be made with caution. Observations and case studies on decision making in natural setting
(e.g., Klein, 1999) indicate DEMO experienced decision makers are capable of considering a
huge amount of information even under severe time constraints. For instance, experienced
chess players (e.g., Ferrari, Didierjean, & Marmeche, 2006) or experienced judges (Glöckner,
in press) base their decisions on complex constellations of information rather than selectively
focusing on single cues or reasons.
An important lesson to be DEMO from the multiple strategy approach is that properties of the
decision task influence decision-making processes (e.g., Beach & Mitchell, 1978; Payne et DEMO,
1992). Taking the present findings, it is important to DEMO decision tasks in which in-
formation is instantly available from those in which it is not. If information is not instantly
available, it has to be looked up in a serial manner. If task constraints obstruct DEMO depth of
information search (e.g., time pressure) it is reasonable DEMO assume that decision makers will
order their search by the importance of information and may apply simple, noncompensatory
strategies for choice (e.g., TTB/LEX, cf. Experiment 2; Payne et al., 1988). Similarly, DEMO
situations in which expected gains from the information search are estimated to be lower than
its costs, only the most important information may be inspected (cf. Beach & Mitchell, 1978;
Newell & Shanks, 2003). In contrast, if the task enables relevant information to be accessed
immediately, as it was the case in our open Mouselab, individuals DEMO likely to employ com-
plex strategies for choice (e.g., WADDauto), even under time constraints.
As already mentioned before, in several other studies, strategy shifts to noncompensatory
strategies under time pressure were observed without relying on Mouselab procedure (for an
overview, see Edland & Svenson, 1993). Thus, we do not argue that all findings concerning
strategy shifts under time pressure can be explained by information search constraints induced
by DEMO or other methods. However, according to our findings it should be DEMO
edged that humans’ total cognitive capacity for information integration is higher than usually
estimated.
To conclude, more research is needed that aims at exploring and disentangling the effects of
the research method and other context variables. DEMO our point of view, it is important to be
aware of DEMO limitations of a particular research method. Some methods (i.e., Mouselab; DEMO
34
aloud protocols) appear unsuitable for identifying an important class of decision strategies,
namely, strategies that capitalize on automatic processing of information. Relying more
strongly on nonobtrusive methods of process tracing (e.g., eye tracking) and considering mul-
tiple correlates of internal processes (e.g., decision times, confidence judgments) might help
to improve our understanding of automatic processes in decision making.
35
References
Ariely, D, & Zakay, D. (2001). A timely DEMO of the role of duration in decision making.
Acta Psychological, 108, 187–207.
Bargh, J. A., & Chartrand, T. L. (1999). DEMO unbearable automaticity of being. American Psy-
chologist, 54, 462–479.
Bargh, DEMO A., & Williams, E. L. (2006). The automaticity of DEMO life. Current Directions in
Psychological Research, 15, 2–4.
Beach, L. DEMO, & Mitchell, T. R. (1978). A contingency model for DEMO selection of decision
strategies. Academy of Management Review, 3, 439–449.
Beach, L. R., & Mitchell, T. R. (1996). Image theory, the unifying perspective. In L. R. Beach
(Ed.), Decision making in the workplace: A unified perspective (pp. 1–20). Mahwah,
NJ: Lawrence Erlbaum.
Beach, L. R., & Potter, R.E. (1992). DEMO pre-choice screening of options. Acta Psychologica,
81, 115–126.
Bergert, F. B., & Nosofsky, R. M. (2007). A response-time approach to comparing general-
ized rational and take-the-best models of decision making. Journal of DEMO
Psychology: Learning, Memory, and Cognition, 33, 107–129.
Betsch, T. (2005). Preference theory: An affect-based approach to recurrent decision making.
DEMO T. Betsch & S. Haberstroh (Eds.), The routines of decision DEMO (pp. 39–66).
Mahwah, NJ: Lawrence Erlbaum.
Betsch, T. (DEMO). The nature of intuition and its neglect in research on judgment and decision
making. In H. Plessner, C. Betsch & T. Betsch (DEMO), Intuition in judgment and deci-
sion making (pp. 3–22). DEMO, NJ: Lawrence Erlbaum.
Bettman, J. R., Luce, M. F., & Payne, J. W. (1998). Constructive consumer choices. The
Journal DEMO Consumer Research, 25, 187–217.
Billings, R. S., & Marcus, DEMO A. (1983). Measures of compensatory and noncompensatory
models of behaviour: Process tracing versus policy capturing. Organizational Behavior
and Human Performance, 31, DEMO
Böckenholt, U., & Hynan, L. S. (1994). Caveats on a process-tracing measure and a remedy.
Journal of Behavioral Decision Making, 7, 103–117.
Broadbent, D. E. (1971). Decision and stress. London: DEMO Press.
36
Bröder, A. (2000a). Assessing the empirical validity of the “take-the-best” DEMO as a
model of human probabilistic inference. Journal of Experimental Psychology: DEMO,
Memory, and Cognition, 26, 1332–1346.
Bröder, A. (2000b)DEMO “Take The Best – Ignore The Rest”. Wann entscheiden Menschen be-
grenzt rational? [When do people make boundedly rational decisions?]. Lengerich,
Germany: Pabst Science Publishers.
Bröder, A. (2003). Decision making with the “Adaptive Toolbox”: Influence of environ-
mental structure, intelligence, and working memory load. Journal of Experimental Psy-
chology: Learning, Memory, and Cognition, DEMO, 611–625.
Bröder, A., & Schiffer, S. (2003a). Take DEMO best versus simultaneous feature matching: Prob-
abilistic inferences from memory and DEMO of representation format. Journal of Ex-
perimental Psychology: General, 132, DEMO
Bröder, A., & Schiffer, S. (2003b). Bayesian strategy assessment in multi-attributive decision
making. Journal of Behavioral Decision Making, 16, 193–213.
DEMO, A., & Gaissmaier, W. (in press). Sequential processing of cues in memory-based
multi-attribute decisions. Psychonomic Bulletin and Review.
Busemeyer, J. R., & Townsend, J. T. (1993). Decision field theory: A DEMO cognitive ap-
proach to decision making in an uncertain environment. Psychological Review, 100,
432–459.
Cartwright, D. & Festinger, L. (1943). DEMO quantitative theory of decision. Psychological Re-
view, 50, 595–621.
Chaiken, DEMO, & Trope, Y. (Eds.). (1999). Dual-process theories in social psychology. New
York: Guilford Press.
Christensen-Szalanski, J. J. (1978). Problem solving strategies: A selection mechanism, some
implications and some data. DEMO Behavior and Human Performance, 22,
307–323.
Czerlinski, J., Gigerenzer, G., & Goldstein, D. G. (1999). How good are simple heuristics? In
Simple heuristics that make us smart (pp. 97–118). DEMO York: Oxford University Press.
Beilock, S. L., & DeCaro, M. S. (2007). From poor performance to success under stress:
Working memory, strategy selection, and mathematical problem solving under pressure.
Journal of DEMO Psychology: Learning, Memory, and Cognition, 33, 983-998.
Doherty, M. E., & Kurz, E. M. (1996). Social judgement theory. Thinking and Reasoning, 2,
109–140.
37
Dougherty, M. R. P., Gettys, C. F., & Ogden, E. E. (1999). MINERVA-DM: A memory proc-
ess model for judgements DEMO likelihood. Psychological Review, 106, 108–209.
Edland, A., & Svenson, DEMO (1993). Judgment and decision making under time pressure: Stud-
ies and findings. In O. Svenson & A. J. Maule (Eds.), Time pressure and stress in hu-
man judgment and decision making (pp. 27–40). New York: Plenum Press.
Epstein, S. (1990). Cognitive-experiential self-theory. In L. Pervin (Ed.), Handbook of per-
sonality: Theory and DEMO (pp. 165–192). New York: Guilford.
Fazio, R. H. (1990). A practical guide to the use of response latency in social DEMO
research. In C. Hendrick & M. S. Clark (Eds.), Research DEMO in personality and so-
cial psychology (pp. 74–97). Thousand Oaks, CA: Sage Publications.
Ferrari, V., Didierjean, A., & Marmeche, DEMO (2006). Dynamic perception in chess. The Quar-
terly Journal of DEMO Psychology, 59, 397–410.
Festinger, L. (1943). Studies in decision: I. Decision-time, relative frequency of judgment and
subjective confidence as related DEMO physical stimulus difference. Journal of Experimen-
tal Psychology, 32, 291–306.
Fishburn, P. C. (1974). Lexicographic orders, utilities, and decision rules: A survey. Man-
agement Science, 20, 1442–1472.
Frederick, S. (2002)DEMO Automated choice heuristics. In D. Griffin, T. Gilovich & D. Kahneman
(Eds.), Heuristics and biases: The psychology of intuitive judgment (pp. DEMO). New
York: Cambridge University Press.
Garcia-Retamero, R., Hoffrage, U., & Dieckmann, A. (2007). When one cue is not enough:
Combining fast and frugal heuristics with compound cue processing. The Quarterly
DEMO of Experimental Psychology, 60(9), 1197-1215.
Gigerenzer, G., Hoffrage, U., & Kleinbölting, H. (1991). Probabilistic mental models: A
DEMO theory of confidence. Psychological Review, 98, 506–528.
Gigerenzer, G., & Hoffrage, U. (1995). How to improve Bayesian reasoning without instruc-
DEMO: Frequency formats. Psychological Review, 102, 684–704.
Gigerenzer, G., & DEMO, D. G. (1996). Reasoning the fast and frugal way: DEMO of
bounded rationality. Psychological Review, 103, 650–669.
Gigerenzer, G., Todd, P. M., & the ABC Group (1999). Simple heuristics that make us smart.
New York: Oxford University Press.
38
Gigerenzer, G. (2004). Fast and frugal heuristics: The tools of bounded rationality. In D.
Koehler & N. Harvey (Eds.), Handbook of judgment and decision making (pp. 62–88).
Oxford, UK: Blackwell.
Glass, G. V., & Hopkins, K. D. (1996). Statistical methods DEMO education and psychology.
Boston, MA: Allyn and Bacon.
Glimcher, P. DEMO, Dorris, M. C., & Bayer, H. M. (2005). DEMO utility theory and the
neuroeconomics of choice. Games and Economic Behavior, DEMO, 213–256.
Glöckner, A. (2006). Automatische Prozesse bei Entscheidungen [Automatic DEMO in de-
cision making]. Hamburg: Kovac.
Glöckner, A., & Hodges, S. D. (2006). Strategy selection in memory based decisions: Simpli-
DEMO fast and frugal heuristics versus weighted compensatory strategies based on
automatic information integration. Manuscript submitted for publication.
Glöckner, A., & Betsch, T. (DEMO press). Do people make decisions under risk based on igno-
rance? An empirical test of the priority heuristic against cumulative prospect theory.
Organizational Behavior and Human Decision Processes.
Glöckner, A. & Betsch, T. (2008). Modeling option and strategy choices with connectionist
networks: Towards an integrative model of automatic and deliberate decision making.
Judgment and Decision Making, 3(3), 215–228.
Glöckner, A. (2007). Does intuition beat fast DEMO frugal heuristics? A systematic empirical
analysis. In H. Plessner, C. Betsch, and T. Betsch (Eds.), Intuition in judgment and de-
cision DEMO (pp. 309–325). Mahwah, NJ: Lawrence Erlbaum.
Glöckner, A. (DEMO press). How evolution outwits bounded rationality: The efficient interaction
of DEMO and deliberate processes in decision making and implications for institu-
tions. In C. Engel and W. Singer (Eds.), Better than conscious. FIAS Workshop Report.
Cambridge, MA: MIT Press.
Greenwald, A. G., McGhee, D. E., & Schwartz, J. L. K. (1998). Measuring individual differ-
ences in implicit cognition: the implicit association test. Journal of Personality and So-
cial Psychology, 74, 1464–1480.
Hammond, K. R., Hamm, R. M., Grassia, J., & Pearson, T. (1987). Direct comparison of the
relative efficiency on intuitive and analytical cognition. IEEE Transactions on DEMO,
Man and Cybernetics, 17, 753–770.
Hasher, L., & Zacks, R. T. (1984). Automatic processing of fundamental information: The
case of frequency of occurrence. American Psychologist, 12, 1372–1388.
39
Hintzman, D. L. (1988). Judgments of frequency and recognition memory DEMO a multiple-trace
memory model. Psychological Review, 95, 528–551.
Hoffman, P. DEMO (1960). The paramorphic representation of clinical judgment. Psychological
Bulletin, 57, 116–131.
Hogarth, R. (2001). Educating intuition. Chicago: University of DEMO Press.
Holyoak, K. J., & Simon, D. (1999). Bidirectional reasoning in decision making by constraint
satisfaction. Journal of Experimental Psychology: General, 128, 3–31.
Johnson, E. J., Payne, J. W., Schkade, D. A., & Bettman, J. R. (1986). Monitoring informa-
tion processing and decisions: The Mouselab system. Unpublished manuscript, Center
for Decision DEMO, Fuqua School of Business, Duke University.
Juslin, P., Olsson, DEMO, & Olsson, A.-C. (2003). Exemplar effects in categorization and DEMO
ple-cue judgment. Journal of Experimental Psychology: General, 132, 133–156.
Kahneman, D., Slovic, P., & Tversky, A. (Eds.) (1982). Judgement under uncertainty: Heu-
ristics and biases. Cambridge, UK: Cambridge University Press.
Kahneman, D. & Frederick, S. (2002). Representativeness revisited: DEMO substitution in
intuitive judgment. In T. Gilovich, D. Griffin  & D. Kahneman (Eds.), Heuristics and
biases: The psychology of intuitive judgment (pp. 49–81). New York: Cambridge Uni-
versity Press.
Klein, G. (1999). Applied decision making. In P. A. Hancock (Ed.), Human performance and
ergonomics (pp. 87-107). San Diego, CA: Academic Press.
Künzler, R., & Bakker, C. M. (2001). Female preferences DEMO single and combined traits in
computer animated stickleback males. Behavioral Ecology, DEMO, 681–685.
Lee, M. D., & Cummins, T. D. R. (DEMO). Evidence accumulation in decision making: Unify-
ing the “take the DEMO and the “rational” models. Psychonomic Bulletin & Review, 11,
343–352.
DEMO, M. D. (2000). Intuition: A social cognition neuroscience approach. DEMO
Review, 126, 109–137.
Lohse, G. L., & Johnson, E. DEMO (1996). A comparison of two process tracing methods for
choice DEMO Organizational Behavior and Human Decision Processes, 68, 28–43.
Maule, A. DEMO (1994). A componential investigation of the relation between structural model-
DEMO and cognitive accounts of human judgement. Acta Psychologica, 87, 199-216.
40
Montgomery, H., & Svenson, O. (1983). A think-aloud study DEMO dominance structuring in de-
cision making. In R. Tietz (Ed.), DEMO levels in bargaining and economic decision
making (pp. 366–383). Berlin: Springer.
Newell, B. R., & Shanks, D. R. (2003). DEMO the best or look at the rest? Factors influencing
“One-Reason” decision DEMO Journal of Experimental Psychology: Learning, Mem-
ory, and Cognition, 29, 53–65.
Newell, B. R. (2005). Re-visions of rationality? Trends DEMO Cognitive Science, 9, 11–15.
Nosofsky, R. M., & Bergert, DEMO B. (2007). Limitations of exemplar models of multi-attribute
probabilistic inference. DEMO of Experimental Psychology: Learning, Memory, and
Cognition, 33, 999-1019.
DEMO, A.-C., Enkvist, T., & Juslin, P. (2006). Go with the flow: How to master a nonlinear
multiple-cue judgment task. Journal of Experimental Psychology: Learning, Memory,
and Cognition, 32, 1371–1384.
DEMO, J. W., Bettman, J. R., & Johnson, E. J. (1988). Adaptive strategy selection in decision
making. Journal of Experimental Psychology: Learning, Memory, & Cognition, 14,
534–552.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1992). Behavioral DEMO research: A con-
structive processing perspective. Annual Reviews of Psychology, 43, 87–131.
Rieskamp, J., & Hoffrage, U. (1999). When do people use simple heuristics and how can we
tell? In G. Gigerenzer, P. M. Todd & the ABC Research Group, Simple heuristics that
DEMO us smart (pp. 141–167). New York: Oxford University Press.
Rieskamp, J., & Otto, P. E. (2006). SSL: A theory of how people learn to select strategies.
Journal of Experimental Psychology: General, 135, 207–236.
Russo, J. E., & Dosher, B. A. (DEMO). Strategies for multiattribute binary choices. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 9, 676–696.
Schneider, W., & Shiffrin, DEMO M. (1977). Controlled and automatic human information proc-
essing: I. Detection, search, and attention. Psychological Review, 84, 1–66.
Shiffrin, R. M., & Schneider, W. (1977). Controlled and automatic human information proc-
essing: II. Perceptual learning, automatic attending, and a general theory. Psychological
Review, 84, 127–190.
Simon, D., Snow, C. J., & Read, S .J. (2004). The redux of cognitive consistency theories:
Evidence judgments by constraint satisfaction. Journal of Personality and Social Psy-
DEMO, 86, 814–837.
41
Simon, H. A. (1955). A behavioral model of rational choice. DEMO Quarterly Journal of Eco-
nomics, 69, 99–118.
Sloman, S. A. (2002). Two systems of reasoning. In T. Gilovich, D. Griffin & D. Kahneman
(Eds.), Heuristics and biases: The psychology of intuitive DEMO (pp. 379–396). New
York: Cambridge University Press.
Sundstroem, G.A. (1987). Information search and decision making: the effects of Information
display.  Acta Psychologica, 65, 165–179.
Svenson, O. (1989). Eliciting and analysing verbal protocols in process studies of judgement
and decision making. In DEMO Montgomery & O. Svenson (Eds.), Process and structure in
human DEMO making (pp. 65–81). New York: Wiley.
Thagard, P. & DEMO, E. (1995). Inference to the best plan: A coherence DEMO of deci-
sion. In A. Ram & D. B. Leake (Eds.), Goal-driven learning (pp. 439–454). Cambridge,
MA: MIT Press.
Tversky, A. (1972). Elimination by aspect: A theory of choice.  DEMO Review, 79,
281–299.
Usher, M., & McClelland, J. L. (2004). Loss aversion and inhibition in dynamical models of
multialternative choice. Psychological Review, 111, 757–769.
Wegner, D. (1994). Ironic processes DEMO mental control. Psychological Review, 101, 34–52.
Zajonc, B. (1980). Feeling and thinking: Preferences need no inferences. American Psycholo-
gist, 35, 151–175.
Zakay, M. P. (1993). The impact of time perception DEMO on decision making under time
stress. In O. Svenson & A. J. Maule (Eds.), Time pressure and stress in human judge-
ment and decision making (pp. 59–72). New York: Plenum Press.
42
Appendix A: Instructions used in Experiment 1
Imagine that you are the head of a company that produces orange juice. You receive offers
from DEMO orange vendors and have to decide which vendor to select. You have three test-
ers A, B, and C, who check each vendor’s oranges for their quality. They give you informa-
tion about each vendor: “+” means the vendor’s oranges are of good quality, “-” means the
vendor’s oranges are of poor quality. [pagebreak] You know from experience that DEMO testers’
information varies in reliability: Tester A’s information is correct in DEMO out of 10 cases, tester
B’s information is correct in 6 DEMO of 10 cases, and tester C’s information is correct in 5 DEMO of
10 cases. [pagebreak] In the experiment you will be repeatedly presented with offers from
three different vendors and information from the testers A, B, and C in the following format:
Orange Vendors
1 2 3
A + + -
B - + -
C  + - +
Your task is to select the vendor with the best-quality oranges. DEMO try to make good deci-
sions and to proceed as quickly as possible. [pagebreak] Three keys are marked on the key-
board for use DEMO selecting the vendors. Please lay three fingers of one hand on the three keys
to avoid unnecessary errors. Hit the left key to select DEMO 1, hit the middle key to select
vendor 2, and hit the right key to select vendor 3.
Appendix B: Additional Instructions used in Experiment 3
Explanations for the Information on Testers’ Reliability
The values for the reliability of the testers’ predictions DEMO from 50 percent to 100 percent.
Fifty percent correct predictions mean that 5 of 10 of the tester’s predictions are wrong. Be-
cause there DEMO only two possible predictions (good–bad), this equates to random probability.
DEMO means that testers’ whose predictions are 50 percent correct can be ignored because they
provide no information about the quality of oranges. In contrast, the information of a tester
who makes 100 percent correct predictions is DEMO correct. The testers in the study will
have different reliability values that are between 50 and 100 percent.
44{1g42fwefx}