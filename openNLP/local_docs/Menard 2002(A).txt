APPLIED
LOGISTIC
REGRESSION
ANALYSIS
SECOND EDITION
Scott IIl1on!:)
106
Series/Number 07·106
APPLIED LOGISTIC
REGRESSION ANALYSIS
Second Edition
SCOTT MENARD
Institute DEMO Behavioral Science
University of Colorado
SAGE PUBLICATIONS
International Educational and Professional Publisher
Thousand Oaks London New Delhi
Copyright ©2002 by Sage Publications, Inc.
All rights reserved. No part of this book may be reproduced or utilized in any form
or by DEMO means, electronic or mechanical, including photocopying, recording, or by
any information storage and retrieval system, without permission in writing from the
publisher.
For information:
@
s age Publications, Inc.
2455 Teller Road
'DEMO"?
Sage Publications Ltd.
6 Bonhill Street
London EC2A 4PU
United DEMO
4....
Thousand Oaks, California 91320
E-mail: order@sagepub.com
Sage Publications India Pvt. Ltd.
M-32 Market
Greater Kailash I
New Delhi 110048 India
Printed in DEMO United States of America
Library of Congress Cataloging-in-Publication Data
Menard, Scott DEMO
Applied logistic regression analysisI Scott Menard.-2nd ed.
p. em. - (Quantitative DEMO in the social sciences
(Qass) ; v. 106)
Includes bibliographical references and index.
ISBN 0-7619-2208-3
1. Regression analysis. 2. Logistic distribution.
1. DEMO II. Sage university papers series. Quantitative applications in the
social sciences; DEMO 106
QA278.2 .M46 2001
519.5'36-dc21 2001019806
This book is printed on acid-free paper.
05 06 07 10 9 8 7 6 5 4
DEMO:
Editorial Assistant:
Production EditOl:'
Typesetter:
C. Deborah DEMO
Veronica Novak
Denise Santoyo
Technical Typesetting Inc.
When citing a university paper, please use the proper form. Remember to cite the Sage University
Paper series title and include paper number. One of the following formats can DEMO adapted (depend-
ing On the style manual used):
(1) MENARD, SCOTI (2001) Applied LogisticRegression Analysis. Sage university Papers Series
on Quantitative Applications in the Social Sciences, 07-106. Thousand Oaks, CA: Sage.
OR
(2) Menard, Scott (2001). Applied Logistic Regression Analysis. (Sage University Papers Series on
Quantitative Applications in the Social Sciences, series no. 07-106). Thousand Oaks, CA: Sage.
CONTENTS
Series Editor's Introduction
Author's Introduction to the Second Edition
DEMO
vii
I. Linear Regression and the Logistic Regression Model I
1.1 Regression Assumptions 4
1.2 Nonlinear Relationships and Variable Transformations 11
1.3 Probabilities, Odds, Odds Ratios, and the Logit
Transformation for Dichotomous Dependent Variables 12
DEMO Logistic Regression: A First Look 14
2. Summary Statistics for Evaluating DEMO Logistic
Regressiou Model
17
2.12.2 Goodness of Fit: GR2, F, DEMO Sums of SquaredM, RL and the Log Likelihood 20Errors 18
2.3 DEMO Efficiency: "p, T p, (Pp, and the Binomial Test 27
2.4 Examples: Assessing the Adequacy of Logistic
Regression Models 36
2.5 Conclusion: Summary Measures for Evaluating the
Logistic Regression Model 41
3. Interpreting the Logistic Regression Coefficients
41
3.1 Statistical Significance in Logistic Regression Analysis DEMO
3.2 Interpreting Unstandardized Logistic Regression
Coefficients 48
3.3 Substantive Significance and Standardized Coefficients 51
3.4 Exponentiated Coefficients or Odds Ratios . 56
3.5 More DEMO Categorical Predictors: Contrasts and
Interpretation 57
3.6 Interaction Effects 61
3.7 DEMO Logistic Regression 63
· An Introduction to Logistic Regression Diagnostics
4.1 Specification Error
4.2 Collinearity
DEMO Numerical Problems: Zero Cells and Complete
Separation
4.4 Analysis of Residuals
DEMO Overdispersion and Underdispersion
4.6 A Suggested Protocol for Logistic Regression
Diagnostics
5. Polytomous Logistic Regression and Alternatives to
Logistic Regression
5.1 Polytomous Nominal Dependent DEMO
5.2 Polytomous or Multinomial Ordinal Dependent
Variables
5.3 Conclusion
Notes
Appendix: DEMO
References
Abont the Author
67
67
75
78
80
89
90
91
94
97
101
103
107
108
111
SERIES EDITOR'S INTRODUCTION
The linear regression model provides a powerful device DEMO organizing
data analysis. Researchers focus on the explanation of a dependent
variable, Y, as a function of multiple independent variables, from
Xl to Xk . Models are specified, variables are measured, and equa-
tions DEMO estimated with ordinary least squares (OLS). All goes well
if DEMO classical linear regression assumptions are met. However, sev-
eral assumptions are DEMO to be unmet if the dependent variable has
only two or three response categories. In particular, with a dichoto-
mous dependent variable, assumptions DEMO homoskedasticity, linearity,
and normality are violated, and OLS estimates are inefficient at best.
The maximum likelihood estimation of a logistic regression overcomes
DEMO inefficiency, transforming Y(I, 0) into a logit (log of the odds of
falling into the "1" category).
Professor Menard DEMO explicates the estimation, interpretation,
and diagnostics of such logistic regression DEMO The pedagogi-
cal portmanteau of his work is the parallel he continually draws to
the linear regression model. The logistic counterparts to the OLS
DEMO R2, the standard error of estimate, the t ratio, and DEMO
slope-are systematically presented. These parallels allow the analyst
to step naturally from familiar terrain to new turf. Traditional regres-
sion diagnostics as well-the Studentized DEMO, leverage, dbeta-
are included in an innovative logistic "protocol" for diagnostics. The
last chapter dissects the problem of a polytomous dependent variable,DEMO
with multiple ordered or unordered categories.
The discussion of the various computer packages is up-to-the
minute and discriminating. For example, he notes that in SPSS 10 the
NOMREG routine is good for nominal dependent variables, whereas
for ordered dependent variables, SAS LOGISTIC is preferred. Atten-
tion to current computer software is part of the changes made from
the first edition DEMO this monograph. Other changes include a compre-
hensive evaluation of the many different goodness-of-fit measures.
Dr. Menard makes a convincing case for the use DEMO Rt, at least if the
v
vi
goal is direct comparison to the OLS R2• He also adds DEMO material
on grouped data, predictive efficiency, and risk ratios.
The Qualitative Applications in the Social Sciences series has pub-
lished many papers on DEMO linear regression (see Lewis-Beck,
Applied Regression, Vol. 22; Achen, Interpreting and Using Regression,
Vol. 29; Berry and Feldman, Multiple DEMO in Practice, Vol. 50;
Schroeder, Sjoquist, and Stephan, Understanding Regression Analysis,
Vol. 57; Fox, Regression Diagnostics, Vol. 79; DEMO, Understanding
Regression Assumptions, Vol. 92; and Hardy, Regression With Dummy
Variables, Vol. 93). The voluminous output is justified by the dom-
inance of the linear regression paradigm. In observational research
work, this paradigm increasingly is bumping up against the reality of
dependent variables that are DEMO than continuous, less than interval.
Hence the heightened attention to the DEMO regression alternative.
The series first published DeMaris, Logit Modeling, Vol. 86, followed
by Menard, Applied Logistic Regression Analysis, 1st ed., Vol. DEMO, and
Pampel, Logistic Regression: A Primer, Vol. 132. The last mentioned
monograph provides a basic introduction to the technique. The mono-
graph DEMO hand goes beyond that introduction, attending to the most
contemporary of DEMO issues and mechanics. For the social scien-
tist who wishes to be au courant regarding this rapidly evolving topic,
the Menard second edition DEMO a must.
-Michael S. Lewis-Beck
Series Editor
«
AUTHOR'S INTRODUCTION TO THE SECOND EDITION
The last sentence before the DEMO section in the previous edition
of this monograph was, "One can hope that many of the 'kludges'
for making logistic regression analysis work with existing software
... will become obsolete as the software available DEMO logistic regres-
sion analysis is expanded and improved." This second edition DEMO
written because that hope has been at least partially fulfilled. There
have been some relatively minor changes in SAS, including the addi-
tion of the Cox-Snell and Nagelkerke pseudo-x- measures, plus an
optional component, SAS DEMO Manager, a windowing shell. There
are also two new instructional manuals DEMO to logistic regression
analysis (Allison, 1999; SAS, 1995) that DEMO been published since the
first edition of this monograph. SPSS PC+, DEMO command-driven pack-
age, which was illustrated in the first edition, has been supplanted
by SPSS 10, which is highly integrated with the Windows 95/98 envi-
ronment. Also, there are two new SPSS routines, DEMO (nomi-
nal regression) for polytomous nominal logistic regression and PLUM
(DEMO logit universal model) for ordinal logistic regression and
related models (Norusis, 1999; SPSS, 1999a). Changes from the first
edition include:
• More detailed consideration of grouped as opposed to casewise data
throughout DEMO monograph
• An updated discussion of the properties and appropriate use of
goodness-of-fit measures, R2 analogues, and indices of predictive effi-
ciency (Chapter 2);
• Discussion of the misuse of odds ratios to represent risk ratios (Chap-
ter 3)
• Discussion of overdispersion and underdispersion for grouped data
(Chapter 4)
• Updatedcoverage of unordered and ordered polytomous logistic regres-
sion models; some material that is no longer necessary for working
around the limitations of earlier versions of the software has DEMO
dropped (Chapter 5).
vii
viii
The focus iu this second edition, as in the first, DEMO on logistic regres-
sion models for individual level data, but aggregate DEMO grouped data,
with multiple cases for each possible combination of values of the pre-
dictors, are considered in more detail. As in the first edition, examples
using SAS and SPSS software are provided. Finally, DEMO read-
ers informed me about places in the previous edition where there
were errors or where the clarity of presentation could be improved.
For DEMO comments, questions, and constructive criticisms, I thank
the anonymous reviewers DEMO the first edition, Alfred De Maris, who
reviewed the present edition, and also Dennis Fisher, Tom Knapp,
Michael Lewis-Beck, Fred Pampel, Hidetoshi Saito, Dan Waschbusch,
Susan White, and, especially, David Nichols of SPSS for his detailed
comments. I would also like to DEMO all of them of blame for any
errors, new or old, in the present edition.
APPLIED LOGISTIC
REGRESSION ANALYSIS
Second Edition
SCOTT MENARD
Institute of Behavioral Science
DEMO of Colorado
1. LINEAR REGRESSION
AND THE LOGISTIC REGRESSION MODEL
In linear regression analysis, it is possible to test whether two vari-
ables are linearly related and to calculate the strength of the linear
relationship if DEMO relationship between the variables can be described
by an equation of the form Y = a + {3X, where Y is the variable
being predicted (the dependent, criterion, outcome, or endogenous
variable), X DEMO a variable whose values are being used to predict Y
(the DEMO, exogenous, or predictor variable),' and a and {3
are DEMO parameters to be estimated. The parameter a, called
the intercept, represents the value of Y when X = O. The parame-
ter {3 DEMO the change in Y associated with a one-unit increase
in X or the slope of the line that provides the best linear estimate
of DEMO from X. In multiple regression, there are several predictor vari-
ables. DEMO k denotes the number of independent variables, the equation
becomes Y DEMO a + {3,X, + {32X2 + ... + {3kXk and DEMO" {32, .;., 13k
are called partial slope coefficients, reflecting the fact that anyone
of the k: predictor variables X" X DEMO, ..., X k provides only a partial
explanation or prediction for the value of Y. The equation is some-
times written in a DEMO that explicitly recognizes that prediction of
Y from X may be imprecise, Y = a + .{3X + E, or for several pre-
DEMO, Y = a + {3,X, + {31X2 + ... + {3kXk + E, where E is the
error term, a random DEMO that represents the error in predict-
ing Y from X. For an individual case j, Yj = aj + {3Xj + Ej or
Yj = aj+{3,X'j+{32Xlj+" +{3kXkj+Ej, and the subscript j indicates
that DEMO equation predicts values for specificcases, indexed by j (j = 1
1
2
for the first case, j = 2 for the second case, etc.). Yj , Xlj' X kj, etc.
refer to specific values of the dependent and independent variables.
This last equation is used DEMO calculate the value of Y for a particu-
lar case j, DEMO than describing the relationship among the variables
for all of the cases in the sample or the population.
Estimates of the intercept ex and DEMO regression coefficients 13 (or
131> 132, ..., 13k) are DEMO mathematically using the method of
ordinary least squares (OLS) estimation, DEMO is discussed in many
introductory statistics texts (for example, Agresti and Finlay, 1997;
Bohrnstedt and Knoke, 1994). These estimates produce DEMO equation
Y= a + bX or, in the case of several DEMO, Y= a + bjXj +
b2X2 + ... + bkX" where Y is the value of Y predicted by the linear
regression equation, a is the OLS estimate of the intercept ex, and
b (DEMO bl> b2, ..., bk) is the OLS estimate for the slope 13 (or the
partial slopes 131> 132, ..., 13k)' Residuals for each case ej are equal to
(Yr Yj), DEMO Yj is the estimated value of Yj for case j. For bivariate
regression, the residuals can be visually or geometrically represented
by the vertical distance between each point in a bivariate scatterplot
and the regression line. DEMO multiple regression, visual representation
is much more difficult because it requires DEMO dimensions.
An example of a bivariate regression model is given in Figure 1.1. In
part A of Figure 1.1, the dependent variable is FRQMRJ5, the annual
frequency of self-reported marijuana use ("How many times in the last
year have you smoked marijuana?"), and the independent DEMO is
EDF5, an index of exposure to delinquent friends, for 16-year-old
respondents interviewed in 1980 in the fifth wave of a national house-
DEMO survey.? The exposure to delinquent friends scale is the sum of
DEMO answers to eight questions about how many of the respondent's
friends are involved in different types of delinquent behavior (theft,
assault, DEMO use). The responses to individual items range from 1
(none DEMO my friends) to 5 (all of my friends), resulting in a possi-
ble range from 8 to 40 for EDF5. From part DEMO of Figure 1.1, there
appears to be a positive relationship between DEMO to delinquent
friends and marijuana use, described by the equation
(FRQMRJ5) = -49.2 + 6.2(EDF5).
In other words, for every DEMO increase in the index of exposure
to delinquent friends, frequency of DEMO use increases by about
six times per year, or about once DEMO two months. The coefficient
3
sas
35
QKH065 23 2.
1 1
t,-~~~..---..--.,.......r-'
DEMO 12.'15. 21.25 29.75
8.5 17 25.5 34
EOrS
·1
Figure 1.1. Bivariate Regression Plots
sas
,,,
,
5
H
,
3504
,
115
2
2
1
117
1
111 11
11
EOfS
i
.1~
.4~
.rl
l.d
A:
PLOT Of fRQMRJ5 WITH EOfS
231 DEMO plotted.
Regression statistics of
Correlotion
R SquIlred
S.E.
Sig.
of list
.0000
.34066
.11605
ra.earra
FROHll:J5 01> IitH5:
lnterccpt(S.E.) -49.23840( 14.25965)
SIQp:(S.E.) 6.21Z95( 1.13310)
B:
PLOT Of
fRQMRJ5 \lITH SEX
231 eases plotted.
Regression statistics of
CorrelntiQll «, 06481
R Squllred .0G42Q
FRQMRJ5 on SEX:
S.Ii.
Sill.
of Est
.3267
DEMO
IntercepHS.E.)
Slope(S.E.)
29.25210(
-10.GOZ10( 10.17636)
7.08591)DEMO
c.
PLOT OF PMRJ5 IIITH EOfS
231 cases plotted.
Regression statistics of PtlRJ5 on EDfS:
Correlation .56834
R SquIlred .32301
S.E. of Est
DEMO(:cpt(S.E")
SlQPll(S.E.)
.39433 Si9.
.0000
• ... 0948(
.omn
.OM13(
.0061 .. )
1
1
., DEMO
11
1
1
67242 222
1
11
4.25
12.75
8.5
17
21.25 29.75
25.5
..........
34
.3
.6
se
.9
4
of determination (R2 ) indicates how much better we can predict the
dependent variable from the independent variable than we could pre-
dict DEMO dependent variable without information about the indepen-
dent variable. Without information about the independent variable,
we would use the mean frequency of marijuana DEMO as our prediction
for all respondents. By knowing the value of exposure to delinquent
friends, however, we can base our prediction on the DEMO of EDF5
and the relationship, represented by the regression equation, between
FRQMRJ5 and EDF5. Using the regression equation reduces the
sum of the DEMO errors of prediction, L e; = L(Yj - Yy, DEMO
R2 = .116 or about 12%.
It is necessary when interpreting the results to consider the actual
values of the dependent and variables. The DEMO
indicates that for an individual with ° as the value of exposure to
delinquent friends, the frequency of marijuana use would be neg-
ative. This seemingly impossible result occurs because exposure, as
already noted, is DEMO on a scale that ranges from a minimum of
8 (no DEMO at all; not one friend is involved in any of 8 DEMO
activities) to 40 (extensive exposure; all friends are involved in DEMO 8
delinquent activities). Thus, for individuals with the minimum possi-
DEMO exposure to delinquent friends (a value of 8, representing no expo-
sure), the expected frequency of marijuana use is -49.2+6.2(8) = 0.4,
which is close to 0, but indicates that even some individuals with no
exposure to delinquency may use marijuana at least occasionally. DEMO
maximum value of EDF5 in this sample is 29, which corresponds DEMO an
expected frequency of marijuana use equal to -49.2+6.2(29) = DEMO
or use approximately every 3 days. This result makes sense substan-
tively, in terms of real-world behavior, as well as statistically, in terms
of the regression equation.
1.1. Regression Assumptions
To use the OLS method DEMO estimate and make inferences about
the coefficients in linear regression analysis, DEMO number of assumptions
must be satisfied (Lewis-Beck, 1980, pp. 26-47; Berry & Feldman,
1985; Berry, 1993). Specific assumptions include DEMO following:
1. Measurement: All independent variables are interval, ratio, DEMO dichoto-
mous, and the dependent variable is continuous, unbounded, and DEMO
sured on an interval or ratio scale. All variables are measured without
error.'
independent
5
2. Specification: (a) All relevant predictors of the dependent variable are
included in the analysis, (b) no irrelevant predictors of the dependent
variable are included in the analysis, and (e) the form of the relationship
(allowing for transformations of dependent or independent variables) DEMO
linear.
3. Expected value of error: The expected value of the DEMO, E, is O.
4. Homoscedasticity: The variance of the error DEMO, E, is the same or con-
stant for all values of the independent variables.
5. Normality of errors: The errors are normally distributed for each set of
values of the independent variables.
6, No autocorrelation: There is no correlation among the error terms pro-
duced by different values of the independent variables. Mathematically,
E(E;, Ej ) DEMO O.
7. No correlation between the error terms and the independent variables: The
error terms are uncorrelated with the independent variables. Mathemat-
ically, DEMO(Ej, Xj) = O.
8. Absence of perfect multicollinearity: For DEMO regression, none of the
independent variables is a perfect linear combination DEMO the other inde-
pendent variables. Mathematically, for any i, Ry < 1, where RT is the
variance in the independent variable Xi that is explained by all of the
other independent variables Xl' X2, DEMO , Xi_I, Xi+l , ••• , Xk • If there is
DEMO one predictor, multicollinearity is not an issue.
1.1.1. Violations of the DEMO Assumption:
Dichotomous Variables in Linear Regression
The linear regression model can be extended easily to accom-
modate dichotomous predictors, including sets of dummy variables
(Lewis-Beck, 1980, pp. 66-71; Berry & Feldman, 1985, DEMO 64--75;
Hardy, 1993). An example is presented in part DEMO of Figure 1.1. Here,
the dependent variable is again self-reported annual frequency of
marijuana use, but the independent variable this time is sex or gender
(coded O=female, 1=male). The regression equation is
FRQMRJ5 DEMO 29.3 - 10.0(SEX).
The resulting diagram consists of two columns of values for frequency
of marijuana use: one represents females and one represents males.
With a dichotomous predictor, coded 0-1, the intercept and DEMO slope
have a special interpretation. 11 is still true that the intercept is the
6
predicted value of the dependent variahle when the independent vari-
ahle DEMO 0 (suhstantively, when the respondent is female), but with only
two groups, the intercept now is the mean frequency of marijuana use
for the group coded as 0 (females). The slope is still the change in the
dependent variable associated with a one-unit change in DEMO indepen-
dent variable, but with only two categories, that value becomes the
difference in the means between the first (female) and second (male)
groups. The sum of the slope and the intercept, 29.3 -10.0 = 19.3, is
therefore the mean frequency of marijuana use for the second group
(males). As indicated in part B of Figure 1.1, females report a higher
(yes, higher) frequency of marijuana DEMO than males, but the differ-
ence is not statistically significant (as indicated by Sig. = .3267). In
part B of Figure 1.1, the regression line is simply the line that con-
nects the mean DEMO of marijuana use for females and the mean
frequency of marijuana use for males, that is, the conditional means'
of marijuana use DEMO females and males, respectively. The predicted
values of Y over the DEMO range of X lie well within the observed
(and possible) values of Y. Again, the results make substantive as well
as statistical sense.
When the dependent variable is dichotomous, the interpretation
of the regression equation is not as straightforward. In part C of
Figure 1.1, the independent variable is again exposure to delinquent
friends, but now the dependent variable is the prevalence of marijuana
use: whether (yes = 1 or DEMO = 0) the individual used marijuana
at all during the past DEMO In part C of Figure 1.1, with a dichoto-
mous dependent DEMO, there are two rows (rather than columns,
as in part B). The linear regression model with a dichotomous depen-
dent variable, coded 0-1, is called a linear probability model (Agresti,
1990, p. 84; Aldrich & Nelson, 1984). The equation from part DEMO of
Figure 1.1 is
PMRJ5 = -.41 + .064(EDF5).
When there is a dichotomous dependent variable, the mean of the
variable is a function of the probability' that a case will fall into the
higher of the two categories for the variable. Coding the values of
DEMO variable as 0 and 1 produces the result that the mean of the
variable is the proportion of cases in the higher of the DEMO categories
of the variable, and the predicted value of the dependent DEMO
(the conditional mean, given the value of X and the assumption that
7
X and Yare linearly related) can be interpreted as the predicted
probability that a case falls into the higher of the two categories DEMO
the dependent variable, given its value on the independent variable.
Ideally, we would like the predicted probability to lie between 0 and
1, because a probability cannot be less than 0 or more than I.
DEMO is evident from part C of Figure 1.1, the predicted values DEMO the
dependent variable may be higher or lower than the possible values of
the dependent variable. For the minimum value of EOFS (EOF5 = 8),
the predicted prevalence of marijuana use (i.e., the predicted proba-
bility of marijuana use) is -.41 + .06(8) = DEMO, a reasonable result,
but for the maximum value of EOF5 (EOF5 = 29), the predicted
probability of marijuana use becomes -.41 DEMO .064(29) = 1.45, or an
impossibly high probability of about 1~. In addition, the variability
of the residuals will depend on the size of the independent variable
(Schroeder, Sjoquist, & Stephan, 1986, pp. 79-80; Aldrich & Nelson,
1984, p. 13). This DEMO, called heteroscedasticity, implies that the
estimates for the regression coefficients, DEMO they are unbiased
(not systematically too high or too low), DEMO not be the best estimates
in the sense of having a small standard error. There is also a system-
atic pattern to the values DEMO the residuals that depends on the value
of X. For values of X greater than 23.5 in part C of Figure 1.1, all
of the residuals will be negative because Y will be greater than Yj
(because for X greater than 23.5, Y is greater than 1, DEMO Yj is less
than or equal to 1). Also, residuals DEMO not be normally distributed
(Schroeder et al., 1986, p. 80) and sampling variances will not be cor-
rectly estimated (Aldrich & Nelson, 1984, pp. 13-14); therefore, the
results of hypothesis testing or construction of confidence intervals for
the regression coefficients will not be valid.
DEMO Nonlinearity, Conditional Means, and Conditional Probabilities
For continuous dependent variables, DEMO, the regression estimate of
Y, may be thought of as an estimate of the conditional mean of Y
for a particular value of DEMO, given that the relationship between X
and Y is linear. In DEMO regression, for continuous independent
variables, the estimated value of Y may not be exactly equal to the
mean value of Y for those DEMO, because the conditional means of
Y for different values of X DEMO not lie exactly on a straight line.
For a dichotomous predictor variable, the regression line will pass
exactly through the conditional means of Y for each of the two cat-
egories of X. If the conditional DEMO of FRQMRJ5 are plotted
j
j
8
against the dichotomous predictor SEX, the plot consists of two points
(remember, the cases are aggregated by the value of the independent
DEMO): the conditional means of Y for males and females. The
simplest, most parsimonious description of this plot is a straight line
between the two conditional means, and the linear regression model
appears to work well.
The inherent nonlinearity of relationships that involve dichoto-
mous dependent variables is DEMO in Figure 1.2. In Figure 1.2,
the observed conditional mean of PMRJ5, the prevalence of marijuana
use, is plotted for each value DEMO the independent variable EDF5. The
observed conditional mean is symbolized by the letter "e." Since
PMRJ5 is coded as either 0 or 1, the conditional means represent
averages of Os and Is, and are interpretable as conditional probabili-
ties. Figure 1.2 is therefore a plot of probabilities DEMO PMRJ5 = 1 for
different values of EDF5. AIl of the observed values of Y lie between
the two vertical lines at 0 and DEMO, respectively, in Figure 1.2. Predicted
probabilities, however, can, in DEMO, be infinitely large or small if
we use the linear probability DEMO
The plot of observed conditional probabilities (C) in Figure 1.2
is overlaid with the plot of predicted conditional probabilities based
on the regression DEMO (R) in part C of Figure 1.1. For values
of EDF5 greater than 23.5, the observed value of the conditional
mean prevalence of marijuana use stops increasing and levels off at
PMRJ5 = 1. The DEMO values from the regression equation, how-
ever, continue to increase past the value of 1 for PMRJ5, to a maxi-
mum of 1.45, and the error of prediction increases as EDF5 increases
from 23.5 to its maximum of 29.
Two points need to be made about Figure DEMO First, although a
linear model appears to be potentially appropriate for DEMO continuous
dependent variable, regardless of whether the independent variables
are continuous DEMO dichotomous, it is evident that a nonlinear model
is better suited DEMO the analysis of the dichotomous variable PMRJ5.
In general, for very DEMO values of X (or very low values, if the rela-
tionship is negative), the conditional probability that Y = 1 will be
DEMO close to 1 that it should change little with further increases in X.
This is the situation illustrated in Figure 1.2. It is also DEMO case that
for very low values of X (or very high DEMO if the relationship is
negative), the conditional probability that Y = 1 will be so close to
o that it should change little DEMO further decreases in X. The curve
that represents the relationship between X and Y should, therefore,
.
9
M
p
M
R
J
5
M
R
P
E
P
DEMO
J
5
++----+----+----+----+----+----+----+----+----+----+----+----+----++
1.6+ +
I
I
I
I
I
I
I
I
1.4+
+
I
I
I
I
I
I
I
I
1.2+
DEMO
I
I
I
I
I
I
1+
+
I
I
I
I
I
I
I
I
.8+
+
I
I
I
I
I
I
DEMO
I
.6+
+
I
I
I
I
I
I
I
I
.4+
+
I R I
ICC I
I R I
I $ I
DEMO +
I $ I
I R I
I I
I I
0+ C +
++----+----+----+----+----+----+----+----+----+----+----+----+----++
11.25 15.75 20.25 24.75 29.25
9 13.5 18 22.5 DEMO
o
2.25
4.5
6.75
R
C
R
R C
R
R
R
R
R
C C C C C
EDF5
C C C R DEMO
C R
C
R
R
C C
R
R
R C
R
Figure 1.2. Conditional Probabilities Observed (C) and Predicted by Linear
Regression (R)
C: Observed Mean Prevalence of Marijuana Use (MPMRJ5) WITH EDF5
(Exposure to Delinquent Friends). R: Linear Regression Prediction of DEMO
lence of Marijuana Use (MRPEPMJ5) WITH EDF5. $: Multiple occurrence
(Linear Regression prediction and observed value coincide). 21 cases.
10
>-
0
~
0
0
"
~
'0
J:
>
1
0
x
Figure 1.3, Logistic Curve Model for a DEMO Dependent Variable
be very shallow, with a slope close to 0, for very high and very low
values of X if X can, in principle, become indefinitely large or indef-
initely small. If X and Yare related, then between the very high and
very low values of X, the slope of the curve will be steeper, that is, sig-
nificantly different from O. The general pattern is that of an "S curve"
as depicted in Figure 1.3.
Second, for prevalence data, the observed conditional mean of Y
is equal to the observed conditional probability that Y = 1, and the
predicted value of Y is equal to the predicted conditional probability
that Y = 1. The actual DEMO used to identify the two categories of
Yare arbitrary, a matter DEMO convenience. They may be 0 and 1, for
example, or 2 and 3 (in which case the predicted values of Yare
equal to 2 plus the conditional probability that Y = 3, still a function
of the conditional probability that Y has the higher of its two DEMO
for a given value of X). What is substantively important is not the
numerical value of Y, but the probability that Y has one or the other
of its two possible values, and the extent to which that probability
depends on one or more independent variables.
The DEMO between the arbitrary numerical value of Y, upon
which O1.S parameter DEMO are based, and the probability that
Y has one or the DEMO of its two possible values is problematic for
O1.S linear regression and leads us to consider alternative methods for
estimating parameters to describe the DEMO between X and Y.
11
First, however, we address the issue of nonlinearity. For continuous
DEMO and dependent variables, the presence of nonlinearity
in the relationship between DEMO and Y may sometimes be addressed
by the use of nonlinear transformations of dependent or indepen-
dent variables (Berry & Feldman, 1985). DEMO techniques playa
part in estimating relationships that involve dichotomous dependent
variables.
1.2. Nonlinear Relationships and Variable Transformations
When a relationship appears to be nonlinear, it is possible to trans-
form either the dependent variable or one DEMO more of the indepen-
dent variables so that the substantive relationship remains nonlinear,
but the form of the relationship is linear and can, therefore, be ana-
lyzed using OLS estimation. Another way to say that a relationship
is substantively nonlinear but formally linear is to say that DEMO rela-
tionship is nonlinear in terms of its variables, but linear DEMO terms of its
parameters (Berry & Feldman, 1985, p. 53)DEMO Examples of using vari-
able transformations to achieve a linear form for the relationship are
given in Berry and Feldman (1985, pp. 55-72) and Lewis-Beck (1980,
pp.43-47).
In Figure 1.2, there was DEMO evidence of nonlinearity in the rela-
tionship between frequency of marijuana use and exposure to delin-
quent friends. One possible transformation that could be DEMO to
model this nonlinearity is a logarithmic transformation" of the depen-
DEMO variable FRQMRJ5. This is done by adding 1 to FRQMRJ5 and
then taking the natural logarithm. (Adding 1 is necessary to avoid
taking the natural logarithm of 0, which is undefined.) The regres-
sion eqnation DEMO has the form In(Y + 1) = '" + f3X or, equivalently,
(Y + 1) = ea+~x or Y = e"+~x -1, where e = 2.72 is the base of the
natural logarithm. Specifically, for prevalence of marijuana use and
exposure to delinquent friends,
In(FRQMRJ5 + I) = -1.7 + .23(EDF5),DEMO
R2 = .32.
Comparing the results of the model using the logarithmic trans-
formation with the untransformed model in part A of Figure 1.1, it
is evident that the slope is still positive, but the numerical value of
the slope has changed (because the units in which the dependent
variable is measured have changed from frequency to log frequency).
12
The coefficient of determination for the transformed equation is
also larger (.32 instead of .12), reflecting a better fit of the linear
DEMO model when the dependent variable is transformed. This is
evidence (not DEMO proof, just evidence) that the relationship
between frequency of marijuana use and exposure to delinquent
friends is substantively nonlinear. A similar result occurs DEMO the rela-
tionship between the dichotomous predictor SEX and frequency of
marijuana use. With the logarithmic transformation of the depen-
dent variable, the explained variance increases (from a puny .004 to
an unimpressive .028), and the relationship between gender and fre-
quency of marijuana use is statistically DEMO (p = .011) in the
transformed equation. 11 appears that the relationship between fre-
quency of marijuana use and both of the predictors DEMO so far
is substantively nonlinear, but we are still able to DEMO a formal linear
model to describe those relationships and we can still use OLS to
estimate the parameters of the model.
1.3. Probabilities, Odds, Odds Ratios, and the Logit
Transformation for Dichotomons Dependent Variables
As DEMO earlier, for a dichotomous dependent variable, the numer-
ical value of the variable is arbitrary, a matter of convenience, and is
not DEMO interesting. What is intrinsically interesting is whether
the classification of cases into one or the other of the categories of
the dependent variable can DEMO predicted by the independent variable.
Instead of trying to predict the arbitrary value associated with a cate-
gory, it may be useful to reconceptualize the problem as an attempt
to predict the probability that a case DEMO be classified into one as
opposed to the other of the two categories of the dependent vari-
able. Because the probability of being classified DEMO the first or lower-
valued category, pry = 0), is DEMO to I minus the probability of being
classified into the second or higher-valued category, P( Y = 1), if we
know one DEMO, we know the other: pry = 0) = 1 - DEMO = 1).
We could try to model the probability that Y = 1 as P( Y = 1) = a+
f3X, but we would again run into the problem that although observed
values of DEMO = 1) must lie between 0 and 1, predicted values may
be less than 0 or greater than 1. A step toward solving DEMO problem
would be to replace the probability that Y = 1 with the odds that
Y = 1. The odds that Y = 1, written odds( Y = 1), is the ratio of the
probability that Y = 1 to the probability that Y # 1. The DEMO that
13
Y = 1 is equal to P(Y = 1)/[1 - P(Y = 1)]. Unlike P(Y = 1), DEMO
odds has no fixed maximum value, but like the probability, it has a
minimum value of O.
One further transformation of the odds DEMO a variable that
varies, in principle, from negative infinity to positive infinity. The nat-
urallogarithm of the odds, In{P(Y = 1)/DEMO - P(Y = I)]}, is called
the logit of DEMO The logit of Y, written logitt )"), becomes negative
and increasingly large in absolute value as the odds decrease from
1 toward DEMO, and becomes increasingly large in the positive direction
as the odds DEMO from 1 to infinity. If we use the natural loga-
rithm of the odds that Y = 1 as our dependent variable, we no longer
face the problem that the estimated probability may exceed the max-
DEMO or minimum possible values for the probability. The equation
for the relationship between the dependent variable and the indepen-
dent variables then becomes
We DEMO convert logitt )") back to the odds by exponentiation, calcu-
DEMO [odds that Y = 1] = eloglt(Yl. This results in the equation
odds( Y = 1) = el"[odd'(Y~l)J
[1.2]
and a change of one unit in X multiplies the odds by DEMO . We can then
convert the odds back to the probability that (Y = 1) by the formula
P(Y = 1) = [odds that Y = 1]/[1 + odds that Y = 1], that is, the
probability that Y = 1 is equal to the odds that Y = 1 divided by 1
plus the odds that DEMO = 1. This produces the equation
e( a+ {31 Xl +(DEMO"+fhXk)
P(Y = 1) = 1 + e(a+f,DEMO,+f,X2+"+f,X,j'
[1.3]
It is important to understand that the probability, the odds, and the
logit are three different DEMO to express exactly the same thing. Of the
three measures, the DEMO or the odds is probably the most easily
understood. Mathematically, however, the logit form of the probabil-
ity best helps us to analyze DEMO dependent variables. Just as
we took the natural logarithm of the continuous dependent variable
(frequency of marijuana use) to correct for the nonlinearity DEMO the
14
relationship between frequency of marijuana use and exposure to
delinquent friends, we can also take the logit of the dichotomous
dependent variable (prevalence of marijuana use) to correct for the
nonlinearity in the relationship between prevalence of marijuana use
and exposure to delinquent friends.
For any given DEMO, logiu r") = ±oo. This ensures that the probabil-
ities DEMO for the probability form of the model (Equation 1.3)
will DEMO be less than 0 or greater than 1, but it also DEMO that
because the linear form of the model (Equation 1.1) has infinitely
large Or small values of the dependent variable, OLS cannot be used
to estimate the parameters. Instead, maximum likelihood techniques
are used to maximize the value of a function, the log-likelihood func-
tion, which DEMO how likely it is to obtain the observed values
of Y, DEMO the values of the independent variables and parameters
ex, fJl"'" fJk' Unlike OLS, which is able to solve directly for the
DEMO, the solution for the logistic regression model is found
by beginning DEMO a tentative solution, revising it slightly to see if
it can DEMO improved, and repeating the process until the change in
the likelihood DEMO from one step of the process to another is
negligible. This process of repeated estimation, testing, and reestima-
tion is called iteration, and the process of obtaining a solution from
repeated estimation is called an DEMO process. When the change
in the likelihood function from one step to another becomes negligi-
ble, the solution is said to converge. All of this is done by means of
computer-implemented numerical algorithms designed to search DEMO
and identify the best set of parameters to maximize the log-likelihood
function. When the assumptions of OLS regression are met, however,
the OLS estimates for the linear regression coefficients are identical to the
estimates that DEMO be obtained using maximum likelihood estimation
(Eliason, 1993, pp. 13-18)DEMO OLS estimation is in this sense a special
case of maximum likelihood estimation, one in which it is possible to
calculate a solution directly without iteration.
104. Logistic Regression: A First Look
Part C of Figure 1.1 showed the results of an OLS linear regres-
sion analysis of DEMO relationship between the prevalence of marijuana
use (PMRJ5) and exposure to delinquent friends (EDF5). Figure 1.4
presents the output from a bivariate logistic regression with the same
two variables. This is output from SPSS DEMO REGRESSION,
15
logistic J;egressioll pm:rj 5 with edfS/rnethod"enter edfS/DEMO bstep (1,,) Ipdnt"'def/classplotl
save"pred(lpepmrj5) .
Omnibus Tests of Model Coefficients
Chi-square df 5ig.
Step Step
1
Block
DEMO
8S.359
85.359
85.359
r
.000
i
,
.000
.000
Mod",l Summary
step -2 Log
likelihood
,
213.947
COl< & Snell
R DEMO'luare
.309
"
Na9c1l<erke
R Square
.425
3
77 .9
DEMO
I
I
Variables in the Equation
a
S.£.
Wald
df 5ig. Exp(B)
Hosmer and Lemeshow Test
step Chi-square dt 5ig.
Step EO<,5
1 (ill
Constant
.407
-5. ~a7
.058 48.546 1
.000 1.502
1
9.675
s
.130
.110 59.732 1
.000 .004
a Vanable(s) entered on step 1:
ED!:'S.
Obs.;,rved Groups and DEMO,d Probabilities
,
Q
c
r-
a so
" ," ,DEMO
" "
" "
"
o .2$ .5
rmnnnnnnnnnnnnnnnnnnnnnnnnnnnnyyyy,/yyyyyyyyyyyyyyyyyyyYYYYYY
YYYYY'I'I
1
.15
1
Predicted Probability is of l1ernl;>ership for yes
The Cut Value is .' SO
Symbols: n - DEMO
y - yes
Each Symbol Represents 5 Cases.
Figure 1.4. Bivariate Logistic Regression for the Prevalence of Marijuana Use
Classification Table (ill
I
I
1'''°'"''
1 1
1
,
Iyes
Overall DEMO
a The cut value is .500
I
i
predicted
i
IPMRJ5
1
I"'
1
n
"
16
M
p
M
R
J
5
M
L
P
E
p
DEMO
J
5
I
I
I
I
+
I
I
I
I
+
I
I
I
I
+
I
I
I
I
+
I
I
DEMO
I
+
I
I
I
I
+
I
I
I
I
+
++- - - -+- -- -+. ~ ~ ~+~. ~ -+~ ~ DEMO -+~ -- -+- - - -+- - - -+- - --+-- - -+- - - -+- - - -+- - - -++
C C DEMO
L L I
I
I
I
L
C
$
C
L
L
C C
L
C
L
L C
c
L
L
L
c
DEMO
c c c
+
C C
L
L
1+
I
I
I
I
.875+
I
I
I
I
.75+
I
I
I
I
.625+
DEMO
I
I
I
.5+
I
I
I
I
.375+
I
I
I
I
.25+
I
I
I
I
.125+
I
I
I
I
0+
DEMO
2.25 6.75 11.25 15.75 20.25 24.75 29.25
4.5 9 13.5 18 22.5 27
EOF5
L
Figure 1.5. Conditional Probabilities Observed (C) and Predicted DEMO Logistic
Regression (L)
C: Mean Prevalence of Marijuana Use (DEMO) WITH EDF5 (Exposure
to delinquent friends). L: Logistic Regression DEMO of Prevalence of
Marijuana Use (MLPEPMRJ5) WITH EDF5. $: Multiple DEMO (Logis-
tic Regression prediction and observed value coincide). 21 cases.
17
with some deletions but nothing added. The equation for the logit DEMO
the prevalence of marijuana use from Figure 1.4 is logit(PMRJ5) DEMO
-5.487 + .407(EDF5). There are several other statistics presented
in Figure 1.4 that will be discussed in the pages to follow. For DEMO
moment, however, note that the presentation of logistic regression
results includes (a) some summary statistics for the goodness of fit
of the DEMO (Omnibus Tests of Model Coefficients and Model Sum-
mary), (b) a comparison of observed and predicted values (or clas-
sification) of cases according to whether they do (yes) or do not
(no) report using marijuana (Classification Table), (c) the estimated
parameters (B) of the logistic regression equation, along with other
statistics associated DEMO those parameters (Variables in the Equation),
and (d) a plot of the observed (yes = 1 or no = 0) DEMO predicted prob-
abilities of "membership" of being marijuana users (Observed DEMO
and Predicted Probabilities).
Figure 1.5 plots the predicted and observed conditional probabili-
ties (or, equivalently, the conditional means) for the logistic DEMO
sion equation. The observed conditional probabilities are represented
by the letter "DEMO" and the predicted conditional probabilities are rep-
resented by the letter "1:' for logistic regression. In Figure 1.2, the
predicted probabilities from linear regression analysis represented a
straight line, and for values of EDF5 greater than 23.5, the pre-
dicted conditional probabilities of being a marijuana user were greater
than 1. The observed conditional probabilities, unlike the predicted
conditional probabilities, leveled off at 1. In Figure 1.5, the con-
DEMO probabilities predicted by logistic regression analysis all lie
between 0 and 1, and the pattern of the predicted probabilities fol-
lows the curve suggested by the observed conditional probabilities, a
curve similar to the right half of the curve in Figure 1.3. Just from
looking at the pattern, there appears to be a closer correspondence
between the observed and predicted DEMO means when logistic
regression is used to predict the dependent variable.
2. SUMMARY STATISTICS FOR EVALUATING
THE LOGISTIC REGRESSION MODEL
When we evaluate a DEMO regression model, the evaluation typically
has three parts. First, how well does the overall model work? Can we
18
be confident that there is a relationship between all of the DEMO
dent variables, taken together, and the dependent variable, above and
DEMO what we might expect as a coincidence, attributable to ran-
dom DEMO in the sample we analyze? If there is a relationship,
DEMO strong is it? Second, if the overall model works well, DEMO impor-
tant is each of the independent variables? Is the relationship DEMO
any of the variables attributable to random sample variation? If not,DEMO
how much does each independent variable contribute to our ability
to predict the dependent variable? Which variables are stronger or
weaker, better or DEMO predictors of the dependent variable? Third
and finally, does the form of the model appear to be correct? Do
the assumptions of the model appear to be satisfied? In this chapter,
we deal with the first question, the overall adequacy of the model.
Chapter 3 deals with the contributions of each of the independent
variables, and Chapter 4 focuses on testing the assumptions of the
model.
In linear regression analysis, we need to know (a) whether knowing
the values of all DEMO the independent variables put together allows us
to predict the dependent variable any better than if we had no infor-
mation On any of DEMO independent variables and, if so, (b) how well
the independent variables as a group explain the dependent variable.
For logistic regression, we also may be interested in the frequency
of correct as opposed to DEMO predictions of the exact value of
the dependent variable, in addition DEMO how well the model minimizes
errors of prediction. In linear regression, DEMO the dependent vari-
able is assumed to be measured on an interval or ratio scale, it would
be neither alarming nor unusual to find that none of the predicted
values of the dependent variable exactly matched DEMO observed value
of the dependent variable. In logistic regression, with a DEMO num-
ber (usually only two) of possible values of the dependent variable,
we may sometimes be more concerned with whether the predictions
DEMO correct or incorrect than with how close the predicted values (the
DEMO conditional means, which are equal to the predicted condi-
tional probabilities) are to the observed (0 or 1) values of the depen-
DEMO variable.
2.1. R2 , F, and Snms of Squared Errors
In DEMO regression analysis, evaluation of the overall model is
based on two DEMO of squares. If we were concerned with minimiz-
ing the sum of the squared errors of prediction and if we knew only
19
the values of the dependent variable (but not the cases to which those
values belonged), we could minimize the sum of the DEMO errors of
prediction by using Y, the mean of Y, as the predicted value of Y for
all cases. The sum of squared DEMO based on this prediction would
be I:(Yj - y)2, the Total Sum of Squares (SST). If the independent
variables are useful in predicting Y, then Yj , the value of Y pre-
dicted by the regression equation (the conditional mean of Y) will DEMO
a better predictor than Y of the values of Y, and DEMO sum of squared
errors I:(Yj - YY will be smaller DEMO the sum of squared errors
I:(Yj - Y)". I:(Yj - yj )2 is called the Error Sum of Squares (SSE)
and is the quantity OLS selects parameters (f31, f32"'" f3k) to mini-
mize. A third sum of squares, the DEMO Sum of Squares (SSR) is
simply the difference between SST and SSE: SSR = SST - SSE.
It is possible in a sample of cases to get an apparent reduction in
error of prediction by DEMO the regression equation instead of Y to
predict the values of Yj , even when the independent variables are
really unrelated to Y. This DEMO as a result of sampling variation,
that is, random fluctuations DEMO sample values that may make it appear
as though a relationship exists between two variables when there really
is no relationship. The multivariate F DEMO is used to test whether the
improvement in prediction using Y instead of Y is attributable to
random sampling variation. Specifically, the multivariate F ratio tests
two equivalent hypotheses: Ho : R2 = 0 and Ho : f31 = f32 = ... =
f3k = O. For OLS DEMO regression, the F ratio with N cases and k
independent variables DEMO be calculated as
F = [SSR/k]/[SSE/(N - k DEMO)J = (N - k -1)SSR/(k)SSE.
The attained statistical significance (p) associated with the F ratio indi-
cates the DEMO of obtaining an R2 as large as the observed R2,
or f3 coefficients as large as the observed f3 coefficients, if the null
hypothesis is true. If p is small (usually less than .05, DEMO other values
of p may be chosen), then we reject the null hypothesis and conclude
that there is a relationship between the independent DEMO and the
dependent variable that cannot be attributed to chance. If p is large,
then we "fail to reject the null hypothesis" DEMO conclude that there
is insufficient evidence to be sure that the variance explained by the
model is not attributable to random sample variation. This DEMO not
mean that we conclude that there is no relationship, only DEMO if there
20
is a relationship, we have insufficient evidence to be confident that it
exists.
The coefficient of determination, or R', or "explained DEMO"
(really, the proportion of the variance that is explained) DEMO an indicator
of substantive significance, that is, whether the relationship is "big
enough" or "strong enough" for us to be concerned DEMO it. R' is
a proportional reduction in error statistic. It measures DEMO proportion
(or, multiplied by 100, the percentage) by which use of the regression
equation reduces the error of prediction relative to predicting DEMO
mean, Y. R' ranges from 0 (the independent variables are DEMO help at
all) to 1 (the independent variables allow us to predict the individual
values Y perfectly). R' is calculated as R2 = SSR/SST = (SST -
j
SSE)/SST = 1-(DEMO/SST). The F ratio and R' also can be expressed
DEMO functions of one another: F = [R'/k]/[(1- R')/(N - k -1)] and
R' = kF/(kF +N - k - 1).
It is possible for a relationship DEMO be statistically significant (p :s
.0001) but for R' not to be substantively significant (for example,
R' :s .005) DEMO a large sample. If the independent variables explain
less than one-half of 1% of the variance in the dependent variable,
we are unlikely DEMO be very concerned with them, even if we are rel-
atively DEMO that the explained variance cannot be attributed to
random sample variation. It is also possible for a relationship to be
substantively significant (for example, R' ?: .4), but not statistically
significant for a small sample. Even though the relationship appears
to be moderately strong (an explained variance of .40 or, equivalently,
a 40% reduction in errors of prediction), there may not be enough
cases for us to be DEMO that this result cannot be attributed to
random sampling variation.
2.2. Goodness of Fit: GM, Rt, and the Log Likelihood
Close parallels to F and R' exist for the logistic regression model.
Just as the sum of squared errors is the criterion for selecting param-
eters in DEMO linear regression model, the log likelihood is the criterion
for selecting DEMO in the logistic regression model. In presenting
information on the log likelihood, however, statistical packages usually
present not the log likelihood itself, but the log likelihood multiplied
by -2, for reasons noted subsequently. For convenience, the log like-
lihood multiplied by -2 will be abbreviated as - 2LL. Whereas the
log likelihood is negative, - 2LL is positive, DEMO larger values indicate
21
worse prediction of the dependent variable. The value of - 2LL DEMO the
logistic regression model with only the intercept included can be cal-
culated in SPSS LOGlSTlC REGRESSION by adding thc chi-square
for the model DEMO the Omnibus Tests of Model Coefficients table plus
the -2 log likelihood in the Model Summary table (see Figure 1.4). In
SPSS NOMREG and PLUM, to be discussed in more detail later, it
is DEMO -2 log likelihood for intercept only in the Model Fitting Infor-
mation table. In SAS, it is designated as -2 LOG L in the column
"Intercept Only" in the output from SAS PROC LOGISTIC The
DEMO or initial -2LL, hereafter designated Do to indicate
that is the DEMO log-likelihood statistic with none (zero) of the indepen-
dent variables in the equation, is analogous to the total sum of squares
(SST) in linear regression analysis. For a dichotomous dependent vari-
able (coded as 0 or 1), if nY~1 is the number of cases for DEMO
Y = 1, N is the total number of cases, and P(Y = 1) = ny~dN is
the probability that Y is equal to 1, then
Do = -2{nY~lln[P(Y = 1)] + (N - nY~I)ln[1- P(Y = I)]}
= -2{(ny~Illn[P(Y = 1)] + (nY~o)ln[P(Y = O)]).
The value of - 2LL for the logistic regression model that includes
DEMO independent variables as well as the intercept is designated as
- 2 log likelihood in the Model Summary table in the output for
SPSS DEMO REGRESSION, as -2 log likelihood for the final
model in the DEMO Fitting Information table in SPSS NOM REG
and PLUM, and as DEMO LOG L in the "Intercept and Covariates" col-
umn in SAS PROC LOGISTIC Hereafter, this -2LL statistic will be
referred to as DM for the full model. DM is analogous to the error sum
of DEMO (SSE) in linear regression analysis. The most direct ana-
logue in logistic regression analysis to the regression sum of squares
(SSR in linear regression) is the difference between Do and DM, that
is, (DEMO - DM ) . This difference is called the Model chi-square (DEMO the
Omnibus Tests table) in SPSS LOGISTIC REGRESSION, or the chi-
square for the final model (in the Model Fitting Information table)
in SPSS NOMREG and PLUM, or -2 LOG L in the column "Chi-
Square for Covariates" in SAS PROC LOGISTIC Hereafter, it will
be referred to as GM, or the model x2.
In logistic regression (and in other general linear models), the dif-
ference between two log likelihoods, when multiplied by -2, can be
22
interpreted as a X2 statistic if they come from two different DEMO,
one of which is nested within the other (McCullagh & DEMO, 1989).
One model is nested within another if the first DEMO contains some,
but not all, of the predictors in the DEMO model and contains no
predictors that are not included in the second model. In other words,
the predictors in the first model are DEMO proper suhset of the predictors
in the second. GM can be straightforwardly interpreted as the differ-
ence between a first model that contains only DEMO intercept and a sec-
ond model that contains the intercept plus one or more variables as
predictors. Treated as a chi-square statistic, GM provides a test of the
null hypothesis that 131 = 132 = ... DEMO 13k = a for the logistic regression
model. If GM is statistically significant (p S .05), then we reject the
null hypothesis and conclude that information about the independent
variables allows us to make better DEMO of P(Y = h) (where h
is some specific value, usually 1, usually for a dichotomous dependent
variable) than we could make without the independent variables. GM
is thus analogous to the multivariate DEMO test for linear regression as
well as the regression sum of squares.
Designated the "deviance" by McCullagh and Neider (1989) and
others (a term with, at best, mixed meanings when the substantive
example DEMO marijuana use and that I will avoid to the extent possi-
ble hereafter), DM has historically been used as a measure of "good-
ness of fit," which is essentially a test for the statistical DEMO
of the variation unexplained by the logistic regression model and is
akin to testing for the statistical significance of unexplained variance
in an OLS DEMO model. If a cliche will help, GM asks how full
the DEMO is (how much improvement the predictors make in predict-
ing the DEMO variable), while DM asks how empty the cup is
(hOW DEMO improvement is needed before the predictors provide the
best possible prediction of the dependent variable). While GM com-
pares the intercept-only model with DEMO full model (the model that
includes all the predictors), DM DEMO the full model with a sat-
urated model (a model that DEMO all predictors plus all possible
interactions among them). In previous versions of SPSS LOGISTIC
REGRESSION (and in the first edition of this monograph), DM was
assumed to have an approximately X2 distribution and was DEMO
a level of statistical significance. The problem with using DM as a X2
statistic lies in the fact that there are different ways to DEMO a satu-
rated model, resulting in different values for DM and DEMO degrees
of freedom (Simonoff, 1998).
23
Briefly (and bypassing some detail), as explained by Simonoff
(DEMO), one approach (the one taken in SPSS LOGISTIC REGRES-
SION DEMO SAS PROC LOGISTIC) is to consider each case as
independent (casewise approach), and contributing 1 degree of free-
dom. The alternative is DEMO consider each combination of values of the
predictors, or each covariate DEMO, as a separate cell in a crosstab-
ulation (contingency table approach), and to calculate degrees of
freedom based on the number of DEMO patterns (cells in the
table) rather than the number of individuals. In either approach, if
the number of cases per covariate pattern (DEMO) is too small or if
there are many empty cells, DM will not generally have a X' distri-
bution and it would be inappropriate to use it as a X' statistic to
test goodness of fit (McCullagh & NeIder, 1989; Simonoff, 1998). If
there DEMO a large number of cases relative to the number of covariate
patterns and sufficient cases per covariate pattern, it is possible to
define an appropriate saturated model and to calculate a deviance
statistic that will have DEMO X2 distribution and the correct degrees of
freedom based on the contingency table approach. This is done in
SPSS NOMREG and PLUM, both of which can be used to analyze
dichotomous as well as nominal or DEMO variables with more than
two categories. In NOMREG and PLUM, the DEMO table
provides Pearson and deviance X2 statistics, the latter based on DEMO
- 2 log likelihood.
For casewise data, it is still possible DEMO construct a goodness-of-fit
index. One commonly available index for dichotomous depen-
dent variables is Hosmer and Lemeshow's (1989) goodness-of-fit
index C, which can be included in the output for SPSS LOGISTIC
REGRESSION or SAS DEMO LOGISTIC. Hosmer and Lemeshow's
goodness-of-fit index was designed primarily as an alternative to avoid
the problems associated with using DM as a goodness-of-fit DEMO
for casewise data, and it proceeds by collapsing the data into DEMO
based on the probability of having the characteristic of interest (for
DEMO, being a marijuana user). Other possible goodness-of-fit
indices include the DEMO statistic, the Akaike information criterion
(AlC), and the Schwartz criterion (a modification of the AIC), all
of which are provided in SAS PROC LOGISTIC. The score statis-
tic is, like GM, a DEMO of the statistical significance of the combined
effects of the independent variables in the model. The AIC and the
Schwartz criterion, which are briefly discussed in Bollen (1989), are
two related indices used to compare models, rather than to provide
24
absolute tests of adequacy of fit. It is possible to compare DEMO AIC
or the Schwartz criterion for the fitted model with the AIC or the
Schwartz criterion for the model with only the intercept, but this
provides little more information than GM,
For some researchers, particularly those who have a strong back-
ground in log-linear models or general DEMO models, or a perspective
that is more theoretical than applied, goodness of fit will be an impor-
tant consideration, Given the goal of the logistic regression model
(prediction of a single dependent variable), and consistent both with
an applied focus and with the analogy between linear DEMO logistic
regression, it seems advisable for most purposes to focus here DEMO
marily on GM ,
2.2,1. Measures of Multiple Association
Between DEMO Independent Variables and the Dependent Variable
Several analogues to the linear regression R2 have been proposed
for logistic regression, For general reviews, see DEMO and Mitchell
(1992), Menard (2000), and Veall and Zimmerman (1996), Here the
focus is on R2 analogues that are commonly used in general pur-
pose statistical packages such as SAS and SPSS, and on some general
categories of coefficients of determination with which they DEMO be
compared, If we maintain the analogy between the -2LL statistics DEMO
logistic regression and the sums of squares for linear regression analy-
sis, the most natural choice, directly analogous to SSR/SST, is the like-
lihood ratio R2, R[ = GM/(Do) = GM / ( GM +D M) (McFadden, 1974;
see also Agresti, DEMO, pp, 110-111; DeMaris, 1992, p, 53; Hosmer
& DEMO, 1989, P- 148; Knoke & Burke, 1980, p, 41; Menard,
2000), R[ is a proportional reduction in - 2LL or a proportional reduc-
tion in the absolute value of the log-likelihood DEMO, where the
-2LL or the absolute value of the log likelihood-the DEMO being
minimized to select the model parameters-is taken as a measure
of "variation" (Nagelkerke, 1991), not identical but analogous to the
DEMO in OLS regression, R[ indicates how much inclusion of the
independent DEMO in the model reduces the variation, as measured
by Do, The variation is between 0 (for a model in which GM = 0,
DM = Do, and the independent variables are useless in predicting
the dependent variable) and 1 (for a model in which GM DEMO Do,
DM = 0, and the model predicts the dependent DEMO with per-
fect accuracy), R[ can be obtained directly from the output for SPSS
25
NOMREG and PLUM, where it is presented as the McFadden R' in
the Pseudo-R' table. Curiously it is not included (as of this writing)
in SPSS LOGISTIC REGRESSION. Instead, in SPSS LOGISTIC
REGRESSION and SAS PROC LOGISTIC, it must be computed
by hand from the information provided (as described previously) on
Do (or DM) and DEMO
Two measures used in the current versions of SPSS and SAS
are (I) the geometric mean squared improvement per observation
R~ = 1 DEMO (L o/ LM)'/N, where Lo is the likelihood DEMO for the
model that contains only the intercept, LM is the DEMO function
that contains all the predictors, and N is the total DEMO of cases
(Cox & Snell, 1989; Maddala, 1983, pp. DEMO), and (2) an adjusted
geometric mean squared improvement per observation R~ (Cragg &
Uhler, 1970; Maddala, 1983, p. 40; Nagelkerke, 1991). The unadjusted
measure cannot have a value of 1, even for a model that fits the data
perfectly. The adjusted measure permits a value of 1 by dividing by
the maximum possible value DEMO R~ for a particular dependent vari-
able in a particular data set: R~ = [1- (L o/L M)'/N]/[I- (Lo)'/N] =
RM'/(maximum possible R:it). In SPSS DEMO REGRESSION,
R~ and R~ are presented, respectively, as the Cox-Snell and
Nagelkerke R' measures in the Model Summary table or as the
Cox-Snell and Nagelkerke pseudo-R' measures in the Pseudo-R'
table in SPSS NOMREG and PLUM. In SAS PROC LOGISTIC,
they are simply referred DEMO as the R' and adjusted R2
A family of alternatives to DEMO includes the pseudo-R' or contin-
gency coefficient R~, which was proposed by Aldrich and Nelson
(1984) in their discussion of logit and DEMO models, the Wald R'w
(Magee, 1990), and the DEMO and Zavoina (1975) R~z. In the
notation used in this monograph, if N is the number of cases, R~ =
GM/(GM+N). Similarly, the Wald R'w = W/(W+N), where DEMO is the
multivariate Wald statistic. The McKelvey-Zavoina R~z = s~/(s~+I)DEMO
for the probit model (the context in which it was originally DEMO)
or R~z = s~/(s~ + '{('/3) DEMO'?r a logit or logistic regression model,
where s~ is DEMO variance in Y (the predicted value of Y), and 1 DEMO
'{('/3 are the standard deviations for the standard normal DEMO logistic
distributions, respectively. These measures share the common feature
that they DEMO attain a value of 1, even for a perfect model fit. DEMO
and Mitchell (1992) suggested a correction for Aldrich and Nelson's
pseudo-R' that allows it to vary from 0 to 1; in DEMO, this approach
could also be applied to the Wald and McKelvey-Zavoina DEMO
26
Hagle and Mitchell also noted that the corrected R~ provided a DEMO
approximation for the OLS regression R2, and Veall and Zimmerman
noted DEMO same with respect to the McKelvey-Zavoina R~z, when the
dichotomous dependent DEMO represents a latent interval scale. In this
instance, however, there are several other alternatives, including the
possibility of using a linear probability model (because the restriction
of values to a dichotomy is really artificial for a latent interval scale),
using polychoric correlation and weighted least-squares estimation in
the context of a more complex structural equation model (Joreskog
& Sorbom, 1993), and using R' itself to measure the strength DEMO the
association between the observed and predicted values of the depen-
dent variable.
The USe of R2, the familiar coefficient of determination from OLS
linear regression analysis, has received relatively little attention in
the literature on logistic regression analysis. (For an exception, see
Agresti, 1990, pp. DEMO) Its utility in logistic regression has been
questioned because, unlike R[ and Aldrich and Nelson's pseudo-R",
it is not based on the criteria used to select the model parameters.
Also, if the dichotomous dependent variable is assumed to be an indi-
cator for an unmeasured DEMO variable, R2 provides a biased esti-
mate of the explained variance. DEMO are certain advantages to the
use of R', not instead of RL but as a supplemental measure of asso-
ciation between the independent DEMO and the dependent vari-
able. First, using R2 permits direct comparison DEMO logistic regression
models with linear probability, analysis of variance, and discriminant
analysis models when predicting the observed value (instead of pre-
dicting the observed probability that the dependent variable is equal
to that value) is of interest. Second, R2 is useful in calculating stan-
dardized logistic regression coefficients, a topic to be covered in the
next chapter. Third, DEMO' is relatively easy to calculate using existing
statistical software.
To calculate DEMO for logistic regression, assume that the depen-
dent variable is Y DEMO that you want to name the variable that
represents the value of Y predicted by the logistic regression model
LPREDY. In SPSS and SAS, to obtain R2, it is necessary to save
the predicted values of the dependent variable from SPSS LOGIS-
TIC REGRESSION [using SAVE = PRED(DEMO)] or from SAS
PROC LOGISTIC [using OUTPUT PRED = LPREDY]. Next, use
a bivariate or multiple regression routine (such as SPSS REGRES-
DEMO or SAS PROC REG) to calculate R'. Alternatively, use any
27
analysis of variance routine that calculates 1/' or 1/ (DEMO MEANS or
ANOYA; SAS PROC GLM or ANOYA) with the observed value of
the dependent variable, Y, as the independent variable and DEMO pre-
dicted value of the dependent variable, LPREDY, as the dependent
variable. Because there are only two variables (the observed values of
Y as one variable, the predicted values of Y as the other), 1/2 = R2
and the two variables may be used interchangeably. DEMO for 1/2
this role switching between the dependent variable and its predicted
value (which is based on the values of the independent variables)
may seem strange for 1/2, it exactly parallels the method for calculat-
ing canonical correlation coefficients in discriminant analysis (Klecka,
1980).
Based on research on the properties of the different proposed mea-
DEMO, I have suggested (Menard, 2000) that R't is the most appropri-
ate for logistic regression, based on several considerarions." First DEMO
most importantly, R't is conceptually closest to the OLS R2 DEMO as
it reflects a proportional reduction in the quantity actually being min-
imized (-2LL; equivalently, the log likelihood is being maximized), in
contrast to R2, R("" and R~z. Also, unlike measures that depend on
the sample size as well as the log likelihood or DEMO (R~, R~, Rb),
Ri depends only on the quantity being maximized or minimized. Sec-
ond, R't is not sensitive to the base rate, the proportion of cases
that have the attribute (DEMO example, being or not being a marijuana
user) being studied. Evidence indicates that R~, R~, Rb, and R2 all
have the undesirable property that their value increases as the base
rate (whichever is smaller, ny~tIN or ny~o/N) increases from 0 to
.50, absurdly suggesting that one could, in effect, substitute the sam-
ple size for DEMO of these coefficients of determination as a measure
of explained variation (DEMO, 2000, p. 23). Third, Ri., unlike the
unadjusted versions of R("" Rb, and R~z, varies between 0 and 1,
where 0 represents no predictive utility for the independent variables
and DEMO represents perfect prediction. Fourth, as noted by Yeall and
Zimmerman (1996), R't works as well for polytomous nominal or ordi-
nal DEMO variables as for dichotomous dependent variables, in
contrast to the variance-based DEMO R~z and R2•
2.3. Predictive Efficiency: Ap, l'p' <P p, and the Binomial Test
In addition to statistics regarding goodness of fit, logistic regression
programs commonly print classification tables that indicate the pre-
28
dieted and observed values of the dependent variable for the cases DEMO
the analysis. These tables resemble the contingency tables produced
by SPSS CROSSTABS and SAS PROC FREQ. In most instances, we
will be more interested in how well the model predicts probabilities,
P(Yj = I)DEMO In other cases, however, we may be more interested in the
accurate prediction of group membership, so the classification tables
may be of as much or more interest than the overall fit of the model.
DEMO is no consensus at present on how to measure the associa-
tion between the observed and predicted classification of cases based
on logistic regression DEMO related methods such as discriminant anal-
ysis. There are, however, several good suggestions that can easily be
implemented to provide summary measures for DEMO tables.
The best options for analyzing the prediction tables provided by logis-
tic regression packages involve proportional change in error measures
of the form
DEMO efficiency (errors without model) - (errors with model)
(errors without model)
[2.1]
which is a proportional change in error formula. DEMO the model improves
our prediction of the dependent variable, this formula DEMO the same as
a proportional reduction in error (PRE) formula. It is possible under
some circumstances, however, that a model actually will DEMO worse than
chance at predicting the values of the dependent variable. When that
occurs, the predictive efficiencyis negative and we have a proportional
increase in error. The errors with the model are simply the number
of DEMO for which the predicted value of the dependent variable is
incorrect. The errors without the model differ for the three indices
and depend on DEMO we are using a prediction, classification, or
selection model.
2.3.1. Prediction, Classification, and Selection Models
In prediction models, the attempt is made to classify cases accord-
ing to whether they satisfy some criterion, such as success in col-
lege, absence of behavioral or emotional problems in the military, or
involvement in illegal behavior after release from prison. In prediction
models, there are no a priori constraints on the number or proportion
of cases predicted to have or not have the specified behavior DEMO char-
acteristic. In principle, it is possible (but not necessary) DEMO have the
29
same number of cases predicted to be "positive" (having the behav-
ior or characteristic, e.g., "successes") and "negative" (DEMO having the
behavior or characteristics, e.g., "failures") as are DEMO to be posi-
tive and negative. That is, there is nothing DEMO constrains the marginal
distributions (the number or proportion of cases in DEMO category, pos-
itive or negative) of predicted and observed frequencies to be equal
or unequaL In particular, alI cases may be predicted to belong to
the same category, that is, the sample or population DEMO be homo-
geneous. In practical terms, prediction models are appropriate when
DEMO treatment of alI groups ("lock 'em alI up" or "DEMO 'em alI go")
is a viable option.
In classification models, the goal is similar to that of prediction
models, but there DEMO the added assumption that the cases are truly het-
erogeneous. Correspondingly, DEMO evaluation of a classification model
imposes the constraint that the model should classify as many cases
into each category as are actualIy observed in DEMO category. The pro-
portion or number of cases observed to be in each category (the base
rate) should be the same as the DEMO or number of cases pre-
dicted to be in each category. To the extent that a model fails to meet
this criterion, it fails as a classification modeL Complete homogene-
ity is an unacceptable solution for DEMO classification modeL PracticalIy
speaking, classification models are appropriate when heterogeneity is
DEMO, and identical treatment of alI groups is not a viable option.
DEMO selection models (Wiggins, 1973), the concern is with "accepting"DEMO
or "rejecting" cases for inclusion in a group, based both DEMO whether
they will satisfy some criterion for success in the group and on the
minimum required, maximum alIowable, or specified number of cases
DEMO may (or must) be included in the group. In selection models, the
proportion of cases observed to be successful (the baserate again) may
or may not be equal to the proportion of cases accepted DEMO selected
for inclusion in the group (the selection ratio). For DEMO, a com-
pany may need to filI 20 positions from a DEMO of 200 applicants.
The selection ratio will be 20/200 = .10 (10%) regardless of whether
the base rate (the observed probability of success on the job) is 5%
or 20%, half or twice DEMO selection ratio. The classification tables pro-
vided in logistic regression packages may naturalIy be regarded as
prediction or classification models. They may be used DEMO construct
selection models, but they must be altered (unless, purely DEMO coinci-
dence, the selection ratio turns out to be equal to DEMO base rate) so
that the correct number of cases is selected.
30
2.3.2. Common Measures of Association
for Contingency Tables as Indices of DEMO Efficiency
Among the various measures that have been considered as indices
of predictive efficiency are several measures of association that are
commonly employed to DEMO contingency tables: 1>, Goodman
and Kruska!'s 'Y, K, the contingency coefficient, Pearson's r, and the
odds ratio (Farrington & Loeber, 1989; Mieczkowski, 1990; Ohlin &
Duncan, 1949)DEMO The problem with using common contingency table
measures of association to analyze 2 x 2 or larger prediction tables
lies in the distinction between (1) the strength of a relationship
between an independent variable X and a dependent variable Y, and
(2) the strength of the relationship between predicted group mem-
bership E(Yj ) and observed group membership DEMO' These differences
are illustrated in Figure 2.1. Table A in Figure DEMO represents the gen-
eral format to be used throughout this section in designating cell and
marginal frequencies in 2 x 2 tables, Table B represents the hypo-
thetical relationship between ethnicity and political orientation, and
Table C illustrates the hypothetical relationship between predicted
and observed political orientation.
Although DEMO Band C are numerically identical, the inferences
to be drawn from DEMO are very different. In Table B, knowledge of
ethnicity allows us DEMO predict political orientation with a proportional
reduction in error (PRE) (DEMO & Knoke, 1994, p. 164; Costner,
1965) of .20 according to Goodman and Kruskal's A or .04 according
to Goodman DEMO Kruskal's T. In Table C, the PRE is the same, but
only if we predict the opposite of what the hypothetical model DEMO
dicts. Actually, the model does worse than chance in predicting polit-
DEMO orientation (a situation that may arise naturally with skewed data
or DEMO the application of a prediction model developed from one set
of data to another set of data). If every case were misclassified, both
A and T would have a value of 1.00 for Table C; they would make no
distinction between perfectly accurate classification and perfect mis-
DEMO Pearson's r and its equivalents for 2 x 2 tables, DEMO's
T and 1>, when it is calculated as
1> DEMO (ad - bc)/J(a + b)(a + c)(b + d)(c + d)
would indicate misclassification with a negative sign and may be
interpreted as PRE measures when squared. For DEMO tables with
J
31
Table A: Standard Format for Prediction Tables
Predicted Y
a
Observed Y
c
a+c
Table B: Ethnicity and Political Orientation
x: Bthnicity
DEMO Non-European
Political Conservative 20 30 50
Orientation
Liberal 30 20 50
50 50 100
Table C: Predicted and Observed Political Orientation
Predicted Political Orientation
Conservative Liberal
Observed Conservative 20 30 50
Political
Orientation Liberal 30 20 DEMO
50 50 100
Figure 2.1. Association Versus Prediction. For Tables Band C, Goodman and
Kruskal's A = 0.20; Goodman and Kruskal's DEMO = 1>' = r 2 = 0.04
unordered categories, however, Pearson's r and Kendall's 7 cannot
be used, aud </> becomes Cramer's V, which no longer has a PRE
interpretation. The odds ratio may also be used for 2 x 2 tables, but
for larger tables, two or more odds ratios must be calculated, and the
odds ratio no longer provides a single summary measure of accuracy
of prediction. On the whole, it does not appear that the applica-
Positive
(success)
Negative
(failure)
Positive
(success)
Negative
(failure)
b
d
b+d
a+b
c+d
a+b+c+d
32
tion of common measures of association for contingency tables to
predictive DEMO provides a straightforward or general solution to the
problem of estimating accuracy of prediction. Pearson's rand r', or
</> and </>', are reasonable indices for use with 2 x 2, but DEMO larger,
tables, as long as we remember to interpret them DEMO upon
the sign of r or </>.
2.3.3. Ap, T p' and </> p
Equation 2.1 provides a basic form for indices of predictive effi-
ciency. Errors with the model are simply the DEMO of cases mis-
classified when we use the model and are analogous to the error sum
of squares. Errors without the model are analogous DEMO the total sum
of squares and depend on whether we are using a prediction model,
a classification model, or a selection model. For a prediction model,
the approach most closely analogous to linear regression (with an
interval level dependent variable) is to use the mode of the depen-
dent variable as the predicted value for all cases (analogous to using
the mean in linear regression). This method of defining DEMO with-
out the model is the same as the one used in defining Goodman and
Kruskal's A for contingency tables with nominal variables, and gives
us an index first proposed by Ohlin and Duncan (1949). Because of
the similarity to Goodman and Kruskal's A, the index is here referred
to as Ap (lambda-p) where the subscript DEMO refers to its use with pre-
diction tables.
Lambda-p is a PRE measure like R2 when it is positive, but if
the model does worse than predicting the mode, Ap may be negative,
indicating the proportional increase in error. The possible values of
Ap vary depending on DEMO marginal distributions. In general, the full
range of possible values for DEMO in all tables with N cases is from 1-N
to 1.
For a classification model, an appropriate definition of the expected
error without the model is
N
errors without model = Lli[(N - I')IN],
i=l
where N is the sample size and Ii is the DEMO of cases observed in
category i. This is the same formula for error without the model as is
used for Goodman and Kruskal's DEMO An index based on this definition
of errors without the model was proposed by Klecka (1980) for use
with discriminant analysis models. Parallel DEMO A, Klecka's index will
be referred to as Tp (tau-p) or T for prediction tables.
p
33
Like "p, Tp is a measure of change. Unlike "p, Tp requires that even
in the estimation of error without the model, cases must be separated
into distinct groups or categories, and not DEMO placed in the same cate-
gory. In effect, "p adjusts the expected number of errors for the base
rates of classification. Accuracy of DEMO is thus secondary, sub-
ject to the a priori assumption of DEMO As with "p, a value
of 1 for Tp indicates that all cases are correctly classified; a nega-
tive value for Tp indicates that the prediction model does worse than
expected (based on the observed marginal distribution) in predict-
ing the classification of cases. Secondary properties of Tp include the
fact that Tp ?: "p for a dichotomous DEMO variable because the
number of errors without the model for Tp will be equal to or larger
than the number of errors without the DEMO for "p' For tables with
equal marginal distributions, Tp varies DEMO -1 and +1, but the
maximum value of T p is DEMO than 1 when the marginal distributions
are unequal. In the worst possible case, with extremely skewed and
inconsistent marginal distributions, the minimum value DEMO Tp is equal
to 1- N 2j2(N - I). The range of Tp is not constant, but varies from
I to 2 for different marginal distributions. A smaller range occurs for
models in which DEMO is negative and large in absolute value.
It is also possible to construct a proportional change in error mea-
sure of accuracy of prediction DEMO selection models. For such a mea-
sure, the error with the DEMO will be b + c, just as it is for "p
and Tp' Error with the model should depend on both the base rate,
B = (a+b)jN, and the selection ratio, S = (a+c)jN. Given B, S, and
N, we know DEMO expected value of cell a (Table A, Figure 2.1): E(a) =
BSN. Because a 2 x 2 prediction table has only 1 degree of freedom,
once the expected value of a is DEMO, then given the marginal dis-
tribution, the expected value of all of the other cells is known and is
identical to the expected DEMO used to calculate the X2 statistic. The
expected error is E(b + c) = [(a + b)(b + d)jN DEMO (c + d)(a + e)jN].
Plugging these values into the PRE formula, we obtain a proportional
change in error measure?
1>
p
= (a+b)(b+d)jN+(c+d)(a+c)jN-(b+c)
(a+b)(b+d)jN+(c+d)(a+c)jN
(a + b)(b + d) + (c + d)(a + e) DEMO N (b + c)
(a + b)(b + DEMO) + (e + d)(a + e)
=
=
DEMO:.5:7:[
ad <be
(~a-+--;"b7':)(7'b-+-c
d::--)+--:-(
e-+-d7')7'(
a-+-e~)]'
-
34
For tables with equal margiual distributions, <Pp has a DEMO
value of +1. In general, it varies between -1 and +1, but the actual
maximum, minimum, and range depend on the marginal DEMO
As long as errors without the model are calculated as the sum of the
expected frequencies in cells band c (Table A, Figure DEMO), and errors
with the model are calculated as the sum of the observed frequencies
in cells band c, 4>p can be extended to tables larger than 2 x 2 and
still retain a proportional DEMO in error interpretation. For 2 x 2
tables, it can be DEMO that l4> pl ::0 1<p1 and that <P p has the same sign
as 4> and Pearson's r (the DEMO is the same, ad - be, as for <p).
DEMO all cases are correctly predicted, <Pp = 1; otherwise, </>p < 1,
even when the maximum possible number of cases for a given set of
marginals is correctly classified."
2.3.4. Statistical DEMO of it p, T p' and <P p
Lambda-p, tau-p, and phi-p are analogous to R2 as measures of
substantive significance. For statistical significance, an analogue to
the F test is the normal approximation to the binomial test. Let
N = total sample size, P, DEMO (errors without model)/N, and p, =
(errors with DEMO)/N. The binomial statistic d may then be com-
puted as
DEMO d is approximately normally distributed (Bulmer, 1979).11 Note
that what is being compared is not the proportion of cases in each
category, but the proportion of cases correctly Or incorrectly classified
by the model. DEMO test is the same for it p, T p' and <DEMO p, for predic-
tive, classification, and selection models. Only the DEMO of errors
without the model differs.
In the proposed test of statistical significance, the value of the
observed classification is taken as given; DEMO test indicates whether
the proportion predicted incorrectly with the model (which DEMO, by
assumption, dependent on the model, and thus variable) differs signif-
icantly from the proportion incorrectly predicted without the model
(which is dependent only on the marginal distribution, not on the
model, and DEMO assumed to be fixed). This form of the binomial
test, DEMO explicitly uses the expected number of errors as the cri-
terion by which the number of errors generated by the model is to
35
be judged, is preferable to the binomial test for a difference of two
proportions (Bulmer, 1979, p. 145), which assumes that the two pro-
portions (errors with the model and errors without the model) are
based on separate samples (possibly of unequal size), DEMO condition that
is clearly not met when comparing observed and predicted classifica-
tions taken from the classification tables generated by logistic regres-
sion, or expected and actual errors, both of which are derived from
these tables. The binomial test for the difference of two proportions
may, however, DEMO useful if we want to test whether the overall predic-
tive accuracy (percent correctly predicted) is statistically significantly
different for two separate prediction DEMO Even in this situation,
however, we would want a separate DEMO to indicate whether either or
both of the prediction models was significantly better than chance in
reproducing the observed classification of cases.
2.3.5. Other DEMO Indices of Predictive Efficiency
Maddala (1983, pp. 76-77) reviewed three DEMO of predictive effi-
ciency proposed in econometric literature. One he dismissed (DEMO
priately) as being unable to distinguish a perfectly accurate model
from DEMO perfectly inaccurate model, a characteristic it shares with many
of the DEMO of association commonly used in the analysis of con-
tingency tables. A second index, which considered both "first best"
and "second best" guesses, was more akin to indices of goodness of
fit insofar DEMO a "near miss" (the second most likely category, according
to the prediction model) was credited as an accurate choice. The third
index typicallyvaried from -1 to +.50, depending on the marginal dis-
tribution, DEMO produced values similar to </> and Pearson's r. Because
it lacks a PRE interpretation, it appears to have little or no advantage
over cjJ or Pearson's r.
Loeber and Dishion (1983), Copas and Loeber (1990), and Far-
rington and Loeber (1989) proposed a measure they called relative
improvement over chance (RIOC). Although Loeber and his col-
leagues applied the RIOC to the analysis of prediction DEMO classifica-
tion tables, the measure corrects for differences between the base DEMO
and the selection ratio, an approach appropriate for selection models
rather DEMO classification or prediction models. This measure is iden-
tical to the coefficient </>', the </> coefficient corrected for the marginal
distribution. DEMO </>, </>' has no PRE interpretation. The measure
varies between -1 (for perfectly inaccurate prediction, if cells band
36
c in Table A of Figure 2.1 are both nonzero) and +1. If either one
of the cells (b or c) that DEMO incorrect predictions is equal to
0, RIOC = 1, regardless of how small a proportion of the cases are
correctly classified (a problem it shares with Yule's Q, a measure of
association sometimes used for contingency tables). Even if over 90%
of the cases are DEMO, RIOC may have a value of 1.12
2.3.6. Comparing Indices of DEMO Efficiency
Menard (2000) provided empirical evidence that when the base
rate alone is manipulated, Ap and cPp are highly correlated with the
base rate, but Tp is not. Soderstrom and Leitner (1997) compared
Ap, T p' and <Pp, and also the RIOC and percentage DEMO, for mod-
els in which both base rate and selection ratio, plus sample size and
reliability of predictors, were manipulated. Based on Monte Carlo
simulations, they found that cP p was least affected by the base rate,
followed by T P and then Ap, for models that included continuous pre-
dictors. For models that involved only dichotomous predictors, how-
ever, T p was less sensitive than cPp to changes in the base rate (and
RIOC often could not be calculated at all, for reasons noted previ-
ously). Soderstrom and Leitner concluded that across a broad range
of conditions, cP p and Tp were the most appropriate choices as indices
of predictive efficiency. Taken together, these results reinforce the
suggestion that selection of the index should be consistent with the
DEMO of the model and, in particular, that Tp is most appropriate for
classification models and cP p is most appropriate for selection mod-
DEMO These indices also may be applied to prediction tables generated
by procedures other than logistic regression, and are not limited to
dichotomous variables; DEMO are applicable to any prediction table in
which correct predictions can be distinguished from incorrect predic-
tions. Unfortunately, none of the aforementioned indices of predictive
efficiency is routinely available at present in such widely used logis-
DEMO regression software as SPSS LOGISTIC REGRESSION or SAS
PROC LOGISTIC.
2.4. Examples: Assessing the Adequacy
of Logistic Regression Models
One reason for the lack of consensus about indices of predictive
efficiency may be the fact that DEMO are more often interested
37
in the goodness of fit of the model (in a broad sense, as indicated
by OM and Rt) than in the accuracy DEMO prediction or classification of
the model, as indicated by the classification DEMO and indices such as
Ap, Tp, and <p p• Especially DEMO theory testing, goodness of fit is sim-
ply more important than DEMO of classification. The amount of
space devoted to accuracy of prediction in this monograph reflects
the relative lack of development in this area, rather than its impor-
tance, compared to the assessment of goodness of fit. Often the two
approaches, goodness of fit and accuracy of prediction, DEMO produce
consistent results. It is entirely possible, however, to have a model
that fits well, but does a poor job predicting category membership.
Figures 2.2 and 2.3 illustrate how indices of goodness of fit and DEMO
dictive efficiency may lead to very different substantive conclusions.
In Figure 2.2, hypothetical data are presented for a single dependent
variable, TRUE, and a single predictor, PI. The standard output has
been edited to include R[, R2 , Ap, and T P' For the 40 cases analyzed
in Figure 2.2, the model fits well. OM = modelx' DEMO 20.123 and is sta-
tistically significant (significance = p = .0000), leading us to reject the
null hypothesis that the independent variable, DEMO, is not related to the
dependent variable, TRUE. R[ = .363, suggesting a moderate asso-
ciation between TRUE and PI. The binomial d is the same for both
Ap and Tp (50% expected error for both): d = 5.060, with statistical
significance p = .000. Both Tp and Ap are equal to .80, indicating that
the independent variable allows us to classify the cases (into the cate-
gories of the dependent variable) with a very high degree of accuracy,
as reflected in the classification table. Overall, the accuracy of pre-
diction is considerably higher than the ability of the model to predict
the probability, P(Yj = I). The plot of observed groups and predicted
probabilities DEMO the bottom of Figure 2.2 indicates that the predicted
probabilities are sometimes very high and sometimes close to .5, the
cutoff for classification into Y = I or Y = O. Accuracy of prediction
is very DEMO, even for cases whose predicted probability of belonging
in (Y = 1) is close to .5.
In Figure 2.3, OM is again DEMO significant, and both R[ and
R2 indicate a moderately strong relationship DEMO the dependent
variable, TRUE, and the new predictor, P2. However, Tp and Ap indi-
cate no more than a weak relationship between DEMO observed and
predicted classification of the cases, and the binomial d DEMO .632, with
statistical significance p = .264 (one-tailed), suggests that the clas-
sification on the dependent variable is not related to the DEMO of
38
Classification Tabl.,(a1
Omnibus Tests of
Mod"l
coefficient"
l'ndictod
Step
Chi-square df Si9.
,
Step
20.123
,
,
,DEMO
.000
Block 20.123
.000
Medel 20.123
.000
T~U<:
Observnd
0
DEMO TRO£
0
0,"
tta
Overall ~ere<lnt"ge
" The DEMO value is .500
~orcent"ge
,
a
re
R.'
n'DEMO
'l'au-p
Lambda-p
.363
.408
.80
Correct
90.0
90.0
90.0
.80
DEMO in the Equation
Step -2
1,09
lik",lihood
,
35.329
Cox
II
&
Snell
Sqllat\>
.3%
Na.. dker~",
II DEMO
.521
,
a.a.
\'Ial.d
df 51\)'.
£"p(B1
Step l'l S.203
l(al
Constant -4.102
2.894 8.035
\.505
i
DEMO 3653.109
,
a
Q
Q
,
"
ObserV<ld Groups DEMO
a variab1e(sl entered on step 1: 1'1.
.006 .017
?tn'Hernd
I'rob:
Grollp:
"r"dieted PrObability is of Mernb\lrShip for 1
The cce Value is .50
Symbols: 0
, - ,
0 -
~ach Sl""bol ll,epresent" 1 case.
Figure 2.2. Logistic Regression Output for Hypothetical "Good Prediction"
Data (Predicted DEMO is of Membership)
the independent variable. The plot of observed groups and predicted
probabilities indicates why. Now, instead of accurate prediction when
the predicted probability is close to .5, predictions close to .5 are
nearly all inaccurate. For 26 of the 40 cases, the predicted probabilities
are the same for P1 and P2. For the other 14 cases, the predicted
"r"dieted Probabilities
a
0
c
o
o
o
o
Q
o
-----+-----1-----+-----
7.43;: 1
39
Classification Tilb1",(<I,0)
omnibus Tests of Model Coefficients
F""dicted
Observed
Step TRUl:
0
TI\O€.
0
c H
a
s
,
,
H
Overall Plltcentage
a Constant lS included ,In ttle modeL
bTM Cllt valu", is .500
Model
Summary
Percentage
Correct
DEMO
100.0
50.0
Chi-square df
,
,
,
$i<)_
.COO
.000
.000
Step
,
Step
aicc»
MOdel
R,,'
R'
Tau-p
Lambda-p
H
'",n
11
" '"
.324
.356
.10
.ao
Variables in tll" Equation
Step -2 Log
likelih.ood
,
31.471
DEMO
R
&
Snell
Square
.362
Naqelkerke
R Squa""
.4$3
e
Step P2
1(al
Constant
7.193
-3.596
a.a.
Wald
df Sig.
£"DEMO>(BI
2.~97 $.2\19 ,
,
.004 1329.985
i
'"
DEMO
a variablo(s) entered 00 step l'
(>2.
.006 DEMO
Observed Groups and hedi<;ted hobabilitie"
r
,
s
c
,,
u
c
"
,,,
,,
,,,
I
c
.25 .5 .15 1
000000000000000000000000000000111111111111111,11111111111111
p,,'1><,DEMO probability is of Membo"ship for 1
'rue Cut vetce is DEMO
Symbol", 0 ~
, . ,
0
~a<:h Symbol ReprCS(lnts 1 cas.:>,
Figure 2.3. Logistic Regression Output for DEMO "Poor Prediction"
Data
probability changed by .02, either from .49 to .51 or from :51 to .49.
This had little impact on the overall goodness of fit of the model as
measured by Rt, R2, or 1/2 and OM' but it had a tremendous DEMO
on the indices of predictive efficiency.
o
40
Figure 1.4, first discussed in Chapter 1, presented the results DEMO
a bivariate logistic regression analysis for real data, the relationship
between DEMO to delinquent friends (EDF5) and prevalence of
marijuana use (PMRJ5)DEMO From Figure 1.4, we can reject the null
hypothesis that EDF5 DEMO unrelated to PMRJ5, based on GM (signif-
icance ; .0000). Notice that the Hosmer and Lemeshow goodness-
of-fit measure is not statistically DEMO, indicating that the model
with only EDF5 as a predictor fits DEMO data well. The prediction table
appears to indicate fairly good accuracy of prediction, but we need to
calculate A and/or Tp to get a quantitative estimate of how well the
cases are classified by the DEMO Finally, notice that the predicted val-
ues from the model have DEMO saved as a new variable, LPEPMRJ5
(logistic regression prediction from EDF5 of PMRJ5). This permits us
to use a separate analysis of DEMO or bivariate regression routine
to calculate R'.
From the data in Figure 1.4, where GM = 85.359 (the Model
Chi-Square in the DEMO Tests block) and DM = 213.947 (the -2
likelihood in the Model Summary block), Ri = GM/(Gm +DM) =
(85.359)/(85.359 + 213.947) = .285. Lambda-p is equal to the num-
ber of cases in the smaller observed category (Y = 1: DEMO = 81)
minus the number of cases incorrectly predicted by the model (37+14
= 51), divided by the number of cases in the smaller category, so
A = (81-51)/81 = .370. This is a moderately strong reduction in
the error of prediction. Tau-p is DEMO bit mare complicated to calculate.
First find the sum of the cases in each category for the observed
value of Y: for Y = 0, ny"o = 150; for Y = 1, nY=l = 81. For a
dichotomous dependent variable, the expected number of errors
is the product of the two sums, divided by the total number of
cases (231) and multiplied by 2 (because we expect the same num-
ber of errors in each category for a dichotomous variable), DEMO is,
(2)(150)(81)/231 = 105.2. Tau-p is the expected number of errors,
minus the actual number of errors (51), divided by the expected num-
ber of errors: Tp = (105.2-51)/105.2 = .515. This indicates that the
model reduces the DEMO of classification of cases as users or nonusers
of marijuana by over half.
We can use the expected errors for A and Tp to DEMO the bino-
mial d statistic for each measure. For A , the expected number of
errors is 81, which corresponds to a proportion of 81/231 = .351,
and the observed number of errors is DEMO, which corresponds to a pro-
portion of 51/231 = .221. DEMO, d = (Pe- Pe)/y'Pe(1- Pe)/N =
p
p
p
p
41
(.351- .221)/J(.351)(.649)/231 = 4.140, with statistical significance
p = .000. For Tp, without going into as much detail, d = 6.996, with sta-
tistical significance p = .000. DEMO, to calculate R2or "12, we must use
the results of DEMO bivariate regression or an analysis of variance routine.
We can compare the results of the logistic regression analysis in
Figure 1.4 directly with the DEMO of the linear regression analysis, with
the same variables, in Part C of Figure 1.1. In particular, the explained
variance for PMRJ5 in the logistic regression model (R2 = .34) is
actually slightly higher DEMO the explained variance for PMRJ5 in the
linear regression model (R2 DEMO .32; from Part C of Figure 1.1).13 This
occurs despite DEMO fact that the linear regression model tries to maxi-
mize R' (by minimizing the sum of the squared errors), whereas the
logistic DEMO model does not. It appears that the logistic regres-
sion model fits the data well, indicates a moderately strong relation-
ship between the predictor and the dependent variable, and does a
fairly good job of predicting the classification of the cases.
2.5. Conclusion: Summary Measures for
Evaluating the Logistic Regression Model
In linear regression, we use the F statistic and R2 to test statistical
significance and substantive significance, respectively, of the DEMO
ship between the dependent variable and the independent variables.
Both are based on the total and error sums of squares, SST and SSE.
In logistic regression, if our principal concern is how well the model
fits the data (for example, in the context of theory testing), DEMO use
GM and based on - 2LL, to test for statistical DEMO substantive sig-
nificance. If our concern is less with the overall fit of the model and
more with the accuracy with which the model DEMO actual category
membership on the dependent variable, the binomial d and DEMO of the
three indices of predictive efficiency (Ap, T p' DEMO <p p) are used to assess
the statistical and substantive significance of the model. Because Ap,
T p' and <P p DEMO not provided in logistic regression routines, they must
be computed by DEMO
3. INTERPRETING THE LOGISTIC
REGRESSION COEFFICIENTS
In linear regression analysis, we DEMO the contribution of each inde-
pendent variable to the model by testing for its statistical significance
RL
42
and then examining the substantive significance of its effect on the
DEMO variable. Statistical significance is evaluated using an F or
t statistic to produce a probability (p) that we would find this strong a
DEMO in a sample this large if there really were no relationship
between the independent variable and the dependent variable. Sub-
stantive significance may be DEMO in one of several ways. We may
examine the unstandardized regression coefficient to see whether the
change in the dependent variable associated with a DEMO amount of
change in the independent variable is large enough to be concerned
about. (The words "are associated with" are used here in preference
to language that would imply a causal relationship, because the rela-
tionships described here are definitely predictive and may, but need
not, DEMO causal in nature.) To apply this test, we must have SOme idea
beforehand how big a change needs to be before we are DEMO
with it, and equivalently how big a change we are willing DEMO ignore.
Unstandardized regression coefficients are especially useful for eval-
uating the practical impact of one variable on another and for com-
paring the effects DEMO the same variable in different samples.
Alternatively, especially when there are DEMO clear criteria for decid-
ing "how big is big" and when some variables are not measured in
natural units of measurement (feet, DEMO, dollars), but are instead
scale scores (an example of this would be the variable EDF5, expo-
sure to delinquent friends), we may focus on a standardized regression
coefficient, which indicates how many standard deviations a dependent
variable changes in response to a 1 standard deviation DEMO in the
independent variable. Use of standardized coefficients is especially
appropriate for theory testing and when the focus is on comparing
the effects of DEMO variables for the same sample.
For some purposes, stepwise methods are DEMO to evaluate the con-
tribution of variables to the regression equation. This is especially
the case when we test for nonlinearity (for example, DEMO including
quadratic terms) or nonadditivity (by including interaction terms) in
DEMO regression equation. The decision about whether the inclusion of
nonlinear or nonadditive terms is justified is typically based on the
magnitude and statistical significance DEMO the change in the explained
variance, R'. Stepwise methods are DEMO used in exploratory analysis,
when we are more concerned with theory development than theory
testing. Such research may occur in the early stages DEMO the study of
a phenomenon, when neither theory nor knowledge about DEMO
of the phenomenon is well developed. Criteria for stepwise inclusion
43
or removal of variables for a model generally involve tests that DEMO
similar to but less restrictive than the tests used in theory testing.
3.1. Statistical Significance in Logistic Regression Analysis
Several methods have been used DEMO evaluate the statistical signif-
icance of the contribution of an independent variable to the expla-
nation of a dependent variable. One stands out as DEMO clearly the
best, in the sense of being the most accurate: the likelihood ratio test.
In the likelihood ratio test, the logistic regression model is calculated
with and without the variable being tested. The likelihood DEMO test
statistic is equal to GM for the model with the variable minus GM for
the model without the variable. The result, which we can call G1 when
we test Xl> G2 when we test X2 , and Gk when we test Xb has a X2
distribution with DEMO of freedom equal to the degrees of freedom
in the model with X minus the degrees of freedom in the model with-
out X. DEMO example, if we designate GM! to represent the model x2
with DEMO in the model and designate GM2 to represent the model X2
with Xk not in the model, Gk = GM! -GM2, and if DEMO is a continuous,
interval, or ratio variable, then Gk has 1 degree of freedom.
The only drawback to the use of the DEMO ratio statistic is that
it requires more time to compute than alternative tests for statistical
significance. If you are paying for every second on DEMO mainframe com-
puter, this may be a serious concern, but for many users with access
to relatively fast personal computers and workstations, this is irrele-
vant except for very large samples. Nonetheless, statistical packages
are often written to use a less computationally intensive alternative
to the likelihood DEMO, the Wald statistic, to test for the statistical sig-
nificance of individual coefficients. In Figure 1.4, the Wald statistic
appears following the coefficient (B) and its standard error (S.E.).
The Wald statistic may be calculated as wf = [bk/(S.E. of bk)J', in
which case it is asymptotically distributed as a X2 distribution or as
DEMO = bk/(S.E. of bkl, in which case it follows a standard normal
distribution (Hosmer & Lemeshow, 1989, p. 31; SAS, 1989, p. 1097;
SPSS, 1991, pp. 140-141) and its DEMO parallels the formula for
the t ratio for coefficients in linear regression. The disadvantage of
the Wald statistic is that for large b, the estimated standard error is
inflated, resulting in failure to reject the null hypothesis when the null
hypothesis is false.!"
44
,
Dependent Variable
,
Encoding
,
Unwoiqllted Cases(,,)DEMO
Select"cl Cases
Unselcceed Cases
"
1n<:1I.'ded in Millysis aav
Missing Cases
ao
'rotal
'"
0
Percont
IOtiqinal Value Internal Value I
ea.a
1·00
lLOO
""
"0
11.1
100.0
.0
I
,
,
iiiIChi-Squat"l"! ISiq.l
I I I
I
I
DEMO"p S~"p
!Hock 109.257
s
.000
Hodel
108.257
s
.000
ClassiHo~tion Tabl,,(,,)
106.257
s
.COO
Total
'" 100.0
It "ei'lht is in effect, see classificatiOn table
for the toed number of cases.
frequency Para'''''t'''' codinq
'"
'"
€THN 1
White m
.000
.000
,
black
37
1.000
DEMO
a
other 15
.000
1.000
''"
1 nMAL£ m
.000
DEMO HJU.l:
no
1.000
variables in the Equation
'"
,
DEMO"ed.
Step PHl1.J5
"""rall
Per<:entage
cut ""lu" DEMO
l>redi<:ted
l>HRJ5
M
"" '"
yes 28
l>erc"ntage
Correct
'"
ra
sa
.500
91.2
65.0
aJ..9
DEMO The
Step sees
Ijal
atLISn
S£X(11
0
.407
-.118
-1.511
S.£.
.069
.060
.105
.50a
.745
2.028
Wald
<If 8i9.
34.341 ,
,
,
3.803
aa.oca
l.iSO
a
.232
,
,
,
DEMO
.744
EXpO,)
Step -2 Log
likelihood
,
186.359
Cox & Snell
fl Squate
.379
llaq<llkotk<>
R Square
.522
.000 1.502
.048
.a8S
.000 .aao
£1'1111
ETIlII(!l
£1'1111(2)
DEMO
.245
JSte!, Chi-square df Sig.
.172
.630 1.27"1
.300 2.163
DEMO,
8.754
e
.363
Constant -1. 749
.aea
.174
a l'a"iable(sJ entered on step 1:
EOfs. 8ELlH4. $n. [TIm
Figure DEMO SPSS LOGISTIC REGRESSION Output
Figure 3.1 presents SPSS output for a dependent variable with
four predictors. PMRJ5, the prevalence of marijuana use, is DEMO
the dependent variable and EDF5, exposure to delinquent friends, is
again included as a predictor. BELIEF4 is a scale that measures how
wrong (very wrong, wrong, a little wrong, not wrong at all) DEMO respon-
dent believes it is to commit each of several illegal acts (assault, theft,
•
45
SteP 1
,
••• OUTPUT
FROM
SFS, /lEANS •••
S""""rl., of
lRPREIHl
.00
1.00
n"
ye'
Within DEMO Toto)
Predicted V~l". By 1•• els of PIIRJS
llean
,DEMO Qev
Su'" of So
.2002317 .1958068
.6320872 .2965058
5.5976854
6.945339&
.3524275
.2361076 12.5430250
C~les
147
eo
An.lysh of Varionoe
S~urce
8et~oen Group,DEMO
Wilhin Group'
Somof
Square,
9.MIIl
12.5~lO
0 .r ,
DEMO
110M
Souare
9.6618
.05$1
173.1160
Si9.
.MOO
H~ "
.65%
H. DEMO"..~· .~151
!'WtJS ~ 1.00
,..
PMI\JS '"
"
14.120
Obs"r"~d I:xp~ceod Observed Expected
c
. 69~
a
DEMO)
,
,
2.621
3.660
s
4.903
ic
s.avi
s
9.921
rs
15.316
,
"
ai
s "
, aa
,
DEMO
s
"
,
,"
e
s
a
rc i
eo
19.871
.00
""
23.306
12.5T!
22.3'19
20.310
18.097
16.129
13.079
DEMO
3.129
.2BO
Tot«l
"
"
as
"
23
n
aa
DEMO
aa
rs
Va"hble
Step
,
tors
BSLHF4
Sl:X
"""
Mod,,1 Log
Likelil.ood
-120.954
-115.122
-101.18S
-93.158
,
Change DEMO -2
1,0'1 Likelj,hoOd
55.549
4.085
16.011
1.1S8
<If
DEMO'l"
,
i
,
z
8ig.
the
"'
.000
.040
.000
.561
Figure 3.1. (Continued)
selling hard drugs, etc.), parallel to the items used to construct EDF5.
BELIEF4 is measured immediately prior to the period for which data
were collected on prevalence of DEMO use. SEX is coded 0 for
females and 1 for males.
The coding for ETHN is given in the Categorical Variables Cod-
ings Table DEMO Figure 3.1. The first coefficient for ETHN corresponds
to being African American ("black") and the second corresponds
to being other than non-Hispanic DEMO American or African
American ("other"). The numbers in the DEMO, (1), (2) or (3), cor-
respond to DEMO number of the coefficient that is set to 1 for individuals
46
falling into each row. Thus, the first coefficient for ETHN is multi-
plied by 1 for African Americans, and by 0 otherwise, DEMO the second
coefficient is multiplied by 1 for other ethnic groups and by 0 other-
wise. This is an example of the use of DEMO set of "dummy" or design
variables in logistic regression to represent a single categorical vari-
able, and is parallel to the use of dummy variables or design variables
in linear regression (Hardy, 1993; Lewis-Beck, 1980).
In the section of Figure 3.1 labeled Variables in the Equation, we
find logistic regression coefficients, standard errors, Wald statistics
(DEMO, the degrees of freedom (df) associated with each variable, and
the statistical significance of the Wald statistic. From Figure 3.1, it
appears that EDF5, BELIEF4, and SEX have statistically significant
effects on PMRJ5. DEMO ETHN, the Wald statistic is computed for the
variable as a DEMO, and also separately for each of the coefficients
that correspond to DEMO separate categories of ethnicity. The effect
of ETHN on PMRJ5 does not appear to be statistically significant,
and neither does the intercept (constant). The Hosmer-Lemeshow
test (here the contingency table for the Hosmer-Lemeshow test is
also included) indicates a good fit for the model. Toward the end
of Figure 3.1, just before the output from SPSS MEANS, DEMO
the heading Model if Term Removed, likelihood ratio statistics
were obtained DEMO the variables in the model.15 Substantively, the
conclusions remain the same DEMO the significance levels are very sim-
ilar for the Wald and likelihood ratio statistics. As noted earlier, the
Cox-Snell and Nagelkerke R' measures DEMO questionable measures,
so they are not discussed here.
Figure 3.2 provides parallel output from SPSS NOMREG. The
NOMREG output is more concise and DEMO some of the same infor-
mation in the output from LOGISTIC REGRESSION. The model x2
(OM) is the same, as is the (DEMO) -2LL (DM) for the model (com-
pare the Model Summary table in Figure 3.1 and the Model Fitting
Information table in Figure DEMO), and the Intercept Only or initial
-2LL (Do) is also provided. The Cox-Snell and Nagelkerke mea-
sures are the same in the DEMO tables, but NOMREG also provides the
McFadden pseudo R-square (RD. The Likelihood Ratio Tests table
in Figure 3.2 provides the same information as DEMO Model if Term
Removed table in Figure 3.1. In place of the Hosmer-Lerneshow test
for model fit, NOMREG provides the Pearson and deviance X2 statis-
tics, adjusted to reflect the number of covariate patterns rather than
the number of cases. Of the two, the deviance X2 is generally regarded
47
Cas" hoccs,.ing S"""",,ry
P!lRJS
sex
.00
DEMO'
,
'"
1. 00
yes SO
,
l11IH
no
~TllN
a
,
l'£l11IL~ m
"Ilit...
no
a
a
black
DEMO"r
"
U
Valid
Hissing
m
ac
Std.
Error
2.122
.069
DEMO
.405
.715
'1'otal
2S'J
I£TllN~3l
O(a)
.8H
DEMO
Hodel <HUng Infor",ation
a This parm"etor 1S set to ZetO becausll It ~S ~"dunda"~.
Good""ss-of~nt
Modd
-2
l,.og Li~i:,1illood Clli-square d e 5ig.
Clli~square df
i si
'"
8ig.
.000
.326
cox Md
snell .379
Nagelkerk"
McFadden
Interc"DEMO Olll~ 279.706
nnal
l?1.~50
Class~fication
10S.257
,
.000
Pearson
261.438
DEMO
l'~edictod
Observed
.00
""
1.00
'"
overall
Percentago
.00
'"
aa
71.4%
no 1.00
ra
ez
28.6%
I'llrCent
'" Conect
91. 2~
65.0%
81.9%
Effect
-2
of R...
Log Li~"lihood
DEMO Hodel
Intercept 17t , 450
EDPS
226.999
BELIEP4
175.535
'"
187,461
ETHN
172.607
Chi-Squate df Si9.
.000
0
55.549
i
.000
LOllS
,
,
.0<13
16.011
.000
1.H8
a
.%1
.367
o""DEMO,,e 1S$.266
The chi-squate statistic is tho diHetence in -2 io<)-
li~"lihoods between the fin"l model and a teduced ",DEMO 'file
reduced mOdel is formed by emitting "n effoct from ~he find
model. 'i'he null hype~hosis is that all pararnHors of that
effect ate O.
Panmet..." f;stilMtes
a
PMl'lJ5
.00
0"
Intetcept .978
EDr5
-.107
llSLIEl:4
(SSX~11
(Sf;Xm2l
(!:THN~ll
·11S
1.515
O(a)
.772
(ETHN~21
·527
\lald
<.If 8ig.
DEMO(l,l)
.212
i
.615
34.341 ,
,
,
DEMO .666
3.903
.046 1 125
14.013
.000 <I '"
0
DEMO
i
.300 2.164
.393
,
.531 1.691
95% Confidence
Int"r"DEMO for f;xp (B)
Lo"er upper
Bound llound
.5S1
DEMO
2.056
.503
.326
.763
1.265
10.054
9.313
ll.797
Figure 3.2. Logistic Regression Output From SPSS NOMREG
to be more informative than the Pearson X2 DEMO logistic regression, and
the deviance X2 indicates a good model fit, similar to the Hosmer-
Lemeshow test in Figure 3.1. The classification table DEMO also identical,
The one striking difference between Figures 3.2 and 3.1 is in the
coefficients in the Parameter Estimates table in Figure 3.2. DEMO
TIC REGRESSION predicts to the second category of the dependent
48
variable (thus setting the first category as the reference category) DEMO
allows us to specify which category is the reference category for each
categorical predictor, and in Figure 3.1, the first category was selected
DEMO the reference category. By default, NOMREG uses the last cate-
gory DEMO the reference category for both the dependent and indepen-
dent variables. As a result, SOme of the coefficients seem different, but
they really DEMO the same story as the coefficients in Figure 3.1. Indi-
viduals with higher exposure to delinquent friends are less likely to be
nonusers; individuals with strong beliefs that it is wrong to violate the
law are DEMO likely to be nonusers; and males are more likely to be
DEMO (note that it is the first category of the dependent variable
DEMO is being predicted here) according to the results in Figure 3.2.
DEMO Figure 3.2, it is "white" instead of "other" that DEMO the reference
category, but still neither of the two logistic regression DEMO is
statistically significant.
Figure 3.3 provides partial output from SAS for the same model
that was estimated in Figure 3.1. One difference between the DEMO out-
put in Figure 3.3 and the SPSS output in Figure 3.1 is the treatment of
the categorical variable ETHN, which in SAS must be separated into
design variables before it is entered into the analysis, because SAS
assumes that the independent variables in PROC LOGISTIC have
true DEMO values (SAS, 1989, p. 1079). Also, there is no test for
ETHN as a single variable; each of the design variables is tested sep-
arately. Such a test could be performed by analyzing DEMO models,
one with and one without ETHN as a predictor. Otherwise, however,
the parameter estimates, standard errors, Wald statistics, p DEMO,
Hosmer-Lemeshow test, R~ (RSquare in Figure 3.3; Cox-Snell in
DEMO), R~ (Adjusted RSquare in Figure 3.3; Nagelkerke in SPSS),DEMO
and -2 Log likelihood statistics are practically identical to those pro-
duced by SPSS LOGISTIC REGRESSION.
3.2. Interpreting Unstandardized Logistic Regression Coefficients
Figure 1.4 DEMO the results of a bivariate logistic regression
analysis. From Figure 1.4, DEMO obtained the equation logit(PMRJ5) =
.407(EDF5) - 5.487. When EDF5 is at its maximum observed value
(29), this becomes Jogit(PMRJ5) = .407(29) - 5.487 = 6.316. If
EDF5 has DEMO minimum observed value (8) it becomes logit(PMRJ5) =
.407(DEMO) - 5.487 = -2.231. Translating the logits into probabilities,
the DEMO of marijuana use for individuals whose score on the
Data Set: WORK. DATAl
Response Variable' PHRJ5
Response levels: <:
Number of Observatians: 227
Link Function: Lagit
Response Profile
49
Ordered
DEMO PMRJS
1 1
2 0
Count
80
147
WARNING:
30 observettcefs) were deleted due to missing values for the response or explanatory variables.
Hodel Fitting tntcrsettcn anti Testing Global Ilull
Hypothesis
aETA"D
Criterion
Ale
" LOG L
Score
·2
Intercept
Only
ZS6.616
300.041
294.616
!nter<:ept
DEMO cover-teres
198.359
218.909
186.359
Chi-Square for Covariates
W8,257
89.457
with 5 OF (p-D,OOOI)
with 5 OF (peO.OOOl)
RSquare •• DEMO
Adjusted RSquare •• 522
Variable
IIlTERCPT
EDF5
8EtlEf4
S"
8LACK
OTHER
OF
Parameter
Estimate
-1. 7498
0.4068
-0.1179
-1.5148
0.2451
0.7720
Standard
Error
DEMO
0.0694
0.0597
1).4047
0.5080
0.7445
AMlysis (If Haximum Likelihood Estimates
DEMO
Chi-Square
pp
Chi-Square
Standardized
Estimate
0.7441
34.3468
3.9033
14.0130
0.2327
1.0748
0.3883
0.0001
0.0482
0.0002
0.5295
0.2999
0.954476
-0.256713
-0.418313
0.1)50013
0.105958
Odds
DEMO
1.502
1).889
0.220
I.US
2.154
Association of Predicted Prol<abilities and Observed Responses
Concordant· 88.2%
Discordant" 11.6%
'l'ied • 0.2%
(11760 pairs)
G._
Tau-a
c
Somers'
(I • 0.766
~ 0.767
• 0.351
~ 0.883
Hosmer and Lemeshow Goodness¥C>f_Fit Test
Group
Total
DEMO
2
3
4
5
6
7
8
9
10 15
""
25
23"
23
23
23
23
GRP
~ 0
GRP •
DEMO -------------------
observed
"21
24
22
18
13
I'
7
3
DEMO
Expected
23.31
22.58
22.38
20.3~
18.10
16.13
13.08
7.68
3.13
.28
Observed
0
3
...
1.42
Expected
1 2.62
2
5 4.90
10 6.87
DEMO 9.92
16 15.32
20 19.87
10 14.72
3.66
Goodness-of-fit Statistic" 8.754 DEMO 8 OF {p"0.363j
Figure 3.3. SAS PROC LOGISTIC Output
exposure scale is 29 becomes e6.316/(1 + e6.316)=.998; for individu-
als DEMO score on the exposure scale is 8, it becomes e- 2.231/(1 +
e- 2.231)=.097. For individuals with the highest levels of DEMO to
delinquent friends, marijuana use is almost, but not quite, DEMO For
individuals with the lowest levels of exposure, the relative frequency
DEMO marijuana use is less than 10%, low, but far from indicating that
50
marijuana use never OCCurs among these individuals. At the mean
level DEMO exposure, logit(PMRJ5) = .407(12) - 5.487 = -.603, and the
probability of using marijuana is e-·603/ ( 1 + e-·603) = .354, which is
approximately equal to the unconditional probability of DEMO USe
(P = .357) for this Io-year-old sample.
Like the linear regression coefficient, the logistic regression coef-
ficient can be interpreted as the change in the dependent variable,
logiu F), associated with a DEMO change in the independent vari-
able. The change in P(Y = 1), however, is not a linear function of
the independent variables. The slope of the curve varies, depending
on the value of the independent variables. It is possible to calculate
the slope of the curve DEMO different pairs of points by examining the
change in P( Y DEMO 1) between those points. For example, going from
EDF5 = 8 to EDF5 = 9 results in a change in probability from .097
DEMO .101, indicating a slope of .004. A change from EDF5 = DEMO to
EDF5 = 29 is associated with a change from P(Y = 1) = .997 to
.998, or a slope of about DEMO Between EDF5 = 12 and EDF5 = 13,
the probability of marijuana use changes from .354 to .451, a slope
of .097, DEMO is many times larger than the changes that result from
one-unit changes at very high or very low values of EDF5.
The interpretation of DEMO logistic regression coefficient is similar
in models with several independent variables. The equation for the
relationship between prevalence of marijuana use and the predictors
DEMO Figure 3.1 is logit(PMRJ5) = .407(EDF5) - .118(BELIEF4) -
1.514(SEX) + .245(BLACK)+ .772(OTHER) -1.749, DEMO BLACK
and OTHER are the descriptive labels associated with ETHN(1) DEMO
ETHN(2) in Figure 3.1. Turning to the individual coefficients, each
one-unit increase in EDF5 is associated with an increase of .407 in
DEMO(PMRJ5). Each one-unit increase in BELIEF4 is associated with
a decrease of .118 in logit(PMRJ5). Being male reduces the logit
of DEMO by 1.514 (remember, in this sample, males have lower
marijuana DEMO than females). The effects of ethnicity are not statisti-
cally significant.16
Predictions for individual cases may be obtained by replacing the
variables in DEMO eqnation with their valnes for specificcases. For exam-
ple, for an DEMO American female (BLACK = 1, OTHER = 0)
with strong beliefs that it is wrong to violate the law (BELIEF4 =
25) and low levels of exposure to delinquent friends (EDF5 = 10),
logit(PMRJ5) = .407(10) - .118(25) -1.514(0) + .245(1) + .772(0)-
1.749 = -.384. This DEMO to a probability of marijuana use of
51
e-· 384/ (1+ e-· 384) ; .405. Alternatively, for DEMO non-Hispanic European
American male (BLACK = 0, OTHER = 0) DEMO moderate levels of
both belief that it is wrong to violate the law (BELIEF4 = 20) and
exposure to delinquent friends (EDF5 = 15), the equation becomes
logit(PMRJ5) = .407(15) - DEMO(20) -1.514(1) + .245(0) + .772(0)-
DEMO = .482. This corresponds to a probability of marijuana use of
e.482/(1 + e·482) = .618.
3.3. Substantive Significance and Standardized Coefficients
DEMO does a one-unit increase in exposure to delinquent friends
really mean? DEMO exposure items are measured on a five-point
scale, and belief items DEMO measured on a four-point scale, and
because the number of items DEMO larger for exposure (8) than for belief
(7), is DEMO one-unit increase in belief really equivalent to a one-unit
increase in exposure? Should we regard a one-unit change in belief
(which has, in principle, a range of 7 to 28) as equivalent to a DEMO
change in gender (which has a range of only one unit, 0 to I)? These
questions could be asked in the context DEMO either linear regression,
with frequency of marijuana use as a dependent variable, or logistic
regression with prevalence of marijuana use as a dependent variable.
When independent variables are measured in different units or on
different DEMO and we want to compare the strength of the rela-
tionship between the dependent variable and different independent
variables, we often use standardized regression coefficients in linear
regression analysis. For the same reasons, we may want to consider
using standardized coefficients in logistic regression analysis.
A standardized coefficient DEMO a coefficient that has been calculated
for variables measured in standard deviation units. A standardized
coefficient indicates how many standard deviations of change in DEMO
dependent variable are associated with a 1 standard deviation increase
in the independent variable. In linear regression, a standardized coef-
ficient between a dependent variable Y and an independent vari-
able X, bh, may be DEMO from the unstandardized coefficient
between Y and X, byx , and DEMO standard deviations of the two vari-
ables, Sy, and sx: DEMO ; (b yx )(sx )/(Sy). Alternatively, standardiz-
DEMO both X and Y prior to regression by subtracting their respective
means and dividing by their respective standard deviations to obtain
Zy = (Y - Y)/Sy and Zx = (X - X)/sx produces a standardized
regression coefficient between Y and X.
52
For a variable that is approximately normally distributed, 99.9865%
of all cases will lie in a range of 6 standard deviations (3 standard
deviations on either side of the mean), and 99.999999713 will lie
DEMO a range of 10 standard deviations. Thus, a 1 standard deviation
DEMO in an independent variable typically means a change of about
one-eighth of the range of its possible values (one-sixth in a small
sample; DEMO in a very large sample). According to Chebycheff's
inequality theorem (Bohrnstedt & Knoke, 1994, pp. 82-83), for any
distribution, DEMO for a very nonnormal distribution, at least 93.75%
of all cases DEMO lie within 8 standard deviations of the mean and 96%
will lie within 10 standard deviations. Thus a change of 1 standard
deviation seems DEMO to be a large enough change that its effect
should be felt (if the independent variable has any impact on the
dependent variable), but not so large that a trivial relationship should
appear to be DEMO, even in a distribution that departs consid-
erably from a normal DEMO By measuring the relationship of
all of the independent variables to the dependent variables in com-
mon units (standard deviations, or about one-eighth DEMO their range),
the relative impact on the dependent variable of DEMO vari-
ables measured in different units can be directly compared.
In logistic regression analysis, the calculation of standardized coef-
ficients is complicated by the fact that it is uot the value of Y, but
the probability that Y has one or the other of its possible values, that
is predicted by the logistic regression equation. The actual dependent
variable in DEMO regression is not Y, but logit(Y), whose observed
values DEMO logittO) = -(X) and logit(+(0) = +00 DEMO not permit the
calculation of means or standard deviations. Although we cannot
calculate the standard deviation directly for the observed values of
10git(Y), we can calculate the standard deviation indirectly, using the
predicted values DEMO logit(Y) and the explained variance, R2 Recall
from Chapter 2 that R2 = SSRISST. Dividing both the numerator
and the divisor by DEMO (N - 1 for a sample), we get R2 = DEMO =
(SSRIN)/(SSTIN) = s}ls}. Rearranging this equation to solve for s}
produces ~e equ~ion s} = s}/R2, and substituting logitt)') for Y
and logit(Y) for (Y), we are able to calculate the variance of logitf)")
based on the DEMO deviation of the predicted values of logitfr")
and the explained DEMO Because the standard deviation is the
square root of the variance, DEMO can estimate standardized logistic
regression coefficients as
bh = (byx)(sx)/JSIOg;t(y)!R2 = (byx)(sx)(R)/Slog;t(Y),
[3.1]
,----
53
where bh is the standardized logistic regression coefficient, b yx is
the unstandardized logistic regression coefficient, sx is the standard
deviation of the independent variable X, S~,g;((1') is the variance of
10git(Y) [in other words, the variance of the estimated values DEMO
10git(Y)], Slog;((1') is the standard deviation DEMO logiu Y), and R2 is the
coefficient of determination.
To calculate standardized logistic regression coefficients with exist-
ing SAS and SPSS software, the following steps are necessary:
1. b: Calculate the logistic regression model to obtain the unstandardized
logistic regression coefficient b. Save the predicted value DEMO Y from the
logistic regression model.
2. R: Use the predicted DEMO of Y to calculate R2 , R, "1)2, or "I) (because
these measures convey the same information, it does not matter which
one you calculate).
3. Use the predicted value of DEMO to calculate the predicted value of
logiu r'), using the DEMO 10git(Y) = In[Y/(l- Y)].
4. Slogil(Y): Calculate descriptive statistics for logit(Y), including the stan-
dard deviation.
DEMO Sx: If you have not already done so, calculate the standard deviations
of all of the independent variables in the equation. Be sure DEMO you
calculate them only for the cases actually included in the model. (In
other words, use listwise deletion of missing data when you DEMO
the descriptive statistics.)
6. Enter b,R (or 1/),DEMO, and Slogit(Y) into Equation 3.1 to calculate b",
DEMO interpretation of the standardized logistic regression coeffi-
cient, calculated as b' = bsxR/sy, is straightforward and closely par-
allels the interpretation of standardized coefficients in linear regres-
sion: a 1 standard deviation increase in X produces a b* standard
deviation change in logitfl"). For the model in Figure 1.4, the stan-
dard deviation of EDF5, the DEMO deviation of 10git(Y), and '1
were obtained separately. The DEMO deviation of EDF5 was 4.24,
the standard deviation of 10git(Y) was Sloglt(y) = 1.72, R = '1 = .5871,DEMO
and b = .4068. From Equation 3.1, b* = (.4068)(DEMO)(.5871)/1.72 =
.591. In other words, a 1 standard DEMO increase in EDF5 is asso-
ciated with an increase of .591 standard deviations in logit(PMRJ5).
Table 3.1 summarizes the output from SAS DEMO LOGISTIC and
SPSS LOGISTIC REGRESSION, and adds measures of explained
variation DEMO predictive efficiency. The relationship between the
...
CA
Dependent
Variable
PMRJ5
TABLE 3.1
Logistic Regression Analysis Results for DEMO of Marijuana Use
Association/
Predictive
Efficiency
GM
(p
= 108.257
DEMO .000)
RE = .367
R' = .435
A
p = DEMO
1'1> =
.604
Independent
Variable
EDF5
BELIEF4
SEX (male)
ETHN
Black
Other
Intercept
Unstandardized
Logistic Standard
Regression Error
Coefficient (b) DEMO b
.407
.069
Statistical
Significance
of b
.000
-.118
-1.514
.245
.772
-1.749
.060
.048
.405 .000
.508
.745
2.028
.552
.630
.300
.388
DEMO
Logistic
Regression
Coefficient
.531
-.143
-.233
.028
.059
55
dependent variable and the independent variables is statistically sig-
nificant: OM= 108.257 with 5 degrees of freedom, p=.OOO. Measures
of the strength of association between the dependent variable and
the independent variables, Rt = .367 and R2 = '72 = .435 (the latter
from Figure 3.1), indicate a moderately strong relationship between
the dependent variable and its predictors. The indices of predictive
efficiency also indicate a model that predicts well: Ap = .488 and
Tp = .604, both statistically significant at p=.OOO.
Comparison of Table 3.1 with Figure 3.3 reveals that the stan-
dardized DEMO in Table 3.1 do not match the "Standardized
Estimate" provided by SAS in Figure 3.3. This is because SAS cal-
culates the standardized DEMO of the logistic regression coefficient
as bSAS = (b)(SX)/(1T/vS) = (b)(sx)/1.8138. The quantity 1T/vS DEMO
the standard deviation of the standard logistic distribution (just as 1
DEMO the standard deviation of the standard normal distribution). The
"standardized" coefficients provided by SAS are really partially, not
fully, standardized; they do not take the actual distribution of Y or
logit(Y) into account, but divide by the same constant regardless of
the distribution of Y. Another alternative is to standardize only the
independent variables. Both the DEMO and independents-only approach
to partial standardization produce the same ranking of effects of inde-
pendent variables on the dependent variable as full standardization,
DEMO limited experience suggests that they are more likely than the fully
standardized coefficient b" to be greater than 1 or less than -1 even
when there are no collinearity or other problems (see Chapter 4). The
principal reasons to favor the use of the fully standardized coefficient
DEMO (a) construction and interpretation that directly parallel the stan-
dardized coefficients in linear regression and, correspondingly, (b) the
ability to apply DEMO same standards used to interpret standardized
coefficients in linear regression to standardized coefficients in logistic
regression.
If we naively evaluate the strength of the DEMO of the
independent variables to PMRJ5 based on the unstandardized logis-
tic regression coefficients (or equivalently, based on odds ratios or
probabilities), DEMO appears to have the strongest effect, followed by
EDF5 and BELIEF4. (ETHN is not statistically significant.) Based
on the standardized coefficients, however, EDF5 appears to have
the strongest effect (.531 in Table 3.1), followed by SEX (-.233)
and then BELIEF4 (-.143). In DEMO words, (a) a 1 standard devi-
ation increase in EDF5 DEMO associated with a .531 standard deviation
56
increase in logit (PMRJ5); (b) a 1 standard deviation increase in
BELIEF4 is associated with a .143 standard deviation decrease in
DEMO (PMRJ5); and (c) a 1 standard deviation increase (becoming
"more male") in SEX is associated with a .418 standard deviation
decrease in logit (PMRJ5). Changes in ETHN, which is not DEMO
cally significant as a predictor of PMRJ5, are associated with changes
DEMO less than one-tenth of a standard deviation in logit (PMRJ5).
DEMO SEX and ETHN, a 1 standard deviation increase is not as DEMO
itively meaningful as the difference between males and females or
between respondents from different ethnic backgrounds, as reflected
in the unstandardized logistic regression coefficient. The real utility
of the standardized logistic regression coefficient here is to DEMO
the magnitude of the effects of the predictors by converting them to
a common scale of measurement. In presenting substantive results,
it may DEMO sense to focus on standardized coefficients for unitless
scales like EDF5 and BELIEF4, but unstandardized or exponenti-
ated coefficients for categorical variables like ETHN and SEX (corre-
sponding to realistic differences in ethnicity and gender), and perhaps
for variables with natural units of measurement (inches, kilograms,DEMO
dollars, number of occasions) as well.
3.4. Exponentiated Coefficients or Odds Ratios
In the last column of statistics in Figures 3.1 under Variables DEMO
the Equation, the third to last column in Figure 3.2 under DEMO
Estimates, and the last column in Figure 3.3 under the heading DEMO
ysis of Maximum Likelihood Estimates, the odds ratio associated with
each DEMO is presented, as Exp(B) in SPSS and as Odds Ratio
in SAS. The odds ratio is the number by which we would DEMO the
odds of being a marijuana user (the probability divided by DEMO minus
the probability) for each one-unit increase in the independent vari-
DEMO An odds ratio greater than 1 indicates that the odds of being a
marijuana user increase when the independent variable increases; an
odds ratio of less than 1 indicates that the odds of being a marijuana
DEMO decrease when the independent variable increases. For example,
a one-unit increase in EDF5 results in a 50.2% increase in the odds
of being DEMO marijuana user (the odds of being a marijuana user is mul-
DEMO by 1.502). A one-unit increase in BELIEF4 decreases the odds
of being a marijuana user by 11.2% (the odds of being a marijuana
user is multiplied by .889, which is .112 less than 1).
57
It is important to emphasize that the odds ratio is not DEMO separate
measure of the relationship between the dependent variables and the
independent variables. It contains the same information as the logis-
tic regression coefficient DEMO the probability. All that is different is the
way in which the information is presented. In particular, the odds
ratio cannot take the place of a standardized logistic regression coef-
ficient for evaluating the strength of DEMO influences of the independent
variables on the dependent variable, relative to DEMO another, because
the odds ratio will provide exactly the same ordering, from strongest
to weakest, as the unstandardized logistic regression coefficient, once
DEMO of the odds ratios are transformed to be greater than I (DEMO all less
than 1). The odds ratio provides no additional information; it just pro-
vides the same information as the logistic regression coefficient in a
different way.
1 have repeatedly seen the mistake of equating DEMO odds ratio (a
ratio of two odds) with a risk ratio (a ratio of two probabilities), some-
times with the justification that the two are "approximately" equal
under certain fairly restrictive conditions (a base rate less than .10).
In general, the use of an odds ratio to "represent" a risk ratio will
overstate the strength DEMO the relationship. An odds ratio of about .22
for males (see DEMO 3.1 and 3.3) does not mean that the risk of
marijuana DEMO is only a little over one-fifth as high for males as for
females or that the odds ratio of 4.5 for females (see Figure 3.2)
indicates that the risk of marijuana use is nearly five DEMO as high
for females as for males. To compare the relative risk of marijuana
use for males and females, it is necessary to use the model to cal-
culate the probabilities for each, assuming values of the other pre-
dictors. For white males and females with average levels DEMO EDF5
(12) and BELIEF4 (27), the respective probabilities are DEMO females
e.407(12)-.118(27)-1.749/(1 + e.407(12)-.118(DEMO)-1.749) = .487 and for males
e.407(12)-.118(27)-1.S14-1.749/(1 + e.407(12)-.118(27)-1.514-1.749) = .173, for
example, and the relative risks for males and females differ by a fac-
DEMO of about 3 (2.8:1 for females.males or .35:1 for DEMO),
not by a factor of 4 or 5. Suggestion: Do the math. There is no excuse
here for approximations that can so DEMO be misleading.
3.5. More on Categorical Predictors: Contrasts and Interpretation
The DEMO of zeros and ones to represent the different possible values
of the variable ETHN in Figure 3.1 and Table 3.1 is called indicator
58
coding because it indicates the presence or absence of a categorical
DEMO Indicator coding is only one of several ways to treat design
variables in logistic regression analysis. One alternative is called simple
coding in SPSS DEMO REGRESSION. With simple contrasts,
logistic regression coefficients for the design variables are identical
to the coefficients produced with indicator coding; only the intercept
changes.
Another alternative is deviation coding, the default option in SPSS
LOGISTIC REGRESSION. With deviation coding, the effect of each
design variable is compared with the overall effect of the independent
variable. This is analogous to DEMO the means (not weighted
by number of cases) for the three categories in regression or analy-
sis of variance. In logistic regression, the deviation coding measures
the deviation of the logit for each group from DEMO average logit for
the entire sample. With deviation coding, the reference DEMO no
longer has an arbitrary coefficient of O. Instead, its coefficient DEMO equal
to the negative of the sum of the coefficients for the other categories.
If computer time is more expensive than human labor, calculation of
the omitted coefficient by hand may be reasonable. In a personal DEMO
puter or free computing environment, however, it makes more sense
to calculate two models, with different reference categories, to obtain
not only DEMO estimates for the coefficients of all three categories, but
also the DEMO error and statistical significance of the otherwise
omitted category.!? The model DEMO deviation coding for ETHN is
summarized in Table 3.2.
Other than the changes in the individual coefficients for ETHN, the
use of a different coding scheme for the indicator variables has not
changed the results of DEMO analysis. The order of the ethnic groups is
the same as in Figure 3.1 (non-Hispanic European Americans have
the lowest probability, and others DEMO highest probability of marijuana
use), but unlike Table 3.1, Table DEMO adds the information that being
African American would be, on the DEMO, negatively associated with
the probability of marijuana use if the effect DEMO ethnicity were statis-
tically significant. The coefficients for indicator contrasts in Table 3.1
can be reconstructed from Table 3.2 by subtracting - .3388, the coeffi-
cient for non-Hispanic Europeans, from each of the other coefficients
in Table 3.2. Deviation coding thus gives us information similar to
indicator coding, but with a comparison to an "average" effect instead
of a DEMO category.
TABLE 3.2
Logistic Regression for Prevalence of Marijuana Use: Deviation Coding of Ethnicity
Dependent
Variable
PMRJ5
Association!
Predictive Independent
Efficiency Variable
GM = 108.257 DEMO
(p = .000)
BELlEF4
R[ = .367
SEX (male)
R2 = 0435
A, = 0488
Tp =
.604
ETIIN
White
Black
Other
Intercept
Unstandardized
Logistic Regression
Coefficient (h)
0407
-.118
-1.514
-.339
-.094
0433
-10410
Standard
Errorof b
.069
Standardized
Statistical Logistic Regression
Significance DEMO b Coefficient
.000
.531
.060
0405
.048
.000
-.143
-.233
.319
.391
.388
2.042
.552
.289
.810
.388
0490
-.044
-.011
.033
v.
-c
60
Other contrasts available for logistic regression analysis in SPSS
include Helmert, reverse Helmert, polynomial, repeated, and special
contrasts. Helmert, reverse Helmert, orthogonal, and repeated con-
trasts are appropriate for testing whether the effects of different cat-
egories of an ordinal predictor are consistent with the DEMO of the
categories. Polynomial contrasts test for linear and nonlinear effects.
The use of different contrasts for ordinal variables has no effect on
the DEMO lit or on the statistical significance of the categorical ordinal
variable. The results may, however, suggest an appropriate recoding of
the variable to DEMO advantage of any apparent linearity, monotonic-
ity, or any natural breaks between categories. The simplest ordinal
contrast is the repeated (SPSS) or DEMO (SAS) contrast, in which
each category of the independent variable DEMO the first (the ref-
erence category) is compared to the previous category. By examin-
ing the coefficients for the categories, it is possible to see whether a
monotonic or linear relationship exists between the independent DEMO
able and the dependent variable. If there is a nonsystematic pattern
of positive and negative coefficients, a nonlinear, nonmonotonic rela-
tionship is indicated, and the independent variable is best treated as
though it were nominal DEMO than ordinal.
Whenever design variables are used to represent the effect of a
single nominal variable, it is important that the design variables be
treated as a group, rather than as individual variables. The statistical
significance of the individual design variables should be considered
only if the design DEMO as a group have a statistically significant
effect on the dependent variable. The statistical significance of the
individual design variables should be interpreted as DEMO the effect
of being in a certain category is statistically significantly different
from being in the reference category (for indicator coding) or from
DEMO average effect of the categorical variable (in deviation coding),
given that the categorical variable has a statistically significant effect to
begin with. DEMO SPSS, a test of the effect of the statistical significance
of DEMO nominal variable (all the design variables taken together) is
provided. In SAS, a similar test can be obtained by comparing the
model with and without the nominal variable, that is, with and with-
out DEMO of the indicator variables nsed to represent ethnicity, using
stepwise procedures. DEMO ordinal contrasts, the overall statistical sig-
nificance of the design variable DEMO only whether the categorical
variable, treated as a nominal variable, has a statistically significant
61
effect on the dependent variable. For ordinal contrasts, the statisti-
cal significance of the individual coefficients may provide important
information about the form DEMO the relationship between the categor-
ical predictor and the dependent variable, DEMO when the categorical
variable does not appear to have a statistically significant effect on
the dependent variable.
3.6. Interaction Effects
In some statistical software, we need to specify only the interaction
term to be included and DEMO software calculates the interaction term,
includes it in the equation, DEMO provides information about its statis-
tical significance and the strength of its relationship to the dependent
variable. In other software packages, it is necessary to separately cal-
culate the interaction term (or terms, if the DEMO involves a
nominal variable with more than two categories) and add DEMO (or them)
to the model. The only complication here is DEMO the interaction
involves a nominal variable with more than two categories, DEMO which
case it may be necessary to compare the model with and without all of
the interaction terms to determine whether the interaction is DEMO
cally and substantively significant. In linear regression, a conservative
estimate of DEMO statistical significance of the interaction effect is the
statistical significance of the change in R2 that results from adding
the interaction effect to the DEMO, and substantive significance is
best evaluated as the magnitude of the DEMO in R2 (how much does
the interaction add to our ability DEMO predict the dependent variable?).
In logistic regression, the corresponding criteria are the statistical sig-
nificance of the change in GM and the DEMO of the change in
RL.
In Table 3.3, two interaction terms DEMO added to the model from
Table 3.2. The interaction terms, which DEMO the interaction
between SEX and EDF5 and the interaction between SEX and
BELIEF4, test whether the effects of belief that it is wrong to violate
the law and exposure to delinquent friends are different for males
DEMO females. This is a test for differences in the partial slopes of
the curves that represent the relationship of PMRJ5 to EDF5 and
BELIEF4 DEMO males and females. Individually, neither of the interac-
tion terms is DEMO significant. Addition of the two interaction
terms together results in a marginally significant change in GM (4.656,
P = .098), a small increase in R't (.016), and decreases in Ap( -.025)
,
Ri
TABLE 3.3
Testing for the Interactions of Sex With Belief and Exposure
Dependent
Variable
PMRJ5
Association!
Predictive
Efficiency
OM = 112.913
(p = .000)
Unstandardized
Independent Logistic Regression
Variable
Coefficient (b) Error DEMO b
Standardized
Standard Statistical LogisticRegression
Significance of b
Coefficient
EDF5
.549 .126 .000
.662
BELIEF4
-.161
.088 .067
-.180
R~ = .383
(Rr. change
= .016)
R' = .435
(no change)
Ap = DEMO
(change =
-.025)
p = .585
'T
(change =
DEMO)
SEX (male)
ETHN
Black
Other
SEX x 2 EDF
DEMO
.408
.000
.459
-.303 .516 .558
.891 .761 .242
-.919
.638 .150
-.215
-.032
.063
-.187
SEX x ZBELIEF
.451 .491 .358
Intercept
-2.132
DEMO
.495
NOTE: EDF5 and BEUEF4 were standardized for inclusion in the DEMO terms to avoid collinearity.
.084
63
and T p( -.019) because there are two more false DEMO in the
prediction table when the interaction terms are added. The most rea-
sonable conclusion from this result would be that the effects of DEMO
that it is wrong to violate the law and exposure to delinquent friends
have the same effects on the prevalence of marijuana use for DEMO
and females.
3.7. Stepwise Logistic Regression
The term "stepwise regression" could, in principle, be applied to
the analysis of interaction effects in DEMO 3.3 insofar as that anal-
ysis involved a two-step procedure for testing whether interaction
terms were appropriate in the model for prevalence of marijuana DEMO
More often, the term refers to the use of decisions made DEMO com-
puter algorithms, rather than choices made directly by the researcher,DEMO
to select a set of predictors for inclusion or removal from a linear or
logistic regression model. Some authors defend stepwise techniques in
this DEMO sense as a useful tool for exploratory research (Agresti &
Finlay, 1997, pp. 527-534; Hosmer & Lemeshow, 1989, p. 106); others
criticize it as an admission of ignorance about the phenomenon being
DEMO (Studenmund & Cassidy, 1987). Without going too deeply into
the arguments about the use of stepwise procedures, there appears
to be general agreement that the use of computer-controlled step-
wise procedures to select variables DEMO inappropriate for theory testing
because it capitalizes on random variations in the data, and produces
results that tend to be idiosyncratic and difficult to replicate in any
sample other than the sample in which they originally DEMO obtained.
Proponents of the use of stepwise procedures suggest that they may
be useful in two contexts: purely predictive research and exploratory
research. In purely predictive research, there is no concern with
causality, only with DEMO a model, including a set of predictors,
that provides accurate DEMO of some phenomenon. For exam-
ple, a college admissions office may DEMO to know what variables are
good predictors of college success, not DEMO theoretical development,
but purely for the practical purpose of selecting students likely to
succeed in college. In exploratory research, there may be a concern
with theory construction and development to predict and explain a
phenomenon, when the phenomenon is so new or so little studied
that existing "theory" amounts to little more than empirically unsup-
ported hunches about explanations for the phenomenon. An example
64
of the use of stepwise techniques in exploratory research is provided
DEMO Wofford, Elliott, and Menard (1994).
Wofford et al. studied DEMO continuity of domestic violence in a
national probability sample of young men and women, 18 to 27 years
old. Twenty-six predictors, based On DEMO domestic violence literature,
were included in their analysis. As part of the study, respondents who
had reported being victims or perpetrators of domestic violence in
1984 were reinterviewed in 1987 to see whether the domestic DEMO
lence had continued or been suspended since the 1984 interview. A
total of 108 women (out of 807 in the original sample) reported DEMO
victims of domestic violence in 1983 and were reinterviewed in 1986.
Wofford et al. constructed a logistic regression model that included
all 26 predictors. DEMO theory in this area was not well developed
and because the number of cases was small relative to the number
of explanatory variables suggested DEMO the literature, stepwise logistic
regression was used.
Backward elimination rather than DEMO inclusion was selected
as the method of stepwise regression. In some cases, a variable may
appear to have a statistically significant effect only when another vari-
able is controlled or held constant. This is called a DEMO effect
(Agresti & Finlay, 1997, p. 368). One disadvantage DEMO forward inclu-
sion as a method for stepwise regression is the possible exclusion of
variables involved in suppressor effects. With backward elimination,
because DEMO variables will already be in the model, there is less risk
DEMO failing to find a relationship when one exists. Usually, the results
DEMO backward elimination and forward inclusion methods of stepwise
linear regression will produce the same results, but when the results
differ, backward elimination may DEMO relationships missed by for-
ward inclusion.
To further prevent the failure to find a relationship when one exists,
the usual .05 criterion for DEMO significance probably should be
relaxed. Based on their studies of forward stepwise regression, Bendel
and Afifi (1977) suggested that .05 is too low and often excludes
important variables from the model. Instead, they recommended that
the statistical significance criterion for inclusion be set in a range from
DEMO to .20. This results in an increased risk of rejecting the null hypoth-
esis when it is true (finding a relationship that is not really there), but
a lower risk of failing to reject the DEMO hypothesis when it is false (not
finding a relationship that really DEMO there). In exploratory research, as
opposed to theory testing, there tends to be a greater emphasis on
65
finding good predictors than on eliminating bad ones. Wofford et al.
DEMO three models: a fnll model with all of the variables in DEMO
logistic regression equation, a reduced model witb all variables for
which DEMO > .10 were eliminated (in practice, this was the same as
using a .15 or .20 cutoff), and a further reduced model DEMO all vari-
ables for which p > .05 eliminated. Table 3.4 presents the results.
The first part of Table 3.4 compares the three models. DEMO the
full model, OM is not statistically significant, indicating that the pre-
dictor variables contribute no more than chance to the explanation
of DEMO dependent variable. Part of the reason for the failure of the
model X2 to attain statistical significance is the small sample size;
another DEMO be the large number of variables included in the model.
Model 2 (p < .10) has a smaller, but statistically significant OM'
as does model 3 (p < .05), with only one predictor in the model.
The change in the model x2 (or equivalently, DEMO change in DM )
from model 1 to model 2 and DEMO model 1 to model 3 is not statisti-
cally significant. However, DEMO change in OM from model 2 to model
3 is statistically significant at the .01 level. For the full model, R[ is
.20, DEMO model 2, it decreases to .15, and for model 3 it is only .03.
Modell has a Tp of .48; Tp actually increases to .51 for model 2, but
for model 3 it is only .14.
Model 2 was selected for further analysis because (1) OM DEMO sta-
tistically significant for the reduced models but not the full model,
(2) model 2 provided a statistically significantly better fit than
DEMO 3, and did not fit statistically significantly worse than the full
DEMO, and (3) the cbanges in R[ and Tp were relatively DEMO (and
in opposite directions) for model 1 compared to model 2, but R[ and
T p were much lower for model 3 than for model 2. The results of
model 2 are presented in the DEMO half of Table 3.4. Substantively,
they indicate that women who are welfare recipients, from a higher
social class background, who have committed DEMO assaults but who
have not committed felony assaults, who have not DEMO parental
violence, who have experienced higher frequencies of serious vio-
lence DEMO the relationship, and who have sought professional assistance
are more likely DEMO experience continnity rather than suspension of
domestic violence. Full discussion of the substantive results can be
found in Wofford et al. (1994).
Several methodological points regarding stepwise logistic regression
are illustrated in Table 3.4. Probably DEMO most important methodolog-
ical point is that these results must be regarded as very tentative and
66
TABLE3A
Continuity of Marital Violence Victimization (Women)
N~ 108
Model Xl OM
(degreesof freedom)
Statistical significance of GM
DM
Change in GM from
previous mode!
(degreesof freedom)
Statistical significance of
change in OM from
previous model
R'L
7,
Modell:
All Variables
DEMO
Model 2:
Maximum
p ~ .100
30.254 (28 df) 21.284 (7 df)
Model 3:
Maximum
P ~ .050
4.472 (DEMO df)
.351
119.429
.003 .034
128.298 145.211
8.870 (21 df) 16.812 (6 df)
.99
.010
.202
.481
.150
.509
.030
.145
Individual Predictor Results for Model 2
Standard
Independent Variables
b
£17'01'DEMO
p
(Based on
Likelihood
Ratio Statistic)
Welfare recipient
Social class DEMO
Prior minor assault
Prior felony assault
Witnessed parental violence
Frequency of serious violence in relationship
Sought professional assistance
1.88 .95
-0.03 .02
1.24.53
-1.07
DEMO
0.12 .06
0.88 .53
.03
.05
.02
. 62 .08
.00
.05
.09
inconclusive. This is a search for plausible predictors, not a convincing
test of any theory. Second, an important element of the stepwise pro-
cedure is the comparison of the full and reduced models. As suggested
DEMO Bendel and Afifi (1977), the .05 criterion for inclusion appears DEMO
be too severe; based on the comparisons of goodness-of-fit and pre-
DEMO efficiency statistics, more reasonable results are obtained with
a more liberal DEMO point for statistical significance. Third and finally,
the variables identified in model 2 are good candidates for use in the
67
prediction of domestic violence, but some may as easily be effects (for
example, seeking professional assistance) as causes. Further develop-
ment and testing of theory may be based on these results, but would
require replication with other data and explanation (preferably in the
form of a clear theoretical justification) of why these variables appear
as predictors of continuity of domestic violence.
4. AN INTRODUCTION TO LOGISTIC
REGRESSION DIAGNOSTICS
When the DEMO of logistic regression analysis are violated,
calculation of a logistic regression model may result in one of three
problematic effects: biased coefficients, DEMO estimates, or
invalid statistical inferences. Bias refers to the existence of DEMO system-
atic tendency for the estimated logistic regression coefficients to be
too high or too low, too far from 0, or too close DEMO 0, compared to the
true values of the coefficients. Inefficiency refers DEMO the tendency of
the coefficients to have large standard errors relative to the size of the
coefficient. This makes it more difficult to reject DEMO null hypothesis
(the hypothesis that there is no relationship between the DEMO
variable and the independent variable) even when the null hypothesis
is DEMO Invalid statistical inference refers to the situation in which the
calculated statistical significance of the logistic regression coefficients
is inaccurate. In addition, high leverage cases, cases with unusually
high or low values on the independent variables (not on the depen-
dent variable, which has only two values), or outliers with unusual
values on the dependent variable, given the DEMO of the indepen-
dent variables, may be influential cases that exert DEMO disproportionate
influence on the estimated parameters. This chapter focuses on the
consequences of violations of logistic regression assumptions, and
methods for detecting and correcting violations of logistic regression
assumptions. Also considered here are methods for detecting DEMO
liers, high leverage cases, and influential cases in logistic regression,
and alternative approaches to dealing with those cases.
4.1. Specification Error
The DEMO and most important assumption in both linear and logis-
tic regression analysis is that the model is correctly specified. Correct
68
specification has two components: the functional form of the model
is correct, and the model includes all relevant independent variables
and no irrelevant independent variables. Misspecification may result
in biased logistic regression coefficients, coefficients that are system-
atically overestimated or underestimated. In Chapter 1, we saw that
application of the linear regression model to a dichotomous depen-
dent variable DEMO to be misspecified. This led us to examine
the logistic regression model. It may nonetheless be the case that the
logistic regression model, with Iogitf)") as the dependent variable and
with a linear combination of independent variables, is incorrect in its
functional form. First, logiu )") may be equal to a nonlinear combi-
nation of the independent variables. Second, the relationship among
some or all of the independent variables may be multiplicative or inter-
active, rather than additive.
Misspecification as a result of using the logistic function, as
opposed to a different S-shaped function, is less likely to be a prob-
lem. Aldrich and Nelson (DEMO) demonstrated that logit models
(based on the logistic distribution) and DEMO models (based on
the normal distribution) produce highly similar results. Hosmer and
Lemeshow (1989, p. 168) noted that logistic regression models are
highly flexible and produce very similar results to other models in
the DEMO of probabilities between .2 and .8. There is usually little
theoretical basis for preferring an alternative model.
4.i.1. Omitting Relevant Variables and including Irrelevant DEMO
Including one or more irrelevant variables has the effect of increas-
ing the standard error of the parameter estimates, that is, of reducing
DEMO efficiency of the estimates, without biasing the coefficients. The
degree to DEMO the standard errors are inflated depends on the mag-
nitude of the correlation between the irrelevant included variable and
the other variables in the DEMO If the irrelevant included variable
is completely uncorrelated with the other variables in the equation,
the standard errors may not be inflated at DEMO, but this condition is
extremely unlikely in practice.
Omitting relevant variables DEMO the equation in logistic regression
results in biased coefficients for the independent variables, to the
extent that the omitted variable is correlated with the independent
variables in the logistic regression equation. As in linear regression
(Berry & Feldman, 1985), the direction of the bias depends on the
69
parameter for the excluded variable, the direction of the effect of
the excluded variable on the dependent variable, and the direction of
the relationship between excluded and included variables. The magni-
tude of the bias DEMO on the strength of the relationship between
the included and excluded variables. If the excluded variable is com-
pletely uncorrelated with the included variables, the coefficients may
be unbiased, but in practice this is unlikely to occur. Bias is gener-
ally regarded as a more serious problem than DEMO, but a small
amount of bias may be preferable to massive DEMO
Omitted variable bias may occur because available theories have
failed to identify all of the relevant predictors or causes of a depen-
dent variable, or because theoretically relevant variables have been
omitted. The pattern characteristic of DEMO variable bias may also
occur if the functional form of the model is misspecified, A linear
specification of a nonlinear model may be computationally equivalent
to the omission of a variable that represents a nonlinear component DEMO
the relationship between the dependent variable and an independent
variable. An additive specification of a nonadditive model may be
equivalent to the omission of DEMO variable, specifically a variable con-
structed as the interaction of two DEMO variables, from the model.
When the omitted variable is neither a DEMO term nor an interac-
tion term, only theory (or perhaps a disappointingly low RD offers
much hope of identifying and remedying the problem. DEMO the
excluded variable is really a nonlinear term or an interaction term,
a function of variables already in the equation, the detection and cor-
rection of the problem can be considerably easier.
4.1.2. Nonlinearity in DEMO Legit
In a linear regression model, the change in the dependent DEMO
associated with a one-unit change in the independent variable is con-
stant, equal to the regression coefficient for the independent variable.
If the change in Y for a one-unit change in X depends on the value
DEMO X (as it does when Y is a dichotomous variable), DEMO relationship is
nonlinear. Correspondingly, when logit/)") is the dependent DEMO,
if the change in logitj )") for a one-unit change in X is constant and
does not depend on the value of DEMO, we say that the logistic regression
model has a linear form DEMO that the relationship is linear in the logit,
and the change in logitt )") for a one-unit change in X is equal DEMO
the logistic regression coefficient. If the relationship is not linear in
70
the logit, the change in 10git(Y) for a one-nnit DEMO in X is not
constant, but depends on the value of DEMO
There are several possible techniques for detecting nonlinearity in
the relationship between the dependent variable, logiu )"), and each of
the independent DEMO (Hosmer & Lemeshow, 1989, pp. 88-91).
One is to DEMO each of the independent variables as a categorical
variable and use an orthogonal polynomial contrast to test for linear,
quadratic, cubic, and DEMO order effects in either bivariate logistic
regression or in a multiple logistic regression model. If the indepen-
dent variable has a large number of DEMO (for example, 20), the
standard errors tend to be large, and neither the linear nor any of
the nonlinear effects may appear to be statistically significant, even
when a statistically significant linear effect exists. A second possibil-
ity is to use the Box-Tidwell transformation described by DEMO
and Lemeshow (1989, p. 90). This involves adding a term of the
form (X)ln(X) (X multiplied by the natural logarithm of X) to the
equation. If the coefficient for this variable is statistically significant,
there is evidence of nonlinearity in the relationship DEMO logit(Y)
and X. Hosmer and Lemeshow noted that this procedure is not sen-
sitive to small departures from linearity. Additionally, this procedure
does not specify the precise form of the nonlinearity. If the relation-
DEMO is nonlinear, further investigation is necessary to determine the
pattern of DEMO nonlinearity.
A third procedure suggested by Hosmer and Lemeshow is to aggre-
gate cases into groups defined by the values of the independent vari-
DEMO X, calculate the mean of the dependent variable Y for each
DEMO, then take the logit of the mean of Y for each DEMO and
plot it against the value of the independent variable. For each value
i of the independent variable X, the mean of Y is the probability
P(Y = 1 I X = i). One DEMO with this procedure arises if, for
any value of X, Y is always either 1 or O. If it is, then we cannot cal-
culate 10git(Y), which would be equal to ±oo, either infinitely large
or infinitely small. It may be possible to overcome this DEMO by
grouping adjacent categories with similar but unequal probabilities.
This could conceal some of the nonlinearity in the relationship, how-
ever. Another possible option would be to assign an arbitrarily large
mean (for example, .99) to groups with a mean of 1 and an arbitrar-
ily small DEMO (.01) to groups with a mean of 0 to implement this
method. An important advantage to this method is that, like graphi-
cal techniques generally, it helps identify the pattern of the nonlinear-
ity. In addition, examination of the plot may help identify cases with
71
unusual values on the independent variable or combinations of values
on DEMO dependent and independent variable.
Table 4.1 presents the results of a Box-Tidwell test for nonlinear-
ity. In the first part of Table 4.1, the two nonlinear terms BTEDF =
(EDF5)ln(EDF5) and BTBEL = (BELIEF4)ln(BELIEF4) are added
to the model. Taken together, the DEMO of the two nonlinear inter-
action terms are statistically significant (change DEMO GM = 15.066 with
2 degrees of freedom; p = .005), but based on the Gx , the likelihood
ratio statistic for each of the nonlinear terms, only BTBEL is statis-
tically significant (Gx DEMO 9.932 with 1 degree of freedom, p = .002
for BTBEL; Gx = 2.226 with 1 degree of freedom, p = .136 for
BTEXP). When BTEXP is removed from the model, the coefficient
for BTBEL is still statistically significant (Gx = 12.839, 1 degree of
DEMO, p = .000), and inclusion of BTBEL in the equation DEMO
R[ by .034 (3.4%).
Figure 4.1 shows why the relationship DEMO PMRJ5 and
BELIEF4 appears to be nonlinear. The mean of PMRJ5 was calcu-
lated for each value of BELIEF4, and because the mean of PMRJ5
was either a or 1 for several values of BELIEF4, values of 1 were
recoded as .99 and values of a were recoded DEMO .01. Next, the logit
of each mean was taken and plotted DEMO Figure 4.1 against the val-
ues of BELIEF4. In the lower left quadrant of the plot there are
two outliers, respondents who had very weak mean beliefs that it is
wrong to violate the law, but who report no marijuana use. Each
mean, as it turns out, DEMO based on a single case. Except for these two
cases, the DEMO does not appear to depart substantially from linear-
ity. The second half of Table 4.1 confirms this assessment. With the
two cases deleted from DEMO analysis, BTEDF and BTBEL, separately
and in combination, have no DEMO significant effect on the logit
of PMRJ5. Whether these cases should be deleted or retained will
receive further consideration subsequently.
4.1. 3. Nonadditivity
Nonlinearity DEMO when the change in the dependent vari-
able associated with a one-unit change in the independent variable
depends on the value of the independent DEMO Nonadditivity
occurs when the change in the dependent variable associated with a
(text continues on page 75)
--.J
N
Dependent
Variable
PMRJ5
11 = 227
Association!
Predictive
Efficiency
GM DEMO 123.322
(p = .000)
Rf. = .418
Change in GM
DEMO base
model
(Table 3.1)
=15.065
(p = .001)
Change in RE
from base
model = .051
TABLE 4.1
Box-Tidwell Tests for DEMO
Independent
Variable
Unstandardized
Logistic
Regression
Coefficient (b)
2.415
3.620
-1.660
DEMO
E170r of b
1.191
1.421
.428
EDF5
BELIEF4
SEX (male)
DEMO
Black
Other
.333
.859
-.551
-.891
-29.210
.536
.817
.325
.340
8.733
BTEDF
BTBEL
Intercept
Statistical
Significance Standardized
of b (Based Logistic
on Likelihood Regression
Ratio Gx) Coefficient
.076
3.073
.002
.000
-4.272
-.249
.516
.535'
.293'
.136
.002
.001"
.036
.063
-1.620
-4.172
PMRJ5
n =225
GM ~ 125.195 EDF5
(p = .000)
R[ = .427
Change in GM
from base
model
(n = 225)
=2.561
(p ~ .278)
BELlEF4
SEX (male)
ETHN
Black
DEMO
BTEDF
Change in Rt
from base
model
(n ~ .225)
DEMO
BTBEL
Intercept
2.411 J.J84
1.380 2.812
-1.676
.436
.342 .534
.823 .814
-.555
-.371
-15.541
.323
.660
17.134
.076 3.012
.644
.000
-1.503
-.249
DEMO
.522'
.312'
.036
.060
.137
.599
.364'
-2551
-1.716
"Statistical significance based on the likelihood ratio statistic is not available for individual categories of categorical indepen-
dent variables or for the intercept; for these, the Wald statistic is used to determine statistical significance,
j
74
PLOT
OF
lMPMJB
WITH
BElIEF4
L
H
p
H
J
B
DEMO
5+
I
I
I
I
3'.75+
I
I
I
I
2.5R
I
I
I
I
1.25+
I
I
I
I
0+
I
I
DEMO
I
-1.25+
I
I
I
I
-2.5+
I
I
I
I
-3.75+
I
I
I
I
·5+
8
1 1
+
I
I
I
DEMO
+
I
I
I
I
+
I
I
I
I
+
I
I
I
I
+
BELlEF4
1
1
I
I
R
I
+
DEMO
I
I
I
+
I
I
I
I
+
I
I
I
I
+
12
16
20
24
28
32
Figure 4.1. Logistic Regression DEMO: Test for Nonlinearity
LMPMJB = Logit of Mean of Prevalence of DEMO use for each value of
BELIEF4. BELIEF4 = Belief that it is wrong to violate the law.
+---+----+----+----+----+----+----+----+----+----+----+----+----+--+
10 14 18 22 26 30
75
one-unit change in the independent variable depends on the value
of DEMO of the other independent variables. For example, a one-unit
change in DEMO to delinquent friends may produce a larger change
in the frequency or prevalence of marijuana use for individuals with
weak to moderate beliefs that DEMO is wrong to violate the law (who
may be more susceptible DEMO peer influence) than in individuals who
strongly believe that it is DEMO to violate the law (who may be less
susceptible to peer DEMO). Detection of nonadditivity is not as
straightforward as detection of nonlinearity in either linear or logistic
regression. Unless theory provides some guidance, we are commonly
left with the choice between assuming an additive model, testing for
interaction effects that seem intuitively plausible, or testing for all
possible interaction effects. This last option is feasible for relatively
simple models, but becomes progressively more tedious and carries
increasingly more risk of capitalizing on DEMO sampling variation
as the number of variables in the model increases.
One example of an interaction effect was examined in Table 3.3.
The results DEMO Table 3.3 indicated that the effects of exposure and
belief on the prevalence of marijuana use were not statistically sig-
nificantly different for males DEMO females. This is an example of
an interaction between a continuous predictor (actually two: EDF5
and BELIEF4) and a dichotomous variable. Other possible patterns
include interactions between two categorical predictors (SEX and
ETHN) or DEMO two continuous variables (an interaction between
EDF5 and BELIEF4).
4.2. DEMO
Collinearity (or colinearity or multicollinearity) is a problem that
arises when independent variables are correlated with one another.
Perfect collinearity means that an DEMO variable is a perfect lin-
ear combination of the other independent variables. If we treated
each independent variable in turn as the dependent variable DEMO a
model with all of the other independent variables as predictors, DEMO
fect collinearity would result in an R' = 1 for each DEMO the independent
variables. When perfect collinearity exists, it is impossible to DEMO
a unique estimate of the regression coefficients; any of an infinite
DEMO of possible combinations of linear or logistic regression coef-
ficients will work equally well. Perfect collinearity is rare, except as an
76
oversight: the inclusion of three variables, one of which is DEMO sum of
the other two would be one example.
Less than perfect collinearity is fairly common. Any correlation
among the independent variables is indicative DEMO collinearity. As
collinearity increases among the independent variables, linear and
logistic DEMO coefficients will be unbiased and as efficient as they
can be (DEMO the relationships among the independent variables),
but the standard errors DEMO linear or logistic regression coefficients
will tend to be large. More efficient unbiased estimates may not be
possible, bnt tbe level of efficiency of the estimates may be poor. Low
levels of collinearity are not generally DEMO, but high levels of
collinearity (perhaps corresponding to an R2 = .80 or more for at
least onc of the independent variables) may pose problems, and very
high levels of collinearity (perhaps corresponding to DEMO R' = .90 or
more for at least one of the DEMO variables) almost certainly
result in coefficients that are not statistically significant, even though
they may be quite large. ColIinearity also tends to produce DEMO and
logistic regression coefficients that appear to be unreasonably high:
as a rough guideline, standardized logistic or linear regression coeffi-
cients greater than 1 or unstandardized logistic regression coefficients
greater than 2 should be examined DEMO determine whether collinearity
is present.
For linear regression, detection of collinearity DEMO straightforward.
Most standard regression routines in widely used software packages
provide optional information on the R' or some function of the R'
for each of the independent variables, wben it is treated as the depen-
dent variable with all of the other independent variables as predictors.
For DEMO, the tolerance statistic, available in SAS PROC REG and
in SPSS REGRESSION, is simply l-R~, where R~ is the variance in
each DEMO variable, X, explained by all of the other indepen-
dent variables. Corresponding to the rough guidelines outlined in the
preceding text, a tolerance of less than .20 is cause for concern; a tol-
erance of less than .10 almost certainly indicates a serious collinearity
problem. Although tolerance DEMO not available in SAS PROC LOGIS-
TIC or SPSS LOGISTIC REGRESSION, DEMO can be obtained easily
by calculating a linear regression model using the same dependent
and independent variables that you are using in the logistic DEMO
sion model. Because the concern is with the relationship among the
independent variables, the functional form of the model for the depen-
dent variable is irrelevant to the estimation of collinearity.
77
In Table 4.1, for botb of the models with the nonlinear terms
BTEDF and BTBEL, the logistic regression coefficients were some-
what high, and the standardized logistic regression coefficients for
EDF5, BELIEF4, BTEDF, DEMO BTBEL were all larger than 1. This
suggests that there may be a problem of collinearity in the nonlinear
model. Table 4.2 presents collinearity DEMO, produced by an OLS
regression routine, for two models. The first, labeled "Basic Model,"
is the logistic regression model from Table 3.1. The second, labeled
"Nonlinear Model," is the model from DEMO first half of Table 4.1 with
the nonlinear terms BTEDF and BTBEL included. In both mod-
els, Black and Other are design variables for ETHN. For the basic
model, all of the tolerances exceed .70, DEMO no serious prob-
lem of collinearity. For the nonlinear model, Table DEMO confirms what
the standardized coefficients in Table 4.1 suggested: the tolerances
DEMO SEX and the two design variables for ETHN remain high, but
DEMO and BTBEL are severely collinear with EDF5 and BELIEF4,
as indicated by tolerances less than .Ol.
The good news about collinearity is that DEMO is easy to detect. The
bad news is that there are few acceptable remedies for it. Deleting
variables involved in collinearity runs the risk DEMO omitted variable
bias. Combining collinear variables into a single scale, for DEMO,
by factor analysis, suggests that the theory (if any) DEMO to construct
your model or the measurement process used to collect your data
was faulty, casting doubt on any further inferences you may draw
from your analysis. Ridge regression (Schaefer, 1986) allows the user to
TABLE 4.2
Testing for Collinearity
Dependent
Variable
PMRJ5
Independent
Variable
EDF5
BELlEF4
DEMO (male)
ETHN
Black
Other
BTEDF
BTBEL
Basic
Model
.717
.707
DEMO
.959
.983
Nonlinear
Model
.00249
.00148
.994
.958
.974
.00253
.00147
Tolerance
78
produce somewhat more biased but substantially more efficient esti-
mates by DEMO the estimated variance of the variables (thereby
decreasing the proportion of DEMO variance that is explained). Perhaps
the safest strategy is to focus on the combined effects of all of the vari-
ahles in the DEMO and to recognize the precariousness of any conclu-
sions about individual predictors in the presence of high collinearity.
For a more detailed discussion of DEMO to collinearity, see Berry
and Feldman (1985, pp. 46-50) or Fox (1991). Briefly, though, there
is no really satisfactory solution to high collinearity.
4.3. Numerical Problems: Zero Cells and Complete Separation
When collinearity exists, it does not necessarily indicate that there
is anything wrong with the model or the theory underlying the model.
Instead, problems arise because of empirical patterns in the data (the
high correlation among independent variables). Two related problems
with similar symptoms are zero cell count DEMO complete separation.
Zero cell count occurs when the dependent variable is invariant for
one or more values of a categorical independent variable. If, for exam-
ple, all of the respondents in the Other category for ethnicity reported
using marijuana (or if they all reported not using marijuana), we
would have a problem with a zero cell in the contingency DEMO for
the relationship between prevalence of marijuana use and ethnicity.
The odds of marijuana use for respondents other than white and black
would be DEMO/(1 - 1) = 1 - 0 = +00 and the logit = In(odds) would
also be +00, infinitely large. [If DEMO prevalence of marijuana use were
o for this group, the odds DEMO be 0/(1- 0) = 0 and the logit would
be In(O) = -00, infinitely small.] When the odds are 0 DEMO 1 for a sin-
gle individual or case, this is not DEMO problem; when they are 0 or 1
for an entire group DEMO cases, as defined by the value of a categorical
independent variable, the result will be a very high estimated stan-
dard error for DEMO coefficient associated with that category (including
coefficients for which that category DEMO as a reference category).
The problem of zero cell count applies specifically to categorical
variables, particularly nominal variables. For continuous variables and
for ordinal categorical variables, it is common to have means of 0 or 1
for some values of the independent variables. The reason that this DEMO
not a problem is that we assume a certain pattern to the relationship
between the dependent variable and the continuous predictor (linear
in linear regression, logistic in logistic regression), and use that pattern
79
to "fill in the blanks" in the distribution of the DEMO variable over
the values of the independent variable. For categorical variables, DEMO
are unable to assume such a pattern. Instead, when we find DEMO
of zero cell count for categorical predictors, we must choose among
(1) accepting the high standard errors and the uncertainty abont the
values of the logistic regression coefficients, (2) recoding the categor-
ical independent variahle in a meaningful way (either by collapsing
categories or hy eliminating the prohlem category) to eliminate the
problem of zero cell count, DEMO (3) adding a constant to each cell of
the contingency table to eliminate zero cells.
The first option may be acceptahle if we DEMO concerned more with
the overall relationship between a set of predictors and a dependent
variable than with the effects of the individual predictors. The DEMO
fit of the model should be unaffected by the zero cell count. The third
option has no serious drawbacks, but Hosmer and Lemeshow (DEMO,
p. 127) suggested that it may not be adequate for DEMO analyses.
The second option results in cruder measurement of the indepen-
dent variable, and may bias the strength of the relationship between
the predictor and the dependent variable toward zero. However, if
there is a conceptual link between some categories of the indepen-
dent variable and if the DEMO of the dependent variable across
those categories appears similar, this may DEMO a reasonable option.
Usually, this will be done during univariate and DEMO screening of
the data. A hidden example of this has been followed throughout this
monograph to this point: the coding of ethnicity. In the original sur-
vey, ethnicity was divided into six categories: non-Hispanic European
DEMO, African American, Hispanic American, Native American,
Asian American, and other. The last four categories were collapsed
into a single category, Other, because of the small numher of cases.
Had they been retained in their original form, problems of zero cell
count would have plagued the analyses.
If you are too successful in predicting the dependent variable with
DEMO set of predictors, you have the problem of complete separation.
Both DEMO logistic regression coefficients and their standard errors will
tend to be extremely large. The dependent variable will be perfectly
predicted: OM = Do, DEMO = 0, R[ = 1. If separation is less than
complete (sometimes called quasicomplete separation), logistic regres-
sion coefficients and their standard DEMO still will be extremely large.
An example of quasicomplete separation is given in Figure 4.2, based
on artificially constructed data. If complete separation occurs in a
80
bivariate logistic relationship, the logistic regression model cannot be
calculated. Although there is nothing intrinsically wrong with com-
plete separation (after all, DEMO prediction is what we are trying to
achieve), as a practical maller it should arouse our suspicions, beca-
sue it almost never occurs in real-world research. Complete or quasi- .
complete separation may instead indicate DEMO in the data or the
analysis, for example, having almost as many variables as there are
cases to be analyzed.
Collinearity, zero cells, and complete separation have the common
symptom of very large standard errors and often, but not always, large
coefficientsas well (Hosmer & Lemeshow, 1989). All, therefore, result
in inefficient estimation of the parameters in the model. None, how-
ever, is known to result in DEMO parameters or in inaccurate (as
opposed to inefficient) inferences. Problems with zero cell connts can
be averted by careful univariate and bivariate analysis DEMO logis-
tic regression is used. Complete separation may indicate either an
error that needs to be corrected or a brilliant breakthrough in theory
and DEMO (Congratulations!) Most likely, it indicates a problem.
Collinearity is the DEMO bothersome of the three problems, because
it indicates either a flaw DEMO the theory, a flaw in the operationaliza-
tion of the theory, or a problem in the empirical data that confounds
the testing of DEMO theory, insofar as the theory is concerned with the
effects of DEMO predictors rather than with the combined effect of
a set of predictors. Like zero cell counts, collinearity can be detected
(with the help DEMO a good multiple regression package) before logis-
tic regression analysis begins. DEMO to do about it if it is detected is
problematic, more DEMO than science.
4.4. Analysis of Residuals18
In l~ear regression, the residual DEMO commonly denoted e, and ej =
Yj - Yj is the DEMO between the observed and predicted values
of Y for a given case j. This should be distinguished from the error of
prediction, denoted €j' which represents the difference between the
true value of Y, in DEMO population (a value that may be different from
the observed value DEMO Y in the sample, for example, as a result of
measurement error) and the estimated value of Yj , Y (Berry, 1993).
j
In linear regression, certain assumptions about errors (zero mean,DEMO
constant variance or homoscedasticity, normal distribution, no corre-
lation of error terms with one another, no correlation of error terms
81
M<X1e1
SUlNllary
Step -2 Log
IHelihood
,
13.003
Cox ~ Snell
R Squilrl1>
.654
Nagelk"rk"
R Square
.812
omnH,DEMO Tests of Model Coefficients
,
Step
Step
Chi-square
12.448
Block 42.448
",
5i9·
.000
Model
1
.000
Classification 'l'ablelal
Observed
,
Step TRUE
0
,
OVerall Percentage
a The cut value is .500
42.448
Step 1'3
1 (a)
a
219. no
Constant -109.860
"
" sas 8.690 1
" a-s 8.667 i
S.E.
Wald
a
V<lnable{s) entered on step 1:
1'3.
Step Ilumi.>er:
1
Observed Groups and Predicted Probabilities
1
.000
Variables in t.he DEMO
Predicted
TRUE
0
rs
,
,
i
rs
gig.
.003
.003
r
n
e
Q
0
e
ia
a
Predicted
Prob:
Group:DEMO
0 ,
0
0 0
0 0
0 0
0 0
DEMO
0
0
0
0
------1,------'1------1------I
o .25 .5 .75 1
000000000000000000000000000000111111), 11111111111111111111111
Predicted Probability is of Membership for
The CUt Value DEMO . SO
Symbols: 0 - 0
, - ,
Bach Symbol Represents 1 Case.
1
Figure 4.2. Quasicomplete Separation
Percentage
Correct
95.0
95.0
DEMO
Exp(Bl
2.65&+95
.000
82
with independent variables) are necessary if we are to draw statistical
inferences from a sample to a larger population. These assumptions
may sometimes DEMO tested by using the residuals, ej as estimates of the
errors DEMO' Violations of some assumptions (zero mean, normal distri-
bution) may have relatively minor consequences. Violation of others
is more problematic. Heteroscedasticity inflates DEMO errors and
renders tests of statistical significance inaccurate, and may itself DEMO
a symptom of nonadditivity or nonlinearity. Correlation between the
independent variable and the error term generally indicates misspeci-
fication, the effects of which may include bias, inefficiency, or inaccu-
rate statistical inference.
In linear regression, the residuals are straightforwardly computed
from the regression equation. In logistic regression, several different
residuals are available, corresponding to the different levels (proba-
DEMO, odds, logit) at which the analysis may be conceptualized. The
DEMO purpose for which residuals analysis is used in logistic regres-
sion is to identify cases for which the model works poorly or cases that
DEMO more than their share of influence on the estimated parameters
of the model.
The difference between the observed and the predicted probability
is ej DEMO P(Yj = 1)-P(Yj = 1), where P(Yj = 1) is the estimated prob-
ability that Y = 1 based on the model. As Hosmer and Lemeshow
explained, in linear regression, DEMO can assume that the error is inde-
pendent of the conditional mean of Y, but in logistic regression, the
error variance is a DEMO of the conditional mean. For this reason,
residuals (estimates of DEMO) are standardized by adjusting them for
their standard errors. The Pearson (Hosmer & Lemeshow, 1989) or
standardized (SPSS) or chi (SAS) residual is
0=~=~=
P(Yj = 1) - P(Yj = DEMO)
_ _
JP(Yj = 1)[1- P(Yj = 1)]
.
This is just the difference between the observed and estimated DEMO
abilities divided by the binomial standard deviation of the estimated
probability. For large samples, the standardized residual, hereafter Zj'
should be normally DEMO with a mean of 0 and a standard devi-
ation of 1. Large positive or negative values of Zj indicate that the
model fits DEMO case j poorly. Because Zj should have a normal distribu-
tion, DEMO of the cases should have values between -2 and +2, and
DEMO of the cases should have values between -2.5 and +2.5.
I
83
An alternative or supplement to the Pearson residual is the
deviance DEMO, which is equal to dj = -21n (predicted probabil-
ity of correct group). The deviance residual is the contribution of
each case DEMO DM. Like Zj' dj should have a normal distribution with
a DEMO of 0 and a standard deviation of 1 for large samples. A third
residual, the logit residual, is equal to the residual ej DEMO by its
variance (instead of its standard deviation, as in the standardized
residual). This may be written
1=
J
P(YJ = DEMO) - P(YJ = 1)
- P(Y~ J = DEMO)J
~
P(YJ = 1)[1
4.4.1. Nonnormality of Residuals
In OLS regression, it is usually assumed that the errors are nor-
mally distributed. In small samples, if this assumption is violated,
it renders statistical inference based on the regression equation (for
example, the statistical DEMO of the regression coefficients) inac-
curate. In large samples, inaccuracy of statistical inference is consid-
ered inconsequential because of results of the central DEMO theorem,
which, briefly, indicates that the distribution of the regression coeffi-
cients in repeated sampling for large enough samples will approach a
DEMO distribution with known mean (equal to the population mean)
and DEMO In logistic regression, the errors are not assumed to
have a DEMO distribution. Instead, it is assumed that the distribu-
tion of the DEMO follows a binomial distribution, which approximates
a normal distribution only for DEMO samples. If the residuals are used
to estimate the errors and if they are normally distributed (for a
large sample), we can be more confident that our inferential statis-
tics are correct, because normal (DEMO distribution we are considering)
and binomial (the assumed distribution) distributions are about the
same for large samples. Contrary to the situation in DEMO regres-
sion analysis, however, if we find that the residuals are not normally
distributed for small samples, we need not necessarily be concerned
about the validity of our statistical inferences.
We can test for normality DEMO plotting the standardized or deviance
residuals against a normal curve, or DEMO a normal probability plot;
see, for example, SPSS (1999b)DEMO More importantly, we can use the
standardized and deviance residuals to DEMO cases for which the
84
model fits poorly, cases with positive or negative standardized or
deviance residuals greater than 2 in absolute value.'? This may help
us DEMO not only cases for which the model fits poorly, but also
DEMO that exert a disproportionately large influence on the estimates
for the model parameters.
4.4.2. Detecting and Dealing With Influential Cases
Cases that potentially have DEMO large influence On the parameters
of the logistic regression model may be identified in part-" by high
values of the leverage statistic, or DEMO value, h;. In linear regression,
the leverage statistic is DEMO from the equation 10 = h 1j Y1+h2jY2+
...+h jnYk = L: h;jY;, and it expresses the predicted value of Y for a
case j as a function of the observed values of Y DEMO case j and for all
of the other cases as well (DEMO, 1991). Each coefficient h;j captures
the influence of the DEMO variable Y; on the predicted value Y. It
j
can be DEMO that h;; = L:(h;j)2, so if we designate h, = h;;, we have
a measure of the DEMO influence of Y; on the predicted values of
Y for all DEMO the cases in the sample. The leverage is similarly derived
in logistic regression (Hosmer & Lemeshow, 1989, pp. 150-151), and
it varies between 0 (no influence) and 1 (it completely determines
the parameters in the model). In an equation with k independent
variables (including each design variable as a separate variable) or,
equivalently, in DEMO equation in which there are k degrees of freedom
associated with GM, the sum of the values of h; is equal to k DEMO 1 and
the mean value of h;, L:h;/N DEMO (k + l)/N. Cases with hat values
larger than (DEMO + 1)/ N are high leverage cases.
Other indices of the influence of an individual case include the
change in the Pearson X2 DEMO and the change in DM attributable
to deleting the case from the analysis. The change in the Pearson
X2 attributable to deleting a case DEMO is tl.X; = zJ/(l - h j), where
Zj is the standardized residual and h , is the leverage statistic for
DEMO j. The change in DM is equal to tl.Dj = dJ - zJh j/(l - h j) =
dJ - h/tl.X2 ) , where d, is the deviance residual, Zj is the standardized
residual, and h; is the leverage statistic for case j. Both DEMO and tl.jx;
have a X2 distribution, and their values should DEMO interpreted accord-
ingly. Their respective square roots should have an approximately
normal distribution. If -Jtl.Dj (the Studentized residual provided in
SPSS LOGISTIC REGRESSION or C in SAS PROC LOGISTIC) or
Jtl.X; is less than -2 DEMO greater than +2, it indicates a case that may
i
85
be poorly fit and deserves closer inspection. The quantity zJh/(l-hj)
is itself an indicator of the overall change in regression estimates
DEMO to deleting an individual observation, and is available in
SAS PROC DEMO as the optional statistic CBAR and in SPSS
LOGISTIC REGRESSION as Cook's distance. A standardized ver-
sion of this measure may be obtained DEMO dividing Cook's distance by
(I-h j); zJhj/(I-hY = dbeta, the standardized change in the regres-
sion coefficients attributable to the deletion of case i The leverage
statistic and the related statistics described DEMO are all summary
indicators of the influence of a case on the estimation of the model
parameters. More detailed information can be obtained by DEMO
changes in individual coefficients that occur when a case is deleted.
The change in the logistic regression coefficient is described as the
DFBETA in DEMO SPSS and SAS.
4.4.3. Outliers and Residual Plots
Table 4.3 presents the results of an analysis of residuals. Cases
with Jt:.Dj less than DEMO or greater than +2 were selected for exam-
ination. The table includes the sequential number of the case, the
observed and predicted values of the case, the Pearson (ZResid), Stu-
dentized (SResid), and deviance (Dev) residuals, the leverage (Lever),
and the deleted residuals t:.Dj (DIFDEV), t:.X2 (DIFCHI), and dbeta
(DBETA). Part A of Table 4.3 presents the residuals for the DEMO
in Table 3.1. Part B presents the results with the most extreme out-
lier deleted. This case is one of the two identified in DEMO analysis of
nonlinearity in Figure 4.1. Part C presents the results with both of the
outliers from Figure 4.1 deleted.
The first comment to DEMO made about Table 4.3 is that several of
the indicators are essentially redundant. The change in the Pearson
X2 statistic, DIFCHI (t:.X2 ) , is approximately equal to the Pearson
residual, ZResid, squared. The deviance residual, Dev(dj ) is approx-
imately equal to the Studentized residual (SResid), and the change
in the deviance residual, DIFDEV (t:.Dj ) , is equal to the Studentized
residual squared. The DEMO x2 -based residuals are larger than the
residuals based on DM but they provide essentially the same informa-
tion about the cases. The leverage DEMO DBETA provide information
that is not evident from the other diagnostics; DEMO is similar but not
redundant. Further analysis of the table focuses on the Pearson resid-
ual, the Studentized residual, the leverage, and DBETA.
86
TABLE4.3
Logistic Regression Diagnostic Snmmaries
Observed
Case PMRJ5 Pred ZResid
SResid DEMO DIFCHI
A. Full Model
66 1 .0991
94 0
139 1
148 1
178 0
201 1
3.0143
.8608 -2.4864
.0815 3.3565
.0612 3.9183
DEMO -10.7055
.0650 3.7937
GM = 108.257
5 df
P ~ .0000
2.1500
-1.9858
2.2391
2.3641
-3.0823
2.3383
2.1637
-2.0325
2.2668
2.3762
-3.0983 .0103
2.3526 DEMO
.0127
.0455
.0243 11.55
.0102 15.51
115.80
14.57
9.20
6.48
R[= .367
1 0
66 I
94 0
139 1
148 1
200 1
DEMO Most Extreme Case Deleted
.9122 -3.2239 -2.2059 -2.2557 .0436
.0894 3.1913 2.1975 2.2116 .0127
.8786 -2.6903 -2.0536 -2.0999 .0436
.0861 3.2577 2.2146 2.2444 .0264
DEMO 4.3137 2.4396 2.4515 .0097
2.3312 2.3463
Rr. = .401
.0661
5 df
3.7601
p = .0000
.0129
10.87
10.32
7.57
10.90
18.79
14.32
GM DEMO 118.156
66 1
94 0
133 0
139 1
148 1
200 1
C. Outliers From Figure 4.1 Deleted (Cases 178 and 1)
3.3732 2.2432 2.2573 .0125 11.52
-2.7852 -2.0832 -2.1289 .0425 8.10
-2.5584 -2.0105 DEMO .0387 6.81
3.2099 2.2023 2.2332 .0275 10.59
4.6536 2.4982 2.5097 .0092 21.86
3.7175 2.3221 2.3378 .0135 14.01
.0808
.8858
.8675
.0885
.0441
.0675
GM DEMO 122.634
5 df
P = .0000
R~ = .416
NOTE: Cases DEMO Studentized residuals greater than 2.0000000 are listed.
DIFDEV
DBETA
4.68 .12
4.13 .31
5.14 .29
5.65 .16
9.60 1.21
5.53 .18
5.09
4.89
4.41
DEMO
6.01
5.51
5.10
4.53
4.20
4.99
6.30
5.47
.50
.13
.34
.30
.18
.19
.15
.36
.27
.30
.20
.19
In part A, case nnmber 178 stands out. The Pearson residual is
an enormous -10.7, the Stndentized residual is greater than 3 in
absolnte value, and DBETA is greater than 1, all indicators of an
extremely poor fit. Deleting this case would result in an improvement
in G of 9.899 (1 degree of freedom, p = .003) and an increase
in Ri of DEMO Clearly the model would work better with this case
deleted. In part B, with case 178 deleted, no case stands out as clearly.
DEMO 148 has the highest Pearson residual and the highest Studen-
tized residual, but would prodnce relatively little change in the logis-
tic regression coefficients if deleted. Case 1 would have more of an
effect on the DEMO regression coefficients (DBETA = .50) and has
the fourth highest Pearson residual and the third highest Stndentized
and deviance residnals of the six DEMO selected as outliers. Case 1
M
87
has the additional feature that it is one of the two DEMO identified
in Figure 4.1 as introducing nonlinearity into the model. With case 1
deleted, GM improves by 4.478 (1 degree of freedom, p = .038) and
R[ increases by .015. The improvement that results from deleting
case 1 is considerably smaller than the improvement from removing
case DEMO
Should cases 1 and 178 be removed from the analysis? The DEMO
to this question requires closer examination of the data. The two cases
in question are both white, one male and one female. Both report
low levels of belief that it is wrong to violate the law, but neither uses
marijuana or hard drugs and both report very low DEMO of alcohol
use as well. Case 1 (female) has a slightly higher level of belief and a
substantially lower level of exposure to DEMO friends than case
178 (male), and is therefore less inconsistent DEMO the model than
case 178. Although unusual, the results are plausible DEMO both cases
probably should be retained. It would be useful, however, to extend
the model to include variables that might explain why an DEMO
who sees nothing wrong with breaking the law chooses not to use
alcohol, marijuana, or other illicit drugs.
Landwehr, Pregibon, and Shoemaker (1984) and Hosmer and
Lemeshow (1989) discussed graphical techniques for logistic regres-
sion diagnostics. These techniques offer a visual rather than numer-
ical DEMO that may be more intuitively appealing to some
researchers. For example, DEMO and Lemeshow (1989) recom-
mended plots of DIFCHl, DlFDEY, and DBETA with the predicted
values to detect outlying cases. Examples of these DEMO are provided
in the first column of plots in Figure 4.3. Each of the three plots rep-
resents two curves, one declining from left to right (cases for which
the observed value of PMRJ5 is 1) and one increasing from left to
right (cases for which the DEMO value of PMRJ5 is 0). Cases in
the upper left and right corners of the plot are cases for which the
model fits DEMO In the plot of the x' change (DlFCHI) with the
DEMO value, one case is an extreme outlier, with DIFCHI greater
than 100. From Table 4.3, we can see that this is case 178. Similarly,
case 178 is the case in the plot of DlFDEV DEMO a value of DlFDEV
greater than 8 and in the plot of DBETA with a value greater than 1.
On the scale of the DEMO in the first column of Figure 4.3, all of the
other DEMO seem to cluster fairly close together. Once case 178 is
deleted, DEMO, the scale of the plots may be changed and other
cases DEMO as outliers.
88
Full Model
Model with case 178 deleted
o
I
F
c
DEMO
I
0
1
F
0
E
V
0
,
T
A
DEMO
I
I
PLOT OF
f. - - _t
I
I
I
I
16>
PLOT OF
DIFeHI
I
I
>
lOOt
+
I
I
I
I
I
I
I
I
I
I
I
1
13121422 13111
DEMO 224165748
121
2331
I
I
I>
0
PLOT OF OBETA WITH PRED1PMJ
+__• M+~ ~ ~ ~+H ~ ~ ~+w w_w+____+__• ~++
I DEMO
I I
>
.45+
XGLAA627543 16
++----...
.15 .45 .75
.3 DEMO .9
I
I
I
I
I
I
I
I
1
11
1
11
2
313211212 13
1
11
.,.
I
I
I
I
>
I
I
I
I
0+ RFFGCC7464733231
++____+___ _+H__
1234 2215245723A >
____+____++
~+u~ ~+~ ~ ~_+
I
I
I
I
.225+
I
I
DEMO
I
0+
tt~
.1'
0
++
PLOT OF DIFCE',' DEMO PREDIPHJ
+_- - _+_ - __ +_- - _+_ - - _+ +.
I
I
'>
I
I
I
I
4>
I
DEMO
I
I
0+
++
RFfGC4____
2
2
11
312
32411
2111
125114 11
874644332 223 12152
+____+ ____+____+ ____+____
.s .75
21
45723A+
____
DEMO .45
.3
++____
.1'
.45
0
.3
.75
.s
+t
I
I
>
I
I
I
I
>
I
I
I
I
>
+t
1.05
.9
1.05
.9
I
I
I
I
>
I
I
I
I
+
----+----+----+----+._._+----'1-+
l.05
+t_. __
PLOT+ +
OF
DEMO','
+ +
WITH
PREDIPHJ+
+
...t
I
I
s-
I
I
I
I
2.5t
I
I
2
1
211
221
221 12
DEMO
1
1
1
I
I
I
I
I
I
>
•
DEMO
I
I 23 161
I 9AB2752
0+ xsu
22411
1 224161
I
I
.o+__
~ ~+~ ~ ~ ~+
___ ..___ M
.45 .75
DEMO
4748
+____
++
.s
.15
0
.3
212 1 31
1222
~
~+~ ~ M+~
l.05
.9
I
I
PLOT OF DBETA WITH PRED1PMJ
DEMO M.+HHH_+W _w_ +____+H _._+.M.~+ ___~++
I
I
>
XGlAAA26443
___+____+___
1
DEMO 1 1 11
1 1 11 1 1
112
111312122212
4 1
1
1
22 1 1
11312 223165748
M+ ____+____+____++
1
I
I
DEMO
I
>
~+~_ ~
1
1
I
I
I
I
>
.3
.45 .75
.s
l.05
.9
I
I
I
I
a-
I
DEMO
I
1
0+
o
50+
+
I I
I I
I I
I 12 1 21 I
0+ RFFGCDASB68454511423612315245723A +
++----+••••+----+•• --+----+----+----++
.15 .45 DEMO 1.05
.3 .6 .9
Predicted Value
Predicted Value
++
CIFellI WITH
+ +
PREOIPMJ+_-- -+-
++
WITH PREQIPMJ
227 cases plotted.
226 cases plotted.
DEMO 4.3. Logistic Regression Diagnostic Plots
89
The second column of plots in Figure 4.3 presents the same DEMO
with case 178 deleted. The plots may appear to be more spread out
than the plots in the first column, but this is only because the scale has
changed (from 0-100 to 0-20 for DIFCHI, DEMO 0-10 to 0-6.25 for
DIFDEY, and from 0-1.25 to 0-.5 for DEMO). The combination of
the two curves for PMRJ5 = 1 and PMRJ5 = 0 takes on a character-
istic goblet-shaped pattern (especially for DIFDEV), with the outliers
again located in the upper right and DEMO corners of the plot, and also
in the "cup" of DEMO goblet. In contrast to the first column, there is a
relatively DEMO transition from the upper corners to the rest of the
graph. The most outlying cases are not as sharply separated as case
178 was DEMO the first column. This is reflected numerically in Table 4.3,
part B, in which none of the Studentized residuals is larger than 2.5
in absolute value and none of the DBETAs is greater than 1.
DEMO Overdispersion and Underdtsperston-!
Logistic regression assumes binomial errors, and thus it DEMO assumed
that the variauce O'~ = PY~l(1 - PY~l)' For casewise data, when
there is only one case per covariate pattern, this condition is satisfied.
For grouped data, however, when cases are aggregated by covariate
pattern and the covariate patterns are treated as the "cases," this
assumption may be violated for one of several reasons, including the
omission of an important predictor, clustering within the sample, DEMO
simply because the underlying distribution of the population is differ-
ent from the assumed distribution. Overdispersion refers to the case
in which O'~ DEMO larger than expected, and underdispersion refers to the
case in which DEMO'~ is less than expected. For grouped data, if we calcu-
DEMO 0 = Dydf', where D is the deviance statistic calculated by covari-
ate pattern (as reported, for example, in the goodness-of-fit table in
SPSS NOMREG) and df is the degrees of freedom associated with the
deviance statistic (and reported in the same table), then ooerdispersion
is indicated by 0 > 1 and underdispersion is indicated by 0 < 1. Under-
dispersion and overdispersion result in incorrect standard errors and
thus incorrect inferential statistics, but it is possible to adjust the stan-
dard error by multiplying by the square root of 0: adjusted standard
error = standard error x ../8. SPSS NOMREG offers the option of
DEMO the dispersion using either the Pearson or the deviance
X', or by using a user-specified value for 0 (N in SPSS NOM REG).
Note in Figure 3.2 that the deviance X2 = 158.266 with DEMO df, so
90
a = 158.266/151 = 1.05, suggesting little or no overdispersion or
underdispersion.
4.6. A Suggested Protocol for Logistic Regression Diagnostics
Testing for DEMO should be a standard part of any logis-
tic regression analysis. It is quick, simple to implement with exist-
ing regression software, and DEMO provide valuable information about
potential problems in the logistic regression analysis before the analy-
sis is undertaken. The Box-Tidwell test for nonlinearity is quick, easy
to perform, and not overly sensitive to minor deviations from linearity,
and should also be incorporated as a standard procedure in logistic
DEMO Whether to test for nonadditivity by modeling interactions
among the independent variables depends on whether there are the-
oretical or other reasons to believe DEMO such interactions exist. Mod-
eling nonlinearity and nonadditivity should be approached with some
caution, however. There is a real danger of overfitting a model, build-
ing in components that really capture random variation, rather than
DEMO regularities in behavior.
Using logistic regression diagnostics, like using linear regression
DEMO, is more art than science. The diagnostic statistics hint at
potential DEMO, but what those problems are and whether reme-
dial action is DEMO, can be decided only after closer inspection
of the data for DEMO unusual Cases. In a sample of 200 to 250, ran-
dom DEMO variation alone will produce 10 to 12 cases with values
greater than 2 or less than -2 on standardized, normally distributed
variables such as the deviance residual or the Studentized residual.
Even cases with very large DEMO, like case 178 in Table 4.3, do not
necessarily indicate problems in the model, insofar as we are dealing
with nondeterministic models in which individual human choice and
free will may naturally produce less than DEMO prediction of human
behavior.
As a general approach, it seems appropriate DEMO perform at least
a limited set of diagnostics on any model as a precaution against
miscoded data and a guide to weaknesses in our DEMO models.
A minimal set of diagnostics might include the Studentized residual,
the leverage, and the dbeta. Studentized residuals less than -3 and
greater than +3 definitely deserve closer inspection; values less than
-2 or greater than +2 may also warrant some concern. The disad-
vantage to the DEMO residual is that the information it provides
91
tends to duplicate the information provided by the deviance and Stu-
DEMO residuals, and the deviance residual, not the Pearson resid-
ual, DEMO the criterion for estimating the parameters of the model and
is thus somewhat more pertinent to the analysis of residuals. The
advantage to the DEMO residual is that, because it has larger values
than the deviance DEMO, outlying cases sometimes stand out more
sharply (as does case 178 in part A of Table 4.3) with the Pearson
residual than with the deviance or Studentized residual, Leverage val-
ues several times the expected value of (k + l)/N (which was about
5/227 = .02 in this example) also deserve close attention. Large val-
ues of dbeta, especially values greater than 1 (remember, this is a
standardized measure), also deserve closer examination. Whether the
information contained in DEMO diagnostics is presented visually is a
matter of taste. The critical concern is that extreme values on these
diagnostics require closer inspection of the DEMO, and possibly recon-
sideration of the modeL
5. POLYTOMOUS LOGISTIC REGRESSION DEMO
ALTERNATIVES TO LOGISTIC REGRESSION
Logistic regression analysis may be extended beyond the analysis of
dichotomous variables to the analysis of categorical (nominal or ordi-
nal) dependent variables with more than two categories. In the lit-
erature on logistic regression, the resulting models have been called
polytomous, polychotomous, or multinomial logistic regression mod-
els. Here, the terms dichotomous and polytomous will be used to
refer to logistic regression models, and the terms binomial and multi-
nomial will be used to refer to logit models DEMO which polytomous
logistic regression models may be derived. For polytomous dependent
variables, the logistic regression model may be calculated as a special
case of the multinomiallogit model (Agresti, 1990;Aldrich & Nelson,
1984; DeMaris, 1992; Knoke & Burke, 1980).
Mathematically, the extension of DEMO dichotomous logistic regres-
sion model to polytomous dependent variables is straightforward. One
value (typically the first or last) of the dependent variable is DEMO
ignated as the reference category, Y = ho, and the probability of
membership in other categories is compared to the probability of
membership DEMO the reference category. For nominal variables, this may
be a direct DEMO, like the indicator contrasts for independent
92
variables in the logistic regression model for dichotomous variables.
For an DEMO variable, contrasts may be made with successive cat-
egories, in a manner similar to repeated or Helmert contrasts for
independent variables in dichotomous DEMO regression models.
For dependent variables with some number of categories M, DEMO
requires the calculation of M - 1 equations, one for each DEMO rel-
ative to the reference category, to describe the relationship between
DEMO dependent variable and the independent variables. For each cate-
gory of the dependent variable except the reference category, we may
write the equation
g (X
hI' X Xk ) = e(tlh+bhIXJ+bh2X2+ ··+bhkXk),
2,""
h = 1,2, ... ,M -1,
[5.1]
DEMO the subscript k refers, as usual, to specific independent vari-
ables X and the subscript h refers to specific values of the dependent
DEMO Y. For the reference category, go(Xj> X2, ... , DEMO = 1. The
probability that Y is equal to any value h other than the excluded
value ho is
e(ah +b"l Xl DEMO"2X2+' .+b/ikXk)
h = 1,2, ... , M - 1,
[5.2]
and for the excluded category ho= M or DEMO,
P(Y = holXj> X 2, ..• , X k )
1
h = 1,2, ... , M - 1.
DEMO
Note that when M = 2, we have the logistic regression DEMO for
the dichotomous dependent variable, the reference category is the
first DEMO, ho = 0, and we have a total of M - 1 = 1 equations
to describe the relationship. Logistic regression models for DEMO
mous nominal dependent variables can be calculated in SAS using
93
CATMOD and in SPSS prior to version 10 using LOGLINEAR,
DEMO general log-linear analysis routines in which the calculation
of polytomous logistic regression models is rather cumbersome.
In SPSS as of version 10, however, DEMO provides a more
user-friendly approach to logistic regression models for nominal
dependent variables. SAS LOGISTIC and SPSS PLUM provide
similarly user-friendly routines for ordered DEMO dependent
variables. Although the focus of this monograph is on SAS and SPSS,
it is also worth noting that STATA (1999) provides DEMO broad range
of routines for logistic regression, including MLOGlT for nominal
DEMO variables and OLOGIT for ordinal dependent variables.
To illustrate the use of polytomous logistic regression, the depen-
dent variable from previous examples, prevalence DEMO marijuana use, is
replaced by drug user type. Drug user type DEMO four categories.
1. Nonusers report that they have not used alcohol, DEMO, heroin,
cocaine, amphetamines, barbiturates, or hallucinogens in the past year.
2, Alcohol users report having used alcohol, but no illicit DEMO, in the past
year.
3. Marijuana users report having used marijuana (and, except in one case,
using alcohol as well).
4, Polydrug users report illicit use of one or more of the "DEMO" drugs
(heroin, cocaine, amphetamines, barbiturates, hallucinogens). Polydrug
users also report using alcohol and, except in one case (a respondent
DEMO reported a single incident of hard drug use), marijuana as well.
The four categories can reasonably be regarded as being ordered from
least DEMO to most serious drugs, in terms of legal consequences.
Alternatively, with respect to the nonlegal consequences of the drugs,
the scale could DEMO be regarded as nominal. Both ordinal and
nominal models of this variable will be considered. One additional
change is made from previous models. Because DEMO dependent vari-
able has four categories and because of the small number of cases
in the category "other" on the variable ethnicity (ETHN), ethnicity
was recoded into two categories, white and nonwhite, for DEMO follow-
ing analyses. Failure to do this would have resulted in problems with
zero cells, and instability in estimates of coefficients and their stan-
dard errors,
94
5.1. Polytomous Nominal Dependent Variables
Figure 5.1 presents the output from DEMO NOMREG22 with
DRGTYPE as a dependent variable, using a contrast for DEMO
that compares, in succession, (a) nonusers with alcohol users,
(b) nonusers with marijuana users, and (c) nonusers with poly-
drug users. The resulting functions, gj(X), g2(X), and g3(X) may be
defined as
gj = logit (probability of DEMO some alcohol versus nonuse
of drugs),
g2 = logit (probability of using marijuana versus nonuse of drugs),
and
g3 = logit (probability of using other illicit drugs versus nonuse
of drugs).
The equations for gj, g2, and g3 using unstandardized coefficients are,
DEMO Figure 5.1,
gj = .165(EDF5)
.271(BELlEF4) + DEMO(SEX)
+ 1.616(WHITE) + 5.085,
g2 = .506(DEMO) - .285(BELlEF4) - .920(SEX)
+ .357(WHITE) DEMO 2.503,
and
g3 = .633(EDF5) - .360(BELlEF4) - 2.224(SEX)
+ 2.209(WHITE) + .768.
The calculation of R2 or TJ2 and the standardized logistic regres-
sion coefficients is done separately DEMO each logistic function, g" g2,
and g3. (This is DEMO to the calculation of separate canonical cor-
relation coefficients and standardized discriminant function coeffi-
cients for each linear discriminant function in discriminant analysis;
DEMO Klecka, 1980.) R2 for the full model is calculated based on the
predicted probabilities and observed classification for all four cate-
gories. Prediction DEMO are included in SPSS NOMREG, and can
•
95
rtOIll,eg drgtyp5by sexemnwilh eers betief4/mooel"«!fSbeliel4 sex elhnlprinl",rrt1ftparametersumffillry ClasSllIble!SClllIFdeviance
Warnings:
.
Thefe are437 (70.9%)cells {i.e., depend,""DEMO subpopulatiOl'\$) with ~erofrequeI\Cies
c
se ptocessing s"","'Mry
DEMO
fining !nformHion
01l(;1'{P5
,
Model
-2
Log
LikelihOOd Chi-SquMfl <it
'"
<;')'HN
valid
Missil'\g
Total
Goodness-of-fit
DEMO
pearson
n9.0n
Oevl-ance
341.094
Classification
1.000
2.000
3.000
alcono1
marijuana
druqs
"'
SO
n
4.000
nonusex
as
i
a
,
a
male
female
Whit'"
nonwhite
,;It
'"
no
m
sa
no
ao
m
5 19.
,n .H2
'"
1.000
51'1.
Int'HCept Only 549.126
rind
319.778
Likel1hoo<\ Ratio Tests
169.34e
" .000
UfeCt
"2
Log Likelihood of Reduced Model Chi-Square df
Sig.
Int(>rcept 379.77B
~Or5
444.%0
B£LIEfoj
'"
S'!'f1N
396.795
404.~6S
399.9%
The DEMO statistic is
between the final mo<lc! and
form"d by omitting
hypothesis is th"t
.000
65.172
17.0n
24.9S7
20.2n
c
,
,DEMO
,
,
.000
.coi
.000
,000
- -
tl1e dHference DEMO -2
a reduced mOdd. 'l'he
"n effect fro'"
DEMO par"",eters
log-HkcUhco<lS
re<luced model is
th" fin"DEMO model. l'hC null
of that "Heet .lr'" O.
pseudo DEMO
Co",
"nd Snell
Na\lelkerke
McFadden
,526
.566
.282
R'DEMO
,,,
R,'
,,>
x,
t
.303
DEMO
.149
,331
,300
.399
P
P
,000
- ,000
Predict"<1
OhS"rved
1 ,000
1 ,000
"lcohol
"
2.000
3.000
4.000
"'ariju""..
dtU9S
nonuser
",
ao
Ov<>DEMO
Percellt"ge n "
alcohol 2.000
,
is
,
;
15,4'i
marijuana 3.000
a
a
ie
0
12.3~
drugs 4,DEMO
"
s
o
"
" "
nOnuSer
?"rc"nt DEMO
70.10-
32.0,
sa n
" "
56. B~
Figure 5,DEMO Polytomous Nominal Logistic Regression
be constructed for SAS CATMOD by calculating the probability of
classification for each value of Y, including the reference category,
using Equations 5.2 and 5.3, then classifying each case into the cat-
egory of Y for which it has the highest probability. The DEMO itself
can then be constructed using SAS PROC FREQ. Once the classi-
Std.
Enor
Wald
df Slq.
£"1'(81
1.~63 4.264
,
,
,
.039
.O9l
3.303
.069 1.119
.070
14.906
.000
.763
.3.38
1.116
i
.136 1.656
0
,400
16.27') ,
.000 5.032
DEMO
2.614 .a-s
,
,
,
.319
.096
27.544
. 000
DEMO 659
.07$
13.319
.000 .752
.439
01
.401
i
.036
.398
0
.462
.596
1
.140
1. 428
0
3.049 .054
, .eci
.106
DEMO?6 .1
.000 1.aB3
.086
17.515 i
.000
.698
.619
11.893 ,DEMO
.000
.1OB
0
.a41
6.901
,
.009 9.104
Figure 5.L
(Continued)
0
fication table has been constructed, indices of predictive efficiency
can be calculated as they have been for the Classification table in
Figure DEMO, using the procedures described in Chapter 2. It is for
polytomous DEMO with nominal dependent variables that the dif-
ferences between Ap and T p' as opposed to other proposed indices of
predictive efficiency, become DEMO evident.
96
ORG'l'Y?S
1.000
alcohol
2.000
ll1ari:Juana
3.000
<i~"g5
a
Intercept 5.085
,:0,5
.165
IlI:LrEN
-.211
[SI:K~lJ
.50S
(l>l:X"'1J
O(a)
(S1'IlN~l)
1.616
[1:'l'HN~21
0(8)
Int'1!<eopt 2.503
EOF5
.506
BELlEr.
-.285
!SI:X~ll
-.920
[SEX~2)
O(a)DEMO
I£THN~l)
.35"1
Il:tHN~21
ote:
r"oerc<Jpt
. 76B
soss
.633
IlELIEr4
-.360
IS;:X~ll
-1.224
(S;:X,.21
Ola)
lE'l'IIN"lj
1.109
IE'l'HN~:;n
O(a)
9S~ Confidilnce
Inte(val for l;><p(81
Lower
DEMO
Upper
Bound
.987
.665
.854
\,409
.87$
3.114
2.295
11.031
1,313
.615
.169
.5"/8
1.531
.590
3.2111:-02
1. 75?
2.M•
.S'16
.9H
3.531
2.)16
.826
. 36~
47.302
Standardiz"DEMO !,.09istic
Regression Coeiiid(mts
Not",
edited
these have beon
DEMO the output.
.209
-.31<.1
,015
.202
.6n
'"
'"DEMO
.0·17
.6'1'1
-.357
- .279
.233
97
In Figure 5.1, the model works fairly well, as indicated DEMO the
statistically significant model x2 and the McFadden Rt of .28.
The explained variance in 10git(Y) varies by the category of the
dependent variable and is highest for g3 (polydrug use) and low-
est DEMO g2 (marijuana use). In the overall model, as indicated by
the Likelihood Ratio Tests table, all four of the predictors are sta-
tistically significant. As indicated at the top of Figure 5.1 in the
DEMO NOMREG statement, the dispersion has been corrected using
tbe deviance X2 (lscale = deviance). This is because the deviance
x2 appears to DEMO somewhat lower than the degrees of freedom
(x2 = 341, df = 447, X2(df = .76), indicating underdispersion. The
adjustment for dispersion will affect the statistical significance of the
Wald coefficients. For alcohol DEMO, the standardized coefficients (not
part of the SPSS output, but DEMO Ap, Tp' and R2 added to the output)
indicate that the best predictor is belief that it is wrong to violate
the DEMO, followed by ethnicity (white respondents are more likely
to use alcohol than nonwhites). Exposure to delinquent friends is
marginally significant according to DEMO Wald statistic (p = .069), and
gender is not statistically DEMO For both marijuana and polydrug
use, the best predictor is exposure DEMO delinquent friends, followed by
belief, then gender. Ethnicity is not a statistically significant predictor
for marijuana use, but white respondents are more likely than non-
white respondents to be polydrug users. Based on the Classification
DEMO in Figure 5.1, the indices of predictive efficiency Ap = .300 DEMO
Tp = .399 are both statistically significant and moderately strong.
5.2. Polytomous or Multinomial Ordinal Dependent Variables
When the dependent variable is measured on DEMO ordinal scale, many
possibilities for analysis exist, including, but by DEMO means limited to,
logisticregression analysis. For a more detailed discussion, DEMO Agresti
(1990, pp. 318-332), Long (1997, pp. 114--147), or Clagg and Shihadeh
(1994). Briefly, the options available include
DEMO Ignoring the ordering of the categories of the dependent variable and
treating it as nominal
2. Treating the variable as though it were measured DEMO a true ordinal scale
3. Treating the variable as though it were measured on an ordinal scale,
but the ordinal scale represented crude DEMO of an underlying
interval/ratio scale
4. Treating the variable as though it were measured on an interval scale.
98
One possibility consistent with the first option is the use of DEMO multi-
nomial logit or logistic regression model for a nominal categorical
dependent variable, as in Figure 5.1. Also possible under option 1
would he the use of discriminant analysis (Klecka, 1980). An example
of DEMO second option is the use of a cumulative logit model, in DEMO
the transformation of the dependent variable incorporates not only
each category compared to a reference category, but also a compari-
son of each category with all of the categories with higher (or lower)
numeric codes than the present category. The third option, assum-
ing an underlying interval scale, could be implemented in LISREL
by using weighted least squares (DEMO) analysis of polychoric corre-
lations (Joreskog & Sorbom, 1988).23 DEMO fourth option might be
implemented by using 01.5 regression with an ordinal dependent
variable.
Selecting one of the options is a matter requiring careful DEMO
ment. The fourth option effectively assumes that the data are mea-
sured more precisely than they really are, but for ordinal variables
with a large number of categories, it may be reasonable. The use of
W1.5 with polychoric correlations appears to be a better option; it
can be used with both large and small numbers of categories, and for
most ordinal variables. The assumption of imprecise measurement of
a quantity that is DEMO continuous (political conservatism, seriousness
of drug use) is inherently plausible. DEMO of these options allow pre-
dicted values that lie outside the range of observed values, but under
the assumption of imprecise measurement, this DEMO be reasonable.
Mechanical application of options available in existing software
packages is not recommended. For example, SAS PROC LOGISTIC
and SPSS PLUM can calculate polytomous logistic regression models
for ordinal dependent variables, but both use a cumulative logit model
for the dependent variable. This model assumes that the DEMO
for each independent variable is invariant across the three equations,
that is, bEDF5.1 = b EDF5,2 = b EDF5,3, b DEMO, 1 = b SEX,2 = b SEX• 3, etc.
(DEMO slopes), where the variable in the subscript is the variable to
which the coefficient refers, and the number in the subscript is the
equation (1, 2, or 3) in which the coefficient appears. DEMO the parallel
slopes model, only the intercept is different for the DEMO equations;
otherwise, the effects of the independent variables are assumed DEMO be
constant across group comparisons. It is important to emphasize that
although this model is easily calculated using SAS PROC LOGISTIC or
99
SPSS PLUM, it may not be the most appropriate model for the relation-
ship between the dependent variable and the predictors.
Figure 5.2 DEMO the results of analyzing drug user type,
DRGTYPE, as an DEMO variable in SAS PROC LOGISTIC.
SAS provides a test of the assumption that the slopes are equal, the
Score test. For Figure 5.2, DEMO Score test of the null hypothesis that
the slopes are equal is 32.066 with 8 degrees of freedom, statistically
significant at the .0001 level. Because the Score test is statistically
significant, the parallel slopes assumption is rejected, indicating that
a model that does not assume parallel slopes would be more appro-
priate. The reasons for the rejection of the equal DEMO model are
evident from Figure 5.1: the variation in both the DEMO and sta-
tistical significance of the effects of EDF5 (not statistically DEMO
for alcohol users as opposed to nonusers), SEX (not statistically
DEMO for alcohol users as opposed to nonusers; stronger for
polydrug users DEMO for marijuana users as opposed to nonusers), and
ETHN (not DEMO significant for marijuana users as opposed
to nonusers). The pattern of the differences in the coefficients in
Figure 5.1 (especially the down-and-up pattern of the coefficients for
ethnicity) suggests that treating DRGTYPE as a categorical nominal
variable may be the best option.
SPSS PLUM provides much the DEMO information as SAS LOGIS-
TIC, except that SPSS PLUM excludes the DEMO at the bottom
of Figure 5.2 (Association of Predicted Probabilities and DEMO
Responses) and (as in SPSS NOMREG) includes the Pearson and
DEMO goodness-of-fit X2 statistics and the MeFadden Rt, the
latter of which (along with R2 for the overall model and for each
of the DEMO functions) has been edited into the SAS output in
Figure 5.2. DEMO PLUM also offers alternatives to the logit distribu-
tion for dependent variables that are normally distributed, positively
or negatively skewed, or have many DEMO values. In both SPSS
PLUM and SAS LOGISTIC, it is possible DEMO save predicted values,
and to use the predicted and observed values to produce contingency
tables (in SAS PROC FREQ or SPSS CROSSTABS) DEMO analyze the
accuracy of classification. Doing so for Figure 5.2 would result in
Ap = .229 (p = .000) and Tp = .208 (p = .000), both smaller than in
Figure 5.1, further suggesting that the dependent variable may better
be treated as nominal rather than DEMO For an ordinal variable in
general, however, the statistics at the bottom of Figure 5.2, particu-
larly the familiar ordinal measures of association Gamma and Tau-a,
100
data:
infi Ie . sas 1rrse .dat ' ratssover 1mes DEMO fi rstcos-t obs~257:
input 10 f66 SEX 8 WIN l(} U$R5 12 PDRUGSS 14-15 PMRJ5 17-18 PAlCS 20-21
ORGH?5 23-24 £DPS DEMO BELlEF4 35·42 MEANSC\N 44-51 MEANfAiN 53·60:
if etnn-t then white~l: DEMO erno-z then wh\te~O; if etno-c then whtte-u:
if drgtyp5~1 then DEMO: if drgtypS"Z then drgtypSrM3:
if drgtypS"'3 then drgtyp5r"'2: if drgtyp5~4 then drgtypSr-l:c.onstS"'l;
run:
prot logistic:
model drgtyp5r~edp5 belief4 sex wntte.run:
Data Set: WORK. DATAl
Response Variable: ORGTYP5R
Response levels: 4
Number of Observations: 227
Link Function; toett
Response Profile
Ordered
Va Jut!
ORGTYPSR
1
2
3
4
1
2
3
4
Count
31
SO
81
59
WARNING,
Variable
DEMO
IIHERCP2
INTERCP3
EOP5
8EllEf4
SEX
WHITE
30 ccserveucots: were del eted DEMO to missing values for the response or explanatory variables,
Score Test for the Proportional Odds Assumption
Chi-Square ~ 32.0660 with 8 Of (p~O.OOO1)
Hodel Fitting Information and Testing Global
Null Hypothests 8ETA~O
Criterion
AIC
DEMO
-2 LOG L
Score
Intercept
Only
606.600
616.875
600.600
RSqua re " .433
Intercept
snd Ccver-tetes
485.626
509.600
471.626
uu.sccere for tovertetes
128.975 with
DEMO with
4
4
OF
OF
(p~O.OOOl)
{p~O.OOOl}
Adjusted nscoere ~ DEMO
R\ ~
Rl) ~
Rl, ~
.004
.089
.151
Rl~ ~ .264
R/ ~ 2lS
Analysis of Maximum Likelihood Estimates
Of
serseater
Estimate
Standard
Error
Wald
Chi-Square
Pc>
Chi Square
Stenderdtzed
Estimate b",
Odes
Ratio
Standardized
coefficient
b*~(l»)(s,)/s,
- 1. 3616 1.4611 0.8684 0.3514
0.6157 1,4513 0,1800 0,6714
2,DEMO 1.4655 4,1583 0.0414
0,2701 0.0424 40,5402 0.0001 0.633781 1.310 .343
-0.1774 0.0426 17.3225 0.0001 -0.386429 0.837 - .209
·U90S 0.2630 9.0312 DEMO -0.218288 0,454 .. 118
0.8343 0.3167 6.9391 0.0084 0.193729 2-303 _105
Association of Predicted Probabilities and Observed Responses
Concordant ~ 80 S~
utscoroent > 18.2%
Tied 1.3%
(18509 cetrs
r
Scners '
Galfllm
Tau-a
c
o~ 0,623
" 0,63\
,. 0.449
.~ 0.811
Figure 5.2. SAS Output for Ordinal Logistic Regression
may be even more informative than DEMO or T p' becanse the former
two measures, unlike the latter two, incorporate information on the
ordering of the categories of the dependent variable.
p
I
I
I
\
«
101
5.3. Conclusion
The principal concern in using logistic regression analysis with DEMO
tomous dependent variables is not how to make the model work,
but instead whether the logistic regression model is appropriate at
all. For DEMO dependent variables, the problems that motivated
the development of the logistic DEMO model (out-of-range pre-
dicted values of the dependent variable, heteroscedasticity) DEMO not
be present, and other models may be more appropriate than DEMO
regression, depending on assumptions about the underlying scale of
the dependent DEMO and the functional form (linear, monotonic,
nonmonotonic) of the DEMO between the dependent variable
and the independent variables. If there is an underlying interval scale,
and if the relationships appear to be linear DEMO monotonic, weighted
least squares with polychoric correlations may be the best DEMO For
nonmonotonic relationships, and especially when there are relatively
few categories DEMO the dependent variable, it may be best to treat the
dependent DEMO as though it were nominal. When the dependent
variable is nominal, DEMO is an ordinal variable with few categories and
is treated as though it were nominal, an alternative worth considering
is discriminant analysis (Klecka, 1980). Another alternative, separate
logistic regressions (Bess & Grey, 1984; Hosmer & Lemeshow, 1989,
pp. 230-232), does not appear DEMO produce results sufficiently consis-
tent with the multinomial logit/polytomous logistic regression model
to warrant its use. Only if polytomous logistic regression software were
DEMO (an increasingly rare phenomenon, with all major soft-
ware packages now including polytomous logistic regression routines)
would this approach have any merit.
DEMO ease of use, flexibility, broad applicability, and current pop-
ularity DEMO logistic regression analysis make it particularly susceptible
to misuse. Thoughtless and mechanical applications of logistic regres-
sion analysis will be no more fruitful than DEMO and mechan-
ical applications of linear regression or any other technique. It is
important to recognize the weaknesses as well as the strengths of DEMO
method. Logistic regression is especially appropriate for the analysis
of dichotomous and unordered nominal polytomous dependent vari-
ables. For ordinal polytomous dependent variables, it may be possi-
ble to use polytomous logistic regression analysis, but other models,
including linear regression and weighted least squares with polychoric
correlations, also deserve serious consideration. Polytomous ordinal
102
variables are the dependent variables for which the technical motiva-
tion DEMO using logistic regression is weakest and for which alternative
methods of analysis are most likely to provide better solutions than
logistic regression. Given these DEMO, however, the same ease
of use (particularly improvements in logistic DEMO software, even
in the few years since the first edition of DEMO monograph), flexibility,
and broad applicability of the logistic regression approach, as men-
tioned at the beginning of this paragraph, make logistic DEMO
an extremely useful tool for analyzing a broad range of dependent
variables for which OLS regression is not appropriate.
103
NOTES
1. Although the relationship being modeled often represents a causal DEMO
in which the single predicted variable is believed to be an effect of the one or more
predictor variables, this is not always the case. We can as easilypredict a cause from an
effect (for example, predict whether different individuals are male or female based on
their income) as predict an effect from a cause (predicting income based on DEMO
someone is male or female), Throughout this monograph, the emphasis DEMO on predic-
tive rather than causal relationships, although the language of DEMO relationships is
sometimes employed. Describing a variable as independent or dependent, DEMO, or
as an outcome or a predictor, does not necessarily imply a causal relationship. Instead,
all relationships should be regarded as definitely DEMO, but only possibly causal in
nature.
2. Data are taken from DEMO National Youth Survey, a national household proba-
bility sample of individuals DEMO were adolescents (age 11 to 17) in 1976 and young
adults (age 27 to 33) in 1992. Data were collected annually for DEMO years 1976 to 1980,
then in 3 year intervals thereafter, DEMO 1983 to 1992. The data include information on
self-reported illegal behavior, DEMO relationships, school performance, and sociode-
mographic characteristics of the respondents. Details on sampling and measurement
may be found in Elliott et aL (1985, 1989), For present purposes, attention is restricted
to respondents who DEMO 16 years old in 1980. In the scatterplot, the numbers and DEMO
bols refer to numbers of cases at a given point on the plot: a 1 indicates one case, a
2 indicates two cases, a 9 indicates nine cases; the letters A to Z continue the count,
A = 10 cases, B = 11 cases, ... , Z = 35 cases. When more than 35 cases occupy a
single point, an asterisk (~) is used.
3. For a review of levels of measurement, see, for example, Agresti and Finlay
(1997, pp. 12-17).
4. The unconditional mean of Y is simply the DEMO mean Y = L Y/N. The
conditional mean of Y for a given value of X is calculated by selecting only those
cases DEMO which X has a certain value and calculating the mean for those cases. The
conditional mean can be denoted Y X",i = L Yij/n;, where i is the value of X for which
DEMO are calculating the conditional mean of Y, Yij are the values DEMO Y for the cases
(j = 1,2, ... , nj ) for which X = t, and nj is the number of cases for which X = i,
5. A brief discussion of DEMO, including conditional probabilities, is presented
in the Appendix.
6. The logarithmic transformation is one of several possibilities discussed by Berry
and Feldman (1985, pp. 63-64), Lewis-Beck (1980, p. 44), and others to deal with
relationships that are nonlinear with respect to the variables, but may be expressed as
linear relationships with respect to the parameters.
7. DEMO is also provided as the pseudo-R" in Stata (Stata, 1999)DEMO An earlier version
of SAS PROC LOGlST1C [SAS (SUG1) PROC LOG1ST (Harrell, 1986)J included
a variant of Rt that was adjusted DEMO the number of parameters in the model. This
104
measure is analogous to the adjusted R2 in linear regression, and we may denote it
as R'L-, to indicate its connection with Rt and to distinguish it from other R2_type
measures. RL. = (G M - 2k)j(Do), where k is the number of DEMO variables
in the model. If GM < 2k and particularly if G'\f = 0, it is possible to get a negative
estimate for explained variance using RLA'
8. It should be noted, however, DEMO in other contexts, it may not be appropriate.
For example, in proportional hazards models, Rr, is more sensitive to censoring than
R~ (Schemper, 1990, 1992).
9. The designation 4>1' was selected because cPp , like 'p, is based on comparisons
between observed DEMO expected values for individual cells (rather than rows or columns,
DEMO with AI' and 7[1)' because the numerical value of o/DEMO is close to the numerical value
of 0/ for tables with DEMO marginals (row and column totals in which the larger
row total DEMO to the larger column total), and o/r and 0/ DEMO the same sign
(because they have the same numerator).
10. DEMO/1' can be adjusted by adding the minimum number of errors, l(a+b )-(a + c)1 =
Ib- c], to DEMO expected number of errors without the model. This results in a coefficient
that (a) retains the proportional change in error interpretation (because the adjustment
is built into the calculation of the expected error) and (DEMO) still may have negative values
if the model is pathologically inaccurate. DEMO extremely poor models, the revised index
still has a maximum value DEMO than 1, even when the maximum number of cases is cor-
DEMO classified, and the increment over 0/1' is small. Based again on similarities with 0/,
we may designate this adjusted o/p as o/~. Note, however, that o/~ cannot be calculated
DEMO 0/1'/ max(o/r); to do so would destroy the proportional change in error interpretation
for the measure and would leave DEMO measure undefined when the maximum value of
o/p was O.
11. For a two-tailed test, the null hypothesis is that there is no difference between
the proportion of errors with and without the prediction model. DEMO alternative hypoth-
esis is that the proportion of errors with the prediction model is not equal to the pro-
portion of errors without the DEMO model. For a one-tailed test, specifying that
the model results in DEMO accuracy of prediction of the dependent variable, the
null hypothesis is DEMO the proportion of errors with the prediction model is no smaller
than the proportion of errors without the prediction model. The alternative hypothesis
is DEMO the proportion of errors with the prediction model is less than the proportion of
errors without the prediction model. If we want to know DEMO the prediction model
improves Our ability to predict the classification of the cases, the one-tailed test is more
appropriate, and a negative value DEMO '\ will result in a negative value for d and failure
DEMO reject the null hypothesis.
12. Copas and Loeber (1990) noted this property and indicated that in this situation
it would be a misinterpretation DEMO regard a value of 1 as indicating perfect prediction.
This leads to two questions. How should we interpret the value of RIOe in this DEMO
tion? What value does indicate perfect prediction for RIOC? Ambiguity of interpreta-
tion is an undesirable quality in any measure of change, and there are enough better
alternatives that the use of the RIOe measure DEMO be avoided.
13. It will not always be the case that logistic regression produces a higher R2 than
linear regression for a dichotomous dependent DEMO In a parallel analysis of theft
for the full National Youth Survey sample, R2 for linear and logistic regression was
.255 and .253, DEMO
105
14. This is sometimes called a Type II error or a DEMO negative (failure to detect a
relationship that exists), as opposed DEMO a Type I error or a false positive (concluding
that there DEMO a relationship when there really is none).
15. This was done using the backward stepwise procedure, to be discussed later
in the text. In SPSS NOMREG and PLUM there is no stepwise procedure, but it is
possible to include the likelihood statistics in the output.
16. If DEMO were, they would indicate that non-Hispanic European Americans have
the lowest DEMO of marijuana use, followed by African Americans, and others have
the highest prevalence of marijuana use. It is always questionable, however, to DEMO
statements about the nature of a relationship that is not statistically significant and may
reflect nothing more than random sample error.
17. Mathematically, the omitted category is redundant or of little or no interest.
In both DEMO testing and applied research, however, it makes more sense to provide
full information about the coefficients and their statistical significance for all three
DEMO, rather than leave one for pencil and paper calculation.
18. Hosmer DEMO Lemeshow (1989) distinguished between analyzing residuals based
on individuals and analyzing residuals based on covariate patterns, the combinations
of values of the independent variables that actually occur in the sample. When the
number of covariate DEMO is equal to the number of cases, or very nearly so, resid-
uals must be analyzed for each case separately. This is the DEMO approach taken in
this section, and in SAS PROC LOGISTIC and DEMO LOGISTIC REGRESSION, but
SPSS NOMREG aggregates cases by covariate pattern and DEMO the correct pre-
dictions, residuals, and goodness-of-fit tests based on those subpopulations (Norusis,
1999). When the number of cases is much larger than the number of covariate pat-
terns or when some of DEMO covariate patterns hold for more than five cases, Hosmer
and Lemeshow DEMO aggregating the cases by covariate pattern, because of
potential underestimation of DEMO leverage statistic hj'
19. In a standard normal distribution with a mean of 0 and a standard deviation of
1, 95% of the cases should have standardized scores (or, in this context, standardized
residuals) between -2 and +2, and 99% should have scores or residuals DEMO -3
and +3. Having a standardized or deviance residual larger than 2 Or 3 does not neces-
sarily mean that there is something wrong DEMO the model. We would expect about 5%
of the sample to lie outside the range -2 to +2, and 1% to lie outside the range -2.5 to
+2.5. Values far outside this range, however, are DEMO indications that the model fits
poorly for a particular case and suggest either that there is something unusual about
the case that merits further DEMO or that the model may need to be modified
to account for whatever it is that explains the poor fit for some of the DEMO
20. As Fox (1991) noted, in linear regression, influence = leverage x discrepancy,
where "discrepancy" refers to being an outlier DEMO Y with respect to the predictors. In
logistic regression, in contrast DEMO linear regression, as fitted probabilities get close to
o (less than .1) or 1 (greater than .9), the leverages stop increasing DEMO turn rapidly
toward 0 (Hosmer & Lemeshow, 1989, pp. 153-154)DEMO
21. A particularly clear and concise discussion of overdispersion and underdisper-
sion may be found in Hutcheson and Sofroniou (1999). See also McCullagh and Neider
(1989, pp. 124-128).
22. Had this been run DEMO SAS CATMOD, neither Do nor GM would be directly
available. For DEMO, the likelihood X2 statistics are based on comparisons of cells in DEMO
contingency table, rather than on probabilities of category membership. The two DEMO
106
related, however, and it is possible to derive the statistics DEMO for logistic regres-
sion analysis from the statistics provided by SAS PROC CATMOD. The appropriate
steps arc
1. Compute Du = :L(lI y", ,,)ln[P( Y = 11)] = 'L(ny",,,)ln(ny,,,,,/N), where llY"'1I is DEMO
number of cases for which Y is equal to 1 of its possible values h, N is the total
sample size, and the DEMO is taken over all possible values h of Y.
2. Examine the iteration history of the model. The "-2 Log Likelihood" from the
DEMO iteration, listed in the Maximum Likelihood Analysis table is approximately
(but not exactly) equal to DM.
3. Compute GM = Do - DM; compute RL = GM/Do.
If these procedures are followed with a dichotomous dependent variable, the result-
ing figures are approximately equal to the GM and R~ that would be obtained in the
identical analysis from DEMO PROC LOGISTIC. (SAS PROC LOGISTIC uses an iter-
atively reweigh ted DEMO squares algorithm to calculate the model parameters; PROC
CATMOD USes weighted DEMO squares or maximum likelihood estimation, depending
on the type of model DEMO calculated.) The process is a bit awkward, but if the likeli-
hood ratio statistics provided in CATMOD are used without modification, they produce
results different from those that would be obtained using SAS PROC LOGISTIC DEMO
the dependent variable is dichotomous.
23. For reliable estimates, this requires DEMO large N (Hu, Bentler, & Kano, 1992).
I
----1
107
APPENDIX: PROBABILITIES
The probability of an event is estimated by its relative frequency
in a population or sample. For example, if ny = I is the number of
cases for which Y = 1 in DEMO sample and N is the total number of cases
in the sample, then
1. We denote the probability that Y is equal to 1 as P(Y=I)
2. pry = 1) = ny=,/N
DEMO The probability that Y is not equal to 1 is pry oft 1) =1 - pry = 1) =
1- (ny=,/N) = (N - ny=,)/N
4. The minimum possible value for a probability is 0 (ny=, = 0 implies
ny=,/N 0)
5. The maximum possible value for a probability is 1 (n y",,] e;:o: N implies
ny=,/N = 1).
The joint probabiiity of two independent events (occurrences that
are unrelated to one another) is the product of their individual prob-
abilities. For example, the probability that both X and Yare equal
to 1, DEMO X and Yare unrelated is prY = 1 and X = 1) = prY =
1) x P(X = I). If DEMO and Yare related (for example, if the probability
that Y is equal to 1 depends on the value of X), then P( Y = 1 and
X = 1) will not be equal to prY = l)xP(X = 1). Instead, we will
want to consider the conditional probability that Y = 1 when X = DEMO,
or prY = llX = 1).
The conditional probability that Y = 1 is the probability that Y = 1
for a DEMO value of some other variable. [In this context, we may some-
DEMO refer to P( Y = 1), the probability that Y DEMO 1 regardless of
the value of any other variable, as the DEMO probability that
Y = 1.] For example, the probability that the DEMO of marijuana
use is equal to 1 for the data in Figure 2.1 is P(PMRJ5 = 1) =.35
(for males and females DEMO; detailed data not shown). The con-
ditional probability that prevalence DEMO marijuana use is equal to 1 is
P(PMRJ5 = 11 SEX = 0) =.45 for females and P(PMRJ5 = 1 I
SEX = 1) =.25 for males. For a dichotomous variable, coded as DEMO
or I, the probability that the variable is equal to 1 DEMO equal to the
mean for that variable, and the conditional probability DEMO the vari-
able is equal to 1 is equal to the conditional mean (see note 4) for
the variable.
108
REFERENCES
AGRESTI, A. (1990). Categorical data analysis. New York DEMO
AGRESTI, A., and FINLAY, B. (1997). Statistical methods for the social sciences (3rd
ed.). Upper Saddle River, NJ: Prentice-Hall.
ALDRICH, J. H., and NELSON, R D. (1984). Linearprobability, logft, and probit models.
Sage University Paper Series on Quantitative Applications in the Social Sciences, 07~
045. Beverly Hills, CA: Sage.
ALLISON, DEMO D. (1999). Logistic regression using the SAS system. Cary, NC: SAS
Institute.
BEGG, C. B., and GREY, R. (1984). Calculation of polychotomous logistic regression
parameters using individualized regressions. Biometrika, 71, DEMO
BENDEL, R. B., and AFIFI, A A. (1977). Comparison of stopping rules in forward
regression. Journal of the American Statistical Association, 72, 46-53.
BERRY, W D. (1993). Understanding regression assumptions. Sage University Paper
Series on Quantitative Applications in the Social Sciences, 07-092. Newbury Park,
CA: Sage,
BERRY, W.D., and FELDMAN, S. (1985). Multiple regression in practice. Sage Univer-
sity Paper Series on DEMO Applications in the Social Sciences, 07-050, Beverly
Hills, CA: Sage,
BOHRNSTEDT, G. W, and KNOKE, D. (1994). Statistics DEMO social data analysis (3rd
ed.). Itasca, IL: F. E. DEMO
BOLLEN, K. A. (1989). Structural equation models with latent variables. New York:
Wiley,
BULMER, M. G. (1979). Principles DEMO statistics. New York: Dover.
CLOGG, C. C., and SHIHADEH, E. S. (1994). Statistical models for ordinal variables.
Thousand Oaks, CA: Sage.
COPAS, J. R, and LOEBER, R. (1990). Relative DEMO over chance (RIOC) for
2x2 tables. British Journal of Mathematical and Statistical Psychology, 43, 293-307.
COSTNER, H. L. (1965). Criteria DEMO measures of association. American Sociological
Review, 30, 341-353.
COX, D, R, and SNELL, E, 1. (1989), The analysis of DEMO data (2nd ed.) London:
Chapman and Hall.
CRAGG, J. DEMO, and UHLER, R. (1970). The demand for automobiles. Canadian DEMO
of Economics, 3, 386-406.
DeMARIS, A. (1992). Logit modeling. Sage University Paper Series on Quantitative
Applications in the Social Sciences, 07-086. Newbury Park, CA: Sage.
ELIASON, S. R. (1993). Maximum DEMO estimation: Logic and practice. Sage Uni-
versity Paper Series on Quantitative DEMO in the Social Sciences, 07-096. New-
bury Park, CA: Sage.
DEMO, D. S, HUIZINGA, D., and AGETON, S. S. (1985). Explaining delinquency
and drug use. Beverly Hills, CA: Sage.
ELLIOTT, D, S., HUIZINGA, D., and MENARD, S. (1989). DEMO problem youth.
New York: Springer-Verlag.
109
FARRINGTON, D. P" and LOEBER, R. (1989). Relative DEMO over chance
(RIOC) and phi as measures of predictive efficiency and strength of association in
2x2 tables. Journal of QuantitativeCriminology, 5, 201-213.
DEMO, J. (1991). Regression diagnostics. Sage University Paper Series on Quantitative
Applications in the Social Sciences, 07~079. Newbury Park, CA: Sage.
HAGLE, 1: M" and MITCHELL, G. E., II (1992). DEMO measures for probit
and legit. American Journal of Political Science, 36, 762-784.
HARDY, M. (1993). Regression with dummy variables. Sage University DEMO Series
on Quantitative Applications in the Social Sciences, 07-093. Newbury Park, CA:
Sage.
HARRELL, F. E., Jr. (1986). The LOGIST procedure. 10 SAS Institute, Inc. (Ed.),
SUGI supplemental library user's guide, (Version 5, pp. 269-293). Cary, NC: SAS
Institute.
HOSMER, D. W, and LEMESHOW, S. (1989). Applied DEMO regression. New York:
Wiley.
HU, L., BENTLER, P. M., AND KANO, Y. (1992). Can test statistics in covariance
structure DEMO be trusted? Psychological Bulletin, 112, 351-362.
HUTCHESON, G., and DEMO, N. (1999). The multioatiate socialscientist: Intro-
ductory statistics using DEMO linear models. Thousand Oaks, CA: Sage.
JORESKOG, K. G., and SORBOM, D. (1988). PRELIS: A program for multivariate
data screening and data summarization (2nd ed.). Chicago, IL: Scientific Software
International.
10RESKOG, K. G., and SORBOM, D. (1993). LISREL 8: Structural equation modeling
with the SIMPLIS command language. Chicago: Scientific Software International.
KLECKA, W R (1980). Discriminant analysis. Sage University Paper Series DEMO Quan-
titative Applications in the Social Sciences, 07~019. Beverly Hills, CA: Sage.
KNOKE, D., and BURKE, P. J. (1980). Log-linear models. Sage University Paper
Series on Quantitative Applications in the Social Sciences, 07-020. Beverly Hills, CA:
Sage.
LANDWEHR, J. M., PREGIBON, DEMO and SHOEMAKER. A. C. (1984). Graphical
methods for assessing logistic DEMO models. Journal of the American Statistical
Association, 79, 61-71.
LEWIS-BECK, DEMO S. (1980). Applied regression: An introduction. Sage University Paper
Series on Quantitative Applications in the Social Sciences, 07-022. Beverly Hills, CA:DEMO
Sage.
LOEBER, R, and DISH ION, T (1983). Early predictors of male delinquency: A review.
Psychological Bulletin, 94, 68-99.
LONG, J. S. (1997). Regression models for categorical and limited dependent DEMO
Thousand Oaks, CA: Sage.
MADDALA, G. S. (1983). Limited-dependent and qualitative oanables in econometrics.
Cambridge, UK Cambridge University Press.
MAGEE, DEMO (1990). R2 measures based on Weld and likelihood ratio joint DEMO
tests. The American Statistician, 44, 250-253.
McCULLAGH, P. and NELDER, J. A. (1989). Generalized linear models (2nd ed.).
London: Chapman and Hall.
McFADDEN, D. (1974). The measurement of urban DEMO demand. Journal of Public
Economics, 3, 303-328.
110
L
McKELVEY, R., and ZAVOINA, W. (1975). A DEMO model for the analysis of
ordinallevel dependent variables. Journal of Mathematical Sociology, 4, 103-120.
MENARD, S. (2000). Coefficients of determination for DEMO logistic regression anal-
ysis. The American Statistician, 54, 17-24.
MIECZKOWSKI, DEMO (1990). The accuracy of self-reported drug use: An evaluation and
analysis of new data, In R. Weisheit (Ed.), Drugs, crime, and the criminaljustice system
(pp. 275-302). Cincinnati: Anderson.
NAGELKERKE, DEMO J. D. (1991). A note on a general definition of DEMO coefficient of
determination. Biometrika, 78, 691-692.
NORUSIS, M. J. (1999). SPSS regression models 10.0. Chicago: SPSS, Inc.
OHLIN, L. E., and DUNCAN, O. D. (1949). The efficiency of prediction in criminology,
ArnericanJournal of Sociology, 54, 441-451.
SAS (1989). SAS/STAT user's guide (Version 6, 4th ed. Vols. I and DEMO). Cary, NC: SAS
Institute.
SAS (1995). Logistic regression DEMO using the SAS system. Cary, NC: SAS Institute.
SCHAEFER, R. DEMO (1986). Alternative estimators in logistic regression when the data
arc DEMO Journal of Statistical Computation and Simulation, 25, 75-91.
SCHEMPER, M. (1990). The explained variation in proportional hazards regression.
Biometrika, 77, DEMO
SCHEMPER, M, (1992). Further results on the explained variation DEMO proportional
hazards regression, Biometrika, 79, 202-204.
SCHROEDER, L. D., DEMO; D. L., and STEPHAN, I' E. (1986). Understanding
DEMO analysis: An introductory guide. Sage University Paper Series on Ouantita-
tive DEMO in the Social Sciences, 07~057, Beverly Hills, CA: Sage.
SIMONOFF, J. S. (1998). Logistic regression, categorical predictors, and goodness DEMO
fit: It depends on who you ask. The American Statistician, 52, 10-14.
SODERSTROM, L, and LEITNER, D. (1997). The effects of base rate, selection ratio,
sample size, and reliability of DEMO on predictive efficiency indices associated
with logistic regression models. Paper presented at the annual meeting of the Mid-
Western Educational Research Association, Chicago.
SPSS (1991). SPSS statisticalalgorithms (2nd ed.). Chicago: SPSS, Inc.
DEMO (1999a). SPSS advanced models 10.0. Chicago: SPSS, Inc.
SPSS (199%). SPSS base 10.0 applicationsguide. Chicago: SPSS, Inc.
STATA (1999). Stata reference manual (Release 6, VoL 2). College Station, TX: State
Press.
STUDENMUND, A. H., and CASSIDY, H. 1. (1987). Using econometrics: A practical
guide. Boston: Little, Brown.
VEALL, M. R., and ZIMMERMAN, K. F. (1996). Pseudo-R'' DEMO for come com-
mon limited dependent variable models. Journal of Economic Surveys, 10, 241-260.
WIGGINS, 1. S. (1973). Personality and prediction: Principles of personality assessment.
Reading, MA: Addison-Wesley.
WOFFORD, S., ELLIOTf, D. S., and MENARD, S. (1994). Continuities in marital
violence. Journal of Family Violence, 9, 195-225.
«
111
ABOUT THE AUTHOR
SCOTT MENARD is Research Associate in the Institute DEMO Behav-
ioral Science at the University of Colorado, Boulder. He received
DEMO A.B. at Cornell University and his Ph.D. at the University of
Colorado, both in sociology. His primary substantive interests are in
the longitudinal study of drug use and other forms of illegal behav-
ior. His publications DEMO the Sage QASS monograph Longitudinal
Research (1991; second edition forthcoming in 2002) and the books
Perspectives on Publication (with Elizabeth W Moen, 1987), Multiple
Problem Youth (with Delbert S. Elliott and David Huizinga, 1989),
and Juvenile Gangs (with Herbert C. Covey and Robert J. Franzese,
second edition 1997).{1g42fwefx}