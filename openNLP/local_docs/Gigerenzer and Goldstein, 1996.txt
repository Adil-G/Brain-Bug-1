Psychological Review
1996, Vol. 103. No. 4, 650-669
Copyright 1996 by DEMO American Psychological Association, Inc.
0033-295X/96/$3.00
Reasoning the Fast and DEMO Way: Models of Bounded Rationality
Gerd Gigerenzer and Daniel G. Goldstein
DEMO Planck Institute for Psychological Research and University
of Chicago
Humans and animals make inferences about the world under limited time and knowledge. In con-
DEMO, many models of rational inference treat the mind as a Laplacean DEMO, equipped with un-
limited time, knowledge, and computational might. Following DEMO Simon's notion of satisficing, the
authors have proposed a family DEMO algorithms based on a simple psychological mechanism: one-
reason decision making. DEMO fast and frugal algorithms violate fundamental tenets of classical
rationality: They DEMO look up nor integrate all information. By computer simulation, the authors
DEMO a competition between the satisficing "Take The Best" algorithm and various "rational" infer-
ence procedures (e.g., multiple regression). The Take DEMO Best algorithm matched or outperformed
all competitors in inferential speed and accuracy. This result is an existence proof that cognitive
mechanisms capable of successful DEMO in the real world do not need to satisfy the classical
norms of rational inference.
Organisms make inductive inferences. Darwin ( 1872/1965 )
observed that people use facial cues, such as eyes that waver and
lids that hang low, to infer a person's guilt. Male toads, roaming
through swamps at night, use the pitch of a rival'DEMO croak to infer
its size when deciding whether to fight (Krebs & Davies, 1987).
Stock brokers must make fast decisions about which DEMO several
stocks to trade or invest when only limited information is avail-
able. The list goes on. Inductive inferences are typically based
on uncertain DEMO: The eyes can deceive, and so can a tiny toad
with a deep croak in the darkness.
How does an organism make inferences DEMO unknown as-
pects of the environment? There are three directions in DEMO
to look for an answer. From Pierre Laplace to George Boole to
Jean Piaget, many scholars have defended the now classical view
that the laws of human inference are the laws of probability and
statistics (and to a lesser degree logic, which does not deal as
easily with uncertainty). Indeed, the Enlightenment probabi-
lists derived the laws of probability from what they believed to
be the laws of human reasoning (Daston, 1988). Following this
time-honored tradition, much contemporary research in psy-
DEMO, behavioral ecology, and economics assumes standard
Gerd Gigerenzer and Daniel G. Goldstein, Center for Adaptive Be-
havior and Cognition, Max Planck Institute DEMO Psychological Research,
Munich, Germany, and Department of Psychology, University DEMO
Chicago.
This research was funded by National Science Foundation Grant
SBR-9320797/GG.
We are deeply grateful to the many people who have contributed to
DEMO article, including Hal Arkes, Leda Cosmides, Jean Czerlinski, Lor-
raine Daston, Ken Hammond, Reid Hastie, Wolfgang Hell, Ralph Her-
twig, Ulrich Hoffrage, Albert Madansky, Laura Martignon, Geoffrey
Miller, Silvia Papal, John Payne, Terry Regier, Werner Schub6, Peter
Sedlmeier, Herbert Simon, Stephen Stigler, Gerhard Strube, Zeno Swi-
jtink, John Tooby, William DEMO, and Werner Wittmann.
Correspondence concerning this article should be addressed to DEMO
Gigerenzer or Daniel G. Goldstein, Center for Adaptive Behavior and
Cognition, Max Planck Institute for Psychological Research, Leo-
poldstrasse 24, 80802 Munich, Germany. Electronic mail may be sent
via Internet to giger@mpipf-muenchen.mpg.de.
650
statistical DEMO to be the normative and descriptive models of
inference and decision making. Multiple regression, for in-
stance, is both the economist's universal DEMO (McCloskey,
1985 ) and a model of inductive inference in DEMO learn-
ing (Hammond, 1990) and clinical judgment (B. Brehmer,
1994); Bayes's theorem is a model of how animals infer DEMO
presence of predators or prey (Stephens & Krebs, 1986) as DEMO
as of human reasoning and memory (Anderson, 1990). This
Enlightenment view that probability theory and human reason-
ing are two sides of DEMO same coin crumbled in the early nine-
teenth century but has remained strong in psychology and
economics.
In the past 25 years, this stronghold came under attack by
proponents of the heuristics and biases program, who con-
cluded that human inference is systematically biased and error
prone, suggesting that the laws of inference are quick-and-dirty
heuristics and not the laws DEMO probability (Kahneman, Slovic, &
Tversky, 1982). This second DEMO appears diametrically
opposed to the classical rationality of the Enlightenment, but
DEMO appearance is misleading. It has retained the normative
kernel of the classical view. For example, a discrepancy between
the dictates of classical rationality and actual reasoning is what
defines a reasoning error in this program. Both DEMO accept the
laws of probability and statistics as normative, but they DEMO
about whether humans can stand up to these norms.
Many experiments have been conducted to test the validity of
these two views, identifying a host of conditions under which
the human mind appears more rational or DEMO But most
of this work has dealt with simple situations, such DEMO Bayesian
inference with binary hypotheses, one single piece of binary
data, and all the necessary information conveniently laid out
for the participant (Gigerenzer & Hoffrage, 1995). In many
real-world situations, however, there are multiple pieces of in-
formation, which are not independent, but redundant. DEMO,
Bayes's theorem and other "rational" algorithms quickly be-
come mathematically complex and computationally intracta-
ble, at least for ordinary human minds. These situations make
neither of the two views look promising. If one DEMO apply the
classical view to such complex real-world environments, this
REASONING THE FAST AND FRUGAL WAY
651
would suggest that the mind DEMO a supercalculator like a Lapla-
cean Demon (Wimsatt, 1976 )---carrying DEMO the collected
works of Kolmogoroff, Fisher, or Neyman--and simply needs a
memory jog, like the slave in Plato's Meno. On the other hand,
the heuristics-and-biases view of human irrationality would
lead us to DEMO that humans are hopelessly lost in the face of
real-world complexity, DEMO their supposed inability to reason
according to the canon of classical rationality, even in simple
laboratory experiments.
There is a third way to look at inference, focusing on the psy-
chological and ecological rather than on logic and probability
theory. This view questions classical rationality as a universal
DEMO and thereby questions the very definition of "good" rea-
soning on which both the Enlightenment and the heuristics-
and-biases views were built. Herbert DEMO, possibly the best-
known proponent of this third view, proposed looking for
models of bounded rationality instead of classical rationality.
Simon (1956, DEMO) argued that information-processing sys-
tems typically need to satisfice rather than DEMO Satisficing,
a blend of sufficing and satisfying, is a word DEMO Scottish origin,
which Simon uses to characterize algorithms that successfully
deal with conditions of limited time, knowledge, or computa-
tional capacities. His DEMO of satisficing postulates, for in-
stance, that an organism would choose the first object (a mate,
perhaps) that satisfies its aspiration DEMO of the intrac-
table sequence of taking the time to survey all possible alterna-
tives, estimating probabilities and utilities for the possible out-
comes associated with each alternative, calculating expected
utilities, and choosing the alternative DEMO scores highest.
Let us stress that Simon's notion of bounded rationality has
two sides, one cognitive and one ecological. As early as in Ad-
ministrative Behavior ( 1945 ), he emphasized the cognitive lim-
itations of real minds as opposed to the omniscient Laplacean
Demons of classical DEMO As early as in his Psychological
Review article titled "Rational Choice DEMO the Structure of the
Environment" (1956), Simon emphasized that minds are
adapted to real-world environments. The two go in tandem:
"Human rational behavior is shaped by a scissors whose two
blades are the DEMO of task environments and the computa-
tional capabilities of the actor" (Simon, 1990, p. 7). For the
most part, however, DEMO of human inference have focused
exclusively on the cognitive side, equating DEMO notion of
bounded rationality with the statement that humans are limited
information processors, period. In a Procrustean-bed fashion,
bounded rationality became almost synonymous with heuris-
tics and biases, thus paradoxically reassuring classical rational-
ity as the normative standard for both biases and bounded ra-
tionality (for a discussion of this confusion see Lopes, 1992).
Simon's insight that the minds of living systems should be un-
derstood relative to the DEMO in which they evolved,
rather than to the tenets of classical rationality, has had little
impact so far in research on human inference. Simple psycho-
logical algorithms that were observed in human inference, rea-
soning, or decision making were often discredited without a fair
trial, because DEMO looked so stupid by the norms of classical
rationality. For instance, DEMO Keeney and Raiffa (1993) dis-
cussed the lexicographic ordering procedure they had observed
in practice--a procedure related to the class of satisficing algo-
DEMO we propose in this article--they concluded that this pro-
cedure "is DEMO simple" and "will rarely pass a test of
'reasonableness' "(p. 78 ). They did not report such a test. We
shall.
Initially, the concept of bounded rationality was only vaguely
defined, often DEMO that which is not classical economics, and one
could "fit a lot of things into it by foresight and hindsight," as
Simon ( 1992, p. 18) himself put it. We wish to do more than
oppose the Laplacean Demon view. We strive to come up with
DEMO positive that could replace this unrealistic view of
mind. What are these simple, intelligent algorithms capable of
making near-optimal inferences? How fast and DEMO accurate are
they? In this article, we propose a class of models that exhibit
bounded rationality in both of Simon's senses. These DEMO
algorithms operate with simple psychological principles that
satisfy the constraints of limited time, knowledge, and compu-
tational might, rather than those of classical rationality. At the
same time, they are designe d to be fast and frugal without a
significant loss of inferential accuracy, because the algorithms
can exploit the structure of environments.
The article is organized as follows. DEMO begin by describing the
task the cognitive algorithms are designed to address, the basic
algorithm itself, and the real-world environment on which the
DEMO of the algorithm will be tested. Next, we report on
a DEMO in which a satisficing algorithm competes with
"rational" algorithms in making inferences about a real-world
environment. The "rational" algorithms start with an DEMO
tage: They use more time, information, and computational
might to DEMO inferences. Finally, we study variants of the sati-
sficing algorithm that DEMO faster inferences and get by with
even less knowledge.
The Task
We deal with inferential tasks in which a choice must be made
between DEMO alternatives on a quantitative dimension. Consider
the following example:
Which city has a larger population? (a) Hamburg (b) Cologne.
Two-alternative-choice tasks occur in various contexts in which
inferences need to be made with DEMO time and knowledge,
such as in decision making and risk assessment during driving
(e.g., exit the highway now or stay on ); treatment-allocation de-
cisions (e.g., who to treat first in the emergency DEMO: the 80-
year-old heart attack victim or the 16-year-old car accident
DEMO); and financial decisions (e.g., whether to buy or sell in
the trading pit). Inference concerning population demograph-
ics, such as city populations of the past, present, and future
(e.g., Brown & DEMO, 1993), is of importance to people work-
ing in urban DEMO, industrial development, and marketing.
Population demographics, which is better understood DEMO, say,
the stock market, will serve us later as a "drosophila" environ-
ment that allows us to analyze the behavior of DEMO
algorithms.
We study two-alternative-choice tasks in situations where a
person has to make an inference based solely on knowledge re-
trieved from memory. We DEMO to this as inference from mem-
ory as opposed to inference from givens. Inference from mem-
ory involves search in declarative knowledge and has DEMO in-
vestigated in studies of, inter alia, confidence in general
knowledge (e.g., Juslin, 1994; Sniezek & Buckley, 1993); the
652
GIGERENZER AND GOLDSTEIN
effect of repetition on belief (e.g., Hertwig, Gigerenzer, &
Hoffrage, in press); hindsight bias (e.g., Fischhoff, 1977); quan-
titative estimates of area and population of nations (DEMO &
Siegler, 1993); and autobiographic memory of time
(Huttenlocher, Hedges, & Prohaska, 1988). Studies of infer-
ence from givens, on the other hand, involve making inferences
from information presented by an experimenter (e.g., Ham-
mond, Hursch, & Todd, 1964). In the tradition of Ebbinghaus's
nonsense syllables, attempts are often made here to prevent in-
dividual knowledge from impacting on the results by using
DEMO about hypothetical referents instead of actual ones.
For instance, in celebrated DEMO and decision-making
tasks, such as the "cab" problem and the "Linda" problem, all
the relevant information is provided by the experimenter, and
individual knowledge about cabs and hit-and-run accidents, or
feminist bank tellers, is considered of no relevance (Gigerenzer
& Murray, 1987). As a consequence, limited knowledge or in-
dividual differences in knowledge play a small role in inference
from givens. In contrast, the satisflcing algorithms proposed in
this article perform inference from memory, they use limited
knowledge as input, and as we will show, they can actually profit
from DEMO lack of knowledge.
Assume that a person does not know or cannot deduce the
answer to the Hamburg-Cologne question but needs to make
an DEMO inference from related real-world knowledge. How
is this inference derived? How DEMO we predict choice (Hamburg
or Cologne) from a person's state of knowledge?
Figure 1. Illustration of bounded search through limited knowledge.
DEMO a, b, and c are recognized; object dis not. Cue DEMO are posi-
tive (+) or negative (-); missing knowledge DEMO shown by question
marks. Cues are ordered according to their validities. To infer whether
a > b, the Take The Best algorithm looks up only the cue values in the
shaded space; to infer whether b > c, search is bounded to the dotted
space. The other cue values are not looked up.
to search for all relevant information, to compute the weights
and covariances, and then to integrate all this information into
an inference.
Limited Knowledge
Theory
A PMM is an inductive device DEMO uses limited knowledge to
make fast inferences. Different from mental models of syllo-
gisms and deductive inference (Johnson-Laird, 1983), which
focus on DEMO logical task of truth preservation and where knowl-
edge is irrelevant (DEMO for the meaning of connectives and
other logical terms), PMMs perform intelligent guesses about
unknown features of the world, based on uncertain indicators.
To make an inference about which of two objects, a or b, has a
higher value, knowledge about a reference class R is DEMO,
with a, b E R. In our example, knowledge about the reference
class "cities in Germany" could be searched. The knowledge
DEMO of probability cues Ci (i = 1,..., n), and the cue values
ai and bi of the objects for the ith DEMO For instance, when mak-
ing inferences about populations of German cities, the fact that
a city has a professional soccer team in the DEMO league
(Bundesliga) may come to a person's mind as a potential cue.
That is, when considering pairs of German cities, if DEMO city has
a soccer team in the major league and the other does not, then
the city with the team is likely, but DEMO certain, to have the larger
population.
Limited knowledge means that the DEMO of objects by cues
has missing entries (i.e., objects, cues, or cue values may be
unknown). Figure 1 models the limited DEMO of a person.
She has heard of three German cities, a, b, and c, but not of
d (represented by three positive and one negative recognition
values). She knows some facts (cue values) about these cities
with respect to five binary cues. For a binary cue, there are two
cue values, positive (e.g., the city DEMO a soccer team) or negative
(it does not). Positive refers to a cue value that signals a higher
value on the target DEMO (e.g., having a soccer team is corre-
lated with high population). Unknown cue values are shown by
a question mark. Because she DEMO never heard of d, all cue val-
ues for object d DEMO, by definition, unknown.
People rarely know all information on which an inference
The cognitive algorithms we propose are realizations of a
framework for DEMO inferences from memory, the theory
of probabilistic mental models (PMM theory; see Gigerenzer,
1993; Gigerenzer, Hoffrage, & Kleinb61ting, 1991 )DEMO The theory
of probabilistic mental models assumes that inferences about
unknown states of the world are based on probability cues
(Brunswik, 1955). DEMO theory relates three visions: (a) Induc-
tive inference needs to DEMO studied with respect to natural envi-
ronments, as emphasized by Brunswik DEMO Simon; (b) induc-
tive inference is carried out by satisficing DEMO, as empha-
sized by Simon; and (c) inductive inferences are based on
frequencies of events in a reference class, as proposed by Rei-
chenbach and other frequentist statisticians. The theory of
probabilistic mental models DEMO for choice and confi-
dence, but only choice is addressed in DEMO article.
The major thrust of the theory is that it replaces the canon of
classical rationality with simple, plausible psychological mech-
anisms of inference--mechanisms that a mind can actually
carry out under limited time and knowledge DEMO that could have
possibly arisen through evolution. Most traditional models of
inference, from linear multiple regression models to Bayesian
models to neural networks, DEMO to find some optimal integration
of all information available: Every bit DEMO information is taken
into account, weighted, and combined in a computationally ex-
pensive way. The family of algorithms in PMM theory does not
DEMO this classical ideal. Search in memory for relevant
information is reduced to a minimum, and there is no integra-
tion (but rather a DEMO) of pieces of information. These
satisficing algorithms dispense with the fiction DEMO the omni-
scient Laplacean Demon, who has all the time and DEMO
REASONING THE FAST AND FRUGAL WAY
653
could be based, that is, knowledge is limited. We model limited
knowledge in two respects: A DEMO can have (a) incomplete
knowledge of the objects in the reference class (e.g., she recog-
nizes only some of the cities ), (b) limited knowledge of the cue
values (facts about cities), or (c) both. For instance, a person
who does not know all of the cities with soccer teams may know
some cities with DEMO cue values (e.g., Munich and Hamburg
certainly have teams), many with negative cue values ( e.g., Hei-
delberg and Potsdam certainly do not have teams), and several
cities for which cue values will DEMO be known.
The Take The Best Algorithm
The first satisficing algorithm presented is called the Take
The Best algorithm, because its policy is "DEMO the best, ignore
the rest" It is the basic algorithm in the PMM framework. Vari-
ants that work faster or with less knowledge DEMO described later.
We explain the steps of the Take The Best algorithm for binary
cues (the algorithm can be easily generalized to many valued
cues), using Figure 1 for illustration.
The Take The Best algorithm DEMO a subjective rank order
of cues according to their validities (as DEMO Figure 1 ). We call the
highest ranking cue (that discriminates between the two
alternatives) the best cue. The algorithm is shown in the form
of a flow diagram in Figure 2.
Step 1: Recognition Principle
The recognition principle is invoked when the mere recogni-
tion of DEMO object is a predictor of the target variable (e.g.,
population)DEMO The recognition principle states the following: If
only one of the DEMO objects is recognized, then choose the rec-
ognized object. If neither DEMO the two objects is recognized, then
choose randomly between them. If DEMO of the objects are rec-
ognized, then proceed to Step 2.
DEMO: Ifa person in the knowledge state shown in Figure
Start
I DEMO the
best cue I
+
No ~Yes
Choose the ]
I alternative [
to whicht he
cue points J
I
Figure 2.
Flow
diagram
DEMO
the Take
The Best
algorithm.
Figure 3.
ternatives
four discriminating
Discriminationr ule. A cue discriminatesb etween
if one has a positive cue value and DEMO other does not. The
cases are shaded.
two al-
1 is asked to infer which of city a and city d has more inhabi-
DEMO, the inference will be city a, because the person has never
heard of city d before.
Step 2: Search for Cue Values
For the two objects, retrieve the cue values of the highest
ranking cue from memory.
Step 3." Discrimination Rule
Decide whether the cue discriminates. The cue is said to dis-
criminate between two objects if one has DEMO positive cue value
and the other does not. The four shaded knowledge states in
Figure 3 are those in which a cue discriminates.
Step DEMO: Cue-Substitution Principle
If the cue discriminates, then stop searching for cue values. If
the cue does not discriminate, go back to Step 2 and continue
with the next cue until a cue that discriminates is DEMO
Step 5: Maximizing Rule
for Choice
Choose the object with the DEMO cue value. If no cue dis-
criminates, then choose randomly.
Examples: Suppose the task is judging which of city a or b is
DEMO (Figure 1). Both cities are recognized (Step 1 ), DEMO
search for the best cue results with a positive and a negative cue
value for Cue 1 (Step 2). The cue discriminates (DEMO 3), and
search is terminated (Step 4). The person DEMO the inference
that city a is larger (Step 5 ).
Suppose now the task is judging which of city b or e is DEMO
Both cities are recognized (Step 1 ), and search for the cue val-
ues cue results in negative cue value on object b DEMO Cue 1, but
the corresponding cue value for object e is DEMO (Step 2).
The cue does not discriminate (Step 3 ), so search is continued
(Step 4). Search for the next DEMO results with positive and a
negative cue values for Cue 2 (DEMO 2). This cue discriminates
(Step 3), and search is DEMO (Step 4). The person makes
the inference that city b DEMO larger (Step 5 ).
The features of this algorithm are (DEMO) search extends through
only a portion of the total knowledge in DEMO (as shown by
the shaded and dotted parts of Figure 1 ) and is stopped imme-
654
GIGERENZER AND GOLDSTEIN
diately when the first discriminating cue is found, (b) the algo-
rithm does not attempt to integrate information but DEMO cue
substitution instead, and (c) the total amount of information
DEMO is contingent on each task (pair of objects) and varies
in a predictable way among individuals with different knowl-
edge. This fast and DEMO simple algorithm is a model
of bounded rationality rather than of classical rationality. There
is a close parallel with Simon's concept of "satisficing": The
Take The Best algorithm stops search after the first discriminat-
DEMO cue is found, just as Simon's satisficing algorithm stops
search DEMO the first option that meets an aspiration level.
The algorithm is hardly a standard statistical tool for induc-
tive inference: It does not use all available information, it is non-
compensatory and nonlinear, and variants DEMO it can violate tran-
sitivity. Thus, it differs from standard linear DEMO for inference
such as multiple regression, as well as from nonlinear DEMO
networks that are compensatory in nature. The Take The Best
algorithm is noncompensatory because only the best discrimi-
nating cue determines the inference or DEMO; no combina-
tion of other cue values can override this decision. DEMO this way,
the algorithm does not conform to the classical economic view
of human behavior (e.g., Becker, 1976), where, under DEMO as-
sumption that all aspects can be reduced to one dimension (DEMO,
money), there exists always a trade-offbetween commodities or
pieces of information. That is, the algorithm violates the Archi-
median axiom, which DEMO that for any multidimensional
object a (aj, a2 ..... a~) DEMO to b (bl, b2 ..... b~), where
al dominates b~, this preference can be reversed by taking
multiples of any one or a combination of b2, b3 ..... bn. As we
discuss, variants DEMO this algorithm also violate transitivity, one
of the cornerstones of classical DEMO (McClennen, 1990).
taught information that suggested doing otherwise (negative
DEMO values for the recognized objects). Among the evidence for
the empirical validity of the Take-The-Best algorithm are the
tests of a bold prediction, the less-is-more effect, which postu-
lates conditions under which people with little knowledge make
better inferences than those who know more. This surprising
prediction DEMO been experimentally confirmed. For instance,
U.S. students make slightly more correct inferences about Ger-
man city populations ( about which they know little) than about
U.S. cities, and vice versa for German students (Gigerenzer,DEMO
1993; Goldstein 1994; Goldstein & Gigerenzer, 1995; Hoffrage,
1994). The theory of probabilistic mental models has been ap-
plied to DEMO situations in which inferences have to be made
under limited time and knowledge, such as rumor-based stock
market trading (DiFonzo, 1994). A general review of the theory
and its evidence is presented in McClelland DEMO Bolger (1994).
The reader familiar with the original algorithm presented DEMO
Gigerenzer et al. ( 1991 ) will have noticed that we simplified the
discrimination rule.~ In the present version, search is already
terminated if one object has a positive cue value and the other
does not, whereas in the earlier version, search was terminated
only when one object had a positive value and the other a nega-
tive one (cf. Figure 3 in Gigerenzer et al. with Figure 3 in this
article)DEMO This change follows empirical evidence that partici-
pants tend to use this faster, simpler discrimination rule
(Hoffrage, 1994).
This article does not attempt to provide further empirical ev-
idence. For the moment, we assume that the model is descrip-
tively valid and investigate how accurate this DEMO algo-
rithm is in drawing inferences about unknown aspects of a
real-world environment. Can an algorithm based on simple
psychological principles that violate the DEMO of classical ra-
tionality make a fair number of accurate inferences?
Empirical Evidence
Despite their flagrant violation of the traditional standards of
rationality, the Take The Best algorithm and other models from
the framework of DEMO theory have been successful in integrat-
ing various striking phenomena in inference from memory and
predicting novel phenomena, such as the confidence-frequency
effect (DEMO et al., 1991) and the less-is-more effect
(Goldstein, 1994; DEMO & Gigerenzer, 1996). The theory
of probabilistic mental models seems DEMO be the only existing
process theory of the overconfidence bias that successfully pre-
dicts conditions under which overestimation occurs, disappears,
and inverts to underestimation (Gigerenzer, 1993; Gigerenzer
et al., 1991; Juslin, 1993, 1994; Juslin, Winman, & Persson,
t995; but see Griffin & Tversk); 1992). Similarly, the theory
predicts when the hard-easy DEMO occurs, disappears, and in-
vertswpredictions that have been experimentally confirmed by
Hoffrage (1994) and by Juslin ( 1993 ). The Take The Best algo-
rithm explains also why the popular confirmation-bias expla-
nation of DEMO overconfidence bias (Koriat, Lichtenstein, &
Fischhoff, 1980) is not supported by experimental data
(Gigerenzer et al., 1991, pp. 521-522 )DEMO
Unlike earlier accounts of these striking phenomena in con-
fidence and choice, the algorithms in the PMM framework al-
low for predictions of choice based on each individual's knowl-
edge. Goldstein and Gigerenzer (1996) DEMO that the recog-
nition principle predicted individual participants" choices in
about DEMO to 100% of all cases, even when participants were
The Environment
DEMO tested the performance of the Take The Best algorithm on
how accurately it made inferences about a real-world environ-
ment. The environment was the DEMO of all cities in Germany
with more than 100,000 inhabitants (DEMO cities after German
reunification), with population as the target variable. The
model of the environment consisted of 9 binary ecological cues
and the DEMO 9 × 83 cue values. The full model of the environ-
ment is shown in the Appendix.
Each cue has an associated validity, which is indicative of its
predictive power. The ecological validity of a cue DEMO the relative
frequency with which the cue correctly predicts the target, DEMO
fined with respect to the reference class (e.g., all German cities
with more than 100,000 inhabitants). For instance, if one
checks all pairs in which one city has a soccer team but the DEMO
city does not, one finds that in 87% of these cases, the city with
the team also has the higher population. This value DEMO the eco-
logical validity of the soccer team cue. The validity vi of the ith
cue is
v, = p[ t (a) > t (b) l
ai is positive and b~ is negative
],DEMO
Also, we now use the term discrimination rule instead of activation
DEMO
REASONING THE FAST AND FRUGAL WAY
655
Table 1
Cues, Ecological Validities,
and Discrimination Rates
edge, time, and computational power. This question DEMO impor-
tant for Simon's postulated link between the cognitive and the
ecological: If the simple psychological principles in satisficing
algorithms are tuned to ecological structures, these algorithms
should not fail outright. We propose a competition between var-
ious inferential algorithms. The contest will go to the algorithm
DEMO scores the highest proportion of correct inferences in the
shortest time.
Cue
Ecological
validity
Discrimination
rate
National capital (Is the city the
national capital?)
Exposition site (Was the city once an
exposition site?)
Soccer team (Does the city have a team
in the major league?)
Intercity train (Is the city on the
Intercity line?)
State capital (Is the city a state capital?)
License plate (Is the abbreviation only
one letter long?)
University (Is the DEMO home to a
university?)
Industrial belt (Is the city in the
industrial belt?)
East Germany (Was the city formerly
in DEMO Germany?)
1.00
.91
.87
.78
.77
.75
.71
.56.
.51
DEMO
.25
.30
.38
.30
.34
.51
.30
.27
Simulating Limited Knowledge
where t(a) and t(b) are the values of objects a DEMO b on the
target variable t and p is a probability measured as a relative
frequency in R.
The ecological validity of the nine DEMO ranged over the whole
spectrum: from .51 (only slightly better than chance) to 1.0
(certainty), as shown in Table 1. A DEMO with a high ecological
validity, however, is not often useful if its discrimination rate is
small.
Table i shows also the discrimination rates DEMO each cue. The
discrimination rate of a cue is the relative frequency with which
the cue discriminates between any two objects from the refer-
DEMO class. The discrimination rate is a function of the distribu-
tion of the cue values and the number N of objects in the refer-
DEMO class. Let the relative frequencies of the positive and nega-
tive cue values be x and y, respectively. Then the discrimination
rate d~ of the ith cue is
We simulated people with varying degrees of knowledge
DEMO cities in Germany. Limited knowledge can take two
forms. One is limited recognition of objects in the reference
class. The other is limited knowledge DEMO the cue values of
recognized objects. To model limited recognition knowledge,
we simulated people who recognized between 0 and 83 German
cities. To DEMO limited knowledge of cue values, we simulated
6 basic classes of DEMO, who knew 0%, 10%, 20%, 50%, 75%,
or DEMO of the cue values associated with the objects they rec-
ognized. Combining the two sources of limited knowledge re-
sulted in 6 x 84 DEMO of people, each having different degrees
and kinds of limited knowledge. DEMO each type of people, we
created 500 simulated individuals, who differed randomly from
one another in the particular objects and cue values they DEMO
All objects and cue values known were determined randomly
within the appropriate constraints, that is, a certain number of
objects known, a certain total percentage of cue values known,
and the validity of the DEMO principle (as explained in the
following paragraph).
The simulation needed DEMO be realistic in the sense that the
simulated people could invoke the recognition principle. There-
fore, the sets of cities the simulated people knew had to be care-
fully chosen so that the recognized cities were DEMO than the
unrecognized ones a certain percentage of the time. We per-
formed a survey to get an empirical estimate of the actual co-
DEMO
2xiyi
1'
1 ---- N
2 For instance, if N DEMO 2 and one cue value is positive and the other
negative (DEMO = Yr = .5), dr = 1.0. If Nincreases, with DEMO and Yi held
constant, then dr decreases and converges to 2xr DEMO
3 There are various other measures of redundancy besides pairwise
correlation. The important point is that whatever measure of redun-
dancy one uses, the resultant value does not have the same meaning
for all algorithms. For DEMO, all that counts for the Take The Best
algorithm is what DEMO of correct inferences the second cue adds
to the first in the cases where the first cue does not discriminate, how
much the third cue adds to the first two in the cases where they do DEMO
discriminate, and so on. If a cue discriminates, search is terminated,
and the degree of redundancy in the cues that were not DEMO in
the search is irrelevant. Integration algorithms, in contrast, integrate all
information and, thus, always work with the total redundancy in the
DEMO (or knowledge base). For instance, when deciding among
objects a, b, c, and din Figure 1, the cue values of DEMO 3, 4, and 5 do
not matter from the point of view of the Take The Best algorithm
(because search is terminated before reaching Cue 3). However, the
values of Cues 3, 4, and 5 affect the redundancy of the ecological system,
from the DEMO of view of all integration algorithms. The lesson is that
the degree of redundancy in an environment depends on the kind of
algorithm that DEMO on the environment. One needs to be cautious
in interpreting measures of redundancy without reference to an
algorithm.
as an elementary calculation shows. Thus, if N is very large,
the discrimination rate is approximately 2xiyi DEMO The larger the
ecological validity of a cue, the better the DEMO The larger
the discrimination rate, the more often a cue can DEMO used to
make an inference. In the present environment, ecological va-
DEMO and discrimination rates are negatively correlated. The
redundancy of cues in the environment, as measured by pair-
wise correlations between cues, ranges between DEMO and .54,
with an average absolute value of. 19. 3
The Competition
The question of how well a satisficing algorithm performs in
a DEMO environment has rarely been posed in research on
inductive inference. The present simulations seem to be the first
to test how well simple satisficing DEMO do compared with
standard integration algorithms, which require more knowl-
656
G1GERENZER AND GOLDSTEIN
variation between recognition of cities and city populations. DEMO
us define the validity c~ of the recognition principle to be the
probability; in a reference class, that one object has a greater
DEMO on the target variable than another, in the cases where the
DEMO object is recognized and the other is not:
a = p[ t
(a) > t
(b) t
a, is positive and b, is negative
],
where t(a) and t(b) are the values of objects a and b on the
target variable DEMO, a, and br are the recognition values of a and b,
and p is a probability measured as a relative frequency in DEMO
In a pilot study of 26 undergraduates at the University of Chi-
cago, we found that the cities they recognized (within the 83
DEMO in Germany) were larger than the cities they did not rec-
DEMO in about 80% of all possible comparisons. We incorpo-
rated this value into our simulations by choosing sets of cities
(for each knowledge state, i.e., for each number of cities
recognized) where the known cities were larger than the un-
known cities in about 80% of all DEMO Thus, the cities known
by the simulated individuals had the same DEMO between
recognition and population as did those of the human individu-
als. Let us first look at the performance of the Take The Best
DEMO
Testing the Take The Best Algorithm ~
We tested how well individuals using the Take The Best algo-
rithm did at answering real-world questions DEMO as, Which city
has more inhabitants: (a) Heidelberg or (DEMO) Bonn? Each of the
500 simulated individuals in each of the 6 X 84 types was tested
on the exhaustive set of 3,DEMO city pairs, resulting in a total of
500 x 6 X DEMO x 3,403 tests, that is, about 858 million.
The curves in Figure 4 show the average proportion of correct
inferences for each DEMO of objects and cue values known.
The x axis represents the number of cities recognized, and the y
axis shows the proportion of correct inferences that the Take
The Best algorithm drew. Each of the 6 DEMO 84 points that make
up the six curves is an average proportion of correct inferences
taken from 500 simulated individuals, who each made 3,403
inferences.
When the proportion of cities recognized was zero, the pro-
portion of correct inferences was at chance level (.5). When up
to half of all cities were recognized, performance increased at
all levels of knowledge about cue values. The maximum per-
centage of correct inferences DEMO around 77%. The striking re-
sult was that this maximum was not achieved when individuals
knew all cue values of all cities, but rather when they knew less.
This result shows the ability of the algorithm DEMO exploit limited
knowledge, that is, to do best when not everything is known.
Thus, the Take The Best algorithm produces the less-is-more
effect. At any level of limited knowledge of cue values, learning
more German cities will eventually cause a decrease in propor-
tion correct. Take, for instance, the curve where 75% of the cue
values were known and the point where the simulated partici-
pants recognized about 60 German cities. DEMO these individuals
learned about the remaining German cities, their proportion
correct DEMO decrease. The rationale behind the less-is-more
effect is the recognition principle, DEMO it can be understood best
from the curve that reflects 0% of total cue values known. Here,
all decisions are made on the DEMO of the recognition principle,
.8 f
f
7 L
///DEMO
.8
Lt/
/
'
0
10
20 30 40 50 60
Number of Objects Recognized
70
80
Figure 4. Correct inferences about DEMO population of German cities
(two-alternative-choice tasks) by the Take The Best algorithm. Infer-
ences are based on actual information about the 83 largest DEMO and
nine cues for population (see the Appendix). Limited knowledge DEMO the
simulated individuals is varied across two dimensions: (a) the DEMO
of cities recognized (x axis ) and (b) the percentage DEMO cue values known
(the six curves).
f
\0;
or DEMO guessing. On this curve, the recognition principle comes
into play most DEMO half of the cities are known, so it takes
on an DEMO shape. When half the cities are known, the
recognition principle can DEMO activated most often, that is, for
roughly 50% of the questions. Because we set the recognition
validity in advance, 80% of these inferences will be correct. In
the remaining half of the questions, when recognition cannot
be used (either both cities are recognized or both cities are
unrecognized), then the organism is forced to guess and only
50% DEMO the guesses will be correct. Using the 80% effective rec-
ognition validity half of the time and guessing the other half of
the time, the organism scores 65% correct, which is the peak of
the bottom curve. The mode of this curve moves to the right
with increasing DEMO about cue values. Note that even
when a person knows everything, DEMO cue values of all cities,
there are states of limited knowledge in which the person would
make more accurate inferences. We are not DEMO to discuss
the conditions of this counterintuitive effect and the supporting
experimental evidence here (see Goldstein & Gigerenzer,
1996). Our focus is on how much better integration algorithms
can do in making inferences.
Integration DEMO
We asked several colleagues in the fields of statistics and eco-
nomics to devise decision algorithms that would do better than
the Take The DEMO algorithm. The five integration algorithms
we simulated and pitted against the Take The Best algorithm in
a competition were among those suggested by our DEMO
REASONING THE FAST AND FRUGAL WAY
657
These competitors include "proper" DEMO "improper" linear
models (Dawes, 1979; Lovie & Lovie, 1986). These algorithms,
in contrast to the Take The Best algorithm, embody two classi-
cal principles of rational inference: (a) complete search--they
use all available information (cue values )--and (b) complete
integration--they DEMO all these pieces of information into
a single value. In short, DEMO refer in this article to algorithms
that satisfy these principles as "DEMO" (in quotation marks)
algorithms.
If Z aivi > ~, DEMO, then choose city a.
i=1
i=1
If ~ aivi <
bivi, then choose city b.
i=1
i=1
If ~ aivi =
i=1
i=1
bivi, then guess.
Contestant 1: Tallying
Note that weighted tallying needs DEMO information than either
tallying or the Take The Best algorithm, namely, quantitative
information about ecological validities. In the simulation, we
provided the real ecological validities to give this algorithm a
good chance.
Calling again on DEMO comparison of objects a and b from Fig-
ure 1, let DEMO assume that the validities would be .8 for recogni-
tion and .9, .8, .7, .6, .51 for Cues 1 through 5. Weighted DEMO
would thus assign 1.7 points to a and 2.3 points to b. Thus,
weighted tallying would also choose b to be the larger.
DEMO tallying algorithms treat negative information and miss-
ing information identically. That is, they consider only positive
evidence. The following algorithms distinguish between nega-
tive and missing information and integrate both positive and
negative in formation.
Let DEMO start with a simple integration algorithm: tallying of
positive evidence (Goldstein, 1994). In this algorithm, the
number of positive cue values DEMO each object is tallied across all
cues (i = 1,..., n), and the object with the largest number
of positive cue DEMO is chosen. Integration algorithms are not
based (at least explicitly) on the recognition principle. For this
reason, and to make the integration algorithms as strong as pos-
sible, we allow all the integration algorithms to make use of rec-
ognition information (the positive and negative recognition val-
ues, see Figure 1 ). Integration algorithms treat recognition as
a DEMO, like the nine ecological cues in Table 1. That is, in the
competition, the number of cues (n) is thus equal to 10
(because recognition is included). The decision criterion for
tallying is the following:
Contestant 3. Unit- Weight Linear Model
If ~ a~ >
b~, then choose city a.
The unit-weight linear model is a special case of the equal-
weight linear model (Huber, 1989) and has been advocated as a
good approximation of weighted linear models (Dawes, 1979;
Einhorn & Hogarth, 1975). The decision criterion for DEMO
weight integration is the same as for tallying, only the assign-
DEMO ofa~ and bi differs:
i=1
i=1
n
n
If ~ ai < ~, bi, then choose city b.
i=1
iffil
If ~ DEMO =
bi, then guess.
1 if
the ith cue value is DEMO
i=l
i=l
ai, b~ =
-1 if the ith cue value DEMO negative
The assignments of ai and b~ are the following:
0 if the ith cue value is unknown.
1 if the ith cue DEMO is positive
Comparing objects a and b from Figure 1 would involve as-
signing 1.0 points to a and 1.0 points to b and, thus, choosing
randomly. This simple linear model corresponds to Model 2 in
Einhorn and Hogarth ( 1975, p. 177 ) with the weight parameter
set equal to 1.
a~, b~ =
0 if the ith cue value is negative
0 if the ith cue value is unknown.
Let DEMO compare cities a and b, from Figure 1. By tallying the
DEMO cue values, a would score 2 points and b would score DEMO
Thus, tallying would choose b to be the larger, in opposition to
the Take The Best algorithm, which would infer that a is larger.
Variants of tallying, such as the frequency-of-good-features
heuristic, have been DEMO in the decision literature (Alba &
Marmorstein, 1987; Payne, DEMO, & Johnson, 1993).
Contestant 4: Weighted Linear Model
Contestant DEMO Weighted Tallying
This model is like the unit-weight linear model except that
the values ofai and bi are multiplied by their respective ecolog-
ical DEMO The decision criterion is the same as with
weighted tallying. The weighted linear model (or some variant
of it) is often viewed as DEMO optimal rule for preferential choice,
under the idealization of independent dimensions or cues (e.g.,
Keeney & Raiffa, 1993; Payne et al., 1993). Comparing objects
a and b from Figure 1 would involve assigning 1.0 points to a
and 0.8 points to b and, thus, choosing a to be the larger.
Tallying treats all cues alike, DEMO of cue validity.
Weighted tallying of positive evidence is identical with tallying,
except that it weights each cue according to its ecological valid-
DEMO, vt. The ecological validities of the cues appear in Table 1.
DEMO set the validity of the recognition cue to .8, which is DEMO
empirical average determined by the pilot study. The decision
rule is as follows:
Contestant 5: Multiple Regression
The weighted linear model reflects the different validities of
the cues, but not the dependencies between cues. Multiple re-
gression creates weights that reflect the covariances between
658
GIGERENZER AND GOLDSTEIN
predictors or cues and is commonly seen as DEMO "optimal" way
to integrate various pieces of information into an estimate (e.g.,
Brunswik, 1955; Hammond, 1966). Neural networks using DEMO
delta rule determine their "optimal" weights by the same prin-
ciples as multiple regression does (Stone, 1986). The delta rule
carries DEMO the equivalent of a multiple linear regression from
the input patterns to the targets.
The weights for the multiple regression could simply be cal-
DEMO from the full information about the nine. ecological
cues, as given DEMO the Appendix. To make multiple regression an
even stronger competitor, we DEMO provided information about
which cities the simulated individuals recognized. Thus, the
DEMO regression used nine ecological cues and the recogni-
tion cue to generate its weights. Because the weights for the rec-
ognition cue depend on DEMO cities are recognized, we calcu-
lated 6 × 500 × 84 DEMO of weights: one for each simulated indi-
vidual. Unlike any of DEMO other algorithms, regression had
access to the actual city populations (even for those cities not
recognized by the hypothetical person) in the calculation of the
weights. 4 During the quiz, each simulated person used the set of
weights provided to it by multiple regression to estimate the
DEMO of the cities in the comparison.
There was a missing-values problem in computing these 6 X
84 × 500 sets of regression coefficients, because most simulated
individuals did not know certain cue values, for instance, DEMO
cue values of the cities they did not recognize. We strengthened
the performance of multiple regression by substituting un-
known cue values with the DEMO of the cue values the person
knew for the given cue. 5 This was done both in creating the
weights and in using these DEMO to estimate populations. Un-
like traditional procedures where weights are estimated from
one half of the data, and inferences based on these weights are
made for the other half, the regression algorithm had access to
all the information in the Appendix (except, of course, the un-
known cue values)--more information than was given to any
of the competitors. DEMO the competition, multiple regression and,
to a lesser degree, the weighted linear model approximate the
ideal of the Laplacean Demon.
4 cue DEMO (that is, one fifth of all possible) are searched for.
DEMO average across all simulated participants was 5.9, which was
less than DEMO third of all available cue values.
Accuracy
Speed
Results
Given that it searches only for a limited amount of informa-
tion, how accurate is the Take The Best algorithm, compared
with the integration algorithms? We DEMO the competition for all
states of limited knowledge shown in Figure 4. We first report
the results of the competition in the case where DEMO algorithm
achieved its best performance: When 100% of the cue values
DEMO known. Figure 6 shows the results of the simulations, car-
ried DEMO in the same way as those in Figure 4.
To our surprise, the Take The Best algorithm drew as many
correct inferences as any of the other algorithms, and more than
some. The curves for Take The Best, multiple regression,
weighted tallying, and tallying are so DEMO that there are only
slight differences among them. Weighted tallying performed
about as well as tallying, and the unit-weight linear model per-
formed about as well as the weighted linear model--demon-
strating that the previous finding DEMO weights may be chosen in
a fairly arbitrary manner, as long DEMO they have the correct sign
( Dawes, 1979), is generalizable DEMO tallying. The two integration
algorithms that make use of both positive and negative infor-
mation, unit-weight and weighted linear models, made consid-
erably DEMO correct inferences. By looking at the lower-left and
upper-right corners of Figure 6, one can see that all competitors
do equally well with a complete lack of knowledge or with com-
plete knowledge. They differ when DEMO is limited. Note
that some algorithms can make more correct inferences when
they do not have complete knowledge: a demonstration of the
less-is-more effect mentioned earlier.
What was the result of the competition across all levels DEMO
limited knowledge? Table 2 shows the result for each level of
DEMO knowledge of cue values, averaged across all levels of
recognition knowledge. (Table 2 reports also the performance
of two variants of the Take DEMO Best algorithm, which we dis-
cuss later: the Minimalist and the Take The Last algorithm.)
The values in the 100% column of DEMO 2 are the values in
Figure 6 averaged across all levels of recognition. The Take The
Best algorithm made as many correct inferences as DEMO of the
competitors (weighted tallying) and more than the others. Be-
cause it was also the fastest, we judged the competition goes to
the Take The Best algorithm as the highest performing, overall.
To our knowledge, this is the first time that it has been dem-
onstrated that a satisficing algorithm, that is, the Take The Best
algorithm, can draw as many correct inferences about a real-
The Take The DEMO algorithm is designed to enable quick de-
cision making. Compared with the integration algorithms, how
much faster does it draw inferences, measured by DEMO amount
of information searched in memory? For instance, in Figure
1, the Take The Best algorithm would look up four cue values
(DEMO the recognition cue values) to infer that a is larger
than DEMO None of the integration algorithms use limited search;
thus, they DEMO look up all cue values.
Figure 5 shows the amount of cue values retrieved from
memory by the Take The Best algorithm for various DEMO of
limited knowledge. The Take The Best algorithm reduces
search in memory considerably. Depending on the knowledge
state, this algorithm needed to search for between 2 (the num-
ber of recognition values) and 20 (the maximum possible cue
values: Each city has nine cue values and one recognition
value). For instance, when a person recognized half of the cities
and knew 50% of their cue values, then, on average, only about
4
nor can we know a priori which small variations DEMO
bumpy real-world
this article we learned that regressing
slightly
what are the structures of
and variants thrive.
5
were substituted by .5. This value
DEMO 0 and 1, which are the values
cue values, respectively.
We
cannot
better than regressing
claim that these
succeed in our
environment. An DEMO:
on the ranks of the cities does
on the city populations. The key issue is
environments in
integration algorithms are the best
ones,DEMO
During
the proof stage
of
which particular algorithms
If
no single
cue value was known for a given
was chosen
used to stand for DEMO
because
cue, the missing
it is the midpoint
and positive
values
REASONING THE FAST AND FRUGAL WAY
.~ 20
O
o
"N 15
0%
• /.
/
10%
>
~
E
Z
<
>
10
ue
10
20 30 40 50 60
Number of Objects DEMO
70
80
Figure 5. Amount of cue values looked up by the Take The Best algorithm and by the competing integra-
tion algorithms (see text), depending on the number of objects known (0-83) and DEMO percentage of cue
values known.
.8 r
Take The Best
Weighted Tallying
Tallying x~
.8
c~
~O
¢.)
.75
.75
~.7
Regre~
.7
DEMO
O .65
.65
O
.55
.6
.
Weighted Linear Model
Unit-Weight Linear Model
20
30
40
50
60
.55
Number of Objects Recognized
~.6
DEMO
O
.5
0
10
70
80 .5
Figure6. Results of the competition. The curve for the Take The Best algorithm is identical with the DEMO
curve in Figure 4. The results for proportion correct have been smoothed by a running median smoother,
to lessen visual noise between the DEMO
659
660
GIGERENZER AND GOLDSTE1N
Table 2
Results of
of
Algorithm
Take The DEMO
Weighted tallying
Regression
Tallying
Weightedlinear model
Unit-weight linear model
Minimalist
Take The Last
10
.621
.621
.625
.620
.623
.621
.619
.619
Percentage
20
DEMO
.635
.635
.633
.627
.622
.631
.630
of
50
.663
.663
.657
.659
.623
.621
.650
.646
the Competition: Average Proportion
Correct Inferences
cue values
known
75
.678
.679
.674
.676
.619
.620
.661
.658
100
DEMO
.693
.694
.691
.625
.622
.674
.675
Average
.658
.658
.657
.656
.623
.621
.647
.645
Note. Values are rounded; averages are computed from the unrounded
values. Bottom two algorithms are variants of the Take The DEMO algo-
rithm.
world environment as integration algorithms, across all states
of DEMO knowledge. The dictates of classical rationality would
have led one to expect the integration algorithms to do substan-
tially better than the satisficing algorithm.
DEMO results of the simulation can be derived analytically. First
and most obvious is that if knowledge about objects is zero,
then all algorithms DEMO at a chance level. Second, and less
obvious, is that if all objects and cue values are known, then
tallying produces as many correct inferences as the unit-weight
linear model. This is because, under complete knowledge, the
score under the tallying algorithm is an increasing linear func-
tion of the score arrived at in the unit-weight linear model. 6
DEMO equivalence between tallying and unit-weight linear models
under complete knowledge is an important result. It is known
that unit-weight linear models can sometimes perform DEMO as
well as proper linear models (i.e., models with weights that are
chosen in an optimal way, such as in multiple regression; DEMO
Dawes, 1979). The equivalence implies that under complete
knowledge, merely counting pieces of positive evidence can
work as well as proper linear DEMO This result clarifies one
condition under which searching only for positive evidence, a
strategy that has sometimes been labeled confirmation bias or
positive test strategy, can be a reasonable and efficient inferen-
tial strategy (Klayman & Ha, 1987; Tweney & Walker, 1990).
Why do the DEMO and weighted linear models perform
markedly worse under limited knowledge of objects? The rea-
son is the simple and bold recognition principle. Algorithms
that do not exploit the recognition principle in environments
where recognition is strongly DEMO with the target variable
pay the price of a considerable number of wrong inferences. The
unit-weight and weighted linear models use recognition infor-
mation DEMO integrate it with all other information but do not
follow the recognition principle, that is, they sometimes choose
unrecognized cities over recognized ones. DEMO is this? In the
environment, there are more negative cue values than positive
ones (see the Appendix), and most cities have more negative
cue values than positive ones. From this it follows that when DEMO
recognized object is compared with an unrecognized object, the
(weighted) DEMO of cue values of the recognized object will often
be smaller than that of the unrecognized object (which is - 1 for
the unit-weight model and -.8 for the weighted linear model).
Here the unit-weight DEMO weighted linear models often make
the inference that the unrecognized object is the larger one, due
to the overwhelming negative evidence for the recognized ob-
ject. Such inferences contradict the recognition principle. Tal-
lying algorithms, in contrast, have the recognition principle
built in implicitly. Because tallying algorithms ignore negative
information, the tally for an unrecognized object is always 0
and, thus, is always smaller than the tally for a recognized ob-
DEMO, which is at least 1 (for tallying, or .8 for DEMO tallying,
due to the positive value on the recognition cue). Thus, tallying
algorithms always arrive at the inference that a recognized ob-
ject is larger than an unrecognized one.
Note that this explanation of DEMO different performances puts
the full weight in a psychological principle (the DEMO
principle) explicit in the Take The Best algorithm, as opposed
to the statistical issue of how to find optimal weights in a linear
DEMO To test this explanation, we reran the simulations for
the unit-weight DEMO weighted linear models under the same con-
ditions but replacing the recognition cue with the recognition
principle. The simulation showed that the recognition principle
DEMO for all the difference.
Can Satisficing Algorithms Get by With Even Less
Time and Knowledge?
The Take The Best algorithm produced a surprisingly DEMO
proportion of correct inferences, compared with more compu-
tationally expensive integration DEMO Making correct in-
ferences despite limited knowledge is an important adaptive
feature of an algorithm, but being right is not the only thing
that counts. In many situations, time is limited, and acting fast
can DEMO as important as being correct. For instance, if you are
driving DEMO an unfamiliar highway and you have to decide in an
instant what to do when the road forks, your problem is not
necessarily making the best choice, but simply making a quick
choice. Pressure to be quick is also characteristic for certain
types of verbal interactions, such as press conferences, in which
a fast answer indicates competence, or commercial DEMO,
such as having telephone service installed, where the customer
has DEMO decide in a few minutes which of a dozen calling features
to purchase. These situations entail the dual constraints of lim-
ited knowledge and DEMO time. The Take The Best algorithm
is already faster than any of the integration algorithms, because
it performs only a limited search and does not need to compute
weighted sums of cue values. Can it be DEMO even faster? It can,
if search is guided by the DEMO of cues in memory rather than
by cue validity.
The Take The Last Algorithm
The Take The Last algorithm first tries the cue that DEMO
nated the last time. If this cue does not discriminate, the DEMO
6 The proof for this is as follows. The tallying score t for a given object
is the number n ÷ of positive cue DEMO, as defined above. The score u
for the unit weight linear DEMO is n + - n-, where n- is the number of
DEMO cue values. Under complete knowledge, n = n + + n-, where n
is the number of cues. Thus, t = n + , and u = n + - n-. Because n- = n
DEMO 4, by substitution into the formula for u, we find that u = n + - ( n -
n +) = 2t - n.
-
REASONING THE FAST AND FRUGAL WAY
661
rithm then tries the cue DEMO discriminated the time before last,
and so on. The algorithm differs from the Take The Best algo-
rithm in Step 2, which is now reformulated as Step 2':
Step 2': Search for the Cue Values of the
Most Recent Cue
For the two objects, retrieve the cue values of the cue used
most recently. If it is DEMO first judgment and there is no discrim-
ination record available, retrieve DEMO cue values of a randomly
chosen cue.
Thus, in Step 4, the algorithm goes back to Step 2'. Variants
of this search DEMO have been studied as the "Einstellung
effect" in the water jar experiments (Luchins & Luchins,
1994), where the solution strategy of the most recently solved
problem is tried first on the subsequent problem. DEMO effect
has also been noted in physicians' generation of diagnoses for
DEMO cases (Weber, B6ckenholt, Hilton, & Wallace, 1993 ).
This algorithm does not need a rank order of cues according
to their DEMO; all that needs to be known is the direction
in which DEMO cue points. Knowledge about the rank order of cue
validities is replaced by a memory of which cues were last used.
Note that such DEMO record can be built up independently of any
knowledge about the structure of an environment and neither
needs, nor uses, any feedback about DEMO inferences are
right or wrong.
The Minimalist Algorithm
Can reasonably accurate inferences be achieved with even
less knowledge? What we call the Minimalist algorithm needs
neither information about the rank ordering of cue validities
nor the DEMO history of the cues. In its ignorance, the
algorithm picks cues DEMO a random order. The algorithm differs
from the Take The Best algorithm in Step 2, which is now re-
formulated as Step 2":DEMO
Step 2": Random Search
For the two objects, retrieve the DEMO values of a randomly
chosen cue.
The Minimalist algorithm does not necessarily speed up
search, but it tries to get by with even less knowledge than any
other algorithm.
Results
Speed
How fast are the fast DEMO? The simulations showed
that for each of the two variant algorithms, the relationship be-
tween amount of knowledge and the number of cue DEMO
looked up had the same form as for the Take The Best algorithm
(Figure 5). That is, unlike the integration algorithms, the
curves are concave and the number of cues searched for is max-
DEMO when knowledge of cue values is lowest. The average num-
ber of cue values looked up was lowest for the Take The Last
algorithm (5.29) followed by the Minimalist algorithm (5.64)
and the Take DEMO Best algorithm (5.91). As knowledge be-
comes more and more DEMO (on both dimensions: recogni-
tion and cue values known), the difference in speed becomes
smaller and smaller. The reason why the Minimalist DEMO
looks up fewer cue values than the Take The Best algorithm is
that cue validities and cue discrimination rates are negatively
correlated (Table 1 ); therefore, randomly chosen cues tend to
have larger discrimination rates DEMO cues chosen by cue
validity.
Accuracy
What is the price to be paid for speeding up search or reduc-
ing the knowledge of cue DEMO and discrimination histories
to nothing? We tested the performance of the DEMO algorithms on
the same environment as all other algorithms. Figure 7 shows
the proportion of correct inferences that the Minimalist algo-
rithm achieved. For DEMO, the performance of the Take
The Best algorithm with 100% of DEMO values known is indicated
by a dotted line. Note that the Minimalist algorithm performed
surprisingly well. The maximum difference appeared when
knowledge was complete DEMO all cities were recognized. In these
circumstances, the Minimalist algorithm did DEMO 4 percent-
age points worse than the Take The Best algorithm. On average,
the proportion of correct inferences was only 1.1 percentage
points DEMO than the best algorithms in the competition (Ta-
ble 2).
DEMO performance of the Take The Last algorithm is similar to
Figure 7, and the average number of correct inferences is shown
in Table 2. The Take The Last algorithm was faster but scored
slightly less than DEMO Minimalist algorithm. The Take The Last
algorithm has an interesting ability, DEMO fooled us in an earlier
series of tests, where we used DEMO systematic (as opposed to a ran-
dom) method for presenting the test pairs, starting with the
largest city and pairing it with all others, and so on. An integra-
tion algorithm such as multiple regression cannot "find out"
that it is being tested in this systematic way, and its inferences
are accordingly independent of the sequence of presentation.
However, the Take The Last algorithm found out and won this
first round of the competition, outperforming the other com-
petitors by some 10 percentage points. How did it exploit sys-
tematic testing? Recall that it tries, first, the cue that discrimi-
nated the last time. If DEMO cue does not discriminate, it proceeds
with the cue that discriminated DEMO time before, and so on. In
doing so, when testing is systematic in the way described, it
tends to find, for each DEMO that is being paired with all smaller
ones, the group of DEMO for which the larger city has a positive
value. Trying these cues first increases the chances of finding a
discriminating cue that points in DEMO right direction (toward the
larger city). We learned our lesson DEMO reran the whole compe-
tition with randomly ordered of pairs of cities.
Discussion
The competition showed a surprising result: The Take The
Best algorithm drew as many correct inferences about un-
known features of a real-world DEMO as any of the inte-
gration algorithms, and more than some DEMO them. Two further
simplifications of the algorithm--the Take The Last algorithm
(DEMO knowledge about the rank orders of cue validities by
a memory of the discrimination history of cues) and the Mini-
malist algorithm (dispensing DEMO both) showed a compara-
662
GIGERENZER AND GOLDSTEIN
.8
~8
0
.75
~.7
.7
•
100% DEMO t
0
o .65
o
o
"~ .6
o
o
.55
DEMO
f
.5
0
10
20
30
40
50
60
Number of Objects Recognized
70
80
.65
.6
.55
Figure 7. Performance of the Minimalist DEMO For comparison, the performance of the Take The
Best algorithm (TTB) is shown as a dotted line, for the case in which DEMO of cue values are known,
tively small loss in correct inferences, and only when knowledge
about cue values was high.
To the best of our knowledge, this is the first inference com-
petition between satisficing and "rational" algorithms in a real-
world environment. The result is DEMO importance for encouraging
research that focuses on the power of simple psychological
mechanisms, that is, on the design and testing of satisficing al-
DEMO The result is also of importance as an existence proof
that cognitive algorithms capable of successful performance in
a real-world environment do not need DEMO satisfy the classical
norms of rational inference. The classical norms may be suffi-
cient but are not necessary for good inference in real
environments.
DEMO Algorithms That Satisfice
In this section, we discuss the fundamental psychological
DEMO postulated by the PMM family of algorithms: one-
reason decision making. DEMO discuss how this mechanism ex-
ploits the structure of environments in making fast inferences
that differ from those arising from standard models of rational
DEMO
One-Reason Decision Making
What we call one-reason decision making is a specific form of
satisficing. The inference, or decision, is based on a DEMO, good
reason. There is no compensation between cues. One-reason
decision making DEMO probably the most challenging feature of the
PMM family of algorithms. As we mentioned before, it is a de-
sign feature of an algorithm that is not present in those models
that depict human inference as DEMO optimal integration of all in-
formation available (implying that all information DEMO been
looked up in the first place), including linear multiple regres-
sion and nonlinear neural networks. One-reason decision mak-
ing means that each DEMO is based exclusively on one reason
(i.e., cue), but this reason may be different from decision to
decision. This allows for highly DEMO modeling of
choice. One-reason decision making is not compensatory. Com-
pensation is, after all, the cornerstone of classical rationality,
assuming that all DEMO can be compared and everything
has its price. Compensation assumes commensurability. How-
ever, human minds do not trade everything, some things are
supposed DEMO be without a price (Elster, 1979). For instance, ifa
DEMO must choose between two actions that might help him or
her get out of deep financial trouble, and one involves killing
someone, then DEMO amount of money or other benefits might
compensate for the prospect of bloody hands. He or she takes
the action that does not involve DEMO a person, whatever other
differences exist between the two options. More DEMO, hier-
archies of ethical and moral values are often noncompensatory:
DEMO friendship, military honors, and doctorates are supposed
to be without a price.
Noncompensatory inference algorithms--such as lexico-
graphic, conjunctive, and disjunctive rules--have DEMO dis-
cussed in the literature, and some empirical evidence has been
DEMO (e.g., Einhorn, 1970; Fishburn, 1988). The closest rel-
REASONING THE FAST AND FRUGAL WAY
663
ative to the PMM family DEMO satisficing algorithms is the lexico-
graphic rule. The largest evidence for lexicographic processes
seems to come from studies on decision under risk (for a recent
summary, see Lopes, 1995). However, despite empirical evi-
dence, noncompensatory lexicographic algorithms have often
been dismissed at face value because they violate the tenets of
classical rationality (Keeney & Raiffa, 1993; Lovie & Lovie,
1986). The PMM family is both more general DEMO more specific
than the lexicographic rule. It is more general because only the
Take The Best algorithm uses a lexicographic procedure in
which cues DEMO ordered according to their validity, whereas the
variant algorithms do not. DEMO is more specific, because several
other psychological principles are integrated with DEMO lexico-
graphic rule in the Take The Best algorithm, such as DEMO recog-
nition principle and the rules for confidence judgment (which
are DEMO dealt with in this article; see Gigerenzer et al., 1991 )DEMO
Serious models that comprise noncompensatory inferences
are hard to find. One of the few examples is in Breiman, Fried-
man, Olshen, and Stone ( 1993 ), who reported a simple, non-
compensatory algorithm with DEMO 3 binary, ordered cues,
which classified heart attack patients into DEMO and low-risk
groups and was more accurate than standard statistical classi-
fication methods that used up to 19 variables. The practical rel-
evance of DEMO noncompensatory classification algorithm is ob-
vious: In the emergency room, the physician can quickly obtain
the measures on one, two, or three DEMO and does not need
to perform any computations because there is no integration.
This group of statisticians constructed satisficing algorithms
that approach the task DEMO classification (and estimation) much
like the Take The Best algorithm handles two-alternative
choice. Relevance theory (Sperber, Cara, & Girotto, 1995 ) DEMO
tulates that people generate consequences from rules according
to accessibility and stop this process when expectations of rele-
vance are met. Although relevance theory DEMO not been as for-
malized, we see its stopping rule as DEMO to that of the Take
The Best algorithm. Finally, optimality theory (Legendre, Ray-
mond, & Smolensky, 1993; Prince & Smolensky, 1991) pro-
poses that hierarchical noncompensation explains how the
grammar of a language determines which structural description
of an input best satisfies well-formedness constraints. Optimal-
DEMO theory (which is actually a satisficing theory) applies the
same inferential principles as PMM theory to phonology and
morphology.
great topic but does DEMO recognize the name of the author, he
makes the inference that DEMO is probably not worth buying. If,
after an inspection of the references, he does not recognize most
of the names, he concludes DEMO book is not even worth reading.
The recognition principle is also known as one of the rules that
guide food preferences in animals. For DEMO, rats choose the
food that they recognize having eaten before (or having smelled
on the breath of fellow rats) and avoid novel foods (Gallistel,
Brown, Carey, Gelman, & Keil, 1991 ).
DEMO empirical validity of the recognition principle for infer-
ences about unknown city populations, as used in the present
simulations, can be directly tested DEMO several ways. First, partic-
ipants are presented pairs of cities, among them critical pairs in
which one city is recognized and the other DEMO, and
their task is to infer which one has more inhabitants. DEMO rec-
ognition principle predicts the recognized city. In our empirical
tests, DEMO followed the recognition principle in roughly
90% to 100% of all cases (Goldstein, 1994; Goldstein & Giger-
enzer, 1996). Second, participants are taught a cue, its ecologi-
cal validity, and the cue DEMO for some of the objects (such as
whether a city has DEMO soccer team or not). Subsequently, they are
tested on critical DEMO of cities, one recognized and one unrec-
ognized, where the recognized city has a negative cue value
(which indicates lower population). The second test is a harder
test for the recognition principle than the DEMO one and can be
made even harder by using more cues with negative cue values
for the recognized object, and by other means. Tests of the sec-
ond kind hax;e been performed, and participants still followed
the recognition principle more than 90% of the time, providing
evidence for its empirical validity (Goldstein, 1994; Goldstein
& Gigerenzer, 1996)DEMO
The recognition principle is a useful heuristic in domains
where recognition is a predictor of a target variable, such as
whether a food contains a toxic substance. In cases where rec-
ognition does not predict the DEMO, the PMM algorithms can
still perform the inference, but without the recognition princi-
ple (i.e., Step 1 is canceled).
Limited Search
DEMO Principle
Both one-reason decision making and the recognition princi-
ple realize limited search by defining stopping points. Integra-
tion algorithms, in contrast, do DEMO provide any model of stop-
ping points and implicitly assume exhaustive search (although
they may provide rules for tossing out some of the variables in
a lengthy regression equation). Stopping rules are crucial for
modeling DEMO under limited time, as in Simon's examples
of satisficing, where search among alternatives terminates when
a certain aspiration level is met.
The DEMO principle is a version of one-reason decision
making that exploits a lack of knowledge. The very fact that
one does not know is used DEMO make accurate inferences. The
recognition principle is an intuitively plausible principle that
seems not to have been used until now in models of bounded
DEMO However, it has long been used to good advantage by
humans DEMO other animals. For instance, advertisement tech-
niques as recently used by DEMO put all effort into making
sure that every customer recognizes the brand name, with no
effort made to inform about the product itself. The idea behind
this is that recognition is a strong force in customers' choices.
One of our dear (and well-read) colleagues, after seeing a draft
of this article, explained to us how he makes inferences about
which books are worth acquiring. If he finds a book about a
DEMO
Linearity is a mathematically convenient tool that has domi-
nated the theory of rational choice since its inception in the
mid-seventeenth century (Gigerenzer et al., 1989). The as-
sumption is that the various components of an alternative add
up independently to its overall estimate or utility. In DEMO,
nonlinear inference does not operate by computing linear sums
of (DEMO) cue values. Nonlinear inference has many variet-
ies, including simple principles such as in the conjunctive and
664
GIGERENZER AND GOLDSTEIN
disjunctive algorithms (Einhorn, 1970) and highly complex
ones such as in nonlinear multiple regression and neural net-
works. The DEMO The Best algorithm and its variants belong to
the family of simple nonlinear models. One advantage of simple
nonlinear models is transparency; every step in the PMM algo-
rithms can be followed through, unlike fully connected neural
networks with numerous hidden units and other free
parameters.
Our competition DEMO that the unit-weight and weighted
versions of the linear models lead to about equal performance,
consistent with the finding that the choice of DEMO, provided
the sign is correct, does often not matter much (DEMO, 1979).
In real-world domains, such as in the prediction of sudden in-
fant death from a linear combination of eight variables
(Carpenter, Gardner, McWeeny & Emery, 1977), the weights
can be varied across a broad range without decreasing predic-
tive accuracy: a phenomenon known as the "fiat maximum
effect" (Lovie & Lovie, 1986; von Winterfeldt & Edwards,
1982). The competition in addition, showed that the fiat maxi-
mum effect extends to tallying, with unit-weight and weighted
tallying performing about equally well. The performance of the
Take The Best DEMO showed that the fiat maximum can
extend beyond linear models: Inferences DEMO solely on the best
cue can be as accurate as any weighted or unit-weight linear
combination ofaU cues.
Most research in psychology and economics DEMO preferred
linear models for description, prediction, and prescription
(Edwards, 1954, 1962; Lopes, 1994; von Winterfeldt & Ed-
wards, 1982). Historically, linear models such as analysis of
variance and multiple regression originated as tools for data
analysis in psychological laboratories and were subsequently
projected DEMO means of the "tools-to-theories heuristic" into the-
ories of mind (DEMO, 1991 ). The sufficiently good fit of
linear models in many judgment studies has been interpreted
that humans in fact might combine cues DEMO a linear fashion.
However, whether this can be taken to mean DEMO humans actu-
ally use linear models is controversial (Hammond & Summers,DEMO
1965; Hammond & Wascoe, 1980). For instance, within a DEMO
tain range, data generated from the (nonlinear) law of falling
DEMO can be fitted well by a linear regression. For the data in
the Appendix, a multiple linear regression resulted in R 2 = .87,
which means that a linear combination of the cues can predict
DEMO target variable quite well. But the simpler, nonlinear, Take
The Best algorithm could match this performance. Thus, good
fit of a linear model does not rule out simpler models of
inference.
Shepard (1967) reviewed DEMO empirical evidence for the
claim that humans integrate information by linear models. He
distinguished between the perceptual transformation of raw
sensory inputs into conceptual DEMO and properties and the
subsequent inference based on conceptual knowledge. He con-
cluded that the perceptual analysis integrates the responses of
the vast number DEMO receptive elements into concepts and prop-
erties by complex nonlinear rules but once this is done, "there
is little evidence that they can DEMO turn be juggled and recom-
bined with anything like this facility" (Shepard, 1967, p. 263 ).
Although our minds can take account of a host of different fac-
tors, and although we can remember and report doing so, "it is
seldom more than one or DEMO that we consider at any one time"
(Shepard, 1967, DEMO 267). In Shepard's view, there is little evi-
Cue DEMO
Cue 2
Cue 3
a
+
b
c
-
?
Figure DEMO Limited knowledge and a stricter discrimination rule can
produce intransitive inferences.
dence for integration, linear or otherwise, in what we term in-
ferences DEMO memory--even without constraints of limited
time and knowledge. A further kind of evidence does not sup-
port linear integration as a model of memory-based DEMO
People often have great difiiculties in handling correlations be-
tween cues (DEMO, Armelius & Armelius, 1974), whereas inte-
gration models such as multiple regression need to handle in-
tercorrelations. To summarize, for memory-based inference,
there seems to be little empirical evidence for the view of DEMO
mind as a Laplacean Demon equipped with the computational
powers to perform multiple regressions. But this need not be
taken as bad news. The DEMO of the nonlinear satisficing algo-
rithms is that they can match the Demon's performance with
less searching, less knowledge, and less computational DEMO
Intransitivity
Transitivity is a cornerstone of classical rationality. It is one
of the few tenets that the Anglo-American school of Ramsey
and Savage shares DEMO the competing Franco-European school
of AUais (Fishburn, 1991 ). If DEMO prefer a to b and b to c, then
we should DEMO prefer a to c. The linear algorithms in our com-
petition always produce transitive inferences (except for ties,
where the algorithm randomly guessed), and city populations
are, in fact, transitive. The PMM family DEMO algorithms includes
algorithms that do not violate transitivity (such as the DEMO The
Best algorithm), and others that do (e.g., the Minimalist
algorithm). The Minimalist algorithm randomly selects a cue
on which to DEMO the inference, therefore intransitivities can re-
suit. Table 2 shows that DEMO spite of these intransitivities, overall
performance of the algorithm is only DEMO 1 percentage point
lower than that of the best transitive algorithms and a few per-
centage points better than some transitive algorithms.
An organism DEMO used the Take The Best algorithm with a
stricter discrimination rule (DEMO, the original version found
in Gigerenzer et al., 1991 ) could also be forced into making
intransitive inferences. The stricter discrimination rule is DEMO
search is only terminated when one positive and one negative
cue value (but not one positive and one unknown cue value)
are encountered. Figure 8 illustrates a state of knowledge in
which this stricter discrimination DEMO gives the result that a
dominates b, b dominates c, and c dominates a.7
7 Note that missing knowledge is necessary for intransitivities DEMO oc-
cur. If all cue values are known, no intransitive inferences DEMO possibly
result. The algorithm with the stricter discrimination rule allows precise
predictions about the occurrence of intransitivitics over the course of
knowledge acquisition. For DEMO, imagine a person whose knowl-
edge is described by Figure 8, except that she does not know the value
of Cue 2 for DEMO c. This person would make no intransitive judgments
REASONING THE FAST AND FRUGAL WAY
665
Biological systems, for instance, DEMO exhibit systematic in-
transitivities based on incommensurability between two sys-
tems on one dimension (Gilpin, 1975; Lewontin, 1968 ). Imag-
ine three species: a, b, and c. Species a inhabits both water and
land; species b inhabits both water and air. Therefor e, the DEMO
only compete in water, where species a defeats species b. Species
DEMO inhabits land and air, so it only competes with b in DEMO air,
where it is defeated by b. Finally, when a DEMO c meet, it is only
on land, and here, c DEMO in its element and defeats a. A linear
model that estimates some value for the combative strength of
each species independently of the species DEMO which it is com-
peting would fail to capture this nontransitive cycle.
Inferences Without Estimation
Einhorn and Hogarth (i975) noted that in the DEMO
model "there is essentially no estimation involved in its use" (DEMO
177), except for the sign of the unit weight. A similar result
holds for the algorithms reported here. The Take The Best algo-
DEMO does not need to estimate regression weights, it only
needs to DEMO a rank ordering of ecological validities. The
Take The Last and the Minimalist algorithms involve essen-
tially no estimation (except for the sign of the cues). The fact
that there is no estimation problem has DEMO important conse-
quence: An organism can use as many cues as DEMO has experi-
enced, without being concerned about whether the size of DEMO
sample experienced is sufficiently large to generate reliable esti-
mates of weights.
Cue Redundancy and Performance
Einhorn and Hogarth (1975) suggested that unit-weight
DEMO can be expected to perform approximately as well as
proper linear models when (a) R 2 from the regression model is
in the DEMO or low range (around .5 or smaller) and (b)
DEMO (cues) are correlated. Are these two criteria neces-
sary, sufficient, or both to explain the performance of the Take
The Best algorithm? The Take The Best algorithm and its vari-
ants certainly can exploit DEMO redundancy: If cues are highly
correlated, one cue can do the job.
We have already seen that in the present environment, R z =
.87, which is in the high rather than the moderate nr lnw range.
As mentioned earlier, the pairwise correlations between the
nine ecological cues ranged between -.25 and .54, with an ab-
solute average value of .19. Thus, despite a high R 2 and only
moderate-to-small correlation between cues, the satisficing al-
gorithms performed quite successfully. Their excellent perfor-
mance in the competition can be explained only partially by cue
redundancy, because the cues were only moderately correlated.
High cue redundancy, thus, DEMO seem sufficient but is not nec-
comparing objects a, b, and c. If she were to learn that object c had a
negative DEMO value for Cue 2, she would produce an intransitive judg-
ment. DEMO she learned one piece more, namely, the value of Cue 1 for
object c, then she would no longer produce an intransitive judgment.
The prediction is that transitive judgments should turn into intransitive
ones and DEMO, during learning. Thus, intransitivities do not simply de-
pend on the amount of limited knowledge but also on what knowledge
is missing.
essary DEMO the successful performance of the satisficing
algorithms.
A New Perspective on the Lens Model
Ecological theorists such as Brunswik (1955) emphasized
that the DEMO system is designed to find many pathways to
the world, substituting DEMO cues by whatever cues happen to
be available. Brunswik labeled this ability vicarious functioning,
in which he saw the most fundamental principle of DEMO science of
perception and cognition. His proposal to model this adaptive
process by linear multiple regression has inspired a long tradi-
tion of neo-Brunswikian DEMO (B. Brehmer, 1994; Ham-
mond, 1990), although the empirical evidence for mental
multiple regression is still controversial (e.g., A. Brehmer & B.
Brehmer, 1988). However, vicarious functioning need not be
equated with linear regression. The PMM family of algorithms
provides an alternative, nonadditive model of vicarious func-
tioning, in which cue substitution operates without integration.
This gives a new perspective of Brunswik's lens model. In a DEMO
reason decision making lens, the first discriminating cue that
passes through DEMO any other rays passing through and de-
termines judgment. Noncompensatory vicarious functioning is
consistent with some of Brunswik's original examples, such as
the substitution of behaviors in Hull's habit-family hierarchy,
and the alternative DEMO of symptoms according to the
psychoanalytic writings of Frenkel-Brunswik (see Gigerenzer &
Murray, 1987, chap. 3).
It has been reported sometimes DEMO teachers, physicians, and
other professionals claim that they use seven or so criteria to
make judgments (e.g., when grading papers or making DEMO differ-
ential diagnosis) but that experimental tests showed that they
in DEMO often used only one criterion (Shepard, 1967). At first
glance, this seems to indicate that those professionals make out-
rageous claims. But it need not be. If experts' vicarious func-
tioning works according to the PMM algorithms, then they are
correct in saying that they use many predictors, but the decision
is made by only one at any time.
What Counts as Good Reasoning?
Much of the research on DEMO in the last decades has
assumed that sound reasoning can be reduced to principles of
internal consistency, such as additivity of probabilities, confor-
DEMO to truth-table logic, and transitivity. For instance, research
on the Wason selection task, the "Linda" problem, and the
"cab" problem DEMO evaluated reasoning almost exclusively by
some measure of internal consistency (Gigerenzer, 1995,
1996a). Cognitive algorithms, however, need to meet more DEMO
portant constraints than internal consistency: (a) They need to
be DEMO plausible, (b) they need to be fast, and (c)DEMO
they need to make accurate inferences in real-world environ-
ments. In real time and real environments, the possibility that
an algorithm (e.g., the Minimalist algorithm) can make intran-
sitive inferences does not mean that it will make them all the
time or that this feature of the DEMO will significantly hurt
its accuracy. What we have not addressed in this article are con-
straints on human reasoning that emerge from the fact DEMO
Homo sapiens is a social animal (Gigerenzer, 1996b). For in-
stance, some choices (e.g., who to treat first in an emergency
666
GIGERENZER AND GOLDSTEIN
room) need to be justified (Tetlock, 1992 ). Going with the sin-
gle best reason, the strategy of DEMO Take The Best algorithm, has
an immediate appeal for justification and DEMO be more convinc-
ing and certainly easier to communicate than some complicated
weighting of cues.
Further Research
Among the questions that need to be DEMO in future re-
search are the following. First, how can we DEMO the pres-
ent satisficing algorithm from two-alternative-choice tasks to
other inferential tasks, such as classification and estimation?
The reported success of the classification and regression tree
models (Breiman et al., 1993 ), which use a form of one-reason
decision making, is an encouraging sign that what we have
shown here for two-alternative-choice tasks might be generaliz-
able. Second, what is the structure of real-world environments
that allows simple algorithms to DEMO so well? We need to
develop a conceptual language that can DEMO important as-
pects of the structure of environments that simple cognitive al-
gorithms can exploit. The traditional proposal for understand-
ing the structure of DEMO in terms of ecological validi-
ties defined as linear correlations (Brunswik, 1955 ) may not be
adequate, as the power of the nonlinear satisficing algorithms
suggests.
Can Reasoning Be Rational and Psychological?
At the DEMO of this article, we pointed out the common
opposition between the DEMO and the psychological, which
emerged in the nineteenth century after the DEMO of the
classical interpretation of probability (Gigerenzer et al., 1989).
Since then, rational inference is commonly reduced to logic and
probability theory, and psychological explanations are called on
when things go wrong. This division of labor is, in a nutshell,
the basis on which much of the current research on judgment
under uncertainty is built. As one DEMO from the Massa-
chusetts Institute of Technology put it, "either reasoning is ra-
tional or it's psychological" (Gigerenzer, 1994). Can not rea-
soning be both rational and psychological?
We believe that DEMO 40 years of toying with the notion of
bounded rationality, it DEMO time to overcome the opposition be-
tween the rational and the psychological and to reunite the two.
The PMM family of cognitive algorithms provides DEMO
models that attempt to do so. They differ from the Enlighten-
ment's unified view of the rational and psychological, in that
they focus on simple psychological mechanisms that operate
under constraints of limited time and DEMO and are sup-
ported by empirical evidence. The single most important result
in this article is that simple psychological mechanisms can yield
about as DEMO (or more) correct inferences in less time than
standard statistical linear models that embody classical proper-
ties of rational inference. The demonstration that DEMO fast and fru-
gal satisficing algorithm won the competition defeats the wide-
spread view that only "rational" algorithms can be accurate.
Models of DEMO do not have to forsake accuracy for sim-
plicity. The mind can have it both ways.
References
Alba, J. W., & Marmorstein, H. ( 1987 ). The effects of frequency knowl-
edge on consumer decision making. Journal of Consumer Research,
14, 14-26.
Anderson, J. R. (1990). The adaptive character of thought. Hillsdale,
N J: Erlbaum.
Armelius, B., & Armelius, K. (1974). The use of DEMO in
multiple-cue judgments: Data from a suppressor-variable task. Amer-
ican Journal DEMO Psychology, 87, 385-392.
Becker, G. (1976). The economic approach to human behavior. Chi-
cago: University of Chicago Press.
Brehmer, A., & Brehmer, B. (1988). What have we learned about hu-
DEMO judgment from thirty years of policy capturing? In B. Brehmer
& DEMO R. B. Joyce (Eds.), Human judgment: The SJT view (DEMO 75-
114). Amsterdam: North-Holland.
Brehmer, B. (1994). The DEMO of linear judgment models. Acta
Psychologica, 87, 137-154.
Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. (1993).
Classification and regression trees. New York: Chapman & Hall.
DEMO, N. R., & Siegler, R. S. (1993). Metrics and mappings: A frame-
work for understanding real-world quantitative estimation. Psycho-
logical Review, 100, 511-534.
Brunswik, E. ( 1955 ). Representative design and DEMO theory in
a functional psychology. Psychological Review, 62, 193-217.
Carpenter, DEMO G., Gardner, A., McWeeny, P. M., & Emery, J. L. (1977).
Multistage scoring system for identifying infants at risk of unex-
pected death. Archives of Disease in Childhood, 53, 606-612.
Darwin, C. ( 1965 ). The expressions of the emotions in man and animal.
Chicago: University of Chicago Press. (Original work published
1872)
DEMO, L. (1988). Classical probability in the Enlightenment.
Princeton, N DEMO" Princeton University Press.
Dawes, R. M. (1979). The robust DEMO of improper linear models.
American Psychologist, 34, 571-582.
DiFonzo, N. (1994). Piggybacked syllogisms for investor behavior.
Probabilistic mental modeling in rumor-based DEMO market trading.
Unpublished doctoral dissertation, Temple University, Philadelphia.
Edwards, W. (1954). The theory of decision making. Psychological Bul-
letin, 51,380-417.
Edwards, W. ( 1962 ). Dynamic decision theory and probabilistic infor-
DEMO processing. Human Factors, 4, 59-73.
Einhorn, H. J. (1970). The use of nonlinear, noncompensatory models
in decision-making. Psychological Bulletin, 73, 221-230.
Einhorn, H. J., & Hogarth, R. M. (1975). DEMO weighting schemes for
decision making. Organizational Behavior and Human Performance,
13, 171-192.
Elster, J. (1979). Ulysses and the sirens: Studies DEMO rationality and irra-
tionality.. Cambridge, England: Cambridge University Press.
Fischer Welt Almanach [Fischer World Almanac]. (1993). Frankfurt,
Germany: Fischer.
Fischhoff, B. ( 1977 ). Perceived informativeness of facts. Journal of Ex-
perimental Psychology: Human Perception and Performance, 3, 349-
358.
Fishburn, P. DEMO (1988). Nonlinear preference and utility theory. Balti-
more: Johns Hopkins University Press.
Fishburn, P. C. (1991). Nontransitive preferences in decision DEMO
Journal of Risk and Uncertainty, 4, 113-134.
Gallistel, C. R., Brown, A. L., Carey, S., Gelman, R., & Keil, E C.
( 1991 ). Lessons from animal learning for the study of cognitive de-
velopment. In S. Carey & R. Gelman (Eds.), The epigenesis of mind.
Essays on biology and cognition (pp. 3-36). Hillsdale, N J: Erlbaum.
Gigerenzer, G. ( 1991 ). From DEMO to theories: A heuristic of discovery
in cognitive psychology. Psychological Review,, 98, 254-267.
Gigerenzer, G. ( 1993 ). The bounded rationality DEMO probabilistic mental
models. In K. I. Manktelow & D. E. Over (DEMO), Rationality: Psy-
chological and philosophical perspectives (pp. 284-313). London:
Routledge.
Gigerenzer, G. (1994). Why the distinction between single-event DEMO
abilities and frequencies is relevant for psychology (and vice versa).
REASONING THE FAST AND FRUGAL WAY
667
In G. Wright & P. DEMO (Eds.), Subjective probability (pp. 129-
161 ). New York: Wiley.
Gigerenzer, G. (1995). The taming of content; Some thoughts about
domains and modules. Thinking and Reasoning, 1, 324-333.
Gigerenzer, G. (1996a). On narrow norms and vague heuristics. A re-
ply to Kahneman and Tversky (1996). Psychological Review, 103,
592-596.
Gigerenzer, G. (1996b). Rationality: Why social context matters. In P.
Baltes & U. M. Staudinger (Eds.), Interactive minds: Life-span per-
spectives on the social foundation of cognition (pp. 319-346). Cam-
bridge, England: Cambridge University Press.
Gigerenzer, G., & Hoffrage, U. (1995). DEMO to improve Bayesian rea-
soning without instruction: Frequency formats. Psychological Re-
DEMO, 102, 684-704.
Gigerenzer, G., Hoffrage, U., & Kleinb61ting, DEMO (1991). Probabilistic
mental models: A Brunswikian theory of confidence. Psychological
Review,, 98, 506-528.
Gigerenzer, G., & Murray, D. J. ( 1987 ). Cognition as intuitive statistics.
Hillsdale, N J: Erlbaum.
DEMO, G., Swijtink, Z., Porter, T., Daston, L., Beatty, J., & Kriiger,
L. ( 1989 ). The empire of chance. How probability changed science
and everyday liJe. Cambridge, England: Cambridge DEMO Press.
Gilpin, M. E. (1975). Limit cycles in competition communities. The
American Naturalist, 109, 51-60.
Goldstein, D. G. (1994). DEMO less-is-more effect in inference. Unpub-
lished master's thesis, University of DEMO
Goldstein, D. G., & Gigerenzer, G; (1996). Reasoning DEMO recognition
alone: How to exploit a lack of knowledge. Unpublished manuscript.
DEMO, D., & Tversky, A. (1992). The weighing of evidence and the
determinants of confidence. Cognitive Psychology, 24, 411-435.
Hammond, K. R. (1966). The psychology ofEgon Brunswik. New
York: Holt, Rinehart & Winston.
Hammond, K. R. (i990). Functionalism and illusionism: Can integra-
tion be usefully achieved? In R. M. Hogarth (Ed.), DEMO in deci-
sion making (pp. 227-261 ). Chicago: University of DEMO Press.
Hammond, K. R., Hursch, C. J., & Todd, DEMO J. (1964). Analyzing the
components of clinical inference. PsychologicalReview, 71,438-456.
Hammond, K. R., & Summers, D. A. ( 1965 )DEMO Cognitive dependence on
linear and nonlinear cues. Psychological Review, 72, 215-244.
Hammond, K. R., & Wascoe, N. E. (Eds.). (1980). Realizations of
Brunswik's representative design: New directions for methodology of
social and behavioral science. San Francisco: Jossey-Bass.
Hertwig, R., Gigerenzer, DEMO, & Hoffrage, U. (in press). The reiteration
effect in DEMO bias. Psychological Review
Hoffrage, U. (1994). Zur Angemessenheit subjektiver Sicherheits-Ur-
teile: Eine Exploration der Theorie der probabilistischen mentalen
Modelle [On the validity of confidence judgments: A study of the
theory of probabilistic mental models]. Unpublished doctoral disser-
tation, Universit~it Salzburg, Salzburg, Austria.
Huber, O. ( 1989 ). Information-processing operators in decision mak-
ing. In H. Montgomery & O. Svenson (Eds.), Process and structure
in human decision making (pp. 3-21 ). New York: Wiley.
Huttenlocher, J., Hedges, L., & Prohaska, V. ( 1988 ). Hierarchical orga-
nization in ordered domains: Estimating the dates of events. Psycho-
logical Review, 95, 471-484.
Johnson-Laird, P. N. (1983). Mental models. Cambridge, MA: Har-
DEMO University Press.
Juslin, P. (1993). An explanation of the hard-easy effect in studies of
realism of confidence in one's general knowledge. DEMO Journal
of Cognitive Psychology, 5, 55-71.
Juslin, P. (1994). The overconfidence phenomenon as a consequence of
informal experimenter-guided selection of almanac DEMO Organiza-
tional Behavior and Human Decision Processes, 57, 226-246.
Juslin, DEMO, Winman, A., & Persson, T. (1995). Can overconfidence DEMO
used as an indicator of reconstructive rather than retrieval processes?
Cognition, 54, 99-130.
Kahneman, D., Slovic, E, & Tversky, A. (Eds.). (1982). Judgment un-
der uncertainty: Heuristics and biases. Cambridge, England: Cam-
bridge University Press.
Keeney, R. L., & DEMO, H. (1993). Decisions with multiple objectives.
Cambridge, England: Cambridge University Press.
Klayman, J., & Ha, Y. (1987). Confrmation, disconfirmation, and in-
formation in hypothesis testing. Psychological Review, 94. 211-228.
DEMO, A., Lichtenstein, S., & Fischhoff, B. (1980). Reasons for confi-
dence. Journal of Experimental Psychology: Human Learning and
Memory 6. 107-118.
Krebs, J. R., & Davies, N. B. (1987). DEMO introduction to behavioral
ecology (2nd ed.). Oxford: Blackwell.
Legendre, DEMO, Raymond, W., & Smolensky, P. (1993). Analytic typol-
DEMO of case marking and grammatical voice. Proceedings of the Berke-
ley Linguistics Society, 19, 464-478.
Lewontin, R. C. (1968). Evolution of DEMO genetic systems. In M.
Gerstenhaber (Ed.), Some mathematical questions in DEMO Provi-
dence, RI: American Mathematical Society.
Lopes, L. L. (1992). Three misleading assumptions in the customary
rhetoric of the bias literature. DEMO and Psychology, 2, 231-236.
Lopes, L. L. ( 1994L Psychology DEMO economics: Perspectives on risk,
cooperation, and the marketplace. Annual Review of Psychology 45,
197-227.
Lopes, L. L. (1995). Algebra DEMO process in the modeling of risky
choice. In J. R. Busemeyer, DEMO Hastie, and D. Medin (Eds.), Decision
making from the perspective of cognitive psychology (pp. 177-220).
New York: Academic Press.
Lovie, A. D., & Lovie, P. (1986). The fiat maximum effect and linear
scoring models for prediction. Journal of Forecasting, 5, 159-168.
DEMO, A. S., & Luchins, E. H. (1994). The water jar experiments and
Einstellung effects: I. Early history and surveys of textbook citations.
Gestalt Theory, 16, 101-121.
McClelland, A. G. R., & DEMO, F. (1994). The calibration of subjective
probabilities: Theories and DEMO 1980-1994. In G. Wright & P.
Ayton (Eds.), Subjective probability (pp. 453-482 ). Chichester, En-
gland: Wiley.
McClennen, E. E (1990). Rationality and dynamic choice. Cambridge,
England: Cambridge University Press.
McCloskey, D. N. ( 1985 ). The rhetoric of economics. Madison: Univer-
sity of Wisconsin Press.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1993). The adaptive
decision maker Cambridge, England: Cambridge University Press.
Prince, A., & Smolensky, P. ( 1991 ). Notes on connectionism andhar-
mony theory in linguistics ( Tech. Rep. No. CU-CS-533-91 ). Boulder:
University of Colorado, Department of DEMO Science.
Shepard, R. N. (1967). On subjectively optimum selections among
multi-attribute alternatives. In W. Edwards & A. Tversky (Eds.), De-
cision making (pp. 257-283 ). Baltimore: Penguin Books.
Simon, H. A. (1945). Administrative behavior. A study of decision-
making processes in administrative DEMO New York: Free
Press.
Simon, H. A. ( 1956 ). DEMO choice and the structure of the environ-
ment. Psychological Review, 63, 129-138.
Simon, H. A. (1982). Models of bounded rationality. Cambridge, MA:
MIT Press.
Simon, H. A. (1990). lnvariants of DEMO behavior. AnnualReview of
Psychology, 41, 1-19.
Simon, H. A. ( DEMO ). Economics, bounded rationality, and the cognitive
revolution. Aldershot Hants, England: Elgar.
Sniezek, J. A., & Buckley, T. ( 1993 ). Becoming more or less uncertain.
In N. J. Castellan (Ed.), Individual and group decision making (pp.
87-108). Hillsdale, N J: Erlbaum.
Sperber, D., Cara, E, & Girotto, V. (1995)DEMO Relevance theory explains
the selection task. Cognition, 57, 31-95.
Stephens, DEMO W., & Krebs, J. R. (1986). Foraging theory Princeton,DEMO
N J: Princeton University Press.
668
GIGERENZER
Stone,
G. O. (1986).
An
analysis
of the delta
rule and
the learning
of
statistical
associations.
In D. Rumelhart,
DEMO McClelland,
& the PDP
Research
Group
(Eds.),
Parallel distributed processing: Explora-
tions in the microstructure of cognition (pp.
444-459).
DEMO,
MA:
MIT
Press.
Tetlock,
P. E. ( 1992 )DEMO The
impact
of accountability
on judgment
and
choice:
Toward
a social contingency
model.
In M. Zanna
vances in experimental social psychology (Vol.
25,
pp.
(Ed.),
Ad-
331-376).
New York: Academic
Press.
Tweney,
R. D., & Walker,
B. J. (1990).
DEMO
education
and the cog-
nitive psychology
of science.
In B. F. Jones
& L. Idol (Eds.),
Dimen-
AND
GOLDSTEIN
sions of thinking DEMO cognitive instruction (pp.
N J: Erlbaum.
291-310).
Hillsdale,
von Winterfeldt,
D., & Edwards,
W. (1982).
Costs
and
DEMO
ceptual
research.
Psychological Bulletin, 91,609-622.
Weber,
U., B6ckenholt,
U., Hilton,
D. J., & Wallace,
B. (1993).
in per-
Deter-
minants
of diagnostic
hypothesis
generation:
Effects of information,DEMO
base rates, and experience. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 19, 1151-1164.
Wimsatt,
W. C. (1976).
DEMO,
levels of organization,
and
the
mind-body
problem.
In G. G. Globus,
G. Maxwell,
& I. Savodnik
(Eds.),
Consciousness DEMO the brain: A scientific and philosophical
inquiry (pp. 199-267
). DEMO York: Plenum.
Appendix
The Environment
City
Berlin
Hamburg
Munich
Cologne
Frankfurt
DEMO
Dortmund
Stuttgart
DiJsseldorf
Bremen
Duisburg
Hannover
Leipzig
Nuremberg
Dresden
Bochum
Wuppertal
Bielefeld
Mannheim
Halle
Chemnitz
Gelsenkirchen
Bonn
Magdeburg
Karlsruhe
Wiesbaden
Mfinster
M6nchengladbach
Braunschweig
Augsburg
DEMO
Kiel
Krefeld
Aachen
Oberhausen
L/ibeck
Hagen
Erfurt
Kassel
SaarbriJcken
Population
3,433,695
1,652,363
1,229,026
953,551
644,865
DEMO,973
599,055
579,988
575,794
551,219
535,447
513,010
511,079
493,692
490,571
396,486
383,660
319,DEMO
310,411
310,234
294,244
293,714
292,234
278,807
275,061
260,301
259,438
259,436
258,833
256,877
DEMO,088
245,567
244,020
241,961
223,840
214,758
214,449
208,989
194,268
191,694
Soccer
team
State
capital
Former
DEMO
Germany
Industrial
belt
Licence
plate
Intercity
trainline
Exposition
site
National
capital
-
+
+
+
+
-
+
+
-
+
-
-
-
DEMO
+
+
-
.....
.....
- - + -
- - + -
- - +
....
-
+
-
.....
+
.....
....
DEMO - +
- + -
-*
.....
- - - +
.....
- - - +
- + + -
.....
+ + - DEMO
+
+
+
+
-
-
-
-
+
+
+
-
+
-
-
-*
-
-
-
+
-
-
-
-
DEMO
+
+
-
-
+
+
+
+
+
+
-
-
-
-
+
+
+
+
....
+ - -
+
........
DEMO
+
-
-
........
+
+
+
+
+
+
+
-
-
-
-
-
-
-
-
-
-
-
-
+
DEMO
-
-
-
-
-
+
+
-
-
-
+
-
-
-
-
-
+
-
+
+
+
+
-
+
DEMO
-
-
+
+
-
-
-
-
-
-
-
+
+
+
+
+
+
+
+
+
+
+
+
+
DEMO
-
-
-
+
+
+ - -
....
+
+
+
+
+
+
-
-
-
-
-
-
-
-
-
DEMO
-
-
-
-
-
-
+
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
DEMO
+
+
+
+
+
+
+
+
-
-
+
+
-
-
+
-
-
-
-
-
-
-
-
-
DEMO
-
-
-
-
University
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
DEMO
-
+
-
-
-
+
+
+
-
+
+
-
-
-
-
+
+
Freiburg
Hamm
Mainz
Herne
M/ilheim
Solingen
Osnabriick
Ludwigshafen
Leverkusen
Neuss
Oldenburg
DEMO
Darmstadt
Heidelberg
Bremerhaven
Gera
Wolfsburg
Wiirzburg
Schwerin
Cottbus
Recklinghausen
Remscheid
GSttingen
Regensburg
Paderborn
Bottrop
Heilbronn
Offenbach
Zwickau
Salzgitter
Pforzheim
Ulm
Siegen
Koblenz
Jena
lngolstadt
DEMO
Hildesheim
Moers
Bergisch Gladbach
Reutlingen
Fiirth
Erlangen
191,029
179,639
179,486
178,132
177,681
165,401
163,168
162,173
160,DEMO
147,019
143,131
139,794
138,920
136,796
130,446
129,037
128,510
127,777
127,447
125,891
125,060
DEMO,155
121,831
121,691
120,680
118,936
115,843
114,992
114,636
114,355
112,944
110,529
109,174
108,DEMO
105,518
105,489
105,403
105,291
104,595
104,037
103,687
103,362
102,440
team
State
THE
Note.
City populations
DEMO The two starred minus
were taken from Fischer Welt Almanach (1993)DEMO
values are, in reality, plus values. Because
of transcription
errors, DEMO ran all simulations
with these two minus
do not affect the rank order of cue validities, should not have any noticeable
effect on the results, and are irrelevant
for our theoretical
City
Population
Soccer
FAST
AND
FRUGAL
WAY
Former
East
Industrial
Licence
Intercity
Exposition
National
......
-
-
DEMO
+
-
-
+
-
-
-
-
+
-
-
-
+
......
+
-
+
-
-
-
-
-
+
-
DEMO
.....
.....
+
-
-
University
.....
.....
+
+
-
-
-
-
+
........
.........
.....
-
+
+
-
.....
+
DEMO
+
+
-
-
-
-
-
-
.....
.....
-
-
+
-
+
+
+
+
-
-
-
-
-
-
DEMO
.....
+
-
-
-
+
+
-
-
+
-
-
-
-
-
-
+
-
......
+
-
+
-
-
DEMO
.....
+
-
-
....
+
+
-
-
.........
-
-
-
+
.....
.........
......
+
-
-
-
+
-
+
DEMO
.........
.....
+
-
-
.....
+
-
........
-
.....
+
-
-
-
-
+
-
.....
+
+
+
-
-
DEMO
-
-
-
-
+
.....
-
-
-
+
.....
+
-
-
.....
.........
.........
.....
.....
+
+
-
-
-
DEMO
values. These
Received
May
argument.
Revision
received
December
Accepted
December
capital
REASONING
Germany
belt
plate
trainline
site
capital
669
+
-
+
-
+
DEMO
+
-
+
+
-
-
+
-
-
+
+
+
-
-
+
+
+
+
-
+
-
+
20,
DEMO
4, 1995
8, 1995
•{1g42fwefx}