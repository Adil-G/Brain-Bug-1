314
IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT, VOL. 51, NO. 3, AUGUST 2004
Key Success Factors for Technological Entrepreneurs’
R&D Projects
Thomas Åstebro
DEMO impact of 36 innovation, technology, and market
characteristics on the probability that early stage R&D projects
will reach the market is examined. DEMO is based on data from
561 R&D projects developed by technological entrepreneurs. Four
characteristics stand out as most predictive: expected proﬁtability,
technological opportunity, development risk, and appropriability
conditions. These predict future commercial success DEMO with an
out-of-sample accuracy of 80.9%. This model performs better than
R&D managers’ and venture capital’s (VC’s) forecasts of success
and has DEMO potential to be used as a screening tool for early stage
R&D investment reviews by, for example, VCs. Implications for
both research DEMO practice are discussed.
Index Terms—Early stage R&D, probability of commercial-
DEMO, project evaluation, project screening, technological
entrepreneurs.
I. INTRODUCTION
ESEARCHERS disagree DEMO how to construct appropriate
R R&D project evaluation models [1]. The most common
method of project evaluation is discounted cash ﬂow (DCF), fol-
lowed by various scoring approaches [2]. Others have proposed
evaluation models DEMO on operations research (OR) principles
[3]. All these approaches have both beneﬁts and shortcomings.
Scoring models may suffer from vaguely measured variables
and DEMO the difﬁculty of combining both ﬁnancial and non-
ﬁnancial variables on a common scale. OR models have been
found to be too complex to DEMO of much practical use [2], [3].
DCF requires detailed information in DEMO where informa-
tion may be very vague and have problems taking into account
information that is difﬁcult to quantify.
As OR approaches were rejected DEMO DCF became a known
entity, R&D project management research in DEMO 1980s focused
on using statistical approaches to investigate “key success
factors” that would explain R&D projects’ success. Such statis-
tical analysis could be DEMO to build calibrated project scoring
models (for example [4]). However, in a review of this research,
Balachandra and Friar [1] conclude DEMO researchers have
been unable to converge on any key success factors. Research
Manuscript received February 1, 2003; revised December 1, 2003. Review
of this manuscript was arranged by Department Editor A. S. Bean and Ed-
DEMO G. F. Farris. This work was supported in part by the Natural Sci-
ences and Engineering Research Council of Canada and the Social Sciences
DEMO Humanities Research Council of Canada’s joint program in Management
of Technological Change, in part by the Canadian Imperial Bank of Commerce,
and in part by the Canadian Innovation Centre.
The author is with the Joseph DEMO Rotman School of Management, University
of Toronto, Toronto, ON M5S3E6 DEMO (e-mail: tastebro@utm.utoronto.ca).
Digital Object Identiﬁer 10.1109/TEM.2004.830863
subsequently shifted gears toward investigating the innovation
process [5], without ever resolving what key characteristics
explain R&D projects’ success.
Recent literature has, therefore, been criticized DEMO an undue
focus on the process of project selection while not addressing
the decision criteria necessary to select projects. Cooper [6]
summarizes recent research DEMO addressing “how to do projects
right, without knowing which are the DEMO projects.” Murphy
and Kumar [7] are critical as well, stating that DEMO the
development process downstream, while neglecting upstream
choices may be a DEMO exercise.”
This paper revisits the question regarding the key success fac-
tors for screening early stage R&D projects. It addresses many
of the DEMO problems that have plagued past research
and focus on a speciﬁc under-researched decision-making con-
text: screening of early-stage R&D projects by technological
entrepreneurs. The scope is limited to examining the likelihood
that projects will reach DEMO market. This is an important inter-
mediate stage for achieving ﬁnancial returns and includes both
technical success as well as acceptance in the marketplace.1 DEMO
561 investigated R&D projects are typically of an incremental
nature with relatively small investments [9].
The research contributions are twofold: 1) this DEMO the ﬁrst
statistical analysis on the effect of key success factors on the
commercial success for early stage R&D projects generated
outside of DEMO organizations and 2) to the author’s
knowledge this is the ﬁrst DEMO study of key success
factors, where three methods biases are avoided: hindsight bias,
common method variance bias, and low statistical power.
The results do not support Balachandra and Friar’s [1]
suggestion that technology factors DEMO less important for incre-
mental and low-tech projects. The degree to which an invention
represents a clear improvement over previous products and the
degree DEMO which there is technological uncertainty associated
with further development are two important success determi-
nants for these projects. The key success factors for screening
DEMO entrepreneurs’ R&D projects are, therefore,
not much different than DEMO that have been researched as
important for screening R&D projects within established
organizations.
Researchers can replicate this study’s useful design. The
critical ingredients DEMO: 1) a large sample of projects; 2) project
screening criteria measured at an early stage; 3) data on key
management interventions; and 4) a clear outcome variable.
Single-ﬁrm studies of large numbers of historical project
screenings within large ﬁrms or venture capital ﬁrms where
1Technical DEMO commercial success are sometimes analyzed separately [8].
0018-9391/04$20.00 © 2004 IEEE
Authorized licensed use limited to: University of Waterloo. Downloaded on April 18, 2009 at 16:02 from IEEE Xplore.  Restrictions apply.
ÅSTEBRO: KEY SUCCESS FACTORS FOR TECHNOLOGICAL ENTREPRENEURS’ R&D PROJECTS 315
records have been kept are likely to be better sources for ob-
taining DEMO data than the previous dominant research design
of cross-ﬁrm post-outcome mail surveys. The use of subjective
evaluations on criteria at the screening stage seems DEMO this
context to be of less concern.
II. R&D PROJECT EVALUATION RESEARCH
There has been a great deal of statistical research on the DEMO
terminants of R&D project performance using various analytical
approaches. Reviews can be found in [1] and [10]–[14]. Rather
than rereviewing this extensive literature, I provide a few exam-
ples and then proceed to draw conclusions DEMO on the excellent
meta-analysis by [1].
In the most comprehensive study to date, Cooper [4] tried to
predict 102 project successes and 93 failures. A factor analysis
on 48 variables was conducted to generate a smaller DEMO more
manageable subset of predictors. Thirteen factors were identi-
ﬁed and they explained 69.3% of the variance of the original 48
variables. A total DEMO seven of the 13 factors were signiﬁcantly
related to perceived project success at least at the 0.10 level.
These were (in decreasing order of signiﬁcance): product supe-
riority and uniqueness, project/company resource compatibility,
market need/growth/size, economic disadvantage to consumer,
newness to ﬁrm, technological resource compatibility and, ﬁ-
nally, market competitiveness. The model had an of 0.42 and
an overall prediction accuracy of 84.1%, and performed well in
anaïve split-sample test.
However, performing a meta-analysis of 60 articles, Bal-
achandra and Friar [1] found contradictory results and little
stability of success factors across studies: there seems to be
no clear agreement even on the direction of inﬂuence of the
speciﬁc factors analyzed, let alone their signiﬁcance, if any.
But when aggregating up to a sufﬁciently generic level of
analysis researchers seem to agree that the following classes of
DEMO are important: market, technology, environment, and
organizational [1], [10], [11], [13], [14], with disagreement as
to the importance of additional classes.
A similar lack of convergence is reached in the literature
on DEMO decision criteria used by venture capitalists. Zo-
pounidis [15] summarizes this literature with two conclusions.
The ﬁrst is that the criterion of the management DEMO is con-
sidered predominant in all the studies concerning decisions in
venture investment and the second is the great diversity of eval-
uation criteria DEMO their relative importance (ranking of criteria)
from one study to DEMO other” [15, p. 63].
The value of using statistically derived models DEMO R&D
decision-making has nevertheless been clearly illustrated by
Zacharakis and Meyer [16] who investigated the ability of VCs
to accurately assess the future DEMO of a venture seeking
investment. The 51 interviewed practicing U.S. VCs had on
average over ten years of VC experience and over 22 years DEMO
work experience and focused on seed and early stage deals.
Zacharakis and Meyer [16] conducted an experiment where
the VCs received several pieces of DEMO about 25 actual
investments that had subsequently achieved either success or
failure. Approximately 57% of the investments were in the
seed and early stages. DEMO VCs were requested to evaluate the
ventures as they would during the initial screening stage. Their
predictions were then compared with the actual outcomes DEMO
the percentage of correctly classiﬁed outcomes was computed.
This study show VCs to have a low ability to correctly fore-
cast the outcomes of DEMO best the VCs had a classiﬁ-
cation accuracy of approximately 40%. Perplexingly, the more
information about the venture that was provided to the VCs the
less able they were at correctly predicting outcomes. When in-
formation DEMO the track record of the team and competition
was included the classiﬁcation accuracy reduced to 31% and
when additional information about the team and DEMO was
introduced the classiﬁcation accuracy declined to 17%. These
results indicate that VCs are rather poor at making investment
decisions and that more information DEMO them more confused
and less accurate evaluators.
Zacharakis and Meyer then compared the ability of the VCs to
the forecasting accuracy of a simple DEMO model that used
the same information as the VCs to make predictions. The clas-
siﬁcation accuracy of the statistical models ranged from 40% to
DEMO, always clearly surpassing the judgments made by the VCs.
These preliminary DEMO are very encouraging. They indicate
that substantial improvements are possible in the screening stage
of investment decisions by using statistical models.
To create a DEMO statistical model for R&D decision
support one should avoid previous methodological mistakes.
Balachandra and Friar [1] identify four major sources of weak-
ness DEMO previous research on R&D key success factors, namely
quality of DEMO, the deﬁnition of a new product, factor selection
and deﬁnition, DEMO measurement of factors.
Most studies on the determinants or factors inﬂuencing the
success of R&D projects have been conducted by simultane-
ously collecting DEMO on independent and dependent
variables after the projects have been completed (DEMO example
[4], [10], [17], and [18]). These studies suffer DEMO both
common method variance bias [19] and hindsight bias [20],
thereby degrading data quality.
Another serious problem in previous work is the relatively
DEMO amount of observations in relation to the number of pre-
dictors that have been used. Cliff [21] suggests: “With 40 or
so variables, DEMO group of 150 persons is about the minimum, al-
though 500 DEMO preferable” [21, p. 339]. Previous studies all fail to
reach the DEMO sample size and only [4] reaches the abso-
lute minimum, as DEMO by [21]. This failure creates instability
of results in test-retests and partly explains the lack of conver-
gence on a stable set of “success DEMO
Balachandra and Friar [1], in addition, report confusion about
the measurement and interpretation of the dependent variable:
project “success” due to the DEMO of subjective scales and vague
(or complete absence) of a deﬁnition to guide respondents.
In all previous studies, the predictive information is collected
on perceptual scales. The respondent is asked to make a judg-
ment DEMO to the importance of a particular variable, for example,
the DEMO of “market size” on a scale with tick-marks,
rather than providing objective data on the size of the market.
This procedure is somewhat DEMO due to the difﬁculty of
collecting objective data on a large set of variables through a
mail survey. Nevertheless, several well-known methodological
problems arise. What does, for example, a “7” on a ten-point
Authorized licensed DEMO limited to: University of Waterloo. Downloaded on April 18, 2009 at 16:02 from IEEE Xplore.  Restrictions apply.
scale mean? What will the estimated coefﬁcient for the vari-
ables mean? Tests of interrater reliability can only provide com-
fort in our belief that higher scores are indeed higher than lower
scores, not on the meaning of particular scores. Nevertheless,
[22], among others, shows that DEMO judgmental scores on pre-
dictors are quite useful in predicting outcomes, DEMO in very
difﬁcult decision situations. In fact, statistical models based on
DEMO scores perform better then experts’ judgmental pre-
dictions based on the same underlying judgmental scores [23].
Armed with this knowledge one can claim that DEMO judg-
mental data on various potential predictors from well-informed
individuals is useful, but asking these individuals about their
overall judgment of the outcome (DEMO, project success) is less
useful.
A ﬁnal issue identiﬁed by Balachandra and Friar [1] is the
wide variety of R&D projects and DEMO product development
projects studied. Quite possibly there are no generic success
factors as they might depend on the stage of the review and
other DEMO Balachandra and Friar [1], therefore, suggest
three contextual variables that condition which variables that
are important: the nature of innovation (incremental versus
DEMO), market (existing versus new), and technology (high
versus low).
In summary, future studies should: 1) avoid common method
and hindsight bias; 2) use larger data-sets than those used be-
fore; 3) deﬁne the outcome variable more precisely and avoid
expert judgment of it; 4) either limit or condition for the mix of
projects DEMO; and 5) use subjective assessments of predic-
tors with caution.
III. SAMPLE SELECTION AND DATA
A. Sampling Strategy
The Inventors’ Assessment Program (IAP) at the Canadian
Innovation Centre (CIC) was used as the main source for R&D
project data. The CIC represents an organization independent
DEMO the R&D projects they evaluate and, therefore, is not likely
to suffer from bias of judgment associated with being directly
involved in DEMO projects.
The IAP collects data on invention and product-market char-
acteristics at a very early stage of the projects’ development,
thus allowing this DEMO to avoid hindsight bias. Data on pre-
dictors are collected on average two years before the successful
projects reach the market. To further illustrate DEMO early stage of
the review, the average accumulated out-of-pocket R&D DEMO
ditures at the time of evaluation are Cdn $9,853 (1995 DEMO).
The average accumulated out-of-pocket R&D expenditures for
those reaching the market are on the other hand Cdn $54,513.
More data on DEMO characteristics of these projects are available
in [9]. Over 14 000 R&D projects have been evaluated since the
inception of the IAP program DEMO 1976.
The IAP strictly evaluates R&D projects undertaken by tech-
nological inventors/entrepreneurs conducting efforts outside the
conﬁnes of established organizations. As will DEMO described, the
sample consists of a rather homogenous set of projects. DEMO
sample is unique. There has been little analysis of the charac-
teristics of technological entrepreneurs’ R&D projects and, to
IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT, VOL. 51, NO. 3, AUGUST 2004
the author’s knowledge there has not been any analysis of these
projects’ key success criteria.2
To DEMO a project evaluated, the inventor/entrepreneur ﬁlls out
a questionnaire and DEMO a fee. The fee was Cdn. $262 in 1995
(about U.S. DEMO). In comparison with models of R&D project’s
success in established organizations [4], this review does not
consider organizational factors since, in DEMO overwhelming ma-
jority of cases, there is not yet an organization DEMO evaluate. The
IAP analyst–typically an engineer–compares the project with
other similar projects using data provided by the potential en-
trepreneur and searches various on-line DEMO such as patent
and trademark databases. The analyst, then, subjectively rates
the project on 37 criteria and reports these back together with
an DEMO recommendation.3 The ratings on 37 criteria serve as
the independent variables in this study. They are collected prior
to and independent of observing project DEMO, thus com-
pletely avoiding common method variance bias [29] and hind-
DEMO bias [20]. The reliability of the criteria range from 0.84 to
0.96 [30].
B. Data
The sample frame was all projects reviewed from the DEMO of
the IAP until and including 1993. Projects reviewed after 1993
were excluded to ensure that outcomes were observable in 1996
when outcome data DEMO collected. A random sample of projects
were selected from each year between 1976 and 1993. Using a
CD-ROM of Canadian residential addresses, 1826 records were
updated with current addresses. This number represents 21% of
the sample DEMO
The “total survey design” method was followed to collect out-
come data [31]. This involved several rounds of pretests of the
survey instrument and DEMO reviews of the instrument by ana-
lysts at the IAP. The telephone survey method was chosen for its
ability to generate high response rates DEMO for greater control of
the data collection process [32]. Individuals recorded as respon-
sible for the projects were ﬁrst mailed a letter informing that DEMO
call would be placed. Telephone calls were made primarily in
evenings to residential telephone numbers during an eight-week
period in the spring of 1996. DEMO the 1826 sampled records,
1465 were from subjects who could be reached and asked to par-
ticipate in the survey. We obtained 1095 DEMO, representing
an adjusted response rate of 75%.4
2For recent research on DEMO entrepreneurs/inventors, see [9] and
[24]–[26].
3Thirty-three of these criteria were DEMO by G. Udell at the Oregon In-
novation Center in 1974 as critical for venture success [27], [28], and were used
at Waterloo DEMO the start in 1976. In 1989, the CIC introduced a revised DEMO
with four more criteria.
4A concern was that there would not be enough successes to estimate mean-
ingful models. A subset of projects where DEMO at the CIC had information
indicating that the invention might have reached the market were, therefore, in-
cluded. CIC analysts had obtained this DEMO through various sources such
as newspaper clippings. Seventy-ﬁve additional observations were included this
way. The addition of the choice-based observations did not change the DEMO
tion of observations across the overall ratings for the full 1976–1993 sample
( =6:39, d:f: =4, n.s.). Neither did DEMO addition of the choice-based obser-
vations change the distribution of observations across ratings for the 1989–1993
subsample ( =6:34, d:f: =4, n.s.). Given that there are no changes in the
underlying distribution of data with the addition of the choice-based observa-
tions, there will be no bias in regression parameter estimates, only a change in
the constant [33, pp. 90–91].
Authorized licensed use limited to: University of DEMO Downloaded on April 18, 2009 at 16:02 from IEEE Xplore.  Restrictions apply.
316
ÅSTEBRO: KEY SUCCESS FACTORS FOR TECHNOLOGICAL ENTREPRENEURS’ R&D PROJECTS 317
The projects in this sample typically represent rather modest
technological improvements. A plurality DEMO the projects are con-
sumer oriented (47%), most for household DEMO general con-
sumer use (28%), followed by sports and leisure DEMO
(15%). A list of successful inventions reviewed by the IAP DEMO
cludes a new milk container design, an impact absorbent mate-
rial DEMO into the back of a T-shirt for hockey players, a meat
DEMO tester, and a toilet tissue holder. However, there is
also a reasonable fraction of “high-tech” (6%), and industrial
equipment (6%) inventions [34], thus representing a broad cross
section of industrial applications. The same list includes an in-
dustrial-strength crusher of recycled cans, a new method for re-
pairing worn feed rolls in sawmills, a reusable plug to insert in
wooden hydroelectric poles after testing for rot, and a comput-
erized and mechanically integrated tree harvester. The concepts
submitted to the IAP DEMO review are at their stage of inception;
none has reached the marketplace, and they range in develop-
ment efforts from brief sketches to working prototypes. Some
are in the process of patenting, very few have already patented
their invention. It is fairly obvious from reading their descrip-
DEMO that the inventions are not radical. Since radial inventions
appear very seldom [35] and incremental innovations represent
the majority of all innovations [36] this DEMO is not an un-
common sample of inventions.
An overwhelming majority of respondents are male (89%)
and from the Province of Ontario (DEMO). A number of tests
were conducted to establish that the variation in sampling and
response proportions across the years of submissions, provinces
in Canada, gender, and rating were random: that is, no selection
DEMO were detected (for details contact the author).
There can be DEMO deﬁnitions of “project success” [37]. In
this study, the dependent variable DEMO deﬁned in the phone
survey as “Did you ever start to sell NAME or a later revised
or improved version of this invention?” DEMO ]. The
deﬁnition employed here is clear and easy to replicate across
studies, does not depend on a subjective evaluation, and is a
DEMO but not a sufﬁcient condition for ﬁnancial success.
A change in both the scaling of variables and variable com-
position in July 1989 unfortunately DEMO the deletion of
records prior to this date.5 The resulting analysis data set for
the period 1989–1993 consisted of 561 projects containing 499
failures DEMO 62 successes, large enough to comply with standard
requirements for multivariate DEMO [21].
The 37 criteria were graded on a three-point scale by the IAP,
i.e., A (Acceptable, which means that the criteria appears to be
favorable or satisfactory), B (Borderline, meaning the criteria
DEMO as B needs to be improved or strengthened), and C (DEMO
5The change in period covered and the inclusion of the choice-based sample
did not have a signiﬁcant effect on the distribution of the probability DEMO success.
A comparison of the distributions of both the absolute number of successes and
the proportion of successes across the ratings in the 1976–1993 DEMO and the
1989–1993 sample produced no signiﬁcant differences ( =7:78, d:f: =4,
n.s. and  =4:13, d:f: =4, n.s., respectively). Similar comparisons between
the 1989–1993 random sample DEMO the 1989–1993 sample augmented with the
choice-based observations produced no differences (DEMO =1:18, d:f: =4, n.s.
and  =4:07, d:f: =4, n.s., respectively.) However, the reduction in the
sample to cover only 1989–1993 resulted in a marginally signiﬁcant change in
DEMO distribution of total number of observations across the overall ratings ( DEMO
8:94, d:f: =4, p < 0:10). DEMO change reﬂects the increased learning at the
IAP.
weakness, meaning it DEMO be necessary to discontinue the effort
to commercialize the project.) For DEMO purpose of statistical anal-
ysis the scores on the underlying criteria were converted into
numerical data according to the following: , , and
. All variables are scaled so that a higher value is thought
to DEMO a higher technical and/or commercial value. Posi-
tive coefﬁcient estimates are, therefore, expected.
Because the analysts used a ﬁxed format for entering
DEMO on the criteria (a sheet where all criteria were listed)
DEMO were few missing observations. Nevertheless, lack of
data on approximately 43% DEMO the observations for one cri-
teria (“Service: Will this innovation require less servicing
or less costly servicing than alternatives?”) resulted in that
criteria being eliminated from further analysis. There were
108 missing observations among DEMO remaining 20 196 cells
( variables observations) representing 0.53%. These
missing DEMO were imputed to variables’ mean value.
While this work is not geared toward testing a priori hy-
potheses, it is nevertheless useful to examine whether the 36
criteria that will be analyzed have face validity for DEMO&D project
evaluation.
Three criteria relate to the potential technological improve-
ment of the invention. In addition, the outstanding development
cost, R&D DEMO, (technological) resource availability,
tooling, and production costs are assessed. These variables
might be grouped under the rubric “technological opportunity”
[36]. Three DEMO examine potential external constraints
such as safety concerns, environmental impacts, and legality.
Seven criteria consider various measures of demand, while ﬁve
additional criteria are the most well-known innovation char-
acteristics impacting the diffusion of innovations DEMO Price
is included, as well as two measures of current and DEMO
competition. Three additional cost measures follow, while one
criterion examines system DEMO issues. Appropriability
conditions [36] and various investment criteria (e.g., expected
return, payback time) are also considered. The variables have
face value. Except DEMO organizational aspects, they cover the
main groups of variables identiﬁed by DEMO and are particularly
detailed on technology and demand characteristics. All of the
36 criteria are covered in one way or another in the review DEMO
Balachandra and Friar [1].
IV. RESULTS
To determine the key success factors of R&D project
commercialization a logistic maximum-likelihood model for
a binary DEMO is estimated,6 starting with the exclusion
of all variables and where the most signiﬁcant variables are
successively included and for each inclusion the DEMO is
reestimated (so-called forward selection).7 A -value of 0.05 is
DEMO alternative link functions were explored: logit, probit, and gompit. All
DEMO generated qualitatively similar results.
7I experimented with other procedures and selection criteria to judge the ro-
bustness of results. The variables selected for inclusion DEMO identical using
a backward selection procedure with the exception of V23 (DEMO), which
was replaced by V2 (functional performance). V23 and DEMO are practically inter-
changeable in their deﬁnitions and have almost identical coefﬁcients. The model
with V23 was selected by tossing a coin. A forward DEMO with a p-level of
0.10 did not cause more variables to be included. The four key success factors
are, therefore, robust to the DEMO of the cutoff point for inclusion.
Authorized licensed use limited to: DEMO of Waterloo. Downloaded on April 18, 2009 at 16:02 from DEMO Xplore.  Restrictions apply.
318
IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT, VOL. 51, NO. 3, AUGUST 2004
used to determine the inclusion of variables. That is, the ﬁnal
model only contains predictors that are signiﬁcant at the 5%
level. The DEMO of using this method instead of retaining the
full model is that the resulting model is easier to understand
and relate to for a DEMO R&D manager. The method is also
consistent with the research tradition in this ﬁeld (for example,
[4]). Finally, if the DEMO is to be used in practice it is important
that it is robust and not overly sensitive to the data on which it
was DEMO The full model will likely fare less well in such
robustness tests as it takes into account the effect of a multitude
of mainly DEMO variables. The research method applied
here is geared toward generating a practically useful tool for
R&D project evaluation rather than to test a DEMO hypotheses.
Following the forward selection process four variables re-
main. These are, in decreasing order of statistical signiﬁcance:
40 (expected proﬁtability), DEMO (development risk), 35 (IP
protection), and 23 (function DEMO), with the following pa-
rameter estimates ( -values in parenthesis):DEMO
where the odds ratio of success.8 The model obtained a
psuedo . This model correctly predicts 444 out of the
561 projects (79.1%). The model correctly predicts 398 of the
499 failures (79.7%) and DEMO 46 of 62 successes correctly
(74.2%). Interestingly, the model is about equally adequate at
predicting successes as it is predicting failures while DEMO number
of successes is an order of magnitude less.
The size of the odds-ratio for 40 “expected proﬁtability” is
the largest. A one-unit increase DEMO the variable “expected prof-
itability” from “B”–borderline to “A–acceptable, means a DEMO
unit increase in the odds-ratio. The interpretation of this re-
sult is straightforward: “A”-rated inventions on “expected prof-
itability” have odds 3.1 times higher to reach the market than
“B”-rated inventions on “expected proﬁtability.” All four DEMO
ables come close to or surpass an odds-ratio of two, indicating
DEMO just signiﬁcant but also substantial effect sizes.
I further test the model’s accuracy using an out-of-sample for-
ward test. The data-set with 561 observations DEMO split in two,
the ﬁrst containing 383 projects that were evaluated between
1989 and 1992, and the second containing 178 projects evalu-
ated during 1993. A model is estimated on the 1989–1992 data
set. I DEMO analyze how well the coefﬁcient estimates from that
data predict the outcomes of projects evaluated during 1993.
This test is more demanding than a DEMO split-sample test
(used by Cooper [4]), since it requires the DEMO to be consis-
tent over time.
As expected, the model on DEMO subset of data from 1989 to
1992 is somewhat different from the model for the overall data
set. This model included only three signiﬁcant DEMO: the
two previous “expected proﬁtability” and “function” and the
additional “trend DEMO demand.” Most of the prediction power is,
8The “odds-ratio” is deﬁned as follows. The odds of an event are calculated
as the number (or probability) of events divided by the number (or probability)
DEMO nonevents. In this particular data set the mean odds of success are 62=499=
0:124. The odds of failure are, therefore, 8:1. DEMO odds ratio is calculated by
dividing the odds in the treated or exposed group by the odds in the control
group.
however, generated by “expected proﬁtability” and “function.”
As this model is optimized on a subset DEMO data, it is likely to
have lower classiﬁcation accuracy for the DEMO sample than
what the model for the complete data set would have. Neverthe-
less, the model correctly classiﬁed 80.9% of all out-of-sample
projects, DEMO correctly classifying 60.9% of the successes and
83.7% of the failures. In this test, the ability to correctly clas-
sify successes has deteriorated, DEMO the ability to correctly
classify failures has improved providing a minute increase in the
classiﬁcation accuracy. Clearly, the model has merit as a classi-
ﬁer when applied to new data.
The recommendation by the IAP is DEMO to have an impact on
whether the inventor continues or not [39]. There are two poten-
tial effects. The ﬁrst is that the advice DEMO shift the baseline odds
of commercialization by increasing the odds that a good project
is pursued and decrease the odds that a poor project DEMO pursued.
This effect has no impact on coefﬁcient estimates. Åstebro and
Chen [39] examine the magnitude of this “treatment” effect in
detail and ﬁnd DEMO it shifts the baseline probability of success
up (for positive advise) or down (for negative advise) on average
about two percent. The DEMO potential effect is that the evalu-
ation by the IAP may bias the relationship between the key suc-
cess criteria and outcomes, for example, by having an inventor
improve on certain key weaknesses singled out by the IAP. This
problem is difﬁcult to address with the available data DEMO gen-
erally requires complicated econometric models that often rests
on untestable assumptions (see, for example, [40]). To the ex-
tent possible, DEMO consider this issue using reduced-form models.
To investigate the potential bias in coefﬁcient estimates due
to the “treatment,” I ﬁrst examine the correlation DEMO the
underlying 36 criteria and the analysts’ overall rating of the
project, and compare the results with those obtained from the
previously estimated statistical model predicting commercial
success. If analysts use the appropriate predictors of commer-
DEMO success as identiﬁed by the statistical model, it is difﬁcult
to DEMO that they do not use the appropriate key success factors
when making their judgments.
To address the above comparison an ordinal logistic regres-
sion DEMO is ﬁtted using the overall recommendation as the
outcome variable. The recommendation has ﬁve values that
represents the advise given to the inventor and DEMO ordered from
“most promising” to “least promising” (for details, see [41]).
Using a -value of 0.05 to determine inclusion of predictors,
DEMO resulting model has a pseudo of 0.38 and contains 11 of
the possible 36 explanatory variables.9 With variables identical
in predicting commercial success and DEMO overall ratings
italicized, the variables predicting analysts’ recommendations
are, “expected proﬁtability,”“IP protection,”“technical fea-
sibility,”“development risk,”“potential sales,”“distribution,”
“size DEMO investment,”“function,”“appearance,”“legality,” and
“duration of demand.” This test shows that experts at the
IAP pay signiﬁcant attention to the variables indicated DEMO the
statistical model as most important in predicting commercial
success. However, DEMO also take into account other information
when making their overall recommendation.
9The same variables appear using either backward or forward variable
selection.
Authorized licensed DEMO limited to: University of Waterloo. Downloaded on April 18, 2009 at 16:02 from IEEE Xplore.  Restrictions apply.
ÅSTEBRO: KEY SUCCESS FACTORS FOR TECHNOLOGICAL ENTREPRENEURS’ R&D PROJECTS 319
A regression is then performed where the predicted value of
the overall recommendation DEMO inserted in the logistic regression
for predicting commercial success. The predicted value is gen-
erated from the previously estimated ordinal logit. If the experts
DEMO using the key success factors appropriately, one would ex-
pect that DEMO would be no remaining explanatory power of the
key success factors once the predicted overall recommendation
is included. To (statistically) identify the ﬁrst-stage DEMO in
the second stage, I include four dummy variables, one each for
the years 1990, 1991, 1992, and 1993, as well DEMO a dummy vari-
able for the location of the inventor, where DEMO value unity is
assigned if the inventor is located in the Province of Ontario
and zero, otherwise. These are likely to be independent of the
key success factors and are reasonable choices for identiﬁcation
purposes.
When DEMO the predicted overall recommendation in the
equation determining future commercial success and using a
variable inclusion criterion of 0.05 there are no other variables
DEMO The predicted overall recommendation generates a
pseudo of 0.24, which is DEMO percentage points greater than
the model with the four success criteria. The former and latter re-
gressions together suggest that the overall recommendation pro-
DEMO similar type of information as the four key success factors.
While I cannot parametrically investigate the potential degree
of bias that is produced by DEMO a reduced-form single-stage
model of the key success criteria, the above-performed DEMO
at least shows that the key success criteria are indeed impor-
tant predictors of the commercial success of these projects. The
out-of-sample test of DEMO model also conﬁrms this conclusion.
It should be noted that previous research on key success
factors has never investigated the problem of biased coefﬁcient
DEMO due to (management or other) intervention, although
such effects are DEMO to be rampant. Consider, for example,
Cooper’s study [4]. Project DEMO were asked to ﬁll out a
questionnaire for one successful and one unsuccessful project
ex post of project completion. The success and failure of DEMO
projects are a function not only of the characteristics at the
start of the projects but also of the management behavior and
resource allocations DEMO the projects’ duration. Projects
that may at an early stage be considered to be most promising
are likely to receive more managerial attention and DEMO
resources leading to a potential self-fulﬁlling prophecy. Any
statistical analysis of project success must take such effects
into account since the model of interest DEMO that which indicates
the likelihood of success before additional resources have been
allocated, not after.
V. DISCUSSION AND CONCLUSION
Recent literature on managing the innovation process has
been criticized for an undue focus on the process DEMO R&D
project selection, while not addressing the decision criteria
necessary DEMO select appropriate projects [6], [7]. I revisit the
fundamental question regarding DEMO key success factors, specif-
ically for early stage R&D projects DEMO by technological
entrepreneurs.
I examine the impact of a comprehensive set of 36 innova-
tion and product-market characteristics on the likelihood that an
R&DEMO project conducted by a technological entrepreneur will be
commercialized. These characteristics include several dimen-
sions of technological opportunity, competition, legal and so-
cietal DEMO, and nine dimensions characterizing user need
and market demand. The examined DEMO, while rea-
sonably comprehensive in their coverage of technical, market,
and commercial conditions, do not include any organizational
dimensions.
The research contributions are twofold: 1) this is the ﬁrst
statistical analysis on the DEMO of key success factors on the
commercial success for early stage R&D projects generated
outside of established organizations and 2) to the author’s
knowledge this is the ﬁrst large-scale study of key success
factors where DEMO methods biases are avoided: hindsight bias,
common method variance bias, and low statistical power.
A statistical model based on four underlying characteristics
DEMO assessed by project-independent analysts correctly predicts
80.9% of all outcomes in terms of reaching the market (or not)
in out-of-sample tests. The model is approximately equally able
to correctly classify both successful and unsuccessful ventures.
DEMO is an unexpected result as it implies that the model is able
to detect and appropriately use information in a highly multi-
variate setting DEMO there is a low signal-to-noise ratio and data
is highly uncertain. Its prediction accuracy is higher than R&D
department managers’ ability to predict DEMO technical success
of their own R&D projects, which was estimated DEMO Mansﬁeld
[42] to be 66%. The model is further at least twice as accurate
as seasoned VCs in the U.S. who have a maximum DEMO
accuracy of 40% for seed and early stage ventures [16].
The estimated model performs seemingly worse than that de-
rived by Cooper [4], which had a within-sample prediction ac-
curacy of 84.1%, but Cooper’s study suffers from four problems
which may inﬂate results. These are the following.
1) There is likely common method variance bias as data on
independent and DEMO variables were collected at the
same time, from the same person DEMO after the fact.
2) There is likely hindsight bias as subjects DEMO asked to se-
lect one successful and one unsuccessful project and then
to provide data that would explain outcomes. In such sit-
uations, subjects are likely to provided inﬂated causation
of outcomes [20].
3) There is potential for biased coefﬁcient estimates due to
(management or other) interventions DEMO Cooper’s study.
That is, while one is interested in how to DEMO the
impact of project characteristics on future success at the
screening stage, Cooper actually estimated the impact
of project success after management interventions. To
control for the effect of interventions it does not help
to merely DEMO subjects to recall project characteristics at
project origination. (It is also DEMO that such recalls
will be accurate.) What is needed is to: a) estimate the ef-
fects of early-stage characteristics on project outcomes in
the hypothetical absence of interventions and b) add the
marginal effect of management and other interventions
on outcomes. This paper showed that estimating such
DEMO models are possible and that in this case
the intervention had relatively little effect.
Authorized licensed use limited to: University of Waterloo. Downloaded on April 18, 2009 at 16:02 from IEEE Xplore.  Restrictions apply.
320
IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT, VOL. 51, NO. 3, AUGUST 2004
4) It is also not clear how well Cooper’s model performs
when used in actual decision situations as his test was
within-sample. The DEMO test used in this paper
is more critical than Cooper’s split-sample test and illus-
trates that the model is likely to perform well for DEMO
data sets than that which it was estimated on.
One should, DEMO, be clear of the limitations of this study.
The statistical model DEMO to what it has been calibrated
on: screening for market success DEMO seed and early stage R&D
projects conducted by technological entrepreneurs. The data
cover R&D projects with, typically, high uncertainty, low
probability of success, and small development costs. Further,
the projects are primarily “low-tech” and incremental. Nev-
ertheless, the obtained statistics implies a great improvement
over current practice in the screening of seed and early stage
R&DEMO investment proposals.
The four key criteria: expected proﬁtability, technological
opportunity (DEMO), technological uncertainty (development
risk), and appropriability conditions (IP protection) contain
no great surprises as past research has already identiﬁed these
characteristics (among 68 others). What is interesting is that
three variables provide additional explanatory power over and
beyond the “overall” estimate of expected returns. DEMO might
be two explanations that are not mutually exclusive. First,
analysts’ at the IAP fail to incorporate all available information
in their estimate DEMO expected returns through cognitive biases.
Second, analysts consider some variables to DEMO predictive of
technical and/or commercial success and consider others to be
determinants of ﬁnancial returns conditional on technical and
commercial success. Further research DEMO necessary to examine
these issues.
The results do not ﬁt Balachandra and Friar’s [1] suggestion
that technology factors are less important for incremental and
DEMO projects since the degree to which a project represents
a clear improvement over previous products and the degree to
which there is technological uncertainty DEMO with fur-
ther development are two out of four important determinants for
these projects.
What can other researchers learn from this study for future DEMO
search designs? It is certainly possible to replicate this study’s
design DEMO other samples. What seem to be critical ingredients
are: 1) a large sample of projects; 2) project screening criteria
measured at an DEMO stage; 3) data on key management inter-
ventions; and 4) a clear outcome variable. Studies of historical
project screenings within single ﬁrms DEMO venture capital ﬁrms
where records have been kept are likely to be better sources for
obtaining good data than the previous dominant research design
DEMO cross-ﬁrm post-outcome mail surveys.
An important distinction between the type of screening model
developed here and DCF analysis for project selection is that
a DEMO model with ordinal subjective ratings of key suc-
cess criteria is quite robust to the use of vague and nonﬁnan-
cial data. It is DEMO likely that high-quality data on the future
cash ﬂow stream exists at the very early stage. A scoring model
that uses a simple high/DEMO/low assessment of the expected
return and other criteria seems sufﬁcient to make an accurate
judgment in a ﬁrst-stage screen. A second-stage screen where
DEMO quality may be higher may use more elaborate ﬁnancial
models. Another important consideration that favors a statisti-
cally calibrated scoring model is that one DEMO much less interested
in the absolute value than the relative ranking of a project. That
is, as Wheelwright and Clark [43] illustrates, many DEMO
tions have more than enough projects to conduct and the R&D
organization is typically ineffective due to oversubscription of
resources. It is suggested DEMO an organization should, there-
fore, conduct a capacity planning exercise where low-ranking
projects are eliminated irrespective of the fact that eliminated
projects may DEMO reach a minimum ROI criterion. The applica-
tion of a simple scoring model to rank order projects would in
such instances be quite effective.
DEMO the underlying criteria are subjectively measured there
is some uncertainty regarding the transferability of the results
to practice. The results do not inform non-IAP DEMO how to
perform the subjective assessments of the four criteria. How-
ever, with some training by individuals knowledgeable about
the IAPs’ process it should nevertheless be possible to use such
a model by assessors at for DEMO VC ﬁrms focused on seed
and early stage investments. This is an area of application rea-
sonably related to the one investigated here. My DEMO rests
on the results by Einhorn [22] who shows that expert judg-
mental scores on predictors are useful in predicting outcomes
and Dawes et DEMO [23] who show that statistical models based on
judgmental scores perform better then experts’ judgmental pre-
dictions based on the same underlying judgmental scores. DEMO the
IAPs’ classiﬁcation accuracy is maintained by VCs using this
model it would suggest a doubling of the rate of return on VCs’
investments DEMO seed and early stage investments due to the im-
provement in screening ability.
As previously suggested, it is highly plausible that superior
statistical decision-support models can be constructed on his-
torical data in other investment decision DEMO It is obvious
that the key criteria may shift across situations. The author is
currently working together with a large VC fund to create DEMO sta-
tistical decision-support model for a later-stage fund. A statis-
tical problem that needs to be addressed is self-selection. Those
investments that received funding DEMO more likely to succeed
than those that did not due to the capital injection. As discussed
in this paper, there are statistical methods to control for this
effect.
ACKNOWLEDGMENT
The author would like to thank T. DEMO, K. Dahlin, and
S. Floricel for their comments and suggestions. This is a thor-
oughly revised version of a paper that received the DEMO Paper
Award, Runner Up, Canadian Council on Small Business and
Entrepreneurship Conference, 1999, and the Best Paper Award,
TIM Division, Administrative Sciences Association of Canada
Conference, 2003.
REFERENCES
[1] R. Balachandra and J. Friar, “Factors for success in R&D projects and
new product innovation: A contextual framework,” IEEE Trans. Eng.
Manage., vol. 44, pp. 276–87, Aug. 1997.
[2] M. J. Liberatore and G. J. Titus, DEMO practice of management science
in R&D project management,” Manage. Sci., vol. 29, pp. 962–74, 1983.
[3] W. E. Souder, “Utility DEMO perceived acceptability of R&D project se-
lection models,” Manage. Sci., vol. 19, pp. 1384–1394, 1973.
Authorized licensed use limited to: DEMO of Waterloo. Downloaded on April 18, 2009 at 16:02 from DEMO Xplore.  Restrictions apply.
ÅSTEBRO: KEY SUCCESS FACTORS FOR TECHNOLOGICAL ENTREPRENEURS’ R&D PROJECTS 321
[4] R. G. Cooper, “An empirically derived new product project selection
model,” IEEE Trans. Eng. Manage., vol. 28, pp. 54–61, 1981.
[5] S. L. Brown and K. M. Eisenhardt, “Product development – Past re-
search, present ﬁndings and future directions,” Acad. Manage. Rev., vol.
20, no. 2, pp. 343–378, 1995.
[6] R. G. Cooper, “Product innovation and technology strategy,” Res.
Technol. Manage., vol. 43, pp. 38–41, 2000.
[7] S. A. Murphy and V. Kumar, “The front end of new product develop-
ment: A Canadian survey,” R&D Manage., DEMO 27, pp. 5–15, 1997.
[8] E. Mansﬁeld, J. Rapaport, A. Romeo, E. Villani, S. Wagner, and
F. Husic, The Production DEMO Application of New Industrial Tech-
nology. New York: Norton, 1977.
[9] T. Åstebro, “Basic statistics on the success rate and proﬁts for techno-
logical entrepreneurs,” Entrepreneurship: Theory and Practice, vol. 23,
pp. DEMO, 1998.
[10] G. Lilien and E. Yoon, “Determinants of new industrial product per-
formance: A strategic reexamination of the empirical literature,” IEEE
Trans. Eng. Manage., vol. 36, pp. 3–10, 1989.
[11] M. M. Montoya-Weiss and R. Calantone, “‘Determinants of new product
performance’ a review and meta analysis,” J. Prod. Innov. Manage., vol.
11, pp. 397–417, 1994.
[12] M. Ozer, “A survey of new product evaluation models,” J. Prod. Innov.
Manage., vol. 16, pp. 77–94, 1999.
[13] D. H. Henard and D. M. Szymanski, “Why some new products are more
successful than others,” J. Marketing Res., vol. 38, pp. 362–375, 2001.
[14] J. D. Linton, S. T. Walsh, and J. Morabito, “Analysis, ranking and selec-
tion of R&D projects in a portfolio,” R&D Manage., vol. 32, no. 32, pp.
139–148, DEMO
[15] C. Zopounidis, “Venture capital modeling: Evaluation criteria for the
appraisal of investment,” The Financier ACMT, vol. 1, pp. 54–64, 1994.
[16] A. Zacharakis and D. Meyer, “The potential of actuarial decision
models: Can they improve the venture capital investment decision?,” J.
Bus. DEMO, vol. 15, pp. 323–46, 2000.
[17] M. A. Maidique and DEMO J. Zirger, “The new product learning cycle,” Res.
Pol., vol. 14, pp. 299–313, 1985.
[18] C. M. Yap and W. E. DEMO, “Factors inﬂuencing new product success
and failure in small entrepreneurial high-technology DEMO ﬁrms,”
J. Prod. Innov. Manage., vol. 11, pp. 418–432, DEMO
[19] D. T. Campbell and D. W. Fiske, “Convergent and discriminant DEMO
tion by the multi-trait-multi-method matrix,” Psych. Bul., vol. 56, pp.
81–105, 1959.
[20] B. Fischhoff, “Hindsight is not equal to foresight: The effect of outcome
knowledge on judgment under uncertainty,” J. Experimental DEMO:
Hum. Perception Perform., vol. 1, no. 3, pp. 288–299, 1975.
[21] N. Cliff, Analyzing Multivariate Data. San Diego, CA: Harcourt Brace
Jovanovich, 1987.
[22] H. Einhorn, “Expert measurement and mechanical combination,DEMO Orga-
nizational Behav. Hum. Perform., vol. 7, pp. 86–106, 1972.
DEMO R. M. Dawes, D. Faust, and P. E. Meehl, “Clinical DEMO actuarial judg-
ment,” Science, vol. 243, pp. 1668–74, 1989.
DEMO G. Markman, D. B. Balkin, and R. A. Baron, “Inventors DEMO new venture
formation: The effects of general self-efﬁcacy and regretful thinking,DEMO
Entrepreneurship: Theory and Practice, pp. 149–165, 2002.
[25] T. Åstebro, “The return to independent invention: Evidence of unreal-
istic optimism, risk DEMO or skewness loving?,” Econ. J., vol. 113, pp.
226–239, 2003.
[26] K. Dahlin, M. Taylor, and M. Fichman, “Today’s Edisons or Hobby-
ists?: Technical merit and success of inventions by technological DEMO
preneurs,” Univ. Toronto, Toronto, ON, Canada, Working Paper, DEMO
[27] G. Udell, “Invention evaluation services: A review of the state of the art,”
J. Prod. Innov. Manage., vol. 6, pp. DEMO, 1989.
[28] G. Udell, R. Bottin, and D. Glass, “The Wal-Mart innovation network:
An experiment in stimulating American innovation,” J. DEMO Innov.
Manage., vol. 10, pp. 23–34, 1993.
[29] R. Rosenthal DEMO R. Rosnow, Essentials of Behavioral Research:
Methods and Data Analysis, 2nd ed. New York: McGraw-Hill, 1991.
[30] K. G. Baker and DEMO S. Albaum, “Modeling new product screening deci-
sion,” J. Prod. DEMO Manage., vol. 3, no. 1, pp. 32–39, 1986.
[31] D. Dillman, Mail and Telephone Surveys: The Total Design
Method. New York: Wiley, 1978.
[32] P. J. Lavrakas, Telephone Survey Methods, 2nd ed. Newbury Park, CA:
Sage, 1993.
[33] G. S. Maddala, Limited Dependent and Qualitative Variables in Econo-
metrics. Cambridge, U.K.: Cambridge Univ. DEMO, 1983.
[34] “Annual Report,” Canadian Industrial Innovation Centre, Waterloo, DEMO,
Canada, 1996.
[35] M. Tushman and P. Anderson, “Technological discontinuities and or-
ganizational environments,” Admin. Sci. Quart., vol. 31, pp. DEMO,
1986.
[36] W. Cohen, “Empirical studies of innovative activity,” DEMO Handbook of
the Economics of Innovation and Technological Change, P. Stoneman,DEMO
Ed. Oxford, U.K.: Blackwell, 1995, pp. 182–264.
[37] R. G. Cooper and E. J. Kleinschmidt, “New products: What separates
winners from DEMO,” J. Prod. Innov. Manage., vol. 4, no. 3, pp. DEMO,
1987.
[38] E. M. Rogers, Diffusion of Innovations, 3rd ed. New York: Free Press,
1983.
[39] T. Åstebro and G. Chen, “A statistically validated method for selecting
early stage ventures,” in “What Next for Venture Capital and Private
Equity?” Conf., Toronto, ON, Canada, June 21–22, 2002.
[40] J. J. Heckman and E. J. DEMO, “Instrumental variables, selection
models, and tight bounds on the average DEMO effect,” Nat. Bureau
of Econ. Res., Cambridge, MA, Tech. DEMO Paper, 2000.
[41] T. Åstebro and Y. Gerchak, “Proﬁtable advice: DEMO value of information
provided by Canada’s inventor’s assistance program,” Econ. Innov. New
Technol., vol. 10, no. 1, pp. 45–72, 2001.
[42] DEMO Mansﬁeld, Industrial Research and Technological Innovation – An
Econometric Analysis. New DEMO: Norton, 1968.
[43] S. C. Wheelwright and K. B. Clark, DEMO project plans to focus
product development,” Harv. Bus. Rev., vol. DEMO, no. 2, pp. 70–83, 1992.
Thomas Åstebro received two degrees DEMO engi-
neering from Chalmers University of Technology,
Göteborg, Sweden, and the Ph.D. degree from
Carnegie Mellon University, Pittsburgh, PA
He is DEMO Associate Professor of Strategic Manage-
ment at the Joseph L. Roadman School of Manage-
ment, University of Toronto, Toronto, ON, Canada.
He DEMO research in the economics and manage-
ment of technological change and entrepreneurship
and has recently published in, among others, RAND
Journal of Economics, and the Economic Journal.He
is frequently invited by the ﬁnancial industry to DEMO speeches on how to assess
entrepreneurial ventures. He has consulted corporations such as Canadian Im-
perial Bank of Commerce, Bank of Montreal, FleetBoston, Skandia Insurance
Company, Nationale Nederlanden B.V., Volvo, and SKF, and DEMO such as
The Royal Swedish Academy of Engineering Sciences. He has taught manage-
ment of innovation in Canada, the U.S., Australia, Sweden, DEMO Italy, received 11
international and national awards and honors, is a cofounder of three start-ups,
is the recipient of numerous research grants, has published over 20 articles, and
made over 50 conference presentations.
Authorized licensed use limited to: University of Waterloo. Downloaded on April 18, DEMO at 16:02 from IEEE Xplore.  Restrictions apply.{1g42fwefx}