Annual Reviews
www.annualreviews.org/aronline
Ann.
Copyright
Rev. Psychol.
©
1977
1977.
by DEMO
28.’1-39
Reviews
Inc. All rights reserved
BEHAVIORAL.DECISION
THEORY1
Paul 2 Slovic, DEMO FischhoJf and Sarah Lichtenstein
Decision Research, Eugene, Oregon 97401
Behavioral
The
most
values and the manner which
is the aim
This
descriptive
the
DEMO
decision
disciplines, including
engineering, marketing,
less, the importance psychological
DEMO descriptive work.
superficial comparisons
now
prescriptive enterprise is being psychologized by challenges to the acceptability
the fundamental axioms of utility theory (140, 188, 256).
~This is the fourth survey of this topic to appear DEMO the Annual Review of Psychology. Its
predecessors were articles by Edwards (DEMO), Becker & McClintock (24), and Rapoport
Wallsten (226). The present review covers publications appearing between Janurary 1, 1971,
and December 31, 1975, with occasional exceptions.
ZSupport for this review was DEMO by the Advanced Research Projects Agency of the
Department of Defense and was monitored by the Office of Naval Research under Contract
No. N00014-76-0074 (ARPA Order No. 3052) under subcontract to Oregon Research Insti-
tute from Decisions and Designs, Inc.
We wish to thank Barbara Combs, Robyn DEMO, Lewis R. Goldberg, and Jerry LaCava
for their comments on an early draft of the manuscript.
Nancy Collins and Peggy Roecker have earned DEMO gratitude and respect for handling an
arduous secretarial job with competence and good humor. 1
decision
normative
closely to the decision
of descriptive
review
DEMO of judgment,
development of
we reviewed
making is
Whereas
between
the psychological
focuses
on
theory
theory is concerned
maker’s
individuals incorporate
decision
is DEMO
inference, and
decision-aiding
the literature, several trends caught
being
medicine,
and management
concepts
past descriptive studies consisted mainly
actual behavior
underpinnings of DEMO
studied
~265
has two
with
beliefs and
them
into their decisions
theory.
around
choice;
the second
section
discusses
techniques.
by researchers
economics,
DEMO
our attention. One
an increasingly
diverse
is that
set of
interrelated facets, normative
prescribing courses
these two
values.
and
of action that conform
Describing these beliefs and
faceis. The
first section deals with
descriptive.
education,
DEMO, as well as psychology.
is increasing, in both
and normative
models,
behavior.
political science,
geography,
Neverthe-
the normative
of rather
DEMO
Likewise,
the
of
in
of
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. DEMO personal use only.
Annual Reviews
www.annualreviews.org/aronline
2
SLOVIC, FISCHHOFF
& LICHTENSTEIN
Second, increasing DEMO is being devoted to the development of practical methods
for helping people cope with uncertainty. Here psychological research provides
guidance about how to elicit DEMO judgments needed for decision-aiding techniques.
Third, the field is growing rapidly, as evidenced by the numerous reviews and
bibliographies produced during the past DEMO years. Slovic & Lichtenstein (254) re-
viewed the literature on Bayesian and regression approaches to studying informa-
tion processing in decision making and DEMO; Dillon (73) covered utility theory
with a view towards its DEMO in agricultural contexts; MacCrimmon (187)
examined work in management decision making; Shulman & Elstein (247) discussed
the implications of judgment and decision making research for teachers; Nickerson
& Feehrer (209) searched for studies relevant to the training of decision makers
(since there aren’t many, they settled for a general review); Beach (21a) reviewed
research about experts’ judgments under uncertainty; Vlek & Wagenaar (292) sur-
veyed the entire field, and Kozielecki (157) and Lee (165) have provided its first
textbooks.
A selective and annotated bibliography on Behavioral Decision DEMO has been
compiled by Barton (18). Kusyszyn (161, 162) has provided bibliographies covering
the psychology of gambling, risk-taking, and subjective DEMO Houle (124) has
accumulated a massive bibliography on Bayesian statistics and related behavioral
work, which by 1975 included 106 specialized books, 1322 DEMO articles, and
about 800 other publications. By the time you read DEMO, Kleiter, Gachowetz &
Huber (153) will have assembled the DEMO complete bibliography ever in this field.
They generously supplied us with more than 1000 relevant references, all produced
between 1971 and 1975.
To ease cognitive strain (and stay within sight of our page allotment), we have
focused on psychological aspects of individual judgment and decision making. Thus
DEMO omit group and organizational decision making, Bayesian statistics, and much
of the work on the axiomatic formulations of decision theory. Game theory is
DEMO elsewhere in this volume. Even with this narrow focus, we have DEMO to limit
our coverage severely, concentrating on those references to which DEMO prejudices
have led us.
DESCRIPTIVE
RESEARCH
Probabilistic
Judgment
Because
able effort has been devoted to studying how
the probabilities of uncertain events. Early research DEMO "intuitive statistics"
Peterson & Beach (218) to an optimistic DEMO:
of the importance of probabilistic reasoning to decision making, consider-
DEMO perceive, process, and evaluate
led
... man
infer the states of his uncertain
ments
normative
inference.
ate directions
gambles
environment and to
that DEMO
model
Inferences made by subjects
(pp. 42-43).
well. He
survives
DEMO
provides a good
human
and
predict
inferences with
first approximation
are influenced
prospers
while
future events
those of statistical man
for a psychological theory DEMO
appropriate
by
using ... fallible information
(p. 29). Experi-
show DEMO the
variables
in appropri-
to
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For DEMO use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION THEORY 3
MODEL-BASED PARADIGMS One result DEMO this high regard for our intellectual
capability has been a reliance on normative models in descriptive research. Thus
Barclay, Beach & Braithwaite (15) proposed beginning with a normative model and
adjusting its form or parameters DEMO produce a descriptive model. This approach is
best exemplified by the study of conservatism--the tendency, when integrating
probabilistic information, to produce posterior probabilities DEMO the prior
probabilities than those specified by Bayes’ theorem. In 1971, DEMO was
identified as the primary finding of Bayesian information integration research (DEMO).
Reports of the phenomenon have continued to appear, in tasks DEMO normally
distributed populations (75, 290, 305), and in that DEMO favorite, the binomial (book-
bag and poker chip) task (3, 196). Even filling the bookbags with male and female
Polish surnames fails to lessen the effect (261). Donnell & DuCharme’s (75) subjects
became optimal when told the normative response, but when the task changed, their
learning failed to generalize. As the next section shows, DEMO occurs only
in certain kinds of inference tasks. In a variety of other settings, people’s inferences
are too extreme.
Cascaded inference Real-life problems often have several stages, with inferences
at each stage relying on data which are themselves inferences from unreliable
observations or reports. For example, a physician who uses the condition of the
patient’s lungs as a cue for DEMO must first infer that condition from unreliable
data (e.g. the sound DEMO a thumped chest). Several normative models for such cas-
caded or multistage inference tasks have been developed in recent years (217, 238)DEMO
Schum (239) has shown the relevance of cascaded inference models to the judicial
problem of witness credibility and the probative value of witness DEMO
Descriptive studies of cascaded inference, comparing subjects’ responses in the
laboratory DEMO a normative model, have consistently shown a result just the oppo-
DEMO of conservatism: subjects’ posterior probabilities are more extreme than those
prescribed DEMO the model (100, 217, 266). The extremity of subjects’ DEMO has
been traced-to their use of a simple, but inappropriate, "DEMO" strategy (103,
137, 257, 266), which is insensitive to data unreliability.
HEURISTICS AND BIASES In these recent studies of conservatism DEMO cascaded
inference, one can see an increasing skepticism about the normative DEMO ability
to fulfill its descriptive role, and the view of humans DEMO intuitive statisticians
is no longer paramount. A psychological Rip van Winkle who dozed off after
reading Peterson & Beach (218) and roused himself DEMO recently would be startled
by the widespread change of attitude exemplified by statements such as "In his
evaluation of evidence, man is apparently DEMO a conservative Bayesian: he is not
Bayesian at all" (138, p. 450), or "... man’s cognitive capacities are not adequate
for the tasks which confront him" (114, p. 4), or "DEMO people systematically violate
the principles of rational decision making when judging probabilities, making
predictions, or otherwise attempting to cope with probabilistic tasks" (DEMO, p.
169).
Van Winkle would be further surprised to see DEMO (114) and Dawes (69)
putting information-processing deficiencies on a DEMO with motivational conflicts as
as
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For DEMO use only.
Annual Reviews
www.annualreviews.org/aronline
4
causes
geographers, statisticians, and others being DEMO on the implications
intellectual shortcomings (14, 121a, 248, 249, DEMO, 282).
In 1971,
tenstein (254)
processing heuristics. Since then, rather than simply comparing
normative
attempted
interaction between
Much the impetus
(138, 139, 284-286)
ness, availability and anchoring--which
variety
lead DEMO biases
making.
Judgment by representativeness What
class A? Or what
& DEMO (138) hypothesized
essential features of A and
the degree to which
an outcome is
probability is judged
Several lines of evidence support this DEMO Tversky
demonstrated a belief in what
small samples are viewed
they are drawn.
mate the error and unreliability inherent in small samples
Tversky (138) showed
probability estimates were
psychologically nonrepresentative factor. In a subsequent paper, DEMO &
Tversky (139) demonstrated
principles in ways that can be DEMO to representativeness biases. For one,
representativeness causes
tions tend not to be properly
reliability.
Judgment by availability Other judgmental biases are due to DEMO of the "availabil-
ity" heuristic (285) whereby event is judged likely or frequent if it is easy
imagine or recall relevant instances. DEMO life, instances of frequent events are typically
easier to recall than DEMO of less frequent events, and likely occurrences are
usually easier to DEMO than unlikely ones. Thus availability is often a valid cue
for the assessment frequency and probability. However, since availability is also
affected by subtle factors unrelated to likelihood, such as familiarity, recency, and
emotional saliency, reliance on it may result in systematic biases.
is the probability that object B belongs
is the probability that process A will generate event DEMO?
of B
B
highly
to be high.
&
they called "the law of small numbers,"
as highly representative of the populations from
This belief led their subjects, research
of
an
that people answer
and
is "representative"
representative
to
Kahneman
such questions by examining
of similarity between
is very
which it originates, then its
Kahneman
whereby
which
psychologists, to underesti-
of data. Kahneman &
that both subjective sampling
DEMO to sample size, a normatively important but
that people’s intuitive predictions DEMO normative
prior probabilities to be neglected.
regressive, being
insensitive
For
to DEMO
another, predic-
of data
assessing
of A.
of the process
the DEMO
When B
from
the
them,
similar to A, as when
(284)
even
distributions and posterior
SLOVIC,
FI$CHHOFF & LICHTENSTEIN
of DEMO ills that plague
humanity,
and
models,
to determine
how
the literature on
of studies
of tasks. Although
always
that are large, persistent,
when
found
reviewing
to see financial analysts, accountants,
of these
probabilistic inference, Slovic
that looked
behavior with
almost every descriptive study of probabilistic thinking has
the underlying
the demands the task and the limitations DEMO the thinker.
for this change
demonstrations of three
determine
efficient, and
DEMO
only
a handful
&
at subjects’ information-
cognitive processes are molded
DEMO the
can be attributed to Tversky
judgmental
at times
serious
&
DEMO
probabilistic judgments
valid, these heuristics can
in their implications
Kahneman’s
in DEMO
for decision
Lich-
of
of
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For DEMO use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION THEORY 5
Judgment by adjustment Another DEMO heuristic is "anchoring and adjust-
ment." With this process, a DEMO starting point or anchor is used as a first
approximation to the judgment. The anchor is then adjusted to accommodate the
implications of additional DEMO Typically, the adjustment is imprecise and
insufficient (248). Tversky & Kahneman (286) showed how anchoring and adjust-
ment could cause the DEMO narrow confidence intervals found by many investiga-
tors (175) and the tendency to misjudge the probability of conjunctive and
disjunctive events (16, DEMO, 317).
Related work Numerous studies have replicated and extended the DEMO &
Tversky studies, and others have independently arrived at similar conclusions. The
representativeness heuristic has received the most attention. Wise & Mockovak
(310), Bar-Hillel (17), and Teigen (278, 279) have documented DEMO importance
similarity structures in probability judgment. Like Kahneman & Tversky (138),
Marks & Clarkson (191, 192) and Svenson (271) observed that subjects’ posterior
probabilities in binomial bookbag and poker chip tasks were DEMO in-
fluenced by the most representative aspect of the sample, the DEMO of red chips.
Contrary to the normative model, population proportion and DEMO size were
relatively unimportant. Leon & Anderson (166) did find an influence of these two
characteristics and, as a result, claimed that DEMO Tversky’s subjects must
have misunderstood the task. Ward (302), however, argued that the conflicting
results were most likely due to differences in DEMO tasks, rather than to misinterpreta-
tion of instructions. Hammerton (113), Lyon & Slovic (184), Nisbett & Borgida
(210), and DEMO & Nisbett3 have replicated Kahneman Tversky’s finding that
subjects neglect population base rates when judging the probability that an individ-
ual belongs to a DEMO category. Nisbett & Borgida argued that this neglect stems
in part from the abstract, pallid, statistical character of base-rate information. They
found that DEMO, case-specific information, even from a sample of one, may have
DEMO greater importance, a rather dramatic illustration of the law of small DEMO
Additional evidence for representativeness comes from studies by Brickman &
Pierce (45), Holzworth & Doherty (123), Bauer (20, 21), and Lichtenstein, Earle
Slovic (173).
Availability and anchoring have been DEMO less often. Evidence of availability
bias has been found by Borgida & Nisbett 3 and Slovic, Fischhoff & Lichtenstein
(252). Anchoring has DEMO hypothesized to account for the effects of response mode
upon bet preferences (176, 177), and it has been proposed as a method DEMO people
use to reduce strain when making ratio judgments (106). DEMO (219) gave the anchor-
ing heuristic a key role in his model describing how people create subjective proba-
bility distributions for imperfectly known (uncertain) quantities.
Overconfidence The evidence presented above suggests that the heuristic selected,
the way it is employed, and the accuracy of the judgment it produces are all highly
problem-specific; they may even vary with different representations of the same
~E. Borgida & R. E. Nisbett. Abstract vs. DEMO information: The senses engulf the mind.
Unpublished, University of Michigan, DEMO
&
&
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use DEMO
Annual Reviews
www.annualreviews.org/aronline
6 SLOVIC, FISCHHOFF & LICHTENSTEIN
problem. Indeed, DEMO may be faulted as a general theory of judgment because
of the difficulty of knowing which will be applied in any particular instance.
There DEMO, however, one fairly valid generalization that may be derived from this
literature. Except for some Bayesian inference tasks, people tend to be overconfident
in their judgments. This may be seen in their nonregressive predictions (139), in their
disregard for the extent of the data base upon DEMO their judgments rest (138),
its reliability (217), and DEMO the miscalibration of their probabilities for discrete and
continuous propositions (175)DEMO Howell (128) has repeatedly shown that people
overestimate their own abilities on tasks requiring skill (e.g. throwing darts). Langer
(163) dubbed this effect "the illusion of control" and demonstrated that it can
DEMO by introducing skill factors (such as competition and choice) into chance
situations.
In a task that had people estimate the odds that they DEMO been able to select the
correct answer to general knowledge questions, DEMO, Fischhoff & Lichtenstein
(251) found that wrong answers were often DEMO with certainty. Furthermore,
subjects had sufficient faith in their odds that they were willing to participate in a
gambling game that punished them DEMO for their overconfidence.
How do we maintain this overconfidence? One possibility DEMO that the environment
is often not structured to show our limits. Many decisions we make are quite
insensitive to errors in estimating what we DEMO (utilities) or what is going to happen
(probabilities)--so that DEMO in estimation are hard to detect (294a). Sometimes
receive no DEMO at all. Even when we do, we may distort its meaning DEMO exagger-
ate our judgmental prowess, perhaps convincing ourselves that the outcome DEMO got
was what we really wanted. Langer & Roth (164) found that subjects who experi-
enced initial successes in a repetitive task overremembered DEMO own past successes.
Fischhoff & Beyth (93) found that people asked to recall their own predictions about
past events remembered having assigned higher DEMO to events that later
occurred than was actually the case. Fischhoff (DEMO) also found that people (a)
overestimate the extent to which they would have been able to predict past events
had they been DEMO to do so, and (b) exaggerate the extent to which DEMO should
have been able to predict past events. These hindsight biases are further evidence
of overconfidence for they show that people have inordinately high DEMO of their
own predictive abilities.
Descriptive theories Most of the research on heuristics and biases can be considered
pretheoretical. It has documented the descriptive DEMO of the normative
model and produced concepts such as representativeness and anchoring that may
serve as the bases for new descriptive theories. Although theory DEMO has
been limited thus far, efforts by Wallsten (300, 301) and Shanteau (243, 244)
produce descriptive algebraic models are noteworthy. DEMO approach is based
upon the averaging model of Anderson’s integration theory (DEMO). Wallsten’s model,
formulated and tested within the framework of conjoint measurement, assumes that
limited capacity causes people to process dimensions of information sequentially and
weight them differentially, according to their salience.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on DEMO/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION THEORY 7
Choice
In their introduction DEMO two volumes on contemporary developments in mathemati-
cal psychology, Krantz et DEMO (159) explained their exclusion of the entire area
preferential choice as follows:
There is no lack whatever of technically excellent papers in DEMO area but they give no sense
of any real cumulation of knowledge. What are established laws of preferential choice
behavior? (Since three of DEMO editors have worked in this area, our attitude may reflect
some DEMO of our own frustration) (p. xii).
This sense of frustration is understandable when one reviews recent research on
choice. The field is DEMO a state of transition, moving away from the assumption that
choice DEMO is expressable as a monotone function of the scale values or
utilities of the alternatives. Present efforts are aimed at developing more detailed,
DEMO concepts that describe choice in terms of information-processing phenom-
ena. Researchers appear to be searching for heuristics or modes of processing
information that are DEMO a wide domain of subjects and choice problems.
However, they are DEMO that the nature of the task is a prime determinant of the
observed behavior.
ELIMINATION BY ASPECTS One major new choice theory is Tversky’s (280, 281)
elimination-by-aspects (EBA) model. The model describes choice as a covert se-
quential elimination process. Alternatives are viewed as sets of DEMO (e.g. cars
described by price, model, color, etc). At each stage in the choice process an aspect
is selected with probability DEMO to its importance; alternatives that are
unsatisfactory on the selected aspect DEMO eliminated. Tversky showed that the EBA
model generalizes the models of Luce (183) and Restle (228) while avoiding
of the counter-examples to DEMO these earlier models are susceptible. Searching for
even broader applicability, Corbin & Marley (62) proposed a random utility model
that includes the EBA model as a special case. Other models built around the
concept of DEMO elimination of alternatives have been developed by Hogarth
(121, 122) DEMO Pollay (220).
PROCESS DESCRIPTION Most recent empirical research has been DEMO with
describing the decision maker’s methods for processing information before choos-
ing. Whereas earlier work focused on external products (e.g. choice proportions and
rankings) and used rather simple methods, process-descriptive studies must employ
more complex DEMO for collecting and analyzing data. Thus we find a return
to introspective methods (28, 199, 272) in which subjects are asked to DEMO aloud
as they choose among various multiattribute alternatives. Bettman & Jacoby (DEMO)
and Payne (214) supplemented the think-aloud procedure by requiring subjects
seek information from envelopes on an "information board." Russo & Rosen (231)
used eye-movement data conjointly with verbal protocols. Onc goal of DEMO studies
is to represent the choice process graphically as a tree or network (discrimination
net) of successive decisions. Swinth, Gaumnitz & Rodriguez (DEMO) developed
to
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by DEMO Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
8 SLOVIC, FISCHHOFF & LICHTENSTEIN
method of controlled introspection that enables subjects to build and validate their
own discrimination nets. DEMO (27) showed how to describe such nets via graph-
theoretical concepts. Uneasy about the subjectivity of introspective techniques,
Hogarth (121) used DEMO ingenious blend of theory and empiricism to develop
computer algorithm that builds the tree without recourse to subjective inputs.
Can introspective methods be trusted? Nisbett & Wilson4 reopened an old debate
by arguing that people lack DEMO of the factors that affect their judgments.
After documenting this claim with results from six experiments, they concluded that
"Investigators who are inclined DEMO place themselves at the mercy of such [introspec-
tive] reports.., would DEMO better advised to remain in the armchair" (p. 35). While
important, this criticism may be overstated. Students of choice have in many in-
stances validated their introspective reports against theoretical predictions (199) and
DEMO from other sources5 (see also 214).
What do these methodologies DEMO us about choice? First they indicate that sub-
jects use many DEMO and strategies enroute to a decision. These include conjunctive,
disjunctive, DEMO and compensatory rules, and the principle of dominance
(274). A typical choice may involve several stages, utilizing different rules at differ-
ent junctures. Early in the process, subjects tend to compare a number of alternatives
on the same attribute and use conjunctive rules to reject some DEMO from
further consideration (26, 214, 245, 272). Later they appear to employ compensa-
tory weighting of advantages and disadvantages on the DEMO set of alternatives
(214). Features of the task that complicate DEMO decision, such as incomplete data,
incommensurable data dimensions, information overload, time pressures, and many
alternatives seem to encourage strain-reducing, noncompensatory strategies (214,
255, 313, 314). Svenson (272) and Russo & Rosen (231) found subjects reducing
memory load by comparing two DEMO at a time and retaining only the better
one for later comparisons. Russo & Dosher5 observed simple strategies, such as
counting the number of dimensions favoring each alternative or ignoring small
differences between alternatives on a DEMO dimension. In some instances, these
strategies led to suboptimal choices.
In DEMO, people appear to prefer strategies that are easy to justify and DEMO not
involve reliance on relative weights, trade-off functions, or other numerical compu-
tations. One implication of this was noted by Slovic (250), whose subjects were
forced to choose among pairs of alternatives that were DEMO in value for them.
Rather than choose randomly, subjects consistently followed DEMO easy and defensible
strategy of selecting the alternative that was superior on the more important dimen-
sion.
SCRIPT PROCESSING Abelson’s (1) new approach DEMO explaining decisions war-
rants further study. It is based on the concept of a "cognitive script," which is a
4R. E. Nisbett & T. D. Wilson. ‘4wareness of factors influencing one’s own evaluations,
judgments, and behavior. Unpublished, University of Michigan, 1976.
~J. E. Russo & DEMO A. Dosher. Dimensional Evaluation: .4 heuristic for binary choice. Unpub-
lished, University of California, Santa Barbara, 1975.
Annu. Rev. Psychol. 1977.28:1-39. DEMO from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL
DECISION THEORY
9
coherent sequence of events DEMO by the individual on the basis of prior learning
or experience. When faced with a decision, individuals are hypothesized to bring
relevant scripts into play. For example, Candidate Y’s application for graduate
school may be rejected because Y reminds the decision maker of Candidate X who
was accepted DEMO failed miserably. Another script might assimilate the candidate
into a category (DEMO one of those shy types who does well in courses, but DEMO
have enough initiative in research). Script theory, though still in DEMO highly speculative
stage, suggests a type of explanation for choice that DEMO thus far been overlooked.
CONSUMER CHOICE Much research on choice has been done within the domain
of consumer psychology. Comprehensive reviews of this research DEMO been pro-
vided by Jacoby (134, 135). Although some of this work is application of multiple
regression, conjoint measurement, and analysis DEMO variance to describe consumers’
values (30, 107, 312), many DEMO studies have investigated basic psychological
questions. For example, one major issue DEMO been the effect of amount and display
of information on the optimality of choice. Jacoby and his colleagues have argued
that more information is DEMO necessarily helpful, as it can overload consumers and
lead them to DEMO suboptimal products. Russo, Krieser & Miyashita (230) observed.
that subjects DEMO great difficulty finding the most economical product among an
array of different prices and packages. Even unit prices, which do the arithmetic for
the consumer, had little effect on buyer behavior when posted on the shelf below
each product. However, when prices per unit were listed in order from high to low
cost, shoppers began t o buy less expensive products.
Models of Risky Choice
Decision making under conditions of risk has DEMO studied extensively. This is
probably due to the availability of (a) an appealing research paradigm, choices
among gambles, and (b) a DEMO normative theory, the subjectively expected
utility (SEU) model, against which behavior can be compared. The SEU model
assumes that people behave as DEMO they maximized the sum of the products of
utility and probability.
Early studies of the model’s descriptive adequacy produced conflicting results.
Situational and task DEMO were found to have strong effects, leading Rapoport
& Wallsten (226) to observe that a researcher might accept SEU with one set of bets
and reject it with another, differently structured set. Proponents of the SEU model
point out that it gives a good global fit to DEMO data, particularly for simple
gambles.6 In addition, certain assumptions of the model, like the independent (mul-
tiplicative) combination of probabilities and payoffs, have been verified for simple
gambles (244, 299).
However, DEMO the .past 5 years, the proponents of SEU have been greatly
DEMO by its critics. Coombs (60) has argued that risky choice is determined
not by SEU, but by a compromise between maximization of expected value (EV)
6B. Goodman, Saltzman, W.
gambles
in a casino
Edwards & D. Krantz. Prediction of bids for two-outcome
setting. Unpublished, 1976.
M.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council DEMO Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
l0
SLOVIC,
FISCHHOFF &
LICHTENSTEIN
and optimization of risk. He proposed an alternative to SEU, "portfolio theory,"
in which risk preferences play a central role. That role is illustrated DEMO a study by
Coombs & Huang (61) in which gamble B was constructed as a probability mixture
of two other gambles, A and C. Many subjects preferred gamble (with its interme-
diate risk level) DEMO gambles A and C, thus violating a fundamental axiom of SEU
DEMO
Zagorski (318) demonstrated a result that appears to violate SEU and many other
algebraic models as well. Zagorski’s subjects were shown pairs of DEMO (A, B)
and were asked to judge the amount of money (A-B) that would induce them
trade the better gamble (A) for the worse gamble (B). He demonstrated that
can construct DEMO of gambles A, B, C, and D such that
(A-B)
d- (B-C) ;~ (A-D) q-
In other words, DEMO independence is violated. The difference between gambles A
and C depends on whether the intermediate gamble is B or D.
A favorite approach of DEMO critics is to develop counterexamples to the funda-
mental axioms of the theory. The paradoxes of Allais (4) and Ellsberg (85) are
DEMO the most famous, both designed to invalidate Savage’s (232) independence DEMO
ple. Until recently, few theorists were convinced. MacCrimmon (185) showed DEMO
business executives who violated various axioms could easily be led, via DEMO,
to see the error of their ways. However, Slovic & DEMO (256) challenged Mac-
Crimmon’s discussion procedure on the grounds that it pressured the subjects to
accept the axioms. They presented subjects with arguments DEMO and against the
independence axiom and found persistent violations, even after DEMO axiom was
presented in a clear and presumably compelling fashion. Moskowitz (DEMO) used
variety of problem representations (matrix formats, trees, and verbal presentations)
to clarify the principle and maximize its acceptability, yet still found that the
independence axiom was rejected. Even MacCrimmon’s faith in many DEMO the key
axioms has been shaken by recent data (see 188), leading him to suggest that
reevaluation of the theory is in order.
Kahneman & Tversky (140, 283) attempted this sort of reevaluation, DEMO
evidence for two pervasive violations of SEU theory. One, the "certainty effect,"
causes consequences that are obtained with certainty to be valued more than uncer-
tain consequences. The Allais paradox may be due to DEMO effect. The second, labeled
the "reference effect," leads people to evaluate alternatives relative to a reference
point corresponding to their status quo, adaptation level, or expectation. By altering
the reference point, formally equivalent DEMO of the same decision problem may
elicit different preferences. These effects pose serous problems for the normative
theory and its application.
Payne (213) DEMO replacing the SEU model with information processing
theories that describe how probabilities and payoffs are integrated into decisions. He
presented a "contingent process" DEMO to describe the sequential processes in-
volved in choice among gambles. For support, he cited a number of display and
response-mode effects that are due to processing difficulties (176, 177, 179, 215).
B
DEMO Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION THEORY 11
Kozielecki’s (158) discussion DEMO the internal representation of risky tasks carried
similar message.
Kunreuther (160) has argued that utility theory would be of little value to a DEMO
maker trying to predict how people would respond to various flood or earthquake
insurance programs. First, the theory makes predictions that are not borne out by
actual behavior--for example, that people will prefer policies with high deductibles
or that subsidizing premiums will increase insurance purchasing. Second, it gives
no guidance about the social, situational, and cognitive factors that are DEMO to
influence insurance purchase. Like Payne, Kunreuther called for an alternative
DEMO, founded on the psychology of human information processing, and presented
a model of his own to support his case.
Readers interested in additional DEMO on the. staggering SEU model should
consult Barron & MacKenzie (19), Davenport & Middleton (66), Fryback, Good-
man & Edwards (DEMO), Ronen (229), and Svenson (273).
Regression Approaches
The regression paradigm uses analysis of variance, conjoint measurement, and
multiple regression DEMO to develop algebraic models that describe the method
by which individuals weight and combine information.
INTEGRATION THEORY Working within the framework of "information inte-
gration theory," Anderson and his colleagues have shown that simple algebra!c
DEMO describe information use quite well in an impressive variety of judgmental,
decision making, attitudinal, and perceptual tasks (6, 7). These DEMO typically
have revealed stimulus averaging, although some subtracting and multiplying has
DEMO observed. Particularly relevant to decision making are studies of risk taking
and inference (244), configurality in clinical judgment (5), intuitive statistics (167,
168), preference for bus transportation (210a), and judgment in stud poker (181).
There is no doubt that algebraic models derived from Anderson’s techniques provide
good surface descriptions of judgmental processes. However, as Graesser & Ander-
son (106) have observed, establishment of an algebraic model is only the first step
towards disclosing the underlying cognitive DEMO, which may be rather
different from the surface form of the DEMO
POLICY CAPTURING Another form of the regression paradigm uses correlational
statistics to provide judgmental models in realistic settings. The most systematic
development of these DEMO has been made by Hammond and his colleagues
(117) within "DEMO judgment theory." This theory assumes that most judgments
depend upon a DEMO of thought that is quasi-rational, that is, a synthesis of analytic
and intuitive processes. The elements of quasi-rational thought are cues (attributes),DEMO
their weights, and their functional relationships (linear and nonlinear) to DEMO the
environment and the judge’s responses. Brunswik’s lens model and multiple regres-
sion analysis are used to derive equations representing the judge’s cue utilization
DEMO Judgmental performance is analyzed into knowledge and "cognitive con-
trol," DEMO latter being the ability to employ one’s knowledge consistently (118).
DEMO Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
12 SLOVIC, FISCHHOFF & LICHTENSTEIN
By 1971 it was evident that linear models could describe college students’ cue-
weighting policies DEMO a wide variety of laboratory tasks (254). During the past
DEMO, such models have been used with similar success to analyze complex DEMO
world judgments. Judges in these studies have included business managers (119, 193,
201, 202), graduate admissions committees (68, 237), auditors, accountants,
loan officers (13, 172, 315), military DEMO (277), literary critics (84), and
hatchery empl6yees (182), as they attempted to predict business failures and stock
market performance, DEMO graduate students, plan work force and production
schedules, evaluate accounting procedures, Air Force cadets, and theatrical plays,
and recommend trout streams. DEMO United States senators have been modeled and
their roll-call votes predicted (DEMO). As in the laboratory studies, linear equations
have accounted for DEMO of the predictable variance in these complex judgments.
The coefficients of these equations have provided useful descriptions of the judges’
cue-weighting policies and have DEMO the sources of interjudge disagreement
and nonoptimal cue use.
While policies were being captured in the field, other researchers were deepening
our understanding of the models. Dawes & Corrigan (70) observed that linear
models have DEMO been applied in situations in which (a) the predictor variables
are monotonically related to the criterion (or can be easily rescaled to be mono-
tonic), and (b) there is error in the independent DEMO dependent variables. They
demonstrated that these conditions insure good fits by linear models, regardless of
whether the weights in such models are optimal. Thus the linearity observed in
judges’ behaviors may be reflecting only a characteristic DEMO linear models, not a
characteristic of human judgment.
In other work, theoretical and methodological refinements of the lens model have
been developed by DEMO (52, 53) and Stenson (267). Cook (59) and Stewart
Carter (268) have worked towards developing interactive computer programsfor
policy DEMO Mertz & Doherty (195) and Brehmer (37) examined the influence
of various task characteristics on the configurality and consistency of policies. Miller
(197) demonstrated that improper cue labels could mislead judges despite the avail-
ability of adequate statistical information about cue validities. Liehtenstein, Earle
& Slovic (173) and Birnbaum (32) showed that even though regression equations
DEMO be used to describe cue-combination policies, subjects often average cues, in
violation of the additivity inherent in the equations. Wiggins (306) discussed DEMO
problems of identifying and characterizing individual differences in judgmental
policies, and DEMO & Goldberg (222) explored the stability and correlates
such differences. McCann, Miller & Moskowitz (193) examined the problems
capturing policies in particularly complex and dynamic tasks such as production
planning.
MULTIPLE CUE PROBABILITY LEARNING DEMO effort has been in-
vested in studying how people learn to make inferences from several probabilistic
cues. Most of this work goes under the DEMO "multiple-cue probability learning"
(MCPL) and relies on the lens DEMO for conceptual and analytic guidance. Typi-
cally, the cues are numerical DEMO vary in their importance and in the form (linear
Annu. Rev. DEMO 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISIONTHEORY
13
or nonlinear) of their relationship to the criterion being judged. The criterion usually
contains error, making perfect prediction impossible. Because these tasks embody
the essential features of diagnostic inference, they are studied for their potential
applied significance as well as their DEMO to basic knowledge.
Slovic & Lichtenstein (254) reviewed MCPL studies published prior to 1971.
They concluded that: (a) subjects can learn to use linear cues appropriately; (b)
learning of nonlinear functions is DEMO, and especially difficult when subjects are not
forewarned that relations may DEMO nonlinear; (c) subjects are inconsistent, particu-
larly when task predictability is low; (d) subjects fail to take proper account of cue
intercorrelations; and (e) outcome feedback is not very helpful.
Research during the past half decade has confirmed and extended these conclu-
sions. Difficulties DEMO have in coping with intercorrelated cues have been docu-
mented in numerous studies (8, 9, 178, 236). Hammond his colleagues (115)
used the MCPL paradigm to analyze the effects of psychoactive drugs DEMO cognition.
They found that some drugs that are used to enhance emotional control interfered
with learning and communication in ways that may be detrimental DEMO therapy.
Bjorkman (33) and Castellan (54) reviewed results from studies using nonmetric
cues and criteria. ~
Other research has worked towards developing DEMO theory to explain MCPL results
in terms of erroneous intuitions about probabilistic tasks, the manner in which
individuals acquire and test hypotheses, and DEMO cognitive limitations. For exam.
pie, Brehmer (38, 40, 41) DEMO studied how subjects formulate and test hypotheses
as they search for rules that will produce satisfactory in~ferences. Hypotheses about
the functional rule relating cues DEMO criterion appear to be sampled from a hierar-
chical set based on previous experience and dominated by the positive linear rule.
Testing of hypotheses DEMO rules shows inadequate appreciation of the probabilistic
nature of the task. Subjects keep searching for deterministic rules that will account
for the randomness in DEMO task; since there are none, they change rules frequently
(i.e. DEMO inconsistent) and eventually resample rules they had previously dis-
carded.
Even DEMO subjects are informed of the correct rules, they have trouble applying
DEMO consistently (31, 36, 42, 118). Nonlinear rules are particularly hard to apply.
Brehmer, Hammond, and their colleagues have thus conceptualized DEMO as a
skill analogous to motor behavior: with both, we can know what we want to do
without necessarily being able to do DEMO
Dynamic Decision
Making
At the time of Rapoport & Wallsten’s review, DEMO active research area was dynamic
decision making (DDM), the study DEMO tasks in which "decisions are made sequen-
tially in time; the task specifications may change over time, either independently or
as a result of previous decisions; information available for later decisions may be
contingent upon the outcomes of earlier decisions; and implications of any decision
may reach into the future" (224, p. 345). The present half-decade began promisingly
with Rapoport & Burkheimer’s (225) explication of formal models for DEMO
decision making and the manner in which they might be utilized in psychological
and
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario DEMO of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
14
SLOVIC, FISCHHOFF
& LICHTENSTEIN
experiments. Shortly thereafter, Ebert (77) reported finding no difference between
stochastic and deterministic versions of a task which Rapoport (223) earlier had
found to differ. DEMO that, relative silence.
Several possible reasons for this decline in interest DEMO to mind. The mathemati-
cal sophistication of DDM may deter some researchers, as may the on-line computer
and long start-up time often required. Furthermore, DDM models are so complex
and require so many assumptions that the interpretation of experimental results is
typically ambiguous--witness the morass of explanations facing DEMO (77) for why
his experiment and Rapoport’s produced different results. Kleiter (151) noted par-
ticular problems with creating cover stories that induce DEMO to accept the
assumptions underlying the model and with ascertaining that subjects understood
the task. He also questioned "the metahypothesis that human behavior is optimal"
(p. 374), which limits psychological theories to variations on the optimal model, (e.g.
using subjective probability estimates rather than "objective" relative frequencies or
assuming a reduced planning horizon). In his own work, Kleiter (152) has assessed
people’s planning horizons and has used a non-normative variance-preference model
to pred~ict betting behavior in a multistage game (154). These predictions relied
the assi~mption that people were perfect Bayesian DEMO processors.
A more active area of DDM research deals with sequential information purchas-
ing or sampling. Levine & Samet (169) allowed subjects to DEMO information
from three fallible sources until they could decide which of eight possible targets
was the object of an enemy advance. They found that DEMO seeking was
greater and accuracy was lower in low reliability conditions. Similar results were
obtained by Snapper & Peterson (259), whose subjects appeared to be relatively
unresponsive to changes in information quality because of a DEMO of purchasing
"intermediate" amounts of information.
Another sequential task that has attracted some attention is optional stopping:
the decision maker must choose DEMO accepting a currently available outcome
versus sampling further outcomes that may be of greater or lesser worth. Although
earlier research (see 225a) found DEMO subjects performed well when options were
generated by a random but stationary process, Bdckman (44) found very poor
performance with options that tended to increase or decrease in value. In particular,
subjects persisted much DEMO in sampling options with a descending than with an
ascending sequence. Brickman likened this behavior to "throwing good money after
bad." His subjects’ "take the money and run" strategy with ascending series was
similar to that found by Corbin, Olson & Abbondanza (63). Their subjects DEMO
have called it quits as soon as an option appeared that was a good bit better than
its predecessors. Olander (212), too, DEMO satisficing (rather than maximizing)
principles that may guide subjects’ decisions DEMO searching further.
Are Important Decisions
Biased?
A coherent picture emerges from research described so far. Because of limited
information-processing capacity and ignorance of DEMO rules for optimal information
processing and decision making, people’s judgments are DEMO to systematic biases.
Can these results be generalized from the lab to the real world?
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
DEMO Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION THEORY 15
A number of critics DEMO doubtful. Edwards (80) argued that experimenters,
denying subjects necessary tools and providing neither the time nor the guidance
to find them, have exaggerated human intellectual limitations. Winkler & Murphy
(309) criticized laboratory experiments DEMO being overly simplified and too well
structured when compared with the real-world situations they are meant to model.
They suggested that people may perform DEMO in the lab because of improper
generalization from their real-world experiences. For example, because real-world
information tends to be redundant and unreliable, people DEMO naturally devalue the
reliable information provided in experiments, producing conservatism. In DEMO,
experimental subjects may be poorly motivated and forced to deal with unfamiliar
tasks and substantive areas without adequate training--even in the meaning of DEMO
response mode (121a).
In rebuttal, one could argue that laboratory studies may show subjects at their
best. Use of unfamiliar substantive topics DEMO free them from preconceived notions
that could prejudice their judgments. Provision of all information necessary for an
optimal decision (and little else) is, as noted by Winkler & Murphy (309), a
seldom offered by the real world. It may create demand characteristics forcing
subjects toward optimal DEMO (90, 97, 302). An alternative rebuttal is that there
DEMO many real-life situations which are quite like the laboratory, forcing people DEMO
make decision without the benefit of training and experience. People typically buy
cars and houses and decide to marry and divorce under such circumstances, func-
tioning as their own best approximation to experts.
Perhaps the best DEMO to resolve this argument is to look at the evidence.
EXPERTS IN THE LABORATORY The robustness of biases is shown in formal
experiments using DEMO as subjects. As examples: Tversky & Kahneman’s (284)
"law DEMO small numbers" results were obtained with statistically savvy psychologists.
Las Vegas DEMO patrons showed the same irrational reversals of preferences for
gambles as did college students (176, 177). Bankers and stock market experts
predicting DEMO prices for selected stocks showed substantial overconfidence and
performed so poorly that they would have done better with a "know nothing"
strategy (DEMO). Lichtenstein & Fischhoff (174) found that the probability assess-
ments of psychology graduate students were no better for questions within their area
DEMO expertise than for questions relating to general knowledge.
The "experts" in these studies were selected on the basis of what they knew about
DEMO subject area, not what they knew about judgment and decision making (i.e. they
were substantive rather than normative experts). Can normative experts DEMO created
in the laboratory by proper training? The evidence is mixed, suggesting either that
some biases are robust or that we have failed DEMO understand the psychology of our
subjects well enough to assist them.
OUT IN THE FIELD With the exception of some well-calibrated weather forecast-
ers (described below), similar biases have been found in a variety of DEMO studies.
For example, Brown, Kahr & Peterson (49, p. 431) observed overconfidence in the
probability assessments of military intelligence analysts. Kidd (DEMO) found that
a
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
DEMO Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
16
SLOVIC, FISCHHOFF
& LICHTENSTEIN
engineers for the United Kingdom’s Central Electricity Generating Board consis-
tently underestimated repair time for DEMO units. Bond (34) observed subopti-
mal play among 53 blackjack players at four South Lake Tahoe casinos. "By
wagering small bets in a sub-fair game, [these] blackjack gamblers practically guar-
anteed loss of their betting capital to the casinos" (p. 413). Flood plain residents
misperceive DEMO probability of floods in ways readily explained in terms of availabil-
ity and representativeness (253). Surveying research published in psychological and
educational journals, Cohen (56) and Brewer & Owen (43) found that investigators
regularly design experiments with inadequate statistical power, reflecting a belief in
the "law of small numbers" (284). Misinterpretation of regression toward the mean
appears to be as endemic to some areas of psychology (101) as to Kahneman
Tversky’s (139) subjects.
A major legal debate concerns the incarceration of individuals for being "danger-
ous." What little evidence DEMO is regarding the validity of dangerousness judgments
indicates substantial "over-prediction," DEMO of people who would not have
misbehaved had they been set free (72, 242). Although this bias may reflect a greater
aversion DEMO freeing someone who causes trouble than to erring in the other direction,
some observers have attributed it to judgmental problems such as failure DEMO consider
base rates, ignorance of the problems of predicting rare events, perception of nonex-
istent correlations, and insensitivity to the reliability of evidence (198a).
Jurors appear to have great dittieulty ignoring first impressions of the accuser’s
personality, pretrial publicity, and other forms of inadmissible evidence (46, 270),
tendencies which may represent both hindsight and anchoring DEMO (92). The
vagaries of eyewitness testimony and witnesses’ overconfidence in DEMO knowl-
edge are quite well known (51, 180).
Zieve (DEMO) has described at length the misinterpretation and abuse of laboratory
test DEMO by medical clinicians. Although some of these errors are due to igno-
rance, others reflect naive statistical reasoning. A classic case of the "DEMO of small
numbers" is Berkson, Magath & Hurn’s (25) discovery that aspiring lab technicians
were expected by their instructors to show greater DEMO in performing blood cell
counts than was possible given sampling variation. These instructors would marvel
that the best students (those who would not cheat) had the greatest difficulty
producing acceptable counts. In a phenomenological study of orthopedic surgeons,
Knurl & Burkett (155) found a variety of DEMO heuristics, some of them in the
form of general treatment philosophies (e.g. "don’t cut unless you absolutely have
to").
The immense DEMO facing our society (e.g: nuclear power) have prompted the
development DEMO formal analytic techniques to replace traditional, error-prone, "seat
of the DEMO" decision making. Fischhoff (91) reviewed a variety of cost-benefit
analyses DEMO risk assessments performed with these techniques and found them
liable to omissions of important consequences reflecting availability biases. In case
studies of policy analyses, Albert Wohlstetter (311) found that American intelli-
gence analysts consistently underestimated DEMO missile strength, a bias possibly
due to anchoring. Roberta Wohlstetter’s (31 la) study of American unpreparedness
at Pearl Harbor found the U.S. Congress and military investigators guilty of hind-
sight bias in their judgment of DEMO Pearl Harbor command staff’s negligence.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For DEMO use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION THEORY 17
Even if policy analyses DEMO performed correctly, they still must be explained
(sold?) to the public. In the area of natural hazard management, well-founded
government policies have foundered because people do not perceive flood hazards
the way policy makers DEMO them to (253). For example, the National Flood
Insurance Program has had only limited success because the endangered people will
not buy DEMO highly subsidized and normatively very attractive insurance offered
them (160).
DEMO ULTIMATE TEST "If behavioral decision theory researchers are so smart,
DEMO aren’t they rich?"
"They’re not in business."
"Then DEMO aren’t people who are in business falling over themselves to utilize
their results?"
Well, although psychological research has not swept the world’s DEMO makers
like wildfire, it has kindled some nonnegligible interest. The concern DEMO fore-
casters and decision analysts have shown for research in probability assessment is
described elsewhere in this review. The Department of Defense is developing DEMO
ticated decision aids to relieve military commanders of the need to integrate infor-
mation in their heads (148). United States intelligence analysts have shown interest
in the use of Bayesian approaches for processing of intelligence DEMO (79a,
147). Researchers in accounting~ (see also 14) DEMO advocated considering informa-
tion-processing limits in designing financial reports. The American College of Radi-.
ology has launched a massive "Efficacy Study" to see DEMO radiologists use the
probabilistic information from X rays. Bettman (29), DEMO, Kendall & Ross
(10), and others have argued that legislation intended to provide consumers with
necessary information (e.g. unit pricing, true DEMO rates) must consider how those
consumers do in fact process information.
DEMO AIDS
"What do you do for a living?"
"Study DEMO making."
"Then you can help me. I have some big DEMO to make."
"Well, actually ..."
That sinking feeling of inadequacy experienced by many of us doing psychological
research in decision making DEMO not felt by most experts in decision analysis,
multiattribute utility theory, or other decision aiding techniques. Proponents of
these approaches have remedies for what ails you--techniques to help users make
better decisions in any and DEMO circumstances.
Most of these decision aids rely on the principle of divide and conquer. This
"decomposition" approach is a constructive response to the DEMO of cognitive
overload. The decision aid fractionates the total problem into a series of structurally
related parts, and the decision maker is asked to make subjective assessments for
7T. A. Climo. Cash flow statements for investom DEMO, University of Kent at Canter-
bury, 1975.
is
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on DEMO/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
18 SLOVIC, FISCHHOFF & LICHTENSTEIN
only the smallest components. Such assessments are presumably simpler and more
manageable than assessing more DEMO entities. Research showing that decomposi-
tion improves judgment has been reported by Armstrong, Denniston & Gordon
(11), Gettys et al (104), and by Edwards and his colleagues (254, pp. 717-21).
Critics DEMO the decomposition approach would argue that many of the aids require
assessments of quantities the decision maker has never thought about, and that these
apparently simple assessments may be psychologically more complex than the origi-
nal DEMO In some situations, people may really know what they want to DEMO better
than they know how to assess the inputs required for the decision aid.
Decision aids which do not rely on decomposition, but instead require the deci-
sion maker to state preferences among whole, nonfractionated alternatives, are here
called "wholistic." The models in these aids are used to smooth or correct the
wholistic judgments and to partial them into DEMO
Since several of the decision aids rely on assessments of probability, DEMO start this
section with a review of probability elicitation techniques.
Assessing Probabilities
What’s the best way to assess probabilities? Spetzler & Sfiiel von Holstein (260) have
written an excellent description of how the Decision Analysis DEMO at Stanford
Research Institute approaches this problem. They recommended (a) carefully struc-
turing the problem with the client ("mental acrobatics should be DEMO",
p. 343), (b) minimizing biases that might affect DEMO assessor, (c) using personal
interviews rather than computer-interactive techniques with DEMO clients, and (d)
using several different elicitation methods, both DEMO and indirect. Their favorite
elicitation technique is a reference bet involving a "probability wheel," a disk with
two differently colored sectors whose relative size is adjustable. The assessor is
offered two bets, each with the same payoff. One bet concerns the uncertain quantity
(you win if next year’s sales exceed $X); the other bet concerns the disk (you
if the pointer lands in the orange sector after the disk is DEMO). The relative size of
the two sectors is varied until the assessor is indifferent between the two bets. The
proportion of the disk DEMO is orange is taken as the probability of the event stated
in the other bet.
Despite the appeal of this method (it is formally justified within axiomatic models
of subjective probability, does not require the assumption that the utility of money
is linear with money, and requires no numerical response from the assessor), we have
been unable to find DEMO research on its use.
DISCRETE EVENTS Comparisons among several direct methods for assessing the
probabilities of discrete events (probabilities vs odds vs log odds) have failed
identify one clearly preferable response mode (35, 73a, DEMO). Beach (22) found
mean within-subject correlation of only 0.49 between probabilities assessed directly
and indirectly (via bids for bets). DuCharme & Donnell (76) found equally conserva-
tive inferences using odds, probabilities, DEMO an indirect method similar in concept
to, but more complicated than, the reference bet method discussed by Spetzler &
Stiiel yon Holstein (DEMO).
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION THEORY 19
These studies focused on DEMO assessment of middle-range probabilities; even less
is known about assessing very DEMO or very small probabilities. Slovic, Fischhoff &
Lichtenstein (251) have shown that subjects grossly misuse odds of greater than
50:1. Selvidge (241) has made some common-sense suggestions for assessing very
small probabilities. She advised first structuring and decomposing the problem, then
ranking various unlikely events, and finally attaching numbers to those events with
the help of reference events (like dying in various rare accidents).
Once you have assessed a probability, how good is it? When there is an agreed-
DEMO "true probability"--as with bookbag and poker chip tasks--the assessed
probability DEMO be compared with the "truth." But more often the assessed proba-
bility states a degree of belief in some proposition, so that no criterion "true"
probability value exists. One test of such probabilities is coherence, that is, do they
abide by the axioms of probability? (290, 316). A second kind of validity, called
calibration, DEMO be examined one collects a large number of assessments for which
the truth of the associated propositions is known. For discrete propositions, calibra-
tion means that for every collection of propositions assigned the same numerical
probability, the hit rate or proportion which actually is true should be equal DEMO the
assessed probability. The research on calibration has recently been reviewed exten-
sively (175), so only a summary of findings will be given here: (a) Experienced
weather forecasters, when performing their customary tasks, are excellently cali-
brated. (b) Everybody else stinks. (c) People DEMO overconfident except with very
tasks.
UNCERTAIN QUANTITIES The most common technique for assessing probability
density functions across uncertain quantities is the fractile method. An DEMO who
names a value of an uncertain quantity as its 0.25 fractile, for example, is saying that
there is just a 25% chance DEMO the true value will be smaller than that specified
value. Stiiel von Holstein (263) and Vlek (290) have studied the consistency between
DEMO fractile method and other elicitation methods. Stliel von Holstein found that
even after four sessions most subjects were inconsistent. Vlek’s subjects showed
greater consistency.
DEMO probability density functions can also be tested for calibration. Asses-
sors are calibrated when, over many such assessments, the proportion of true
answers DEMO below a given fraetile is equal to that fractile. The evidence on
calibration (175) may be summarized as follows: (a) A strong and nearly universal
bias exists: the assessed distributions are too tight, DEMO that from 20% to 50% of the
true values, instead of DEMO, fall outside of the 0.01 to 0.99 range of the distributions.
(b) Training improves performance.
SCORING RULES Scoring rules are functions which assign a score to an assessed
probability (or a vector of probabilities) DEMO a function of both the true outcome
the event being assessed and the size of the probability associated with the true
outcome. Such rules DEMO strictly proper if and only if the only strategy for maximiz-
ing one’s expected score is to tell the truth--to state one’s true belief DEMO
hedging. Usually the only rules considered are those which reward expertise: DEMO
if
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
20
SLOVIC, FISCHHOFF
& LICHTENSTEIN
that one tells the truth, the more one knows, the larger the score [an DEMO is
Vlek’s (291) fair betting game]. Scoring rules have recently been discussed
Murphy & Winkler (205, 206) and by Shuford & Brown (50, 246).
Scoring rules may be used for three purposes. DEMO first use is as an indirect method
for measuring probabilities. A list of bets is generated from the scoring rule. Each
bet gives two DEMO, how much the assessor wins if the event in question occurs
DEMO how much is lost if it does not. The assessor selects his or her preferred bet from
the list; this choice implies a probability. Jensen & Peterson (136) and Seghers~
Fryback & Goodman (240) DEMO this method unsatisfactory; their subjects were
apparently using other strategies rather DEMO trying to maximize winnings.
The second use of scoring rules is to educate assessors about probability assess-
ments made with other methods. Several studies DEMO used scoring rule feedback
(246, 262, 308) without reporting whether it helped. Hoffman & Peterson (120)
reported that subjects who received such feedback improved their scores on a
subsequent task, but Vlek (DEMO) found no such improvement. Scoring rules are now
widely used by DEMO forecasters, and this may be why they are so well calibrated
(175). Murphy & Winkler (207) reported that a majority of DEMO weather forecasters
(a) described themselves as being uncomfortable thinking in probabilistic terms
(though their job is to report probabilities and they do it well), and (b) rejected
idea that their forecasts can be DEMO evaluated by a sinl~le quantitative measure
like a scoring rule (though DEMO had had experience with such feedback).
The third use for scoring rules is to evaluate assessors. When all assessors are
working in the DEMO situation, the assessor with the highest score is the best assessor.
DEMO, not all situations are equal; there is more uncertainty in forecasting rain
in Chicago than in Oregon. Thus Oregon forecasters will earn higher DEMO simply
because of where they work. Murphy (203) has shown that the Brier scoring rule
(the one used in meteorology) may be DEMO into three additive components,
measuring (a) the inherent uncertainty in the task, (b) the resolution of the assessor
(i.e. the DEMO to which the assessor can successfully assign probabilities different
from the overall hit rate), and (c) the assessor’s calibration. None of the DEMO
is itself a proper scoring rule, but the difference between the DEMO score and the
inherent uncertainty component is proper, and this difference DEMO be used to
compare assessors in different situations (204).
The DEMO reader will note that the research does not provide an adequate answer
to the question, asked at the start of this section: What DEMO the best way to assess
probabilities? In addition, the research has yielded few theoretical ideas. Only Pitz
(219) has speculated on the DEMO processes underlying probability assessment.
Finally, although a few studies have noted DEMO training improves performance in
eliciting probabilities, a definitive long-range learning study DEMO still needed.
Multiattribute
Utility
Theory
Suppose you must choose one object or course of action from a set. Each object or
action is describable DEMO terms of a number of dimensions or attributes of value to
you, and the outcomes of your choice are certain. Then multiattribute utility theory
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of DEMO Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION THEORY 21
(MAUT) prescribes that DEMO compute, for each object j, the following weighted
utilities, summed DEMO the attributes P
MAUj = iF’w,u#
where w~. is the relative importance of the ith attribute and u# is the utility of the
DEMO object on the ith attribute. For example, when choosing a car, w~. might be the
importance of design, and u# would indicate how beautifully designed car j is. The
theory prescribes that you choose the DEMO with the largest MAU. While this model
is the most common, DEMO exist which incorporate additional features such as
uncertainty, multiplicativity (rather than additivity) of the weighted utilities, time
factors, and the possibility that your choice will affect others (293).
MAUT is a decision aid strongly grounded in theory. The axioms of the theory
lead to the DEMO, to methods for measuring the utilities and weights, and to
specified tests that show which of the models is applicable. MAUT models have DEMO
developed extensively in the last 5 years (94-96, 141,143, DEMO, 234). If these sources
are too technical, the review papers by MacCrimmon (186), Fischer (86, 88),
Winterfeldt & DEMO (296), Humphreys (131), and Huber (129a) may be helpful.
ASSESSMENT TECHNIQUES The first step in constructing a MAU is to DEMO the
attributes. Techniques for doing this are rarely discussed. Among those who have
faced the problem, some have used the Delphi technique (e.g. DEMO, 211). Humphreys
& Humphreys (132) suggested using George Kelly’s DEMO grid technique.
Dalkey, Lewis & Snyder (65) proposed evaluating diverse DEMO (e.g. job choice,
modes of transportation) not on the basis of their apparent attributes but on
common set of attributes reflecting quality DEMO life (e.g. security, fun, freedom). Beach
et al (23) described an extensive interviewing technique, involving several interac-
tions with different DEMO makers, to arrive at a list of attributes.
It seems obvious DEMO the omission of an important attribute can seriously alter
the results of a MAUT application. However, Aschenbrenner & Kasubek (12) found
reasonably similar results for preferences among apartments from MAU analyses
based on two different, only partially overlapping sets of attributes.
Weights and utilities can be assessed DEMO directly or indirectly. Direct ap-
proaches, which are simple but not DEMO justified, include ranking or rating
scales, or just asking the assessor for the relevant numbers. For utilities, the assessor
may be presented with graph paper and asked to sketch a curve. Utility functions
may also DEMO derived by constructing indifference curves for pairs of variables (189,
DEMO); these methods are lengthy, tedious, and clearly impractical when there are
many variables. After two indifference curves for the same pair of DEMO are
assessed, a "staircase" method can be used by the DEMO to uncover the utility
curves for each of the variables, assuming DEMO the variables are value independent
(see 156, p. 57-61).
Indirect methods are justified within the theory, but are exceedingly complex.
They rely on a comparison between a gamble and a sure thing, and thus introduce
probabilities into an otherwise risk, less situation. For example, to DEMO the weight
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
22 SLOVIC, FISCHHOFF & LICHTENSTEIN
of one attribute from a set of 14 attributes describing apartments (such as number
of bedrooms, general cleanliness, etc), the analyst says, "Apartment A DEMO the best
(most preferred) level of all 14 attributes. Apartment B has the worst level of all
14 attributes. Apartment C has the DEMO level on one attribute and the worst level
on each of the other 13. State a probability p such that you are indifferent between
DEMO C for sure versus receiving a gamble wherein you will obtain A with
probability p and B with probability (l-p). What is the value ofp that makes you
indifferent?" The value of p that DEMO name is the weight; such a question must be
asked for DEMO attribute.
The two indirect methods for assessing utilities are similar to the indirect method
for assessing weights, except that "Apartment C" now has an intermediate level for
one alternative, and the worst level for all others. In the variable-probability method,
as with assessing weights, the task is to name probability that makes the sure thing
(Apartment C) DEMO to the gamble. In the fixed-probability method, the
probabilities associated with DEMO gamble are held constant at (1/2, 1/2), and the
assessor must name that intermediate value on one attribute of the DEMO thing which
leads to indifference. In either case, one answer gives DEMO one point on the utility
curve, so that several responses are DEMO to estimate its shape, for each attribute.
Kneppreth et al (156) have written an excellent review of the methods for assess-
ing utilities, explaining each method in detail, noting advantages and disadvantages,
and DEMO relevant research. That research has been unsystematic and allows
no clear conclusions. Perhaps future researchers should model their work on a study
by Vertinsky & Wong (289). Comparing an indifference curve method with the
indirect DEMO method, they looked at test-retest reliability and a host of
other DEMO, including the acceptance of particular rationality axioms, realism of
the task, confidence in the method, bias in the interpretation of probability, and a
measure of the width of an indifference band across the variables. DEMO found that
the indirect method was more reliable and easier for the subjects, while the indiffer-
ence curve technique predicted more subsequent choices.
IssuEs In MAUT, two issues are paramount. The first is: Is it DEMO? Early re-
search in the use of MAUT frequently involved correlating DEMO results of the model
with unaided wholistic judgments of the same situations made by the same subjects
(e.g. 130, 132, 294, and DEMO papers referenced in the reviews mentioned above).
A high correlation between the model and the wholistic judgments, the usual result,
was taken as evidence that the model was valid. This conclusion seems faulty to DEMO
If unaided wholistic preferences are good enough to constitute criteria for a decision
aid like MAUT, who needs the decision aid? Furthermore, a decade or more of
research has abundantly documented that humans are quite DEMO at making complex
unaided decisions (248); it could thus be DEMO that high correlations with such
flawed judgments would suggest a lack of validity. More sophisticated approaches
have been taken by Fischer (87), who showed greater agreement among three
different decomposition procedures than among three different DEMO proce-
dures, and by Newman (208), who proposed applying Cronbach’s (64) theory
generalizability to the problem of validating MAUT techniques.
a
DEMO Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL
DECISION THEORY
23
But most practitioners and DEMO approach the validity question as follows: the
theory specifies the models, the assessment procedures, and the tests for choosing
which model applies. Thus if you accept the axioms (yes, I do want my choices DEMO
be transitive; I should not be swayed by irrelevant alternatives, etc) and pass the
tests, then you can be assured that you DEMO doing the right thing. There is no
remaining validity question.
The second issue concerns error. Indirect elicitation techniques for both weights
and utilities are, as previously noted, quite complex, but theoretically justifiable. The
direct methods, in contrast, seem easier, but are theoretically unjustified. If one
assumes DEMO the decision maker has underlying weights, utilities, and preferences,
which approach, direct or indirect, elicits these underlying values with least error?DEMO
Von Winterfeldt (293) discussed but did not resolve this issue. Practitioners can (and
often do) perform sensitivity analyses (how much can I change this parameter before
the decision changes?). Such sensitivity analyses will identify potential problems of
measurement but not solve them.
The tests which DEMO used to determine which MAUT model is applicable are
equally complex. The test for additivity uses the weights derived from the indirect
method. If DEMO weights across all the attributes sum to 1.0, an additive model DEMO
be used. Otherwise, a multiplicative model is used. No error theory DEMO available to
tell you whether a sum of, say, 1.4 is "close enough" to 1.0 to justify an additive
model. An alternative, and seemingly easier, test is available for additivity (see 296,
DEMO 70). Unfortunately, no alternatives are available for two other necessary DEMO
These tests are for two kinds of utility independenc~ [called i’preferential indepen-
dence" and "utility independence" by KeeneY (142), and "WCUI" and "SCUI"
others (see 296)]. The following question, DEMO reference to the location of the
Mexico City airport (142), DEMO just the starting point for these tests: "How many
people seriously injured or killed per year, call that number makes you indifferent
between the option: [x injured or killed and 2500 persons subjected to high noise
levels] and the option: [one person injured or killed and 1,500,000 subjected to high
noise level]?" Several such questions must DEMO asked for each attribute and for all
pairs of attributes. The frequent avoidance of these tests may not reflect laziness,
but a genuine DEMO that using an unjustified model may lead to fewer errors than
choosing a model on the basis of confused responses to complex questions such DEMO
these. As von Winterfeldt (293) has noted, "even after you go through the process
of model elimination and selection, you will still have to make up your mind about
the possible trade-offs between assessment DEMO and modeling error" (p. 65).
The flavor of the indirect assessment methods and the three tests mentioned above
may be appreciated by DEMO 54 pages of dialogue between an analyst (Keeney)
and an DEMO as they evaluate alternatives for the production of electrical energy
RECENT
Can it be done? What
ing MAUT?
(coastal land development)
DEMO The "new
problems are encountered?
Edwards
two groups of experts (developers and conservationists)
Gardiner &
look" in MAUT
What can DEMO
that in a highly
(102) showed
research
is to explore its uses.
learned from apply-
controversial issue
x,
Annu. Rev. Psychol. 1977.28:DEMO Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
24
SLOVIC, FISCHHOFF
& LICHTENSTEIN
showed notably less disagreement about the evaluation of proposed apartment
buildings in their MAUT evaluations DEMO in their wholistic evaluations. O’Connor
(211) reported the difficulties in getting many experts to agree on evaluations
water.quality while trying to (a) DEMO the amount of experts’ time needed for
the evaluation, (b) DEMO redundant or strongly interrelated attributes, and
(c) cope with possible DEMO factors (if the water is loaded with arsenic,
nothing else DEMO). Guttentag & Sayeki (110) used a MAUT technique to illumi-
nate the cultural differences in values and beliefs about peace issues between DEMO
nese and Americans. In one of two reports of real applications (DEMO working with
clients who paid for the advice), Kcency observed the changes in a MAUT system
after 2 years of use (145). In the second report, he described the complexities
deciding where and when to build a new airport in Mexico City 042). Additional
proposals DEMO applications of MAUT, without relevant data, have been made for the
development social indicators (258), military system effectiveness (287), and DEMO
waste management 050). Finally, computer programs to aid elicitation of DEMO
have been written 046).
Decision ~tnalysis
The most general approach for systematically evaluating alternative actions is deci-
sion analysis, an approach developed largely at the Harvard Business School (221,
235) and two private DEMO research firms, the Stanford Research Institute (125),
and Decisions DEMO Designs, Inc. (49). In facing a new problem, the DEMO lists the
decision alternatives, constructs a model of their interrelations, assesses the
probabilities of relevant contingencies, finds out what the decision maker wants, and
finally, assays the expected value or utility of each alternative. DEMO do this, decision
analysts use a bag of tricks drawn from DEMO such as operations research, Bayesian
statistics, SEU and MAUT, which DEMO the analyst to "in principle, address any
decision problem with unimpeachable rigor" (49, p. 64). A common tool is the
decision tree which diagrams the uncertain consequences arising from a decision.
Among problems DEMO have boon given full-dress decision analyses are whether
to seed hurricanes in hopes of reducing their intensity (126), how to establish
planetary quarantine requirements for trips to Mars and Jupiter (127), what value
nuclear power generating plants have for Mexico (265), and how to design export
controls on computer sales to the Soviet Bloc (71). Many environmental impact
statements, cost-benefit analyses, and risk assessments constitute variants on DEMO
sion analytic-methodology (55, 91, 198, 216).
Although many of these analyses are already highly sophisticated, the basic
methodology still developing---often in response to specific problems. Work in the
last 5 years has increased DEMO ability to evaluate decision trees efficiently (288), assess
the value DEMO decision flexibility (194), and understand how models approximate the
processes DEMO are intended to describe (276).
Some awareness of psychological issues DEMO be found in decision analysis. One
example attempts to use the best psychological scaling techniques for eliciting
probability judgments (260). Another emphasizes communicating effectively with
decision makers; the analyst is encouraged to develop a role "not too dissimilar to
the
is
of
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/DEMO For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION THEORY 25
that of a psychoanalyst" (49, p. 9). Brown (48) raised a cognitive problem
DEMO further examination. He noted that decision analyses often fail to model
responses to future events. As a result, when those future events actually occur, they
are responded to in totally unanticipated ways, because in the DEMO they look
different than they did at the time of the analysis.
Man~Machine Systems
For years, one of the most promising areas in decision aiding has been the develop-
ment of computerized aids for helping decision DEMO cope with complex problems.
Systems designed to elicit MAUT appraisals fall into this category, as do the
approaches described below.
REGRESSION APPROACHES Research within the regression paradigm has shown
that people have difficulty both applying the DEMO policies they wish to
implement and describing the policies they actually are implementing. Hammond
and colleagues have developed computer-graphics systems to combat both of DEMO
problems (113a, 117). Since these techniques can describe the policies of several
participants in a given situation, they have been used to resolve interpersonal and
intergroup conflicts (39) and to facilitate policy formation DEMO the societal level (2,
116).
Another major decision-aiding technique DEMO bootstrapping, which replaces judges
with algebraic models of their own weighting DEMO Recent research has contin-
ued to demonstrate that these models perform as well as or better than the judges
themselves 04, 68, 119, 202, 237, 307). Additional work promises to further en-
hance DEMO usefulness of bootstrapping. Einhorn (81, 82) showed how expert judg-
DEMO and statistical techniques can incorporate poorly defined and hard to measure
variables into judges’ models. Dawes & Corrigan (70) demonstrated that in most
DEMO the criterion being judged could be predicted well by models with unit
weights (see also 83, 297). These unit-weighting results suggest that DEMO many deci-
sion settings, all the judge needs to know is DEMO variables to throw into the
equation, which direction (+ or -) to weight them, and how to add. Actually,
Benjamin Franklin DEMO this insight about unit weighted linear models back in 1772
(186, p. 27).
PIP One of the earliest proposals for sharing the DEMO load between the
machine and the decision maker was (79) the Probabilistic Information Processing
System (PIP). In situations where judges must revise their probabilities upon receipt
of new information, the PIP system accepts the judges’ subjective assessments of
prior probabilities, and of the probability of each datum conditional on each hypoth-
esis, and then aggregates them according to Bayes’ theorem in order to produce
posterior probabilities of the hypotheses. A DEMO in 1971 (254) revealed an abun-
dance of research on PIP; since then, however, the flood has receded. A few recent
studies have.discussed what to do when the data are not conditionally independent
of DEMO another and have examined how well subjects handle such data (74, 129, 266).
A couple of interesting medical applications have been proposed (21a, 108, 109).
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For DEMO use only.
Annual Reviews
www.annualreviews.org/aronline
26
SLOVIC, FISCHHOFF
& LICHTENSTEIN
DYNAMIC SYSTEMS Some of the most ambitious interactive man/machine sys-
tems have been developed DEMO handle dynamic decision-making situations. The prob-
lems studied by researchers in this area are extremely varied and the systems
developed to solve them tend DEMO be highly specific. However a pattern of conceptual-
izing the task, DEMO the mathematics and software to handle it, and then
validating the DEMO in one or a series of experiments is common. As an example,
a team at Perceptronics, Inc. has developed a highly sophisticated system to assist
naval officers tracking "the elements of a simulated fishing fleet [one trawler and one
iceberg] as it moves about in an expanse DEMO ocean," a task that vaguely resembles
a futuristic version of Battleships (67, sect. 3, p. 1). The system tracks the decision
maker’s responses continuously and uses utilities inferred from them to recommend
maximum DEMO utility decisions (98). From an experiment testing the system
with DEMO Naval Reserve NCOs during four 90-minute sessions, Davis et al (67)
concluded that it worked in realistic decision-making situations, was accepted by
experienced operators, and markedly improved performance.
Such systems may be designed either as products that will actually work in some
field situation or as DEMO tools. Perhaps because of their expense, most products
have been designed DEMO solve specific military problems with no civilian analog
[although readers concerned about the possible presence of Soviet frogpersons in
their bathtub or swimming pool DEMO want to consult Irving (133)]. It is difficult
for the DEMO to judge the validity of these systems and the acceptability of their
advice.
With systems designed for research purposes, a critical issue is the tradeoff
between realism and generality. One strategy is to design systems whose DEMO
begins to approach that found in the real world--at the risk of investing too much
of available resources in the machine and too little DEMO understanding how people use
it. Some human factors questions worth studying are (a) how do variations in the
basic system (e.g. different instructions or information displays) affect people’s
performance? (b) how do person DEMO machine errors interact? (c) how should
machine output be adjusted DEMO different decision makers’ cognitive styles and work
paces (170, 171)? and (d) when do people heed the machine’s advice (l 1 l,
Another problem with these systems is that their very complexity DEMO it
difficult to compare results from one research context to the next. Perhaps the only
way to do that is to interpret the results DEMO terms of basic psychological (judgmental)
phenomena. If that tack is DEMO, then one might ask whether the development of
general behavioral principles DEMO not be served best by using a number of simpler,
cheaper, and more flexible systems, such as the tactical and negotiations game DEMO
by the Streuferts and colleagues (e.g. 269). Research showing why DEMO/machine
systems should be adopted might provide a more convincing case than the demon-
stration in a complex simulation that decision makers do better DEMO the machine’s
help. The skeptic may argue that such demonstrations merely show that one can
design a simulated task in which it helps to DEMO machine assistance.
Using Decision Aids
Do decision makers use these sophisticated techniques? Bootstrapping is now being
applied for a variety of repeated decisions. On the other hand, apparently few, if any,
Annu. Rev. Psychol. DEMO:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL
DECISION THEORY
27
PIP systems are operational DEMO despite the mass of research refining its methodol-
ogy. For most aids, a clear picture is hard to come by. In the scientific literature
one can find demonstration projects showing a procedure’s viability. However, when
a technique passes the test of getting someone to pay for it, the result typically
becomes proprietary. For reasons of national or industrial security, the details of
such projects are not divulged, nor are the decision makers’ responses to them. Most
overviews by those in the decision aiding business DEMO tend to be quite
optimistic.
Brown (47, 49), however, DEMO presented an insightful discussion of factors that
may limit decision makers’ receptiveness to decision analysis and presumably to
other techniques as well. One is DEMO fact that decision makers often employ an
analyst to reduce the uncertainty in a problem situation, not to acknowledge and
quantify it. Another source of resistance is the absence of top-level decision makers
familiar with the DEMO; a third is the bad experiences of decision makers who
try DEMO solo on the technique without proper training. Brown, Kahr & Peterson (49)
suggested that decision analysis is a clinical skill that should DEMO be practiced after
internship with an expert.
Another problem is that decision makers may, even after careful coaching, reject
the basic conception (e.g. the axioms) on which the aids are bhsed. Protocols
conversations between analysts and decision makers leave the impression that deci-
sion makers are under DEMO pressure to adopt the analyst’s perspective. It
is debatable whether satisfaction with the results of such an analysis show that the
analyst has really DEMO, the decision maker’s needs. Conrath (58) and Reeser
(227) DEMO that decision makers reject decision analysis (and related techniques)
for DEMO both overly complicated and divorced from reality. Individuals who may
accept the assumptions of such analysis may still reject their logical implications if
they DEMO unintuitive or too difficult to explain and justify to others.
A problem discussed earlier is whether decision makers can provide the required
probability, utility, and modeling judgments. Because of the vagaries of such judg-
ments, DEMO decision aider runs the risk of grinding through highly sophisticated
analyses on inputs of very little value. Certainly "garbage in--garbage out" applies
to DEMO aiding--with the particular danger that undue respect may be given to
garbage produced by high-powered and expensive grinding. Relatively little is
known about the DEMO of decision aids to errors in elicitation and problem
structuring. Von Winterfeldt & Edwards (294a) have proved that under very general
conditions probability DEMO utility estimates can be somewhat inaccurate without
leading to appreciably suboptimal decisions. Their proof is applicable to the case
where decision options are continuous (e.g. invest X dollars). However, Lichten-
stein, Fischhoff & Phillips (175) have shown how a moderate error in probability
estimation can lead to a substantial decrease in expected utility when the decision
options are DEMO (e.g. operate vs don’t operate). Von Winterfeldt & Edwards
(295) have identified a large class of errors which can lead to large expected losses
and are extremely difficult to detect. They arise from the DEMO of dominated
decision alternatives as the result of inappropriately modeling the decision problem.
How much is a decision aid worth? This difficult queskion is typically answered
with arguments why aids should, in principle, be worth DEMO resources invested in
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use DEMO
Annual Reviews
www.annualreviews.org/aronline
28
SLOVIC, FISCHHOFF
& LICHTENSTEIN
them. Recently Watson & Brown (303) provided enlightenment with a formal model
for performing DEMO decision analysis of a decision analysis. The model is accompanied
by three case studies (304) that highlight the difficulties of performing hindsightful
analysis. DEMO, the greatest value of two of these analyses came from their
DEMO to organizational processes (reduction of controversy and improve-
ment of communication), considerations that were left out of the formal model for
the sake of simplicity.
a
CONCLUSION
One reason for the vitality of the research DEMO here is the increased importance
of deliberative decision making in our daily lives. In a nontraditional society individ-
uals must rely on their analytical DEMO rather than habit in guiding their affairs.
A rapidly changing and interrelated world cannot allow itself the luxury of trial and
error as it DEMO to cope with problems like nuclear power and natural hazard
management. Economists, engineers, operations researchers, decision analysts and
others are developing sophisticated procedures for these problems. It is our job as
psychologists to remind them DEMO the human component in implementing these
techniques and explaining their conclusions to the public--in particular to point out
the errors that may arise from DEMO biases. We must help the public to make
its private decisions and to develop a critical perspective on those decisions made
in its behalf.
DEMO t
Cited
1. Abelson,
in attitude formation
ing. In Cognition
ed. J. S. Carroll, J. W.
NJ: Erlbaum.
2. Adelman, L., DEMO, T. R., Ham-
mond, K. R. 1975. A case history DEMO the
application of social judgment theory to
policy formulation. PolicySc£ 6:137-59
3. Alker, H. A., Hermann, M. G. 1971.
Are Bayesian decisions artificially intel-
ligent? The effect of task and personality
on conservatism in processing informa-
tion. J. Pets. Soc. Psychol. 19:31-41
4. Allais, P. M. 1953. The behavior of ra-
tional man in risk situations---A cri-
DEMO of the axioms and postulates of the
American School. Econometrika 21:
503-46
5. Anderson, N. H. 1972. Looking for
configurality in clinical judgment. P~y-
chol. Bull. 78:93-102
6. Anderson, N. H. 1974. Algebraic mod-
els in perception. In Handbook of Per-
R. P. 1976.
and
In DEMO
Script processing
and decision mak-
Social Behavior,
Payne. Hillsdale,
Res.
ception, ed. E. C. Carterette, M. P.
Friedman, pp. 215-98. New York: Aca-
demic. 556 pp.
7. Anderson, N. H. 1974. Information DEMO
tegration theory: A brief survey. In
Measurement, Psychophysics, and Neu-
DEMO Information Processing, ed. D. H.
Krantz, R. C. Atkinson, R. DEMO Luce,
P. Suppes, 2:236-305. San Francisco:
Freeman. 468 DEMO
8.. Armelius, B., Armelius, K. 1974. Utili-
zation of redundancy DEMO multiple-cue
judgments: Data from a suppressor
variable task. Am. J. Psychol. DEMO:385-92
9. Armelius, K., Armelius, B. 1976. The
effect of DEMO correlations, cue
intereorrelations and the sign of the cue
intercorrelation on DEMO in sup-
pressor variable tasks. OBHP. In press
10. Armstrong, O. DEMO, Kendall, C. L.,
Russ, F. A. 1975. Applications of DEMO
sumer information processing research
to public policy issues. Commun.
2:232-45
tTo conserve
of Experimental
space,
frequently
Psychology);
cited sources
OBHP
have
(Organizational Behavior
been
abbreviated
as follows:
and Human
JEP
Performance).
(Journal
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL
DECISION THEORY
29
11. Armstrong, J. S., Denniston, W. B. Jr.,
Gordon, M. M. 1975. The use of the
decomposition principle in making
judgments. OBHP 14:257-63
12. Aschenbrenner, K, M., Kasubek, W.
1976. Convergence of multiattribute
evaluations when different sets of at-
tributes are used. In Proceedings of the
Fifth Research DEMO on Subjective
Probability, Utility, and Decision Mak-
ing, ed. H. DEMO, G. de Zeeuw.
In press
13. Ashton, R. H. 1974. Cue utilization and
expert judgments: A comparison of in-
dependent auditors with other judges.
J./ippl. Psychol. 59:437-44
14. Ashton, R. H. 1975. User prediction
models in accounting: An alternative
use. Account. Rev. 50:710-22
15. Barclay, S., Beach, L. R., Braithwaite,
W. P. 1971. DEMO models in the
study of cognition. OBHP 6:389-413
16. Bar-Hillel, DEMO 1973. On the subjective
probability of compound events. OBHP
9:396-406
17. Bar-Hillel, M. 1974. Similarity and
probability. OBHP 11:277-82
18. Barron, DEMO H. 1974. Behavioral decision
theory: A topical bibliography for man-
agement DEMO Interfaces 5:56-62
19. Barron, F. H., Mackenzie, K. D. DEMO
A constrained optimization model of
risky decisions. J.. Math. Psychol. 10:
60-72
20. Bauer, M. 1971. Accuracy and congru-
ence in estimations of probabilities and
odds from binomial distributions. Ume~
Psychol. Rep. 36. Ume,~, Sweden: Univ.
Umd
21. Bauer, M. 1973. Inference strategies in
Bayesian DEMO not requiring high scale-
level responses. Umed Psychol. Reu. 61.
Ume~, DEMO: Univ. Ume~
21a. Beach, B. H. 1975. Expert judgment
about uncertainty: Bayesian decision
making in realistic settings. OBHP
14:10-59
22. Beach, DEMO R. 1974. A note on the
intrasubject similarity of subjective
probabilities obtained by estimates and
by bets. OBHP 11:250-52
23. Beach, L. R., Townes, B. D., Campbell,
F. L., Keating, G. W. 1976. Developing
and testing a decision aid for birth plan-
ning decisions. DEMO 15:99-116
24. Becker, G. M., McClintock, G. 1967.
Value: Behavioral decision theory. ~Inn.
Re~. PsychoL 18:239-86
25. Berkson, J., DEMO, T. B., Hum, M.
1940. The error of estimate of DEMO blood
cell count as made with the hemocy-
tometer./Im. J. Physiol. 128:309-23
26. Bed, J., Lewis, G., Morrison, R. S.
1976. Alternative models of choice in
important and nonrepetitive situations.
See Ref. DEMO
27. Bettman, J. R. 1971. A graph theory
approach to comparing DEMO infor-
mation processing models. Manage. ScL
18:114-28
28. Bettman, R. DEMO Toward a statistics
for consumer decision net models. J.
Consum. Rex 1:71-80
29. Bettman, R. 1975. Issues in designing
consumer information environments, DEMO
Consum. Res~ 2:169-77
30. Bettman, J. R., Capon, N., Lutz, R.
1975. Multiattribute measurement
models and multiattribute attitude the-
ory: DEMO test of construct validity, d. Con-
sum. Res. 1:1-15
31. DEMO, J. R., Jacoby, J. 1975. Pat-
terns of processing in DEMO infor-
mation acquisition. Papers in Consumer
Psychol. No. 150. West Lafayette, DEMO:
Purdue Univ.
32. Birnbaum, M. H. 1976. Intuitive nu-
merical DEMO Am. J. PsychoL
press
33. Bjtirkman, M. 1973. Inference behavior
in DEMO ecologies. In Human
Judgment and Social Interaction, ed. L.
Rappoport, D. A. Summers, pp. 144-
68. New York: Holt, Rinehart & Win-
ston. 403 pp.
34. Bond, N. A. Jr. 1974. Basic strategy and
expectation in casino blackjack. OBHP
12:413-28
35. Braithwaite, A. 1974. A note compar-
ing three measures subjective proba-
bility, their validity and reliability./Icta
Psychol. 38:337-42
36. Brehmer, B. 1971. Subjects’ ability to
use functional rules. Psychon. Sci.
24:259-60
37. Brehmer, B. 1973. Note on clinical
judgment and the formal characteristics
of clinical tasks. Ume~ PsychoL Rep. DEMO
Ume~,
38. Brehmer,
lations between
learning
OBHP 11:1-27
39. Brehmer, B. 1976. Social judgment the-
ory and the analysis of interpersonal
conflict. Psychol. Bull. In press
40. Brehmer, B., Kuylenstierna, J., DEMO
jergren, J. 1974. Effects of function form
and cue validity on DEMO hypotheses
in probabilistic inference tasks. OBltP
11:338-54
Sweden: Univ’. Umd
DEMO 1974.
of probabilistie
Hypotheses
sealed variables in the
inference
about
re-
tasks.
J.
J.
In
of
C.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from DEMO
by Ontario Council of Universities Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
30
SLOVIC,
FISCHHOFF & LICHTENSTEIN
41. Brehmer, B., Kuylenstierna, J., Lil-
jergren, J. 1975. Effects of information
DEMO the probabilistic nature of the
task on learning of uncertain inference
tasks. Ume~ Psychol. Rep. 90. Umea,
Sweden: Univ. Umea
42. Brehmer, DEMO, Quarnstrom, G. 1976. In-
formation integration and subjective
weights in multiple-cue judgments.
OBHP. In press
43. Brewer, J. K., Owen, P. W. 1973. A
note on the power of statistical tests in
the Journal DEMO Educational Measure-
ment. J. Educ. Meas. 10:71-4
44. Brickman, P. DEMO Optional stopping
on ascending and descending series.
OBHP 7:53-62
45. Bdckman, P., Pierce, S. M. 1972. Esti-
mates of conditional probabilities of
confirming versus disconfirming events
as a function of inference situation and
prior DEMO JEP 95:235-37
46. Brooks, W. N., Doob, A. N. DEMO Jus-
tice and the jury. Z Soc. Issues
31:171-82
47. Brown, R. V. 1971. Marketing applica-
tions of personalist decision analysis.
MSI Field Res~ Pro~ Rep. P-55.
Cambridge: Manage. Sci. Inst.
48. Brown, R. DEMO 1975. Modeling subse-
quent acts for decision analysis. DDI
Tech. Rep. 75-1. McLean, Va: Deci-
sions & Designs
49. Brown, R. V., DEMO, A. S., Peterson, C.
1974. Decision Analysis for the Man-
DEMO New York: Holt, Rinehart &
Winston. 618 pp.
50. Brown, T. A., Shuford, E. H. 1973.
Quantifying uncertainty into numerical
probabilities DEMO the reporting of intelli-
gence. RAND Rep. 1185-ARPA. Santa
Monica: Rand DEMO
51. Buckhout, R. 1974. Eyewitness testi-
mony. Sci. Am. 231:23-31
DEMO Castellan, N. J. Jr. 1972. The analysis of
multiple criteria in DEMO judg-
ment tasks. OBHP 8:242-61
53. Castellan, N. J. Jr. DEMO Comments on
the "lens model" equation and the anal-
ysis of multiple-cue judgment tasks.
Psychometrika 38:87-100
54. Castellan, N. J. Jr. 1976. Decision mak-
ing with multiple probabilistic cues. In
Cognitive Theory, ed. N. J. Castellan
Jr., D. B. Pisoni, G. R. Potts, Vol. 2.
Hillsdale, NJ: Erlbaum. In press
55. Coates, J. F. 1976. The role of formal
models in technology assessment. Tech.
Forecasting Soc. Change. In DEMO
56. Cohen, J. 1962. The statistical power of
abnormal-social psychological research.
DEMO .4bnorm. Soc. PsychoL 65:145-53
57. Cohen, J., Chesniek, E. DEMO, Haran, D.
1972. A confirmation of the inertial-~
effect in sequential choice and decision.
Br. Z PsychoL 63:41-6
58. Conrath, D. W. 1973. From statistical
decision theory to practice: Some prob-
lems with the transition. Manage. Sci.
19:873-83
59. Cook, R. L. 1974. An interactive and
iterative approach to computer-aided
policy capturing. Prog. Res. Hum.
Judgment Soc. DEMO Rep. 64.
Boulder: Inst. Behav. Sci., Univ. Colo-
rado
60. Coombs, C. H. 1975. Portfolio theory
and the measurement of risk. In Human
Judgment and Decision Processes, ed.
M. F. Kaplan, $. Schwartz. pp. DEMO
New York: Academic. 325 pp.
61. Coombs, C. H., Huang, L. C. 1974.
Tests of the betweenness property of ex-
pected utility. DEMO 74-13. Ann
Arbor: Univ. Michigan
62. Corbin, R. M., Marcy, A. A. 1974.
Random utility models with equality:
An apparent but DEMO actual generaliza-
tion of random utility models. Z Math.
PsychoL 11:274-93
63. Corbin, R. M., Olson, C. L., Abbon-
danza, M. 1975. Context effects in op-
tional stopping decisions. OBHP 14:
207-16
DEMO Cronbach, L. J., Gleser, G., Nanda, H.,
Rajaratnam, N. 1972. The Dependabil-
ity of Behavioral Measurements: Theory
of Generalizability for Scores and Pro-
files. New York: Wiley
65. Dalkey, N. C., Lewis, R., Snyder, D.
1970. Measurement and analysis of the
quality of life: With exploratory illus-
trations of applications to career and
transportation choices. RAND RM-
6228-DOT. Santa Moniea: Rand Corp.
66. Davenport, W. DEMO, Middleton, M. A.
1973. Expectation theories of decision
duplex gambles. ,DEMO Psy-
chol. making 37:155-72for
67. Davis, K. B., Weisbrod, DEMO L., Freedy,
A., Weltman, G. 1975. Adaptive com-
puter DEMO in dynamic decision pro-
cesses: An experimental study of aiding
effectiveness. DEMO Rep. PTR-1016-75-
5. Woodland Hills, Calif: Perceptronics
68. Dawes, R. DEMO 1971. A case study of
graduate admissions: Applications of
three principles DEMO human decision mak-
ing. Am. Psychol. 26:180-88
69. Dawes, R. DEMO 1976. Shallow psy-
chology. See Ref. 1
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/DEMO For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION
THEORY
31
70. Dawes, R. M., Corrigan; B. 1974. Lin-
ear models in decision making. Psychol.
Bull. DEMO:95-106
71. Decisions & Designs, Inc. 1973. Com-
puter sale to DEMO Soviet bloc. Tech. Rep.
73-4
72. Dershowitz, A. M. 1968. Psychiatry DEMO
the legal process: "Knife that cuts both
ways." Judicature 51:DEMO
73. Dillon, J. L. 1971. An expository review
of Bernoullian decision DEMO Rev.
Mark. Agric. Econ. 39:3-80
73a. Domas, P. A., Goodman, B. C., Peter-
son, C. R. 1972. Bayes’s theorem: Re-
DEMO scales and feedback. Eng. Psy-
chol. Lab. Tech. Rep. 037230-5-T. Ann
Arbor: Univ. Michigan
74. Domas, P. A., Peterson, C. R. 1972.
DEMO information processing
systems: Evaluation with conditionally
dependent data. OBHP 7:77-85
DEMO Donnell, M. L., DuCharme, W. M.
1975. The effect of DEMO feedback
on learning 14:305-13in an odds estimation task.
76. DuCharme, DEMO M., Donnell, M. L.
1973. Intrasubject comparison of four
response modes for "subjective proba-
bility" assessment. OBHP 10:108-17
77. Ebert, R. J. 1972. Human control of a
two-variable decision system. OBHP
7:237-64
DEMO Edwards, W. 1961. Behavioral decision
theory. Ann. Rev. Psychol. 12:473-98
DEMO Edwards, W. 1962. Dynamic decision
theory and probabilistic information
processing. Hum. DEMO 4:59-73
79a. Edwards, W. 1972. Application of re-
search on DEMO to man-machine
system design. Eng. Psychol. Lab. Rep.
010342-1-F. Ann Arbor: DEMO Michi-
gan
80. Edwards, W. 1975. Comment. J. Am.
Stat. Assoc. DEMO:291-93
81. Einhorn, H. J. 1972. Expert measure-
ment and mechanical DEMO
OBHP 7:86-106
82. Einhorn, H. J. 1974. Cue definition and
DEMO judgment. OBHP 12:30-49
83. Einhorn, H. J., Hogarth, R. DEMO 1975.
Unit weighting schemes for decision
making. OBHP 13:171-92
84. Einhorn, H. J., Koelb, C. 1976. Psycho-
metric study of literary critical judg-
ment. Grad. Sch. Bus. Work. Pap. Univ.
Chicago Press
85. Ellsberg, D. 1961. Risk, ambiguity, and
the Savage axioms. Q. Z Econ. DEMO:
643-49
86. Fischer, (3. W. 1975. Experimental ap-
plications of multi-attribute utility
models. In Utility, Probability, and Hu-
man Decision Making, ed. D. Wendt,
C. A. J. Vlek, pp. 7-46. Dordrecht, DEMO
Netherlands: Reidel. 418 pp.
87. Fischer, (3. W. 1972. Four DEMO for
assessing multi-attribute utilities: An
experimental validation. Eng. Psychol.
Lab. Tech. DEMO 037230-6-T. Ann Ar-
bor: Univ. Michigan
88. Fischer, G. W. 1976. Multidimensional
utility models for risky and riskless
choice. OBHP In press
89. DEMO, B. 1975. Hindsight ~ fore-.
sight: The effect of outcome knowl-
edge on judgment under uncertainty.
JEP." Hum. Percept. Performance
h288-99
90. Fischhoff, B. 1976. Attribution theory
and judgment under uncertainty. In
New Directions in Attribution Research,
ed. J. H. Harvey, W. J. Ickes, R. DEMO
Kidd, pp. 419-50. Hillsdale, NJ: Erl-
baum.
91. Fischhoff, B. 1976. Cost-benefit analysis
and the art of motorcycle maintenance.
OR1 Res. Monogr. DEMO(1). Eugene: Ore-
gon Res. Inst.
92. Fischhoff, B. 1976. Perceived informa-
tiveness of factual information. OR1
Res. Bull. 16(3). DEMO: Oregon Res.
Inst.
Fischhoff, B., Beyth, R. 1975. "I DEMO
it would happen"--remembered prob-
abilities of once-future things. OBHP
13:1-16
Fishburn, P. C. 1970. Utility Theory for
Decision Making. Publ. in Oper. Res.
Ser. 18, ed. D. B. Hertz. New York:
Wiley. 234 pp.
Fishburn, P. C. 1974. von Neumann-
Morgenstern utility functions on two at-
tributes. Oper. Res. 22:35-45
Fishburn, P. C., Keeney, R. L. 1974.
Seven independence concepts and con-
tinuous multiattribute utility functions.
J. DEMO Psychol. 11:294-327
Fontaine, (3. 1975. Causal attribution in
simulated versus real situations: When
J.. are Pets. people Soc. logical, PsychoL when DEMO:1021-29are they not?
Freedy, A., Weisbrod, R., Davis, DEMO,
May, D., Weltman, G. 1974. Adaptive
computer aiding in DEMO decision
processes: Adaptive decision models
and dynamic utility estimation, Part I.
Tech. l~ep. PTR-lO16-74-5(1). Wood-
land Hills, Calif: Perceptronics
Fryback, D. G., Goodman, B. C., Ed-
wards, W. 1973. Choices DEMO bets by
Las Vegas gamblers: Absolute and con-
textual effects. JEP DEMO:271-78
93.
94.
95.
96.
97.
98.
99.
OBI-IP
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on DEMO/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
32
SLOVIC~ FISCHHOFF & LICHTENSTEIN
100. Funaro, J. F. 1975. An empirical analy-
sis of five descriptive models for cas-
DEMO inference. OBHP 14:186-206
101. Furby, L. 1973. Interpreting regression
toward DEMO mean in developmental re-
search. Dev. Psychol. 8:172-79
102. Gardiner, DEMO C., Edwards, W. 1975.
Public values: Multiattribute-utility
measurement for social DEMO mak-
ing. See Ref. 60, pp. 1-37
103. Gettys, C. F., Kelly, C. W. III, Peter-
son, C. R. 1973. The DEMO guess hypoth-
esis in multistage inference. OBHP
10:364-73
104. Gettys, DEMO F., Michel, C., Steiger, J. H.,
Kelly, (2. W. III, Peterson, C. R. 1973.
Multiple-stage probabilistic informa-
tion processing. DEMO 10:374-87
105. Goodman, B. C. 1973. Direct estima-
tion procedures DEMO eliciting judgments
about uncertain events. Eng. PsychoL
Lab. Tech. Rep. 011313-5-T. Ann Ar-
bor: Univ. Michigan
106. Graesser, C. C., Anderson, N. DEMO 1974.
Cognitive algebra of the equation: Gift
size ---- generosity X DEMO JEP
103:692-99
107. Green, P. E., Wind, Y. 1975. DEMO way
to measure consumers’ judgments. Har-
vard Bux Rev. 53:107-17
108. Greist, J. H., Gustafson, D. H., Stauss,
F. F., Rowse, G. L., Laughren, T. P.,
Chiles, J. A. DEMO A computer inter-
view for suicide-risk prediction. Am.
Psychiatry 130:1327-32
109. Gustafson, D. H., Kestly, J. J., Greist,
J. H., Jensen, N. M. 1971. Initial evalu-
ation of a subjective Bayesian diagnostic
system. Health Serv. Res. 6:204-13
110. Guttentag, M., Sayeki, Y. 1975. A deci-
sion-theoretic technique for the illumi-
nation of cultural differences. DEMO Cross-
Cult. Psychol. 6:203-17
111. Halpin, S. M., Johnson, DEMO M., Thorn-
berry, J. A. 1973. Cognitive reliability
in manned systems. IEEE Tran~ Re-
liab. R-22:165-70
112. Halpin, S. M., Thornberry, J. A.,
Streufert, S. 1973. The credibility of
computer estimates in a simple decision
making task. ONR Tech. Rep. .~. West
Lafayette, Ind: Purdue Univ.
113. Hammerton, M. 1973. A case of radical
probability DEMO JEP 101:252-54
113a. Hammond, K. R. 1971. Computer
graphics as DEMO aid to learning. Science
172:903-8
114. Hammond, K. R. 1974. DEMO judg-
ment and social policy. Prog. Rex Hum.
Judgment Soc. Interaction Rep. 170.
J.
Boulder: Inst. Behav. Sci., Univ. Colo-
rado
115. Hammond, R., Joyce, C. R. B., eds.
1975. Psychoactive Drugs and Social
Judgment. New York: Wiley. 278 pp.
116. Hammond, K. R., Stewart, T. R., Add-
man, L., Wascoe, N. E. 1975. Report to
the Denver city council and mayor re-
garding the choice of DEMO ammuni-
tion for the Denver police department.
Prog. Res. Hum. Judgment Soc. Interac-
tion Rep. 179. Boulder: Inst. Behav.
Sci., Univ. Colorado
117. DEMO, R., Stewart, T. R., Breh-
mer, B., Steinmann, DEMO O. 1975. Social
judgment theory. See Ref. 60, pp. 271-
312
DEMO Hammond, K. R., Summers, D. A.
1972. Cognitive control. Psychol. DEMO
79:58-67
119. Hamner, W. C., Carter, P. L. 1975. DEMO
comparison of alternative production
management coefficient decision rules.
Dec. Sci. 6:324-36
120. Hoffman, J., Peterson, C. R. 1972. A
scoring rule to train probability asses-
sors. Eng. Ps.vchol. Lab. Tech. Rep.
037230-4-T. Ann Arbor: Univ. Michi-
gan
121. Hogarth, R. M. 1974. Process tracing in
clinical judgment. Behav. Sci. 19:298-
313
121a. Hogarth, R. M. 1975. Cognitive pro-
eesses and the assessment of subjective
probability distributions. J. Am. Stat.
DEMO 70:271-94
122. Hogarth, R. M. 1975. Decision time as
a DEMO of task complexity. See Ref.
86, 321-38
123. Holzworth, R. J., Doherty, M. E. 1974.
Inferences and predictions: normative
vs. representative responding. Bull.
Psychon. Soc. 3:300-2
124. Houle, A. 1973. Bibliography." Bayesian
DEMO Supplemented 1974-75. Ste-
Foy, Quebec: Univ. Laval
125. Howard, R. DEMO, Matheson, J. E., Miller,
K. E. 1976. Readings in DEMO Analy-
six Menlo Park: Stanford Res. Inst.
126. Howard, R. A., Matheson, J. E., North,
D. W. 1972. The decision to seed hurri-
canes. Science 176:1191-1202
127. Howard, R. A., North, D. W., Pezier,
J. P. 1975. A new methodology to inte-
grate planetary quarantine require-
ments into mission planning, with ap-
plication to a Jupiter orbiter. SRIFinal
Rep. N,4S7-100. Menlo Park: Stanford
Res. Inst.
128. Howell, W. C. 1972. Compounding un-
K.
K.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on DEMO/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION
THEORY
33
certainty from internal sources. DEMO
95:6-13
129. Howell, W. C., Gettys, C. F., Martin,
D. W. 1971. On the allocation of infer-
ence functions in DEMO Systems.
OBHP 6:132-49
129a. Huber, 13. P. 1974. Multi-attribute
utility DEMO: A review of field and
field-like studies. Manage. Sci. 20:
DEMO
130. Huber, G. P., Daneshgar, R., Ford,
D. L. 1971. An empirical comparison of
five utility models for predicting job
preferences. DEMO 6:267-82
131. Humphreys, P. 1976. Applications of
multiattribute utility theory. DEMO Ref. 12
132. Humphreys, P., Humphreys, A. 1975.
An investigation DEMO subjective prefer-
ence ordedngs for multi-attributed al-
ternatives. See Ref. 86, DEMO 119-33
133. Irving, 13. W. 1975. Alternative man/
machine interface DEMO for swimmer
defense systems. Integrated Sci. Corp.
TM-75-36. Point Mugu, Calif: Pacific
Missile Test Cent.
134. Jacoby, J. 1975. Perspectives on a con-
sumer information processing research
program. Commun. Res. 2:203-15
135. Jacoby, J. 1976. Consumer psychology:
An octennium. ~Inn. Rev. PsychoL
27:331-58
136. DEMO, F. A., Peterson, C. R. 1973.
Psychological effects of proper DEMO
rules. OBHP 9:307-17
137. Johnson, E. M., Cavanagh, R. DEMO,
Spooner, R. L., Samet, M. G. 1973. Uti-
lization DEMO reliability measurements in
Bayesian inference: Models and human
performance. IEEE Tran~ DEMO
R22:176-83
138. Kahneman, D., Tversky, A. 1972.
Subjective probability: A judgment
of representativeness. Cogn. Psycho£
3:430-54
139. Kahneman, D., DEMO, A. 1973. On
the psychology of prediction. Psychol.
Rev. 80:237-51
DEMO Kahneman, D., Tversky, A. 1975.
Value Theory: An Analysis of Choices
UnderRisk. Presented at Conf. on Pub-
lic Economics, Jerusalem, Israel
DEMO Keeney, R. L. 1971. Utility indepen-
dence and preferences for multi-
DEMO consequences. Oper. Res.
19:875-93
142. Keeney, R. L. 1973. A DEMO analysis
with multiple objectives: The Mexico
City Airport. Bell ~. Econ. DEMO Sci.
4:101-17
143. Keeney, R. L. 1974. Multiplicative util-
ity DEMO Oper. Rex 22:22-34
144. Keeney, R. L. 1975. Energy policy DEMO
value tradeoffs. IIASA Res. Memo RM-
75-76. Schloss Laxenburg, Austria: Int.
Inst. Appl. Syst. Anal.
145. Keeney, R. L. 1975. Examining corpo-
rate policy using multiattribute utility
analysis. Sloan Manage. Rev. 17:63-76
146. Keeney, R. L., Sicherman, A, 1975. An
interactive computer program for as-
sessing and analyzing preferences con-
eerning multiple objectives. IIASA Res.
Memo 75-12. DEMO Laxenburg, Aus-
tria: Int. Inst. Appl. Syst. Anal.
147. Kelly, DEMO W. III, Peterson, C. R. 1971.
Probability estimates and probabilistic
procedures in current-intelligence anal-
ysis. IBM Rep. 71-5047. Gaithersburg,
Md: Int. Bus. Mach.
148. Kelly, C. W. III, Peterson, C. R. 1975.
Decision theory research. DD1 Tech.
Rep. DT/TR 75-5. McLean, Va: Deci-
DEMO & Designs
149. Kidd, J. B. 1970. The utilization of sub-
DEMO probabilities in production plan-
ning. Acta Psychol. 34:338-47
150. Klee, DEMO J. 1971. The role of decision
models in the evaluation of competing
environmental health alternatives.
Manage. ScL 18B:52-67
151. Kleiter, G. D. 1975. Dynamic decision
behavior: Comments on Rapoport’s pa-
per. See Ref. 86, DEMO 371-80
152. Kleiter, G. D. 1975. Estimating the
planning horizon in DEMO multistage deci-
sion task. Psychol. Res. 38:37-64
153. Kleiter, G. DEMO, Gaehowetz, H., Huber,
D. 1976. Bibliography: Decision Mak-
ing. Salzburg, Austria: Psyehol. Inst.,
Univ. Salzburg
154. Kleiter, G. D., Wimmer, H. 1974. In-
formation seeking in a multistage bet-
ting DEMO Arch. Psychol. 126:213-30
155. Knurl, K., Burkett, G. 1975. DEMO
sional socialization in a surgical spe-
cialty: Acquiring medical judgment.
Soc. DEMO Med. 9:397-404
156. Kneppreth, N. P., Gustafson, D. H.,DEMO
Leifer, R. P., Johnson, E. M. 1974.
Techniques for the DEMO of worth.
Tech. Paper 254. Arlington, Va: Army
Res. Inst.
157. Kozieleeki, J. 1975. Psychologiczna Te-
oria Decyzji (Behavioral Decision The-
ory)DEMO Warszawa, PWN 352 pp. (Table
of contents in English and Russian)
158. Kozielecki, J. 1975. The internal repre-
sentation of risky tasks. Pol. Psychol.
Bull. 6:115-21
159. Krantz, D. H., Atkinson, R. C., Luce,
R. D., Suppes, P., eds. 1974. Contempo-
DEMO Developments in Mathematical Psy-
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal DEMO only.
Annual Reviews
www.annualreviews.org/aronline
34
SLOVIC,
FISCHHOFF & LICHTENSTEIN
chology, Vol. 1. San Francisco: Free-
man
160. Kunreuther, H. 1976. Limited knowl-
DEMO and insurance protection. Public
Policy 24:227-61
Kusyszyn, I. 1972. Psychology DEMO gam-
bling, risk-taking, and subjective
probability: A bibliography. J. Suppl.
DEMO Serv., Cat. Sel. Doc. Psychol. 2:7
Kusyszyn, I. 1973. Gambling, risk-tak-
ing and personality: A bibliography.
Int. J.. Addict. 8:173-90
DEMO, E. J. 1975. The illusion of con-
trol. J. Per~Soc. Psychol. DEMO:311-28
Langer, E. J., Roth, J. 1975. Heads I
win, tails it’s chance: The illusion of
control as a function of the sequence of
outcomes in a purely chance task. d..
Per~ Soc. Psychol. DEMO:951-55
Lee, W. 1971. Decision Theory and
Human Behavior New York: Wiley.
352 pp.
Leon, M., Anderson, N. H. 1974. A
ratio rule from integration theory ap-
plied to inference judgments. JEP
102:27-36
DEMO, I. P. 1974. Averaging processes
and intuitive statistical judgments.
OBHP 12:DEMO
Levin, I. P. 1976. Information integra-
tion in numerical judgments and DEMO
sion processes. JEP:Gen. 104:39-53
Levine, J. M., Samet, DEMO (3. 1973. Infor-
mation seeking with multiple sources of
conflicting and DEMO information.
Hum. Factors 15:407-19
Levine, J. M., Samet, M. DEMO, Brahlek,
R. E. 1975. Information seeking with
limitations on available DEMO and
resources. Hum. Factors 17:502-13
Levit, R. A., Alden, DEMO G., Eriekson,
J. M., Heaton, B. J. 1974. Development
DEMO application of a decision aid for tac-
tical control of battlefield operations.
ARIDAHC19-73-C-O069, Vol. 2. Min-
neapolis: Honeywell
Libby, R. 1975. The use of simulated
decision makers in information evalu-
ation. Account. Rev. 50:475-89
DEMO, S. C., Earle, T., Slovic, P.
1975. Cue utilization DEMO a numerical
prediction task. JEP.’Hum. Percept. Per-
formance 104:77-85
Lichtenstein, DEMO C., Fischhoff, B. 1976.
Do those who know more also know
more about how much they know? ORI
Re~ Bull, 16(1) Eugene: Oregon Res.
Inst.
Lichtenstein, S. C., Fisehhoff, B., Phil-
lips, L. 1976. Calibration of probabili-
ties: The state of the DEMO See Ref. 12
176. Lichtenstein, S. C., Slovic, P. 1971. DEMO
versals of preference between bids and
choices in gambling decision. JEP
89:46-55
177. Lichtenstein, S. C., Slovic, P. 1973. Re-
sponse-induced reversals of preference
in gambling: An extended replication in
Las Vegas. JEP 101:16-20
178. Lindell, M. K., Stewart, T. R. 1974.
The effects of redundancy in multiple-
cue probability learning. Am. J. Psychol.
87:393-98
DEMO Lindman, H. R. 1971. Inconsistent
preferences among gambles. JEP 89:
DEMO
180. Loftus, E. 1974. The incredible eyewit-
ness. Psychol. Today 8:DEMO
181. Lopes, L. 1976. Model based decision
and judgment in stud DEMO JEP.’Gen.
In press
182. Louviere, J.J. 1974. Predicting theeval-
uation of DEMO stimulus objects from ab-
stract evaluation of their attributes: The
case DEMO trout streams. £ Appl. PsychoL
59:572-77
183. Lute, R. D. DEMO Individual Choice Be-
havior. New York: Wiley
184. Lyon, D., DEMO, P. 1976. Dominance
of accuracy information and neglect of
base rates DEMO probability estimation.
Acta Psychol. In press
185. MacCrimmon, K. R. 1968. DEMO
and normative implications of the deci-
sion theory postulates. In Risk and Un-
certainty, ed. K. Borch, J. Mossin, pp.
3-32. New York: St. Martin’s. 455 pp.
186. MacCrimmon, K. R. 1973. An over-
DEMO of multiple objective decision mak-
ing. In Multiple Criteria Decision Mak-
ing, ed. J. L. Cochrane, M. Zeleny, pp.
18-44. Columbia, SC: Univ. South
Carolina Press. 816 pp.
187. MacCrimmon, K. R. 1974. Managerial
decision making. In Contemporary
Management: Issues and Viewpoints,
ed. J. W. McGuire, pp. 445-95. Engle-
wood Cliffs, NJ: Prentice-Hall
188. MacCrimmon, DEMO, Larsson, S. 1976.
Utility theory: Axioms versus "para-
doxes." DEMO Rational Decisions Under
Uncertainty, special volume of Theory
and Decision, ed. M. Allais, O. Hagen.
In press
189. MacCrimmon, K. R., Siu, J. K. 1974.
Making trade-offs. Decis. ScL 5:680-
7O4
190. MacCrimmon, K. R., Wehrung, D. A.
1975. Trade-off analysis: Indifference
and DEMO proportion. Fae. Corn-
met. Bu~ Admin. ~Vork. Pap. 323. Van-
eouver, DEMO: Univ. British Columbia
K.
161.
162.
163.
164.
165.
166.
167.
DEMO
169.
170.
171.
172.
173.
174.
175.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/DEMO For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION
THEORY
35
191. Marks, D. F., Clarkson, J. K. 1972. An
explanation of conservatism in the
bookbag-and-pokerchips DEMO Acta
Psychol. 36:145-60
192. Marks, D. F., Clarkson, J. DEMO 1973.
Conservatism as non-Bayesian perfor-
reply to DeSwart. Acta Psy-
mance: DEMO 37:55-63A
193. McCann, J. M., Miller, J. G., Mosko-
witz, H. 1975. Modeling and testing dy-
namic multivariate decision processes.
OBHP 14:281-303
194. Merkhofer, M. W. 1975, Flexibility and
decision analysis. DEMO Anal, Program
Res. Rep. EES-DA-75-L Stanford
Univ. Press
195. Mertz, W. H., Doherty, M. E. 1974.
The influence of task characteristics on
DEMO of cue combination. OBHP
12:196-216
196. Messick, D. M., Campos, F. T. 1972.
Training and conservatism in subjective
probability revision. JEP 94:335-37
197. Miller, P. M. 1971. Do labels mislead?
A multiple cue study, within the frame-
work of Brunswik’s probabilistic func-
tionalism. OBHP 6:480-500
198. Mishan, E. J. 1972. Cost-BenefitAnaly-
sis. New York: DEMO
198a. Monahan, J., Cummings, L. 1974. Pre-
diction of dangerousness DEMO a function
of its perceived consequences. J. Crim.
Justice 2:239-42
199. Montgomery, H. 1976. A study of in-
transitive preferences using a think
aloud procedure. See Ref. 12
200. Moskowitz, H. 1974. Effects of problem
representation and feedback on rational
behavior in Allais and Morlat-type
problems. Decis. DEMO 5:225-42
201. Moskowitz, H. 1974. Regression mod-
els of behavior DEMO managerial decision
making. OMEGA, lnt. Z Manage. ScL
2:677-90
202. DEMO, H., Miller, J. G. 1972. In-
formation and decision systems DEMO pro-
duction planning: An inter-disciplinary
perspective. Inst. Res. Behav. Econ.
Manage. DEMO paper 373. West La-
fayette, Ind: Purdue Univ.
203. Murphy, DEMO H. 1973. A new vector par-
tition of the probability score. J. AppL
Meteorol. 12:595-600
204. Murphy, A. H. 1974. A sample skill
score for probability forecasts. Mort.
Weather Rev. 102:48-55
205. Murphy, A. H., Winkler, R. L. 1970.
Scoring rules in probability assessment
and DEMO Acta Psychol. 34:
273-86
206. Murphy, A. H., Winkler, DEMO L. 1971.
Forecasters and probability forecasts:
Some Meteorol. current Soc. 52:239-47problems. Bull. Am.
207. Murphy; A. H., Winkler, R. L. 1974.
Probability forecasts: A survey of na-
tional weather service forecasters. Bull.
Am. Meteorol. Soc. 55:1449-53
208. Newman, J. R. 1975. Assessing the reli-
ability and validity of multi-attribute
utility procedures: An application of the
theory of generalizability. SSR! Res.
Rep. 75-Z Los Angeles: Univ. South.
Calif.
209. Nickerson, R. S., Feehrer, C. E. 1975.
Decision making and training: A review
of theoretical and empirical studies of
decision making and their implications
for the training of decision makers.
Tech. Rep. 73-C-0128-1. Orlando, Fla:
Nay. Train. Equip. Cent. 210 pp.
210. Nisbett, R. E., DEMO, E. 1975. Attri-
bution and the psychology of predic-
tion. J. DEMO Soc. Psychol. 32:932-43
210a. Norman, K. L., Louviere, J. DEMO 1974.
Integration of attributes in bus trans-
portation: Two modeling approaches. DEMO
Appl. Psychol. 59:753-58
211. O’Connor, M. F. 1973. The application
DEMO multiattribute sealing procedures to
the development indices of water qual-
ity. Cent. Math. Stud. Bus. Econ. Rep.
7339. Univ. Chicago Press
212. Olander, F. 1975. Search behavior in
non-simultaneous choice situations:
Satisficing or maximizing. See DEMO 86,
pp. 297-320
213. Payne, J. W. 1973. Alternative ap-
DEMO to decision making under risk:
Moments versus risk dimensions. Psy-
chol. Bull. 80:439-53
214. Payne, J. W. 1976. Task complexity and
contingent processing in decision ma-
king: An information search and proto-
col analysis. OBHP. In press
215. Payne, J. W., Braunstein, M. L. 1971.
Preference among gambles with equal
underlying distributions. JEP 87:13-18
216. Peskin, H. M., Seskin, E. P. 1973. Cost
Benefit Analysis and Water DEMO
Policy. Washington, DC: Urban Inst.
325 pp.
217. Peterson, C. DEMO, ed. 1973. Special Issue:
Cascaded inference. OBHP 10:315-432
218. DEMO, C. R., Beach, L. R. 1967. Man
as an intuitive DEMO Psychol. Bull.
68:29-46
219. Pitz, G. F. 1974. Subjective probability
DEMO for imperfectly known
quantities. In Knowledge and Cognition,
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on DEMO/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
36
SLOVIC,
FISCHHOFF & LICHTENSTEIN
ed. L. DEMO Gregg, pp. 29-41. New York:
Wiley. 321 pp.
220. Pollay, R. W. 1970. The structure of
executive decisions and decision times.
Admi~ DEMO Q. 15:459-71
221. Raiffa, H. 1968. Decision dnalysis: In-
troductory Lectures on Choice Under
Uncertainty. Reading, Mass: Addison
Wesley. 309 pp.
DEMO Ramanaiah, N. V., Goldberg, L. R.
1976. Stylistic components of DEMO
judgment: The generality of individual
differences. Appl. Psychol. Meas. In
press
DEMO Rapoport, A. 1966. A study of human
control in a stochastic DEMO deci-
sion task. Behav. ScL 11:18-32
224. Rapoport, A. 1975. DEMO para-
digms for studying dynamic decision
behavior. See Ref. 86, pp. DEMO
225. Rapoport, A., Burkheimer, G. J. 1971.
Models for deferred DEMO making. J.
Math. Psychol. 8:508-38
225a. Rapoport, A., Tversky, DEMO 1970.
Choice behavior in an optimal stopping
task. OBHP 5:105-20
226. Rapoport, A., Wallsten, T. S. 1972. In-
dividual decision behavior. Ann. Rev.
Psycho[. 23:131-75
227. Reeser, C. 1971. The use of sophis-
ticated analytical methods for decision
making in the aerospace industry. MSU
Bus. DEMO 19:63-69
228. Restle, F. 1961. Psychology of Judgment
and Choice. DEMO York: Wiley
229. Ronen, J. 1973. Effects of some proba-
bility displays on choices. OBHP
9:1-15
230. Russo, J. E., Kriescr, G., Miyashita, S.
1975. An effective display of unit price
information. DEMO Mark. 39:11-19
231. Russo, J. E., Rosen, L. D. DEMO An eye
fixation analysis of multialteruativc
choice. Merr~ Cogn. 3:267-76
232. Savage, L. J. 1954. The Foundations of
Statisticz New York: Wiley. DEMO pp.
233. Sayeki, Y. 1972. Allocation of impor-
tance: An axiom system. £ Math. Psy-
choL 9:55-65
234. Sayeki, Y., Vesper, K. H. 1973. Alloca-
tion of importance in a hierarchical goal
structure. DEMO Sci. 19:667-75
235. Schlaifer, R. 1969. ,4nalysis of Deci-
sions Under Uncertainty. New York:
McGraw-Hill. 729 pp.
236. Schmitt, N., DEMO, A. 1975. A re-
evaluation of the effect of cue redudancy
DEMO multiple-cue probability learning.
JEP 104:307-15
237. Sfhmidt, F. L., Marshall, R. L. 1973.
Construction and use of a paramorphic
representation of departmental policies
in graduate admissions decision mak-
ing. J. Suppl. Abstr. Serv., Cat. Sel. Doc.
Psychol. 3:92
238. Schum, D. A. 1975. Contrast effects in
inference: On the conditioning of cur-
rent evidence by prior evidence. Res.
Rep. Set. 75-05. Houston, Tex: Rice
Univ.
239. Schum, D. A. 1975. On the behavioral
richness of cascaded inference models:
Examples DEMO jurisprudence. Res. Rep.
Set. 75-1. Houston, Tex: Rice Univ.
240. Seghers, R. C., Fryback, D. G., Good-
man, B. C. 1973. Relative variance pref-
erences in a choice-among-bets para-
digm. Eng. Psychol. Lab. DEMO Rep.
011313-6-T. Ann Arbor: Univ. Michi-
gan
241. Selvidge, J. 1975. A three-step proce-
dure for assigning probabilities to rare
events. See Ref. DEMO, pp. 199-216
242. Shah, S. A. 1975. Dangerousness and
civil commitment of the mentally ill:
Some public policy consideration..4m.
J. Psychiatry 132:DEMO
243. Shanteau, J. 1972. Descriptive versus
normative models of sequential infer-
DEMO jtfdgment. JEP 93:63-68
244. Shanteau, J. 1975. An information-inte-
gration DEMO of risky decision mak-
ing. See Ref. 60, pp. 110-34
245. DEMO, J. E., Richards, M. D., Slo-
cum, J. W. DEMO Comparative analysis
of expectancy and heuristic models of
decision behavior. J. Appl. Psychol.
60:361-68
246. Shuford, E., Brown, T. A. 1975. Elicita-
tion of personal probabilities and their
assessment. Instr. Sci. 4:137-8g
247. DEMO, L. S., Eistein, A. S. 1975.
Studies of problem solving, judgment,
and decision making: Implications for
educational research. In Review of Re-
search in Education, ed. F. N. Kerlin-
get, 3:3-42. DEMO, Ill: Peacock Publ.
3O5 pp.
248. Slovlc, P. 1972. From DEMO to
Simon: Speculations--and some evi-
dence-about man’s ability to process
information. DEMO Res. Monogr. 12(2).
Eugene: Ore. Res. Inst.
249. Slovic, P. 1972. Psychological study of
human judgment: Implications for in-
vestment decision making. J. Finance
27:779-99
250. Slovic, P. 1975. Choice between equal-
ly-valued alternatives. JEP.’Hum. Per-
cept. Performance 1:280-87
251. Slovic, P., DEMO, B., Lichtenstein,
S. C. 1976. The certainty illusion. ORI
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities DEMO on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION
THEORY
37
Rez Bull. 16(4)DEMO Eugene: Ore. Res.
Inst.
252. Slovic, P., Fischhoff, B., DEMO,
S. Co 1976. Cognitive processes and so-
cietal risk taking. See Ref. 1
253. Slovic, P., Kunreuther, H., White, G. F.
1974. Decision processes, rationality
and adjustment to natural hazards. In
Natural Hazards, Local, National and
Global, ed. G. F. White, pp. 187-205.
DEMO York: Oxford Univ. Press. 288 pp.
254. Slovic, P., Lichtenstein, .S.C. 1971.
Comparison of Bayesian and regression
approaches to the study of DEMO
processing in judgment. OBI-IP 6:649-
744
255. Slovic, P., MacPhillamy, J. 1974. Di-
mensional commensurability and cue
utilization in comparative judgment.
OBHP 11:172-94
256. Slovic, P., Tversky, A. 1974. Who ac-
cepts Savage’~ axiom? Behav. ScL
19:368-73
257. Snapper, K. J., Fryback, D. G. 1971.
Inferences based on unreliable reports.
JEP 87:401--4
258. Snapper, K. J., O’Connor, M. F., Ein-
horn, H. J. 1974. Social indicators: A
new method for indexing quality. SOC.
Res. Group Tech. Rep. 74-4. Washing-
ton DC: George Washington Univ.
259. Snapper, DEMO J., Peterson, C. R. 1971.
Information seeking and data diagnos-
ticity. JEP 87:429-33
260. Spetzler, C. S., Stall yon Holstein,
DEMO S. 1975. Probability encoding in
decision analysis. Manage. Sc~ 22:
340-58
261. Stachowski, R. 1974. Effect of predeci-
sional information integration strategy
on cognitive conservatism. Pol. Psychol.
Bull, 5:17-23
262. Stall yon Holstein, DEMO S. 1971. An
experiment in probabilistic weather
forecasting. J. dppl. MeteoroL 10:
635-45
263. Stall von Holstein, C.-A. S. 1971. Two
techniques for assessment of subjective
probabdity distributions~an experi-
mental study, dcta Psychol. 35:478-94
264. Stall yon Holstein, C.-A. S. 1972.
Probabilistic forecasting: An experi-
DEMO related to the stock market.
OBHP 8:139-58
265. Stanford Research Institute 1968. Deci-
sion analysis of nuclear plants in dec-
tdcal system expansion. DEMO Pro~ 6496
Final Rep.
266. Steiger, J. H., Gettys, C. DEMO 1972. Best-
guess errors in multistage inference.
JEP 92:1-7
267. Stenson, H. H. 1974. The lens model
with unknown cue structure. Psychol.
Rev. 81:257--64
268. Stewart, T. R., Carter, J. E. 1973. POL-
ICY: An interactive computer program
for externalizing, executing, and refin-
ing judgmental policy. Prog. Res. Hum.
Judgment Soc. Interaction Rep. 139.
Boulder: Univ, Colorado Inst, Behav.
Sci.
269. Streufert, S. C. 1973. Effects of informa-
tion relevance on decision making in
complex environments. Mere. Cogn.
1:DEMO
270. Sue, S., Smith, R. E., Caldwell, C. 1973.
DEMO of inadmissible evidence on the
decisions of simulated jurors: A moral
DEMO J. AppL Soc. Psychol. 3:
345-53
271. Svenson, O. 1973. DEMO of strategies
in subjective probability inferences as
evidenced in continuous verbal reports
and numerical responses. Psychol. Labs.
Rep. 396. Sweden: Univ. Stockholm
272. Svenson, O. 1974. A note on think
aloud protocols obtained during the
choice of a home. Psychol. Lab~ Rep.
42L Sweden: Univ. Stockholm
273. Svenson, O. 1975. A unifying interpre-
tation of different models for the inte-
gration of information when evaluating
gambles. Scand. J. Psychol. 16:187-92
274. DEMO, O., Montgomery, H. 1976. On
decision rules and information process-
DEMO strategies for choices among mui-
tiattribute alternatives. Scand. J. Psy-
choL In press
275. Swinth, R. L., Gaumnitz, J. E., Ro-
driguez, C. 1975. Decision making pro-
cesses: Using discrimination nets for
security selection. Decis. Sci. 6:439-48
Tani, S~ N. 1975. Modeling and decision
analysis. Deciz Anal. Prog. Res. Rep.
EES-DA-73-3. Stanford Univ.
Taylor, R. L., DEMO, W. D. 1974.
Capturing judgment policies: A field
study of performance appraisal. Acad.
Manage. £ 17:440-49
Teigen, K. H. 1974. Overestimation of
ehol. subjective 15:56-62probabilities. Scand. J. Psy-
Teigen, K. H. 1974. Subjective sam-
pling distributions and the additivity of
estimates. Scand. d. Psychol. 15:DEMO
Tversky, A. 1972. Choice by elimina-
tion. J. Math. Psychol. 9:DEMO
Tversky, A. 1972. Elimination by as-
pects: A theory of choice. PsychoL Rev.
79:281-99
Tversky, A. 1975. Assessing uncer-
tainty, d. DEMO Stat. Soc. 36B:148-59
276.
277.
278.
279.
280.
281.
282.
D.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of DEMO Libraries on 04/23/08. For personal use only.
Annual Reviews
www.annualreviews.org/aronline
38
SLOVIC,
FISCHHOFF & LICHTENSTEIN
283. Tversky, A. 1975. On the Elicitation of
Preferences: Descriptive and Prescriptive
Considerations. Presented at Workshop
on Decision Making with Multiple
Conflicting Objectives, IIASA, Schloss
DEMO, Austria
284. Tversky, A., Kahneman, D. 1971. The
belief in the "law of small numbers."
Psychol. Bull. 76:105-10
285. Tversky, A., Kahneman, D. 1973.
Availability: A heuristic for judging fre-
DEMO and probability. Cogn. Psychol.
5:207-32
286. Tversky, A., Kahneman, DEMO 1974.
Judgment under uncertainty: Heuristics
and biases. Science 185:1124-31
287. DEMO, E., Metersky, M. L. 1971. Util-
ity theory applied to DEMO sys-
tem effectiveness evaluation. Manage.
ScL 17B:817-28
288. Ulvila, J. DEMO 1975. A pilot survey of
computer programs for decision analy-
sis. DDI Tech. Rep. 75-2. McLean, Va:
Decisions & Designs
289. Vertinsky, DEMO, Wong, E. 1975. Eliciting
preferences and the construction of in-
difference maps: A comparative empiri-
cal evaluation of two measurement
methodologies. Socio-Econ. Plan. ScL
9:15-24
290. Vlck, C. A. J. 1973. Coherence of hu-
man judgment in a limited probabilistic
environment. OBHP 9:460-81
291. Vlek, C. A. J. 1973. The fair betting
game as an admissible procedure DEMO as-
sessment of subjective probabilities. Br.
£ Math. Stat. Psychol. 26:18-30
292. Vlek, C. A. J., Wagenaar, W. A. 1975.
Judgment and Decision Under Uncer-
tainty. Leiden, The Netherlands: Univ.
Leiden. 82 pp.
DEMO yon Winterfeldt, D. 1975. An overview,
integration, and evaluation of utility
theory for decision analysis. SSRI Rez
Rep. 75-9. Los Angeles: Univ. South.
Calif.
294. von Winterfeldt, D., Edwards, W. 1973.
Evaluation of complex stimuli using
multi-attribute utility procedures. Eng.
PsychoL Lab. Tech. Rep. 011313-2-T.
DEMO Arbor: Univ. Michigan
294a. yon Winterfeldt, D., Edwards, W.
1973. Flat maxima in linear optimiza-
tion models. Eng. Psychol. Lab. Tech.
Rep. DEMO Ann Arbor: Univ.
Michigan
295. von Winterfeldt, D., Edwards, W. 1975.
Error in decision analysis: How to cre-
ate the possibility of large losses by us-
ing dominated strategies. SSRI Res.
Rep. 75-4. Los DEMO: Univ. South.
Calif.
296. von Winterfeldt, D., Fischer, G. W.
1975. Multi-attribute utility theory:
Models and assessment procedures. See
Ref. 86, pp. 47-86
297. Wainer, H. 1976. Estimating coeffi-
cients in linear models: It don’t make no
nevermind. Psychol. Bull. 83:213-17
298. Wainer, DEMO, Zill, N., (3ruvaeus, (3.
1973. Senatorial decision making: DEMO
Prediction. Behav. Sci. 18:20-26
299. Wallsten, T. S. 1971. Subjectively DEMO
pected utility theory and subjects’ prob-
ability estimates: Use of measurement-
DEMO techniques. JEP 88:31-40
300. Wallsten, T. S. 1972. Conjoint-measure-
ment DEMO for the study of
probabilistic information processing.
Psychol. Rev. 79:245-60
301. Wallsten, T. 1975. Using a conjoint
measurement model to develop theory
about probabilistic information process-
ing. Psychometric Lab. Rep. 127 (re-
vised). Chapel Hill, NC: Univ. North
Carolina
302. Ward, W. M. 1975. Heuristic use or in-
formation integration in the estimation
of subjective likelihood? Bull. Psychon.
Soc. 6:43-46
303. Watson, S. R., Brown, R. V. 1975. Is-
sues in the value of decision analysis.
DDI Tech. Rep DEMO McLean, Va: De-
cisions & Designs
304. Watson, S. R., Brown, R. V. 1975. Case
studies in the value of decision analysis.
DDI Tech. Rep. 7.5-10. McLean, Va:
Decisions & Designs
305. Wheeler, G. E., Edwards, W. 1975.
Misaggregation explains conservative
inference about normally distributed
populations. SSRI Res. Rep. 75-11. Los
Angeles: Univ. South. Calif.
306. Wiggins, N. 1973. Individual differ-
ences in human judgments: A mul-
DEMO approach. See Ref. 33, pp.
110-42
307. Wiggins, N., Kohen, E. S. 1971. Man
versus model of man revisited: The fore-
casting of graduate school success. J.
Pers. Soc. Psychol. 19:100-6
308. Winkler, R. L. 1971. Probabilistic pre-
diction: Some experimental results. J.
Am. Stat. Assoc. 66:675-85
309. Winkler, R. L., Murphy, A. H. 1973.
Experiments in the laboratory and the
real world. OBHP 10:252-70
310. DEMO, J. A., Mockovak, W. P. 1973. De-
scriptive modeling of DEMO
probabilities. OBHP 9:292-306
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of Universities Libraries on 04/23/08. For personal DEMO only.
Annual Reviews
www.annualreviews.org/aronline
BEHAVIORAL DECISION
THEORY
39
311. Wohlstetter, A. 1974. Legends of the
strategic arms race, Part I: The driving
machine. DEMO Rev. pp. 67-92
311a. Wohlstetter, R. 1962. Pearl Harbor."
lYarning DEMO Decision. Stanford Univ.
Press. 422 pp.
312. Wright, P. L., 1973. Use of consumer
judgment models in promotion plan-
nine. J. Marl 37:DEMO
313. Wright, P. 1974. The harassed decision
maker: Time pressures, DEMO and
the use of evidence. J. Appl. Psychol.
59:555-61
314. Wright, P. 1974. The use of phased,
noneompensatory strategies in deci-
sions between multiattribute products.
Grad. Sch. Bus. Res. Pap. Set. 223.
Stanford Univ.
DEMO Wright, W. F. 1975. Cognitive informa-
tion processing models: An empirical
study. Grad. Sch. Bus. Res. Paper Set.
246. Stanford Univ.
316. Wyer, R. S. 1974. Cognitive Organiza-
tion and Change: An Information Pro-
cessing Approach. Potomac, Md: Erl-
baum. 502 pp.
317. Wyer, R. S. 1976. An investigation of
the relations among probability esti-
mates. OBItP 15:DEMO
318. Zagorski, M. A. 1975. Risky decision:
attention effects or DEMO effects?
Acta Psychol. 39:487-94
319. Zieve, L. 1966. Misinterpretation DEMO
abuse of laboratory tests by clinicians.
Ann. NY Acad. Sci. 134:563-72
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of DEMO Libraries on 04/23/08. For personal use only.
Annu. Rev. Psychol. 1977.28:1-39. Downloaded from arjournals.annualreviews.org
by Ontario Council of DEMO Libraries on 04/23/08. For personal use only.{1g42fwefx}