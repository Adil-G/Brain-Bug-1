Computational Models 1
Computational models of decision making
Jerome R. Busemeyer
&
Joseph G. Johnson
Indiana University
April 7, 2003
To appear in D. Koehler & N. Harvey (Eds.) Handbook of Judgment and Decision
Making, Blackwell Publishing Co.
Send Correspondence to:
Jerome R. Busemeyer
Psychology Department
DEMO University
Bloomington In, 47405
voice: 812 855 4882
fax: 812 DEMO 4691
email: jbusemey@indiana.edu
Computational Models 2
Abstract
This chapter presents a connectionist or artificial neural DEMO approach to
decision making. An essential idea of this approach is that decisions are based on the
accumulation of the affective evaluations produced by DEMO action until a threshold
criterion is reached. This type of sequential sampling process forms the basis for decision
making in a wide variety of DEMO cognitive tasks such as perception, categorization, and
memory. We apply these concepts to several important preferential choice phenomena,
including similarity effects, attraction effects, compromise effects, loss aversion effects,
and preference reversals. These DEMO indicate that a relatively complex model of an
individual’s choice process reveals a relatively simple representation of the individual’s
underlying value structure.
Computational Models 3
What are computational models of cognition?
In his DEMO book on computational vision, Marr (1982) proposed three levels of
DEMO about cognitive systems. At the highest level, theories aim to understand DEMO
abstract goals a sys tem is trying to achieve; at an DEMO level, theories are designed
to explain the dynamic processes used to DEMO the top level goals; and at the bottom
level, theories attempt to describe the neurophysiologic substrate of the second level.
Judgment and decision-making DEMO have generally been concerned with
theorizing at the higher and more abstract levels. From this higher point of view,
explanations based on principles DEMO as context dependent weights, loss aversion, and
anchoring-adjus tment are considered satisfactory.  This chapter presents arguments for
viewing decision making from the perspective of a lower level microanalysis. By doing
so, we can try to answer deeper questions such as: why decision weights change across
contexts, DEMO people are loss averse, and why anchors are more influential than
DEMO
Computational models are constructed from simple units that conform to a small
number of elementary principles of cognition, but a large number of these simple units
are connected together to form a dynamical system. Although the DEMO of the
individual units are simple, the emergent behavior of the DEMO becomes fairly
complex.  Computational models appear in a variety of forms, but this chapter focuses on
a class known as artificial neural networks, connectionist networks, or parallel distributed
processing systems (see Grossberg, 1988; DEMO Rumelhart & McClelland, 1986, for
general overviews of these models). This class of computational models is designed to
form a bridge that DEMO between the neural and behavioral sciences.
Computational Models 4
How does the brain make decisions?
A decade DEMO, the brain was an impenetrable black box, but with recent advances
in neuroscience, we can start to look inside. It is informative to point out a conclusion
arising from converging evidence obtained through neuroscience research DEMO decision
-
making. Neuroscientists have examined decision-making processes in the brains of
Macaque monkeys using single cell recording techniques (for reviews, see Gold &
Shadlen, 2001, 2002; Platt, 2002; Schall, 2001), DEMO well as from the brains of humans
using evoked response potentials (DEMO, Coles, Sirevaag, & Donchin, 1988). A simple
but important conclusion from this work is that decisions in the brain are based DEMO the
dynamic accumulation of noisy activation for each action, and the DEMO whose
activation first exceeds the threshold is chosen. This process is illustrated in Figure 1, for
three actions, with each trajectory representing the DEMO activatio n (i.e., preference
state) for an action. The horizontal DEMO represents deliberation time and the vertical axis
indicates the activation for each action at each moment in time. In this figure, action A
reaches the threshold first, and is chosen at time T = 425.
Computational Models 5
Figure 1: The decision process for a choice among three actions
2
1.5
1
0.5
0
-0.5
-1
-1.5
-2
0
DEMO
A
C
100
Threshold  Bound
200 300
Deliberation Time
A
B
DEMO
400
500
This dynamic decision process is known as a sequential sampling process
(DeGroot, 1970). It forms the basis of decision models DEMO in a wide variety of cognitive
applications including sensory detection (Smith, 1995), perceptual discrimination
(Laming, 1968; Link & Heath, 1975; Usher & McClelland, 2001; Vickers, 1979),
memory recognition (Ratcliff, 1978); categorization (Nosofsky & Palmeri, 1997; Ashby,
2000), probabilistic inference (Wallsten & Barton, 1982) and preferential choice
(Aschenbrenner, Albert, & Schmalhofer, 1984; Busemeyer, 1985).
Computational models for Decision Making.
Several artificial neural network or connectionist models have been recen
DEMO
developed for judgment and decision tasks: some placing more emphasis on DEMO neural
processing aspects (Grossberg & Gutowski, 1987; Levin & Levine, 1996; Usher &
McClelland, 2002), and others placing more emphasis on applications to judgment and
decision making (Holyoak & Simon, 1999; Guo and Holyoak, 2002; Busemeyer &
Preference State
Computational Models 6
Townsend, 1993; Roe Busemeyer, & Townsend, 2001)DEMO  Here we will initially focus on
our own, known as decision field theory, but we will also compare this to others later in
this chapter.
Decision field theory uses a sequential sampling process to make DEMO,
consistent with the other areas of cognition.  This theory has DEMO applied to a variety of
traditional decision making problems including decision making under uncertainty
(Busemeyer & Townsend, 1993), selling prices and certainty DEMO (Busemeyer &
Goldstein, 1992; Townsend & Busemeyer, 1995), DEMO
-attribute decision making
(Diederich, 1997), and multi
-alternative decision making (Roe et al., 2001), and decision
rule learning (Johnson & Busemeyer, in press).
To introduce decision field theory, it will DEMO helpful to consider an example
problem. Suppose you have to choose a penalty program for a young offender, convicted
of a serious crime, DEMO one of three options: (A) a mild 5 year imprisonment, with a
population of inmates that only have minor convictions, and a possibility for parole in 2
years; (B) a moderate 15 year imprisonment, with a population of inmates with
moderately serious convictions, and DEMO possibility for parole in 7 years; or (C) a severe DEMO
year imprisonment with a population of hardcore criminals with no possibility for parole.
If we assume that the offender may be either corrigible (labeled event g for good) or
incorrigible (labeled event b for bad), then Table 1 displays the six types of possible
consequences for this decision.  For example, if a mild penalty is chosen (option A) but
the criminal is incorrigible (state b), then the outcome DEMO the release of a dangerous man
who will very likely repeat the crime.
Computational Models 7
Table 1: Hypothetical Decision about Penalty for a Crime
Action
Event g: Corrigible
Event b: Incorrigible
A: Mild Penalty
B: Moderate Penalty
C: Severe Penalty
c11 : Reform to normal life
DEMO: Damage the man
c31: Destroy a life
c12: Release dangerous DEMO
c22: Delay danger
c32: Safely incarcerate
According to decision field theory, the decision maker deliberates over these
courses of action by thinking about the various possible consequences of each action.
From moment to moment, different consequences come to mind over a period of time.
For example, at one moment the decision maker may remember something (e.g., the kind
DEMO of the offender) that makes her think the offender can be DEMO, and then she is
appalled by the thought wasting his life, locked behind bars for 30 years. But at another
moment, she may recall a recent story in which a parolee committed a horrible crime, and
she may feel a cold fear arise from the idea of DEMO another on the streets in a few
years. At each moment, DEMO affective reactions to the consequences of each action are
evaluated and compared, and these comparisons are accumulated over time to form a
preference state. The preference state for an action represents the integration of all the
DEMO affective reactions produced by thinking about that action during deliberation.
This deliberation process continues until the accumulated preference for one action
reaches a threshold, which determines the choice and the deliberation time of the decision
(refer back to Figure 1).
Computational Models 8
The threshold bound for the decision process, symbolized θ, is a key parameter
for controlling speed and accuracy tradeoffs. If θ is set to a low threshold, then only a
weak preference is required to make a choice. In this case, decisions are made very
quickly, which may be reasonable for trivial decisions of small consequence. However, a
low threshold would cause the decision to be based on little thought about the
consequences, which is likely to lead to a choice with bad unforeseen outcomes. For
more serious decisions, θ is set to a very high threshold, so that a very strong preference
is required to make a decision. In this case, deliberation takes longer, but DEMO decision is
based on a more thoughtful evaluation of all the consequences, producing a choice that is
more likely to result in a positive outcome. Impulsive individuals may tend to use lower
thresholds, while perspicacious individuals may tend to use higher thresholds.
The dynamical system used to generate DEMO deliberation process is presented next,
and the connectionist network is represented in Figure 2.  The three actions
corresponding to the mild, moderate, and severe penalty option are labeled A, B, and C,
DEMO this figure. The network has three layers of simple units that perform the following
computations.
Computational Models 9
Figure 2: Connectionist Network Representation of Decision Field Theory
m11
m21
m31
m12
m22
mm
32
A
B
C
A
B
DEMO
A
B
C
Weights
Contrasts
Valences
Preferences
The inputs into this network, shown on the far left, represent the affective
evaluations of the DEMO consequences of a decision. These values are assumed to be
generated by a motivational system (hence the symbol mij ), which is not DEMO
represented here (but see Busemeyer, Townsend, & Stout, 2002). For example, m11
represents the positive evaluation of the consequence produced by reforming the offender
and allowing him to return to society as a DEMO citizen, and m12 represents the
negative evaluation of the consequence produced DEMO releasing a dangerous man back into
society.
The connections, linking the DEMO to the first layer of nodes, are designed to
represent an DEMO process. At any moment in time, the decision maker is assumed DEMO
attend to one of the possible events leading to consequences for each action. For example,
if the decision maker thinks the criminal is DEMO, then at that moment, option A is
evaluated at m12, DEMO B is evaluated at m22, and option C is evaluated at DEMO However,
if something comes to mind which makes the decision maker switch her attention and
Computational Models 10
think that the offender can be reformed, then at that later moment, option A is evaluated
at m11, option B DEMO evaluated at m21, and option C is evaluated at m31. Thus, the inputs to
the first layer fluctuate from one moment (time t) to another moment (time t+h) as the
decision maker’s attention switches from one possible event to another. The probability
of attending to a DEMO event at each moment reflects the decision maker’s underlying
subjective probability or belief that the offender is corrigible. To formalize these ideas,
we DEMO Wg(t) and Wb(t) = 1- Wg(t) as DEMO variables, called the attention weights,
which fluctuate across time. For DEMO, attention may be focused at time t on the
corrigible event DEMO that Wg(t) > Wb(t), but a moment later DEMO time t+h, attention may
switch to the incorrigible event so that DEMO(t+h) > Wg(t+h). The first layer of the network
DEMO a weighted value for each option i within a set of n options as follows
Ui(t) =  Wg(t)⋅mi1 + Wb(DEMO)⋅mi2 + e i(t),
(1)
The la st ‘error’ term, e i(t), represents the influence of irrelevant features (e.g., in an
experiment, these are features outside of an experimenter’s control). The above equation
looks like the classic weighted additive utility DEMO, but unlike the classic model, the
attention weights are stochastic rather than deterministic (see Fisher, Jia, & Luce, 2000,
for DEMO related model). The mean values of the attention weights correspond to the
deterministic weights used in the classic weighted additive model.
The connections DEMO the first and second layers are designed to perform
comparisons among weighted values of the options, to produce what are called valences.
A positive valence for one option indicates that the option has an advantage under DEMO
current focus of attention, and a negative valence for another option DEMO that the
option has a disadvantage under the current focus of attention. For example, if attention is
Computational Models 11
currently focused on event g (corrigible), then action A has an advantage over other
options, and option C has a disadvantage under this state. But these valences reverse
when attention is switched DEMO event b (incorrigible). The second layer computes the
valence for DEMO option i within a set of n options by comparing the weighted value for
option i with the average of the of the other (n -1) options:
v i(t) = Ui(t) – U(t) ,
(2)
where U(t) = Σ DEMO i Uk(t) / (n-1). Valence is closely related to the concept of advantages
and disadvantages used in Tversky’s (1969) additive DEMO model. Note, however,
that the additive difference model assumed complete DEMO of all features, whereas
the present theory assumes a sequential sampling DEMO that stops when a threshold is
crossed.
The connections, between the DEMO and third layers, and the interconnections
among the nodes in the DEMO layer, form a network that integrates the valences over time
into DEMO preference state for each action. This is a recursive network, with DEMO self-
recurrence within each unit, and negative lateral inhibitory connections between DEMO
Positive self- feedback is used to integrate the valences produced by an action over time,
and lateral inhibition produces negative feedback from other DEMO The third layer
computes the preference state for option i from a set of n options according to the linear
dynamic system:
Pi(DEMO) = s⋅Pi(t) + v i(t+h) – Σ k DEMO sik⋅Pk(t) .
(3)
Conceptually, the new state of DEMO is a weighted combination of the previous state
of preference and the new input valence. The initial preference state, Pi(0), at the start of
a decision problem, represents a preference recalled from past experience. This is used to
Computational Models 12
explain carry over effects from previous decisions or past DEMO, such as the status
quo effect (Samuelson & Zeckhauser, 1988)DEMO
Inhibition is also introduced from the competing alternatives. We assume that the
strength of the lateral inhibition connection is a decreasing function of the DEMO
between a pair of alternatives. For example, in Table 1, options A and C are more
dissimilar than options A and B, and so the lateral inhibition between A and C would be
smaller than DEMO between options A and B. Lateral inhibition is commonly used in
artificial neural networks and connectionist models of decision making to form a
competitive DEMO in which one option gradually emerges as a winner dominating over
the other options (cf. Grossberg, 1988; Rumelhart & McClelland, 1986). DEMO shown later
in this chapter, this concept serves a crucial function DEMO explaining seve ral paradoxical
phenomena of preferential choice.
In summary, a DEMO is reached by the following deliberation process: as
attention switches from DEMO event to another over time, different affective values are
probabilistically selected, and these values are compared across actions to produce
valences, and finally these valences are integrated into preference states for each action.
This process DEMO until the preference for one action exceeds a threshold criterion, at
DEMO point in time the winner is chosen. Formally, this is a DEMO process, and matrix
formulas have been mathematically derived for computing the DEMO probabilities and
distribution of choice response times (for details, see Busemeyer & Townsend, 1992;
Busemeyer & Diederich, 2002; Diederich & Busemeyer, 2003). Alternatively, Monte
Carlo computer simulation can be used to DEMO predictions from the model.
Computational Models 13
(However, all of the predictions presented below were DEMO from the matrix
formulas).
To illustrate the dynamic behavior of the model, consider a simple binary choice
between a gamble and a sure thing. Suppose values for options A and B in Table 1 are DEMO
equal to the following: m11 = .96, m12=0, m21= .40, m22 = .40. With these values, option A
can be viewed as a risky gambl
e, and option B can be viewed as a sure thing. Also
assume an equal probability of attending to events g DEMO b, i.e., Pr[Wg(t) = 1] = Pr[Wb(t) =
1] = .50. The variance of irrelevant dimensions (variance of ε ) was set to zero, the self
feedback was set to s = 1, and the lateral inhibition was set to sAB = sBA =  .01.
Under these assumptions, we computed the choice probabilities and the DEMO
deliberation times, for a wide range of threshold parameters (θ ranged from .20 to 8.0).
Figure 3 plots the relation between choice DEMO and mean decision time for option
A, the gamble, as a function of the threshold parameter. Both decision time and choice
probability increase DEMO with the threshold magnitude. Busemeyer (1985)
presents empirical evidence supporting DEMO dynamic predictions for choices between a
gamble and a sure thing under various time pressure conditions.
Computational Models 14
Figure 3: Predictions from decision field theory for binary choice
What do computational models contribute to decision theory?
Computational models DEMO a lot more complex than the algebraic models
commonly used by decision theorists. One could argue that computational models are too
microscopic in their DEMO, and they have little to show for their increased cost in
DEMO Can computational models provide a gain in explanatory power that has not
been achieved by the algebraic models? To answer this question, we DEMO review a set of
empirical phenomena that have resisted a coherent explanation by their algebraic
counterparts.
To review these empirical phenomena within a common DEMO, it will be
helpful to place the example decision problem, shown in Table 1, into a two dimensional
representation, shown in Figure DEMO below. The first dimension represents the evalua tion of
Computational Models 15
the options from the perspective that the offender is DEMO, and the second dimension
represents the evaluation of the options from DEMO perspective that the offender is
incorrigible. Consider option A from Table 1: From the perspective that th
e offender is
corrigible, then option DEMO has a very high value; but from the perspective that the DEMO
is incorrigible, then option A has a very low value. Thus DEMO A is high on the first
dimension and low on the second. Alternatively, option C has a low value from the
corrigible perspective, DEMO option C has a high value from the incorrigible perspective.
Similarly, DEMO B is midway between options A and C.  We can also DEMO other
possible options in this space, which are variations of those DEMO in Table 1.  Option D
is another penalty program that is DEMO more severe than option C; and option F is severe
Figure DEMO: Two dimensional Representations of Actions
D
F  C
B
A
Corrigible
like option C, but it is deficient, perhaps because there is DEMO security at that institution.
These examples will be used to illustrate the essential properties of the empirical
phenomena reviewed below.
Incorrigible
Computational Models 16
Similarity effect.  This refers to the effect, on DEMO probabilities, produced by
adding a competitive option D to an earlier DEMO set containing only A and C, where
option D is very DEMO to option C.  Suppose that in a binary choice between A DEMO C,
options A and C are chosen equally frequently so that Pr[ C | {A,C} ] = Pr[ A | {A,C}].
DEMO a new option D to this choice set, mainly takes away DEMO from the nearby
option C, and leaves the probability of choosing DEMO A unaffected. The empirical
result is that the probability ordering for A and C changes from equality with the binary
choice set, to Pr[ A | {A,C,D} ] > Pr[ C | {A,C,DEMO ] for the triadic choice set, producing a
violation of a DEMO principle called independence of irrelevant alternatives (see
Tversky, 1972, for DEMO review).  This robust empirical finding eliminates a large class of
DEMO choice models called simple scalability models, which includes for example,
DEMO (1959) ratio of strength model. Tversky (1972) elegantly explained these results
with a theory he called the elimination by aspects model of DEMO Tversky (1972) also
proved that the elimination by aspects model satisfies another important choice principle
called regularity, which is considered next.
Attraction effect. This refers to the effect, on choice probabilities, of adding a
DEMO option F to an earlier choice set containing only options A and C, where the decoy
F is similar to, but also dominated DEMO, option C. Suppose, once again, that in a binary
choice DEMO A and C, options A and C are chosen equally frequently DEMO that
Pr[C|{A,C}] = .50.  A second robust finding is that DEMO the decoy option F to this
choice set enhances the probability of the nearby dominant option C, so that
Pr[C|{A,C,F}]  >  Pr[C|{A, C}], which produces a violation of the regularity principle
(Huber, Payne, & Puto, 1982; see Heath & Chatterjee, 1995, DEMO a review). Consequently,
Computational Models 17
this result cannot be explained by Tversky’s (1972) DEMO by aspects model.  This
violation of regularity also rules out a DEMO class of random utility models of choice
(Luce & Suppes, 1965), including Thurstone’s (1959) preferential choice theory.
Compromise effect.  This refers to the effect, on choice probabilities, of adding an
intermediate option DEMO to an earlier choice set containing only two extreme options A and
C, where the compromise B is midway between the two extremes. Suppose, that all the
binary choices are equal so that Pr[ A | {A,B) ] = Pr[ A | {A,C) ] = DEMO B | {B,C) ] = .50.
A third robust finding DEMO that adding the compromise option B to a set containing A and C
enhances the probability of the compromise option so that Pr[ B DEMO {A,B,C} ]  >
Pr[A|{A,B,C}]  =  Pr[ C | {A,B,C}], which is another violation of the independence
between irrelevant alternatives principle (Simonson, 1989; see Tversky & Simonson,
1993 for a review). Tversky and Simonson (1993) proposed a DEMO
preference model based on the principle of loss aversion to explain the attraction and
compromise effects. However, the context-dependent preference model cannot account
for the similarity effect (see Roe et al., 2001, for a proof). Thus no model was proposed
to account for all three simultaneously.
DEMO common explanation. Decision field theory provides an explanation for all
three phenomena using a common set of principles (see Roe et al., 2001, for details). In
other words, we do not need to change any of the assumptions of the model across
phenomena, and neither do we need to change any of the model parameters. The same
assumptions DEMO apply, and the same parameters can be used to predict all DEMO
effects. The mathematical basis for these predictions is derived elsewhere (see DEMO et al.,
2001; Busemeyer & Diederich, 2002), and here we only present an intuitive discussion.
Computational Models 18
First consider the similarity effect -- that is, the effect of adding option D to an
earlier set containing A and DEMO The attention
-switching property is essential for
explaining this effect. On the one hand, whenever attention is focused on the corrigible
event (corresponding DEMO the first dimension in Figure 4), then option A
alone gets a large
positive advantage, while options C and D both have negative valences; on the other
hand, whenever attention is focused on the DEMO event (corresponding to the
second dimension in Figure 4), then DEMO options C and D have positive valences, while
option A gets DEMO large negative valence. If an individual happens to pay more attention to
the corrigible event, then option A will tend to be chosen; DEMO if an individual happens to
pay more attention to the incorrigible event, then eith
er option C or option D tend to be
chosen. Therefore, option D only takes away probability from its neighboring option, DEMO,
and it does not affect the probability of choosing the more distant option, A.
Next consider the attraction effect. In this case the lateral inhibition mechanism
serves a crucial purpose. Neuroscientists long ago established the DEMO that the strength of
lateral inhibitory connections decrease as a function of distance, and this property is
responsible for generating contour and edge enhancement effects in vision (cf.
Cornsweet, 1970). According to decision field DEMO, lateral inhibition produces an
attraction effect for preference in the same DEMO that it produces an edge enhancement
effect for vision. During deliberation, DEMO preference state for the dominated alternative F
is driven toward a negative state because it competes with the nearby dominant
alternative C. The negative DEMO state associated with option F feeds back through a
negative inhibitory connection to option C, producing a bolstering (disinhibitory) effect
on option C. This bolstering effect is not applied to option A because it is DEMO distant from
Computational Models 19
F, and the lateral inhibitory link is too weak. Thus option C shines out by being close to
an unattractive alternative, F.
Note that the attention switching and lateral inhibition processes are assumed DEMO
be operating all the time for both the similarity and attraction effects. These two
components operate in synchrony to generate both effects. As a DEMO of fact, it is the
interaction between these two processes that DEMO essential for producing the compromise
effect.  In this case, if attention happens to focus on some irrelevant features favoring the
compromise option, B, then this sends lateral inhibition to the neighboring extreme
options A and C, decreasing their strength, which then builds up an advantage for DEMO
compromise option.
The predictions for all three effects were computed from decision field theory as
follows. We simply set the values (mij in Equation 1) proportional to the coordinates
shown in Figure 4, and the DEMO of attending to each dimension were equal
(Pr[Wg(t) = 1] =  Pr[Wb(t) = 1] = .50). The self feedback DEMO coefficient was set to s =
.94, the lateral inhibitory coefficient DEMO nearby options (e.g., sCD ) was set to .04, and DEMO
lateral inhibitory coefficient for distant options (e.g., sAC ) was set to .001. The standard
deviation of the error, e, due to DEMO dimensions was set equal to 1.25. Figure 5
shows the predictions for the triadic choice probabilities plotted as a function of
deliberation time, separately for each effect. As can be seen in this figure, a common set
of assumptions, and exactly the same parameters, reproduces all three DEMO
Computational Models 20
Figure 5: Predictions computed from decision field theory
An interesting prediction that follows from the above explanations for the
attraction and DEMO effects is that they should become stronger as deliberation
time increases. In other words, if decision makers are encouraged to deliberate longer,
then the attraction and compromise effects will increase. This is because lateral inhibitory
DEMO grow in strength during deliberation. Two experiments have now been reported
that confirm these dynamic predictions of the model (Simonson, 1989; Dhar, DEMO, &
Sherman, 2000).
Loss Aversion.  An influential article by Tversky and Kahneman (1991) provides
the most compelling evidence for loss DEMO The basic ideas are illustrated in Figure
6, where each letter DEMO in the figure represents a choice option described by two
Computational Models 21
attributes; such as for example, consumer products that DEMO in size and quality, or jobs
that vary in salary and DEMO  In this case, option X is high on dimension 1 but low on
dimension 2, whereas option Y is low on dimension 1 but high on dimension 2.
Figure 6: Options used to examine loss aversion
Sy
Y
Ry
Rx
Dimension 1
X
Sx
The first study DEMO a reference point, using either option R
x or Ry. Under
DEMO condition, participants were asked to imagine that they currently owned the
DEMO Rx, and they were then given a choice of keeping Rx DEMO trading it for either
commodity X or commodity Y. From the reference point of R
x, option X has a small
advantage on dimension 1 and no disadvantage on dimension 2, whereas Y has both large
advantages (dimension 2) and disadvantages (dimension 1). Under these conditions, R
x
was rarely chosen, and X was strongly favored over DEMO Under another condition,
participants were asked to imagine that they owned option Ry, and they were then given a
choice of keeping Ry or trading it for either X or Y. From the reference point DEMO R
y, Y has
a small advantage and no disadvantages, whereas X now has both large advantages and
Dimension 2
Computational Models 22
disadvantages. Under this condition, Ry was rarely chosen again, but now Y was slightly
favored over X. (The smaller effect DEMO R
y may indicate that dimension 2 was less
important than dimension 1.) Tversky and Kahneman (1991) interpreted this pair of
results as a loss aversion effect, because X was favored when Y entailed large losses
relative to the reference point R
x, but the opposite occurred when X entailed large losses
relative to the reference point R
y.
DEMO field theory provides an explanation for this loss aversion effect through
the lateral inhibition mechanism. To derive predictions from decision field theory, we
simply set the values (mij in Equation 1) proportional to coordinates of DEMO options in
Figure 6. We set the probability of attending to the first dimension equal to .55, and the
probability of attending to the second dimension equal to .45. The remaining parameters
were the same as DEMO to generate Figure 5.  These predictions are shown in Figure 7,DEMO
which shows the probability of the triadic choices as a function of deliberation time,
separately for the two reference point conditions. As can DEMO seen in this figure,
Figure 7: Decision field theory predictions for loss aversion effect.
Computational Models 23
decision field theory reproduces the loss aversion effect  that is, the change in
preference for option X relative to Y depending on DEMO reference point. It is important to
note that exactly the same parameters are used for both reference point conditions. This
reversal of preference does DEMO depend on the probability of attending to each dimension
if we set the probabilities equal to .50 then the reversal becomes even stronger,
DEMO symmetric in size. In fact, the result depends primarily on the DEMO inhibition
parameter if it is set to zero, then the effect DEMO
The second study also manipulated a reference point, but in this DEMO, using either
option Sx or Sy. In one condition, participants were asked to imagine that they trained on
Computational Models 24
job Sx, but that job would end, and DEMO had to choose between two new jobs X or Y.
From this reference point, job X has small advantages and disadvantages over Sx,
whereas Y has large advantages and disadvantages. Under these conditions, option X was
strongly favored over option Y. In a second condition, participants were asked to imagine
that they trained on job Sy, and in this case, preferences reversed, and option Y was
strongly favored over option DEMO Tversky and Kahneman (1991) also interpreted these
results as a loss aversion effect.
To apply decision field theory to this study, we assume that each option is
described by three dimensions:  the values of DEMO first two dimensions (e.g., salary and
interest) are taken from DEMO positions of the options shown in Figure 6, and the third
DEMO represents job availability. Jobs X and Y both have a positive value on
dimension 3 (they are available), whereas jobs Sx and Sy both have negative values on
dimension 3 (they are no longer available). For example, option Sx is assigned a slightly
higher value on dimension 1 than option X, a slightly lower value on dimension 2 than
option X, and it has a large negative value on dimension 3. We assumed an equal
probability of attending to each of the DEMO dimensions, and the remaining parameters
were the same as used to DEMO Figure 5. The asymptotic choice probability results,
predicted the theory, DEMO summarized in Table 2, below.
Table 2: Predictions Computed from Decision Field Theory
Sx Reference Point
Sy Reference Point
Option
X
Choice Probability
.87
Choice Probability
.13
Y
S
DEMO
0
.87
0
Computational Models 25
As can be seen in the table, decision field theory again reproduces the reversal in
preference as a function of the reference point. In sum, we find that both loss aversion
effects, as well as attraction and compromise effects, all can DEMO derived from the lateral
inhibitory mechanism of decision field theory.
Endowment effect.  There are other phenomena that are often interpreted in terms
of loss aversion (cf. Tversky & Kahneman, 1991), including both the endowment DEMO
as well as differences between willingness to buy versus willingness to pay. Kahneman,
Knetsch, and Thaler (1990) gave one group of subjects a mug and asked them how much
they would be willing to DEMO to give up the mug, whereas another group was simply
given DEMO money and asked how much they would be willing to pay to buy the mug.
They found that subjects were willing to buy the DEMO for only about $3, but they were
asking a much higher DEMO of $7 to sell the mug. This price difference is interpreted as
the loss aversion effect produced by an owner giving up his or DEMO mug. As Tverksy &
Kahneman (1991) noted, the endowment effect can be viewed a special case of a more
general finding of DEMO between the price individuals are willing to accept to sell
Computational Models 26
something they own (WTA or selling prices), versus the price they are willing to pay to
acquire something do not DEMO (WTP or buying prices).
At first glance, one might argue that differences between buying and selling
prices are simply a strategic effect: a person may deliberately underestimate the buying
price and overestimate the selling DEMO to gain an advantage. But this simple explanation
implies that buying and selling prices would still produce the same rank orders. In fact,
DEMO is not the case. Birnbaum, Yeary, Luce, & Zhou (2002) review several studies that
report preference reversals between buying versus selling prices. For example, Birnbaum
and Sutton (1992) presented subjects with the following two gambles: gamble G gives a
.5 probability of winning $96, DEMO $0; gamble F gives a .5 probability of winning
$48, otherwise $36 dollars. On the average, subjects gave a higher buying price to
gamble F than gamble G, but at the same time they gave a higher selling price to gamble
G than gamble F. Birnbaum and DEMO (1992) explained these effects as a change in
decision weight that depends on the buyer or seller point of view.
This type of DEMO reversal is predicted by decision field theory even when
the inputs to the process used to produce buying and selling prices are based on DEMO
common set of weights and values.  The reversals emerge from the DEMO process used
to select the prices. A brief presentation of the computational model used in decision field
theory to select prices for gambles is DEMO below (see Busemeyer & Goldstein, 1992;
and Townsend & Busemeyer, 1995, for more details).
The basic idea is that prices DEMO selected by a series of covert comparisons (refer
to Figure 8)DEMO To find a price equivalent to a gamble, the decision maker DEMO search f
or a
candidate that produces an indifference response. During each step of this search process,
Computational Models 27
the decision maker compares a candidate price to the DEMO, and this comparison may
result in one of three judgments: if the candidate price is preferred, then
the price is
decremented by a small amount and the search continues (a left transition in Figure 8); if
the gamble is preferred, then the price is incremented by a small amount and the search
continues (a right transition in Figure 8); if the comparison produces an indifference
judgment, then the search stops and the candidate price is reported as the price (a
downward transition in Figure 8).  We simply use decision field theory to perform this
comparison process, which provides the probabilities for the three judgments at each
stage of the search process (see Busemeyer & Goldstein, DEMO, for details).  Then
Markov chain theory is used to determine the distribution of prices generated by the
search process (see Busemeyer & Townsend, 1992, for the mathematical derivations).
Figure 8: Illustration of the search process for finding the price of a gamble.
Start search DEMO buying price
36
38
40
42
44
Exit search for buying price
46
48
When asked to find a certainty equivalent for a gamble, we assume that the search
process starts near the middle of the DEMO set of prices in an attempt to minimize the
number of steps needed to find the price equivalent. When asked to find a maximum
DEMO price for a gamble, we assume that the search process starts DEMO the minimum of
Computational Models 28
the feasible set of prices, biased away from paying excess money. Finally, when asked to
find a minimum selling price, DEMO assume that the search process starts near the maximum
of the feasible set of prices, biased toward saving extra money.
This simple scheme was used to find buying and selling prices for gambles F and
G DEMO by Birnbaum and Sutton (1992). In this case, we simply set the values (mij in
Equation 1) equal to the stated DEMO values of the gambles, and we simply set the
probability of DEMO to each event equal to the stated probabilities. Figure 9 shows the
distribution of prices produced by this model for buying prices (top panel) and selling
prices (bottom panel).
Computational Models 29
Figure 9: Predicted Buying Prices (top panels) and Selling Prices (bottom panels)
As can be seen in Figure 9, the predicted buying prices (or WTP) are lower than
the predicted selling prices (or WTA), accounting for the well known disparity between
these measures. More importantly, preference reversals occur for buying and selling
prices: referring to the top panels, the mean buying price for gamble DEMO is larger than the
buying price for gamble G; referring to DEMO bottom panels, the mean selling price for
gamble G is greater DEMO the mean selling price for gamble F.
There is an intuitive explanation for these computational results. The price for
gamble F is restricted to DEMO small range, which makes the price insensitive to changes in
the DEMO position produced by the selling or buying price task. However, the DEMO for
gamble G has a wide range of possible values, and DEMO is more strongly affected by the
Computational Models 30
starting position produced by buying and selling tasks. This DEMO is similar to earlier
anchoring and adjustment models of preference reversal (DEMO, Goldstein & Einhorn,
1987).  However, unlike these earlier DEMO and adjustment theories, the amount of
adjustment is not a free DEMO in decision field theory, because it is derived from the
dynamics DEMO the search process.
Preference reversals also occur between prices and choices (DEMO and
Slovic, 1971; see Slovic and Lichtenstein, 1983, for a review). Decision field theory can
also reproduce these types of preference DEMO by using a common set of weights and
values as inputs into the choice and price processes (Busemeyer & Goldstein, 1992).
Decision DEMO theory can also explain discrepancies reported by Hershey and Shoemaker
(1985) between certainty equivalents and probability equivalents for gambles (Townsend
& Busemeyer, DEMO).
Preference reversals under time pressure. Up to this point we ha ve argued that
computational models, such as decision field theory, provide DEMO deeper level analysis of
several traditional effects from the decision
- making literature. Now we turn to new
predictions that arise from the dynamic DEMO of the model.
There is a growing body of evidence showing that it is possible to reverse an
individual’s preference by changing the amount DEMO time given to make the decision. For
example, Svenson and Edland (1987) asked people to choose among apartments under
short vs. long time deadlines. Under the short time deadlines, the lower rent apartment
was chosen more frequently; but under longer time deadlines, they preferred apartments
with DEMO rents that provided other attractive features. Diederich (2003) extended these
findings by asking individuals to choose between two gambles, and each gamble could
Computational Models 31
yield either a monetary reward or a blast of DEMO punishment. Several individuals
reversed their preferences under time pressure. For example, DEMO avoiding noise was more
important than winning money, then the low DEMO gamble was chosen more frequently
under short deadlines, but the high DEMO payoff gamble was chosen more frequently
under the longer deadlines.
A common explanation for these effects is that decision makers swi
tch strategies
(Payne, Bettman, & Johnson, 1993). Under short deadlines, it is DEMO that
decision makers use a non
-compensatory heuristic strategy such as a lexicographic rule or
an elimination by aspects rule. These strategies are quick DEMO easy to execute but are not
very accurate in the sense of maximizing weighted additive utility. Under longer
deadlines, decision makers can use the more time consuming compensatory strategy such
as a weighted additive rule which DEMO accuracy.
Sequential sampling models provide an alternative view, which simply assumes
DEMO individuals reduce their threshold criterion under time pressure.  Diederich (1997)
developed a multi –attribute version of decision field theory, which assumes individuals
sequentially sample information over time, but they begin processing the more important
dimension, and later switch to process the other less important dimensions. Under short
deadlines, a low threshold is used, only the most important DEMO tends to get
processed, and so this dimension alone determines the DEMO Under long deadlines, a
high threshold is used, and now there is sufficient time to process additional attributes. If
these additional attributes disagree DEMO the most important attribute, then this additional
processing can reverse the DEMO of the evolving preference state. Diederich (1997)
Computational Models 32
showed that this model provided a very accurate quantitative DEMO of her preference
reversals under time pressure.
Are computational models testable?
One might argue that computational models are so complex that they cannot DEMO
empirically tested. On the contrary, it is possible to rigorously test DEMO models both
quantitatively as well as qualitatively. For example, to quantitatively DEMO decision field
theory, one can estimate all of the model parameters DEMO a set of binary choice
probabilities, and then use these same DEMO to predict other measures of preference
including choice response times, triadic DEMO probabilities, and buying/selling prices
(see, for examples, Dror, DEMO, & Basola, 1999; Diederich & Busemeyer, 1999;
Diederich, DEMO; and Diederich, 2003b). Qualitative tests of the theory are also possible:
on the one hand, decision field theory predicts violations of strong stochastic transitivity,
but on the other hand it predicts that DEMO stochastic transitivity will be satisfied
(Busemeyer & Townsend, 1993). In agreement with the first qualitative prediction,
violations of strong stochastic transitivity DEMO occur (see Mellers & Biagini, 1994,
for a review); but contrary to the second qualitative prediction, violations of weak
stochastic transitivity also have been reported under special conditions (see Gonzalez –
Vallejo, DEMO, for a recent review and explanation for this result).
What DEMO some alternative computational models?
Up to this point we have highlighted one computational model, decision field
theory, but there are a growing DEMO of new computational models for decision
making. Three of these are briefly described below.
Computational Models 33
Competing accumulator model
. Usher and McClelland (2001, DEMO) have recently
proposed a competing accumulator model that shares many assumptions DEMO decision
field theory, but departs from this theory on a few DEMO points. The connectionist
network of the competing accumulator model is virtually the same as shown in Figure 2.
However, this model makes different assumptions about (a) the evaluations of advantages
and disadvantages (what we call valences in Equation 2), and (b) the dynamics of
response DEMO (what we call preference states in Equation 3). First, they adopt
Tversky and Kahneman’s (1991) loss aversion hypothesis so that disadvantages DEMO a
larger impact than advantages. Using our own notation, the valence DEMO alternative i ∈
{A,B,C}, and i ≠ j ≠ DEMO, is computed as follows:
v i(t) = F[Ui(t) – Uj(t)] + F[Ui(t) - Uk(t)] DEMO c
(4)
Where F(x) is a nonlinear function that satisfies the loss aversion properties presented in
Tversky & Kahneman (1991). Thus, rather than deriving loss aversion effects indirectly
from the dynamics as we have done, they build this effect directly into the model.
Second, they use a nonlinear dynamic system that restricts the response activation to
remain positive at all times, whereas we use a linear dynamical
system that permits
positive and negative preference states. The non
-negativity restriction was DEMO to be
consistent with their interpretation of response activations as neural firing rates.
Usher and McClelland (2002) have shown that the competing accumulator DEMO
can account for the main findings concerning the similarity effect, the DEMO effect,
and the compromise effect, using a common set of DEMO Like decision field theory,
this model uses an attention switching mechanism to produce similarity effects, but
unlike decision field theory, this model DEMO loss aversion to produce the attraction and
Computational Models 34
compromise effects. Further research is needed to discriminate between DEMO two
models.
ECHO model. Guo and Holyoak (2002; see also Glockner, 2002) proposed a
different kind of connectionist network, called ECHO, DEMO from Thagard and
Millgram (1995). Figure 10 illustrates the model DEMO two attributes and three options. At
the far left in this figure, there is a special node, called the ex
ternal driver, representing
the goal to make a decision, which is turned on when a decision is presented. The driver
node is directly connected to the attribute DEMO, with a constant connection weight. Each
attribute node is connected to DEMO alternative node with a bidirectional link, which allows
activation to pass DEMO and forth from the attribute node to the alternative node.
Figure 10: Illustration of the Echo Model for 2 dimensions and 3 alternatives
d1
d2
D
A
B
C
Computational Models 35
The connection weight between an attribute node and an DEMO node is determined
by the value of the alternative on that attribute (our mij). There are also constant lateral
inhibitory connections between the alternative nodes.
The decision process works as follows. Upon presentation of a DEMO problem,
the driver is turned on and applies constant input activation into the attribute nodes, and
each attribute node then activates each alternative node (differentially depending on
value). Then each alternative node provides positive feedback to each attribute node, and
negative feedback to the other alternative nodes. Activation in the network evolves over
time according to a nonlinear DEMO system, which keeps the activations bounded
between zero and one. The DEMO process stops as soon as the changes in activations
fall below some threshold. At that point, the probability of choosing an option is
determined by a ratio of activation strengths.
Guo and Holyoak (2002) used DEMO model to explain the similarity and attraction
effects. To account for these effects, they assumed that the system first processes the two
similar alternatives, and during this time, the lateral inhibition produces a competition
between DEMO two options. After this initial comparison process is completed, the system
DEMO all three options, including the dissimilar option. In the case of DEMO similarity
effect, the initial processing lowers the activation levels of the DEMO similar options; in the
case of the attraction effect, the initial processing enhances the activation level of the
dominating option. Thus lateral inhibition DEMO alternatives plays a crucial role for
explaining both effects. Although the model has been shown to account for the similarity
and attraction effects, at this point, it has not been shown to account for the compromise
effect or loss aversion effects.
Computational Models 36
The ECHO model makes an important prediction that differs DEMO both decision
field theory and the competing accumulator model. The ECHO model predicts that as one
option becomes dominant during deliberation, this will enhance the activation of the
attribute nodes favored by the dominant alternative. The DEMO is caused by the
feedback from the alternative node to the attribute node, which tends to bias the
evaluation of the attributes over time. This property of the model is related to the
dominance-seeking principle included DEMO other decision
- making theories (Montgomery,
1989; Svenson, 1992)DEMO Holyoak and Simon (1999) tested this hypothesis by asking
individuals to rate attribute importance at various points during deliberation, and they
report evidence for increases in the importance of attributes that are favored by the
DEMO alternative during deliberation.
Affective Balance Theory
. Grossberg and Gutowski (1987) presented a dynamic
theory of affective evaluation based on an opponent processing DEMO called a gated
dipole neural circuit. Habituating transmitters within the circuit determine an affective
adaptation level, or reference point, against which later events DEMO evaluated.  Neutral
events can become affectively charged either through direct activation DEMO antagonistic
rebound within the habituated dipole circuit.  This neural circuit was DEMO to provide an
explanation for the probability weighting an
d value functions of Kahneman and
Tversky’s (1979) prospect theory, and the affective dynamics of addiction and
withdrawal symptoms hypothesized by Solomon and Corbit (1974).
Computational models of inference.  Although this chapter focused on
computatio nal models of preference, there are also new developments for probabilistic
inference and prediction. Dougherty, Gettys, and Ogden (1999) developed an instance-
Computational Models 37
based memory model for probability judgments that accounts for DEMO effects
and conjunctive fallacies. Read, Vanman, and Miller (1997) developed a connectionist
model for social inference judgments which is closely related to DEMO ECHO model used
by Holyoak and Simon (1999). Busemeyer, Byun, Delosh, and McDaniel (1997)
proposed a connectionist model for cue - criterion prediction tasks.
Concluding Comments
During the past 40 years, decision theorists have let the utility function do most of
the work of DEMO choice results. By positing the simplest possible hypotheses about
the choice processes, all the explanatory power falls upon the utility function itself.
Consequently, DEMO this 40-year span of time, the forms of utility functions have
DEMO increasingly complex (see Luce, 2000, for a review). However, it is possible that
if theorists work harder in understanding the complexities DEMO in the choice
processes, then the underlying utility representations may become DEMO and more
coherent.  As others have argued (cf. Plott, 1996), it may be too early for decision
theorists to accept the conclusion that utilities are constructed on the fly for every
variation of task DEMO context, and instead it may be possible to retain a stable DEMO
value system that is expressed through a very complex choice process.
Computational Models 38
References
Aschenbrenner, K. M., Albert, D., & DEMO, F. (1984). Stochastic choice
heuristics. Acta Psychologica, 56(1-3), 153-166.
Ashby, F. G.  (2000).  A stochastic version of general recognition theory. Journal of
Mathematical Psychology, 44, 310-329.
Birnbaum, M. H., Yeary, S., Luce, R. D., & Zhou, L. (2002, submitted). Contingent
Valuation, Endowment, or Viewpoint Effects: Testing DEMO in judgments of buying
and selling prices of lotteries.
Birnbaum, M. DEMO, & Sutton, S. E. (1992). Scale convergence and utility DEMO
Organizational Behavior and Human Decision Processes, 52, 183-215.
Busemeyer, J. DEMO (1985).  Decision making under uncertainty:  Simple scalability, fixed
DEMO, and sequential sampling models.  Journal  of Experimental Psychology:
Learning, Memory, and Cognition, 11, 538-564.
Busemeyer, J. R. & Diederich, A. (2002). Survey of decision field theory. Mathematical
Social Sciences, DEMO, 345-370.
Computational Models 39
Busemeyer, J. R. & Goldstein, W. M.  (DEMO).  Linking together different measures of
preference: A dynamic model of matching derived from decision field theory.
Organizational Behavior and Human Decision Processes, 52, 370-396.
Busemeyer, J. R. & Townsend, J. T. (1992)DEMO Fundamental derivations from decision field
theory. Mathematical Social Sciences, 23, 255-282.
Busemeyer, J. R. & Townsend, J. T. (1993). Decision Field Theory: A dynamic cognition
approach to decision making. Psychological Review, 100, 432-459.
Busemeyer, J. R., Townsend, J. T., & Stout, J. C. (2002). Motivational underpinnings of
utility in decision making: Decision DEMO theory analysis of deprivation and satiation. To
appear in S. Moore (DEMO) Emotional Cognition. Amsterdam: John Benjamins.
Cornsweet, T. N. (1970) DEMO Perception. New York: Academic Press.
DeGroot, M.H. (1970). Optimal DEMO decisions. New York: McGraw-Hill.
Dhar, R., Nowlis, S. M. & Sherman, S. J. (2000). Trying hard or hardly trying: An
analysis of context effects in choice. Journal of Consumer Psychology, 9, DEMO
Diederich, A. (1997). Dynamic stochastic models for decision making under time
constraints. Journal of Mathematical Psychology, 41(3), 260-274.
Computational Models 40
Diederich, A. (2003). Multi
-attribute decision field DEMO account for decision making
under time pressure. Psychonomic Bulletin and Review.
Diederich, A. (2003). Decision making under conflict: Decision time as a measure of
conflict strength. Psychonomic Bulletin and Review.
Diederich, A. & Busemeyer, J. R. (1999). Conflict and the stochastic dominance principle
of DEMO making. Psychological Science, 10, 353-359.
Diederich, A. & Busemeyer, J. R. (2003). Simple matrix methods for analyzing diffusion
models of choice probability, choice response time, and simple response time. Journal of
Mathematical DEMO
Dougherty, M. R. P., Gettys, C. F., & Ogden, DEMO E. (1999). MINERVA-DM: A memory
process model for judgements of likelihood. Psychological Review, 106, 108-209.
Dror, I. E., Busemeyer, J. R., & Basola, B. (1999). Decision making under time pressure:
An independent test of sequential sampling models. Memory and Cognition, 27, 713-725.
Fischer, G. W., Jia, J. & Luce, M. F. (2000). Attribute conflict and preference
uncertainty: The RandMAU model. Management DEMO,  46,  669-684.
Computational Models 41
Glockner, A. (2002). The maximizing consistency
heuristic: Parallel processing in human
decision making. Diplomarbeit, Universitat Heidelberg.
Gold, J. DEMO, & Shadlen, M. N. (2001). Neural computations that underlie DEMO about
sensory stimuli. Trends in Cognitive Neuroscience, 5, 10-16.
Gold, DEMO I., Shadlen, M. N. (2002) Banburismas and the brain: DEMO the relationship
between sensory stimuli, decisions, and reward. Neuron, 36, 299-308.
Goldstein, W. & Einhorn, H. J. (1987). Expression theory and the preference reversal
phenomena. Psychological Review 94, 236-254.
Gonzalez-Vallejo, C. (2002). Making trade-offs: A probabilistic and context-sensitive
model of choice behavior.  Psychological Review, 109(1), 137-155.
Gratton, G. Coles, M. DEMO, Sirevaag, E. J., Erickson, C. J., & Donchin, E. (1988). Pre- and
poststimulus activation of response channels: A psychophysiological DEMO Journal of
Experimental Psychology: Human Perception and Performance, 14, 331- DEMO
Grossberg, S. (1988). Neural Networks and Natural Intelligence. Cambridge, DEMO: MIT
Press.
Computational Models 42
Grossberg, S. & Gutowski, W. E., (1987)DEMO Neural dynamics of decision making under
risk: Affective balance and cognitive-emotional DEMO Psychological Review,
94(3), 300-318.
Guo, F. Y. & DEMO, K. J. (2002). Understanding similarity in choice behavior: A
DEMO model. Proceedings of the Cognitive Science Society Meeting.
Heath, T. B. & Chatterjee, S. (1995). Asymmetric decoy effects on lower - quality versus
higher-quality brands: Meta analytic and experimental evidence. Journal of Consumer
Research, 22, 268-284.
Hershey, J.C. & Schoemaker, P.J.H. (1985). Probability versus certainty equivalence
methods in utility measurement: Are they equivalent?  Mangement Science, 31, 1213-
1231.
Holyoak, K. J. & Simon, D. (1999). Bidirecti
onal reasoning in decision making by
constraint satisfaction.  Journal of Experimental Psychology: General, 128(1), 3-31
Huber, J., DEMO, J. W., & Puto, C. (1982). Adding asymmetrically dominated
alternatives: Violations of regularity and the similarity hypothesis. Journal of Consumer
Research, 9(1), 90-98.
Computational Models 43
Johnson, J. G. & Busemeyer, J. R. (in press). Rule-based Decision Field Theory:  A
dynamic computational model of DEMO among decision-making strategies. To
appear in T. Betsch (Ed.) The routines of decision making. Mahwah, NJ: Erlbaum.
Kahneman, D., Knetsch, J., & Thaler, R. (1990). Experimental tests of the endowment
effect and the Coase theorem.  Journal of Political Economy, 98(6), DEMO
Kahneman, D. & Tversky, A. (1979). Prospect Theory: An analysis of decision under
risk. Econometrica 47(2), 263-297.
Laming, D. R. (1968). Information theory of choice-reaction times. New York: Academic
DEMO
Levin, S. J., & Levine, D. S. (1996). Multiattribute decision making in context: A
dynamic neural network methodology. Cognitive Science, DEMO, 271-299.
Lichtenstein, S. & Slovic, P. (1971). Reversals of preference between bids and choices in
gambling decisions.  Journal of Experimental Psychology, 89, 46-55.
Link, S. W. & Heath, R. (1975). A sequential theory of psychological discrimination.
Psychometrika, 40,77-111.
Computational Models 44
Luce, R. D. (1959). Individual choice behavior: A theoretical analysis. New York:
Wiley.
Luce, R. D. (2000)DEMO Utility of gains and losses. Mahwah, NJ: Erlbaum.
Luce, R. DEMO & Suppes, P. (1965). Preference, utility, and subjective probability. In R. D.
Luce, R. R. Bush, & E. Galanter (Eds.) Handbook of Mathematical Psychology (Vol. 3,
pp. 249-410). New DEMO: Wiley.
Marr, D. (1982) Vision. Cambridge, MA: MIT Press.
Montgomery, H. (1989). From cognition to action: The search for dominance in decision
making.  In H. Montgomery, & O. Svenson (Eds.), Process and structure in human
decision making (pp. 23 - 49), New York: Wiley.
Nosofsky, R. M. & Palmeri, T. J. (1997). An exemplar based random walk model of
speeded classification. Psychological Review, 104, 266-300.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1993).  The adaptive decision maker.NY:
DEMO University Press.
Platt, M. L. (2002) Neural correlates of decisions. DEMO Opinion in Neurobiology,
12(2), 141-148.
Computational Models 45
Plott, C. R. (1996) Rational individual behavior in markets and social processes: The
discovered preference hypothesis. In K. Arrow, DEMO Collombatto, M. Perlaman, & C.
Schmidt (Eds.) The Rational Foundations of Economic Behavior  London: MacMillian.
Ratcliff, R. (1978). A DEMO of memory retrieval. Psychological Review, 85, 59-108.
Read, S. J., Vanman, E. J., & Miller, L. C. (1997). Connectionism, parallel constraint
satisfaction and gestalt principles: (Re)introducting cognitive dynamics to DEMO
psychology. Personality and Social Psychology Review, 1, 26 – 53.
Roe, R., Busemeyer, J. R., & Townsend, J. T. (2001)  Multi
- Alternative Decision Field
Theory: A Dynamic Connectionist Model of DEMO
-Making. Psychological Review,
108, 370-392.
Rumelhart, D., & McClelland, J. L. (1986) Parallel distributed processing: Explorations
in the microstructure of cognition. (Vol. 1) Cambridge, MA: MIT Press.
Samuelson, W. & Zeckhauser, R. (1988). Status quo bias in decision
making. Journal DEMO
Risk and Uncertainty, 1, 7-59.
Schall, J. D. (2001) DEMO basis of deciding, choosing, and acting. Nature Reviews:
Neuroscience, DEMO, 33-42.
Computational Models 46
Simonson, I. (1989) Choice based on reasons: DEMO case of attraction and compromise
effects. Journal of Consumer Research, 16, 158-174.
Slovic, P., and S. Lichtenstein. (1983). Preference reversals: DEMO broader perspective.
American Economic Review, 73, 596-605.
Smith, P. L. (1995). Psychophysically principled models of visual simple reaction time.
Psychological Review, 102(3), 567-593.
Solomon, R. L. & Corbit, J. D. (1974) An opponent process theory of motivation : 1.
Temporal dynamics of affect. Psychological Review, 81, 119-145.
Svenson, O. (1992). Differentiation DEMO consolidation theory of human decision making:
A frame of reference for the study of pre- and post-decision processes. Acta
Psychologica, 80, 143-168.
DEMO, O. & Edland, A. (1987).  Change of preferences under time pressure: Choices
and judgments. Scandinavian Journal of Psychology, 28, 322-330.
Thagard, P. & Millgram, E. (1995). Inference to the best plan: A coherence theory of
decision. In A. Ram & D. B. Leake (Eds.), Goal-driven learning (pp. 439-454).
Cambridge, MA: DEMO Press.
Computational Models 47
Thurstone, L. L. (1959). The measurement of DEMO lues. Chicago: University of Chicago
Press.
Townsend, J. T., & DEMO, J. R. (1995). Dynamic representation of decision
- making.
In R. F. Port and T. van Gelder (Eds.) Mind as Motion. DEMO, MA: MIT press.
Tversky, A. (1969). Intransitivity of preferences. Psychological Review, 76, 31-48.
Tversky, A. (1972). Elimination by DEMO: A theory of choice. Psychological Review,
79(4), 281-299.
DEMO, A. & Kahneman, D. (1991) Loss aversion in riskless choice: A reference
dependent model. Quarterly Journal of Economics, 106, 1039-1061.
Tversky, A. & Simonson, I. (1993). Context dependent preferences. Management
Science, 39, 1179-1189.
Usher, M. & McClelland, J. L. (2001) DEMO the time course of perceptual choice: A model
based on principles DEMO neural computation. Psychological Review, 108, 550-592.
Usher, M. & McClelland, J. L. (2002) Decisions, decisions: Loss aversion, information
leakage, DEMO inhibition in multi
-attribute choice situations. Unpublished Note.
Computational Models 48
Vickers, D. (1979). Decision Processes in Visual DEMO New York: Academic
Press.
Wallsten, T. S. & Barton, C. (1982). Processing probabilistic multidimensional
information for decisions. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 8, 361-384.{1g42fwefx}