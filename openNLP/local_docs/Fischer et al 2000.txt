Attribute Conflict and Preference Uncertainty: Effects on Judgment Time and Error
Author(s): Gregory W. Fischer, Mary Frances Luce and Jianmin Jia
Reviewed work(s):
Source: Management Science, Vol. 46, No. 1 (Jan., 2000), pp. 88-103
Published by: INFORMS
Stable URL: http://www.jstor.org/stable/2634910 .
Accessed: 25/06/2012 21:58
Your use of the JSTOR archive indicates your acceptance of the Terms & DEMO of Use, available at .
http://www.jstor.org/page/info/about/DEMO/terms.jsp
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of
content DEMO a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms
of scholarship. For more information about JSTOR, please contact support@jstor.org.
INFORMS is collaborating with JSTOR to digitize, preserve and extend access to Management Science.
http://www.jstor.org
Attribute
Uncertainty:
Time
Conflict
Effects
and
and
on
Error
Preference
Judgment
DEMO W. Fischer * Mary Frances Luce * Jianmin Jia
Fu qua School of Business, Duke University, Durham, North Carolina 27708
The Wharton School, University of Pennsylvania, Philadelphia, Pennsylvania 19104
Faculty of Business Administration, DEMO University of Hong Kong, Shatin, NT, Hong
fischer@mail.duke.edu *
maryfran@marketing.wharton.upenn.edu DEMO
Kong
jjia@tcuhk.edu.hk
T his research investigates preference uncertainty generated as a function of specific
alternative characteristics during multiattribute evaluative judgments. We propose that
preference DEMO has at least two behavioral manifestations: longer judgment times and
greater DEMO error in expressed preferences. We investigate two hypotheses regarding
stimulus-based causes of preference uncertainty. As predicted by our attribute conflict
hypothesis, greater within-alternative conflict (discrepancy among the attributes of an evalu-
ative alternative) led to DEMO judgment times and greater response error. As predicted by our
attribute extremity hypothesis, greater attribute extremity (very high or low attribute values)
DEMO in shorter judgment times and less response error. We also found that judgment times
and response errors were strongly positively correlated at the item DEMO, consistent with our
assumption that preference uncertainty generated by stimulus characteristics DEMO manifested in
judgment time and error. Finally, we found that the DEMO preference uncertainty effects
proposed here operate in parallel with strategy-level, effort-accuracy DEMO observable
across participants. These findings are consistent with the RandMAU random multiattribute
utility model developed in a companion article by Fischer et al. (2000).
Introduction
Recent decision research has focused increasingly on
psychological aspects of DEMO such as loss aversion,
anticipation, dread, and regret. In this research, we
consider another psychological dimension of prefer-
ence-feelings of ambivalence preference uncertainty
that arise when one must evaluate a single alternative
that is DEMO in some respects but bad in others. For
example, the highest DEMO products are frequently
among the most expensive. The best-paying jobs are
frequently not the most interesting, or secure, or in the
best location. DEMO safest cars may not be the most fun
to drive.
We argue that such conflict between different as-
MANAGEMENT SCIENCE ? 2000 INFORMS
Vol. DEMO, No. 1, January 2000 pp. 88-103
pects of choice or evaluation tasks leads to preference
uncertainty. If one is choosing between two alterna-
DEMO, preference uncertainty means not being sure
which alternative one prefers, or to what degree. If one
is evaluating a single alternative in terms DEMO some
metric of value, preference uncertainty means not
being sure what DEMO to assign to the alternative.
Preference uncertainty may be manifested in a variety
of ways. For instance, if one is unsure about whether
the positive features of an alternative outweigh the
negative, one is likely to take longer to evaluate it and
to express less consistent evaluations over DEMO
Preference uncertainty may arise for a variety of
reasons. In general, DEMO are likely to be more
0025-1909/00/4601/0088$05.00
1526-5501 electronic ISSN
or
FISCHER, LUCE, AND JIA
Attribtute Conflict and Preference UTncertainty
uncertain in DEMO that are novel or unfamiliar
(e.g., March 1978). In addition, the properties of deci-
sion alternatives themselves may contribute to prefer-
ence uncertainty. In this article, we investigate two
stimulus properties that we believe contribute to pref-
erence uncertainty in the evaluation of a single alter-
DEMO Our primary interest is in a stimulus charac-
teristic that we call attribute conflict, or the degree to
which the attractiveness of an alternative varies across
the attributes that describe it. For example, a car might
have excellent acceleration, braking, and handling
characteristics, but be uncomfortable, DEMO, and
perform poorly in crash tests. High attribute conflict
means that DEMO individual must forego some goal(s) in
order to attain others. DEMO argue below that such
conflict will lead to greater preference uncertainty. We
are also interested in a second stimulus characteristic
that we refer to DEMO attribute extremity. Attribute extrem-
ity is high for either very high or very low attribute
values and low for attribute values near the middle DEMO
the attribute scale. We argue that extreme attribute
values are easier to evaluate than intermediate ones.
Thus, greater attribute extremity leads to less prefer-
ence uncertainty.
In short, the focus of this article is on how two
stimulus characteristics-attribute conflict and at-
tribute extremity-affect preference uncertainty in an
DEMO rating task. We have two basic hypotheses.
First, greater attribute conflict DEMO to greater uncer-
tainty regarding the value of the alternative. Second,
greater attribute extremity leads to less uncertainty
regarding the value of an DEMO We test these
predictions in the context of evaluative ratings, not
DEMO In the next section, we discuss the theoretical
considerations that lead DEMO these hypotheses. In the
section that follows, we describe the results DEMO an
experimental investigation that tests them. The final
section discusses implications for preference modeling
and assessment.
Conflict, Extremity, and Preference
Uncertainty
Preference Uncertainty
DEMO models of choice permit decision makers to
be uncertain about the occurrence of events in the
MANAGEMENT
SCIENCE/Vol.
46, No. 1, January DEMO
external environment, but assume that decision mak-
ers know their own DEMO with certainty. In this
paper, we adopt the more psychologically realistic
DEMO that decision makers also experience un-
certainty when they evaluate decision outcomes
(March 1978). What does it mean to experience ex ante
uncertainty about one's preferences? When one is
choosing, preference uncertainty may DEMO experienced
as indecision, not being sure whether one would rather
eat DEMO or lobster. When one is evaluating a single
alternative, preference uncertainty DEMO be experi-
enced as indecision about what rating to assign to the
alternative. For example, if one's favorite entree is leg
of lamb and one's least preferred entree is a hot dog,
where DEMO a turkey burger located on a scale of value
where a hot dog is 0 and leg of lamb is 1? For either
choice or evaluative ratings, a decision maker may
experience ex ante preference uncertainty.
Measuring Preference Uncertainty
Our hypotheses involve ex ante preference uncer-
tainty generated DEMO the evaluation of an alternative.
This form of uncertainty is likely related to, but not
necessarily perfectly correlated with, ex post subjec-
tive DEMO ratings made after evaluation of an
alternative. There is a substantial literature on errors
in calibration of subjective confidence judgments (e.g.,
Lichtenstein et al. 1982). While this research typically
addresses confidence regarding factual statements DEMO
probability estimates, there is no compelling reason to
believe that ratings DEMO subjective confidence in prefer-
ence assessments will be better calibrated. Thus, DEMO
post judgments of subjective confidence may not be
perfectly correlated with preference uncertainty dur-
ing evaluation. We leave to future research the ques-
tion DEMO the correspondence between preference uncer-
tainty (as operationalized below) and subjective
confidence. Instead, we focus on developing opera-
tionalizations of ex ante preference uncertainty that
we will use to test our hypotheses regarding how
stimulus DEMO affect preference uncertainty
regarding the evaluation of a single alternative.
Broadly, DEMO may take two approaches to measur-
ing preference uncertainty in evaluative judgments.
The first is to ask the decision maker to directly assess
preference DEMO, much as one would do with
89
FISCHER, LUCE, AND JIA
Attribute Coniflict and Preference Uncertainty
event uncertainty. DEMO, one might ask a decision
maker to estimate a 90% confidence DEMO for the
value of a particular alternative. Alternatives that
evoke greater preference uncertainty should evoke
wider confidence intervals-but only if people have
direct insight DEMO their own preference uncertainty. In
this article, we take a second DEMO, inferring
preference uncertainty from other properties of the
judgment process. In DEMO, we focus on two
indirect indicators of preference uncertainty. The first
DEMO response time. The more uncertain one is as to the
overall value of an alternative, the longer one is likely
to take in assigning a value to the alternative. This
would occur, for instance, if DEMO attempted to resolve
one's uncertainty by adopting different frames of
mind, then stopped when a stable evaluation
emerged. As random variations in the weights gov-
erning attribute tradeoffs increased, for example, suc-
cessively generated DEMO of an alternative
would likely diverge more greatly from one another,
and a stable evaluation would take longer to obtain.
The second measure DEMO response error. If one is uncer-
tain about one's preferences, DEMO to judgment
tasks are likely to fluctuate from moment to moment,
as one adopts different frames of mind. Therefore,
greater preference uncertainty DEMO be associated
with greater response error-that is, greater inconsis-
tency between DEMO particular decision maker's evalua-
tions of an identical stimulus at different times.
There is no direct way to verify that either re-
sponse DEMO or response error reflects preference
uncertainty. However, if we are correct DEMO assuming
that each provides a measure of preference uncer-
tainty, then DEMO alternatives that take longer
to evaluate on average should also evoke greater
average response error. Thus, a significant positive,
item-level correlation between the two types of
measures would support our assumption that each is
an DEMO manifestation of stimulus-generated
preference uncertainty. Further, each is of interest in
DEMO own right.
Representing Preference Uncertainty in Models of
Judgment
As we noted earlier, preference uncertainty may arise
for several reasons. Lack of familiarity with the alter-
90
natives or lack of familiarity with the preference-
revealing DEMO may both contribute to prefer-
ence uncertainty. In addition, some alternatives DEMO
be more difficult to evaluate than others, thus leading
to greater DEMO in one's preferences. Our em-
phasis in this paper is on characteristics of individual
alternatives that evoke greater or lesser degrees of
uncertainty DEMO the value of the alternative
during the process of developing an evaluative rating.
Our focus will be on situations in which a decision
maker DEMO the overall value of a series of alterna-
tives. Each judgment will be made independently
of every other judgment (apart from any memory
carryover effects). We assume that each alternative is
described by a set DEMO attributes and that the state of
each attribute describing an outcome is known with
certainty. Thus, we will speak interchangeably of
evaluating an alternative and evaluating its associated
outcome. Finally, we assume that overall evaluations
of alternatives can be represented by a compensatory
evaluation model, such as an additive or multiplica-
tive multiattribute value or utility model. Previous
research indicates DEMO compensatory value models
provide a very good approximation to ratings of
individual evaluative alternatives, especially in situa-
tions where alternatives are described by only two or
three attributes (e.g., Fischer 1976). We do not DEMO
that decision makers explicitly use a compensatory
evaluative model to calculate the overall value of a
multiattribute alternative. We only assume that they
form DEMO impression of the alternative with respect to
each attribute, then subjectively DEMO these values
in arriving at an overall judgment of value.
The standard way to represent preference uncer-
tainty in multiattribute preference models is with DEMO
additive error model-that is, a standard multiattribute
value or utility model DEMO a random (error) compo-
nent added on at the end (DEMO, Laskey and Fischer
1987). This method explicitly assumes that error DEMO
independent of the attributes describing an alterna-
tive, and thus independent DEMO attribute extremity and
conflict. Because we believe that preference uncer-
tainty is affected by item characteristics such as at-
tribute conflict and extremity, we do not believe that
MANAGEMENT
SCIENCE/Vol.
46, No. 1, January DEMO
FISCHER, LUCE, AND JIA
Attribtnte Conflict and Preference Uncertainty
preference uncertainty DEMO fully represented by a stan-
dard additive error model.
In order to clarify our current approach, it will be
helpful to briefly review one of the random multiat-
tribute utility (RandMAU) models of preference uncer-
DEMO that Fischer et al. develop in more detail in a
companion paper (Fischer et al. 2000). Our RandMAU
models represent item-specific sources of preference
uncertainty by introducing random variation in the
parameters of a standard DEMO value model.
For example, an additive RandMAU model whose
single-attribute utility DEMO can be represented as
simple power functions is given by
U(X,.
..
,
x11)
=
E wiui(xi)
=
E
ixi7
Here the levels of an attribute Xi are rescaled from 0 DEMO
1, ensuring that the resultant single attribute values
represented by xi DEMO from 0 to 1. The a i > 0 are
curvature parameters reflecting the degree of concav-
ity or convexity of the single-attribute value DEMO,
that is determining the mapping from the scaled
attribute value xi to the single-attribute utility value
ui(xi). Random variation in the DEMO parameter
for each single-attribute value function represents
uncertainty regarding how to encode and evaluate
outcomes with respect to a single value attribute. The
attribute DEMO factors o, ... w 1 are random
variables that satisfy both DEMO < wi < 1 and Eiwi = 1,
as the standard normalization of an additive utility
function requires. Random variation in these attribute
DEMO parameters represents uncertainty regarding
the relative importance of different value relevant
attributes. Such uncertainty primarily affects the final
stage of the evaluation process-integrating value
DEMO attributes. Together, random variation in the
curvature parameters and weights induce DEMO
uncertainty (random variation) regarding overall eval-
uations of judgment alternatives.
In effect, this additive RandMAU model formalizes
and extends Roger Shepard's (DEMO) notion that im-
plicit attribute weights vary substantially over the
time DEMO of a multiattribute decision process. Thus,
our modeling approach represents different frames of
mind regarding attribute tradeoffs and valuations by
MANAGEMENT
SCIENCE/Vol.
DEMO, No. 1, January 2000
allowing preference-summarizing parameters (at-
tribute weights DEMO curvature parameters) to vary
randomly. In the discussion that follows, we develop
qualitative implications of this general view of the
preference generating process. DEMO discussion does
not depend on the quantitative details of RandMAU
models, DEMO the intuitions developed below can also
be demonstrated in simulations based on the model
(Fischer et al. 2000).1
The Attribute Conflict Hypothesis
The notion of conflict among objectives-or among
the attributes representing them-lies at the DEMO of
both normative (e.g., Keeney and Raiffa 1976) and
behavioral DEMO of multiattribute choice (e.g., Tver-
sky et al. 1988). It is widely accepted that conflict
among objectives makes it more difficult to DEMO
one's preferences.
For our purposes, it is useful to distinguish DEMO
two different types of attribute conflict. Between-
alternative conflict arises in cases where one must
choose between two options where one option is
superior DEMO some respects but the other option is
superior in others. Thus, DEMO conflict
arises only in choice or other comparative tasks.
Within-alternative conflict arises in cases where one
must form an evaluation of an alternative that DEMO good
in some respects but bad in others. Although within-
alternative conflict is a basic feature of both judgment
and choice tasks, it has not received much attention in
behavioral decision research. Our primary focus in
DEMO article is the neglected issue of within-alternative
conflict. However, because most DEMO research on
attribute conflict has focused on between-alternative
conflict, we briefly DEMO some essential findings
from that research.
Between-Alternative Conflict. Conflict has fre-
quently been defined as the presence of competing
response tendencies that arise when DEMO one of several
alternatives, each satisfying different goals, must be
1 In that companion paper, we rely mainly on a somewhat more
complex version of the RandMAU model in which value aggregates
multiplicatively across attributes. DEMO, the hypotheses devel-
oped below follow from both additive and multiplicative DEMO
of the model.
91
**
FISCHER, LUCE, AND JIA
Attribute Con1flict and Preference Uncertainty
chosen (e.g., Coombs and Avrunin 1976, Lewin 1951).
For instance, suppose that a young woman is buying a
car and has narrowed her choice DEMO two cars, A and B.
Her research indicates that Car A DEMO generally superior
to Car B in terms of performance, safety, reliability,
and comfort. However, Car B is less expensive to
purchase and maintain. If cost is an important consid-
eration, the decision maker is likely to feel uncertain
about her choice. It depends on the relative DEMO she
attaches to the conflicting attributes. Greater emphasis
on cost favors Car B, whereas greater emphasis on
quality attributes favors Car A. Thus, DEMO cognitive
analysis of conflict focuses on the relative weighting of
competing attributes (Fischer and Hawkins 1993, Fi-
scher et al. 1999, Payne et al. 1993, Tversky et al. 1988).
Whichever choice she makes, DEMO decision maker in
our example is likely to experience feelings of regret
(Bell 1982, Loomes and Sugden 1982), or emotional loss
associated DEMO giving up the positive features of the
foregone alternative (Festinger 1957, Hogarth 1987,
Janis and Mann 1977, Shepard 1964).
Past research on the effects of between-alternative
conflict has frequently supported the hypothesis that
DEMO is linked to increased response time in choice
(Bettman et al. DEMO, Hansen 1972). Kiesler (1966)
actually defined conflict as increased decision deliber-
ation time (choice time minus time to scan alterna-
tives), although this operationalization of conflict was
controversial (Berlyne 1966). Recent work on emo-
tional consequences of conflict has linked the negative
affect DEMO by conflict with the tendency to
prolong decision search times (Luce DEMO, Tversky and
Shafir 1992). Thus, greater response times may be one
manifestation of the preference uncertainty generated
by high-conflict situations.
Within-Alternative Conflict. DEMO most past re-
search on attribute conflict, the research reported in
DEMO article focuses on conflict among the attributes of
a single evaluative alternative. To illustrate, consider
the car example begun earlier. Suppose that Car A
costs more than the decision maker can afford, so Car
B is her preferred option. However, although Car B is
both affordable and better than average in most re-
spects, its crashworthiness and reliability are both
below average. Consequently, she is uncertain about
92
whether Car B is desirable and whether she should go
ahead with the purchase. In short, she is experiencing
the cognitive and emotional state of ambivalence, re-
sulting from conflict among the attributes of a single
alternative. Such ambivalence is DEMO relevant in
cases where some attributes are good and others bad
in comparison to a neutral reference outcome (in this
case, the average DEMO).
Little is known about the consequences of within-
alternative conflict on judgment. However, the logic
underlying the RandMAU model leads to the follow-
ing:
ATTRIBUTE CONFLICT HYPOTHESIS. High conflict
among the attributes of a DEMO alternative leads to
greater uncertainty regarding the overall evaluation of that
alternative.
This hypothesis concerns the final cognitive process
involved in evaluating alternatives, integrating value
across attributes. Consider a decision maker attempt-
ing to evaluate an DEMO described by two at-
tributes that are highly discrepant-i.e., the alternative
DEMO very good in one respect but very bad in another.
Using the terminology of the RandMAU model intro-
duced above, suppose that u,(DEMO,) = 0.8 whereas
u2(x2) = 0.2. In this high-conflict DEMO, random vari-
ation in the weighting parameters will have a major
DEMO on overall evaluation. If w1 = 0.7, then the
overall value DEMO 0.62 whereas if w= 0.3, the overall
value is only 0.38. DEMO consider a low-conflict alter-
native for which u,(x,) = DEMO and u2(x2) = 0.45. In
this case, if w1 = 0.7, then the overall value is 0.52
whereas if w1 = 0.3, the overall value only falls to 0.48.
In short, a given DEMO in weights has much
greater impact on overall evaluations when attribute
conflict is high rather than low. Thus, we predict that
high conflict among the attributes of an evaluative
alternative leads to greater uncertainty regarding the
DEMO evaluation of that alternative.
The Attribute Extremity Hypothesis
Of course, an DEMO must form a judgment about
single-attribute values before combining these into an
overall valuation. Uncertainty about single-attribute
values also contributes to uncertainty about overall
DEMO We address this in the following:
MANAGEMENT
SCIENCE/Vol.
46, DEMO 1, January 2000
FISCHER, LUCE, AND JIA
Attribtute Coniflict and Preference Uncertainty
ATTRIBUTE EXTREMITY DEMO Extreme levels
of an attribute tend to be easier to evaluate than interme-
diate levels and thus are less prone to preference uncer-
tainty.
DEMO clarify the logic behind this prediction, consider
a task whose instructions DEMO that the worst pos-
sible level of an attribute is to be assigned a value of 0
and the best possible level a value DEMO 1. The respon-
dent's task is to evaluate intermediate levels of the
attribute by assigning each a value between 0 and 1.
Under DEMO circumstances, extreme levels of the
attribute-those that are either very good DEMO very
bad-are easier to encode and evaluate than intermediate
levels. As one approaches 0 at the lower extreme, or 1
at the upper extreme, there is less and less ambiguity
about the value of the attribute level, and thus less
room for error. In the middle, though, things become
increasingly ambiguous.
For example, suppose that a person has to compare
three medical outcomes: at the lower extreme, a life of
DEMO pain; at the upper extreme, a life with no pain; DEMO
the middle, a life with moderate pain. The worst and
best DEMO are easy to judge. The middle case is not. Is
moderate pain more like extreme pain (indicating a
convex underlying single-attribute utility function) DEMO
more like no pain (indicating a concave underlying
function)? It DEMO on the frame of mind one
adopts. Thus, we predict that DEMO levels of an
attribute will evoke greater preference uncertainty.
Like our conflict hypothesis, this somewhat counter-
intuitive prediction is consistent with the RandMAU
models developed in Fischer et al. (2000). For example,
suppose that attribute Xi is at or near its upper bound,
so that DEMO re-scaled attribute value, xi, is close to 1.0.
In that case, the single-attribute valuation of this
outcome will not depend much on the degree of
curvature of the value function; ui(xi) will be DEMO to
1.0 regardless of the value of the curvature parameter
ai. For example, if xi = 0.95, then ui(xi) = 0.975
when ai =0.5, and ui(xi) = 0.926 when ai = 1.5.
DEMO, if Xi is at or near its lower bound of 0, then
uj(xi) will be close to 0 regardless of the value of the
curvature parameter ai. However, if Xi is in the
middle of its range (i.e., xi is close to 0.5), changes DEMO
the curvature parameter ai can have a big effect on
MANAGEMENT
SCIENCE/Vol.
46, No. 1, January 2000
uj(xi). For example, if xi = 0.5, then ui(xi) 0.707
when axi = DEMO but ui(xi) = 0.354 when ai 1.5. In
short, the same degree of variation in the curvature
parameter has much greater impact DEMO estimates of
single-attribute utility for intermediate attribute val-
ues than for extreme ones.
This prediction may seem to be an artifact of the
presence DEMO upper and lower scale boundaries. How-
ever, such boundaries are frequently DEMO in real
life as well as in psychological scaling methods. There
are two reasons why this is the case. First, the frames
of reference that people bring to problems include
extreme values that place bounds on DEMO In
many cases, the frame of reference provided by past
experience DEMO it quite natural to think of an
outcome as being very good or very bad with respect
to individual outcome attributes (e.g., very DEMO ac-
celeration, very poor braking). Second, task con-
straints and task logic frequently impose upper and
lower bounds on evaluations. Lottery procedures DEMO
assessing utility naturally bound utility judgments
between 0 and 1. Willingness-to-pay for a good is
naturally constrained by $0 at the lower extreme
(assuming the seller will not pay to be rid of it) and by
one's total wealth, or current budget for consumption,
on the upper. In a similar fashion, ratings of prefer-
ence or attractiveness are naturally constrained when
an upper bound value (e.g., 1.0) is assigned to the best
level of the attribute in question and a lower DEMO
(e.g., 0) to the worst level of the attribute.
Effort-Accuracy DEMO
Our assumption that response times and response
errors are positively correlated may at first glance
appear to contradict Payne et al.'s (1993) DEMO
accuracy model. According to their model, people
choose among judgment strategies DEMO differ both in
the effort required to implement them and the accu-
racy (quality) of resulting judgments and decisions.
High effort strategies lead DEMO both longer response
times and greater decision accuracy. Payne et al.
(DEMO) operationalize decision accuracy as the gap
between indicated and expected utility-maximizing
DEMO (a systematic rather than random error). How-
ever, one might also expect random judgment error
(our operationalization of error) to be DEMO with
93
FISCHER, LUCE, AND JIA
Attribtnte Conflict and Preference Uncertainty
greater deviations DEMO utility-maximization (Payne et
al.'s operationalization). Thus, it may appear that the
effort-accuracy framework predicts that response time
and random response error DEMO be negatively
correlated. The contradiction between our prediction
and theirs is apparent, not real, however. Our predic-
tion concerns item-level relationships. Difficult items
(i.e., those characterized by greater within-alternative
conflict or less within-attribute extremity) DEMO
more time and evoke more error. The effort-accuracy
predictions concern strategy-level effects. These ef-
fects can be observable within an individual. For
instance, decision makers may shift to less norma-
tively accurate (but more simplified and therefore
faster) decision strategies in reaction to increasing
problem size. However, DEMO experiments will confront
individuals with judgment tasks that are relatively
stable in terms of most important task and context
characteristics (e.g., time pressure, problem size). In
this relatively constrained task environment, we ex-
pect effort-accuracy tradeoffs to be observable primar-
ily across participants. In particular, those individuals
who choose to adopt more effortful strategies will take
more time DEMO be more reliable (less error-prone).
Thus, it is possible to observe the preference uncer-
tainty effects that we predict at the item DEMO (i.e., a
positive correlation between response time and error)
as well as the effort-accuracy effects that Payne et al.
predict at the DEMO level (i.e., a negative corre-
lation between average response time and average
response error). We will investigate this further in
analyzing the DEMO of our study.
Summary
We have identified two indicators of preference
uncertainty-response time and response error. We
have also identified two potential sources of DEMO
ence uncertainty, associated with the cognitive pro-
cesses underlying evaluations of DEMO deci-
sion alternatives. First, the greater the degree of
conflict among DEMO attributes of an alternative, the
greater the uncertainty in judging the DEMO value.
Second, extreme levels of an attribute are easier to
evaluate DEMO intermediate ones, and thus less prone
to preference uncertainty. Other factors, such as the
ease of encoding an attribute value, may also influence
94
preference uncertainty (e.g., Johnson et al. 1988). How-
ever, our research will focus on conflict and extremity,
using standard preference-assessment DEMO that
leave little or no ambiguity about attribute levels.
A Preference Assessment
Experiment
In this section, we describe a behavioral experiment
that tests the attribute conflict and attribute extremity
hypotheses. Students evaluated individually pre-
sented course DEMO characterized by three at-
tributes: interest of subject matter, teaching quality,
and average course grade.
Method
Participants and Procedure. Twenty-two under-
graduate DEMO at Duke University individually
completed this experiment in return for course credit.
The experimental instructions and stimuli were deliv-
ered via the Mouselab software DEMO (Payne et al.
1993). For each stimulus, three pieces of attribute
information were hidden in labeled boxes. Partici-
pants used a mouse-controlled DEMO to open boxes to
search for information. They evaluated each alterna-
tive by using the mouse to drag a sliding pointer
across a continuous DEMO, whose endpoints were
labeled with descriptions of the best and worst DEMO
ble alternatives. (No numerical values were shown on
the scale.) The Mouselab program presented stimuli in
a random order and recorded the total DEMO time
for each judgment to an accuracy of 1/60th of a
second.
After receiving instructions regarding the Mouselab
program and the judgment task, participants were
asked to complete two practice judgments. Then, they
were told that the experimental task was beginning.
The initial five judgments were filler DEMO (not labeled
as such), intended to minimize the degree to DEMO
time and error ratings included variance associated
with acclimating to the task environment. Next, par-
ticipants judged the 20 experimental stimuli once,
presented in an individually randomized order for
each participant, and were then encouraged to take a
break. After the break, participants evaluated three
filler items (not labeled as such) which were intended
MANAGEMENT
SCIENCE/Vol.
46, No. 1, January 2000
FISCHER, LUCE, AND JIA
Attribatte Conflict and Preference Uncertainty
to capture DEMO re-acclimation to the task following the
break. These fillers were followed by the 20 experi-
mental stimuli, presented in a different individually
randomized order. After making these judgments,
participants made a series of choices which DEMO
related to a different research project and which will
not be discussed further. Finally, participants an-
swered one manipulation check question (described
below) on the computer screen, then were directed to
a paper and pencil questionnaire collecting their im-
portance weights for the three attributes they had
DEMO
Task and Attributes. The basic experimental task
was to make a series of judgments regarding the
attractiveness of elective college courses, where attrac-
tiveness was defined as "what makes you decide to
take one elective course over another." Although these
choices were hypothetical, we believe that the DEMO
matter was meaningful and realistic for our student
participants.
Elective courses were described in terms of three
five-level attributes. The first was the participant'DEMO
degree of interest in the subject matter of the course,
with each course scored as: Very Low, Low, Average,
High, DEMO Very High. Participants were asked to con-
sider their own goals and preferences, then to generate
examples of courses that would correspond to the best
(Very High), the worst (Very Low), and middle (Av-
erage) levels of this attribute. They recorded these
reference courses on a piece of paper available for
reference during judgment tasks. The second DEMO
was expected teaching quality, described as the instruc-
tor's score DEMO the previous year's student evaluations,
categorized into one of five categories: Very Poor,
Poor, Average, Good, or Very Good. DEMO third at-
tribute was the average grade to be earned by students
in the course; the levels of this attribute were 2.8, 2.9,DEMO
3.0, 3.1, and 3.2. We instructed participants that the
courses they would be rating were average with
respect to all attributes other than DEMO three.
Stimulus Design. Our primary objective in con-
structing the set of judgment stimuli was to manipu-
late the degree of conflict among the DEMO de-
scribing each alternative. With three attributes, each
assuming five levels, there were 125 possible alterna-
tives. We operationalized the degree of conflict DEMO
the attributes of each alternative as the standard
deviation of the attribute levels of the alternative,
where each attribute level was assigned an DEMO
value between 1 and 5 (from worst to best). With DEMO
approach, each of the 125 possible stimuli received
one of the DEMO conflict scores: 0.0, 0.47, 0.82, 0.94,
1.25, 1.41, 1.63, 1.69, and 1.89. In order to cover the
range of DEMO levels and to allow several alterna-
tives per conflict level, we DEMO to sample from
stimuli with standard deviations of 0.0, 0.47, 0.94, 1.41,
and 1.89. We chose four stimuli from each of these five
conflict levels, with the following exceptions. For the
lowest level of conflict, only three stimuli other than
the most and least attractive alternatives exist.2 Thus,
we used all three stimuli from the first conflict DEMO
and sampled five stimuli from the second level.
A second essential consideration in constructing
stimuli was the attribute extremity of each stimulus,
which DEMO defined as the average absolute deviation of
its attributes' levels from DEMO, the mid-level of each
attribute; i.e., Extremity = 3 li=1 DEMO Xi - 3 1, where xi
is the level of attribute DEMO, which may assume values
from 1 to 5. With three attributes, the possible extrem-
ity levels for our stimuli were 0.00, 0.33, DEMO, 1.00,
1.33, 1.67, and 2.00. The ideal stimulus design DEMO
cover each possible range of extremity within each
conflict level. Unfortunately, DEMO and conflict
are naturally confounded, because more extreme lev-
els of DEMO are possible only with higher levels of
extremity (see Table 1)DEMO The product-moment correla-
tion between conflict and extremity was 0.70 for the 20
experimental stimuli. Because we predict that at-
tribute conflict and attribute DEMO will have op-
posite effects on preference uncertainty, it is still
DEMO to use statistical methods to disentangle the
effects of these two conceptually distinct constructs.
A final consideration in designing stimuli was to be
sure DEMO conflict and extremity levels were indepen-
dent of the overall attractiveness of each stimulus.
Overall value (attractiveness) was estimated using
2 It is DEMO to evaluate the most and least attractive stimuli
because they anchor the scale.
MANAGEMENT
SCIENCE/Vol.
46, No. 1, January 2000
95
FISCHER, LUCE, AND JIA
Attributte Conflict and Preference Uncertainty
Table
1
DEMO
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Mean
St Dev
Experimental
DEMO
and Average
Data
Stimulus
Characteristics
X
Y
Z
Conflict
Note.
each attribute
scale),
by
2
3
4
1
2
2
3
4
1
2
3
3
1
2
4
5
1
1
5
5
2.7
DEMO
2
3
4
1
1
3
4
5
1
2
5
5
4
5
4
5
1
5
1
5
3.3
1.6
2
3
DEMO
2
1
3
4
5
3
4
3
5
1
2
1
2
5
1
1
1
2.7
1.4
0.00
0.00
0.00
0.47
0.47
DEMO
0.47
0.47
0.94
0.94
0.94
0.94
1.41
1.41
1.41
1.41
1.89
1.89
1.89
1.89
0.97
0.64
X, Y,
level
AvgError the mean
taking
and
Z denote
from
the inverse
the levels
3, and
absolute
of the mean
Value
of the three
the weighted
deviation of time
negative-reciprocal
DEMO
sum of the attribute
1-time 2 responses,
response
Conflict
time.
denotes
levels,
and
Extremity
1.00
0.00
1.00
1.67
1.67
0.33
0.67
1.67
DEMO
1.00
0.67
1.33
1.67
1.33
1.33
1.67
2.00
2.00
2.00
2.00
1.32
0.56
Value
2.0
3.0
4.0
1.2
1.5
2.5
3.5
4.5
1.4
2.4
DEMO
4.0
1.9
2.9
3.4
4.4
1.8
2.2
3.0
4.2
2.87
1.03
the standard
based
AvgRT
deviation of the
on a pretest.
the average
attribute
DEMO
response
levels,
indicates
time
for
AvgRate
0.13
0.48
0.76
0.05
0.07
0.26
0.66
0.88
0.09
0.20
0.69
0.78
0.22
0.32
0.62
0.82
0.17
DEMO
0.32
0.79
0.43
0.28
Experimental
Results
AvgError
0.050
0.041
0.076
0.037
0.037
0.076
0.086
0.049
0.040
0.070
0.065
0.068
0.088
0.068
0.081
0.081
0.053
DEMO
0.081
0.064
0.066
0.019
Extremity the mean
the average
the stimulus
(DEMO
rating
seconds).
absolute
of each stimulus
AvgRT
AvgRT
10.53
12.20
12.05
11.36
12.20
12.99
13.51
11.63
11.11
13.16
12.50
12.66
13.51
13.16
14.71
DEMO
11.63
12.82
13.33
12.82
12.50
0.95
deviation of
(on
was calculated
DEMO 0-1
importance weights from a pretest (N = 18) in which
participants were asked to indicate the importance of
several aspects of courses. DEMO pretest indicated that
the relative weights for the three attributes used in this
study would be approximately 0.5 (for interest), 0.3
(for DEMO), and 0.2 (for grade). Using these pretest
data, stimuli were classified into four levels of overall
value, and one alternative was selected from each
level of value for each of the five conflict DEMO There
were some minor constraints on the degree to which
we could vary value independently of attribute con-
flict and extremity. For instance, the highest possible
value score varies across levels of conflict. However,
the DEMO between estimated value and conflict
was only 0.03 in our stimulus set. Extremity and
estimated value were correlated -0.10, because items
with low extremity levels are necessarily restricted in
terms of their possible value. Table 1 DEMO the attribute
levels of the 20 stimuli used in our experiment, DEMO well
as the conflict, extremity, and estimated value scores
for each stimulus.
Measures
Preference Ratings. Each stimulus appeared on a
computer screen with DEMO heading "Please Rate," at
the top of the screen, the three labeled attribute values
in the middle of the screen, and the rating scale at the
bottom. The lower end of the rating scale DEMO an-
chored by a verbal description of the worst alternative
("interest level is Very Low, average grade is 2.8,
teaching quality is Very Poor"). The upper end of the
scale was anchored by a description of the best possi-
96
MANAGEMENT
SCIENCE/Vol.
46, No. 1, January
2000
FISCHER, LUCE, AND JIA
Attribute Conflict and Preference Uncertainty
ble alternative ("interest level is Very High, average
grade is 3.2, teaching quality is Very Good"). Partici-
pants used this scale to evaluate other course descrip-
tions by moving a slider along the continuous scale
using DEMO optical mouse. No numerical scale values
were displayed. We converted all responses to a 0 to 1
scale, assuming a linear mapping of pointer locations
to scale values.
Preference Uncertainty Measures. To measure an
individual participant'DEMO response times, we first aver-
aged the response times for the DEMO presentations of
each stimulus. This yielded 20 response times for each
participant, one for each stimulus. Because the distri-
bution of these response times was strongly skewed to
the right, we applied a negative reciprocal transforma-
tion (-1/response time) to the average time each
participant took DEMO responding to each item. This
resulted in a more normal distribution.3 All statistical
tests were performed on these transformed response
times. However, to facilitate interpretation of the
results, descriptive statistics are presented as response
times measured in seconds. These were computed by
reversing the negative reciprocal transformation. To
DEMO response error, we calculated the absolute
value of the difference between DEMO stimulus' attractive-
ness ratings at time 1 and time 2. We DEMO use the terms
"response error" and "response inconsistency" inter-
changeably when referring to this measure.
Our primary interest was in how attribute DEMO
and other stimulus properties affect preference uncer-
tainty, not in individual DEMO in response ten-
dencies. To control for such individual differences in
our statistical analyses, we used individual partici-
pants' average error or average DEMO time scores
as covariates. Adding these covariates to our models
allows more precise inferences regarding the effects of
attribute conflict and extremity.
Auxiliary Variables. DEMO the end of the Mouselab
program, participants were asked to indicate DEMO
preferences for differing levels of average course
3 The negative reciprocal transformation is commonly applied to
response time data. Because a simple reciprocal transformation DEMO a
decreasing function of response time, the negative reciprocal is used
DEMO preserve the ordering of response times.
MANAGEMENT
SCIENCE/Vol.
46, No. DEMO, January 2000
grades by responding to a scale reflecting either a
DEMO grade is better (0), the participant is unsure (5),DEMO
or a higher grade is better (10). This manipulation
check DEMO was used to test our assumption that
higher average grades are more preferred. The aver-
age response on this scale was 8.22 (standard devia-
tion = 2.48), supporting our assumption.
Each participant's final task DEMO to complete a paper
and pencil questionnaire eliciting attribute importance
weights. Participants were instructed to assign 100
points to the most important attribute, and then to
assign points to the two remaining attributes relative
to this DEMO of 100 points. These importance weights
were normalized to sum to 1.0. The average weights
were somewhat different from those in our pre-test
(0.38 for interest, 0.41 for teaching quality, and 0.21 for
average grade)DEMO We used these participant-assessed
weights to compute participant-specific values for
each stimulus. In calculating these values, the normal-
ized weights for the participant were multiplied by the
respective three attribute values (each scored as 1
through 5). These individual-level value scores corre-
lated 0.04 with conflict and DEMO with extremity.
These correlations indicate that we were successful in
manipulating attribute conflict and attribute extremity
independently of the overall value of outcomes.
Results
DEMO are three levels of analysis at which we test
predictions in this experiment. The first is the re-
sponse level, in which an individual participant eval-
uates one alternative twice, in the two replications.
At this level, our data will consist of either an
absolute error score (DEMO difference between the two
evaluations) or an average negative reciprocal re-
DEMO time for the two judgments of each stimulus.
Second, we can DEMO item (or stimulus) level data
regarding the average negative reciprocal response
times and absolute error scores for each of the 20
stimuli (alternatives) used in the experiment. This
level of analysis pools data across participants.
Third, we can analyze participant level data regard-
ing the average negative reciprocal response times
and average absolute error scores for each partici-
pant. DEMO level of analysis pools across the 20
stimuli evaluated twice by each participant.
97
FISCHER, LUCE, AND JIA
Attribute Conflict and Preference Uncertainty
Relationship Between DEMO Time and Re-
sponse Error. Our analysis assumes that response
time and response error both reflect the same under-
lying construct-preference uncertainty. Thus, we
predict a positive correlation between response time
and response error. Because we DEMO preference
uncertainty to be driven by stimulus characteristics
(conflict, extremity), we expect this relationship to be
evident at both the item level (i.e., average response
time and error for each stimulus) and the DEMO
level (individual participants' response times and er-
ror scores for individual stimuli).4
At the item level, the correlation between negative
reciprocal response time and average absolute re-
sponse error was strong and highly significant5 (r
= 0.69, p < 0.001, N = 20). Calculating DEMO corre-
lation at the response level is more complex, because
participants DEMO differ substantially in terms of both
response time and response error. To control for such
individual differences, we used a z-transformation to
standardize each participant's response time and re-
sponse error scores for the 20 DEMO The result-
ing response-level correlation between negative recip-
rocal response time and average absolute response
error was more modest but still highly significant (r
= 0.18, p = 0.003, N = 440). In short, we found clear
evidence that higher response error was associated
with longer DEMO times at both the item and
response levels. These correlations are consistent with
our assumption that response time and response error
both reflect underlying DEMO uncertainty.
Effects of Attribute Conflict and Extremity on
Response Time. Our theoretical analysis led us to
predict that greater attribute conflict should lead to
DEMO response times whereas greater attribute ex-
tremity should lead to shorter response times. Because
the two independent variables, attribute conflict and
4Our assumption that response time and error both reflect prefer-
ence uncertainty does not imply DEMO we will find a positive
correlation between the two at the participant level. At this level,
participant differences in effort-accuracy tradeoffs could well DEMO
to a negative correlation; those who employ more effortful strategies
will DEMO less prone to response error.
5 Because our hypotheses involve clear directional predictions, we
report one-tailed tests, unless otherwise noted.
98
attribute extremity, are inherently positively corre-
lated, we used multiple regression methods to test
these predictions simultaneously. To control for indi-
vidual differences in these analyses, we included a
participant-level covariate for average negative recip-
rocal response time.6
DEMO 1 in Table 2 summarizes the relevant regres-
sion results. Our predictions were strongly supported.
First, greater attribute conflict led to longer response
times (p < 0.001). Second, greater attribute extremity
led to shorter DEMO times (p = 0.001). We ran
additional regressions, not reported in the table, to test
for the presence of quadratic effects for either conflict
or extremity. Once linear effects were included in the
model, quadratic terms did not significantly improve
the model fit (for attribute conflict, p = 0.24, for
attribute extremity, p = 0.39).
To obtain a better sense of the relative effect sizes,
we used DEMO regression results to calculate the pre-
dicted impact of attribute conflict and extremity on
response time. Consistent with the relative magni-
tudes of the DEMO regression coefficients, esti-
mated regression effects were roughly equal in mag-
DEMO for attribute conflict and attribute extremity. As
conflict moved from its lowest to highest levels, pre-
dicted average response times (converted from nega-
DEMO reciprocals back into seconds) increased from 11.6
seconds to 14.3 seconds. DEMO, as extremity moved
from its lowest to highest levels, estimated average
response times decreased from 14.1 seconds to 11.8
seconds. In short, these response time results provide
strong support for both our attribute conflict and
DEMO extremity hypotheses.
6 The average scores used as covariates were calculated from
responses over all 20 stimuli. These covariate analyses are concep-
tually similar DEMO using error and time measures standardized
separately for each participant. The covariate analyses are also
conceptually similar to standard within-subjects ANOVA methods,
with DEMO average error and average response time covariates repre-
senting a (more DEMO) substitute for a multi-level factor
accounting for subject variance. The results DEMO analyses using these
covariates were identical (in their implications) to both analyses of
standardized data and analyses using within-subjects ANOVA
methods.
MANAGEMENT
SCIENCE/DEMO
46, No. 1, January 2000
FISCHER, LUCE, AND JIA
Attributte Conflict and Preference Uncertainty
Table
2
DEMO Multiple Regression
Response Error
Models
of the Effects
of Attribute
Conflict,
Attribute
Extremity,
and Outcome
Value
on Response Time
and
1. NegRec
DEMO
Dependent
Variable
2. Absolute
Error
3. NegRecip
RT
p
t
f
t
4. Absolute
Error
ft
Independent
Variable
f
t
Conflict
Extremity
Outcome Value
DEMO
AvgAbErr
Adjusted
R2
0.203
-0.148
0.706
0.517
4.37***
- 3.19***
21.28***
0.209
-0.117
0.274
0.092
3.29***
- 1.83*
6.03***
0.194
-0.136
0.074
0.705
0.521
DEMO
- 2.91**
2.21*
21.33***
0.200
-0.103
0.082
0.272
0.097
3.13***
- 1.61 t
1.79t
5.98***
clear directional predictions, all
on 440 observations.
***p < 0.001,**p
Note. AvgNegRecRT and AvgAbErr are
p-levels
< 0.01, *p
are
covariates
one-tailed,
except
0.05 tp < 0.10.
controlling for between-participant
those
DEMO
the
outcome
value
differences
term,
for
in response
which
time
we made
and
no
response
predictions.
error.
Each
Because
regression
our
model
equation
DEMO
is based
Effects of Attribute Conflict and Attribute Extrem-
ity on Response Error. Our theoretical analysis also
led us to predict that greater attribute DEMO should
lead to greater response error, whereas greater at-
tribute extremity DEMO lead to less response error.
Because attribute conflict and attribute extremity are
inherently positively correlated, we again used multi-
ple regression methods to test these predictions simul-
taneously. To control for individual differences in
these analyses, we included participant-level covari-
ates for average absolute error. Model 2 in DEMO 2
summarizes the regression analyses testing these pre-
dictions. Both were supported. Greater attribute con-
flict led to greater response errors (p = 0.001) while
greater attribute extremity led to smaller response
errors (p = DEMO). Additional tests showed no evi-
dence of quadratic effects. Once the linear effects were
included in the model, quadratic terms did not signif-
icantly improve the model fit (for attribute conflict, p
0.71, for attribute extremity, p = 0.23).
To obtain a better sense of the relative effect sizes,
we used the regression results to calculate DEMO pre-
dicted impact of attribute conflict and extremity on
response errors. Moving attribute conflict from its
lowest to highest level increased the predicted average
DEMO error score from 0.049 to 0.091 (on a 0 to 1
DEMO
SCIENCE/Vol.
46, No. 1, January 2000
scale). Moving attribute extremity from its lowest to
highest levels decreased the predicted average abso-
DEMO error score from 0.084 to 0.056. Thus, the esti-
mated effect DEMO attribute conflict was roughly 50%
larger than that of attribute extremity. In short, the
response error data, like the response time data,
DEMO support for our attribute conflict and attribute
extremity hypotheses.
Finally, note DEMO the overall R2 is higher for the
response time analysis (Model DEMO in Table 2) than for
the response error analysis (Model 2). This difference
is largely due to larger systematic individual differ-
ences DEMO response time than in response error. Thus,
the individual difference covariate explains more vari-
ance in response times than in response errors. The
DEMO regression coefficients for the stimulus
properties of interest here (attribute conflict DEMO ex-
tremity) are actually very similar in magnitude for the
two DEMO measures.
Alternative Value Effects on Response Time and
Response Error. Our main theoretical emphasis has
been on the effects of attribute conflict and attribute
DEMO on response time and response error. In this
section, we address DEMO question of whether response
times and response errors also depend on overall
99
FISCHER, LUCE, AND JIA
Attribute Coniflict and Preference Uncertainty
evaluations of DEMO For instance, one can imag-
ine that it is easier to DEMO that an outcome is low in
value (because it has at DEMO one bad feature) than it is
to judge that an outcome DEMO high in value. On the other
hand, it might be easier DEMO judge positive outcomes-
it's only good if it is perfect, DEMO degrees of bad are
harder to assess. Thus, a qualitative analysis DEMO
reasons to expect that the effect might be in either
direction.
To investigate this question, we conducted an addi-
tional set of multiple regression analyses to assess
value effects while controlling for possible effects of
attribute DEMO and attribute extremity (see Models 3
and 4 in Table 2)DEMO For the negative-reciprocal, re-
sponse-time dependent variable, higher value out-
comes were associated with significantly longer re-
sponse times. The effects of attribute DEMO and
extremity also remained highly significant. Using
standardized ,Bs as a DEMO of effect strength, the
value effect was roughly I as great DEMO the extremity
effect and - as great as the conflict effect. Similarly, the
estimated regression effects indicate that alternative
value had a relatively small effect on response time.
As the value of an outcome increased from DEMO to 1,
predicted response time increased from 12.4 to 13.4
seconds.
For the absolute error dependent variable, higher
value outcomes were associated with marginally sig-
nificantly greater response error. The attribute conflict
effect remained highly DEMO, and the extremity
effect also remained strong (though it fell below the
traditional 0.05 significance level). Using standardized
,Bs as a measure of effect strength, the value effect was
about 4 as strong as the extremity effect and 5 as strong
as the attribute conflict effect. DEMO estimated impact of
value on absolute response error indicates that as the
value of an outcome increased from 0 to 1, predicted
response error increased from 0.062 to 0.080. Addi-
tional tests, not reported in the table, indicated that
value did not interact with conflict or extremity for
either the response time or response error models.
In short, in the present context, outcomes that evoke
more positive evaluations also evoke greater prefer-
ence uncertainty, as measured both by response error
and response time. Hereafter, we refer to this as the
100
alternative value effect. This effect is smaller than the
attribute conflict and extremity effects that we also
DEMO Nevertheless, it persists even in regression
models controlling for these other DEMO While this
alternative value effect was not predicted by our
earlier theoretical analysis of stimulus characteristics,
the effect can be explained by the DEMO Rand-
MAU model presented in Fischer et al. (2000).
Participant DEMO in Effort-Accuracy Tradeoffs.
As noted earlier, the results of this experiment
DEMO our assumption that response times and
response errors are both manifestations of prefer-
ence uncertainty. For instance, the two measures
were strongly positively correlated at the item level
(r = 0.69). As noted in the Introduction, however,
this positive correlation might appear to contradict
Payne et al.'s (1993) hypothesis that increasingly
effortful decision strategies lead to DEMO accurate
decisions (i.e., less response error) but also to longer
DEMO times. Note, however, that we predict a
positive correlation between response error and
time at the item level of analysis, while the effort-
accuracy model predicts a negative correlation be-
tween measures at the strategy DEMO participant level.
These predictions are different but not necessarily
contradictory.
Suppose for example that a person chooses a high-
accuracy, high-effort strategy. On the average, this
person should make relatively small errors. Neverthe-
less, the DEMO we have proposed here predicts
that this person will take longer and make larger
errors when evaluating high conflict than low conflict
alternatives. Now DEMO a second individual who
chooses a low-accuracy, low-effort strategy. On the
DEMO, this person should make relatively large
errors. Nevertheless, our framework predicts that this
person will also take longer and make larger errors
when DEMO high conflict than low conflict alter-
natives. In short, participant-level strategy DEMO can
co-exist with response-level, preference uncertainty
effects.
One can test the DEMO models simultaneously by
predicting response-level errors using both participant-
level and response-level measures of response time.
Table 3 displays the results of two multiple DEMO
MANAGEMENT
SCIENCE/Vol.
46, No. 1, January 2000
FISCHER, LUCE, AND JIA
Attribntte Conflict and Preference Uncertainty
Table 3 DEMO Multiple Regression Models of the Effort-
Accuracy Tradeoff Hypothesis
Dependent Variable
Absolute Error Absolute Error
Independent
Variable t t
NegRecRT 0.242 3.63*** 0.242 3.77***
DEMO -0.219 - 3.29*** -0.171 - 2.64**
AvgAbErr 0.274 5.96***
Adjusted R2 0.027 0.098
Note. AvgNegRecRT and AvgAbErr covariates controlling for between-
participant differences in DEMO time and response error. Because our model
involves clear directional predictions, DEMO p-levels are one-tailed. Each regression
is based on 440 observations.
***p s 0.001, **p ? 0.01.
analyses. In the first, we predicted response-level
DEMO errors (AbErr) using both a response-level re-
sponse-time measure (NegRecRT) and a participant-
level response-time measure (AvgNegRecRT, which re-
flects the DEMO response time of a participant, pooling
across all 20 stimuli). DEMO we are controlling for
participant-level effects with the AvgNegRecRT mea-
sure, DEMO expect that the response-level NegRecRT mea-
sure will primarily reflect the difficulty that a participant
has in evaluating a particular item. Thus, this measure
reflects preference uncertainty about a particular alter-
native and its coefficient should DEMO positive. In contrast,
the participant-level AvgNegRecRT measure should re-
flect participant-level strategy choices based on effort-
accuracy considerations. Thus, we predict that its coeffi-
cient will be negative. Those participants who engage in
more effortful (time-consuming) strategies should make
smaller response errors.7 The results of the analysis
strongly support both predictions. Both regression coef-
ficients have the predicted sign DEMO both are significant
at beyond the p = 0.001 level.
The second analysis adds a second participant-level
measure, AvgAbErr, which controls for participant
'In making this prediction, we assume that participants do not
differ substantially in expertise or other factors that might lead to
participant differences in DEMO uncertainty.
are
differences in response error, apart from those cap-
tured DEMO the AvgNegRecRT measure. These might
relate to differences in expertise, for DEMO The
coefficient for this variable should be positive. As
before, we DEMO that the coefficient for NegRecRT
will be positive (preference uncertainty) while that for
AvgNegRecRT will be negative (effort-accuracy).
Again, the results DEMO support both the prefer-
ence uncertainty and effort-accuracy predictions. All
three coefficients have the predicted signs and all
three are highly significant. In short, we find strong
support for both our preference-uncertainty hypothe-
ses and the DEMO et al. effort-accuracy hypothesis.
These results are consistent with our argument that
the preference uncertainty effects arise at the item or
response level, because of differences in item diffi-
culty, whereas the effort-accuracy effects arise mainly
at the participant level (in our data), because of
differences in strategies adopted by different partici-
pants.
Conclusion
This experimental work is intended DEMO a beginning
step towards understanding and quantifying the feel-
ings of ambivalence and preference uncertainty that
often arise when people evaluate multiattribute alter-
natives. DEMO operationalize the construct of preference
uncertainty using both a measure of response time
and a measure of test-retest response error. Our ex-
perimental results DEMO the measurement approach
taken in this article. As predicted, at the DEMO (or
item) level, higher levels of response error were
strongly DEMO correlated with higher levels of
response time. Response times and response errors
were also significantly correlated at the response level.
This supports our theoretical DEMO that response
time and error are both manifestations of preference
uncertainty, DEMO suggests that both depend on basic
properties of stimuli, such as DEMO conflict and
attribute extremity. While it is widely acknowledged
that preferences may be expressed with error, we do
not know of other behavioral work that has operation-
alized preference uncertainty using both measures of
response time DEMO response error.
The empirical results also supported our two main
MANAGEMENT
SCIENCE/Vol.
46, No. 1, January 2000
101
FISCHER, LUCE, AND JIA
Attribute Conflict and Preference Uncertaiinty
predictions regarding DEMO causes of preference
uncertainty. First, greater attribute conflict led to both
DEMO response times and larger response errors.
Second, greater attribute extremity led DEMO smaller
response errors and shorter response times. Finally,
we found one unanticipated effect-higher value out-
comes appeared to be more uncertain in value, as
reflected by the significant positive effect of value on
response error DEMO response time while controlling for
conflict and extremity effects. In short, DEMO prop-
erties, such as attribute conflict, extremity, and posi-
tivity DEMO a strong impact on levels of preference
uncertainty, as manifested in DEMO error and re-
sponse time.
These findings have important implications for
measuring and modeling preferences in the social
sciences or decision analysis. One implication DEMO that
researchers attempting to measure multiattribute util-
ity should consider stimulus characteristics such as
attribute conflict and extremity when collecting and
interpreting judgment data. DEMO high-conflict
alternatives are potentially more informative about
preferences, they also evoke DEMO response error.
On the other hand, extreme attribute levels evoke less
DEMO error. This work also has implications for
formal models of multiattribute judgment. In a com-
panion paper (Fischer et al. 2000), we develop a
multiattribute utility model that represents preference
uncertainty as random variation in DEMO parameters.
By doing so, we extend and formalize the current
behavioral DEMO that preference uncertainty is a
function of stimulus characteristics.
Note that by linking preference uncertainty to ran-
dom variation in model parameters, we associate it
with preference construction (evaluation) rather than
with preference expression (Goldstein and Einhorn
1987). Preference construction involves constructing
an internal impression of DEMO whereas preference
expression involves translating internal evaluations to
an external response scale. Thus, expression effects
should depend on outcome value but not on the
configuration of attributes generating a given level of
value. Because we found DEMO conflict and extrem-
ity effects even when controlling for value, it DEMO
likely that the attribute conflict and extremity effects
102
arise at the evaluation stage. The value effect could
arise either during the preference construction DEMO
evaluation stage, so we cannot rule out the existence of
expression DEMO in addition to preference construc-
tion effects on preference uncertainty.
Finally, DEMO is noteworthy that our hypothesized
preference uncertainty effects may co-exist with the
effort-accuracy tradeoff model proposed and sup-
ported by Payne et al. (1993). According to this model,
decision strategies that lead to more DEMO choices
generally require greater effort. Thus, at the strategy
level, greater effort should be negatively related to
accuracy. Consistent with this prediction, we found a
highly significant negative relationship between par-
ticipant-level measures of response DEMO and response
error on individual judgments. This finding extends
the effort-accuracy model from systematic to random-
error measures of accuracy. On the other hand, as
predicted by our preference uncertainty model, we
also found highly significant positive relationships
between item and response-level measures of re-
sponse time and DEMO error. These findings show
that stimulus-based preference uncertainty effects
may operate in parallel with between-participant
effort-accuracy effects. Together, the preference uncer-
tainty and effort-accuracy frameworks provide a pow-
erful basis for analyzing the causes and consequences
DEMO preference uncertainty, as manifested in response
time and response error.8
8 DEMO research was supported in part by grant SBR-97-09615 from
the Decision, DEMO, and Management Science Program of the Na-
tional Science Foundation and DEMO the Fuqua Business Associates
Research Fund. We thank Jim Bettman, John DEMO, three anony-
mous referees, and Department Editor Robin Keller for helpful
comments and suggestions.
References
Bell, D. E. 1982. Regret in decision making under uncertainty. Oper.
Res. 30 961-981.
Berlyne, D. E. 1966. Conflict and reaction time: reply to Kiesler.
Psych. Reports 19 413-414.
Bettman, J. DEMO, E. J. Johnson, M. F. Luce, J. W. Payne. 1993.
DEMO, conflict, and choice. J. of Experiment. Psych.: Learn-
ing, Memory, and Cognition 19 931-951.
Coombs, C. H., G. S. Avrunin. 1976. Single-peaked functions and the
theory of preference. Psych. Rev. 84 216-230.
Festinger, L. 1957. A Theory of Cognitive Dissonance. Row, Peterson,
Evanston, DEMO
MANAGEMENT
SCIENCE/Vol.
46, No. 1, January 2000
FISCHER, LUCE, AND JIA
Attribute Conflict and Preference Uncertainty
Fischer, G. W. 1976. Multi-dimensional utility models for risky and
riskless choice. Organ. Behavior DEMO Performance 17 127-146.
- Z. Carmon, D. Ariely, G. Zauberman. 1999. Goal-based
construction of preferences: Task goals and the prominence
effect. Management Sci. 45(8) 1057-1075.
- S. A. Hawkins. 1993. Strategy compatibility, scale DEMO
ity, and the prominence effect. J. of Experimeint. Psych.: Human
Perception and Performnance 19 580-597.
, J. Jia, M. F. Luce. 2000. Attribute conflict and preference
uncertainty: The RandMAU model. Management Sci. Forthcom-
ing.
Goldstein, W. M., H. J. Einhorn. 1987. Expression theory and the
preference DEMO phenomenon. Psych. Rev. 94 236-254.
Hansen, F. 1972. Consumner Choice Behavior: A Cognitive Theory. Free
Press, New York.
Hogarth, R. M. 1987. DEMO and Choice, 2nd Edition. Wiley, New
York.
Janis, I. L., L. Mann. 1977. Decision Making. Free Press, New York.
Johnson, E. DEMO, J. W. Payne, J. R. Bettman. 1988. Information displays
and preference reversals. Organ. Behavior and Human Decision
Process. 42 1-21.
Keeney, R. L., H. Raiffa. 1976. Decisions zvith Multiple Objectives:
Preferences and Valute Tradeoffs. Wiley, New York.
Kiesler, C. A. 1966. Conflict and number of DEMO alternatives.
Psych. Reports 18 603-610.
Laskey, K. B., G. W. Fischer. 1987. Estimating utility functions in the
presence of response error. Managemnent Sci. DEMO 965-980.
Lewin, K. 1951. Field Theory in Social Science. Greenwood Press,DEMO
Westport, CT.
Lichtenstein, S., B. Fischhoff, L. D. Phillips. 1982. Calibration of
probabilities: the state of the art to 1980. D. Kahneman, P.
Slovic, A. Tversky eds. Under Uncertainty: Heuri istics
and Biases. Cambridge University Press, Cambridge, En-
gland.
Loomes, G., R. Sugden. DEMO Regret theory: An alternative theory of
rational choice under uncertainty. Econom. DEMO 92 805-824.
Luce, M. F. 1998. Choosing to avoid: coping with negatively
emotion-laden consumer decisions. J. Constmner Res. 24 409-
433.
March, J. G. 1978. Rationality, ambiguity, and the engineering of
choice. Bell J. DEMO 9 587-608.
Payne, J. W., J. R. Bettman, E. J. DEMO 1993. The Adaptive Decision
Maker. Cambridge University Press, Cambridge, England.
Shepard, R. N. 1964. On subjectively optimum selection among
multiattribute alternatives. Maynard W. Shelly, Glenn L. Bryan,
eds. Human Jutdginent and Optimnality. Wiley, DEMO York, 257-281.
Tversky, A., S. Sattath, P. Slovic. 1988. Contingent weighting in
judgment and choice. Psych. Rev. 95 371-384.
Tversky, A., DEMO Shafir. 1992. Choice under conflict: the dynamics of
deferred decisions. Psych. DEMO 6 358-361.
Accepted by L. Robin Keller; received
July 18, 1998. This paper
has been zvith
the auithors nmonths
5
for 1 revision.
DEMO
SCIENCE/Vol.
46, No. 1, January 2000
Jutdgmenewt
103{1g42fwefx}