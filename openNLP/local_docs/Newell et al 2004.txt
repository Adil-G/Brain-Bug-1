Journal of Behavioral Decision Making
J. Behav. Dec. Making, 17: 117–137 (2004)
Published online in Wiley InterScience
(www.interscience.wiley.com) DOI: 10.1002/bdm.465
Search Strategies in Decision Making: The
Success of ‘‘Success’’
BEN R. NEWELL1*, TIM RAKOW2, NICOLA J. WESTON1
and DAVID R. SHANKS1
1University College DEMO, UK
2 University of Essex, Colchester, UK
ABSTRACT
Examination of DEMO strategies has tended to focus on choices determined by decision
makers’ personal preferences among relevant cues, and not on learning cue-criterion
relationships. We present an empirical and rational analysis of cue search for environ-
ments with DEMO criteria. In such environments, cues can be evaluated on the basis
DEMO three properties: validity (the probability that a cue identiﬁes the correct choice if cue
values differ between alternatives); discrimination rate (the proportion of occasions on
which a cue has differing values); and success (the expected proportion of correct
choices when only that cue can be DEMO). Our experiments show that though there is
a high degree of individual variability, success is a key determinant of search. Further-
more, DEMO rational analysis demonstrates why success-directed search is the most adaptive
strategy in many circumstances. Copyright # 2004 John Wiley & Sons, Ltd.
key words
search strategies; heuristics; cue hierarchies, adaptive behaviors
When faced with a decision it is often impossible to consider all of the options, their attributes and their
potential consequences simultaneously, so we must do so sequentially. The order that we adopt to dictate
this sequential search may have DEMO effects on our decisions and the consequences of those decisions
(Hastie & Dawes, 2001). In this paper we present a new conceptualization DEMO search in decision making in
which search is dictated by the ‘‘success’’ of information in predicting the correct outcomes of decisions.
Success is a DEMO of the likelihood that a piece of information is usable and its accuracy in leading to a
correct inference. We report empirical evidence showing DEMO people’s search patterns are allied to those
determined by success, and DEMO rational analysis that demonstrates the variety of circumstances in which suc-
cess-directed search achieves the best outcomes.
Decision making can be considered to have DEMO component processes: information acquisition; evalua-
tion/action; and feedback/learning (Einhorn & Hogarth, 1981; Payne, 1982). Arguably, information acquisi-
DEMO has received the least attention of these three aspects. Indeed, Anderson (1990) notes that the literature
* Correspondence to: Ben R. Newell, School of Psychology, The University of New South Wales, Sydney 2052, Australia.
E-mail: ben.newell@unsw.edu.au
Contract/grant sponsors: Economic and Social Research Council, UK; The Leverhulme Trust, UK.
Copyright # 2004 John Wiley & DEMO, Ltd.
118
Journal of Behavioral Decision Making
on decision making under uncertainty focuses DEMO on one-step problems that obviate the need for infor-
mation search.
The literature on information purchase (for an overview, see Connolly & Gilani, 1982; or, Connolly &
Thorn, 1987) shows that people generally respond in the appropriate direction to changes in task character-
istics such DEMO the cost or diagnosticity of information. However, the magnitude of response DEMO typically less
than normative principles specify (Hershman & Levine, 1970; DEMO & Peterson, 1969; Lanzetta & Kanareff,
1962; Pitz, 1968; Van Wallendael & Guignard, 1992). Relative to the prescriptions of DEMO principles
(e.g., Edwards, 1965; Marschak, 1954; Stigler, 1961; Wendt, 1969), ﬁndings regarding the scale of acquisi-
tion are equivocal: overpurchase; underpurchase; and near optimal purchase are all observed (Hershman &
Levine, 1970; Kaplan & Newman, 1966; Pruitt, 1961; DEMO & Edwards, 1966).
There has been some focus on sequential DEMO in decision making (e.g., Einhorn, Kleinmuntz, &
Kleinmuntz, 1979; Russo & Rosen, 1975), and this research has implications concerning DEMO order in which
we search through a ﬁxed amount of information. There is clear evidence that the order in which information
is presented (and processed) inﬂuences judgment (Hogarth & Einhorn, 1992). Likewise, choice DEMO be inﬂu-
enced by the order in which alternatives are presented (DEMO & Levine, 1978), and by whether information
relevant to the DEMO is presented sequentially or simultaneously (Russo, 1977). In this paper we exam-
ine information acquisition in detail, considering situations in which people have control of both the amount
of information they acquire and the DEMO in which they search through that information.
Gigerenzer (2001) suggests that search can be conceived as the exploration of two dimensions: a search
for alternatives or ‘‘the choice set’’; and a search for cues on which to evaluate the alternatives. Our concern
here is the search for DEMO in environments with an objective criterion in which cues are probabilistically
related to this criterion.
SEARCHING FOR CUES
One approach to decision making that DEMO search in such environments is the fast-and-frugal heuristics
framework (e.g., Gigerenzer, Todd and The ABC Research Group, 1999). The view of DEMO and col-
leagues is that humans possess an adaptive toolbox comprising a variety of heuristics, and building blocks to
construct heuristics, that can DEMO applied to a wide range of decision problems.
In our previous work we have questioned the ‘‘toolbox’’ approach, suggesting that much of the empirical
evidence for the use of heuristics could just as easily, and more parsimoniously, be incorporated into a general
evidence-accumulation model of decision making (DEMO, Newell & Shanks, 2003; Newell, Weston & Shanks,
2003—see also Lee & Cummins, 2004), for a formal instantiation of such a model). Such a general model has
the potential to replace DEMO ‘‘ultimate’’ free parameter—i.e., a blank page on which new heuristics can DEMO
invented to accommodate each and every variation in behavior—with a single, DEMO determined, evi-
dence-threshold parameter. The important consideration for the current work DEMO that both approaches require a
mechanism for determining the sequential search through information. Thus our examination of potential
search mechanisms is consistent with both DEMO general evidence-accumulation model and the ‘‘toolbox’’
approach. We will not reiterate here the arguments why we believe a general model may be more appealing
DEMO rather focus on potential mechanisms for search required both by heuristics and a general model.
The most prominent heuristic in the adaptive toolbox—‘‘take-the-best’’—speciﬁes a DEMO for serial
search through binary cues. It uses computed cue validities to order this search, where validity is deﬁned
as the probability that the cue will identify the correct alternative on a random selection of alternatives DEMO
differ on this cue. The ‘‘take-the-best’’ heuristic (TTB) comprises three basic building blocks: the search rule
(search cues in order of descending DEMO); the stopping rule (stop after the ﬁrst discriminating cue is DEMO
covered); and the decision rule (choose the outcome pointed to DEMO the ﬁrst cue that discriminates). In many of
the situations in which TTB is thought to be applied people are assumed to have DEMO to a reference class of
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
B. R. Newell et al.
Search Strategies
119
cues ranked according to DEMO validities. TTB is a special case of a lexicographic rule (e.g., Fishburn, 1974)
formulated for inference rather than preference, where search DEMO directed by the objective validity of cues
rather than a subjective measure of cue importance.
A simple example of an inferential search problem is DEMO an almanac question like, ‘‘Which has the
larger population, Hamburg or Leipzig?’’ (cf. Gigerenzer & Goldstein, 1996). The reference class DEMO
to answer such a question is assumed to include cues such as, ‘‘Is the city the capital?’’, ‘‘Does it have an
airport/DEMO/football team?’’, etc. Assuming both cities are recognized, as soon as a cue is discovered
that has different values for the two DEMO (e.g., Hamburg has a soccer team but Leipzig does not) DEMO single
cue is used to infer (correctly in this case) that Hamburg has the larger population.
It is worth noting here that TTB DEMO on the use of binary rather than continuous cues, as indeed DEMO
many empirical analyses of multiple-cue judgment (e.g., Castellan, 1974; Castellan & Edgell, 1973) and
categorization (e.g., Smith & Minda, 2000; Nosofsky, Palmeri, & McKinley, 1994) (which can be considered
DEMO formally equivalent—see Juslin, Olsson, & Olsson, 2003). Although this DEMO may seem unrepresenta-
tive of many ‘‘real-world’’ situations, it is common DEMO cues to take a binary form even when they could be
treated as continuous. For instance, a glance through any medical journal will reveal many analyses where a
continuous patient variable, such as age, is DEMO as a binary cue (e.g., age > 50 years). This is reﬂected in
how doctors are encouraged to make decisions with these DEMO (see Choussat et al., 1978, for an example),
and are observed to do so (Abernathy & Hamm, 1994).
The DEMO plausibility and simplicity of the validity-based search rule used by TTB has been
championed (e.g., Martignon & Hoffrage, 1999). Gigerenzer, Hoffrage, and Kleinbo¨ lting (1991) proposed
that people construct the hierarchy of DEMO validities in their reference class through the operation of some
frequency-encoding mechanism. This monitoring of the frequencies of co-occurrences in the environment
appears plausible DEMO the research into the effectiveness of frequency estimation (e.g., Hasher & Zacks,
1984), but empirical tests remain scarce. In order to DEMO theoretical development, we and others (Bro¨ der,
2000; Bro¨ DEMO, 2003; Jones, Juslin, Olsson, & Winman, 2000; Newell & Shanks, 2003; Newell, Weston, &
Shanks, 2003; Rieskamp & Hoffrage, 1999) have used experimental environments in which the explicit
building blocks of the fast-and-frugal heuristics can be examined.
Existing empirical evidence suggests DEMO people have great difﬁculty in learning a hierarchy of cue valid-
ities, although they can employ a validity-based search rule if told this hierarchy (Bro¨ der 2003; Newell &
Shanks, 2003; Newell et al., 2003; Rakow, Hinvest, Jackson, & Palmer, 2004). In DEMO paper we focus on the
way in which participants search through cues in an attempt to discover why participants might ﬁnd it difﬁ-
cult DEMO learn about validities, and to examine what other properties of cues DEMO might also be sensitive to.
To illustrate the properties of cues consider the example mentioned above of determining which of two
German cities has DEMO larger population (e.g., Gigerenzer & Goldstein, 1996). Each of DEMO pieces of informa-
tion in memory (e.g., knowing if the city has a university, or knowing if it has an airport, or DEMO if it has a
football team, etc.) will have different validities. In addition to validity, a cue also has a discrimination
rate—that is, the proportion of occasions on which the cue discriminates between the two (or more) alter-
natives. For example, a cue such as ‘‘Is the city the capital?’’ will have a high validity because the DEMO city
has a very large population, but a low discrimination rate DEMO only in the small proportion of compar-
isons involving the capital will knowing the answer to ‘‘Is the city the capital?’’ help in DEMO the
population size. In contrast, knowing whether or not the city DEMO a university will have a much higher dis-
crimination rate (because DEMO are many, but not all, cities with universities, but only DEMO capital) but a lower
validity because it is not always the DEMO that universities are in the largest cities.
We argue that the overall usefulness of a cue is a function of both its discrimination rate DEMO its validity.
More useful cues are those that can frequently be used to make an inference, and, when used, usually point in
the correct direction. We are not the ﬁrst to assert this; Gigerenzer and Goldstein (1999) comment that, ‘‘A
cue with a high ecological validity, however, is not very useful if its discrimination rate is small’’ (p. 85).
However, in this study, we seek to develop DEMO position further, and to consider people’s ability to search
Copyright # DEMO John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
120 Journal of Behavioral Decision Making
through cues ordered according to both DEMO and discrimination. Note that the inﬂuence of discrimination
rate on cue search has not been examined empirically before in the context of fast-and-frugal heuristics,DEMO
because in previous studies the discrimination rate has been held constant across all cues (e.g., Bro¨ der,
One previously described function of DEMO discrimination rate and validity is the success (rate) of the cue
(see Martignon & Hoffrage, 1999). The success of a cue DEMO the expected proportion of correct inferences
when only that cue can be used to make a choice. In the context of two-alternative forced choice
(2AFC), this can be considered in two components. The ﬁrst component DEMO the expected proportion of correct
inferences from choices on which the cue does discriminate. As a proportion of all choices in a set, this is the
product of the cue’s discrimination rate and its validity. The DEMO component is the expected proportion of
correct inferences from those choices on which the cue does not discriminate, forcing the decision maker to
guess (because the cue has the same value for both objects). As a proportion of all choices in a set, this is the
product of the complement of the discrimination rate and 0.5 (0.5 being the expected accuracy when ran-
domly selecting one of the two alternatives). DEMO success of the cue is hence the sum the of two component
terms shown in Equation 1:
dv þð1 dÞ0:5 ð1Þ
where DEMO is the discrimination rate of the cue and v is the cue validity. d*v is the expected proportion of correct
inferences from occasions when DEMO cue discriminates. (1 d)*0.5 is the expected proportion of correct
DEMO from occasions when the cue does not discriminate, forcing a guess (with a 0.5 probability of
a correct choice in a 2AFC task)DEMO
A highly successful cue is one with both a high discrimination rate and a high validity. Success is low
when a cue has both DEMO low discrimination rate and a low validity. Across all possible pairs of objects sampled
from a large set of objects, validity ranges from 0.50 (non-predictive) to 1.0 (perfectly predictive), whereas
discrimination rate for binary cues ranges from 0.0 (when all objects take the same cue value, either all posi-
tive or all negative) to 0.5 (when half of the objects take one cue value, and half the other). Consequently, for
large sets of objects, the upper bound of success DEMO at 0.75 and the lower bound is at 0.50. Intermediate levels
of success may derive from many combinations of validity and discrimination rates: intermediate values for
both cue parameters; or high validity combined with a low discrimination rate, or vice versa. For instance,
three cues having the following combinations of cue parameters all have identical success rates (of 0.59): (1)
validity of 0.68, discrimination rate of 0.5; (DEMO) validity of 0.8, discrimination rate of 0.3; (3) validity DEMO 1.0,
discrimination rate of 0.18.
Using the earlier example of German cities, the success rate of the university cue (0.61) exceeds that of the
national capital cue (0.51) (based on ﬁgures from Gigerenzer & Goldstein, 1999, p. 85). Despite the high
validity of DEMO national capital cue (1.0, indicating it always points in the correct direction), it has a very low
discrimination rate (0.02, reﬂecting DEMO, in almost every pair of cities, neither one is the capital). In contrast,
the validity of the university cue is moderate (0.71), but it has a high discrimination rate (0.51, reﬂecting DEMO,
in about half of all possible pairs, one city will DEMO a university and the other will not—because about half
of the cites have a university).
Gigerenzer and Goldstein (1999) noted that discrimination DEMO validity were negatively correlated in their
German cities environment. Thus, more DEMO cues tended to have lower discrimination rates. This means that
the ﬁrst few cues looked at under a TTB strategy often fail to discriminate, necessitating the search for
further cues. In such circumstances, TTB is less frugal (i.e., searches more information) than other one-
reason algorithms such as Minimalist (which searches randomly through cues) or Take The Last (which
starts with the last cue that discriminated, therefore increasing the likelihood of needing only one cue).
Such a negative correlation between discrimination DEMO validity is presumably not uncommon in real-world
Copyright # 2004 John Wiley & Sons, Ltd. Journal of Behavioral Decision Making, 17, 117–137 (DEMO)
2000; Bro¨
der, 2003; Newell & Shanks, 2003; DEMO et al., 2003).
B. R. Newell et al.
Search Strategies
121
environments, as the ABC Research Group found that the Minimalist strategy was more frugal than TTB DEMO
inferences made across 20 data sets (Czerlinski, Gigerenzer, & Goldstein, 1999).
If information search is costly in such an environment, then searching through cues in descending order of
validity (as prescribed by TTB) may not be ideal. The discrimination rate of cues should have a signiﬁcant
bearing upon the order of cue search, as selecting cues with high discrimination rates tends to decrease the
scale of information search. It DEMO reasonable to assume that there is always some form of constraint on the
amount of information that can or should be searched through. This DEMO if we agree that ‘‘information
always costs something in terms of time, effort, or money’’ (Fried & Peterson, 1969, p. 525). Therefore,
TTB, which searches following cue validity (with no regard DEMO cue discrimination rates), is best adapted
to environments where information is without cost. We doubt that such environments are common. Some
(such as Fried and Peterson, above) would argue that they do not exist DEMO all. In his rational analysis of mem-
ory, Anderson (1990) DEMO some similar points. He asserts that memory structures should be searched in
(descending) order of the probability that they are relevant to the DEMO at hand. We take this to be equiva-
lent to prescribing cue search in (‘‘descending’’) order of discrimination. However, Anderson’s discussion
does not deal with the possibility that different pieces of relevant information may have DEMO value
(‘‘validity’’). This is certainly the case in many situations DEMO decision under uncertainty, where decisions are
more likely to be correct DEMO more valid cues are used. Therefore, if the accuracy of decisions DEMO inferences
is important, the validity (in addition to the discrimination rate) of cues should still have a bearing on the
order of cue search.
Our hypothesis is that success is one of the determinants of DEMO search. This implies that people are sen-
sitive to both the discrimination rate of cues (to reduce search) and the validity of cues (to enhance accuracy).
To test this hypothesis we examine an environment DEMO search is costly, accuracy is rewarded, and cues
differ in both their discrimination rates and validities. To our knowledge, all previous tests of search behavior
have been conducted in environments in which search by validity DEMO success could not be distinguished
because discrimination rates were held constant across cues, thus making validity and success orderings
identical—see Equation 1 above (DEMO, Bro¨ der, 2003; Bro¨ der, 2000, Newell & Shanks, 2003; Newell et al.,
2003). The key test in the two experiments that follow is whether search behavior is more closely allied DEMO the
rank order predicted by success than to other plausible orders.
EXPERIMENT 1
The purpose of Experiment 1 was to examine search strategies in DEMO multiple-cue environment where parti-
cipants’’ choices could be assessed against an objective criterion. Our principal interest was to determine
which of the three properties DEMO the cues— validity, discrimination rate (DR),or success —would drive DEMO
ticipants’’ information acquisition behavior. As can be seen from Table 1, DEMO three properties predict three
distinct acquisition orders. If participants buy information on the basis of validity we should observe an
A > B > DEMO > D order; in contrast, if DR drives behavior then the order would be C > D > B > A; ﬁnally if
success is most important then the information should be acquired in the DEMO C > B > A > D.
Table 1. The validities, DEMO rates and success of Cues A–D and the search orders that they predict
Cue properties Predicted orders
AB C D
VDR S
Validity 0.82 DEMO 0.73 0.56 A > B > C > D
Discrimination rate 0.22 0.37 0.50 0.47 C > D > B > A
Success 0.57 DEMO 0.62 0.53 C
Note: V
¼
Validity; DR
¼
Discrimination Rate; S
¼
Success.
Journal of Behavioral Decision Making, 17, 117–137 (DEMO)
>
B
>
Copyright # 2004 John Wiley & Sons, Ltd.
A
>
D
122 Journal of Behavioral Decision Making
Participants
Twenty members of the University DEMO London community took part in the experiment. Fourteen were
male and six were female. They had a mean age of 25.4 years (range 19–45, sd ¼ 8.0).
Stimuli and design
The experiment was programmed in Microsoft Visual Basic 6 and run on PCs. The experiment used a DEMO
proﬁtability prediction task similar to the one used in a number of previous studies (Bro¨ der, 2000; Newell &
Shanks, 2003; DEMO et al., 2003). Participants were presented with a series of DEMO forced-choice
decisions between the shares of two ﬁctional companies (Share A DEMO Share B). The shares were described
by four binary cues with semantic labels concerning aspects of the company’s ﬁnancial status (see below).
Each cue had an associated validity, discrimination rate and success rate.
Repeated choices were presented to participants in blocks of 64 trials. Each block DEMO generated
(independently) according to a fractional factorial design using SPSS ORTHOPLAN, to ensure that all four cues
were independent (i.e., uncorrelated). Four binary cues were created such that 1/8, 1/4, DEMO/8 or 1/2 of the
generated sets of cue-values were positive, resulting in cue discrimination rates of 0.22, 0.37, 0.47 and
0.50 respectively.
Table 1 displays the validities, discrimination rates and the success of the four cues A–D. The assignment
of these properties to the four DEMO (binary) cues was counterbalanced across participants, but the screen
position DEMO the cue labels was constant for all participants. (Note that this DEMO mitigates the
possibility that participants’ prior beliefs about the ‘‘usefulness’’ of particular cues systematically inﬂuenced
search behavior. Each label (e.g., Share Trend Positive, see below) was assigned every combination of cue
properties across participants.)
For each comparison there was an associated probability of Share A being DEMO most proﬁtable. After each
choice the probability that the chosen share was most proﬁtable was computed according to Bayes’ Rule,
assuming stochastic independence DEMO the cues (details of the calculations can be found in Newell & Shanks,
2003). A random number generator then determined which share became most proﬁtable according to this
probability. Participants were motivated by the DEMO of winning 3p (£0.03) for every correct prediction
during the training trials and 6p (£0.06) for every correct prediction during test trials.
DEMO the training phase cue information was supplied automatically and simultaneously to participants. At
test, information was not provided automatically but participants were able to buy information about each
cue in any order and were required to DEMO at least one cue. This feature was included to ensure that data on
cue-search (our principal interest) was obtained for all participants. The DEMO of each piece of information
was 1p (£0.01).
Procedure At DEMO start of the experiment the participants were given a brief verbal description of the ex-
periment telling them they would be making decisions about DEMO proﬁtability of company shares. Participants
were then given full written instructions on the screen, which they read through with the experimenter.
Participants were told that on each trial they would be asked to choose a share (one of two alternatives) that
they thought would turn out to be the most proﬁtable. To help them make this choice, participants were
provided with four pieces of information about the two companies that the shares DEMO from. These were:
1. Was the share trend positive over the last few months?
2. Does the company have ﬁnancial reserves?
DEMO Does the company invest in new projects?
4. Is it an established company?
Participants were told that in making their predictions they DEMO try to work out which pieces of infor-
mation were most useful as not all the pieces were equally informative.
Copyright # 2004 John DEMO & Sons, Ltd. Journal of Behavioral Decision Making, 17, 117–137 (2004)
B. R. Newell et al.
Search Strategies
123
Figure 1. Screen layout DEMO test trials in Experiments 1 and 2.
Participants then clicked a button to advance to the ﬁrst trial. Participants worked through one 64-trial
block DEMO described above. The trials were presented in an order randomly selected for each participant. Par-
ticipants were required to make a choice by clicking DEMO the ‘‘CHOOSE SHARE A’’ or ‘‘CHOOSE SHARE
B’’ buttons. On clicking either button, two windows below the choice buttons displayed the probability
(expressed DEMO a percentage) that the chosen share would be most proﬁtable, and the most proﬁtable share
on that trial. If the ‘‘correct’’ share was DEMO the Private Account window was incremented by 3p. On
completion of the 64 training trials, a further set of instructions was displayed telling participants that for
the next 128 trials (two more blocks of 64 trials) the information would no longer be automatically supplied
to them but that instead they had to buy each piece. Participants were told that they DEMO buy as many or as
few pieces as they desired and in any order.
The screen layout for the test trials was slightly different DEMO that of the training trials and is displayed in
Figure 1. Clicking on the ‘‘BUY INFORMATION’’ buttons changed the contents of the pair of DEMO
windows from ‘‘?’’ to either ‘‘YES’’ or ‘‘NO’’. Having bought at least one piece of information (minimum 1,
maximum 4) participants DEMO their choice. The most proﬁtable share for that trial was then displayed in the
window. If the ‘‘correct’’ share was chosen the private account DEMO incremented by 6p minus any money that
had been used to buy information. The 128 test trials were presented in a different random order DEMO each
participant.
On completion of the test trials, participants were presented DEMO a new screen and asked to type in num-
bers between 0 and 100 that reﬂected the ‘‘usefulness’’ of each cue. The deﬁnition of DEMO was left
intentionally rather open ended. Participants were simply told: ‘‘Give DEMO score of 0 if you believe a piece
of information was ‘‘no use whatsoever in making predictions’’. Give a score of 100, if you believe that a
piece of information was ‘‘as useful as any single DEMO of information could be’’ for this type of prediction
task.’’ Participants were then thanked, debriefed and paid their participation fee plus their earnings from the
experiment.
RESULTS AND DISCUSSION
Our interest in Experiment 1 was to DEMO which property of the cues would drive participants’’ cue
search most strongly— validity, discrimination rate (DR),or success. The three properties predict three
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
124
Journal of Behavioral Decision Making
Table 2. Classiﬁcation of search orders
DEMO order classiﬁcation
Success and DR Validity DR Success Incompatible
Experiment 1
Mean percentage of trials 24.8 9.9 0.2 1.9 63.3
Percentage of participants 10.0 DEMO 0.0 15.0 65.0
Experiment 2
Mean percentage of trials 19.1 8.7 4.0 4.7 64.2
Percentage of participants 0.0 4.2 8.3 16.7 70.8
Note: DR
¼
Discrimination rate.
distinct orders: A > B > C > D, C > D > B > A and C > B > A > D for validity, discrimination rate and suc-
cess, respectively (see Table 1).
To examine participants’ search orders we classiﬁed each DEMO trial for each participant as compatible/
incompatible with the competing predicted orderings. If only cue C (most successful and most discriminat-
ing cue) was selected, this trial was classiﬁed as compatible with both success DEMO DR. In addition, we clas-
siﬁed each participant according to which DEMO order he or she used most often.1 The upper half of Table 2
summarizes these analyses.
The preponderance of incompatible classiﬁcations in these descriptive DEMO shows that only a min-
ority of participants strictly followed any of the speciﬁed, deterministic orders. This rather disappointing
ﬁnding highlights a potential problem with using the strict deterministic orders for classifying behavioral
search patterns. The DEMO is that the measures displayed in Table 2 do not provide an indication of
whether the ‘‘incompatible’’ orderings that were adopted were more akin DEMO one speciﬁed order than to
another. For example, although only three DEMO were classiﬁed as buying according to success, a
further six participants DEMO the most successful cue ﬁrst but then deviated from the success ordering,
resulting in being classiﬁed as ‘‘incompatible’’. Indeed if the analysis is DEMO simply to the cue pur-
chased ﬁrst most often, then participants DEMO commonly (45% of participants) bought the most success-
ful/discriminating cue ﬁrst and least commonly (15%) bought the most valid cue ﬁrst. DEMO remaining two
cues were bought ﬁrst most often by 20% of participants.
A further problem with using the strict deterministic classiﬁcation of search patterns DEMO the possible inﬂu-
ence of the screen interface. As shown in Figure 1 the position of the ‘‘Buy Information’’ buttons on the
screen, for which we counterbalanced, could result in deviations from the speciﬁed orders on individual trials
and for individual participants. Consider a participant who decides always DEMO buy the two most successful
cues but because of the button position on the computer screen and the ease of using the mouse quite DEMO
mately buys the second most successful followed by the most successful. Such a strategy would result in the
participant being classiﬁed as ‘‘incompatible’’ despite DEMO or her consistent use of the most successful cues.
To overcome the problems with these descriptive measures we considered the proportion of occasions—
or DEMO —with which each cue was used. We then aggregated this analysis across all participants in
order to examine which of the three speciﬁed orders DEMO most closely allied to participants’ information
acquisition behavior.
The ﬁrst row of Section 3.1 of Table 3 displays the proportion of trials on which DEMO cue was bought in
the 128 test trials.2 As can be seen from the mean values, the cue-purchase frequency follows the pattern
1In our previous work we have used an on-line ranking based on modal cue DEMO to classify participants’ search behavior. This
measure is inappropriate for the current studies because three competing orders are considered (as opposed to one order—validity—in
the previous studies) and no hint as to the correct ordering was provided (see Newell & Shanks, 2003; Newell, Weston, & Shanks, 2003).
2Qualitative analysis of information purchase strategies across test trials revealed a high degree of consistency within subjects. We infer
that learning was DEMO to asymptote at the end of the 64 training trials—see General Discussion for further consideration of learning.
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
B. R. Newell et al. Search Strategies 125
Table 3. Section 3.1: The proportion of trials on which each cue was purchased—cue purchase frequency. DEMO 3.2:
Participants’ ratings of the usefulness, validity, discrimination rate and success of Cues AD. Right-hand columns: the
signiﬁcance of Page trend test for search orders predicted by validity (V), discrimination rate (DR), and success (S)
3.1 Cue-purchase frequency Predicted orders
AB C DEMO VDR S
Experiment 1 0.43 0.46 0.67 0.40 — — *
Experiment 2 (ﬁrst test block) 0.35 0.60 0.60 0.39 — — *
DEMO 2 (VE Group) 0.24 0.59 0.53 0.28 — — *
Experiment 2 (DE Group) 0.54 0.53 0.67 0.34 — — —
3.2 DEMO
Usefulness (Expt 1) 0.23 0.26 0.31 0.19 — — *
Usefulness (Expt 2) 0.21 0.26 0.27 0.22 — — *
Validity 0.55 DEMO 0.61 0.47 * — *
Discrimination rate 0.38 0.50 0.54 0.51 — * *
Success 2.50 2.17 2.17 3.17 * — *
Note: VE stands for validities equal. DE stands for discrimination rates equal. Usefulness ratings DEMO normalized to account for
individual differences in interpretation of the measure. Validity and discrimination rate ratings are mean raw scores (unnormalized).
Success rankings were calculated from the order in which participants selected cues; a lower rank indicates a higher estimate of success.
*Indicates signiﬁcance at the p < 0.05 level (one tailed).
predicted by cues acquired on the DEMO of success, that is C > B > A > D. DEMO examine this pattern further we
used the nonparametric Page Trend test for ordered alternatives (Siegel & Castellan, 1988). The Page Test
evaluates DEMO hypothesis that the proportions are ordered in a speciﬁc sequence versus the null hypothesis that
the proportions are the same. A nonparametric test was DEMO because the nature of our predictions was
ordinal. The experimental environment allows us to test whether the proportions are ordered in each of the
DEMO predicted by success, DR or validity.
The Page Trend test indicated DEMO signiﬁcant trend (zL ¼ 2.63, p ¼ 0.004)3 across the four values in the order
predicted by success (C > B > A > D). Page Trend tests for the cue-purchase frequencies predicted DEMO valid-
ity and DR were not signiﬁcant ( ps ¼ 0.323 and 0.115, respectively). The signiﬁcant Page test for the success
ordering indicates that there is an overall trend but it does not tell us DEMO there are signiﬁcant differences
in proportions between pairs of cues. In order to test whether pairs of cues differed from each other, we used
a multiple-comparisons procedure for ranked scores (Siegel & Castellan, 1988, p. 180). Planned compari-
sons revealed that only the difference between the DEMO of trials on which cue C and cue D were bought
was statistically signiﬁcant ( p < 0.05). This result demonstrates that participants DEMO good at distinguishing
between the most and least successful cues.
The ﬁrst row of Section 3.2 of Table 3 displays the mean normalized estimated DEMO ratings of each
cue. These were calculated by summing the ratings given to each cue and dividing each rating by this total for
each DEMO Consistent with the behavioral measure, the order of the means reﬂects DEMO predicted by
ratings on the basis of the success of cues. A Page Trend test conﬁrmed this predicted ordering, indicating a
signiﬁcant trend in the order C > B > A > D(zL ¼ 2.90, p ¼ 0.001). Page Trend tests for the usefulness rating
orders DEMO by validity and DR were not signiﬁcant ( ps ¼ 0.367, DEMO 0.071 respectively). Planned com-
parisons again revealed that only the difference between the estimated usefulness of cue C and cue D was
statistically DEMO ( p < 0.05).
3We report the zL value for the Page trend tests following the conversion formula for an N exceeding 12 (Siegel & Castellan, 1988). For
consistency, in Experiment 2 we DEMO both the standard L value and the zL value for the analyses involving an N of 12.
Copyright # 2004 John Wiley & Sons, Ltd. Journal of Behavioral Decision Making, 17, 117–137 (2004)
126
Journal of Behavioral Decision Making
This consistency between the cue-purchase frequency DEMO the rating of cue usefulness was conﬁrmed by
individual participant analyses that revealed that, for 80% of participants, the most highly rated cue DEMO the
cue most frequently purchased. For 12 out of 20 participants (DEMO), their frequency of purchase corre-
sponded exactly to their stated order of usefulness (6 out of 20 participants if one does not permit ties in
either sequence).
The aim of Experiment 1 was to DEMO which property of a set of cues would determine participants’
search through those cues. Although the descriptive measures of search order indicated considerable indi-
DEMO variability in search patterns, the evidence from the purchase-frequency measure indicates DEMO
that search is inﬂuenced by the success of cues.
EXPERIMENT 2
Experiment 1 indicated that participants’ cue-purchase behavior was more consistent with search according
DEMO the success of cues (which is a function of a cue’s DEMO and discrimination rate) rather than to the valid-
ity alone. In DEMO to their actual behavior, participants’ post-test ratings of the usefulness of DEMO cues also
reﬂected the order predicted by success.
As we noted earlier, ‘‘useful’’ is a somewhat open-ended term, and though the ratings data DEMO Experi-
ment 1 suggest that participants interpret ‘‘useful’’ in terms that correspond to success, the ratings do not
allow us to determine whether participants are sensitive to the individual properties of a cue that contribute
to DEMO success. In Experiment 2 we investigated this question by asking participants not only to rate the order
of usefulness of the four cues, but also the orders of validity, discrimination rate, and success.
Furthermore, we introduced an additional test block after the ratings phase to examine whether DEMO
cue-purchase behavior would be affected by a change in the task environment. For one group the cue validities
were all made equal in the DEMO test block (all set to 0.72), making purchase dictated by DEMO
rate the optimal strategy. A second group was instead given a test block in which all the discrimination rates
were equal (all set to 0.50), making purchase in the order of validity the optimal strategy. DEMO that when dis-
crimination rates are set equal, success order is DEMO identical to validity order (see Equation 1, above).
Thus, DEMO 2 aimed to answer two questions: (1) would participants’ ratings DEMO the orders of valid-
ity, discrimination rate, and success reﬂect the objective orderings; and (2) would participants’ cue-purchase
patterns adapt in accordance with changes in the task environment? In addition to answering these questions,
we aimed to replicate the success ordering of cue purchase for DEMO ﬁrst test phase.
METHOD
Participants
Twenty-four members of the University College London community took part in the experiment. Twelve
were male and 12 were DEMO They had a mean age of 23.8 years (range 18–29, sd ¼ 3.52). Participants
were assigned randomly to two groups of 12—the DEMO Equal group (VE) and the Discrimination Rates
Equal group (DE)DEMO
Stimuli, design and procedure
The training phase and the ﬁrst test DEMO were identical to those of Experiment 1. At the end of the ﬁrst test
block of 128 trials, participants were given relevant deﬁnitions and asked to provide ratings of the cues in
terms of their usefulness, discrimination, validity, and success. Ratings for usefulness, discrimination, and
validity DEMO given by entering numbers between 0 and 100 into text boxes on the screen. Success ratings
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
B. R. Newell et al. Search Strategies 127
were obtained by asking DEMO to imagine that they could only buy one cue before making their choice
and that they should click on the one they most wanted DEMO buy. Once they had clicked on this cue it disap-
peared and a dialogue box appeared telling participants that the cue they had picked DEMO no longer available
and that they should pick the one they next most wanted to buy from the remaining cues. This procedure
continued until DEMO four cues had disappeared. The cue picked ﬁrst was given a rank of 1, the cue picked
second a rank of 2, etc.
DEMO all the ratings had been obtained participants were given one of two ﬁnal test blocks consisting of a
further 64 trials. Participants in the DEMO group were told that they would be given more trials in which the
general nature of the task was the same as on the DEMO trials (i.e., predicting the more proﬁtable share) but
that now DEMO validities of all the cues were equal (they were not told DEMO actual value). Participants in the DE
group were given similar instructions but told that all the discrimination rates of the cues were now DEMO
(they were not told the actual value). On completion of DEMO ﬁnal block, participants were paid their earnings
and debriefed.
RESULTS AND DEMO
The lower half of Table 2 displays the descriptive measures of search order. Consistent with Experiment 1,
most search behavior was classiﬁed as DEMO with any of the three speciﬁed orders. However, for
those that DEMO be classiﬁed, the success ordering was again the most common classiﬁcation. DEMO
restricted to the ﬁrst cue bought most often was more suggestive of the inﬂuence of the successful cues.
Ten participants (42%) purchased cue DEMO ﬁrst, ten (42%) purchased cue B ﬁrst, three (12%) purchased cue
A ﬁrst and one (4%) purchased cue D ﬁrst. DEMO a full 84% of subjects consistently bought one of the two
most successful cues ﬁrst most often.
The second row of Section 3.1 of DEMO 3 displays the frequency with which each cue was purchased
across the 128 test trials. As can be seen from the mean values, the cue-purchase frequency follows the pattern
C ¼ B > D > A. DEMO this pattern is not exactly the same as that predicted by success (C > B > A > D),
a Page test DEMO ordered alternatives indicated a signiﬁcant trend in the order predicted by cues acquired on the
basis of success (zL ¼ 2.58, p ¼ DEMO), but not on the basis of validity or discrimination rate ( ps ¼ 0.433, and
0.074, respectively). The ﬁnding that cue DEMO frequency was related to the order predicted by success
and not by the other two properties of the cues replicates the ﬁnding of Experiment DEMO Planned comparisons
between individual cues revealed that no differences between pairs were signiﬁcant.
Ratings
The last four rows of Section 3.2 of Table 3 DEMO the ratings for all four measures of cue properties. The
order observed for the usefulness rankings (C > B > D > A), although not exactly the same as that predicted
by estimates made on DEMO basis of success (C > B > A > D), DEMO shown by a Page test to manifest a signiﬁ-
cant trend in the order predicted by success (zL ¼ 2.09, p ¼ 0.018), but not in the orders predicted by the
validity or discrimination rate ( ps ¼ 0.230, and 0.352, respectively). Planned comparisons revealed DEMO
none of the differences between individual pairs of ratings were signiﬁcant. The ﬁnding that estimates of
cue usefulness are related to the order predicted DEMO success and not to the other two properties of the cues
is a replication of Experiment 1.
The Page test analyses indicated that participants DEMO differentially sensitive to the validity, discrimina-
tion rate and success of DEMO cues. For each cue property there was a signiﬁcant trend in the order predicted by
that property. However, for two of the three properties (validity and discrimination rate) there was also a
signiﬁcant trend for DEMO order predicted by success. This ‘‘overlap’’ in orderings suggests that participants
found it difﬁcult to dissociate success from validity and discrimination rate. (For brevity only statistical sig-
niﬁcance is reported for these tests—see Section 3.2 of DEMO 3.)
Copyright # 2004 John Wiley & Sons, Ltd. Journal DEMO Behavioral Decision Making, 17, 117–137 (2004)
128
Journal of Behavioral Decision Making
Final test block
We considered adaptation DEMO the new environment by examining cue purchase frequency—a measure that
would be sensitive to changes in search regardless of whether those changes occurred on DEMO, or only some,
trials. Cue-purchase frequency for the ﬁnal test DEMO is shown in the lower two rows of Section 3.1 of Table 3
for Groups VE and DE respectively.
When validities are equal the DEMO cue search is one dictated by the discrimination rate order
C > D > B > A. The observed cue purchase frequency, as indicated in the third row of Section 3.1 of Table
3 was B > C > D > A. Page tests for ordered alternatives indicated a signiﬁcant trend in the order predicted
by the initial (i.e., ﬁrst DEMO block) success of cues (L ¼ 324, zL ¼ 2.40, p ¼ 0.008), a nonsigniﬁcant trend for
the order predicted by DEMO rate (L0.725) (critical¼ 315, zL ¼ 1.50,L p ¼ 0.067) and no trend for the order predicted
by initial validity (DEMO ¼ 294, zL ¼0.06, p ¼ ¼ 317, p ¼ DEMO). (Note that initial orders were
tested to examine whether participants DEMO with strategies adopted in the ﬁrst test block or adapted to the
new orders.) Planned comparisons between individual cues revealed that only the difference between Cue A
and Cue B was signiﬁcant ( p < 0.05, one-tailed), indicating that participants were able to distinguish well
between the DEMO most and least discriminating cues.
When discrimination rates are equal the optimal cue-purchase order is one dictated by the order of valid-
ities A > B > C > D. The observed order, as indicated in DEMO fourth row of Section 3.1 of Table 3 was
C > A > B > D. Page tests indicated a nonsigniﬁcant trend for the DEMO predicted by the validity of cues
(L¼ 315, zL ¼ 1.50, p ¼ 0.067) and no trend for the orders predicted by DEMO discrimination rate
(L Perhaps the most diagnostic result from the ﬁnal DEMO block is the pattern of use for Cue A. Cue A was the¼ 304, zL ¼ 0.4, p ¼ 0.345) or initial success (L¼ 307, zL ¼ 0.7, p ¼ 0.242) (critical L¼ 317, p ¼ 0.05).
most valid and least discriminating cue and these two properties appear to have had a differential inﬂuence on
the DEMO groups. For the DE group, in which the optimal strategy was DEMO buy in order of validities, there was an
increase of almost DEMO in the proportion of trials on which Cue A (the most DEMO cue) was bought in com-
parison to the ﬁrst test block. DEMO contrast, in the VE group in which the optimal strategy was DEMO buy in the order
of discrimination rates, there was an 0.11 DEMO in the amount of trials on which Cue A (the least DEMO
minating cue) was purchased. The difference between the purchase frequency of DEMO A in the VE group
(0.24) and in the DE group (0.54) was signiﬁcant (t(22) ¼ 2.05, p < 0.05, one tailed). This difference indicates
that participants did adapt their cue-purchase behavior in accordance with changes in the environment.
A RATIONAL ANALYSIS OF DEMO STRATEGIES INVOLVING SEARCH
In the introduction, we argued that the order DEMO cues in a sequential search should have regard to both the
validity and discrimination rates of cues. In our experiments, we did ﬁnd that the frequency with which peo-
ple acquired cues matched the order of DEMO success more closely than it matched other orders. To investigate
the rationality of such a search strategy, we present an analysis of one-reason choice strategies that search
through cues in sequence.
We consider three strategies that DEMO in the order in which they search through cues. Take The Best (TTB)
searches cues in descending order of validity. Draw The Discriminator (DTD) searches cues in descending order
of discrimination rate. Select The DEMO (STS) searches cues in descending order of success. These stra-
tegies stop search and make a choice on the basis of the ﬁrst DEMO cue that is found (i.e., they are ‘‘one-
reason’’ decision strategies). In addition, we consider ‘‘families’’ of strategies, derived from each DEMO these three
basic strategies, which stop and guess if no discriminating DEMO is found by a particular point. Strategies that stop
after a maximum of one, two, or three cues, we term ‘‘Truncated #1’’, DEMO #2’’ and ‘‘Truncated #3’’
strategies respectively (cf., Martignon & Hoffrage, DEMO). Such strategies may have value in situations where
cue search is costly. In order to distinguish them from these truncated strategies, we refer to the strategy within
each family that potentially searches all available cues (four cues in our environment) as ‘‘Full’’ strategies.
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
B. R. Newell et al.
Search Strategies
129
Figure 2. Proportion of DEMO bought and proportion correct for participants and for three ‘families’ of decision
strategy.
Note: For each family of strategies (joined by a line), the leftmost point represents the ‘Truncated #1’ strategy. Moving rightwards, the
DEMO #2, #3, and Full strategies are shown. Values for all models are expected values computed from the 128 test trials, whereas
those for participants are actual values observed from those same 128 test trials in DEMO 1 and 2.
For comparison, we also consider the performance of DEMO weighted additive model (WADD) derived using
multiple linear regression on the learning block of 64 trials (but applied to the test phase of 128 trials). The
performance of every model we consider can be DEMO to that achieved if the option pointed to by the
Bayesian calculation is selected.
Figure 2 shows the relationship between frugality and expected accuracy DEMO our experimental environment
for the TTB, DTD and STS families of DEMO (open shapes). For a given level of frugality (proportion of
information bought), Full-STS strategies are the most accurate. The Full-TTB strategy DEMO achieve the high-
est level of accuracy (0.728), but only DEMO more so than the Full-STS strategy (0.697), which is consid-
DEMO more frugal. In order to beat the accuracy of Full-STS by 4.3%, Full-TTB uses 20.7% more
information (both ﬁgures in relative terms). DEMO effort/accuracy trade-off means that the two strategies
would only give equivalent expected earnings were we to raise our reward for a correct choice DEMO 6 to
14.4 times the cost of each cue. Full-TTB selects the option pointed to by the Bayesian calculation on
95% of choices, and is consequently only slightly less accurate. WADD always selects the option pointed
DEMO by the Bayesian calculation, and therefore matches its accuracy (0.736).
Six participants matched or beat the expected accuracy of the Full-TTB strategy, three of these did so
with more frugal strategies.4 Eight participants purchased DEMO information than would be dictated by
the Full-TTB stopping rule (i.e., > 63% of available information). With one (higher performing) exception,DEMO
these participants had much the same levels of accuracy as participants with more frugal strategies (e.g.,
purchasing 50 to 60% of information). Simulations have demonstrated that compensatory strategies such
as WADD only just outperform DEMO more frugal (Full-) TTB strategy in data-ﬁtting, on average (Czerlinski,
Gigerenzer, & Goldstein, 1999). The pattern of performance here DEMO with this ﬁnding. Levels of cue
purchase sufﬁciently high to support some compensatory decision-making did not lead to levels of accuracy
in excess of DEMO achieved by participants with purchase patterns broadly consistent with a more frugal
4Due to the probabilistic nature of the task it is possible for DEMO participants to perform slightly above (or below) the level of
accuracy that is expected given their choices.
Copyright # 2004 John Wiley & DEMO, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
130
Journal of Behavioral Decision Making
Figure 3. Proportion of information bought DEMO earnings for participants and for all models
Note: See note accompanying DEMO 2 for explanation.
one-reason decision strategy. Why this should be so, DEMO be seen from the relatively similar levels of
expected performance for the one-reason and compensatory strategies.
Figure 3 shows the relationship between the proportion DEMO information purchased and the expected earnings
for the three families of strategies. This scatter-plot illustrates the value of the STS family of strategies in DEMO
onments (such as this) where information search is relatively expensive. In terms of earnings, Full-TTB is a
relatively poor strategy in this environment, as its higher level of information purchase reduces expected earn-
ings at a faster rate than its enhanced accuracy increases earnings. Seventy percent of DEMO earned more
than would have been expected had they followed a Full-TTB strategy. They achieved this by adopting stra-
tegies that were more frugal DEMO Full-TTB. In this environment, strategies of buying at most one or DEMO items
of information, or buying randomly until a cue discriminates, all lead to greater frugality and hence higher
earnings than TTB. Consequently, observing that many people earn more than TTB would be uninteresting
were it DEMO for the fact that people do not buy randomly, but are DEMO by the success of cues.
As was the case with purchase orders, there was considerable variation between individuals in the amount
of information purchased. In general, our participants could be described as ‘‘frugal.’’ Eighty-two percent of
them purchased less of the available information than Full-TTB would prescribe, and 59% of them pur-
chased fewer cues than Full-STS would. However, for the ‘‘harsh’’ environment our participants encountered
even this limited information search represented DEMO of (expensive) cues (to their ﬁnancial det-
riment). This DEMO consistent with prior research, where over-purchase is often observed when information DEMO
expensive though under-purchase occurs when it is cheap (Connolly & Gilani, 1982; Connolly & Serre,
1984). We cannot rule out the possibility that non-ﬁnancial considerations inﬂuenced information search
(and perhaps differentially for our participants). If participants value correct responses over and above
earnings, or perceive their task, in part, as gaining knowledge or reducing uncertainty (see Lindley, 1956;
Oaksford & Chater, 1998) it may not be quite so clear-cut that what we observe here is ‘‘gross’’ over DEMO
GENERAL DISCUSSION
In the introduction we argued that search through cues should be sensitive to both the validity and the dis-
crimination rate of DEMO cues. We contended that success-directed search would often be adaptive because
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
B. R. Newell et al.
Search Strategies
131
validity and discrimination rate DEMO frequently negatively correlated. To test the success of ‘‘success’’ we
investigated search strategies when search was costly, decision outcomes could be objectively determined,
and people had to learn an environment in which they had no DEMO hierarchy of the values of different cues.
We set up a straightforward competition between three potential search orders: validity; discrimination rate;
and DEMO Success was the ‘‘winner’’ in both of our experiments.
It is fair to say that a reader looking at Table 2 with its high DEMO of ‘‘incompatible’’ classiﬁcations
might ﬁnd the conclusion that success was the winner rather unconvincing. Clearly, determining the winner
of the competition is dependent on the method used to classify the responses. When the behavior of each
DEMO on each trial is examined and compared with the strict deterministic orders, the ability of any of
the proposed rules to capture the strategies used is rather poor. In contrast, a frequency of purchase measure,
that aggregates across participants and takes into account possible idiosyncrasies resulting from DEMO screen
layout, or the possibility of errors in making selections, reveals search patterns much more akin to one
order—success—than to the other two DEMO orders.
However, even if one accepts that the frequency data provide DEMO evidence for the success of success (as
we do), it DEMO still important to consider possible reasons for the failure of the strict deterministic orders to
capture individual participants’ behavior. A good starting point is DEMO ask whether we need better theories of
how people search in these environments. The three search rules that we considered are deterministic in that
DEMO predict the same order of cue selection on every trial. In contrast to such deterministic rules, Tversky
(1972) proposed a probabilistic search rule for the elimination-by-aspects model of choice (a model that is
closely related to the lexicographic strategies under consideration here). In that model, cues (or ‘‘aspects’’)
are selected with a probability proportional to their weight or importance for the particular choice at a par-
ticular moment in DEMO As Tversky (1972) stated, ‘‘the probabilities merely reﬂect the fact DEMO at different
moments in time different states of mind (leading to DEMO choices) may prevail’’ (p. 296).
It is possible that the momentary salience of a particular cue inﬂuenced search order in our experimental
DEMO For example, on some trials a cue might be selected because DEMO predicted the correct outcome
on the preceding trial (i.e., the search rule used in the ‘‘take-the-last’’ heuristic, Gigerenzer et al., 1999). DEMO
inﬂuence of such probabilistic rules may indeed give rise to the patterns of data we observed—especially if,
as is likely, the momentary salience of particular cues was different for individual participants. Support for
such an DEMO comes from Albert, Aschenbrenner, and Schmalhofer (1989) who proposed that
‘‘probabilistically’’, important cues are processed earlier than less important ones, but DEMO reading habits,
accessibility (recency), salience and availability can also DEMO a role.
An additional explanation of why participants’ search frequencies did not uniformly reﬂect cue success (or
validity, or DR) could simply be that their experience was not uniform. Outcomes were determined prob-
abilistically (in keeping with the nature of the environment) and, therefore, the cue orders according to
success or validity that individual participants observed would sometimes DEMO (as a result of sampling
variability) from those that were programmed. Note that sampling variability of this kind affects cue rank-
ings by DEMO and success, and therefore, does not provide an explanation of why overall search frequen-
cies reﬂected success more so than they did validity. DEMO, observed validity and success are far more
likely to vary from DEMO programmed values in the case of individuals (observing 64 learning trials) than
across the experiment as a whole (with 20  64, DEMO 24  64 learning trials). For this reason, we are DEMO
of reading too much into the variability in search behavior revealed by our individual analysis shown in
Table 2. That said, the possibility that a portion of this variability might reﬂect stable individual differences
(e.g., DEMO for speed over accuracy, or vice versa) is worthy of future investigation.
A related consideration is that the ‘‘deﬁnition’’ or ‘‘precision’’ with which DEMO and success rates can
be learned is a function of the cues’ DRs. By examining Table 1, it can be seen that the most extreme example
is for Cue A because it has the lowest DR. DEMO its DR of 0.22 there are only 14 discriminating trials for Cue
A within a block of 64 trials (64  0.22 ¼ 14.08). Its programmed validity is 0.82, but the closest validity to
this that can be observed is 0.786 (11/14 choices correct) or DEMO (12/14 correct). When cues have low
Copyright # 2004 DEMO Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, DEMO (2004)
132 Journal of Behavioral Decision Making
discrimination rates, quite large numbers of trials may be necessary before validities observed in samples
of choice pairs DEMO fall close to the corresponding validities for the population of all possible choice pairs.
For instance, during 192 learning trials, (three times the sample used in the current experiments) Cue A would
discriminate on 42 trials (192  0.22 ¼ 42.24) allowing validities of 0.810 (34/42 discriminating trials) or
0.833 (35/42) to be observed for Cue A. Observed (sample) validities are most variable when DRs are DEMO
(yielding small numbers of discriminating trials). Readers may therefore wonder DEMO the chances of
observing cue orders that are discordant from those programmed are greater for validity (which is computed
from a subset of trials) than for success (which is computed from all trials). Using DEMO binomial approximation to
estimate the overlap of cue parameter distributions for each cue suggests that this is not the case. The lower
variability in DEMO success is counteracted by the lower dispersion in success rates (as DEMO in Table 1
these rates differ by only 0.02, 0.03, and 0.04 compared with much greater dispersion for cue validities)—
making the DEMO of discriminating cues by success no easier than the task of discriminating cues according to
their validity.
Recent evidence from our laboratory sheds some DEMO on the issue of precision in learning cue properties.
Rakow, Newell, Fayers and Hersby, (2003) employed an equivalent methodology to the current studies, with
similar cue properties, but extended training. Analysis of the DEMO test session (which followed 256 learning
trials spaced across four sessions) indicated that only 15% of trials were incompatible with any of the DEMO
rules, while 43%, 33% and 9% were compatible with validity, DEMO and discrimination rate respectively.
Analysis of the dominant strategies among participants (DEMO, those used on the majority of trials) revealed
ﬁve (out DEMO twelve) adopting validity, four adopting success, one adopting discrimination rate DEMO two using
‘‘incompatible’’ strategies. The picture that emerges from the descriptive measures is that both success and
validity vie for the dominant strategy, but with near equal numbers of participants opting for each one. Ana-
lysis DEMO the frequency of purchase also suggested the persistence of individual variability, DEMO, consistent with
the current experiments, a strong inﬂuence of successful cues. For example, even in the ﬁnal testing session
there were ﬁve distinct rank orders of frequency with which the twelve participants purchased cues. How-
DEMO, for every testing session the most successful cue was the most DEMO bought cue, and, aggregating
across testing sessions, the frequency of DEMO purchase was much more akin to that prescribed by success than
by validity. Furthermore, there was no evidence of dependable relative changes in cues use with increasing
practice (nonsigniﬁcant cue by session interaction, (F(9, 99) ¼ 0.73, p ¼ 0.677). This evidence suggests that
individual differences in cue purchase persist even with extensive training.
However, one key aspect of the design—speciﬁcally the cost of information—makes detailed compari-
sons DEMO the data sets problematic. Simply put, when information was very expensive—as DEMO was in one
of the conditions of the experiment in Rakow et al. (2003)—search was curtailed and therefore participants’
strategies were more likely to be compatible with one of the search orders. This in turn DEMO the over-all
proportion of incompatible classiﬁcations. Hence there are interactions between length of training and cost
of information, which make it difﬁcult to draw strong conclusions about the isolated effect of increased num-
bers of trials.
DEMO these considerations of sampling variability and the limits on precision, it DEMO in many ways all
the more remarkable that the present experiments demonstrated the appropriate learning of validities and
success rates. It is likely that DEMO beneﬁted from the summary feedback (the probability that they
chose the DEMO proﬁtable share), which was not subject to such variability or imprecision. Nonetheless,
we feel that our participants’ performance in the far from DEMO task of learning validity, DR, and success
can be seen as an example of successful intuitive statistics on their part. Here we consider DEMO classes of
explanation for how people are able to achieve such success.
Learning the cue hierarchy
Gigerenzer et al. (1991) proposed that people DEMO learn validities by logging the frequency of correct
responses within a given reference class of events. This ability is a central feature of the DEMO Mental
Copyright # 2004 John Wiley & Sons, Ltd. Journal of DEMO Decision Making, 17, 117–137 (2004)
B. R. Newell et al.
Search Strategies
133
Model (PMM) of DEMO judgment (Gigerenzer et al., 1991), and of TTB (Gigerenzer & Goldstein,
1999). However, in order to determine the validity DEMO a cue, the required reference class of events is the sub-
DEMO of occasions on which the cue discriminates. For every cue, this DEMO a different subset of events. In envir-
onments where cues have differing discrimination rates, each reference class (for each cue) will be of a
different size. This strikes us as a difﬁcult task—to construct separate DEMO classes, of different size,
and establish a hierarchy of validity DEMO on differing frequencies of correct inferences. This difﬁculty is
most acute in cases where cue discrimination rates and validities are inversely related. In such DEMO, accurate
learning of validities requires that people assess a cue that DEMO to a smaller number of correct inferences as
more valid than one leading to a greater number of correct inferences. In other words, establishing a correct
hierarchy of validities requires learning a series of relative frequencies, it cannot be done by logging frequen-
cies alone. Participants’ difﬁculty in DEMO success and validity in the second experiment may reﬂect
precisely these problems.
In contrast, learning the success rates of cues strikes us as a far more robust process. The reference class is
the same for all DEMO, and is the full set of observed events rather than a DEMO of events. The proportion of
correct inferences when only that cue is used (i.e., success) is, in principle, directly observable. As all cues
have the same reference class, logging frequencies is sufﬁcient to establish a hierarchy of cues by success.
Further to this, we noted that, for the environment we considered, the order of the unstandardized regres-
DEMO weights for the WADD model derived using MLR followed the order of validity, whereas the order of
the standardized regression weights (s) followed that of success. It is known that an interesting class of
connectionist DEMO layer networks employing the delta rule—asymptotically compute weights
equivalent to unstandardized regression weights (Stone, 1986). This suggests that such networks, which are
known to capture many important aspects of human learning (McClelland & Rumelhart, 1985), do so by
learning about cue validity rather than success. Our results and rational analysis suggest that learning about
success would be DEMO adaptive. The success ordering of the s might also be taken to imply further support
for the notion that the informativeness of cues is DEMO reﬂected by success than by validity alone.
Strategic advantages of success-based search
There is an eminent tradition within psychology proposing that behavior should be DEMO as adaptation
to the environment, and therefore modeling behavior requires understanding DEMO environment (Tolman &
Brunswik, 1935; Simon, 1956; Gibson, DEMO; Anderson, 1990; Gigerenzer & Todd, 1999). Guided by this
approach, we consider under what conditions success-based search is better than validity-based search, by
examining two one-reason strategies that adopt these orders (STS DEMO TTB).
The TTB strategy is more accurate than STS in our environment, and we suspect that this would be the
case in all environments. However, the advantage is small (3% in absolute terms), DEMO similar to the advan-
tage that Martignon and Hoffrage (1999) report for the German cities environment (2%). Nonetheless, if
accuracy is DEMO sole consideration, there is no doubt that TTB is the better DEMO the two strategies. However,
there are many situations where aspects other than accuracy come into play.
We have illustrated that, when there is some cost to search, the more frugal the strategy the better. STS is
more frugal than TTB (because discrimination rates play some part in the selection of cues), yet is so without
severely damaging accuracy (because success partially reﬂects validity). If we concur that there is DEMO
some cost to search (Fried & Peterson, 1969), it follows that situations where information is sufﬁciently
cheap to favor TTB are relatively DEMO In addition, if time and information are sufﬁciently inexpensive to
favor DEMO less frugal TTB, it may be more appropriate to use a DEMO strategy (which is even less
frugal). Czerlinski, Gigerenzer, Goldstein (1999) report that the advantage of WADD over TTB in ﬁtting
data is small (approximately 2% higher accuracy over 20 environments). Though small, this advantage is
similar to the accuracy advantage we noted for TTB over STS. Thus, it is precisely those situations where
low information costs favor TTB over STS, where an information-heavy compensatory strategy may be
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
134
Journal of Behavioral Decision Making
preferable to TTB. Of course, with a compensatory strategy one also needs to consider the additional cost or
DEMO of computing the solution (Payne, Bettman, & Johnson, 1993). Notwithstanding, when the cost of
search is taken into account, it DEMO unclear whether there are many environments where TTB is preferable
to the more frugal (though less accurate) STS, and preferable to the typically more accurate (though more
effortful) compensatory strategies. Indeed, empirical evidence demonstrates that people often depart from
the TTB stopping rule by purchasing additional DEMO when information costs are low (Bro¨ der, 2000; Newell
& DEMO, 2003).
In addition to the cost of information search, there may also be constraints upon the length of search. Time
pressure may DEMO such that there is a maximum length for any one search, DEMO for the average length of search.
Competitive choice situations may be such that, the longer you search the more likely it is that one choice
option will disappear (because someone else has chosen it ﬁrst). In these situations, search can be truncated
before a discriminating cue is found. This acts as a disincentive for strategies with greater search lengths:DEMO
either the maximum search length is reached, forcing a guess; or the choice set is smaller by the time a deci-
sion is DEMO Our rational analysis shows why STS is preferable to TTB in such situations. If lower levels of
frugality are required, the STS family of strategies is more accurate. Only when it is permissible to undertake
a DEMO search is the accuracy of TTB greater. STS is more likely to reach a quick decision, and therefore
less likely to lose a race to select an option.5
A corollary follows in that we may not DEMO know exactly how long we have to make a decision. This
uncertainty about the decision situation also works against TTB. We can be conﬁdent DEMO TTB will be a
more accurate strategy than STS only if we know that time permits an exhaustive (or near exhaustive) search
through DEMO available information. Otherwise, the possibility of truncating search (due to some external con-
straint) risks lowering the accuracy of TTB (due to DEMO guessing.)
The ecological rationality of success-based search
Gigerenzer and colleagues suggest that heuristics develop to exploit the structure of environments, and have
demonstrated that there is a class of environments where a one-reason heuristic that DEMO according to
cue validity (TTB) is surprisingly accurate (Czerlinski et DEMO, 1999). However, our analyses suggest that when
the costs of search are considered, success-based search is likely to exploit these environments more effec-
tively. In addition, we argue that learning a success-based cue hierarchy is more robust than learning a hier-
archy of validities. Thus, it is hard for us to see how, and why, people might DEMO and use validity-based
search strategies when both validities and discrimination rates vary. Importantly, the behavior of participants
in our experiments accords with this reasoning.
We acknowledge that an empirical question remains as to whether the costs DEMO search in external environ-
ments as we have characterized them (i.e., explicit monetary costs for uncovering information on a computer
screen) are synonymous with the ‘‘cognitive costs’’ of accessing information in memory. Validity-based
search may DEMO prove to be a better description of what occurs in memory. We hope that new techniques
for investigating the use of heuristics in memory-based DEMO (cf., Bro¨ der & Schiffer, 2003a; 2003b) will help
DEMO answer this question.
Our focus in the rational analysis was on the use of one-reason heuristics in order to demonstrate that the
validity search DEMO employed by one member of the ‘‘adaptive toolbox’’ (TTB) could be bettered by a dif-
ferent search rule (success) in our environment. DEMO, our principal ﬁnding regarding the importance of
success for determining the DEMO search through information is equally applicable to a general evidence
5We note that, in general, TTB can appropriately be described as a frugal DEMO In their analysis of 20 environments, Czerlinski,
Gigerenzer, & Goldstein (1999) found that TTB used 31% of available information. The point DEMO is that STS is more frugal than TTB,
and this does confer beneﬁts.
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (2004)
B. R. Newell et al.
Search Strategies
135
accumulation model of forced-choice DEMO making, of the kind alluded to in the introduction and dis-
DEMO in more detail in Lee and Cummins (2004) and in our previous work (Newell & Shanks, 2003; Newell
et al., 2003)DEMO Such a model requires a mechanism for search and we argue that using the success of cues
provides a good candidate.
ACKNOWLEDGEMENTS
The ﬁrst DEMO second authors contributed equally to this project and order of authorship was determined arbi-
trarily. The support of the Economic and Social Research Council (ESRC) and The Leverhulme Trust is
gratefully acknowledged. The work was part of the programme of the ESRC Centre for Economic Learning
and Social DEMO, University College London.
REFERENCES
Abernathy, C. M., & Hamm, R. M. (1994). Surgical scripts: Master surgeons think aloud about 43 DEMO surgical
problems. Philadelphia: Hanley & Belfus.
Albert, D., Aschenbrenner, K. M., & Schmalhofer, F. (1989). Cognitive choice processes and the attitude–behavior
relation. In A. Upmeyer (Ed.), Attitudes and behavioral decisions. New York: Springer.
Anderson, J. R. (1990). The adaptive character of thought. Hillsdale, NJ: Lawrence Erlbaum Associates.
Bro¨ der, A. (2000)DEMO Assessing the empirical validity of the ‘‘Take-The-Best’’ heuristic as a model of human probabilistic
inference. Journal of Experimental Psychology: Learning, Memory, and Cognition, 26, 1332–1346.
Bro¨ der, A. (2003). Decision making with DEMO adaptive toolbox: Inﬂuence of environmental structure, personality,
intelligence, and DEMO memory load. Journal of Experimental Psychology: Learning, Memory, and Cognition, 29,
611–625.
Bro¨ der, A., & Schiffer, S. (2003a)DEMO Bayesian strategy assessment in multi-attribute decision-making. Journal of
Behavioral Decision Making, DEMO, 193–213.
Bro¨ der, A., & Schiffer, S. (2003b). DEMO versus simultaneous feature matching: Probabilistic inferences from
memory and effects of DEMO format. Journal of Experimental Psychology: General, 172, 277–293.
Castellan, N. J. (1974). The effect of different types of feedback in multiple-cue probability learning. Organizational
Behavior and Human Performance, 11, 44–64.
Castellan, N. J., & Edgell, S. E. (1973). An hypothesis generation model for judgment in nonmetric multiple-cue
probability learning. Journal of Mathematical Psychology, 10, 204–222.
Choussat, A., Fontan, F., Besse, P., Vollot, DEMO, Chauve, A., & Bricaud, H. (1978). Selection criteria DEMO Fontan’s procedure.
In R. H. Anderson, & E. Shinebourne (Eds.), Paediatric Cardiology (pp. 559–566). Edinburgh: Churchill Livingstone.
Connolly, T., & Gilani, N. (1982). Information search in judgment tasks: A DEMO model and some preliminary
ﬁndings. Organizational Behavior and Human Decision Processes, DEMO, 330–350.
Connolly, T., & Serre, P. (1984). Information DEMO in judgment tasks: The effects of unequal validity and cost.
Organizational DEMO and Human Performance, 34, 387–401.
Connolly, T., & Thorn, DEMO K. (1987). Predecisional information acquisition: Effects of task variables on suboptimal
search strategies. Organizational Behavior and Human Decision Processes, 39, 397–416.
DEMO, J., Gigerenzer, G., & Goldstein, D. G. (1999). How good are simple heuristics? In G. Gigerenzer, P. M. Todd,DEMO
& The ABC Research Group (Eds.), Simple heuristics that make DEMO smart (pp. 97–118). New York: Oxford University
Press.
Edwards, DEMO (1965). Optimal strategies for seeking information. Journal of Mathematical Psychology, 2, 312–329.
Einhorn, H. J., & Hogarth, R. M. (1981). Behavioral decision theory: Processes of judgment and choice. Annual Review
of Psychology, 32, 53–88.
Einhorn, H. J., Kleinmuntz, D. N., & Kleinmuntz, B. (1979). Linear regression and process-tracing models of judgment.
Psychological Review, 86, 465–485.
Fishburn, P. C. (1974). Lexicographic DEMO, utilities and decision rules. Management Science, 20, 1442–1471.
Fried, L. S., & Peterson, C. R. (1969). Information seeking: Optional DEMO ﬁxed stopping. Journal of Experimental
Psychology, 80, 525–529.
Gibson, J. DEMO (1979). The ecological approach to visual perception. Boston, MA: DEMO Mifﬂin.
Gigerenzer, G. (2001). The adaptive toolbox. In G. Gigerenzer, & R. Selten (Eds.), Bounded rationality: The adaptive
toolbox (DEMO 37–51). Cambridge, Mass: MIT Press.
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (DEMO)
136 Journal of Behavioral Decision Making
Gigerenzer, G., & Goldstein, D. G. (1996). Reasoning the fast and frugal way: Models of DEMO rationality.
Psychological Review, 103, 650–669.
Gigerenzer, G., & Goldstein, DEMO G. (1999). Betting on one good reason: The take the best heuristic. In G. Gigerenzer,
P. M. Todd, & The ABC Research Group (Eds.), Simple heuristics that make us smart (pp. DEMO). Oxford: Oxford
University Press.
conﬁdence. Psychological Review, 98, 506–528.
DEMO, G., & Todd, P. M. (1999). Fast and frugal heuristics: The adaptive toolbox. In G. Gigerenzer, P. M. Todd, &DEMO
The ABC Research Group (Eds.), Simple Heuristics that Make us DEMO (pp. 3–34). Oxford: Oxford University Press.
Gigerenzer, G., Todd, P. M., & The ABC Research Group (Eds.) (1999). Simple heuristics that make us smart. Oxford:
Oxford University Press.
Hasher, L., & Zacks, R. T. (1984). Automatic processing of fundamental information. American Psychologist, 39, 1327–1388.
Hastie, R., & Dawes, R. M. (2001). Rational choice in an uncertain world. Thousand Oaks, DEMO: Sage.
Hershman, R. L., & Levine, J. R. (1970)DEMO Deviations from optimal purchase strategies in human decision making.
Organizational Behavior and Human Performance, 5, 313–329.
Hogarth, R. M., & Einhorn, H. J. (1992). Order effects in belief updating: The belief adjustment DEMO Cognitive
Psychology, 24, 1–55.
Jones, S., Juslin, P., Olsson, H., & Winman, A. (2000). Algorithm, heuristic or exemplar: Process and representation in
multiple-cue judgment. In L. R. Gleitman, & DEMO K. Joshi (Eds.), Proceedings of the 22nd Annual Conference of DEMO
Cognitive Science Society (pp. 244–249). Hillsdale, NJ: Lawrence Erlbaum.
DEMO, P., Olsson, H., & Olsson, A -C. (2003). Exemplar effects in categorization and multiple-cue judgment. Journal of
Experimental Psychology: General, 132, 133–156.
Kaplan, R. J., & Newman, J. R. (DEMO). Studies in probabilistic information processing. IEEE Transactions on Human
Factors in Electronics, HFE-7, 49–63.
Lanzetta, J. T., & Kanareff, V. T. (1962). Information cost, amount of payoff, and level of aspiration as determinants of
information seeking in decision making. Behavioral Science, 7, DEMO
Lee, M. D., & Cummins, T. D. R. (2004). Evidence accumulation in decision making: Unifying ‘‘take the best’’ and
‘‘rational’’ models. Psychonomic Bulletin & Review, in press.
Lindley, D. V. (1956). On a measure of the information provided by an experiment. Annals of DEMO Statistics,
27, 986–1005.
Marschak, J. (1954). Towards an DEMO theory of organization and information. In R. M. Thrall, C. H. DEMO, &
R. L. Davis (Eds.), Decision processes (pp. 187–220). New York: Wiley.
Martignon, L., & Hoffrage, U. (1999). Why does one-reason decision making work? A case study in ecological
rationality. In G. Gigerenzer, P. M. Todd, & The ABC Research DEMO (Eds.), Simple heuristics that make us smart
(pp. 119–140). New York: Oxford University Press.
McClelland, J. L., & Rumelhart, DEMO E. (1985). Distributed memory and the representation of general and DEMO
information. Journal of Experimental Psychology: General, 114, 159–188.
Newell, B. R., & Shanks, D. R. (2003). Take-the-best or look at the rest? Factors inﬂuencing ‘‘one-reason’’ decision
making. Journal of Experimental Psychology: DEMO, Memory, and Cognition, 29, 53–65.
Newell, B. R., Weston, N. J., & Shanks, D. R. (2003). Empirical tests DEMO a fast and frugal heuristic: not everyone ‘‘takes-
the-best’’. Organizational Behavior DEMO Human Decision Processes, 91, 82–96.
Nosofsky, R. M., Palmeri, DEMO J., & McKinley, S. C. (1994). Rule plus exception DEMO of classiﬁcation learning.
Psychological Review, 101, 53–79.
Oaksford, M., & Chater, N. (1998). Rationality in an uncertain world: Essays on the cognitive science of human
reasoning. Hove, UK: Psychology Press.
Payne, J. W. (1982). Contingent decision behavior. Psychological Bulletin, 92, 382–402.
Payne, J. W., Bettman, J. R., & Johnson, E. J. (1993). The adaptive decision maker. Cambridge, UK: Cambridge
University Press.
Pitz, G. F. (1968). Information seeking when available information is DEMO Journal of Experimental Psychology, 76,
25–34.
Plott, C. R., & Levine, M. E. (1978). A model of agenda inﬂuence on committee decision. American Economic Review,
68, 146–160.
Pruitt, D. G. (1961). Informational requirements in decision making. American Journal of Psychology, 74, 433–439.
Rakow, T., Hinvest, N., Jackson, E., & Palmer, M. (2004). Simple heuristics from the adaptive toolbox: Can we perform
the requisite learning? Thinking & Reasoning, in press.
Rakow, T., Newell, B. R., Fayers, K., & Hersby, M. (2003). Information search with variable cost, time pressure and
uncertainty. Manuscript in preparation.
Copyright # 2004 John Wiley & Sons, Ltd. Journal of Behavioral Decision Making, 17, 117–137 (2004)
Gigerenzer, G., Hoffrage, DEMO, & Kleinbo¨
lting, H. (1991). Probabilistic mental models: A Brunswikian theory of
B. R. Newell et al. Search Strategies 137
Rieskamp, J., & DEMO, U. (1999). When do people use simple heuristics and how can we tell? In G. Gigerenzer, P. M.
Todd, & The ABC Research Group (Eds.), Simple heuristics that make us smart (DEMO 141–167). Oxford: Oxford
University Press.
Russo, J. E., & DEMO, L. D. (1975). An eye movement analysis of multi-alternative choice. Memory and Cognition, 3,
267–276.
Russo, J. E. (1977). The value of unit price information. Journal of Marketing Research, 14, DEMO
Siegel, S., & Castellan, N. J. (1988). Nonparametric statistics for the behavioral sciences (2nd ed.). New York: McGraw-
Hill.
DEMO, H. A. (1956). Rational choice and the structure of environments. Psychological Review, 63, 129–138.
Smith, J. D., & Minda, J. P. (2000). Thirty categorization results in search of a model. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 26, 3–27.
Stigler, G. J. (1961). The economics of information. The Journal of DEMO Economy, 69(3), 213–225.
Stone, G. O. (1986). DEMO analysis of the delta rule and the learning of statistical associations. In D. E. Rumelhart, J. L.
McClelland, & The PDP Research Group (Eds.), Parallel distributed processing: Explorations of the microstructure of
cognition. (DEMO 1: Foundations, pp. 444–459). Cambridge: MIT Press.
Tolman, E. C., & Brunswik, E. (1935). The organism and the causal texture of the environment. Psychological Review,
42, 43–77.
Tversky, A. (1972). Elimination by aspects: A theory of choice. Psychological Review, DEMO, 281–299.
Tversky, A., & Edwards, W. (1966). Information DEMO reward in binary choices. Journal of Experimental Psychology,
71, 680–683.
DEMO Wallendael, L. R., & Guignard, Y. (1992). Diagnosticity, DEMO, and the need for information. Journal of
Behavioral Decision Making, 5, 25–37.
Wendt, D. (1969). Value of information for decisions. Journal of Mathematical Psychology, 6, 430–443.
Authors’ biographies:
Ben Newell (PhD 2001, University of New South Wales) is a Lecturer in Cognitive DEMO at the University of New
South Wales and a Research Fellow of the ESRC Centre for Economic Learning and Social Evolution. His interests
include DEMO heuristics and the implicit/explicit distinction in human learning and judgment.
Tim Rakow (PhD 2001, University College London) is a Teaching Fellow in Psychology at the University of Essex. His
research interests include probability elicitation, risk assessment and decision making in medicine, information search,
and inter-temporal choice.
Nicola J. Weston is a PhD student at the University of DEMO She was a research assistant at University College
London where she completed this work. Her research interests include decision making, face recognition and eyewitness
memory.
DavidShanks (PhD 1985, University of Cambridge) is Professor of Psychology and Head of the Psychology Department
at University College London, and Scientiﬁc Director of the ESRC Centre for Economic Learning and Social Evolution.
His DEMO interests include human learning, computational modelling (especially with neural network models), and
decision making.
Authors’ addresses:
Ben R.Newell, NicolaJ.Weston and DavidR.Shanks, Department of Psychology, University College London, Gower
Street, London WC1E DEMO, UK.
Tim Rakow, Department of Psychology, University of Essex, Wivenhoe Park, Colchester, Essex CO4 3SQ, UK.
Copyright # 2004 John Wiley & Sons, Ltd.
Journal of Behavioral Decision Making, 17, 117–137 (DEMO){1g42fwefx}