Published in: Swiss Journal of Economics and Statistics, 133 (2/2), 1997, 201‚Äì218.
¬© 1997 Peter Lang, 0303-9692.
Bounded Rationality: Models of Fast and Frugal Inference
Gerd Gigerenzer1
Max Planck Institute for Psychological DEMO, Munich, Germany
Humans and other animals need to make inferences about their environment under constraints of
limited time, knowledge, and computational capacities. DEMO, most theories of inductive infer-
ences model the human mind as DEMO supercomputer like a Laplacean demon, equipped with unlim-
ited time, knowledge, and computational capacities. In this article I review models of fast and
frugal inference, that is, satisÔ¨Å cing strategies whose task is to DEMO unknown states of the world
(without relying on computationaly expensive procedures DEMO as multiple regression). Fast and
frugal inference is a form of bounded rationality (Simon, 1982). I begin by explaining what
bounded DEMO in human inference is not.
1. Bounded Rationality is Not Irrationality
In his chapter in John Kagel and Alvin Roth‚Äôs Handbook of Experimental Economics (1995), Colin
Camerer explains that ‚Äúmost research on individual decision making DEMO taken normative theo-
ries of judgment and choice (typically probability rules DEMO utility theories) as null hypotheses
about behavior,‚Äù and has labeled DEMO deviations from these norms ‚Äúcognitive illusions‚Äù (p.
588). Camerer continues, ‚ÄúThe most fruitful, popular alternative theories spring from the idea
that limits on computational ability force people to use simpliÔ¨Å ed procedures or ‚Äòheuristics‚Äô DEMO
cause systematic mistakes (biases) in problem solving, judgment, and choice. The roots of this
approach are in Simon‚Äôs (1955) distinction between DEMO rationality (the result of norma-
tive maximizing models) and procedural rationality.‚Äù (p. 588) In the preface to their anthol-
ogy, Daniel Kahneman, Paul Slovic, and Amos Tversky (1982) relate their heuristics-and-biases
program DEMO ‚ÄúSimon‚Äôs treatment of heuristics of reasoning and of bounded rationality‚Äù (p. DEMO).
Richard Thaler (1991) explains that Kahneman and Tversky have shown that ‚Äúmental illusions
should be considered the rule rather than the exception. DEMO, predictable differences be-
tween normative models of behavior and actual behavior DEMO because of what Herbert Simson
[sic!] (1957, p. 198) called DEMO rationality‚Äô.‚Äù (p. 4)
My Ô¨Å rst point is to disentangle DEMO confusion between bounded rationality (or procedural
rationality) and irrationality inherent in these statements‚Äîa confusion which has been repeated
many times (e.g., Oaksford & Chater, 1992; see Lopes, 1992). I use the term DEMO as a
shorthand for the various ‚Äúerrors‚Äù and ‚Äúfallacies‚Äù in statistical and probabilistic judgment which
Camerer lists, such as the conjunction fallacy, the DEMO rate fallacy, and the overconÔ¨Å dence bias.
In each of these DEMO demonstrations of irrationality, the assumption is made that it is crystal-
DEMO I am grateful for comments on earlier versions of this paper by Bernhard Borges, Ralph Hertwig, Ulrich
Hoffrage, Timothy Ketelaar, and Laura DEMO
GG_Boun_1997.indd 1
17.04.2007 8:04:27 Uhr
2
Bounded Rationality: Models of Fast and Frugal Inference
clear what the correct judgment is. Sound reasoning is reduced to applying a simple rule DEMO as
the conjunction rule or Bayes‚Äô rule, without even looking at DEMO content and context of the task
(Gigerenzer, 1996a; Gigerenzer & DEMO, 1987). Systematic deviations of human judgment
from these norms (the ‚Äúnull hypotheses‚Äù) are called ‚Äúbiases‚Äù or ‚Äúerrors‚Äù and attributed to crude
‚Äúheuristics‚Äù‚Äîrepresentativeness, availability, and anchoring. What do these ‚Äúheuristics and  biases‚Äù
have to do with bounded rationality?
To start with, most of the heuristics and biases in statistical and probabilistic judgment that
Camerer lists stem from DEMO anthology by Kahneman et al. (1982), in which, as mentioned
before, the link to bounded rationality is made in the preface. This anthology contains all of
Tversky and Kahneman‚Äôs major papers since the early DEMO, none of which has a single citation
to Simon. Given the DEMO care that Tversky and Kahneman take in crediting others, it is DEMO
likely that their research actually had its roots in Simon‚Äôs concept of bounded rationality (Lopes,
1992). This leaves us with the possibility that there is, nevertheless, a deep link between the two
programs DEMO has just gone unnoticed for a decade or so. So let us examine how the heuristics
and biases actually relate to bounded rationality.
For DEMO we need some criteria for bounded rationality. To Ô¨Å nd speciÔ¨Å c criteria turns out to be
harder than it seems: initially, the DEMO of bounded rationality was only vaguely deÔ¨Å ned, and
one could DEMO t a lot of things into it by foresight and hindsight‚Äù (DEMO, 1992, p. 18). I introduce
four general requirements (rather DEMO speciÔ¨Å c ones such as explicit stopping rules, see below),
two related to each ‚Äúblade‚Äù of the ‚Äúscissors‚Äù that shape bounded rationality: ‚Äúthe structure of task
environments and the computational capabilities of the actor‚Äù (Simon, 1990, p. 7).
(1) The task is too DEMO to compute an exact solution. In Simon‚Äôs (1979) words, ‚ÄúSatisÔ¨Å DEMO [is]
aiming at the good when the best is incalculable‚Äù (p. DEMO). To use one of his favorite examples,
‚ÄúIf the game of chess, limited to its 64 squares and six kinds of pieces, is beyond exact com-
putation, then we may expect the same DEMO almost any real-world problem ‚Ä¶‚Äù (Simon, 1990,
p. 6). There are two readings of the term ‚Äúincalculable.‚Äù First, the task is too hard for the
computational power humankind has available today, in minds and machines, such as in the
case of chess. Second, the DEMO is too hard for the limited computational resources the average
mind has available.
(2) The task environment needs to be studied. The moral DEMO Simon‚Äôs two-bladed scissors analogy
is ‚Äúthat one must consider both the task environment and the limits upon the adaptive pow-
ers of the system‚Äù (Simon, 1991, p. 36).
(3) Limited cognitive resources. A DEMO has to make an inference under limited time, limited
knowledge, limited computational capacities, and limited resources for obtaining further
information. These resources are insufÔ¨Å cient to compute the exact solution.
(4) A satisÔ¨Å cing DEMO is speciÔ¨Å ed. This condition requires some precisely formulated strategy,
which is proposed as a model of bounded rationality. This satisÔ¨Å cing strategy DEMO a
judgment or decision from the analysis of the task environment.
Do ‚Äúheuristics and biases‚Äù satisfy these four general requirements? Consider Ô¨Å rst a concrete ex-
ample, one of the most celebrated cognitive illusions: the DEMO fallacy‚Äù in the Linda
problem. Imagine you are a participant in an experiment; in front of you is a text problem and
you begin to read (Tversky & Kahneman, 1983):
Linda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a
student, she was deeply concerned with issues of discrimination and social justice, and also par-
ticipated in anti-nuclear demonstrations. Which is more probable:
(a) Linda is a bank teller,
(b) Linda DEMO a bank teller and active in the feminist movement.
GG_Boun_1997.indd 2
17.04.2007 8:04:28 Uhr
Gerd Gigerenzer 3
Assume you chose (b), just as some 80%‚Äì90% of the participants in previous experiments did.
Tversky & Kahneman (1983) DEMO that this judgment is a reasoning fallacy, because it violates
the DEMO rule:
p(A‚à©B) ‚â§ p(A), and p(A‚à©B) ‚â§ p(B).
GG_Boun_1997.indd 3
In words, the probability of the conjunction of two events A and B cannot be larger than the
DEMO of either of the two events. This alleged demonstration of human irrationality has
been widely accepted and publicized. Stephen J. Gould (1992) puts DEMO message clearly:  ‚ÄúTversky
& Kahneman argue, correctly I think, that our minds are not built (for whatever reason) to
work by DEMO rules of probability.‚Äù (p. 469) The conjunction fallacy has been suggested as a cause
of many human misfortunes and disasters, such as US security policy (Kanwisher, 1989) and
people‚Äôs assessment of the chance of nuclear reactor failures (Stich, 1985). Let us now see what
DEMO alleged demonstration of human irrationality has to do with bounded rationality.
(DEMO) Is the task too hard? No. Different from chess and real-world situations, one does not even
need a pocket calculator to compute (DEMO is considered to be) the ‚Äúcorrect‚Äù solution to the
Linda problem.
(2) Is the task environment studied? No. No analysis of the DEMO is needed for the ‚Äúcorrect‚Äù
solution. One does not even need to read the description of Linda. Tversky and Kahneman
(1983) assume that DEMO that matters for sound reasoning is to map the term ‚Äúprobable‚Äù into
mathematical probability, and the term ‚Äúand‚Äù into logical AND. That‚Äôs all that is needed for
the conjunction rule. The norm is content-blind, therefore the environment does not matter
(Gigerenzer, 1996a). Any knowledge, such as about bank tellers and feminists, is considered
irrelevant for sound reasoning. As a consequence, the participants‚Äô assumptions about what
the experimenter wants them to do are not analyzed either.
(3) Do limited cognitive resources apply? Limited cognitive resources are not an issue in the Linda
problem. For DEMO nding the ‚Äúcorrect‚Äù solution, absolutely no knowledge about the environment
is DEMO and no resources for obtaining further information are required; thus the DEMO of
limited knowledge does not apply. Similarly, little if any computational DEMO are needed,
and time constraints or information costs are of no relevance.
(4) Is a satisÔ¨Å cing strategy speciÔ¨Å ed? The standard explanation for the ‚Äúconjunction fallacy‚Äù is that
people do not reason according DEMO the laws of probability, but use a heuristic called ‚Äúrepre-
sentativeness‚Äù: The description of Linda is more representative of a feminist bank teller DEMO
of a bank teller. The term ‚Äúrepresentative‚Äù seems to mean ‚Äúsimilar.‚Äù But which of the many
different strategies for computing similarity is meant by DEMO word? The strategy for comput-
ing representativeness has not yet been DEMO ed.
I conclude that the conjunction fallacy and its proposed explanation, DEMO representativeness heu-
ristic, satisfy none of these four general criteria of DEMO rationality. This result holds more
generally for the ‚Äúheuristics and biases‚Äù in statistical and probabilistic reasoning (though occa-
sionally one of the criteria may be satisÔ¨Å ed). First, what is considered to be the ‚Äúcorrect‚Äù solution
can almost always be computed with a few keystrokes on a DEMO calculator (overconÔ¨Å dence
bias is one exception). Second, the norms are content-blind, therefore any analysis of the task
environment is assumed to be unnecessary in the Ô¨Å rst place. Third, for the same reason‚Äîcon-
tent-blind norms‚Äîknowledge and information search play little if any role, and nor do limits of
memory and attention. Fourth, none of the three heuristics proposed in the early 1970s‚Äîrep-
resentativeness, availability, and anchoring‚Äîhas ever been DEMO into a precise model. They
have remained one-word explanations with the virtue of Rorschach inkblots. Every researcher
can read into them what he or DEMO wishes. The reluctance to specify precise and falsiÔ¨Å able pro-
17.04.2007 8:04:28 Uhr
4
Bounded Rationality: Models of Fast and Frugal Inference
cess models, DEMO clarify the antecedent conditions that elicit various heuristics, and to work DEMO
the relationship between heuristics has been repeatedly pointed out (e.g., Einhorn & Hogarth,
1981; Lopes, 1991; Shanteau, 1989; Wallsten, DEMO). However, Kahneman and Tversky (1996,
p. 585) still DEMO to defend undeÔ¨Å ned ‚Äúheuristics‚Äù in reaction to critique (see Gigerenzer,DEMO
1993, 1994, 1996a). Thus, by all four criteria, the heuristics-and-biases program has little to do
with models of bounded rationality.
However, one could argue that at least the Ô¨Å rst criterion holds in DEMO weak version, which
says that the solution is incalculable for the DEMO person. Even if the task does not look dif-
Ô¨Å cult, DEMO is so for human minds, so the argument goes. And this DEMO allegedly holds fairly stable
across variations, as we learn from Camerer (1995). But this picture is misleading; it ignores the
recent demonstrations of how to make the conjunction fallacy largely disappear (Fiedler, 1988;DEMO
Gigerenzer, 1991; Hertwig & Gigerenzer, 1996). Consider the simple DEMO that the term ‚Äúprob-
able,‚Äù attached to a single event (DEMO as that Linda is a bank teller), has several legitimate mean-
ings besides mathematical probability. Some examples are ‚Äúplausible,‚Äù ‚Äúcredible‚Äù as in DEMO credible
story,‚Äù and ‚Äúthat may in view of present evidence be reasonably expected to happen,‚Äù (see e.g.,
the Oxford English Dictionary). Similarly, statisticians of the frequentist school would not ac-
cept that single-event ‚Äúprobabilities‚Äù as in the Linda problem have anything to do with DEMO math-
ematical theory of probability (Gigerenzer, 1994). Thus, for DEMO psychological and statistical
reasons, an adequate test of the human capacity DEMO reason according to the conjunction rule is
to state the problem in frequencies rather than in ambiguous single-event probabilities. Ralph
Hertwig and I have DEMO the Linda problem in terms of frequencies (Hertwig & Gigerenzer,
DEMO). Everything was left constant except that we replaced the ambiguous phrase ‚ÄúWhich is
more probable?‚Äù by a frequency judgment: ‚ÄúThere are 100 women like Linda. How many of
them are (a) bank tellers, (b) bank tellers and active in the feminist movement?‚Äù In DEMO series of
experiments, conjunction violations dropped from almost 90% in the DEMO probability ver-
sion to as low as 0% in the frequency version. Fiedler (1988) had earlier shown similar results:
Violations of the DEMO rule dropped from 80% to 90% in probability judgments to about
20% in frequency judgments.2 Thus, the task is not too hard for most people, once it is clariÔ¨Å ed
that it is about mathematical probability and not about something else.3
2 Note that Tversky and Kahneman (1983) had reported an effect of frequency for a different problem, but DEMO
GG_Boun_1997.indd 4
not pay much attention to it.
3 The reason why most people chose to interpret ‚ÄúWhich is more probable?‚Äù other than DEMO terms of mathemati-
cal probability seems to be that the latter would imply that the description of Linda is irrelevant for the task,
DEMO in turn would imply that the experimenter violates Grice‚Äôs (1975) conversational maxim of ‚Äúrelevance.‚Äù
This conclusion is supported by the task analysis, experiments, and paraphrasing tasks reported in Hertwig
and Gigerenzer (1996). In DEMO words, people‚Äôs judgments reÔ¨Ç ect social rationality, not mental inability. In
defense against my critique (e.g., Gigerenzer, 1991), Kahneman and Tversky (1996) constructed a between-
subjects design for the Linda problem, and claimed that at least in this special situation the conjunction
fallacy is DEMO even with frequency judgments. They asked one group ‚ÄúSuppose there are 1,000 women
who Ô¨Å t this description. How many of them are (a) high school teachers? (b) bank tellers?‚Äù and a DEMO
group ‚ÄúHow many of them are (a) high school teachers, DEMO (c) bank tellers and active feminists.‚Äù (p. 587)
The DEMO of (c) was higher than that of (b), which DEMO took as a violation of the conjunction rule. Note
that Kahneman and Tversky (1996) had changed in this experiment the original conjunction ‚Äúbank DEMO
and active in the feminist movement‚Äù into ‚Äúbank tellers and feminists,‚Äù that is, a noun-active/adjective to a
noun-noun combination. They did not point out this change. Hertwig (1997) has provided evidence that
people DEMO tend to read the new formulation as a disjunction (rather than DEMO conjunction), and that
the ‚Äúconjunction fallacy‚Äù in Kahneman and Tversky‚Äôs (DEMO) between-subjects design disappeared when this
misleading formulation is replaced by the DEMO conjunction. The problem with Kahneman and Tversky‚Äôs
(1996) defense is the same as with their original analysis of the Linda problem: A content-blind norm is ap-
plied, and how people actually understand the task environment is not analyzed.
17.04.2007 8:04:28 Uhr
Gerd Gigerenzer 5
The conjunction fallacy is not the only so-called cognitive DEMO that largely disappears
when probabilities are replaced by frequencies. Gigerenzer, Hoffrage DEMO Kleinb√∂lting (1991)
showed that overconÔ¨Å dence bias completely disappeared when DEMO were asked ‚ÄúHow
many of the last 50 questions did you get correct?‚Äù instead of ‚ÄúWhat is the probability that
your answer to DEMO question is correct?‚Äù (see also May, 1987; Sniezek & DEMO, 1993). Lay
persons‚Äô reasoning followed Bayes‚Äô rule about three times DEMO often when the information was in
a frequency format rather than in a probability format (Cosmides & Tooby, 1996; Gigerenzer &
Hoffrage, 1995). Physicians‚Äô diagnostic inferences followed Bayes‚Äô rule four times as often DEMO
frequency formats than with probabilities (Gigerenzer, 1996b; Hoffrage & Gigerenzer, 1996).
Teigen (1974) reported that overestimation of probabilities (e.g., DEMO is the probability that a
randomly chosen female student at the University of Bergen is above 160 cm tall?) changed into
more realistic DEMO when subjects were given the opportunity to estimate frequencies (e.g., If
we measure 500 female students, how many of them will be above 160 cm tall?). The difference
between single events and repeated events also makes the ‚Äúillusion of control‚Äù (Langer, 1975)
largely disappear (Budescu & Bruderman, 1995; Koehler, Gibbs, & Hogarth, 1994), makes the
certainty effect and the possibility effect (Kahneman & Tversky, DEMO) largely disappear (Keren,
1991; Keren & Wagenaar, 1987), and reduces preference reversals (Wedell & B√∂ckenholt, 1990).
A review DEMO the effects of frequency is in Gigerenzer (1991, 1994), and theoretical explanations in
Gigerenzer and Hoffrage (1995) and Gigerenzer et al. (1991). For a different view see Kahneman
and Tversky (1996), and for my response, Gigerenzer (1996a).
‚ÄúCognitive illusions‚Äù have been DEMO in the last three decades as hard facts similar to
‚Äúvisual illusions‚Äù‚Äîstubborn, largely ineradicable, genuine illusions, to which laymen and experts
fall prey. The fact that one-and-the-same factor, frequencies versus probabilities, can make such DEMO
broad spectrum of alleged cognitive illusions largely disappear suggests that the tasks are not too
hard, and the fault is not simply in the human mind. These results should not be read to imply
that frequency DEMO are always correct. There exist theories of cognitive processes that pre-
dict when they are and when not (Gigerenzer et al., 1991; Gigerenzer & Hoffrage, 1995). But
it should be clear that the single most trenchant conclusion reached by the heuristics-and-biases
program, namely that people are all too bad at reasoning, is itself, to a large degree, an illusion
fostered by all-too-narrow norms of sound reasoning.
To summarize: The study of bounded rationality has been recently associated with the search
for DEMO, deÔ¨Å ned as systematic discrepancies from some rule of probability. I DEMO stated four
general requirements for bounded rationality and concluded that the heuristics-and-biases ap-
proach to human judgment has little to do with studying bounded DEMO The stock-in-
trade biases tend to disappear largely when the problems are formulated in terms of frequencies
rather than probabilities.
The purpose of models DEMO bounded rationality cannot be to explain deviations of human
judgment from rules of probability. In the situations in which bounded rationality applies, the
solution cannot be reduced to one of these rules. The purpose is to DEMO how people can do
better than chance, that is, to explain deviations from random performance in the direction of
successful performance.
GG_Boun_1997.indd 5
DEMO 8:04:28 Uhr
6
2. Models of SatisÔ¨Å
cing Inference
How can a mind infer DEMO properties of its environment on the basis of limited knowledge
about that environment? How can these inferences be modeled, assuming the constraints of
DEMO time and computational capacities? I will consider models of satisÔ¨Å cing DEMO that
embody, in addition to the general criteria listed above, the following speciÔ¨Å c criteria:
‚Äì Step-by-step procedures
‚Äì Limited search (simple stopping rules)
‚Äì One-reason decision making (non-compensatory strategies)
‚Äì Exploitation of a lack of knowledge (how to make positive use of one‚Äôs ignorance)
‚Äì Exploitation of structures of information (structures of environments).
This paper deals with the following type of inference: Which of two objects scores higher on a
criterion? This inference is a special case of the more general problem of infering which object in
a class DEMO M objects has the highest value on a criterion, but I DEMO consider here only the case of
M = 2. Examples are treatment allocation (e.g., which of two patients to treat Ô¨Å rst in DEMO emer-
gency room, with life expectancy after treatment as criterion), DEMO nancial investment (e.g., which
of two options to buy, with DEMO t as criterion), and demographic predictions (e.g., which of two
places has higher pollution, mortality rates, and so on).
Bounded DEMO: Models of Fast and Frugal Inference
Take The Best
Take The DEMO is a satisÔ¨Å cing algorithm designed for problems of this kind, DEMO is, for situations
in which fast inferences have to be made DEMO which of two objects (patients, alternatives) scores
higher on some DEMO (Gigerenzer & Goldstein, 1996). The general situation is illustrated in
Figure 1. There are N objects (a, b, c, ‚Ä¶) and a number of predictors that have binary values
(the situation can be generalized to continuous predictors, e.g., by dichotomizing). I explain DEMO
step-by-step algorithm of Take The Best with a demographic problem that we originally used to















 
 
 
 DEMO
 
 
 
 
 
 
 
 
 
 




DEMO













			 !" #$ #$%&
'(!	)(*+&'			*) !	,-())
),',).!)&!'"!*) !)"	",-())
)		)		",))"	 !!'	"#/0
/!	112$
DEMO 1.  Illustration of bounded search through limited knowledge.
GG_Boun_1997.indd 6
17.04.2007 DEMO:04:28 Uhr
Gerd Gigerenzer 7
GG_Boun_1997.indd 7
study its performance: Which of two cities has a larger population? Here, a and b are two Ger-
DEMO cities, say Bremen and Heidelberg. Examples of predictors that indicate higher DEMO
are soccer team (whether or not a city has a team DEMO the major soccer league) and state capital
(whether or not a city is a state capital). The predictors are ordered according to DEMO (perceived)
validity, with Predictor 1 at the top. The predictor values can be positive (a city has a soccer team,
which indicates larger population), negative (has no soccer team), or unknown (the person has
no information). The task is to infer which city, a or b, has a larger population. In addition to
DEMO ecological predictors, there is a subjective cue, recognition (whether or DEMO the person has
heard of the city). Recognition only plays a role when it is correlated with the criterion, as it is
with population.
Step-by-step procedure. Take The Best looks up in memory, step-by-step, DEMO concern-
ing predictors, until a predictor is found that discriminates. Discrimination DEMO when one
object has a positive value and the other has no positive value (negative or unknown). How does
Take The Best infer which of two cities, Bremen (a) and Heidelberg (b), DEMO the larger popula-
tion, given the limited knowledge in Figure 1? First, the recognition values are looked up, which
in this case DEMO not discriminate, because both are positive. Next, the values on the top-ranking
ecological predictor, the soccer team cue (Predictor 1) are searched. Bremen has a soccer team in
the major league, but Heidelberg does not. Search in memory is terminated, and the inference is
made that Bremen has the larger population. No other predictor values are looked up DEMO memory.
Thus, only 4 out of 12 values in Figure 1 (striped area) are looked up. None are integrated. Con-
sider now the inference, which of b and c has a higher population. The values for recognition and
Predictor 1 do not discriminate, but those of Predictor 2 do. Thus 6 values are looked up (dot-
ted area in Figure 1) before search is terminated and the inference is made that b has the higher
population. Finally, consider the inference, which of DEMO and d is larger? Object c is recognized, d is
not; that‚Äôs it. The inference is made that c has the larger population. The Take The Best algorithm
is shown in the form of a DEMO ow chart in Figure 2.
Limited search. Take The Best operates by limited search with an explicit stopping (discrimi-
nation) rule. Its motto DEMO ‚Äútake the best, ignore the rest.‚Äù In contrast, ‚Äúrational‚Äù inference, DEMO
traditionally conceived, needs to look up all available information. Take Figure DEMO
The Best violates this tenet of classical rationality. The stopping rule makes the algorithm fast
(search is quickly terminated) and frugal (only a few predictor values are used for the inference).
One-reason decision making. DEMO inference is made by one predictor only; there is no inte-
DEMO and compensation of predictors. Take The Best is non-compensatory. For instance, DEMO
positive values of object b in Predictors 2 and 3 (Figure DEMO) cannot reverse the decision made solely
on the basis of the DEMO ranking Predictor 1. In contrast, ‚Äúrational‚Äù inference, as traditionally
conceived, DEMO all available information in some optimal way. Take The Best violates this
maxim. One-reason decision making makes the algorithm computationally simple, if computa-
tion is sequential.
Exploitation of a lack of knowledge. Take The Best operates DEMO the recognition principle: If one
of the two alternatives is recognized, and the other not, then choose the recognized object. Note that
this principle is non-compensatory. For instance, the three negative predictor values of object c
do not reverse the inference that c is larger than d (Figure 1). The recognition principle can only
be used when a DEMO has a lack of knowledge (i.e., does not recognize one of the alternatives)
and exploits this lack in environments where recognition is DEMO random but correlated with the
criterion. The recognition principle is the most frugal satisÔ¨Å cing principle, because it feeds on a
lack of knowledge rather than just limited knowledge. Its surprising power can lead to the DEMO
terintuitive less-is-more effect, that is, that inferences based on less knowledge can be systemati-
17.04.2007 8:04:29 Uhr
8
Bounded Rationality: Models of Fast and Frugal Inference
3
 
DEMO 

/
5
)

'(
))! 
()))"
4
)
)
.
5



4
Figure 2.  Flow diagram of the Take The Best algorithm (Gigerenzer & Goldstein, 1996).
cally better DEMO inferences based on more knowledge. The structures of environments in which
less-is-more effects occur are described in Goldstein and Gigerenzer (1997).
Exploitation of structures of information (environments). The recognition principle can exploit
certain structures of information (recognition correlated with the criterion). Similarly, Take The
DEMO can exploit certain structures of information, such as exponentially decreasing weights DEMO
binary predictors (see below), which allows high levels of accuracy (Martignon, Hoffrage, &
Kriegeskorte, 1997).
A Competition
Although Take DEMO Best seems to reÔ¨Ç ect what people actually do in many situations under con-
straints of limited time and knowledge, its simplicity raises the suspicion that it will dismally fail
when making inferences about unknown features DEMO real environments. For instance, when Kee-
ney and Raiffa (1993) DEMO the lexicographic ordering procedure‚Äîa procedure related to
Take The Best‚Äîthey concluded that this procedure ‚Äúis naively simple‚Äù and ‚Äúwill rarely pass a test
of DEMO (p. 78). How could an inference based on only one DEMO compete with
one based on an integration of all information available? DEMO order to test how accurate Take The
Best is, Daniel Goldstein DEMO I set up a competition between Take The Best and Ô¨Å ve linear inte-
gration algorithms, including multiple regression (Gigerenzer & Goldstein, 1996). The task was
to infer which of two cities has the DEMO population, as described above, for all German cities
GG_Boun_1997.indd 8
17.04.2007 8:04:29 Uhr
Gerd Gigerenzer 9
with more than 100,000 inhabitants (83 cities) DEMO nine ecological predictors. In order to simu-
late limited knowledge, we DEMO millions of hypothetical subjects, each of whom had a differ-
ent DEMO of knowledge, by replacing actual predictor values with unknown values. For DEMO
of these subjects, the proportion of correct inferences (whether Heidelberg is really larger than
Bonn) in all possible tests (83 x 82/DEMO pairs of cities) was determined using Take The Best. Simi-
larly, the proportion of correct inferences was determined using each of the Ô¨Å DEMO linear integration
algorithms. Competitors such as multiple regression computed inferences with the beta weights.
The linear algorithms always based each inference on all information (predictor values), whereas
Take The Best used, on the average, DEMO less than one third of this information. The counterin-
tuitive result was that Take The Best matched every one of the competing algorithms in DEMO,
including multiple regression, and performed better than some (Gigerenzer &  Goldstein, 1996).
Figure 3 illustrates this result for the special DEMO in which every algorithm performs best, that
is, when the simulated persons have complete knowledge of predictor values for each city they
recognize. DEMO recognition is shown on the x-axis, from 0 to all cities DEMO
Note that the performance exhibits a less-is-more effect. For instance, the DEMO person
who recognizes all cities and has complete information about all values of 83 cities in 9 predic-
tors (at the very right of Figure 3) would make more accurate inferences if she had less complete
information, such as information about the values of only 60 cities. The reason is the power
97
8
,',).
:)	!!*
,!!*
97
8
87


2
87
2
27

27
DEMO
:)	!&	!
;<()	!&	!
7
5&-
DEMO
7
7 77777278797
,)=<=)(9*"-&!	()(DEMO,!!*
)&-" "	 !%()	!!*()) !()) !	
-)"	%)<()!&	!&")&-"  !&)&-
  !%)()	!&	!()) !()) DEMO)"	%	
)&!"!&	!&")()>DEMO)&!/
	/!	#112$"*)112*??
Figure 3.  DEMO of the competition between Take The Best and Ô¨Å
ve linear algorithms.
GG_Boun_1997.indd 9
17.04.2007 8:04:29 Uhr
"-6-
10
Bounded Rationality: Models of Fast and Frugal Inference
of the recognition principle (which can no longer be applied when all objects are recognized),
which is explicit in Take The Best and implicit in some of the linear algorithms (Gigerenzer &
Goldstein, 1996).
This result is an existence proof that fast and frugal inference can be as DEMO as computa-
tionally expensive algorithms that use more knowledge and time. But does this result generalize
to other situations, or is there something peculiar with the population demographics of German
cities? What is the structure of information in natural environments that Take The Best can ex-
ploit, and when would it fail? How do variants of Take The Best that are faster and more frugal
perform?
Does the Performance of Take DEMO Best Generalize to Other Environments?
We have simulated the performance of Take The Best in eight task environments, and compared
it to the most powerful linear competitor, multiple regression (Czerlinski, Goldstein, &  Gigerenzer,
1997). The tasks included predicting the mortality rates in 20 DEMO Angeles districts from 15 in-
dicators of pollution and demographic information; DEMO rates in 57 Chicago high schools
based on 18 indicators such as the average salary of the teachers and the proportion of white
students; and attractiveness ratings of prominent men and women, based on three cues. These
competitions were performed for the case of complete knowledge, that is, where the recognition
principle (which exploits a lack of knowledge) could not help Take The Best. In four of the eight
environments, the proportion of accurate inferences was the same for multiple regression and
Take DEMO Best, in two others multiple regression performed slightly better (1 or 2 percentage
points), and in only two environments there was a DEMO advantage of multiple regression (6 and
9 percentage points). The DEMO proportions of correct inferences ranged between 65% and 84%.
Thus, the DEMO performance of Take The Best did generalize. Equally important, there were
DEMO differences that provide clues for understanding why and when Take The Best per-
forms so well.
What Structures of Environments Allow Take The Best DEMO Perform So Well?
Martignon et al. (1997) have proven conditions under which Take The Best can and cannot be
outperformed by a DEMO linear model (with predictor-criterion correlations as weights). I
summarize here DEMO gist of their proofs. In environments with abundant information (i.e., where
the number of cues is very large compared to log ÀÜ
linear DEMO perform better. Consistent with this proof, the two environments in which DEMO
tiple regression had a clear edge in performance in the simulations were those where the number
of predictors was large relative to the number DEMO objects (such as 15 cues for 20 objects). In
environments DEMO scarce information (where the number of cues is small relative to DEMO number
of objects, deÔ¨Å
Finally, when the weights of binary predictors are exponentially decreasing, such as 1/2,1/4,1/8,
and therefore are non-compensatory, no weighted linear model, including multiple regression,DEMO
can outperform the faster and more frugal Take The Best.
In many situations humans must make inferences on the basis of scarce information. Envi-
DEMO with strictly non-compensatory cue weights are also not uncommon. For instance, DEMO
ned as less than or equal than log 2ÀÜ
N), Take The Best performs better on average.
2 N, where N is the number of objects), weighted
GG_Boun_1997.indd 10
17.04.2007 8:04:29 Uhr
Gerd Gigerenzer 11
a study about people‚Äôs reactions to their experience with DEMO ofÔ¨Å cers and judges, Tyler (1997,
Figure 2) reported DEMO beta weights of three predictors (fairness of the procedure, fairness of the
outcome, and favorability of the outcome) for each of three DEMO: people‚Äôs respect of the law,
their evaluation of the legal DEMO involved, and their personal feelings following the experi-
ence. For the DEMO rst two criteria, the sets of beta weights were strictly non-compensatory, and for
the third, approximately so. Among the eight data sets that Czerlinski et al. (1997) analyzed there
were three with strictly non-compensatory DEMO Scarce information as well as non-compensa-
tory information is where Take The Best Ô¨Ç ourishes.
Can SatisÔ¨Å
cing Inferences Get by With Even Less DEMO?
Take The Best uses information about the rank order of the validity of the predictors (as opposed
to weighted linear models which use information about the quantitative validities of predictors).
Assume that this rank DEMO is not known, only the direction into which each of the DEMO
points (whether a predictor signals a higher or a lower value DEMO the criterion). Two variants of Take
The Best operate with this reduced information. They differ from Take The Best only in which
predictors DEMO look up Ô¨Å rst. ‚ÄúTake The Last‚Äù tries Ô¨Å rst the predictor that discriminated the last
time; if it does not discriminate, then DEMO predictor that worked the next to last time is examined,
and so on. Take The Last works by a well-known psychological principle, the ‚ÄúEinstellung effect‚Äù
(Luchins & Luchins, 1994) of Gestalt psychology. By contrast, the ‚ÄúMinimalist‚Äù just tries predic-
tors in random order. Neither of these two algorithms needs information about which predictors
are better than others. How DEMO are the inferences that these satisÔ¨Å cing algorithms draw? For
population DEMO, Gigerenzer and Goldstein (1996) showed that the accuracy of these DEMO algo-
rithms was, on average, only about 1 percentage point less than that of Take The Best, and still
higher than some of the linear models. Each of them stopped earlier than Take The Best, that is,
searched for less information. The performance of these two DEMO cing algorithms was striking.
Take The Best is a member of a larger family, the PMM (‚ÄúProbabilistic Mental Models‚Äù)
family of satisÔ¨Å DEMO algorithms (Gigerenzer, 1994; Gigerenzer et al., 1991). The closest relatives
to Take The Best (but not to Take The Last and the Minimalist, which do not order predictors
according to their validity) DEMO lexicographic strategies and the classiÔ¨Å cation and regression tree
(CART) models (Breiman et al., 1993). Different from lexicographic strategies, however, DEMO
The Best does not produce systematic intransitive inferences.
3. Summing Up
When a person makes inferences about unknown states of the world under constraints DEMO limited
knowledge and time, she is typically not in a position DEMO calculate the optimal solution, even if
such a solution is attainable. DEMO The Best and its variants are fast and frugal algorithms that
can draw inferences with a minimum of knowledge and computational effort. These algorithms
DEMO based on simple psychologically plausible principles. They violate two classical tenets of ratio-
nality: They do not look up all available information and they use one-reason decision making.
Nevertheless, Take The Best can be as accurate as weighted linear models, and we can specify
the structure of environments in which these satisÔ¨Å cing algorithms do well. Models of bounded
inference DEMO not necessarily have to forsake accuracy for simplicity, nor rationality for DEMO
logical plausibility‚Äîthe mind can have it both ways.
GG_Boun_1997.indd 11
17.04.2007 8:04:30 Uhr
12
Bounded Rationality: Models of Fast and Frugal Inference
References
Breiman, DEMO, Friedman, J. H., Olshen, R. A., & Stone, C. J. (1993). ClassiÔ¨Å cation and regression trees. New York:
Chapman and Hall.
Budescu, D. V., & Bruderman, M. (1995). DEMO relationship between the illusion of control and the desirability
bias. Journal of Behavioral Decision Making, 8, 109‚Äì125.
Camerer, C. (1995). Individual DEMO making. In J. H. Kagel & A. E. Roth (Eds.), DEMO of experimental
economics (pp. 587‚Äì703). Princeton, NJ: Princeton University DEMO
Cosmides, L., & Tooby, J. (1996). Are humans good intuitive statisticians after all? Rethinking some conclusions
from the literature on judgment under uncertainty. Cognition, 58, 1‚Äì73.
Czerlinski, J., Goldstein, D., & Gigerenzer, G. (1997). Information environments and algorithms that exploit them.
Manuscript, Max Planck Institute for Psychological Research, Munich.
Einhorn, H. J., & Hogarth, R. M. (1981). Behavioral decision theory: Processes DEMO judgment and choice. Annual
Review of Psychology, 32, 53‚Äì88.
Fiedler, DEMO (1988). The dependence of the conjunction fallacy on subtle linguistic DEMO Psychological Research,
50, 123‚Äì129.
Gigerenzer, G. (1991). How DEMO make cognitive illusions disappear: Beyond ‚Äúheuristics and biases‚Äù. European
Review of DEMO Psychology, 2, 83‚Äì115.
Gigerenzer, G. (1993). The bounded rationality of probabilistic mental models. In K. I. Manktelow & D. E. Over
(Eds.), Rationality: Psychological and philosophical perspectives (pp. 284‚Äì313). London: Routledge.
Gigerenzer, G. (1994). Why the distinction between single-event probabilities DEMO frequencies is relevant for
psychology (and vice versa). In G. DEMO & P. Ayton (Eds.), Subjective probability (pp. 129‚Äì161). New York:
Wiley.
Gigerenzer, G. (1996a). On narrow norms and DEMO heuristics: A reply to Kahneman and Tversky (1996). Psy-
chological Review, 103, 592‚Äì596.
Gigerenzer, G. (1996b). The psychology of DEMO judgment: Frequency formats and simple algorithms. Journal of
Medical Decision Making, 16, 273‚Äì280.
Gigerenzer, G., & Goldstein, D. G. (1996). Reasoning the fast and frugal way: Models of bounded rationality.
Psychological Review, 103, 650‚Äì669.
Gigerenzer, G., & Hoffrage, U. (1995). DEMO to improve Bayesian reasoning without instruction: Frequency
formats. Psychological Review, 102, 684‚Äì704.
Gigerenzer, G., Hoffrage, U., & Kleinb√∂lting, H. (1991). Probabilistic mental models: A Brunswikian theory of
conÔ¨Å dence. Psychological Review, 98, 506‚Äì528.
Gigerenzer, G., & Murray, D. J. (1987)DEMO Cognition as intuitive statistics. Hillsdale, NJ: Erlbaum.
Goldstein, D. G., & Gigerenzer, G. (1997). Recognition: How to exploit a lack of knowledge. Manu script submitted
for publication.
Gould, S. J. (1992)DEMO Bully for brontosaurus. Further reÔ¨Ç ections in natural history. London: Penguin DEMO
Grice, H. P. (1975). Logic and conversation. In P. Cole & J. L. Morgan (Eds.), Syntax and semantics 3: Speech DEMO
(pp. 41‚Äì58). New York: Academic Press.
Hertwig, R. (1997). Judgement under uncertainty: Beyond probabilities. Manuscript submitted for publication.
Hertwig, DEMO, & Gigerenzer, G. (1996). The ‚Äúconjunction fallacy‚Äù revisited: How intelligent inferences look like reason-
ing errors. Manuscript submitted for publication.
Hoffrage, U., & Gigerenzer, G. (1996). The impact of information representation on Bayesian reasoning. In G.
Cottrell (Ed.), Proceedings of the Eighteenth Annual Conference of the Cognitive Science Society (pp. 126‚Äì130).
Mahwah, DEMO: Erlbaum.
Kahneman, D., Slovic, P., & Tversky, A. (DEMO). (1982). Judgment under uncertainty: Heuristics and biases. Cam-
bridge, UK: Cambridge University Press.
Kahneman, D., & Tversky, A. (DEMO). Prospect theory: An analysis of decision under risk. Econometrica, 47,
263‚Äì291.
Kahneman, D., & Tversky, A. (1996). On DEMO reality of cognitive illusions. Psychological Review, 103, 582‚Äì591.
Kanwisher, N. (1989). Cognitive heuristics and American security policy. Journal of ConÔ¨Ç ict DEMO, 33, 652‚Äì
675.
Keeney, R. L., & Raiffa, H. (1993). Decisions with multiple objectives. Cambridge, UK: Cambridge University
Press.
DEMO, G. (1991). Additional tests of utility theory under unique and repeated conditions. Journal of Behavioral
Decision Making, 4, 297‚Äì304.
Keren, G., & Wagenaar, W. A. (1987). Violation of utility theory in unique and repeated gambles. Journal of
Experimental Psychology: Learning, Memory and DEMO, 13, 387‚Äì391.
GG_Boun_1997.indd 12
17.04.2007 8:04:30 Uhr
Gerd Gigerenzer 13
Koehler, J. J., Gibbs, B. J., & DEMO, R. M. (1994). Shattering the illusion of control: Multi-shot DEMO single-
shot gambles. Journal of Behavioral Decision Making, 7, 183‚Äì192.
Langer, E. J. (1975). The illusion of control. Journal of Personality DEMO Social Psychology, 32, 311‚Äì328.
Lopes, L. L. (1991). The rhetoric of irrationality. Theory & Psychology, 1, 65‚Äì82.
Lopes, L. L. (1992). Three misleading assumptions in the customary rhetoric of the bias literature. Theory &
Psychology, 2, 231‚Äì236.
Luchins, A. S., & Luchins, E. H. (1994). The water jar experiments and Einstellung DEMO: I. Early history and
surveys of textbook citations. Gestalt Theory, 16, 101‚Äì121.
Martignon, L., Hoffrage, U., & Kriegeskorte, N. (1997). Lexicographic comparison under uncertainty: A satisÔ¨Å cing
algorithm. Manuscript, Max DEMO Institute for Psychological Research, Munich.
May, R. S. (1987). DEMO von Subjektiven Wahrscheinlichkeiten. Frankfurt a.M.: Lang.
Oaksford, M., & Chater, N. (1992). Bounded rationality in taking risks and drawing inferences. Theory & Psy-
chology, 2, 225‚Äì230.
Shanteau, J. (1989). Cognitive DEMO and biases in behavioral auditing: Review, comments and observations.
Accounting Organizations and Society, 14, 165‚Äì177.
Simon, H. A. (1955). A DEMO model of rational choice. Quarterly Journal of Economics, 69, 99‚Äì118.
Simon, H. A. (1979). Models of thought. New Haven, CT: DEMO University Press.
Simon, H. A. (1982). Models of bounded rationality (2 vols.). Cambridge, MA: MIT Press.
Simon, H. A. (1990). Invariants of human behavior. Annual Review of Psychology, 41, DEMO
Simon, H. A. (1991). Cognitive architectures and rational analysis: DEMO In K. Vanlehn (Ed.), Architectures
for intelligence (pp. 25‚Äì39). Hillsdale, NJ: Erlbaum.
Simon, H. A. (1992). Economics, bounded rationality, and the cognitive revolution. Aldershot Hants, UK: Elgar.
Sniezek, DEMO A., & Buckley, T. (1993). Decision errors made by DEMO and groups. In N. J. Castellan (Ed.),
Individual and group decision making. Hillsdale, NJ: Erlbaum.
Stich, S. P. (1985). DEMO man be an irrational animal? Synthese, 64, 115‚Äì135.
Teigen, K. H. (1974). Overestimation of subjective probabilities. Scandinavian Journal of Psychology, DEMO, 56‚Äì62.
Thaler, R. H. (1991). Quasi rational economics. New DEMO: Sage.
Tversky, A., & Kahneman, D. (1983). Extensional DEMO intuitive reasoning: The conjunction fallacy in prob-
ability judgment. Psychological Review, 90, 293‚Äì315.
Tyler, T. R. (1997). Procedural fairness and compliance with the law. Schweizerische Zeitschrift f√ºr Volkswirtschaft
und Statistik, 133 (2/DEMO).
Wallsten, T. S. (1983). The theoretical status of judgmental heuristics. In R. W. Scholz (Ed.), Decision making
under uncertainty (DEMO 21‚Äì39). Amsterdam: Elsevier.
Wedell, D. H., & B√∂ckenholt, U. (1990). Moderation of preference reversals in the long run. Journal of Experi-
mental Psychology: Human Perception and Performance, 16, 429‚Äì438.
Summary
I specify general criteria for models of bounded rationality and discuss speciÔ¨Å c DEMO for sat-
isÔ¨Å cing inference. The task of these fast and frugal algorithms is to infer unknown features of
their environment under the constraints DEMO limited knowledge, limited time, and limited com-
putational capacities. These algorithms violate fundamental tenets of classical rationality: They
neither look up nor integrate all information. I review the performance of the satisÔ¨Å cing ‚ÄúTake
The DEMO algorithm. Despite its frugality, Take The Best can make as many DEMO inferences as
computationally expensive weighted linear models that use and combine all available informa-
tion. Accurate inferences need not follow the dictates of classical DEMO
Zusammenfassung
Ich formuliere allgemeine Kriterien f√ºr Modelle begrenzter Rationalit√§t und diskutiere spezi-
Ô¨Å sche ‚ÄúsatisÔ¨Å cing‚Äù Modelle f√ºr Inferenz unter Unsicherheit. Die Aufgabe dieser DEMO und
GG_Boun_1997.indd 13
17.04.2007 8:04:30 Uhr
14
Bounded Rationality: Models of Fast and Frugal Inference
einfachen Algorithmen ist, unbekannte Eigenschaften der Umwelt zu erschlie√üen, und zwar mit
begrenztem Wissen, begrenzter Zeit und begrenzter rechnerischer Kapazit√§t. Diese Algorithmen
verletzen fundamentale Annahmen klassischer DEMO: Sie suchen weder alle verf√ºgbare In-
formation, noch integrieren sie Information. Ich berichte √ºber die Leistung des ‚ÄúTake The Best‚Äù
Algorithmus. Trotz seiner DEMO kann ‚ÄúTake The Best‚Äù genauso viele richtige Inferenzen
machen wie rechnerisch aufwendige gewichtete lineare Modelle, welche alle verf√ºgbare Infor-
mation verwenden und kombinieren. Richtige Inferenzen m√ºssen nicht den Regeln klassischer
Rationalit√§t folgen.
GG_Boun_1997.indd 14
17.04.2007 8:DEMO:30 Uhr{1g42fwefx}